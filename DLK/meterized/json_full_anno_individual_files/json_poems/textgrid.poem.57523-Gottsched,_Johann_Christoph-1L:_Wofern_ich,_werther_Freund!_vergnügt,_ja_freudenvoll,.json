{"textgrid.poem.57523": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wofern ich, werther Freund! vergn\u00fcgt, ja freudenvoll,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wofern ich, werther Freund! vergn\u00fcgt, ja freudenvoll,", "tokens": ["Wo\u00b7fern", "ich", ",", "wert\u00b7her", "Freund", "!", "ver\u00b7gn\u00fcgt", ",", "ja", "freu\u00b7den\u00b7voll", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$.", "VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey deinem Hochzeitfest mein Wort erf\u00fcllen soll,", "tokens": ["Bey", "dei\u00b7nem", "Hoch\u00b7zeit\u00b7fest", "mein", "Wort", "er\u00b7f\u00fcl\u00b7len", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den treuen Gl\u00fcckwunsch dir in Versen abzusingen;", "tokens": ["Den", "treu\u00b7en", "Gl\u00fcck\u00b7wunsch", "dir", "in", "Ver\u00b7sen", "ab\u00b7zu\u00b7sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So sey es mir erlaubt, ein Spr\u00fcchwort vorzubringen,", "tokens": ["So", "sey", "es", "mir", "er\u00b7laubt", ",", "ein", "Spr\u00fcch\u00b7wort", "vor\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du h\u00e4ltst es sonst zwar auch mit unsrer neuen Welt;", "tokens": ["Du", "h\u00e4ltst", "es", "sonst", "zwar", "auch", "mit", "uns\u00b7rer", "neu\u00b7en", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch weil dir Ehrlichkeit und alte Treu gef\u00e4llt,", "tokens": ["Doch", "weil", "dir", "Ehr\u00b7lich\u00b7keit", "und", "al\u00b7te", "Treu", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "KON", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dergleichen Tugenden die lieben Alten trieben:", "tokens": ["Derg\u00b7lei\u00b7chen", "Tu\u00b7gen\u00b7den", "die", "lie\u00b7ben", "Al\u00b7ten", "trie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wirst du auch ein Wort von ihren Lippen lieben;", "tokens": ["So", "wirst", "du", "auch", "ein", "Wort", "von", "ih\u00b7ren", "Lip\u00b7pen", "lie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Wort, darinn die Spur von alter Weisheit steht,", "tokens": ["Ein", "Wort", ",", "da\u00b7rinn", "die", "Spur", "von", "al\u00b7ter", "Weis\u00b7heit", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die leider! t\u00e4glich mehr bey uns zu Grunde geht.", "tokens": ["Die", "lei\u00b7der", "!", "t\u00e4g\u00b7lich", "mehr", "bey", "uns", "zu", "Grun\u00b7de", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$.", "ADJD", "ADV", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Es hei\u00dft, damit ich auch fein nach der Ordnung schreibe,", "tokens": ["Es", "hei\u00dft", ",", "da\u00b7mit", "ich", "auch", "fein", "nach", "der", "Ord\u00b7nung", "schrei\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dir das Thema nicht so lange schuldig bleibe:", "tokens": ["Und", "dir", "das", "The\u00b7ma", "nicht", "so", "lan\u00b7ge", "schul\u00b7dig", "blei\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "PTKNEG", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In Gruft und Moder hin! Bey diesen zwenen Theilen,", "tokens": ["In", "Gruft", "und", "Mo\u00b7der", "hin", "!", "Bey", "die\u00b7sen", "zwe\u00b7nen", "Thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Soll mein Gedichte sich f\u00fcr diesesmal verweilen.", "tokens": ["Soll", "mein", "Ge\u00b7dich\u00b7te", "sich", "f\u00fcr", "die\u00b7ses\u00b7mal", "ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PRF", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu Anfang handelt es das sp\u00e4te Lob und Grab,", "tokens": ["Zu", "An\u00b7fang", "han\u00b7delt", "es", "das", "sp\u00e4\u00b7te", "Lob", "und", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So dann die L\u00e4sterung bey dem Verm\u00e4hlen ab.", "tokens": ["So", "dann", "die", "L\u00e4s\u00b7te\u00b7rung", "bey", "dem", "Ver\u00b7m\u00e4h\u00b7len", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "In beyden will ich dir den Lauf der Welt erkl\u00e4ren,", "tokens": ["In", "bey\u00b7den", "will", "ich", "dir", "den", "Lauf", "der", "Welt", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VMFIN", "PPER", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und dann den Wunsch an dich und deine Braut gew\u00e4hren.", "tokens": ["Und", "dann", "den", "Wunsch", "an", "dich", "und", "dei\u00b7ne", "Braut", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Zum ersten ist es wahr, die Welt lobt keinen leicht,", "tokens": ["Zum", "ers\u00b7ten", "ist", "es", "wahr", ",", "die", "Welt", "lobt", "kei\u00b7nen", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VAFIN", "PPER", "ADJD", "$,", "ART", "NN", "VVFIN", "PIAT", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bevor er in der Gruft sein letztes Ziel erreicht.", "tokens": ["Be\u00b7vor", "er", "in", "der", "Gruft", "sein", "letz\u00b7tes", "Ziel", "er\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lange jemand lebt, wird alles, was er machet,", "tokens": ["So", "lan\u00b7ge", "je\u00b7mand", "lebt", ",", "wird", "al\u00b7les", ",", "was", "er", "ma\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "VAFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beginnet und vollbringt, getadelt und verlachet.", "tokens": ["Be\u00b7gin\u00b7net", "und", "voll\u00b7bringt", ",", "ge\u00b7ta\u00b7delt", "und", "ver\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Sein Wesen nennt man schlecht. Man lobt und billigt nichts.", "tokens": ["Sein", "We\u00b7sen", "nennt", "man", "schlecht", ".", "Man", "lobt", "und", "bil\u00b7ligt", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "ADJD", "$.", "PIS", "VVFIN", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In allem, was er thut, gedenkt und sagt, gebrichts,", "tokens": ["In", "al\u00b7lem", ",", "was", "er", "thut", ",", "ge\u00b7denkt", "und", "sagt", ",", "ge\u00b7brichts", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "An hundert wenigstens, wo nicht an tausend St\u00fccken:", "tokens": ["An", "hun\u00b7dert", "we\u00b7nigs\u00b7tens", ",", "wo", "nicht", "an", "tau\u00b7send", "St\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADV", "$,", "PWAV", "PTKNEG", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn besser pflegt es auch dem Kl\u00fcgsten nicht zu gl\u00fccken.", "tokens": ["Denn", "bes\u00b7ser", "pflegt", "es", "auch", "dem", "Kl\u00fcgs\u00b7ten", "nicht", "zu", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Allein er sterbe nur: da geht das Loben an!", "tokens": ["Al\u00b7lein", "er", "ster\u00b7be", "nur", ":", "da", "geht", "das", "Lo\u00b7ben", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was nie ein Mensch vermocht, was niemand glauben kann,", "tokens": ["Was", "nie", "ein", "Mensch", "ver\u00b7mocht", ",", "was", "nie\u00b7mand", "glau\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was hunderte vor ihm vergebens unternommen,", "tokens": ["Was", "hun\u00b7der\u00b7te", "vor", "ihm", "ver\u00b7ge\u00b7bens", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das alles ist durch ihn in rechten Stand gekommen.", "tokens": ["Das", "al\u00b7les", "ist", "durch", "ihn", "in", "rech\u00b7ten", "Stand", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er hat die Fr\u00f6mmigkeit und Tugend stets geliebt;", "tokens": ["Er", "hat", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "und", "Tu\u00b7gend", "stets", "ge\u00b7liebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er hat durch Wort und Werk kein kleines Kind betr\u00fcbt.", "tokens": ["Er", "hat", "durch", "Wort", "und", "Werk", "kein", "klei\u00b7nes", "Kind", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ihm ist die Vaterstadt f\u00fcr all ihr Heil verbunden;", "tokens": ["Ihm", "ist", "die", "Va\u00b7ter\u00b7stadt", "f\u00fcr", "all", "ihr", "Heil", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIAT", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bey ihm hat allezeit das Armuth Rath gefunden.", "tokens": ["Bey", "ihm", "hat", "al\u00b7le\u00b7zeit", "das", "Ar\u00b7muth", "Rath", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er war der Weysen Trost, der Wittwen Schirm und Schild,", "tokens": ["Er", "war", "der", "Wey\u00b7sen", "Trost", ",", "der", "Witt\u00b7wen", "Schirm", "und", "Schild", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und kurz, der Unschuld Schutz, der Tugend Ebenbild.", "tokens": ["Und", "kurz", ",", "der", "Un\u00b7schuld", "Schutz", ",", "der", "Tu\u00b7gend", "E\u00b7ben\u00b7bild", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ja w\u00e4r er in der That von allem nichts gewesen:", "tokens": ["Ja", "w\u00e4r", "er", "in", "der", "That", "von", "al\u00b7lem", "nichts", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "APPR", "ART", "NN", "APPR", "PIS", "PIS", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So l\u00e4\u00dft mans doch gedruckt in mancher Lobschrift lesen.", "tokens": ["So", "l\u00e4\u00dft", "mans", "doch", "ge\u00b7druckt", "in", "man\u00b7cher", "Lob\u00b7schrift", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "VVPP", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "O! merkt euch dieses an, die ihr aus Eitelkeit", "tokens": ["O", "!", "merkt", "euch", "die\u00b7ses", "an", ",", "die", "ihr", "aus", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PPER", "PDS", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von toller Ehrsucht krank, nach Lobe durstig seyd!", "tokens": ["Von", "tol\u00b7ler", "Ehr\u00b7sucht", "krank", ",", "nach", "Lo\u00b7be", "durs\u00b7tig", "seyd", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was qu\u00e4let ihr euch viel, ber\u00fchmt und gro\u00df zu werden?", "tokens": ["Was", "qu\u00e4\u00b7let", "ihr", "euch", "viel", ",", "be\u00b7r\u00fchmt", "und", "gro\u00df", "zu", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "ADV", "$,", "ADJD", "KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist euch mit Ruhm gedient? verkriecht euch in der Erden!", "tokens": ["Ist", "euch", "mit", "Ruhm", "ge\u00b7dient", "?", "ver\u00b7kriecht", "euch", "in", "der", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$.", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lang ihr lebend hofft am Lobe reich zu seyn:", "tokens": ["So", "lang", "ihr", "le\u00b7bend", "hofft", "am", "Lo\u00b7be", "reich", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "VVFIN", "APPRART", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So trifft der Wunsch gewi\u00df nur bey den Schm\u00e4uchlern ein;", "tokens": ["So", "trifft", "der", "Wunsch", "ge\u00b7wi\u00df", "nur", "bey", "den", "Schm\u00e4uch\u00b7lern", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der abgeschmackten Brut, in deren bl\u00f6den Augen", "tokens": ["Der", "ab\u00b7ge\u00b7schmack\u00b7ten", "Brut", ",", "in", "de\u00b7ren", "bl\u00f6\u00b7den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die \u00e4rgsten Fehler auch zu Wunderdingen taugen.", "tokens": ["Die", "\u00e4rgs\u00b7ten", "Feh\u00b7ler", "auch", "zu", "Wun\u00b7der\u00b7din\u00b7gen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seyd froh! wenn euch der Hof zu seinen Dienern z\u00e4hlt,", "tokens": ["Seyd", "froh", "!", "wenn", "euch", "der", "Hof", "zu", "sei\u00b7nen", "Die\u00b7nern", "z\u00e4hlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da glaubt nur, da\u00df es euch an keinem Lobe fehlt.", "tokens": ["Da", "glaubt", "nur", ",", "da\u00df", "es", "euch", "an", "kei\u00b7nem", "Lo\u00b7be", "fehlt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Aus Hoffnung eurer Gunst wird alles sich bem\u00fchen,", "tokens": ["Aus", "Hoff\u00b7nung", "eu\u00b7rer", "Gunst", "wird", "al\u00b7les", "sich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VAFIN", "PIS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn ihr gleich Zwerge seyd, euch Riesen vorzuziehen.", "tokens": ["Wenn", "ihr", "gleich", "Zwer\u00b7ge", "seyd", ",", "euch", "Rie\u00b7sen", "vor\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "$,", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch wem ein ernstlich Lob, ohn Eigennutz, gef\u00e4llt,", "tokens": ["Doch", "wem", "ein", "ernst\u00b7lich", "Lob", ",", "ohn", "Ei\u00b7gen\u00b7nutz", ",", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJD", "NN", "$,", "KOUI", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der mache sich je ehr je lieber aus der Welt.", "tokens": ["Der", "ma\u00b7che", "sich", "je", "ehr", "je", "lie\u00b7ber", "aus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADJD", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Alsdann erf\u00fcllt sein Ruhm den weiten Kreis der Erden,", "tokens": ["Als\u00b7dann", "er\u00b7f\u00fcllt", "sein", "Ruhm", "den", "wei\u00b7ten", "Kreis", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ja was er niemals war, das wird er dann erst werden.", "tokens": ["Ja", "was", "er", "nie\u00b7mals", "war", ",", "das", "wird", "er", "dann", "erst", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "PPER", "ADV", "VAFIN", "$,", "PDS", "VAFIN", "PPER", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Das war mein erster Theil. Zum zweyten merk ich auch,", "tokens": ["Das", "war", "mein", "ers\u00b7ter", "Theil", ".", "Zum", "zwey\u00b7ten", "merk", "ich", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "APPRART", "ADJA", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach meines Spr\u00fcchworts Sinn, den h\u00e4\u00dflichen Gebrauch", "tokens": ["Nach", "mei\u00b7nes", "Spr\u00fcch\u00b7worts", "Sinn", ",", "den", "h\u00e4\u00df\u00b7li\u00b7chen", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des klugen P\u00f6bels an; der, wenn man sich verm\u00e4hlet,", "tokens": ["Des", "klu\u00b7gen", "P\u00f6\u00b7bels", "an", ";", "der", ",", "wenn", "man", "sich", "ver\u00b7m\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "ART", "$,", "KOUS", "PIS", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Fehler, die man hat, wohl zehnmal \u00fcberz\u00e4hlet.", "tokens": ["Die", "Feh\u00b7ler", ",", "die", "man", "hat", ",", "wohl", "zehn\u00b7mal", "\u00fc\u00b7berz\u00b7\u00e4h\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du seyst auch, wer du seyst, ein Junggesell, ein Mann,", "tokens": ["Du", "seyst", "auch", ",", "wer", "du", "seyst", ",", "ein", "Jung\u00b7ge\u00b7sell", ",", "ein", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWS", "PPER", "VAFIN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein M\u00e4gdchen, oder Weib; so bist du \u00fcbel dran,", "tokens": ["Ein", "M\u00e4gd\u00b7chen", ",", "o\u00b7der", "Weib", ";", "so", "bist", "du", "\u00fc\u00b7bel", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "NN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dafern du freyen willst. Was du von Kindesbeinen", "tokens": ["Da\u00b7fern", "du", "frey\u00b7en", "willst", ".", "Was", "du", "von", "Kin\u00b7des\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$.", "PWS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Begangen oder nicht, wird hier entdeckt erscheinen.", "tokens": ["Be\u00b7gan\u00b7gen", "o\u00b7der", "nicht", ",", "wird", "hier", "ent\u00b7deckt", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKNEG", "$,", "VAFIN", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was du dein Lebenlang geredet und gedacht,", "tokens": ["Was", "du", "dein", "Le\u00b7ben\u00b7lang", "ge\u00b7re\u00b7det", "und", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das wird hervor gesucht, zur L\u00e4sterung gemacht,", "tokens": ["Das", "wird", "her\u00b7vor", "ge\u00b7sucht", ",", "zur", "L\u00e4s\u00b7te\u00b7rung", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wacker ausposaunt. Ja, was du nie verrichtet,", "tokens": ["Und", "wa\u00b7cker", "aus\u00b7po\u00b7saunt", ".", "Ja", ",", "was", "du", "nie", "ver\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$.", "PTKANT", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ja, was du nie getr\u00e4umt, wird doch von dir erdichtet.", "tokens": ["Ja", ",", "was", "du", "nie", "ge\u00b7tr\u00e4umt", ",", "wird", "doch", "von", "dir", "er\u00b7dich\u00b7tet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "PPER", "ADV", "VVPP", "$,", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bald schrecket man die Braut mit ihres Freyers Art;", "tokens": ["Bald", "schre\u00b7cket", "man", "die", "Braut", "mit", "ih\u00b7res", "Frey\u00b7ers", "Art", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Erz\u00e4hlt, wie vielmal er sich w\u00f6chentlich den Bart", "tokens": ["Er\u00b7z\u00e4hlt", ",", "wie", "viel\u00b7mal", "er", "sich", "w\u00f6\u00b7chent\u00b7lich", "den", "Bart"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWAV", "ADV", "PPER", "PRF", "ADJD", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Herunter nehmen l\u00e4\u00dft? wie oft er schon purgiret,", "tokens": ["Her\u00b7un\u00b7ter", "neh\u00b7men", "l\u00e4\u00dft", "?", "wie", "oft", "er", "schon", "pur\u00b7gi\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "$.", "PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Geschwitzt und Ader lie\u00df, und wo das herger\u00fchret?", "tokens": ["Ge\u00b7schwitzt", "und", "A\u00b7der", "lie\u00df", ",", "und", "wo", "das", "her\u00b7ge\u00b7r\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "NN", "VVFIN", "$,", "KON", "PWAV", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie manches M\u00e4gdchen er bald hie, bald da gek\u00fc\u00dft?", "tokens": ["Wie", "man\u00b7ches", "M\u00e4gd\u00b7chen", "er", "bald", "hie", ",", "bald", "da", "ge\u00b7k\u00fc\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "ADV", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was er bezahlet hat, und was er schuldig ist?", "tokens": ["Was", "er", "be\u00b7zah\u00b7let", "hat", ",", "und", "was", "er", "schul\u00b7dig", "ist", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VAFIN", "$,", "KON", "PWS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Bald schildert man das Bild der Br\u00e4ute bey den Freyern:", "tokens": ["Bald", "schil\u00b7dert", "man", "das", "Bild", "der", "Br\u00e4u\u00b7te", "bey", "den", "Frey\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die, hei\u00dft es, l\u00e4\u00dft sich stets das Angesicht erneuern;", "tokens": ["Die", ",", "hei\u00dft", "es", ",", "l\u00e4\u00dft", "sich", "stets", "das", "An\u00b7ge\u00b7sicht", "er\u00b7neu\u00b7ern", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die hat so manchen schon durch ihren Ku\u00df vergn\u00fcgt;", "tokens": ["Die", "hat", "so", "man\u00b7chen", "schon", "durch", "ih\u00b7ren", "Ku\u00df", "ver\u00b7gn\u00fcgt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die hat kein baares Geld, und nur ihr Staat betr\u00fcgt;", "tokens": ["Die", "hat", "kein", "baa\u00b7res", "Geld", ",", "und", "nur", "ihr", "Staat", "be\u00b7tr\u00fcgt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "ADJA", "NN", "$,", "KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die hat ein loses Maul, und sonsten b\u00f6se Fl\u00fcsse;", "tokens": ["Die", "hat", "ein", "lo\u00b7ses", "Maul", ",", "und", "sons\u00b7ten", "b\u00f6\u00b7se", "Fl\u00fcs\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die ist an H\u00e4nden plump, und die hat krumme F\u00fc\u00dfe.", "tokens": ["Die", "ist", "an", "H\u00e4n\u00b7den", "plump", ",", "und", "die", "hat", "krum\u00b7me", "F\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "ADJD", "$,", "KON", "PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "So pflegt es denen auch in ihrer Art zu gehn,", "tokens": ["So", "pflegt", "es", "de\u00b7nen", "auch", "in", "ih\u00b7rer", "Art", "zu", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sonst Verdienst und Gl\u00fcck zu Aemtern will erh\u00f6hn.", "tokens": ["Die", "sonst", "Ver\u00b7dienst", "und", "Gl\u00fcck", "zu", "A\u00b7em\u00b7tern", "will", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "KON", "NN", "PTKZU", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da pflegt ein jedes Maul den Neiderzahn zu sch\u00e4rfen,", "tokens": ["Da", "pflegt", "ein", "je\u00b7des", "Maul", "den", "Nei\u00b7der\u00b7zahn", "zu", "sch\u00e4r\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihm bald die\u00df, bald das, aus Bosheit, vorzuwerfen.", "tokens": ["Und", "ihm", "bald", "die\u00df", ",", "bald", "das", ",", "aus", "Bos\u00b7heit", ",", "vor\u00b7zu\u00b7wer\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PDS", "$,", "ADV", "PDS", "$,", "APPR", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bald spricht der Unverstand: die Schrift ist ihm ein Spott!", "tokens": ["Bald", "spricht", "der", "Un\u00b7ver\u00b7stand", ":", "die", "Schrift", "ist", "ihm", "ein", "Spott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald ruft die K\u00fchnheit nach: er glaubet keinen Gott!", "tokens": ["Bald", "ruft", "die", "K\u00fchn\u00b7heit", "nach", ":", "er", "glau\u00b7bet", "kei\u00b7nen", "Gott", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bis endlich, wenn die Treu ihr Amt geschickt erf\u00fcllet,", "tokens": ["Bis", "end\u00b7lich", ",", "wenn", "die", "Treu", "ihr", "Amt", "ge\u00b7schickt", "er\u00b7f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die L\u00e4sterung sich sch\u00e4mt, die Unvernunft sich stillet.", "tokens": ["Die", "L\u00e4s\u00b7te\u00b7rung", "sich", "sch\u00e4mt", ",", "die", "Un\u00b7ver\u00b7nunft", "sich", "stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "$,", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Wie gl\u00fccklich ist denn nicht ein kluger Freyersmann,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", "denn", "nicht", "ein", "klu\u00b7ger", "Frey\u00b7ers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, wenn er freyen will, es heimlich halten kann:", "tokens": ["Der", ",", "wenn", "er", "frey\u00b7en", "will", ",", "es", "heim\u00b7lich", "hal\u00b7ten", "kann", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil die\u00df nicht gar oft gelinget und gedeihet;", "tokens": ["Und", "weil", "die\u00df", "nicht", "gar", "oft", "ge\u00b7lin\u00b7get", "und", "ge\u00b7dei\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "PTKNEG", "ADV", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie kl\u00fcglich handelt der, der lieber gar nicht freyet!", "tokens": ["Wie", "kl\u00fcg\u00b7lich", "han\u00b7delt", "der", ",", "der", "lie\u00b7ber", "gar", "nicht", "fre\u00b7yet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "$,", "PRELS", "ADV", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Doch nein, geehrter Freund! dein Beyspiel strafet mich.", "tokens": ["Doch", "nein", ",", "ge\u00b7ehr\u00b7ter", "Freund", "!", "dein", "Bey\u00b7spiel", "stra\u00b7fet", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "ADJA", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du freyest offenbar: und hier erweiset sich", "tokens": ["Du", "frey\u00b7est", "of\u00b7fen\u00b7bar", ":", "und", "hier", "er\u00b7wei\u00b7set", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "KON", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein unerschrocknes Herz, das Gott und Tugend ehret,", "tokens": ["Dein", "un\u00b7er\u00b7schrock\u00b7nes", "Herz", ",", "das", "Gott", "und", "Tu\u00b7gend", "eh\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich in aller Welt an keine L\u00e4strer kehret.", "tokens": ["Und", "sich", "in", "al\u00b7ler", "Welt", "an", "kei\u00b7ne", "L\u00e4st\u00b7rer", "keh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man sage, was man will, du hast doch wohl gethan.", "tokens": ["Man", "sa\u00b7ge", ",", "was", "man", "will", ",", "du", "hast", "doch", "wohl", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PRELS", "PIS", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du folgtest jederzeit der wahren Ehrenbahn;", "tokens": ["Du", "folg\u00b7test", "je\u00b7der\u00b7zeit", "der", "wah\u00b7ren", "Eh\u00b7ren\u00b7bahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und bist durch Flei\u00df und Gl\u00fcck nunmehr so weit gedrungen,", "tokens": ["Und", "bist", "durch", "Flei\u00df", "und", "Gl\u00fcck", "nun\u00b7mehr", "so", "weit", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dir die Heirath auch nach Herzenswunsch gelungen.", "tokens": ["Da\u00df", "dir", "die", "Hei\u00b7rath", "auch", "nach", "Her\u00b7zens\u00b7wunsch", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was schadt es, wenn der Neid bald die\u00df, bald jenes spricht?", "tokens": ["Was", "schadt", "es", ",", "wenn", "der", "Neid", "bald", "die\u00df", ",", "bald", "je\u00b7nes", "spricht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "ADV", "PDS", "$,", "ADV", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auf andrer Leute Wort beruht dein Gl\u00fccke nicht.", "tokens": ["Auf", "an\u00b7drer", "Leu\u00b7te", "Wort", "be\u00b7ruht", "dein", "Gl\u00fc\u00b7cke", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wenn ein neues Paar einander herzlich liebet,", "tokens": ["Und", "wenn", "ein", "neu\u00b7es", "Paar", "ein\u00b7an\u00b7der", "herz\u00b7lich", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Schw\u00e4tzern keinen Raum zu leerem Plaudern giebet;", "tokens": ["Den", "Schw\u00e4t\u00b7zern", "kei\u00b7nen", "Raum", "zu", "lee\u00b7rem", "Plau\u00b7dern", "gie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So lebt es doch vergn\u00fcgt, und lacht in seinem Sinn:", "tokens": ["So", "lebt", "es", "doch", "ver\u00b7gn\u00fcgt", ",", "und", "lacht", "in", "sei\u00b7nem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie du, mein ", "tokens": ["Wie", "du", ",", "mein"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Gl\u00fcck zu! (der Wunsch ist kurz) der Himmel wird es lenken,", "tokens": ["Gl\u00fcck", "zu", "!", "(", "der", "Wunsch", "ist", "kurz", ")", "der", "Him\u00b7mel", "wird", "es", "len\u00b7ken", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "$(", "ART", "NN", "VAFIN", "ADJD", "$(", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und eurer neuen Eh sehr viel Vergn\u00fcgen schenken.", "tokens": ["Und", "eu\u00b7rer", "neu\u00b7en", "Eh", "sehr", "viel", "Ver\u00b7gn\u00fc\u00b7gen", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Wofern ich, werther Freund! vergn\u00fcgt, ja freudenvoll,", "tokens": ["Wo\u00b7fern", "ich", ",", "wert\u00b7her", "Freund", "!", "ver\u00b7gn\u00fcgt", ",", "ja", "freu\u00b7den\u00b7voll", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJA", "NN", "$.", "VVPP", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bey deinem Hochzeitfest mein Wort erf\u00fcllen soll,", "tokens": ["Bey", "dei\u00b7nem", "Hoch\u00b7zeit\u00b7fest", "mein", "Wort", "er\u00b7f\u00fcl\u00b7len", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den treuen Gl\u00fcckwunsch dir in Versen abzusingen;", "tokens": ["Den", "treu\u00b7en", "Gl\u00fcck\u00b7wunsch", "dir", "in", "Ver\u00b7sen", "ab\u00b7zu\u00b7sin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So sey es mir erlaubt, ein Spr\u00fcchwort vorzubringen,", "tokens": ["So", "sey", "es", "mir", "er\u00b7laubt", ",", "ein", "Spr\u00fcch\u00b7wort", "vor\u00b7zu\u00b7brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVPP", "$,", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du h\u00e4ltst es sonst zwar auch mit unsrer neuen Welt;", "tokens": ["Du", "h\u00e4ltst", "es", "sonst", "zwar", "auch", "mit", "uns\u00b7rer", "neu\u00b7en", "Welt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Doch weil dir Ehrlichkeit und alte Treu gef\u00e4llt,", "tokens": ["Doch", "weil", "dir", "Ehr\u00b7lich\u00b7keit", "und", "al\u00b7te", "Treu", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "KON", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dergleichen Tugenden die lieben Alten trieben:", "tokens": ["Derg\u00b7lei\u00b7chen", "Tu\u00b7gen\u00b7den", "die", "lie\u00b7ben", "Al\u00b7ten", "trie\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So wirst du auch ein Wort von ihren Lippen lieben;", "tokens": ["So", "wirst", "du", "auch", "ein", "Wort", "von", "ih\u00b7ren", "Lip\u00b7pen", "lie\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein Wort, darinn die Spur von alter Weisheit steht,", "tokens": ["Ein", "Wort", ",", "da\u00b7rinn", "die", "Spur", "von", "al\u00b7ter", "Weis\u00b7heit", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PAV", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die leider! t\u00e4glich mehr bey uns zu Grunde geht.", "tokens": ["Die", "lei\u00b7der", "!", "t\u00e4g\u00b7lich", "mehr", "bey", "uns", "zu", "Grun\u00b7de", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$.", "ADJD", "ADV", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-++--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Es hei\u00dft, damit ich auch fein nach der Ordnung schreibe,", "tokens": ["Es", "hei\u00dft", ",", "da\u00b7mit", "ich", "auch", "fein", "nach", "der", "Ord\u00b7nung", "schrei\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und dir das Thema nicht so lange schuldig bleibe:", "tokens": ["Und", "dir", "das", "The\u00b7ma", "nicht", "so", "lan\u00b7ge", "schul\u00b7dig", "blei\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "PTKNEG", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In Gruft und Moder hin! Bey diesen zwenen Theilen,", "tokens": ["In", "Gruft", "und", "Mo\u00b7der", "hin", "!", "Bey", "die\u00b7sen", "zwe\u00b7nen", "Thei\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Soll mein Gedichte sich f\u00fcr diesesmal verweilen.", "tokens": ["Soll", "mein", "Ge\u00b7dich\u00b7te", "sich", "f\u00fcr", "die\u00b7ses\u00b7mal", "ver\u00b7wei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PRF", "APPR", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zu Anfang handelt es das sp\u00e4te Lob und Grab,", "tokens": ["Zu", "An\u00b7fang", "han\u00b7delt", "es", "das", "sp\u00e4\u00b7te", "Lob", "und", "Grab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So dann die L\u00e4sterung bey dem Verm\u00e4hlen ab.", "tokens": ["So", "dann", "die", "L\u00e4s\u00b7te\u00b7rung", "bey", "dem", "Ver\u00b7m\u00e4h\u00b7len", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "In beyden will ich dir den Lauf der Welt erkl\u00e4ren,", "tokens": ["In", "bey\u00b7den", "will", "ich", "dir", "den", "Lauf", "der", "Welt", "er\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VMFIN", "PPER", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und dann den Wunsch an dich und deine Braut gew\u00e4hren.", "tokens": ["Und", "dann", "den", "Wunsch", "an", "dich", "und", "dei\u00b7ne", "Braut", "ge\u00b7w\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "APPR", "PPER", "KON", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Zum ersten ist es wahr, die Welt lobt keinen leicht,", "tokens": ["Zum", "ers\u00b7ten", "ist", "es", "wahr", ",", "die", "Welt", "lobt", "kei\u00b7nen", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VAFIN", "PPER", "ADJD", "$,", "ART", "NN", "VVFIN", "PIAT", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bevor er in der Gruft sein letztes Ziel erreicht.", "tokens": ["Be\u00b7vor", "er", "in", "der", "Gruft", "sein", "letz\u00b7tes", "Ziel", "er\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So lange jemand lebt, wird alles, was er machet,", "tokens": ["So", "lan\u00b7ge", "je\u00b7mand", "lebt", ",", "wird", "al\u00b7les", ",", "was", "er", "ma\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "VAFIN", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Beginnet und vollbringt, getadelt und verlachet.", "tokens": ["Be\u00b7gin\u00b7net", "und", "voll\u00b7bringt", ",", "ge\u00b7ta\u00b7delt", "und", "ver\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.5": {"text": "Sein Wesen nennt man schlecht. Man lobt und billigt nichts.", "tokens": ["Sein", "We\u00b7sen", "nennt", "man", "schlecht", ".", "Man", "lobt", "und", "bil\u00b7ligt", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PIS", "ADJD", "$.", "PIS", "VVFIN", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "In allem, was er thut, gedenkt und sagt, gebrichts,", "tokens": ["In", "al\u00b7lem", ",", "was", "er", "thut", ",", "ge\u00b7denkt", "und", "sagt", ",", "ge\u00b7brichts", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "An hundert wenigstens, wo nicht an tausend St\u00fccken:", "tokens": ["An", "hun\u00b7dert", "we\u00b7nigs\u00b7tens", ",", "wo", "nicht", "an", "tau\u00b7send", "St\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ADV", "$,", "PWAV", "PTKNEG", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Denn besser pflegt es auch dem Kl\u00fcgsten nicht zu gl\u00fccken.", "tokens": ["Denn", "bes\u00b7ser", "pflegt", "es", "auch", "dem", "Kl\u00fcgs\u00b7ten", "nicht", "zu", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Allein er sterbe nur: da geht das Loben an!", "tokens": ["Al\u00b7lein", "er", "ster\u00b7be", "nur", ":", "da", "geht", "das", "Lo\u00b7ben", "an", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was nie ein Mensch vermocht, was niemand glauben kann,", "tokens": ["Was", "nie", "ein", "Mensch", "ver\u00b7mocht", ",", "was", "nie\u00b7mand", "glau\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,", "PRELS", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Was hunderte vor ihm vergebens unternommen,", "tokens": ["Was", "hun\u00b7der\u00b7te", "vor", "ihm", "ver\u00b7ge\u00b7bens", "un\u00b7ter\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das alles ist durch ihn in rechten Stand gekommen.", "tokens": ["Das", "al\u00b7les", "ist", "durch", "ihn", "in", "rech\u00b7ten", "Stand", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er hat die Fr\u00f6mmigkeit und Tugend stets geliebt;", "tokens": ["Er", "hat", "die", "Fr\u00f6m\u00b7mig\u00b7keit", "und", "Tu\u00b7gend", "stets", "ge\u00b7liebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er hat durch Wort und Werk kein kleines Kind betr\u00fcbt.", "tokens": ["Er", "hat", "durch", "Wort", "und", "Werk", "kein", "klei\u00b7nes", "Kind", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "NN", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ihm ist die Vaterstadt f\u00fcr all ihr Heil verbunden;", "tokens": ["Ihm", "ist", "die", "Va\u00b7ter\u00b7stadt", "f\u00fcr", "all", "ihr", "Heil", "ver\u00b7bun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PIAT", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Bey ihm hat allezeit das Armuth Rath gefunden.", "tokens": ["Bey", "ihm", "hat", "al\u00b7le\u00b7zeit", "das", "Ar\u00b7muth", "Rath", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Er war der Weysen Trost, der Wittwen Schirm und Schild,", "tokens": ["Er", "war", "der", "Wey\u00b7sen", "Trost", ",", "der", "Witt\u00b7wen", "Schirm", "und", "Schild", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und kurz, der Unschuld Schutz, der Tugend Ebenbild.", "tokens": ["Und", "kurz", ",", "der", "Un\u00b7schuld", "Schutz", ",", "der", "Tu\u00b7gend", "E\u00b7ben\u00b7bild", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ART", "NN", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Ja w\u00e4r er in der That von allem nichts gewesen:", "tokens": ["Ja", "w\u00e4r", "er", "in", "der", "That", "von", "al\u00b7lem", "nichts", "ge\u00b7we\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VAFIN", "PPER", "APPR", "ART", "NN", "APPR", "PIS", "PIS", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "So l\u00e4\u00dft mans doch gedruckt in mancher Lobschrift lesen.", "tokens": ["So", "l\u00e4\u00dft", "mans", "doch", "ge\u00b7druckt", "in", "man\u00b7cher", "Lob\u00b7schrift", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "VVPP", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "O! merkt euch dieses an, die ihr aus Eitelkeit", "tokens": ["O", "!", "merkt", "euch", "die\u00b7ses", "an", ",", "die", "ihr", "aus", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PPER", "PDS", "PTKVZ", "$,", "PRELS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von toller Ehrsucht krank, nach Lobe durstig seyd!", "tokens": ["Von", "tol\u00b7ler", "Ehr\u00b7sucht", "krank", ",", "nach", "Lo\u00b7be", "durs\u00b7tig", "seyd", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was qu\u00e4let ihr euch viel, ber\u00fchmt und gro\u00df zu werden?", "tokens": ["Was", "qu\u00e4\u00b7let", "ihr", "euch", "viel", ",", "be\u00b7r\u00fchmt", "und", "gro\u00df", "zu", "wer\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "ADV", "$,", "ADJD", "KON", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist euch mit Ruhm gedient? verkriecht euch in der Erden!", "tokens": ["Ist", "euch", "mit", "Ruhm", "ge\u00b7dient", "?", "ver\u00b7kriecht", "euch", "in", "der", "Er\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "VVPP", "$.", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "So lang ihr lebend hofft am Lobe reich zu seyn:", "tokens": ["So", "lang", "ihr", "le\u00b7bend", "hofft", "am", "Lo\u00b7be", "reich", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "ADJD", "VVFIN", "APPRART", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So trifft der Wunsch gewi\u00df nur bey den Schm\u00e4uchlern ein;", "tokens": ["So", "trifft", "der", "Wunsch", "ge\u00b7wi\u00df", "nur", "bey", "den", "Schm\u00e4uch\u00b7lern", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der abgeschmackten Brut, in deren bl\u00f6den Augen", "tokens": ["Der", "ab\u00b7ge\u00b7schmack\u00b7ten", "Brut", ",", "in", "de\u00b7ren", "bl\u00f6\u00b7den", "Au\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die \u00e4rgsten Fehler auch zu Wunderdingen taugen.", "tokens": ["Die", "\u00e4rgs\u00b7ten", "Feh\u00b7ler", "auch", "zu", "Wun\u00b7der\u00b7din\u00b7gen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seyd froh! wenn euch der Hof zu seinen Dienern z\u00e4hlt,", "tokens": ["Seyd", "froh", "!", "wenn", "euch", "der", "Hof", "zu", "sei\u00b7nen", "Die\u00b7nern", "z\u00e4hlt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$.", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da glaubt nur, da\u00df es euch an keinem Lobe fehlt.", "tokens": ["Da", "glaubt", "nur", ",", "da\u00df", "es", "euch", "an", "kei\u00b7nem", "Lo\u00b7be", "fehlt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Aus Hoffnung eurer Gunst wird alles sich bem\u00fchen,", "tokens": ["Aus", "Hoff\u00b7nung", "eu\u00b7rer", "Gunst", "wird", "al\u00b7les", "sich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "VAFIN", "PIS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wenn ihr gleich Zwerge seyd, euch Riesen vorzuziehen.", "tokens": ["Wenn", "ihr", "gleich", "Zwer\u00b7ge", "seyd", ",", "euch", "Rie\u00b7sen", "vor\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "$,", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Doch wem ein ernstlich Lob, ohn Eigennutz, gef\u00e4llt,", "tokens": ["Doch", "wem", "ein", "ernst\u00b7lich", "Lob", ",", "ohn", "Ei\u00b7gen\u00b7nutz", ",", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJD", "NN", "$,", "KOUI", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der mache sich je ehr je lieber aus der Welt.", "tokens": ["Der", "ma\u00b7che", "sich", "je", "ehr", "je", "lie\u00b7ber", "aus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "ADJD", "ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Alsdann erf\u00fcllt sein Ruhm den weiten Kreis der Erden,", "tokens": ["Als\u00b7dann", "er\u00b7f\u00fcllt", "sein", "Ruhm", "den", "wei\u00b7ten", "Kreis", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Ja was er niemals war, das wird er dann erst werden.", "tokens": ["Ja", "was", "er", "nie\u00b7mals", "war", ",", "das", "wird", "er", "dann", "erst", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PWS", "PPER", "ADV", "VAFIN", "$,", "PDS", "VAFIN", "PPER", "ADV", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Das war mein erster Theil. Zum zweyten merk ich auch,", "tokens": ["Das", "war", "mein", "ers\u00b7ter", "Theil", ".", "Zum", "zwey\u00b7ten", "merk", "ich", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "APPRART", "ADJA", "NN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nach meines Spr\u00fcchworts Sinn, den h\u00e4\u00dflichen Gebrauch", "tokens": ["Nach", "mei\u00b7nes", "Spr\u00fcch\u00b7worts", "Sinn", ",", "den", "h\u00e4\u00df\u00b7li\u00b7chen", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des klugen P\u00f6bels an; der, wenn man sich verm\u00e4hlet,", "tokens": ["Des", "klu\u00b7gen", "P\u00f6\u00b7bels", "an", ";", "der", ",", "wenn", "man", "sich", "ver\u00b7m\u00e4h\u00b7let", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "ART", "$,", "KOUS", "PIS", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Fehler, die man hat, wohl zehnmal \u00fcberz\u00e4hlet.", "tokens": ["Die", "Feh\u00b7ler", ",", "die", "man", "hat", ",", "wohl", "zehn\u00b7mal", "\u00fc\u00b7berz\u00b7\u00e4h\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du seyst auch, wer du seyst, ein Junggesell, ein Mann,", "tokens": ["Du", "seyst", "auch", ",", "wer", "du", "seyst", ",", "ein", "Jung\u00b7ge\u00b7sell", ",", "ein", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "PWS", "PPER", "VAFIN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein M\u00e4gdchen, oder Weib; so bist du \u00fcbel dran,", "tokens": ["Ein", "M\u00e4gd\u00b7chen", ",", "o\u00b7der", "Weib", ";", "so", "bist", "du", "\u00fc\u00b7bel", "dran", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "NN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dafern du freyen willst. Was du von Kindesbeinen", "tokens": ["Da\u00b7fern", "du", "frey\u00b7en", "willst", ".", "Was", "du", "von", "Kin\u00b7des\u00b7bei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "$.", "PWS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Begangen oder nicht, wird hier entdeckt erscheinen.", "tokens": ["Be\u00b7gan\u00b7gen", "o\u00b7der", "nicht", ",", "wird", "hier", "ent\u00b7deckt", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKNEG", "$,", "VAFIN", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was du dein Lebenlang geredet und gedacht,", "tokens": ["Was", "du", "dein", "Le\u00b7ben\u00b7lang", "ge\u00b7re\u00b7det", "und", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das wird hervor gesucht, zur L\u00e4sterung gemacht,", "tokens": ["Das", "wird", "her\u00b7vor", "ge\u00b7sucht", ",", "zur", "L\u00e4s\u00b7te\u00b7rung", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "VVPP", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wacker ausposaunt. Ja, was du nie verrichtet,", "tokens": ["Und", "wa\u00b7cker", "aus\u00b7po\u00b7saunt", ".", "Ja", ",", "was", "du", "nie", "ver\u00b7rich\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVPP", "$.", "PTKANT", "$,", "PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ja, was du nie getr\u00e4umt, wird doch von dir erdichtet.", "tokens": ["Ja", ",", "was", "du", "nie", "ge\u00b7tr\u00e4umt", ",", "wird", "doch", "von", "dir", "er\u00b7dich\u00b7tet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PWS", "PPER", "ADV", "VVPP", "$,", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Bald schrecket man die Braut mit ihres Freyers Art;", "tokens": ["Bald", "schre\u00b7cket", "man", "die", "Braut", "mit", "ih\u00b7res", "Frey\u00b7ers", "Art", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Erz\u00e4hlt, wie vielmal er sich w\u00f6chentlich den Bart", "tokens": ["Er\u00b7z\u00e4hlt", ",", "wie", "viel\u00b7mal", "er", "sich", "w\u00f6\u00b7chent\u00b7lich", "den", "Bart"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWAV", "ADV", "PPER", "PRF", "ADJD", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Herunter nehmen l\u00e4\u00dft? wie oft er schon purgiret,", "tokens": ["Her\u00b7un\u00b7ter", "neh\u00b7men", "l\u00e4\u00dft", "?", "wie", "oft", "er", "schon", "pur\u00b7gi\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "$.", "PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Geschwitzt und Ader lie\u00df, und wo das herger\u00fchret?", "tokens": ["Ge\u00b7schwitzt", "und", "A\u00b7der", "lie\u00df", ",", "und", "wo", "das", "her\u00b7ge\u00b7r\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "NN", "VVFIN", "$,", "KON", "PWAV", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Wie manches M\u00e4gdchen er bald hie, bald da gek\u00fc\u00dft?", "tokens": ["Wie", "man\u00b7ches", "M\u00e4gd\u00b7chen", "er", "bald", "hie", ",", "bald", "da", "ge\u00b7k\u00fc\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "ADV", "ADV", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Was er bezahlet hat, und was er schuldig ist?", "tokens": ["Was", "er", "be\u00b7zah\u00b7let", "hat", ",", "und", "was", "er", "schul\u00b7dig", "ist", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "VAFIN", "$,", "KON", "PWS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Bald schildert man das Bild der Br\u00e4ute bey den Freyern:", "tokens": ["Bald", "schil\u00b7dert", "man", "das", "Bild", "der", "Br\u00e4u\u00b7te", "bey", "den", "Frey\u00b7ern", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die, hei\u00dft es, l\u00e4\u00dft sich stets das Angesicht erneuern;", "tokens": ["Die", ",", "hei\u00dft", "es", ",", "l\u00e4\u00dft", "sich", "stets", "das", "An\u00b7ge\u00b7sicht", "er\u00b7neu\u00b7ern", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Die hat so manchen schon durch ihren Ku\u00df vergn\u00fcgt;", "tokens": ["Die", "hat", "so", "man\u00b7chen", "schon", "durch", "ih\u00b7ren", "Ku\u00df", "ver\u00b7gn\u00fcgt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Die hat kein baares Geld, und nur ihr Staat betr\u00fcgt;", "tokens": ["Die", "hat", "kein", "baa\u00b7res", "Geld", ",", "und", "nur", "ihr", "Staat", "be\u00b7tr\u00fcgt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PIAT", "ADJA", "NN", "$,", "KON", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die hat ein loses Maul, und sonsten b\u00f6se Fl\u00fcsse;", "tokens": ["Die", "hat", "ein", "lo\u00b7ses", "Maul", ",", "und", "sons\u00b7ten", "b\u00f6\u00b7se", "Fl\u00fcs\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "KON", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Die ist an H\u00e4nden plump, und die hat krumme F\u00fc\u00dfe.", "tokens": ["Die", "ist", "an", "H\u00e4n\u00b7den", "plump", ",", "und", "die", "hat", "krum\u00b7me", "F\u00fc\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "ADJD", "$,", "KON", "PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "So pflegt es denen auch in ihrer Art zu gehn,", "tokens": ["So", "pflegt", "es", "de\u00b7nen", "auch", "in", "ih\u00b7rer", "Art", "zu", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die sonst Verdienst und Gl\u00fcck zu Aemtern will erh\u00f6hn.", "tokens": ["Die", "sonst", "Ver\u00b7dienst", "und", "Gl\u00fcck", "zu", "A\u00b7em\u00b7tern", "will", "er\u00b7h\u00f6hn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "NN", "KON", "NN", "PTKZU", "VVINF", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da pflegt ein jedes Maul den Neiderzahn zu sch\u00e4rfen,", "tokens": ["Da", "pflegt", "ein", "je\u00b7des", "Maul", "den", "Nei\u00b7der\u00b7zahn", "zu", "sch\u00e4r\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihm bald die\u00df, bald das, aus Bosheit, vorzuwerfen.", "tokens": ["Und", "ihm", "bald", "die\u00df", ",", "bald", "das", ",", "aus", "Bos\u00b7heit", ",", "vor\u00b7zu\u00b7wer\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PDS", "$,", "ADV", "PDS", "$,", "APPR", "NN", "$,", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bald spricht der Unverstand: die Schrift ist ihm ein Spott!", "tokens": ["Bald", "spricht", "der", "Un\u00b7ver\u00b7stand", ":", "die", "Schrift", "ist", "ihm", "ein", "Spott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Bald ruft die K\u00fchnheit nach: er glaubet keinen Gott!", "tokens": ["Bald", "ruft", "die", "K\u00fchn\u00b7heit", "nach", ":", "er", "glau\u00b7bet", "kei\u00b7nen", "Gott", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bis endlich, wenn die Treu ihr Amt geschickt erf\u00fcllet,", "tokens": ["Bis", "end\u00b7lich", ",", "wenn", "die", "Treu", "ihr", "Amt", "ge\u00b7schickt", "er\u00b7f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "KOUS", "ART", "NN", "PPOSAT", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die L\u00e4sterung sich sch\u00e4mt, die Unvernunft sich stillet.", "tokens": ["Die", "L\u00e4s\u00b7te\u00b7rung", "sich", "sch\u00e4mt", ",", "die", "Un\u00b7ver\u00b7nunft", "sich", "stil\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "$,", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Wie gl\u00fccklich ist denn nicht ein kluger Freyersmann,", "tokens": ["Wie", "gl\u00fcck\u00b7lich", "ist", "denn", "nicht", "ein", "klu\u00b7ger", "Frey\u00b7ers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der, wenn er freyen will, es heimlich halten kann:", "tokens": ["Der", ",", "wenn", "er", "frey\u00b7en", "will", ",", "es", "heim\u00b7lich", "hal\u00b7ten", "kann", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und weil die\u00df nicht gar oft gelinget und gedeihet;", "tokens": ["Und", "weil", "die\u00df", "nicht", "gar", "oft", "ge\u00b7lin\u00b7get", "und", "ge\u00b7dei\u00b7het", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PDS", "PTKNEG", "ADV", "ADV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie kl\u00fcglich handelt der, der lieber gar nicht freyet!", "tokens": ["Wie", "kl\u00fcg\u00b7lich", "han\u00b7delt", "der", ",", "der", "lie\u00b7ber", "gar", "nicht", "fre\u00b7yet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "$,", "PRELS", "ADV", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "Doch nein, geehrter Freund! dein Beyspiel strafet mich.", "tokens": ["Doch", "nein", ",", "ge\u00b7ehr\u00b7ter", "Freund", "!", "dein", "Bey\u00b7spiel", "stra\u00b7fet", "mich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$,", "ADJA", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Du freyest offenbar: und hier erweiset sich", "tokens": ["Du", "frey\u00b7est", "of\u00b7fen\u00b7bar", ":", "und", "hier", "er\u00b7wei\u00b7set", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "KON", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein unerschrocknes Herz, das Gott und Tugend ehret,", "tokens": ["Dein", "un\u00b7er\u00b7schrock\u00b7nes", "Herz", ",", "das", "Gott", "und", "Tu\u00b7gend", "eh\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und sich in aller Welt an keine L\u00e4strer kehret.", "tokens": ["Und", "sich", "in", "al\u00b7ler", "Welt", "an", "kei\u00b7ne", "L\u00e4st\u00b7rer", "keh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man sage, was man will, du hast doch wohl gethan.", "tokens": ["Man", "sa\u00b7ge", ",", "was", "man", "will", ",", "du", "hast", "doch", "wohl", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PRELS", "PIS", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du folgtest jederzeit der wahren Ehrenbahn;", "tokens": ["Du", "folg\u00b7test", "je\u00b7der\u00b7zeit", "der", "wah\u00b7ren", "Eh\u00b7ren\u00b7bahn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und bist durch Flei\u00df und Gl\u00fcck nunmehr so weit gedrungen,", "tokens": ["Und", "bist", "durch", "Flei\u00df", "und", "Gl\u00fcck", "nun\u00b7mehr", "so", "weit", "ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df dir die Heirath auch nach Herzenswunsch gelungen.", "tokens": ["Da\u00df", "dir", "die", "Hei\u00b7rath", "auch", "nach", "Her\u00b7zens\u00b7wunsch", "ge\u00b7lun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was schadt es, wenn der Neid bald die\u00df, bald jenes spricht?", "tokens": ["Was", "schadt", "es", ",", "wenn", "der", "Neid", "bald", "die\u00df", ",", "bald", "je\u00b7nes", "spricht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "ADV", "PDS", "$,", "ADV", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auf andrer Leute Wort beruht dein Gl\u00fccke nicht.", "tokens": ["Auf", "an\u00b7drer", "Leu\u00b7te", "Wort", "be\u00b7ruht", "dein", "Gl\u00fc\u00b7cke", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und wenn ein neues Paar einander herzlich liebet,", "tokens": ["Und", "wenn", "ein", "neu\u00b7es", "Paar", "ein\u00b7an\u00b7der", "herz\u00b7lich", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Den Schw\u00e4tzern keinen Raum zu leerem Plaudern giebet;", "tokens": ["Den", "Schw\u00e4t\u00b7zern", "kei\u00b7nen", "Raum", "zu", "lee\u00b7rem", "Plau\u00b7dern", "gie\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So lebt es doch vergn\u00fcgt, und lacht in seinem Sinn:", "tokens": ["So", "lebt", "es", "doch", "ver\u00b7gn\u00fcgt", ",", "und", "lacht", "in", "sei\u00b7nem", "Sinn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "VVPP", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wie du, mein ", "tokens": ["Wie", "du", ",", "mein"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWAV", "PPER", "$,", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Gl\u00fcck zu! (der Wunsch ist kurz) der Himmel wird es lenken,", "tokens": ["Gl\u00fcck", "zu", "!", "(", "der", "Wunsch", "ist", "kurz", ")", "der", "Him\u00b7mel", "wird", "es", "len\u00b7ken", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "$(", "ART", "NN", "VAFIN", "ADJD", "$(", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und eurer neuen Eh sehr viel Vergn\u00fcgen schenken.", "tokens": ["Und", "eu\u00b7rer", "neu\u00b7en", "Eh", "sehr", "viel", "Ver\u00b7gn\u00fc\u00b7gen", "schen\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}