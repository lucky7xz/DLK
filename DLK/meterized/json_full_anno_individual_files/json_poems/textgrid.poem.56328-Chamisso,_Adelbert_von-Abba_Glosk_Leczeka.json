{"textgrid.poem.56328": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "Abba Glosk Leczeka", "genre": "verse", "period": "N.A.", "pub_year": 1809, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es schallen gut im Liede der Purpur und das Schwert,", "tokens": ["Es", "schal\u00b7len", "gut", "im", "Lie\u00b7de", "der", "Pur\u00b7pur", "und", "das", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch h\u00fcllt sich oft in Lumpen, der auch ist preisenswert;", "tokens": ["Doch", "h\u00fcllt", "sich", "oft", "in", "Lum\u00b7pen", ",", "der", "auch", "ist", "prei\u00b7sens\u00b7wert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,", "PRELS", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich f\u00fchr euch einen Juden und Bettler heute vor,", "tokens": ["Ich", "f\u00fchr", "euch", "ei\u00b7nen", "Ju\u00b7den", "und", "Bett\u00b7ler", "heu\u00b7te", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "KON", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Abba Glosk Leczeka, verschlie\u00dft ihm nicht das Ohr.", "tokens": ["Den", "Ab\u00b7ba", "Glosk", "Le\u00b7cze\u00b7ka", ",", "ver\u00b7schlie\u00dft", "ihm", "nicht", "das", "Ohr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "NE", "$,", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Er harrte vor der T\u00fcre von Moses Mendelssohn", "tokens": ["Er", "harr\u00b7te", "vor", "der", "T\u00fc\u00b7re", "von", "Mo\u00b7ses", "Men\u00b7dels\u00b7sohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gelassen und geduldig vor Sonnenaufgang schon;", "tokens": ["Ge\u00b7las\u00b7sen", "und", "ge\u00b7dul\u00b7dig", "vor", "Son\u00b7nen\u00b7auf\u00b7gang", "schon", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie hoch in Himmelsr\u00e4umen zu steigen sie begann,", "tokens": ["Wie", "hoch", "in", "Him\u00b7mels\u00b7r\u00e4u\u00b7men", "zu", "stei\u00b7gen", "sie", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "APPR", "NN", "PTKZU", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Trat erst aus seiner Wohnung der weitber\u00fchmte Mann.", "tokens": ["Trat", "erst", "aus", "sei\u00b7ner", "Woh\u00b7nung", "der", "weit\u00b7be\u00b7r\u00fchm\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.3": {"line.1": {"text": "Ihn gr\u00fc\u00dft der fremde Bettler in polnisch j\u00fcd'scher Tracht,", "tokens": ["Ihn", "gr\u00fc\u00dft", "der", "frem\u00b7de", "Bett\u00b7ler", "in", "pol\u00b7nisch", "j\u00fcd'\u00b7scher", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sein Gru\u00df den Schriftgelehrten dem andern kenntlich macht,", "tokens": ["Sein", "Gru\u00df", "den", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "dem", "an\u00b7dern", "kennt\u00b7lich", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "ART", "ADJA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er aber geht vor\u00fcber: \u00bbAn Zeit es mir gebricht!\u00ab \u2013", "tokens": ["Er", "a\u00b7ber", "geht", "vor\u00b7\u00fc\u00b7ber", ":", "\u00bb", "An", "Zeit", "es", "mir", "ge\u00b7bricht", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$.", "$(", "APPR", "NN", "PPER", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Fremde weicht zur\u00fccke, doch von der Schwelle nicht.", "tokens": ["Der", "Frem\u00b7de", "weicht", "zu\u00b7r\u00fc\u00b7cke", ",", "doch", "von", "der", "Schwel\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ADV", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Und Mittag ward's und Abend, und als zur Nacht es ging,", "tokens": ["Und", "Mit\u00b7tag", "ward's", "und", "A\u00b7bend", ",", "und", "als", "zur", "Nacht", "es", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "KON", "NN", "$,", "KON", "KOUS", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Stadt in ihren Stra\u00dfen die Schatten schon empfing,", "tokens": ["Die", "Stadt", "in", "ih\u00b7ren", "Stra\u00b7\u00dfen", "die", "Schat\u00b7ten", "schon", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kam heim zu seinem Herde der weitber\u00fchmte Mann,", "tokens": ["Kam", "heim", "zu", "sei\u00b7nem", "Her\u00b7de", "der", "weit\u00b7be\u00b7r\u00fchm\u00b7te", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da gr\u00fc\u00dft' ihn noch der Bettler, wie morgens er getan.", "tokens": ["Da", "gr\u00fc\u00dft'", "ihn", "noch", "der", "Bett\u00b7ler", ",", "wie", "mor\u00b7gens", "er", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PWAV", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.5": {"line.1": {"text": "Er sucht in seiner B\u00f6rse nach einem Silberst\u00fcck,", "tokens": ["Er", "sucht", "in", "sei\u00b7ner", "B\u00f6r\u00b7se", "nach", "ei\u00b7nem", "Sil\u00b7ber\u00b7st\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihm h\u00e4lt der fremde Bettler die milde Hand zur\u00fcck:", "tokens": ["Ihm", "h\u00e4lt", "der", "frem\u00b7de", "Bett\u00b7ler", "die", "mil\u00b7de", "Hand", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbdas nicht von dir begehr ich, nur dein lebend'ges Wort,", "tokens": ["\u00bb", "das", "nicht", "von", "dir", "be\u00b7gehr", "ich", ",", "nur", "dein", "le\u00b7ben\u00b7d'\u00b7ges", "Wort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "PTKNEG", "APPR", "PPER", "VVFIN", "PPER", "$,", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Mich f\u00fchrt der Durst nach Wahrheit allein an diesen Ort.\u00ab \u2013", "tokens": ["Mich", "f\u00fchrt", "der", "Durst", "nach", "Wahr\u00b7heit", "al\u00b7lein", "an", "die\u00b7sen", "Ort", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "ADV", "APPR", "PDAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "\u00bbdu scheinst der kleinen Gabe bed\u00fcrftig mir zu sein.\u00ab \u2013", "tokens": ["\u00bb", "du", "scheinst", "der", "klei\u00b7nen", "Ga\u00b7be", "be\u00b7d\u00fcrf\u00b7tig", "mir", "zu", "sein", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "ADJD", "PPER", "PTKZU", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbdu h\u00e4ltst mich f\u00fcr unw\u00fcrdig der gr\u00f6\u00dfern!\u00ab \u2013 \u00bbTritt herein!", "tokens": ["\u00bb", "du", "h\u00e4ltst", "mich", "f\u00fcr", "un\u00b7w\u00fcr\u00b7dig", "der", "gr\u00f6\u00b7\u00dfern", "!", "\u00ab", "\u2013", "\u00bb", "Tritt", "her\u00b7ein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ADJD", "ART", "ADJA", "$.", "$(", "$(", "$(", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Suchst redlich du die Wahrheit, die vielen so verha\u00dft,", "tokens": ["Suchst", "red\u00b7lich", "du", "die", "Wahr\u00b7heit", ",", "die", "vie\u00b7len", "so", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "$,", "PRELS", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So sei dem Gleichgesinnten ein liebgehegter Gast.\u00ab", "tokens": ["So", "sei", "dem", "Gleich\u00b7ge\u00b7sinn\u00b7ten", "ein", "lieb\u00b7ge\u00b7heg\u00b7ter", "Gast", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Beim wogenden Gespr\u00e4che, beim h\u00e4uslich trauten Mahl,", "tokens": ["Beim", "wo\u00b7gen\u00b7den", "Ge\u00b7spr\u00e4\u00b7che", ",", "beim", "h\u00e4us\u00b7lich", "trau\u00b7ten", "Mahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Beim Becher edlen Weines, dem fl\u00fcss'gen Sonnenstrahl,", "tokens": ["Beim", "Be\u00b7cher", "ed\u00b7len", "Wei\u00b7nes", ",", "dem", "fl\u00fcss'\u00b7gen", "Son\u00b7nen\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Erbl\u00fcht dem fremden Bettler die Rede wunderbar,", "tokens": ["Er\u00b7bl\u00fcht", "dem", "frem\u00b7den", "Bett\u00b7ler", "die", "Re\u00b7de", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein Gl\u00e4ub'ger und ein Denker, wie nie noch einer war.", "tokens": ["Ein", "Gl\u00e4ub'\u00b7ger", "und", "ein", "Den\u00b7ker", ",", "wie", "nie", "noch", "ei\u00b7ner", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PWAV", "ADV", "ADV", "PIS", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Er hat des Wortes Fessel gesprengt mit Geistes-Kraft,", "tokens": ["Er", "hat", "des", "Wor\u00b7tes", "Fes\u00b7sel", "ge\u00b7sprengt", "mit", "Geis\u00b7tes\u00b7Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er h\u00e4ngt am Guten, Wahren so recht mit Leidenschaft,", "tokens": ["Er", "h\u00e4ngt", "am", "Gu\u00b7ten", ",", "Wah\u00b7ren", "so", "recht", "mit", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "NN", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er spr\u00fchet Lichtgedanken so machtvoll vor sich hin,", "tokens": ["Er", "spr\u00fc\u00b7het", "Licht\u00b7ge\u00b7dan\u00b7ken", "so", "macht\u00b7voll", "vor", "sich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "ADV", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So eignen Reiz verleiht ihm sein heitrer froher Sinn.", "tokens": ["So", "eig\u00b7nen", "Reiz", "ver\u00b7leiht", "ihm", "sein", "hei\u00b7trer", "fro\u00b7her", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Und ob des seltnen Mannes verwundert und erfreut,", "tokens": ["Und", "ob", "des", "selt\u00b7nen", "Man\u00b7nes", "ver\u00b7wun\u00b7dert", "und", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der seine Neigung fesselt und Ehrfurcht ihm gebeut,", "tokens": ["Der", "sei\u00b7ne", "Nei\u00b7gung", "fes\u00b7selt", "und", "Ehr\u00b7furcht", "ihm", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Fragt Mendelssohn ihn traulich: \u00bbWie haben Schul und Welt", "tokens": ["Fragt", "Men\u00b7dels\u00b7sohn", "ihn", "trau\u00b7lich", ":", "\u00bb", "Wie", "ha\u00b7ben", "Schul", "und", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPER", "ADJD", "$.", "$(", "PWAV", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So seltsam dich erzogen und deinen Geist erhellt?\u00ab", "tokens": ["So", "selt\u00b7sam", "dich", "er\u00b7zo\u00b7gen", "und", "dei\u00b7nen", "Geist", "er\u00b7hellt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVPP", "KON", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Drauf er: \u00bbDu lenkst vom Lichte die Blicke niederw\u00e4rts,", "tokens": ["Drauf", "er", ":", "\u00bb", "Du", "lenkst", "vom", "Lich\u00b7te", "die", "Bli\u00b7cke", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$.", "$(", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zu forschen nach dem Menschen und schauen ihm ins Herz;", "tokens": ["Zu", "for\u00b7schen", "nach", "dem", "Men\u00b7schen", "und", "schau\u00b7en", "ihm", "ins", "Herz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich zeige mich dem Freunde, und meinen Weg und Ziel,", "tokens": ["Ich", "zei\u00b7ge", "mich", "dem", "Freun\u00b7de", ",", "und", "mei\u00b7nen", "Weg", "und", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,", "KON", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und melde, wie die Binde mir von den Augen fiel.", "tokens": ["Und", "mel\u00b7de", ",", "wie", "die", "Bin\u00b7de", "mir", "von", "den", "Au\u00b7gen", "fiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.11": {"line.1": {"text": "Mein Forschen und mein Trachten, das bin ich selbst und ganz;", "tokens": ["Mein", "For\u00b7schen", "und", "mein", "Trach\u00b7ten", ",", "das", "bin", "ich", "selbst", "und", "ganz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Minuten so wie diese sind meines Lebens Glanz;", "tokens": ["Mi\u00b7nu\u00b7ten", "so", "wie", "die\u00b7se", "sind", "mei\u00b7nes", "Le\u00b7bens", "Glanz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "PDS", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich trage sechzig Jahre noch frisch und wohlgemut,", "tokens": ["Ich", "tra\u00b7ge", "sech\u00b7zig", "Jah\u00b7re", "noch", "frisch", "und", "wohl\u00b7ge\u00b7mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Noch schmilzt den Schnee des Alters des Herzens innre Glut.", "tokens": ["Noch", "schmilzt", "den", "Schnee", "des", "Al\u00b7ters", "des", "Her\u00b7zens", "inn\u00b7re", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.12": {"line.1": {"text": "Zu Glosk in unsern Schulen bekam ich Unterricht;", "tokens": ["Zu", "Glosk", "in", "un\u00b7sern", "Schu\u00b7len", "be\u00b7kam", "ich", "Un\u00b7ter\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Talmud und der Talmud! sie wu\u00dften andres nicht;", "tokens": ["Der", "Tal\u00b7mud", "und", "der", "Tal\u00b7mud", "!", "sie", "wu\u00df\u00b7ten", "and\u00b7res", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "PPER", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Verhangen und verfinstert das g\u00f6ttliche Gebot,", "tokens": ["Ver\u00b7han\u00b7gen", "und", "ver\u00b7fins\u00b7tert", "das", "g\u00f6tt\u00b7li\u00b7che", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das leis aus tiefstem Herzen sich doch mir mahnend bot.", "tokens": ["Das", "leis", "aus", "tiefs\u00b7tem", "Her\u00b7zen", "sich", "doch", "mir", "mah\u00b7nend", "bot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "ADJA", "NN", "PRF", "ADV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Wie hab ich oft mit Schmerzen die stumme Mitternacht", "tokens": ["Wie", "hab", "ich", "oft", "mit", "Schmer\u00b7zen", "die", "stum\u00b7me", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Auf ihren toten B\u00fcchern verst\u00f6rt herangewacht;", "tokens": ["Auf", "ih\u00b7ren", "to\u00b7ten", "B\u00fc\u00b7chern", "ver\u00b7st\u00f6rt", "her\u00b7an\u00b7ge\u00b7wacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie h\u00e4tt ich fromm und willig den Lehrern nur geglaubt,", "tokens": ["Wie", "h\u00e4tt", "ich", "fromm", "und", "wil\u00b7lig", "den", "Leh\u00b7rern", "nur", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und wiegte doch verneinend mein sorgenschweres Haupt.", "tokens": ["Und", "wieg\u00b7te", "doch", "ver\u00b7nei\u00b7nend", "mein", "sor\u00b7gen\u00b7schwe\u00b7res", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVPP", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Und nun ich sollte lehren, so wie ich selbst belehrt,", "tokens": ["Und", "nun", "ich", "soll\u00b7te", "leh\u00b7ren", ",", "so", "wie", "ich", "selbst", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VMFIN", "VVINF", "$,", "ADV", "KOKOM", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da hat sich mir die Rede gar wundersam verkehrt;", "tokens": ["Da", "hat", "sich", "mir", "die", "Re\u00b7de", "gar", "wun\u00b7der\u00b7sam", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da schalt aus mir die Stimme auf Satzungen und Trug,", "tokens": ["Da", "schalt", "aus", "mir", "die", "Stim\u00b7me", "auf", "Sat\u00b7zun\u00b7gen", "und", "Trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--++--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dem Blitze zu vergleichen, der aus den Wolken schlug.", "tokens": ["Dem", "Blit\u00b7ze", "zu", "ver\u00b7glei\u00b7chen", ",", "der", "aus", "den", "Wol\u00b7ken", "schlug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.15": {"line.1": {"text": "Sie haben sich entsetzet, sie haben mich fortan", "tokens": ["Sie", "ha\u00b7ben", "sich", "ent\u00b7set\u00b7zet", ",", "sie", "ha\u00b7ben", "mich", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bedrohet und gef\u00e4hrdet und in den Bann getan;", "tokens": ["Be\u00b7dro\u00b7het", "und", "ge\u00b7f\u00e4hr\u00b7det", "und", "in", "den", "Bann", "ge\u00b7tan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich hatte mich gefunden, ich war, der ich nun bin,", "tokens": ["Ich", "hat\u00b7te", "mich", "ge\u00b7fun\u00b7den", ",", "ich", "war", ",", "der", "ich", "nun", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich folgte meiner Sendung mit leichtem, freud'gem Sinn.", "tokens": ["Ich", "folg\u00b7te", "mei\u00b7ner", "Sen\u00b7dung", "mit", "leich\u00b7tem", ",", "freu\u00b7d'\u00b7gem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "So wallt ich, in der Heimat ein Fremder, nun hinfort", "tokens": ["So", "wallt", "ich", ",", "in", "der", "Hei\u00b7mat", "ein", "Frem\u00b7der", ",", "nun", "hin\u00b7fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "ART", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Versto\u00dfen, fluchbeladen, unst\u00e4t von Ort zu Ort,", "tokens": ["Ver\u00b7sto\u00b7\u00dfen", ",", "fluch\u00b7be\u00b7la\u00b7den", ",", "un\u00b7st\u00e4t", "von", "Ort", "zu", "Ort", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJD", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und forschte, sprach und lehrte, und trachtete doch nur,", "tokens": ["Und", "forschte", ",", "sprach", "und", "lehr\u00b7te", ",", "und", "trach\u00b7te\u00b7te", "doch", "nur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das arme Volk zu leiten auf eine be\u00dfre Spur.", "tokens": ["Das", "ar\u00b7me", "Volk", "zu", "lei\u00b7ten", "auf", "ei\u00b7ne", "be\u00df\u00b7re", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.17": {"line.1": {"text": "Und dreizehn B\u00fccher hatt ich verfa\u00dft mit allem Flei\u00df,", "tokens": ["Und", "drei\u00b7zehn", "B\u00fc\u00b7cher", "hatt", "ich", "ver\u00b7fa\u00dft", "mit", "al\u00b7lem", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "PPER", "VVFIN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die B\u00fccher, sie enthielten das Beste, was ich wei\u00df;", "tokens": ["Die", "B\u00fc\u00b7cher", ",", "sie", "ent\u00b7hiel\u00b7ten", "das", "Bes\u00b7te", ",", "was", "ich", "wei\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zu Wilna, oh! da waren fast grausam allzusehr", "tokens": ["Zu", "Wil\u00b7na", ",", "oh", "!", "da", "wa\u00b7ren", "fast", "grau\u00b7sam", "all\u00b7zu\u00b7sehr"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "FM", "$.", "ADV", "VAFIN", "ADV", "ADJD", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die \u00c4ltesten des Volkes, wie nirgends anders mehr.", "tokens": ["Die", "\u00c4l\u00b7tes\u00b7ten", "des", "Vol\u00b7kes", ",", "wie", "nir\u00b7gends", "an\u00b7ders", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PWAV", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Sie haben meine B\u00fccher zerrissen insgesamt,", "tokens": ["Sie", "ha\u00b7ben", "mei\u00b7ne", "B\u00fc\u00b7cher", "zer\u00b7ris\u00b7sen", "ins\u00b7ge\u00b7samt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und haben zu den Flammen sie ungeh\u00f6rt verdammt;", "tokens": ["Und", "ha\u00b7ben", "zu", "den", "Flam\u00b7men", "sie", "un\u00b7ge\u00b7h\u00f6rt", "ver\u00b7dammt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie schichteten den Holzsto\u00df beim alten Apfelbaum", "tokens": ["Sie", "schich\u00b7te\u00b7ten", "den", "Holz\u00b7sto\u00df", "beim", "al\u00b7ten", "Ap\u00b7fel\u00b7baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vor ihrer Synagoge im innern Hofesraum.", "tokens": ["Vor", "ih\u00b7rer", "Syn\u00b7a\u00b7go\u00b7ge", "im", "in\u00b7nern", "Ho\u00b7fes\u00b7raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Da standen in dem Rauche die Alten bl\u00f6d und blind,", "tokens": ["Da", "stan\u00b7den", "in", "dem", "Rau\u00b7che", "die", "Al\u00b7ten", "bl\u00f6d", "und", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den schlug auf sie hernieder ein m\u00e4cht'ger Wirbelwind,", "tokens": ["Den", "schlug", "auf", "sie", "her\u00b7nie\u00b7der", "ein", "m\u00e4cht'\u00b7ger", "Wir\u00b7bel\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gereinigt schwang die Flamme sich zu dem h\u00f6hern Licht;", "tokens": ["Ge\u00b7rei\u00b7nigt", "schwang", "die", "Flam\u00b7me", "sich", "zu", "dem", "h\u00f6\u00b7hern", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "ART", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Geist, das Licht, die Sonne vernichten sie doch nicht.", "tokens": ["Den", "Geist", ",", "das", "Licht", ",", "die", "Son\u00b7ne", "ver\u00b7nich\u00b7ten", "sie", "doch", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "Ich selbst ich sollte sterben, kaum heimlich war der Rat;", "tokens": ["Ich", "selbst", "ich", "soll\u00b7te", "ster\u00b7ben", ",", "kaum", "heim\u00b7lich", "war", "der", "Rat", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "VMFIN", "VVINF", "$,", "ADV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch fand sich ein Rabbiner, der um mein Leben bat,", "tokens": ["Doch", "fand", "sich", "ein", "Rab\u00b7bi\u00b7ner", ",", "der", "um", "mein", "Le\u00b7ben", "bat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich wurde blo\u00df gegei\u00dfelt, und als man frei mich gab,", "tokens": ["Ich", "wur\u00b7de", "blo\u00df", "ge\u00b7gei\u00b7\u00dfelt", ",", "und", "als", "man", "frei", "mich", "gab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KON", "KOUS", "PIS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So griff ich heitern Sinnes zu meinem Wanderstab.", "tokens": ["So", "griff", "ich", "hei\u00b7tern", "Sin\u00b7nes", "zu", "mei\u00b7nem", "Wan\u00b7der\u00b7stab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.21": {"line.1": {"text": "Der freud'ge, r\u00fcst'ge Waller zieht \u00fcber Berg und Tal,", "tokens": ["Der", "freu\u00b7d'\u00b7ge", ",", "r\u00fcst'\u00b7ge", "Wal\u00b7ler", "zieht", "\u00fc\u00b7ber", "Berg", "und", "Tal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihm scheinet, ihn erw\u00e4rmet der lieben Sonne Strahl,", "tokens": ["Ihm", "schei\u00b7net", ",", "ihn", "er\u00b7w\u00e4r\u00b7met", "der", "lie\u00b7ben", "Son\u00b7ne", "Strahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Scho\u00df der gr\u00fcnen Erde empf\u00e4ngt mit rechter Lust", "tokens": ["Der", "Scho\u00df", "der", "gr\u00fc\u00b7nen", "Er\u00b7de", "emp\u00b7f\u00e4ngt", "mit", "rech\u00b7ter", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein m\u00fcdes Haupt am Abend, er ruht an Mutterbrust.", "tokens": ["Sein", "m\u00fc\u00b7des", "Haupt", "am", "A\u00b7bend", ",", "er", "ruht", "an", "Mut\u00b7ter\u00b7brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.22": {"line.1": {"text": "Wer je von seinen Br\u00fcdern den Hunger selber litt,", "tokens": ["Wer", "je", "von", "sei\u00b7nen", "Br\u00fc\u00b7dern", "den", "Hun\u00b7ger", "sel\u00b7ber", "litt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Teilt ihm vom letzten Brote gern einen Brocken mit,", "tokens": ["Teilt", "ihm", "vom", "letz\u00b7ten", "Bro\u00b7te", "gern", "ei\u00b7nen", "Bro\u00b7cken", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er zieht durch Land und St\u00e4dte und r\u00fchmt sich reich und frei,", "tokens": ["Er", "zieht", "durch", "Land", "und", "St\u00e4d\u00b7te", "und", "r\u00fchmt", "sich", "reich", "und", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "KON", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und wei\u00df von keiner Armut und keiner Sklaverei.", "tokens": ["Und", "wei\u00df", "von", "kei\u00b7ner", "Ar\u00b7mut", "und", "kei\u00b7ner", "Skla\u00b7ve\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.23": {"line.1": {"text": "Vor Sprach- und Stammverwandten entquillt an jedem Ort", "tokens": ["Vor", "Sprach", "und", "Stamm\u00b7ver\u00b7wand\u00b7ten", "ent\u00b7quillt", "an", "je\u00b7dem", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "TRUNC", "KON", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Aus \u00fcbervollem Herzen ihm das lebend'ge Wort,", "tokens": ["Aus", "\u00fc\u00b7ber\u00b7vol\u00b7lem", "Her\u00b7zen", "ihm", "das", "le\u00b7ben\u00b7d'\u00b7ge", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Zu lehren und zu bessern, zu sichten sonder Scheu", "tokens": ["Zu", "leh\u00b7ren", "und", "zu", "bes\u00b7sern", ",", "zu", "sich\u00b7ten", "son\u00b7der", "Scheu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Glauben von dem Wahne, den Weizen von der Spreu.", "tokens": ["Den", "Glau\u00b7ben", "von", "dem", "Wah\u00b7ne", ",", "den", "Wei\u00b7zen", "von", "der", "Spreu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Ist Felsen auch der Boden, die Saat verstreue nur!", "tokens": ["Ist", "Fel\u00b7sen", "auch", "der", "Bo\u00b7den", ",", "die", "Saat", "ver\u00b7streu\u00b7e", "nur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ART", "NN", "$,", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es tr\u00e4ufelt auf den Felsen, wie auf die gr\u00fcne Flur,", "tokens": ["Es", "tr\u00e4u\u00b7felt", "auf", "den", "Fel\u00b7sen", ",", "wie", "auf", "die", "gr\u00fc\u00b7ne", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Des Ew'gen milder Regen. Beharrlichkeit! Geduld!", "tokens": ["Des", "Ew'\u00b7gen", "mil\u00b7der", "Re\u00b7gen", ".", "Be\u00b7harr\u00b7lich\u00b7keit", "!", "Ge\u00b7duld", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Du zahlest deinem Sch\u00f6pfer so deines Lebens Schuld.", "tokens": ["Du", "zah\u00b7lest", "dei\u00b7nem", "Sch\u00f6p\u00b7fer", "so", "dei\u00b7nes", "Le\u00b7bens", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.25": {"line.1": {"text": "Und herw\u00e4rts zog mich m\u00e4chtig und ahndungsvoll mein Herz,", "tokens": ["Und", "her\u00b7w\u00e4rts", "zog", "mich", "m\u00e4ch\u00b7tig", "und", "ahn\u00b7dungs\u00b7voll", "mein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von deines Namens Klange gelockt, du reines Erz;", "tokens": ["Von", "dei\u00b7nes", "Na\u00b7mens", "Klan\u00b7ge", "ge\u00b7lockt", ",", "du", "rei\u00b7nes", "Erz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVPP", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Du bist, den ich gesuchet, du, der vom Wahne fern", "tokens": ["Du", "bist", ",", "den", "ich", "ge\u00b7su\u00b7chet", ",", "du", ",", "der", "vom", "Wah\u00b7ne", "fern"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VVPP", "$,", "PPER", "$,", "PRELS", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.4": {"text": "Zerbricht die hohle Schale und sucht nach ihrem Kern.", "tokens": ["Zer\u00b7bricht", "die", "hoh\u00b7le", "Scha\u00b7le", "und", "sucht", "nach", "ih\u00b7rem", "Kern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "Das will auch ich, so reiche mir deine liebe Hand,", "tokens": ["Das", "will", "auch", "ich", ",", "so", "rei\u00b7che", "mir", "dei\u00b7ne", "lie\u00b7be", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wir schaffen hier und kn\u00fcpfen ein gottgef\u00e4llig Band;", "tokens": ["Wir", "schaf\u00b7fen", "hier", "und", "kn\u00fcp\u00b7fen", "ein", "gott\u00b7ge\u00b7f\u00e4l\u00b7lig", "Band", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Licht, das ist das Gute; die Finsternis, die Nacht,", "tokens": ["Das", "Licht", ",", "das", "ist", "das", "Gu\u00b7te", ";", "die", "Fins\u00b7ter\u00b7nis", ",", "die", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das ist das Reich der S\u00fcnde und ist des B\u00f6sen Macht.", "tokens": ["Das", "ist", "das", "Reich", "der", "S\u00fcn\u00b7de", "und", "ist", "des", "B\u00f6\u00b7sen", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "KON", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.27": {"line.1": {"text": "Dir str\u00f6met von den Lippen ein ruhig klarer Born,", "tokens": ["Dir", "str\u00f6\u00b7met", "von", "den", "Lip\u00b7pen", "ein", "ru\u00b7hig", "kla\u00b7rer", "Born", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es leiht gewalt'ge Worte mir oft ein heil'ger Zorn;", "tokens": ["Es", "leiht", "ge\u00b7walt'\u00b7ge", "Wor\u00b7te", "mir", "oft", "ein", "heil'\u00b7ger", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So la\u00df vor unserm Volke zerrei\u00dfen uns vereint", "tokens": ["So", "la\u00df", "vor", "un\u00b7serm", "Vol\u00b7ke", "zer\u00b7rei\u00b7\u00dfen", "uns", "ver\u00b7eint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Des Aberglaubens Schleier, bis hell der Tag ihm scheint.", "tokens": ["Des", "A\u00b7berg\u00b7lau\u00b7bens", "Schlei\u00b7er", ",", "bis", "hell", "der", "Tag", "ihm", "scheint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "ADJD", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Nicht tr\u00e4ge denn, nicht l\u00e4ssig; die Hand ans Werk gelegt!", "tokens": ["Nicht", "tr\u00e4\u00b7ge", "denn", ",", "nicht", "l\u00e4s\u00b7sig", ";", "die", "Hand", "ans", "Werk", "ge\u00b7legt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ADV", "$,", "PTKNEG", "ADJD", "$.", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Versammle du die J\u00fcnger, es tagt, die Stunde schl\u00e4gt!", "tokens": ["Ver\u00b7samm\u00b7le", "du", "die", "J\u00fcn\u00b7ger", ",", "es", "tagt", ",", "die", "Stun\u00b7de", "schl\u00e4gt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir hammern an den Felsen, bis hell der Stein erklingt,", "tokens": ["Wir", "ham\u00b7mern", "an", "den", "Fel\u00b7sen", ",", "bis", "hell", "der", "Stein", "er\u00b7klingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und an das Licht der Sprudel lebend'gen Wassers springt.\u00ab", "tokens": ["Und", "an", "das", "Licht", "der", "Spru\u00b7del", "le\u00b7ben\u00b7d'\u00b7gen", "Was\u00b7sers", "springt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.29": {"line.1": {"text": "Darauf mit R\u00fchrung l\u00e4chelnd der Wirt zu seinem Gast:", "tokens": ["Da\u00b7rauf", "mit", "R\u00fch\u00b7rung", "l\u00e4\u00b7chelnd", "der", "Wirt", "zu", "sei\u00b7nem", "Gast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "ADJD", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbgen\u00fcgt dir nicht, du Guter, was du erduldet hast?", "tokens": ["\u00bb", "ge\u00b7n\u00fcgt", "dir", "nicht", ",", "du", "Gu\u00b7ter", ",", "was", "du", "er\u00b7dul\u00b7det", "hast", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "NN", "$,", "PWS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Soll wiederum sich schichten ein Scheiterhaufen? kann", "tokens": ["Soll", "wie\u00b7de\u00b7rum", "sich", "schich\u00b7ten", "ein", "Schei\u00b7ter\u00b7hau\u00b7fen", "?", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "ADV", "PRF", "VVFIN", "ART", "NN", "$.", "VMFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Gei\u00dfel nicht dich lehren? du lehrbegier'ger Mann!", "tokens": ["Die", "Gei\u00b7\u00dfel", "nicht", "dich", "leh\u00b7ren", "?", "du", "lehr\u00b7be\u00b7gier'\u00b7ger", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PPER", "VVINF", "$.", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Du forschest nach der Wahrheit; erkenne doch die Welt,", "tokens": ["Du", "for\u00b7schest", "nach", "der", "Wahr\u00b7heit", ";", "er\u00b7ken\u00b7ne", "doch", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die fester als am Glauben am Aberglauben h\u00e4lt;", "tokens": ["Die", "fes\u00b7ter", "als", "am", "Glau\u00b7ben", "am", "A\u00b7berg\u00b7lau\u00b7ben", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KOKOM", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was je gelebt im Geiste, geh\u00f6rt der Ewigkeit,", "tokens": ["Was", "je", "ge\u00b7lebt", "im", "Geis\u00b7te", ",", "ge\u00b7h\u00f6rt", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nur ruft es erst ins Leben die allgewalt'ge Zeit.", "tokens": ["Nur", "ruft", "es", "erst", "ins", "Le\u00b7ben", "die", "all\u00b7ge\u00b7walt'\u00b7ge", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.31": {"line.1": {"text": "Bleib hie und lerne schweigen, wo sprechen nicht am Ort;", "tokens": ["Bleib", "hie", "und", "ler\u00b7ne", "schwei\u00b7gen", ",", "wo", "spre\u00b7chen", "nicht", "am", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "VVFIN", "VVINF", "$,", "PWAV", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du magst im Stillen forschen, erw\u00e4gen Geist und Wort,", "tokens": ["Du", "magst", "im", "Stil\u00b7len", "for\u00b7schen", ",", "er\u00b7w\u00e4\u00b7gen", "Geist", "und", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVINF", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und magst das Korn der Furche der Zeiten anvertraun;", "tokens": ["Und", "magst", "das", "Korn", "der", "Fur\u00b7che", "der", "Zei\u00b7ten", "an\u00b7ver\u00b7traun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vielleicht wird einst dein Enkel die goldnen Saaten schaun.\u00ab", "tokens": ["Viel\u00b7leicht", "wird", "einst", "dein", "En\u00b7kel", "die", "gold\u00b7nen", "Saa\u00b7ten", "schaun", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "Drauf er: \u00bbDu schweigst, du Kluger, und schweigen soll mein Mund!", "tokens": ["Drauf", "er", ":", "\u00bb", "Du", "schweigst", ",", "du", "Klu\u00b7ger", ",", "und", "schwei\u00b7gen", "soll", "mein", "Mund", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$.", "$(", "PPER", "VVFIN", "$,", "PPER", "NN", "$,", "KON", "VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So sprich, wer soll denn reden und tun die Wahrheit kund?", "tokens": ["So", "sprich", ",", "wer", "soll", "denn", "re\u00b7den", "und", "tun", "die", "Wahr\u00b7heit", "kund", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWS", "VMFIN", "ADV", "VVINF", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+------+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Du helles Licht des Geistes sollst leuchten freundlich mir;", "tokens": ["Du", "hel\u00b7les", "Licht", "des", "Geis\u00b7tes", "sollst", "leuch\u00b7ten", "freund\u00b7lich", "mir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "VMFIN", "VVFIN", "ADJD", "PPER", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Hand darauf! \u2013 wir scheiden! mein Pfad, der trennt sich hier.\u00ab", "tokens": ["Die", "Hand", "da\u00b7rauf", "!", "\u2013", "wir", "schei\u00b7den", "!", "mein", "Pfad", ",", "der", "trennt", "sich", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PAV", "$.", "$(", "PPER", "VVINF", "$.", "PPOSAT", "NN", "$,", "PRELS", "VVFIN", "PRF", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.33": {"line.1": {"text": "Er ging; dem Flammengeiste, dem Flammenherzen galt", "tokens": ["Er", "ging", ";", "dem", "Flam\u00b7men\u00b7geis\u00b7te", ",", "dem", "Flam\u00b7men\u00b7her\u00b7zen", "galt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "F\u00fcr Feigheit jede Vorsicht, und freundlich z\u00fcrnend schalt", "tokens": ["F\u00fcr", "Feig\u00b7heit", "je\u00b7de", "Vor\u00b7sicht", ",", "und", "freund\u00b7lich", "z\u00fcr\u00b7nend", "schalt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PIAT", "NN", "$,", "KON", "ADJD", "VVPP", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihn Mendelssohn vergebens; er ging und lehrt' und sprach,", "tokens": ["Ihn", "Men\u00b7dels\u00b7sohn", "ver\u00b7ge\u00b7bens", ";", "er", "ging", "und", "lehrt'", "und", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "$.", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bis \u00fcber ihn aufs neue das Ungewitter brach.", "tokens": ["Bis", "\u00fc\u00b7ber", "ihn", "aufs", "neu\u00b7e", "das", "Un\u00b7ge\u00b7wit\u00b7ter", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPER", "APPRART", "ADJA", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.34": {"line.1": {"text": "Die \u00c4ltesten des Volkes entr\u00fcstet, luden ihn", "tokens": ["Die", "\u00c4l\u00b7tes\u00b7ten", "des", "Vol\u00b7kes", "ent\u00b7r\u00fcs\u00b7tet", ",", "lu\u00b7den", "ihn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,", "VVFIN", "PPER"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Vor ihre Schranken: \u00bbRede, was machst du in Berlin?\u00ab \u2013", "tokens": ["Vor", "ih\u00b7re", "Schran\u00b7ken", ":", "\u00bb", "Re\u00b7de", ",", "was", "machst", "du", "in", "Ber\u00b7lin", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "NN", "$,", "PWS", "VVFIN", "PPER", "APPR", "NE", "$.", "$(", "$("], "meter": "-+-+-+--+-+++", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "\u00bbich forsch in dem Gesetze, dar\u00fcber sprech ich auch", "tokens": ["\u00bb", "ich", "forsch", "in", "dem", "Ge\u00b7set\u00b7ze", ",", "da\u00b7r\u00fc\u00b7ber", "sprech", "ich", "auch"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADJD", "APPR", "ART", "NN", "$,", "PAV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Mit andern Schriftgelehrten nach hergebrachtem Brauch.\u00ab \u2013", "tokens": ["Mit", "an\u00b7dern", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "nach", "her\u00b7ge\u00b7brach\u00b7tem", "Brauch", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.35": {"line.1": {"text": "\u00bbdu stehst in keinem Dienste? hast kein Gewerbe?\u00ab \u2013 \u00bbNein!", "tokens": ["\u00bb", "du", "stehst", "in", "kei\u00b7nem", "Diens\u00b7te", "?", "hast", "kein", "Ge\u00b7wer\u00b7be", "?", "\u00ab", "\u2013", "\u00bb", "Nein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "VAFIN", "PIAT", "NN", "$.", "$(", "$(", "$(", "PTKANT", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich kann und will nicht handeln, und mag nicht dienstbar sein.\u00ab \u2013", "tokens": ["Ich", "kann", "und", "will", "nicht", "han\u00b7deln", ",", "und", "mag", "nicht", "dienst\u00b7bar", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "PTKNEG", "VVINF", "$,", "KON", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbund wir, nach hies'ger Ordnung, verbieten diese Stadt", "tokens": ["\u00bb", "und", "wir", ",", "nach", "hies'\u00b7ger", "Ord\u00b7nung", ",", "ver\u00b7bie\u00b7ten", "die\u00b7se", "Stadt"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "PDAT", "NN"], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dem \u00e4rgerlichen Neurer, der hier gel\u00e4stert hat.\u00ab", "tokens": ["Dem", "\u00e4r\u00b7ger\u00b7li\u00b7chen", "Neu\u00b7rer", ",", "der", "hier", "ge\u00b7l\u00e4s\u00b7tert", "hat", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}}, "stanza.36": {"line.1": {"text": "Darauf erhob sich Abba und sprach: \u00bbHartherzigkeit,", "tokens": ["Da\u00b7rauf", "er\u00b7hob", "sich", "Ab\u00b7ba", "und", "sprach", ":", "\u00bb", "Har\u00b7ther\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "NE", "KON", "VVFIN", "$.", "$(", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Du bist zur Ordnung worden, du herrschest hier zur Zeit!", "tokens": ["Du", "bist", "zur", "Ord\u00b7nung", "wor\u00b7den", ",", "du", "herr\u00b7schest", "hier", "zur", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VAPP", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und kennt ihr den Propheten Jeremia denn nicht,", "tokens": ["Und", "kennt", "ihr", "den", "Pro\u00b7phe\u00b7ten", "Je\u00b7re\u00b7mia", "denn", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "NE", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der so aus meinem Munde zu euch, ihr Starren, spricht:", "tokens": ["Der", "so", "aus", "mei\u00b7nem", "Mun\u00b7de", "zu", "euch", ",", "ihr", "Star\u00b7ren", ",", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.37": {"line.1": {"text": "\u203adie Missetat der Tochter von Sion, unerh\u00f6rt!", "tokens": ["\u203a", "die", "Mis\u00b7se\u00b7tat", "der", "Toch\u00b7ter", "von", "Si\u00b7on", ",", "un\u00b7er\u00b7h\u00f6rt", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "APPR", "NE", "$,", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Verdunkelt Sodoms S\u00fcnde, die doch mein Grimm zerst\u00f6rt.\u2039", "tokens": ["Ver\u00b7dun\u00b7kelt", "So\u00b7doms", "S\u00fcn\u00b7de", ",", "die", "doch", "mein", "Grimm", "zer\u00b7st\u00f6rt", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "NN", "$,", "PRELS", "ADV", "PPOSAT", "NE", "VVPP", "$.", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Schrift und die Propheten, die les ich Tag und Nacht,", "tokens": ["Die", "Schrift", "und", "die", "Pro\u00b7phe\u00b7ten", ",", "die", "les", "ich", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PRELS", "PIS", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und hab auch andre Worte zu eigen mir gemacht!", "tokens": ["Und", "hab", "auch", "and\u00b7re", "Wor\u00b7te", "zu", "ei\u00b7gen", "mir", "ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJA", "NN", "PTKA", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.38": {"line.1": {"text": "\u203adu sollst dich nicht entsetzen, und sollst, du Menschenkind,", "tokens": ["\u203a", "du", "sollst", "dich", "nicht", "ent\u00b7set\u00b7zen", ",", "und", "sollst", ",", "du", "Men\u00b7schen\u00b7kind", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "KON", "VMFIN", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Vor ihnen dich nicht f\u00fcrchten, die mir abtr\u00fcnnig sind;", "tokens": ["Vor", "ih\u00b7nen", "dich", "nicht", "f\u00fcrch\u00b7ten", ",", "die", "mir", "ab\u00b7tr\u00fcn\u00b7nig", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PRF", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Du wohnst bei scharfen Dornen und Skorpionen dort,", "tokens": ["Du", "wohnst", "bei", "schar\u00b7fen", "Dor\u00b7nen", "und", "Skor\u00b7pi\u00b7o\u00b7nen", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch sollst du dich nicht f\u00fcrchten, verk\u00fcndest du mein Wort.\u2039\u00ab", "tokens": ["Doch", "sollst", "du", "dich", "nicht", "f\u00fcrch\u00b7ten", ",", "ver\u00b7k\u00fcn\u00b7dest", "du", "mein", "Wort", ".", "\u2039", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.39": {"line.1": {"text": "Sie holten ihn am Abend wohl mit der Polizei,", "tokens": ["Sie", "hol\u00b7ten", "ihn", "am", "A\u00b7bend", "wohl", "mit", "der", "Po\u00b7li\u00b7zei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihn auf die Post zu bringen, er rief den Freund herbei,", "tokens": ["Ihn", "auf", "die", "Post", "zu", "brin\u00b7gen", ",", "er", "rief", "den", "Freund", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der schafft' ihm einen Dienstschein, geschirmet war er so", "tokens": ["Der", "schafft'", "ihm", "ei\u00b7nen", "Dienst\u00b7schein", ",", "ge\u00b7schir\u00b7met", "war", "er", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "$,", "VVPP", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vor seinen Widersachern, sie waren des nicht froh.", "tokens": ["Vor", "sei\u00b7nen", "Wi\u00b7der\u00b7sa\u00b7chern", ",", "sie", "wa\u00b7ren", "des", "nicht", "froh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "ART", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.40": {"line.1": {"text": "Und eine Rechnung reichten zur Zahlung sie ihm dar,", "tokens": ["Und", "ei\u00b7ne", "Rech\u00b7nung", "reich\u00b7ten", "zur", "Zah\u00b7lung", "sie", "ihm", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wo Postgeld nebst der B\u00fctteln Geb\u00fchr verzeichnet war;", "tokens": ["Wo", "Post\u00b7geld", "nebst", "der", "B\u00fct\u00b7teln", "Ge\u00b7b\u00fchr", "ver\u00b7zeich\u00b7net", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er aber sprach und lachte: \u00bbGeduldet euch, ihr Herrn,", "tokens": ["Er", "a\u00b7ber", "sprach", "und", "lach\u00b7te", ":", "\u00bb", "Ge\u00b7dul\u00b7det", "euch", ",", "ihr", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KON", "VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Hier pa\u00dft wohl ein Geschichtchen, und ich erz\u00e4hl es gern:", "tokens": ["Hier", "pa\u00dft", "wohl", "ein", "Ge\u00b7schicht\u00b7chen", ",", "und", "ich", "er\u00b7z\u00e4hl", "es", "gern", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.41": {"line.1": {"text": "Den Unsern wird zu Lemberg ein kummervolles Los,", "tokens": ["Den", "Un\u00b7sern", "wird", "zu", "Lem\u00b7berg", "ein", "kum\u00b7mer\u00b7vol\u00b7les", "Los", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die jungen Herrn, die Sch\u00fcler sind ganz erbarmungslos,", "tokens": ["Die", "jun\u00b7gen", "Herrn", ",", "die", "Sch\u00fc\u00b7ler", "sind", "ganz", "er\u00b7bar\u00b7mungs\u00b7los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den armen Unterdr\u00fcckten mi\u00dfhandeln sie und schm\u00e4hn,", "tokens": ["Den", "ar\u00b7men", "Un\u00b7ter\u00b7dr\u00fcck\u00b7ten", "mi\u00df\u00b7han\u00b7deln", "sie", "und", "schm\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und werfen ihn mit Steinen, wo immer sie ihn sehn.", "tokens": ["Und", "wer\u00b7fen", "ihn", "mit", "Stei\u00b7nen", ",", "wo", "im\u00b7mer", "sie", "ihn", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$,", "PWAV", "ADV", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.42": {"line.1": {"text": "Als einer, den sie schlugen, nah am Verscheiden war,", "tokens": ["Als", "ei\u00b7ner", ",", "den", "sie", "schlu\u00b7gen", ",", "nah", "am", "Ver\u00b7schei\u00b7den", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Verma\u00df sich die Gemeinde, bedr\u00e4ngt von der Gefahr,", "tokens": ["Ver\u00b7ma\u00df", "sich", "die", "Ge\u00b7mein\u00b7de", ",", "be\u00b7dr\u00e4ngt", "von", "der", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den Jesuiten Obern zu klagen ihre Not;", "tokens": ["Den", "Je\u00b7su\u00b7i\u00b7ten", "O\u00b7bern", "zu", "kla\u00b7gen", "ih\u00b7re", "Not", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die haben unparteiisch erlassen ein Verbot:", "tokens": ["Die", "ha\u00b7ben", "un\u00b7par\u00b7tei\u00b7isch", "er\u00b7las\u00b7sen", "ein", "Ver\u00b7bot", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.43": {"line.1": {"text": "Es d\u00fcrfen nicht die Sch\u00fcler aus eitlem Zeitvertreib", "tokens": ["Es", "d\u00fcr\u00b7fen", "nicht", "die", "Sch\u00fc\u00b7ler", "aus", "eit\u00b7lem", "Zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Juden so mi\u00dfhandeln, da\u00df sie an ihrem Leib", "tokens": ["Die", "Ju\u00b7den", "so", "mi\u00df\u00b7han\u00b7deln", ",", "da\u00df", "sie", "an", "ih\u00b7rem", "Leib"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Besch\u00e4digt werden m\u00f6chten; es wird auch untersagt,", "tokens": ["Be\u00b7sch\u00e4\u00b7digt", "wer\u00b7den", "m\u00f6ch\u00b7ten", ";", "es", "wird", "auch", "un\u00b7ter\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VMFIN", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Blutr\u00fcnstig sie zu schlagen, wie eben wird geklagt.", "tokens": ["Blut\u00b7r\u00fcns\u00b7tig", "sie", "zu", "schla\u00b7gen", ",", "wie", "e\u00b7ben", "wird", "ge\u00b7klagt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PTKZU", "VVINF", "$,", "PWAV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.44": {"line.1": {"text": "Ein arglos Schimpfen, Werfen, ein Sto\u00df und solcherlei,", "tokens": ["Ein", "arg\u00b7los", "Schimp\u00b7fen", ",", "Wer\u00b7fen", ",", "ein", "Sto\u00df", "und", "sol\u00b7cher\u00b7lei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "NN", "$,", "ART", "NN", "KON", "PIAT", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das m\u00fcssen sie erdulden und steht den Sch\u00fclern frei,", "tokens": ["Das", "m\u00fcs\u00b7sen", "sie", "er\u00b7dul\u00b7den", "und", "steht", "den", "Sch\u00fc\u00b7lern", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Weil mancher unter diesen ist guter Eltern Kind,", "tokens": ["Weil", "man\u00b7cher", "un\u00b7ter", "die\u00b7sen", "ist", "gu\u00b7ter", "El\u00b7tern", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDS", "VAFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Juden doch am Ende nur eben Juden sind.", "tokens": ["Und", "Ju\u00b7den", "doch", "am", "En\u00b7de", "nur", "e\u00b7ben", "Ju\u00b7den", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPRART", "NN", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.45": {"line.1": {"text": "Ein Jud in diesen Tagen, der her die Stra\u00dfe kam,", "tokens": ["Ein", "Jud", "in", "die\u00b7sen", "Ta\u00b7gen", ",", "der", "her", "die", "Stra\u00b7\u00dfe", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bemerkte, da\u00df ein Sch\u00fcler ihn recht zum Ziele nahm,", "tokens": ["Be\u00b7merk\u00b7te", ",", "da\u00df", "ein", "Sch\u00fc\u00b7ler", "ihn", "recht", "zum", "Zie\u00b7le", "nahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er b\u00fcckte sich bei Zeiten, und wich dem Stein noch aus,", "tokens": ["Er", "b\u00fcck\u00b7te", "sich", "bei", "Zei\u00b7ten", ",", "und", "wich", "dem", "Stein", "noch", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$,", "KON", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der klirrend flog ins Fenster dem n\u00e4chsten B\u00fcrgerhaus.", "tokens": ["Der", "klir\u00b7rend", "flog", "ins", "Fens\u00b7ter", "dem", "n\u00e4chs\u00b7ten", "B\u00fcr\u00b7ger\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.46": {"line.1": {"text": "Die Scheibe war zerbrochen; der B\u00fcrger s\u00e4umte nicht,", "tokens": ["Die", "Schei\u00b7be", "war", "zer\u00b7bro\u00b7chen", ";", "der", "B\u00fcr\u00b7ger", "s\u00e4um\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und zog, Ersatz zu fodern, den Juden vor Gericht:", "tokens": ["Und", "zog", ",", "Er\u00b7satz", "zu", "fo\u00b7dern", ",", "den", "Ju\u00b7den", "vor", "Ge\u00b7richt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NN", "PTKZU", "VVINF", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203adenn h\u00e4ttest du gestanden dem Wurf, wie sich's geb\u00fchrt,", "tokens": ["\u203a", "denn", "h\u00e4t\u00b7test", "du", "ge\u00b7stan\u00b7den", "dem", "Wurf", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "VVPP", "ART", "NN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So wurde von dem Steine mein Fenster nicht ber\u00fchrt.\u2039", "tokens": ["So", "wur\u00b7de", "von", "dem", "Stei\u00b7ne", "mein", "Fens\u00b7ter", "nicht", "be\u00b7r\u00fchrt", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.47": {"line.1": {"text": "\u203aihr habt den Stein geworfen, ich habe mich geb\u00fcckt,", "tokens": ["\u203a", "ihr", "habt", "den", "Stein", "ge\u00b7wor\u00b7fen", ",", "ich", "ha\u00b7be", "mich", "ge\u00b7b\u00fcckt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So hat der Wurf die Scheibe des Nachbars nur zerst\u00fcckt;", "tokens": ["So", "hat", "der", "Wurf", "die", "Schei\u00b7be", "des", "Nach\u00b7bars", "nur", "zer\u00b7st\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich soll die Scheibe zahlen, das Recht, das eure, spricht's,", "tokens": ["Ich", "soll", "die", "Schei\u00b7be", "zah\u00b7len", ",", "das", "Recht", ",", "das", "eu\u00b7re", ",", "spricht's", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,", "ART", "NN", "$,", "PRELS", "PPOSAT", "$,", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch hat das Recht verloren, denn, seht! ich habe nichts.\u2039\u00ab", "tokens": ["Doch", "hat", "das", "Recht", "ver\u00b7lo\u00b7ren", ",", "denn", ",", "seht", "!", "ich", "ha\u00b7be", "nichts", ".", "\u2039", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$,", "KON", "$,", "VVFIN", "$.", "PPER", "VAFIN", "PIS", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.48": {"line.1": {"text": "Als jene sich entfernet, verblieben noch die zwei", "tokens": ["Als", "je\u00b7ne", "sich", "ent\u00b7fer\u00b7net", ",", "ver\u00b7blie\u00b7ben", "noch", "die", "zwei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PRF", "VVFIN", "$,", "VVFIN", "ADV", "ART", "CARD"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Im traulichen Gespr\u00e4che, sie dachten laut und frei;", "tokens": ["Im", "trau\u00b7li\u00b7chen", "Ge\u00b7spr\u00e4\u00b7che", ",", "sie", "dach\u00b7ten", "laut", "und", "frei", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Begegnen sich die Geister verwandt im Lichtrevier,", "tokens": ["Be\u00b7geg\u00b7nen", "sich", "die", "Geis\u00b7ter", "ver\u00b7wandt", "im", "Licht\u00b7re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das ist des Lebens Freude, das ist des Lebens Zier.", "tokens": ["Das", "ist", "des", "Le\u00b7bens", "Freu\u00b7de", ",", "das", "ist", "des", "Le\u00b7bens", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.49": {"line.1": {"text": "Und Abba zu dem Freunde: \u00bbBin friedlich ja gesinnt,", "tokens": ["Und", "Ab\u00b7ba", "zu", "dem", "Freun\u00b7de", ":", "\u00bb", "Bin", "fried\u00b7lich", "ja", "ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "$.", "$(", "VAFIN", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du siehst, da\u00df aller Orten sich Hader um mich spinnt;", "tokens": ["Du", "siehst", ",", "da\u00df", "al\u00b7ler", "Or\u00b7ten", "sich", "Ha\u00b7der", "um", "mich", "spinnt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIAT", "NN", "PRF", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Frei mu\u00df ich denken, sprechen und atmen Gottes Luft,", "tokens": ["Frei", "mu\u00df", "ich", "den\u00b7ken", ",", "spre\u00b7chen", "und", "at\u00b7men", "Got\u00b7tes", "Luft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,", "VVFIN", "KON", "ADJA", "NN", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und wer die drei mir raubet, der legt mich in die Gruft.", "tokens": ["Und", "wer", "die", "drei", "mir", "rau\u00b7bet", ",", "der", "legt", "mich", "in", "die", "Gruft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "CARD", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.50": {"line.1": {"text": "Von hinnen will ich ziehen, den Wanderstab zur Hand", "tokens": ["Von", "hin\u00b7nen", "will", "ich", "zie\u00b7hen", ",", "den", "Wan\u00b7der\u00b7stab", "zur", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VMFIN", "PPER", "VVINF", "$,", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Land der Freiheit suchen, nach Holland, Engelland;", "tokens": ["Ein", "Land", "der", "Frei\u00b7heit", "su\u00b7chen", ",", "nach", "Hol\u00b7land", ",", "En\u00b7gel\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$,", "APPR", "NE", "$,", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Druck hat hier den Juden Bedr\u00fcckung auch gelehrt,", "tokens": ["Der", "Druck", "hat", "hier", "den", "Ju\u00b7den", "Be\u00b7dr\u00fc\u00b7ckung", "auch", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohl wird er Duldung \u00fcben, wo Duldung er erf\u00e4hrt.\u00ab", "tokens": ["Wohl", "wird", "er", "Dul\u00b7dung", "\u00fc\u00b7ben", ",", "wo", "Dul\u00b7dung", "er", "er\u00b7f\u00e4hrt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "VVINF", "$,", "PWAV", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.51": {"line.1": {"text": "Und Mendelssohn dagegen und sch\u00fcttelte das Haupt:", "tokens": ["Und", "Men\u00b7dels\u00b7sohn", "da\u00b7ge\u00b7gen", "und", "sch\u00fct\u00b7tel\u00b7te", "das", "Haupt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PAV", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbdu liebewerter Schw\u00e4rmer, der noch an Duldung glaubt,", "tokens": ["\u00bb", "du", "lie\u00b7be\u00b7wer\u00b7ter", "Schw\u00e4r\u00b7mer", ",", "der", "noch", "an", "Dul\u00b7dung", "glaubt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zeuch hin, dich blo\u00df zu geben auch dort der Eulenbrut!", "tokens": ["Zeuch", "hin", ",", "dich", "blo\u00df", "zu", "ge\u00b7ben", "auch", "dort", "der", "Eu\u00b7len\u00b7brut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "ADV", "PTKZU", "VVINF", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dein zugewognes Gl\u00fccksteil, das ist dein froher Mut.\u00ab \u2013", "tokens": ["Dein", "zu\u00b7ge\u00b7wog\u00b7nes", "Gl\u00fccks\u00b7teil", ",", "das", "ist", "dein", "fro\u00b7her", "Mut", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.52": {"line.1": {"text": "\u00bbmein zugewognes Gl\u00fccksteil, das ist die Liebe mein", "tokens": ["\u00bb", "mein", "zu\u00b7ge\u00b7wog\u00b7nes", "Gl\u00fccks\u00b7teil", ",", "das", "ist", "die", "Lie\u00b7be", "mein"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "PPOSAT"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zu meinem Volk; mein Glaube, zu bessern m\u00fcss' es sein;", "tokens": ["Zu", "mei\u00b7nem", "Volk", ";", "mein", "Glau\u00b7be", ",", "zu", "bes\u00b7sern", "m\u00fcss'", "es", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Mein Hoffen, mitzuwirken dazu mit Gut und Blut;", "tokens": ["Mein", "Hof\u00b7fen", ",", "mit\u00b7zu\u00b7wir\u00b7ken", "da\u00b7zu", "mit", "Gut", "und", "Blut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PAV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Du nennst die drei zusammen, das ist mein froher Mut.\u00ab", "tokens": ["Du", "nennst", "die", "drei", "zu\u00b7sam\u00b7men", ",", "das", "ist", "mein", "fro\u00b7her", "Mut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "CARD", "PTKVZ", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.53": {"line.1": {"text": "Und frohen Mutes nahm er den Wanderstab zur Hand,", "tokens": ["Und", "fro\u00b7hen", "Mu\u00b7tes", "nahm", "er", "den", "Wan\u00b7der\u00b7stab", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und zog wohl in die Fremde, nach Holland, Engelland;", "tokens": ["Und", "zog", "wohl", "in", "die", "Frem\u00b7de", ",", "nach", "Hol\u00b7land", ",", "En\u00b7gel\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,", "APPR", "NE", "$,", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den blut'gen Welterobrer verfolgt die Sage nur,", "tokens": ["Den", "blut'\u00b7gen", "Wel\u00b7te\u00b7ro\u00b7brer", "ver\u00b7folgt", "die", "Sa\u00b7ge", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vom Menschenfreund und Bettler verlieret sich die Spur.", "tokens": ["Vom", "Men\u00b7schen\u00b7freund", "und", "Bett\u00b7ler", "ver\u00b7lie\u00b7ret", "sich", "die", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.54": {"line.1": {"text": "Zur\u00fcck nach manchen Jahren gleich frohen Mutes kam", "tokens": ["Zu\u00b7r\u00fcck", "nach", "man\u00b7chen", "Jah\u00b7ren", "gleich", "fro\u00b7hen", "Mu\u00b7tes", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "NN", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er nach Berlin gewandert; sein rechter Arm war lahm;", "tokens": ["Er", "nach", "Ber\u00b7lin", "ge\u00b7wan\u00b7dert", ";", "sein", "rech\u00b7ter", "Arm", "war", "lahm", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "VVPP", "$.", "PPOSAT", "ADJA", "NN", "VAFIN", "PTKVZ", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und blind sein andres Auge, vernarbt sein Angesicht,", "tokens": ["Und", "blind", "sein", "and\u00b7res", "Au\u00b7ge", ",", "ver\u00b7narbt", "sein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein Herz allein, das alte, ver\u00e4ndert war es nicht.", "tokens": ["Sein", "Herz", "al\u00b7lein", ",", "das", "al\u00b7te", ",", "ver\u00b7\u00e4n\u00b7dert", "war", "es", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$,", "ART", "ADJA", "$,", "VVPP", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.55": {"line.1": {"text": "So trat er freundlich l\u00e4chelnd vor Moses Mendelssohn:", "tokens": ["So", "trat", "er", "freund\u00b7lich", "l\u00e4\u00b7chelnd", "vor", "Mo\u00b7ses", "Men\u00b7dels\u00b7sohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJD", "APPR", "NE", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwie dort es mir ergangen, du Kluger, siehst es schon;", "tokens": ["\u00bb", "wie", "dort", "es", "mir", "er\u00b7gan\u00b7gen", ",", "du", "Klu\u00b7ger", ",", "siehst", "es", "schon", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ADV", "PPER", "PPER", "VVPP", "$,", "PPER", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie haben mich geschm\u00e4het, mi\u00dfhandelt und verbannt,", "tokens": ["Sie", "ha\u00b7ben", "mich", "ge\u00b7schm\u00e4\u00b7het", ",", "mi\u00df\u00b7han\u00b7delt", "und", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "War ihnen Macht gegeben, sie h\u00e4tten mich verbrannt.\u00ab", "tokens": ["War", "ih\u00b7nen", "Macht", "ge\u00b7ge\u00b7ben", ",", "sie", "h\u00e4t\u00b7ten", "mich", "ver\u00b7brannt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "NN", "VVPP", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}}, "stanza.56": {"line.1": {"text": "Und wieder frohen Mutes, da ihn Berlin verstie\u00df,", "tokens": ["Und", "wie\u00b7der", "fro\u00b7hen", "Mu\u00b7tes", ",", "da", "ihn", "Ber\u00b7lin", "ver\u00b7stie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Zog er nach seiner Heimat, die Ha\u00df ihm nur verhie\u00df,", "tokens": ["Zog", "er", "nach", "sei\u00b7ner", "Hei\u00b7mat", ",", "die", "Ha\u00df", "ihm", "nur", "ver\u00b7hie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da wallt' er r\u00fcst'gen Schrittes, ein Fremder, fort und fort,", "tokens": ["Da", "wallt'", "er", "r\u00fcst'\u00b7gen", "Schrit\u00b7tes", ",", "ein", "Frem\u00b7der", ",", "fort", "und", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,", "ART", "NN", "$,", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Versto\u00dfen, fluchbeladen, unst\u00e4t von Ort zu Ort.", "tokens": ["Ver\u00b7sto\u00b7\u00dfen", ",", "fluch\u00b7be\u00b7la\u00b7den", ",", "un\u00b7st\u00e4t", "von", "Ort", "zu", "Ort", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJD", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.57": {"line.1": {"text": "Einst sucht' er wohl vergebens seit manchem Tag vielleicht,", "tokens": ["Einst", "sucht'", "er", "wohl", "ver\u00b7ge\u00b7bens", "seit", "man\u00b7chem", "Tag", "viel\u00b7leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wer ihm von seinem Brote das d\u00fcrft'ge St\u00fcck gereicht;", "tokens": ["Wer", "ihm", "von", "sei\u00b7nem", "Bro\u00b7te", "das", "d\u00fcrft'\u00b7ge", "St\u00fcck", "ge\u00b7reicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Scho\u00df der Mutter Erde empfing zur letzten Ruh", "tokens": ["Der", "Scho\u00df", "der", "Mut\u00b7ter", "Er\u00b7de", "emp\u00b7fing", "zur", "letz\u00b7ten", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein graues Haupt, ihm fielen die m\u00fcden Augen zu.", "tokens": ["Sein", "grau\u00b7es", "Haupt", ",", "ihm", "fie\u00b7len", "die", "m\u00fc\u00b7den", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.58": {"line.1": {"text": "Es schallen gut im Liede der Purpur und das Schwert,", "tokens": ["Es", "schal\u00b7len", "gut", "im", "Lie\u00b7de", "der", "Pur\u00b7pur", "und", "das", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Doch h\u00fcllt sich oft in Lumpen, der auch ist preisenswert;", "tokens": ["Doch", "h\u00fcllt", "sich", "oft", "in", "Lum\u00b7pen", ",", "der", "auch", "ist", "prei\u00b7sens\u00b7wert", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,", "PRELS", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich f\u00fchr euch einen Juden und Bettler heute vor,", "tokens": ["Ich", "f\u00fchr", "euch", "ei\u00b7nen", "Ju\u00b7den", "und", "Bett\u00b7ler", "heu\u00b7te", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "KON", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Abba Glosk Leczeka, verschlie\u00dft ihm nicht das Ohr.", "tokens": ["Den", "Ab\u00b7ba", "Glosk", "Le\u00b7cze\u00b7ka", ",", "ver\u00b7schlie\u00dft", "ihm", "nicht", "das", "Ohr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "NE", "$,", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.59": {"line.1": {"text": "Er harrte vor der T\u00fcre von Moses Mendelssohn", "tokens": ["Er", "harr\u00b7te", "vor", "der", "T\u00fc\u00b7re", "von", "Mo\u00b7ses", "Men\u00b7dels\u00b7sohn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gelassen und geduldig vor Sonnenaufgang schon;", "tokens": ["Ge\u00b7las\u00b7sen", "und", "ge\u00b7dul\u00b7dig", "vor", "Son\u00b7nen\u00b7auf\u00b7gang", "schon", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie hoch in Himmelsr\u00e4umen zu steigen sie begann,", "tokens": ["Wie", "hoch", "in", "Him\u00b7mels\u00b7r\u00e4u\u00b7men", "zu", "stei\u00b7gen", "sie", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "APPR", "NN", "PTKZU", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Trat erst aus seiner Wohnung der weitber\u00fchmte Mann.", "tokens": ["Trat", "erst", "aus", "sei\u00b7ner", "Woh\u00b7nung", "der", "weit\u00b7be\u00b7r\u00fchm\u00b7te", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.60": {"line.1": {"text": "Ihn gr\u00fc\u00dft der fremde Bettler in polnisch j\u00fcd'scher Tracht,", "tokens": ["Ihn", "gr\u00fc\u00dft", "der", "frem\u00b7de", "Bett\u00b7ler", "in", "pol\u00b7nisch", "j\u00fcd'\u00b7scher", "Tracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Sein Gru\u00df den Schriftgelehrten dem andern kenntlich macht,", "tokens": ["Sein", "Gru\u00df", "den", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "dem", "an\u00b7dern", "kennt\u00b7lich", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "ART", "ADJA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er aber geht vor\u00fcber: \u00bbAn Zeit es mir gebricht!\u00ab \u2013", "tokens": ["Er", "a\u00b7ber", "geht", "vor\u00b7\u00fc\u00b7ber", ":", "\u00bb", "An", "Zeit", "es", "mir", "ge\u00b7bricht", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PTKVZ", "$.", "$(", "APPR", "NN", "PPER", "PPER", "VVFIN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Fremde weicht zur\u00fccke, doch von der Schwelle nicht.", "tokens": ["Der", "Frem\u00b7de", "weicht", "zu\u00b7r\u00fc\u00b7cke", ",", "doch", "von", "der", "Schwel\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ADV", "APPR", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.61": {"line.1": {"text": "Und Mittag ward's und Abend, und als zur Nacht es ging,", "tokens": ["Und", "Mit\u00b7tag", "ward's", "und", "A\u00b7bend", ",", "und", "als", "zur", "Nacht", "es", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "KON", "NN", "$,", "KON", "KOUS", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Stadt in ihren Stra\u00dfen die Schatten schon empfing,", "tokens": ["Die", "Stadt", "in", "ih\u00b7ren", "Stra\u00b7\u00dfen", "die", "Schat\u00b7ten", "schon", "emp\u00b7fing", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kam heim zu seinem Herde der weitber\u00fchmte Mann,", "tokens": ["Kam", "heim", "zu", "sei\u00b7nem", "Her\u00b7de", "der", "weit\u00b7be\u00b7r\u00fchm\u00b7te", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da gr\u00fc\u00dft' ihn noch der Bettler, wie morgens er getan.", "tokens": ["Da", "gr\u00fc\u00dft'", "ihn", "noch", "der", "Bett\u00b7ler", ",", "wie", "mor\u00b7gens", "er", "ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "PWAV", "ADV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.62": {"line.1": {"text": "Er sucht in seiner B\u00f6rse nach einem Silberst\u00fcck,", "tokens": ["Er", "sucht", "in", "sei\u00b7ner", "B\u00f6r\u00b7se", "nach", "ei\u00b7nem", "Sil\u00b7ber\u00b7st\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihm h\u00e4lt der fremde Bettler die milde Hand zur\u00fcck:", "tokens": ["Ihm", "h\u00e4lt", "der", "frem\u00b7de", "Bett\u00b7ler", "die", "mil\u00b7de", "Hand", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbdas nicht von dir begehr ich, nur dein lebend'ges Wort,", "tokens": ["\u00bb", "das", "nicht", "von", "dir", "be\u00b7gehr", "ich", ",", "nur", "dein", "le\u00b7ben\u00b7d'\u00b7ges", "Wort", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "PTKNEG", "APPR", "PPER", "VVFIN", "PPER", "$,", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Mich f\u00fchrt der Durst nach Wahrheit allein an diesen Ort.\u00ab \u2013", "tokens": ["Mich", "f\u00fchrt", "der", "Durst", "nach", "Wahr\u00b7heit", "al\u00b7lein", "an", "die\u00b7sen", "Ort", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "ADV", "APPR", "PDAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}}, "stanza.63": {"line.1": {"text": "\u00bbdu scheinst der kleinen Gabe bed\u00fcrftig mir zu sein.\u00ab \u2013", "tokens": ["\u00bb", "du", "scheinst", "der", "klei\u00b7nen", "Ga\u00b7be", "be\u00b7d\u00fcrf\u00b7tig", "mir", "zu", "sein", ".", "\u00ab", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "ADJD", "PPER", "PTKZU", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbdu h\u00e4ltst mich f\u00fcr unw\u00fcrdig der gr\u00f6\u00dfern!\u00ab \u2013 \u00bbTritt herein!", "tokens": ["\u00bb", "du", "h\u00e4ltst", "mich", "f\u00fcr", "un\u00b7w\u00fcr\u00b7dig", "der", "gr\u00f6\u00b7\u00dfern", "!", "\u00ab", "\u2013", "\u00bb", "Tritt", "her\u00b7ein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "ADJD", "ART", "ADJA", "$.", "$(", "$(", "$(", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Suchst redlich du die Wahrheit, die vielen so verha\u00dft,", "tokens": ["Suchst", "red\u00b7lich", "du", "die", "Wahr\u00b7heit", ",", "die", "vie\u00b7len", "so", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "NN", "$,", "PRELS", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So sei dem Gleichgesinnten ein liebgehegter Gast.\u00ab", "tokens": ["So", "sei", "dem", "Gleich\u00b7ge\u00b7sinn\u00b7ten", "ein", "lieb\u00b7ge\u00b7heg\u00b7ter", "Gast", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.64": {"line.1": {"text": "Beim wogenden Gespr\u00e4che, beim h\u00e4uslich trauten Mahl,", "tokens": ["Beim", "wo\u00b7gen\u00b7den", "Ge\u00b7spr\u00e4\u00b7che", ",", "beim", "h\u00e4us\u00b7lich", "trau\u00b7ten", "Mahl", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPRART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Beim Becher edlen Weines, dem fl\u00fcss'gen Sonnenstrahl,", "tokens": ["Beim", "Be\u00b7cher", "ed\u00b7len", "Wei\u00b7nes", ",", "dem", "fl\u00fcss'\u00b7gen", "Son\u00b7nen\u00b7strahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Erbl\u00fcht dem fremden Bettler die Rede wunderbar,", "tokens": ["Er\u00b7bl\u00fcht", "dem", "frem\u00b7den", "Bett\u00b7ler", "die", "Re\u00b7de", "wun\u00b7der\u00b7bar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein Gl\u00e4ub'ger und ein Denker, wie nie noch einer war.", "tokens": ["Ein", "Gl\u00e4ub'\u00b7ger", "und", "ein", "Den\u00b7ker", ",", "wie", "nie", "noch", "ei\u00b7ner", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PWAV", "ADV", "ADV", "PIS", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.65": {"line.1": {"text": "Er hat des Wortes Fessel gesprengt mit Geistes-Kraft,", "tokens": ["Er", "hat", "des", "Wor\u00b7tes", "Fes\u00b7sel", "ge\u00b7sprengt", "mit", "Geis\u00b7tes\u00b7Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er h\u00e4ngt am Guten, Wahren so recht mit Leidenschaft,", "tokens": ["Er", "h\u00e4ngt", "am", "Gu\u00b7ten", ",", "Wah\u00b7ren", "so", "recht", "mit", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "NN", "ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er spr\u00fchet Lichtgedanken so machtvoll vor sich hin,", "tokens": ["Er", "spr\u00fc\u00b7het", "Licht\u00b7ge\u00b7dan\u00b7ken", "so", "macht\u00b7voll", "vor", "sich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "ADV", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So eignen Reiz verleiht ihm sein heitrer froher Sinn.", "tokens": ["So", "eig\u00b7nen", "Reiz", "ver\u00b7leiht", "ihm", "sein", "hei\u00b7trer", "fro\u00b7her", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "PPOSAT", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.66": {"line.1": {"text": "Und ob des seltnen Mannes verwundert und erfreut,", "tokens": ["Und", "ob", "des", "selt\u00b7nen", "Man\u00b7nes", "ver\u00b7wun\u00b7dert", "und", "er\u00b7freut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der seine Neigung fesselt und Ehrfurcht ihm gebeut,", "tokens": ["Der", "sei\u00b7ne", "Nei\u00b7gung", "fes\u00b7selt", "und", "Ehr\u00b7furcht", "ihm", "ge\u00b7beut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Fragt Mendelssohn ihn traulich: \u00bbWie haben Schul und Welt", "tokens": ["Fragt", "Men\u00b7dels\u00b7sohn", "ihn", "trau\u00b7lich", ":", "\u00bb", "Wie", "ha\u00b7ben", "Schul", "und", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "PPER", "ADJD", "$.", "$(", "PWAV", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So seltsam dich erzogen und deinen Geist erhellt?\u00ab", "tokens": ["So", "selt\u00b7sam", "dich", "er\u00b7zo\u00b7gen", "und", "dei\u00b7nen", "Geist", "er\u00b7hellt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVPP", "KON", "PPOSAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.67": {"line.1": {"text": "Drauf er: \u00bbDu lenkst vom Lichte die Blicke niederw\u00e4rts,", "tokens": ["Drauf", "er", ":", "\u00bb", "Du", "lenkst", "vom", "Lich\u00b7te", "die", "Bli\u00b7cke", "nie\u00b7der\u00b7w\u00e4rts", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$.", "$(", "PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zu forschen nach dem Menschen und schauen ihm ins Herz;", "tokens": ["Zu", "for\u00b7schen", "nach", "dem", "Men\u00b7schen", "und", "schau\u00b7en", "ihm", "ins", "Herz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "ART", "NN", "KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich zeige mich dem Freunde, und meinen Weg und Ziel,", "tokens": ["Ich", "zei\u00b7ge", "mich", "dem", "Freun\u00b7de", ",", "und", "mei\u00b7nen", "Weg", "und", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,", "KON", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und melde, wie die Binde mir von den Augen fiel.", "tokens": ["Und", "mel\u00b7de", ",", "wie", "die", "Bin\u00b7de", "mir", "von", "den", "Au\u00b7gen", "fiel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.68": {"line.1": {"text": "Mein Forschen und mein Trachten, das bin ich selbst und ganz;", "tokens": ["Mein", "For\u00b7schen", "und", "mein", "Trach\u00b7ten", ",", "das", "bin", "ich", "selbst", "und", "ganz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "PPER", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Minuten so wie diese sind meines Lebens Glanz;", "tokens": ["Mi\u00b7nu\u00b7ten", "so", "wie", "die\u00b7se", "sind", "mei\u00b7nes", "Le\u00b7bens", "Glanz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KOKOM", "PDS", "VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich trage sechzig Jahre noch frisch und wohlgemut,", "tokens": ["Ich", "tra\u00b7ge", "sech\u00b7zig", "Jah\u00b7re", "noch", "frisch", "und", "wohl\u00b7ge\u00b7mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Noch schmilzt den Schnee des Alters des Herzens innre Glut.", "tokens": ["Noch", "schmilzt", "den", "Schnee", "des", "Al\u00b7ters", "des", "Her\u00b7zens", "inn\u00b7re", "Glut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NN", "ADJA", "NN", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}}, "stanza.69": {"line.1": {"text": "Zu Glosk in unsern Schulen bekam ich Unterricht;", "tokens": ["Zu", "Glosk", "in", "un\u00b7sern", "Schu\u00b7len", "be\u00b7kam", "ich", "Un\u00b7ter\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Talmud und der Talmud! sie wu\u00dften andres nicht;", "tokens": ["Der", "Tal\u00b7mud", "und", "der", "Tal\u00b7mud", "!", "sie", "wu\u00df\u00b7ten", "and\u00b7res", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$.", "PPER", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Verhangen und verfinstert das g\u00f6ttliche Gebot,", "tokens": ["Ver\u00b7han\u00b7gen", "und", "ver\u00b7fins\u00b7tert", "das", "g\u00f6tt\u00b7li\u00b7che", "Ge\u00b7bot", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das leis aus tiefstem Herzen sich doch mir mahnend bot.", "tokens": ["Das", "leis", "aus", "tiefs\u00b7tem", "Her\u00b7zen", "sich", "doch", "mir", "mah\u00b7nend", "bot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "APPR", "ADJA", "NN", "PRF", "ADV", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.70": {"line.1": {"text": "Wie hab ich oft mit Schmerzen die stumme Mitternacht", "tokens": ["Wie", "hab", "ich", "oft", "mit", "Schmer\u00b7zen", "die", "stum\u00b7me", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Auf ihren toten B\u00fcchern verst\u00f6rt herangewacht;", "tokens": ["Auf", "ih\u00b7ren", "to\u00b7ten", "B\u00fc\u00b7chern", "ver\u00b7st\u00f6rt", "her\u00b7an\u00b7ge\u00b7wacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wie h\u00e4tt ich fromm und willig den Lehrern nur geglaubt,", "tokens": ["Wie", "h\u00e4tt", "ich", "fromm", "und", "wil\u00b7lig", "den", "Leh\u00b7rern", "nur", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und wiegte doch verneinend mein sorgenschweres Haupt.", "tokens": ["Und", "wieg\u00b7te", "doch", "ver\u00b7nei\u00b7nend", "mein", "sor\u00b7gen\u00b7schwe\u00b7res", "Haupt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVPP", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.71": {"line.1": {"text": "Und nun ich sollte lehren, so wie ich selbst belehrt,", "tokens": ["Und", "nun", "ich", "soll\u00b7te", "leh\u00b7ren", ",", "so", "wie", "ich", "selbst", "be\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VMFIN", "VVINF", "$,", "ADV", "KOKOM", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Da hat sich mir die Rede gar wundersam verkehrt;", "tokens": ["Da", "hat", "sich", "mir", "die", "Re\u00b7de", "gar", "wun\u00b7der\u00b7sam", "ver\u00b7kehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da schalt aus mir die Stimme auf Satzungen und Trug,", "tokens": ["Da", "schalt", "aus", "mir", "die", "Stim\u00b7me", "auf", "Sat\u00b7zun\u00b7gen", "und", "Trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--++--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dem Blitze zu vergleichen, der aus den Wolken schlug.", "tokens": ["Dem", "Blit\u00b7ze", "zu", "ver\u00b7glei\u00b7chen", ",", "der", "aus", "den", "Wol\u00b7ken", "schlug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.72": {"line.1": {"text": "Sie haben sich entsetzet, sie haben mich fortan", "tokens": ["Sie", "ha\u00b7ben", "sich", "ent\u00b7set\u00b7zet", ",", "sie", "ha\u00b7ben", "mich", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "VVFIN", "$,", "PPER", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bedrohet und gef\u00e4hrdet und in den Bann getan;", "tokens": ["Be\u00b7dro\u00b7het", "und", "ge\u00b7f\u00e4hr\u00b7det", "und", "in", "den", "Bann", "ge\u00b7tan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVPP", "KON", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich hatte mich gefunden, ich war, der ich nun bin,", "tokens": ["Ich", "hat\u00b7te", "mich", "ge\u00b7fun\u00b7den", ",", "ich", "war", ",", "der", "ich", "nun", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VAFIN", "$,", "PRELS", "PPER", "ADV", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ich folgte meiner Sendung mit leichtem, freud'gem Sinn.", "tokens": ["Ich", "folg\u00b7te", "mei\u00b7ner", "Sen\u00b7dung", "mit", "leich\u00b7tem", ",", "freu\u00b7d'\u00b7gem", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.73": {"line.1": {"text": "So wallt ich, in der Heimat ein Fremder, nun hinfort", "tokens": ["So", "wallt", "ich", ",", "in", "der", "Hei\u00b7mat", "ein", "Frem\u00b7der", ",", "nun", "hin\u00b7fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "ART", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Versto\u00dfen, fluchbeladen, unst\u00e4t von Ort zu Ort,", "tokens": ["Ver\u00b7sto\u00b7\u00dfen", ",", "fluch\u00b7be\u00b7la\u00b7den", ",", "un\u00b7st\u00e4t", "von", "Ort", "zu", "Ort", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJD", "APPR", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und forschte, sprach und lehrte, und trachtete doch nur,", "tokens": ["Und", "forschte", ",", "sprach", "und", "lehr\u00b7te", ",", "und", "trach\u00b7te\u00b7te", "doch", "nur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "KON", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Das arme Volk zu leiten auf eine be\u00dfre Spur.", "tokens": ["Das", "ar\u00b7me", "Volk", "zu", "lei\u00b7ten", "auf", "ei\u00b7ne", "be\u00df\u00b7re", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.74": {"line.1": {"text": "Und dreizehn B\u00fccher hatt ich verfa\u00dft mit allem Flei\u00df,", "tokens": ["Und", "drei\u00b7zehn", "B\u00fc\u00b7cher", "hatt", "ich", "ver\u00b7fa\u00dft", "mit", "al\u00b7lem", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "PPER", "VVFIN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die B\u00fccher, sie enthielten das Beste, was ich wei\u00df;", "tokens": ["Die", "B\u00fc\u00b7cher", ",", "sie", "ent\u00b7hiel\u00b7ten", "das", "Bes\u00b7te", ",", "was", "ich", "wei\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zu Wilna, oh! da waren fast grausam allzusehr", "tokens": ["Zu", "Wil\u00b7na", ",", "oh", "!", "da", "wa\u00b7ren", "fast", "grau\u00b7sam", "all\u00b7zu\u00b7sehr"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "FM", "$.", "ADV", "VAFIN", "ADV", "ADJD", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die \u00c4ltesten des Volkes, wie nirgends anders mehr.", "tokens": ["Die", "\u00c4l\u00b7tes\u00b7ten", "des", "Vol\u00b7kes", ",", "wie", "nir\u00b7gends", "an\u00b7ders", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "PWAV", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.75": {"line.1": {"text": "Sie haben meine B\u00fccher zerrissen insgesamt,", "tokens": ["Sie", "ha\u00b7ben", "mei\u00b7ne", "B\u00fc\u00b7cher", "zer\u00b7ris\u00b7sen", "ins\u00b7ge\u00b7samt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVFIN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und haben zu den Flammen sie ungeh\u00f6rt verdammt;", "tokens": ["Und", "ha\u00b7ben", "zu", "den", "Flam\u00b7men", "sie", "un\u00b7ge\u00b7h\u00f6rt", "ver\u00b7dammt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ART", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie schichteten den Holzsto\u00df beim alten Apfelbaum", "tokens": ["Sie", "schich\u00b7te\u00b7ten", "den", "Holz\u00b7sto\u00df", "beim", "al\u00b7ten", "Ap\u00b7fel\u00b7baum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vor ihrer Synagoge im innern Hofesraum.", "tokens": ["Vor", "ih\u00b7rer", "Syn\u00b7a\u00b7go\u00b7ge", "im", "in\u00b7nern", "Ho\u00b7fes\u00b7raum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.76": {"line.1": {"text": "Da standen in dem Rauche die Alten bl\u00f6d und blind,", "tokens": ["Da", "stan\u00b7den", "in", "dem", "Rau\u00b7che", "die", "Al\u00b7ten", "bl\u00f6d", "und", "blind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Den schlug auf sie hernieder ein m\u00e4cht'ger Wirbelwind,", "tokens": ["Den", "schlug", "auf", "sie", "her\u00b7nie\u00b7der", "ein", "m\u00e4cht'\u00b7ger", "Wir\u00b7bel\u00b7wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gereinigt schwang die Flamme sich zu dem h\u00f6hern Licht;", "tokens": ["Ge\u00b7rei\u00b7nigt", "schwang", "die", "Flam\u00b7me", "sich", "zu", "dem", "h\u00f6\u00b7hern", "Licht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "ART", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Geist, das Licht, die Sonne vernichten sie doch nicht.", "tokens": ["Den", "Geist", ",", "das", "Licht", ",", "die", "Son\u00b7ne", "ver\u00b7nich\u00b7ten", "sie", "doch", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.77": {"line.1": {"text": "Ich selbst ich sollte sterben, kaum heimlich war der Rat;", "tokens": ["Ich", "selbst", "ich", "soll\u00b7te", "ster\u00b7ben", ",", "kaum", "heim\u00b7lich", "war", "der", "Rat", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPER", "VMFIN", "VVINF", "$,", "ADV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Doch fand sich ein Rabbiner, der um mein Leben bat,", "tokens": ["Doch", "fand", "sich", "ein", "Rab\u00b7bi\u00b7ner", ",", "der", "um", "mein", "Le\u00b7ben", "bat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich wurde blo\u00df gegei\u00dfelt, und als man frei mich gab,", "tokens": ["Ich", "wur\u00b7de", "blo\u00df", "ge\u00b7gei\u00b7\u00dfelt", ",", "und", "als", "man", "frei", "mich", "gab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "KON", "KOUS", "PIS", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So griff ich heitern Sinnes zu meinem Wanderstab.", "tokens": ["So", "griff", "ich", "hei\u00b7tern", "Sin\u00b7nes", "zu", "mei\u00b7nem", "Wan\u00b7der\u00b7stab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.78": {"line.1": {"text": "Der freud'ge, r\u00fcst'ge Waller zieht \u00fcber Berg und Tal,", "tokens": ["Der", "freu\u00b7d'\u00b7ge", ",", "r\u00fcst'\u00b7ge", "Wal\u00b7ler", "zieht", "\u00fc\u00b7ber", "Berg", "und", "Tal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihm scheinet, ihn erw\u00e4rmet der lieben Sonne Strahl,", "tokens": ["Ihm", "schei\u00b7net", ",", "ihn", "er\u00b7w\u00e4r\u00b7met", "der", "lie\u00b7ben", "Son\u00b7ne", "Strahl", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Scho\u00df der gr\u00fcnen Erde empf\u00e4ngt mit rechter Lust", "tokens": ["Der", "Scho\u00df", "der", "gr\u00fc\u00b7nen", "Er\u00b7de", "emp\u00b7f\u00e4ngt", "mit", "rech\u00b7ter", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein m\u00fcdes Haupt am Abend, er ruht an Mutterbrust.", "tokens": ["Sein", "m\u00fc\u00b7des", "Haupt", "am", "A\u00b7bend", ",", "er", "ruht", "an", "Mut\u00b7ter\u00b7brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.79": {"line.1": {"text": "Wer je von seinen Br\u00fcdern den Hunger selber litt,", "tokens": ["Wer", "je", "von", "sei\u00b7nen", "Br\u00fc\u00b7dern", "den", "Hun\u00b7ger", "sel\u00b7ber", "litt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Teilt ihm vom letzten Brote gern einen Brocken mit,", "tokens": ["Teilt", "ihm", "vom", "letz\u00b7ten", "Bro\u00b7te", "gern", "ei\u00b7nen", "Bro\u00b7cken", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "ADJA", "NN", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er zieht durch Land und St\u00e4dte und r\u00fchmt sich reich und frei,", "tokens": ["Er", "zieht", "durch", "Land", "und", "St\u00e4d\u00b7te", "und", "r\u00fchmt", "sich", "reich", "und", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "KON", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und wei\u00df von keiner Armut und keiner Sklaverei.", "tokens": ["Und", "wei\u00df", "von", "kei\u00b7ner", "Ar\u00b7mut", "und", "kei\u00b7ner", "Skla\u00b7ve\u00b7rei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.80": {"line.1": {"text": "Vor Sprach- und Stammverwandten entquillt an jedem Ort", "tokens": ["Vor", "Sprach", "und", "Stamm\u00b7ver\u00b7wand\u00b7ten", "ent\u00b7quillt", "an", "je\u00b7dem", "Ort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "TRUNC", "KON", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Aus \u00fcbervollem Herzen ihm das lebend'ge Wort,", "tokens": ["Aus", "\u00fc\u00b7ber\u00b7vol\u00b7lem", "Her\u00b7zen", "ihm", "das", "le\u00b7ben\u00b7d'\u00b7ge", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Zu lehren und zu bessern, zu sichten sonder Scheu", "tokens": ["Zu", "leh\u00b7ren", "und", "zu", "bes\u00b7sern", ",", "zu", "sich\u00b7ten", "son\u00b7der", "Scheu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$,", "PTKZU", "VVINF", "KON", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Glauben von dem Wahne, den Weizen von der Spreu.", "tokens": ["Den", "Glau\u00b7ben", "von", "dem", "Wah\u00b7ne", ",", "den", "Wei\u00b7zen", "von", "der", "Spreu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.81": {"line.1": {"text": "Ist Felsen auch der Boden, die Saat verstreue nur!", "tokens": ["Ist", "Fel\u00b7sen", "auch", "der", "Bo\u00b7den", ",", "die", "Saat", "ver\u00b7streu\u00b7e", "nur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "ART", "NN", "$,", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es tr\u00e4ufelt auf den Felsen, wie auf die gr\u00fcne Flur,", "tokens": ["Es", "tr\u00e4u\u00b7felt", "auf", "den", "Fel\u00b7sen", ",", "wie", "auf", "die", "gr\u00fc\u00b7ne", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Des Ew'gen milder Regen. Beharrlichkeit! Geduld!", "tokens": ["Des", "Ew'\u00b7gen", "mil\u00b7der", "Re\u00b7gen", ".", "Be\u00b7harr\u00b7lich\u00b7keit", "!", "Ge\u00b7duld", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "NN", "$.", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Du zahlest deinem Sch\u00f6pfer so deines Lebens Schuld.", "tokens": ["Du", "zah\u00b7lest", "dei\u00b7nem", "Sch\u00f6p\u00b7fer", "so", "dei\u00b7nes", "Le\u00b7bens", "Schuld", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.82": {"line.1": {"text": "Und herw\u00e4rts zog mich m\u00e4chtig und ahndungsvoll mein Herz,", "tokens": ["Und", "her\u00b7w\u00e4rts", "zog", "mich", "m\u00e4ch\u00b7tig", "und", "ahn\u00b7dungs\u00b7voll", "mein", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADJD", "KON", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von deines Namens Klange gelockt, du reines Erz;", "tokens": ["Von", "dei\u00b7nes", "Na\u00b7mens", "Klan\u00b7ge", "ge\u00b7lockt", ",", "du", "rei\u00b7nes", "Erz", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "VVPP", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Du bist, den ich gesuchet, du, der vom Wahne fern", "tokens": ["Du", "bist", ",", "den", "ich", "ge\u00b7su\u00b7chet", ",", "du", ",", "der", "vom", "Wah\u00b7ne", "fern"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "PPER", "VVPP", "$,", "PPER", "$,", "PRELS", "APPRART", "NN", "ADJD"], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}, "line.4": {"text": "Zerbricht die hohle Schale und sucht nach ihrem Kern.", "tokens": ["Zer\u00b7bricht", "die", "hoh\u00b7le", "Scha\u00b7le", "und", "sucht", "nach", "ih\u00b7rem", "Kern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.83": {"line.1": {"text": "Das will auch ich, so reiche mir deine liebe Hand,", "tokens": ["Das", "will", "auch", "ich", ",", "so", "rei\u00b7che", "mir", "dei\u00b7ne", "lie\u00b7be", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADV", "PPER", "$,", "ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wir schaffen hier und kn\u00fcpfen ein gottgef\u00e4llig Band;", "tokens": ["Wir", "schaf\u00b7fen", "hier", "und", "kn\u00fcp\u00b7fen", "ein", "gott\u00b7ge\u00b7f\u00e4l\u00b7lig", "Band", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "KON", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das Licht, das ist das Gute; die Finsternis, die Nacht,", "tokens": ["Das", "Licht", ",", "das", "ist", "das", "Gu\u00b7te", ";", "die", "Fins\u00b7ter\u00b7nis", ",", "die", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "$.", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das ist das Reich der S\u00fcnde und ist des B\u00f6sen Macht.", "tokens": ["Das", "ist", "das", "Reich", "der", "S\u00fcn\u00b7de", "und", "ist", "des", "B\u00f6\u00b7sen", "Macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "KON", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.84": {"line.1": {"text": "Dir str\u00f6met von den Lippen ein ruhig klarer Born,", "tokens": ["Dir", "str\u00f6\u00b7met", "von", "den", "Lip\u00b7pen", "ein", "ru\u00b7hig", "kla\u00b7rer", "Born", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Es leiht gewalt'ge Worte mir oft ein heil'ger Zorn;", "tokens": ["Es", "leiht", "ge\u00b7walt'\u00b7ge", "Wor\u00b7te", "mir", "oft", "ein", "heil'\u00b7ger", "Zorn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "So la\u00df vor unserm Volke zerrei\u00dfen uns vereint", "tokens": ["So", "la\u00df", "vor", "un\u00b7serm", "Vol\u00b7ke", "zer\u00b7rei\u00b7\u00dfen", "uns", "ver\u00b7eint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Des Aberglaubens Schleier, bis hell der Tag ihm scheint.", "tokens": ["Des", "A\u00b7berg\u00b7lau\u00b7bens", "Schlei\u00b7er", ",", "bis", "hell", "der", "Tag", "ihm", "scheint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "ADJD", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.85": {"line.1": {"text": "Nicht tr\u00e4ge denn, nicht l\u00e4ssig; die Hand ans Werk gelegt!", "tokens": ["Nicht", "tr\u00e4\u00b7ge", "denn", ",", "nicht", "l\u00e4s\u00b7sig", ";", "die", "Hand", "ans", "Werk", "ge\u00b7legt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ADV", "$,", "PTKNEG", "ADJD", "$.", "ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Versammle du die J\u00fcnger, es tagt, die Stunde schl\u00e4gt!", "tokens": ["Ver\u00b7samm\u00b7le", "du", "die", "J\u00fcn\u00b7ger", ",", "es", "tagt", ",", "die", "Stun\u00b7de", "schl\u00e4gt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Wir hammern an den Felsen, bis hell der Stein erklingt,", "tokens": ["Wir", "ham\u00b7mern", "an", "den", "Fel\u00b7sen", ",", "bis", "hell", "der", "Stein", "er\u00b7klingt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und an das Licht der Sprudel lebend'gen Wassers springt.\u00ab", "tokens": ["Und", "an", "das", "Licht", "der", "Spru\u00b7del", "le\u00b7ben\u00b7d'\u00b7gen", "Was\u00b7sers", "springt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}}, "stanza.86": {"line.1": {"text": "Darauf mit R\u00fchrung l\u00e4chelnd der Wirt zu seinem Gast:", "tokens": ["Da\u00b7rauf", "mit", "R\u00fch\u00b7rung", "l\u00e4\u00b7chelnd", "der", "Wirt", "zu", "sei\u00b7nem", "Gast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "ADJD", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbgen\u00fcgt dir nicht, du Guter, was du erduldet hast?", "tokens": ["\u00bb", "ge\u00b7n\u00fcgt", "dir", "nicht", ",", "du", "Gu\u00b7ter", ",", "was", "du", "er\u00b7dul\u00b7det", "hast", "?"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "NN", "$,", "PWS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Soll wiederum sich schichten ein Scheiterhaufen? kann", "tokens": ["Soll", "wie\u00b7de\u00b7rum", "sich", "schich\u00b7ten", "ein", "Schei\u00b7ter\u00b7hau\u00b7fen", "?", "kann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VMFIN", "ADV", "PRF", "VVFIN", "ART", "NN", "$.", "VMFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Gei\u00dfel nicht dich lehren? du lehrbegier'ger Mann!", "tokens": ["Die", "Gei\u00b7\u00dfel", "nicht", "dich", "leh\u00b7ren", "?", "du", "lehr\u00b7be\u00b7gier'\u00b7ger", "Mann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PPER", "VVINF", "$.", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.87": {"line.1": {"text": "Du forschest nach der Wahrheit; erkenne doch die Welt,", "tokens": ["Du", "for\u00b7schest", "nach", "der", "Wahr\u00b7heit", ";", "er\u00b7ken\u00b7ne", "doch", "die", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$.", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die fester als am Glauben am Aberglauben h\u00e4lt;", "tokens": ["Die", "fes\u00b7ter", "als", "am", "Glau\u00b7ben", "am", "A\u00b7berg\u00b7lau\u00b7ben", "h\u00e4lt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KOKOM", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Was je gelebt im Geiste, geh\u00f6rt der Ewigkeit,", "tokens": ["Was", "je", "ge\u00b7lebt", "im", "Geis\u00b7te", ",", "ge\u00b7h\u00f6rt", "der", "E\u00b7wig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VVPP", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Nur ruft es erst ins Leben die allgewalt'ge Zeit.", "tokens": ["Nur", "ruft", "es", "erst", "ins", "Le\u00b7ben", "die", "all\u00b7ge\u00b7walt'\u00b7ge", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.88": {"line.1": {"text": "Bleib hie und lerne schweigen, wo sprechen nicht am Ort;", "tokens": ["Bleib", "hie", "und", "ler\u00b7ne", "schwei\u00b7gen", ",", "wo", "spre\u00b7chen", "nicht", "am", "Ort", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "VVFIN", "VVINF", "$,", "PWAV", "VVFIN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du magst im Stillen forschen, erw\u00e4gen Geist und Wort,", "tokens": ["Du", "magst", "im", "Stil\u00b7len", "for\u00b7schen", ",", "er\u00b7w\u00e4\u00b7gen", "Geist", "und", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVINF", "$,", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und magst das Korn der Furche der Zeiten anvertraun;", "tokens": ["Und", "magst", "das", "Korn", "der", "Fur\u00b7che", "der", "Zei\u00b7ten", "an\u00b7ver\u00b7traun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vielleicht wird einst dein Enkel die goldnen Saaten schaun.\u00ab", "tokens": ["Viel\u00b7leicht", "wird", "einst", "dein", "En\u00b7kel", "die", "gold\u00b7nen", "Saa\u00b7ten", "schaun", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.89": {"line.1": {"text": "Drauf er: \u00bbDu schweigst, du Kluger, und schweigen soll mein Mund!", "tokens": ["Drauf", "er", ":", "\u00bb", "Du", "schweigst", ",", "du", "Klu\u00b7ger", ",", "und", "schwei\u00b7gen", "soll", "mein", "Mund", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "$.", "$(", "PPER", "VVFIN", "$,", "PPER", "NN", "$,", "KON", "VVINF", "VMFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So sprich, wer soll denn reden und tun die Wahrheit kund?", "tokens": ["So", "sprich", ",", "wer", "soll", "denn", "re\u00b7den", "und", "tun", "die", "Wahr\u00b7heit", "kund", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PWS", "VMFIN", "ADV", "VVINF", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+------+-+-+", "measure": "dactylic.init"}, "line.3": {"text": "Du helles Licht des Geistes sollst leuchten freundlich mir;", "tokens": ["Du", "hel\u00b7les", "Licht", "des", "Geis\u00b7tes", "sollst", "leuch\u00b7ten", "freund\u00b7lich", "mir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "ART", "NN", "VMFIN", "VVFIN", "ADJD", "PPER", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die Hand darauf! \u2013 wir scheiden! mein Pfad, der trennt sich hier.\u00ab", "tokens": ["Die", "Hand", "da\u00b7rauf", "!", "\u2013", "wir", "schei\u00b7den", "!", "mein", "Pfad", ",", "der", "trennt", "sich", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PAV", "$.", "$(", "PPER", "VVINF", "$.", "PPOSAT", "NN", "$,", "PRELS", "VVFIN", "PRF", "ADV", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.90": {"line.1": {"text": "Er ging; dem Flammengeiste, dem Flammenherzen galt", "tokens": ["Er", "ging", ";", "dem", "Flam\u00b7men\u00b7geis\u00b7te", ",", "dem", "Flam\u00b7men\u00b7her\u00b7zen", "galt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "F\u00fcr Feigheit jede Vorsicht, und freundlich z\u00fcrnend schalt", "tokens": ["F\u00fcr", "Feig\u00b7heit", "je\u00b7de", "Vor\u00b7sicht", ",", "und", "freund\u00b7lich", "z\u00fcr\u00b7nend", "schalt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PIAT", "NN", "$,", "KON", "ADJD", "VVPP", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihn Mendelssohn vergebens; er ging und lehrt' und sprach,", "tokens": ["Ihn", "Men\u00b7dels\u00b7sohn", "ver\u00b7ge\u00b7bens", ";", "er", "ging", "und", "lehrt'", "und", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "$.", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bis \u00fcber ihn aufs neue das Ungewitter brach.", "tokens": ["Bis", "\u00fc\u00b7ber", "ihn", "aufs", "neu\u00b7e", "das", "Un\u00b7ge\u00b7wit\u00b7ter", "brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "PPER", "APPRART", "ADJA", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.91": {"line.1": {"text": "Die \u00c4ltesten des Volkes entr\u00fcstet, luden ihn", "tokens": ["Die", "\u00c4l\u00b7tes\u00b7ten", "des", "Vol\u00b7kes", "ent\u00b7r\u00fcs\u00b7tet", ",", "lu\u00b7den", "ihn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VVPP", "$,", "VVFIN", "PPER"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Vor ihre Schranken: \u00bbRede, was machst du in Berlin?\u00ab \u2013", "tokens": ["Vor", "ih\u00b7re", "Schran\u00b7ken", ":", "\u00bb", "Re\u00b7de", ",", "was", "machst", "du", "in", "Ber\u00b7lin", "?", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "$(", "NN", "$,", "PWS", "VVFIN", "PPER", "APPR", "NE", "$.", "$(", "$("], "meter": "-+-+-+--+-+++", "measure": "iambic.septa.relaxed"}, "line.3": {"text": "\u00bbich forsch in dem Gesetze, dar\u00fcber sprech ich auch", "tokens": ["\u00bb", "ich", "forsch", "in", "dem", "Ge\u00b7set\u00b7ze", ",", "da\u00b7r\u00fc\u00b7ber", "sprech", "ich", "auch"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADJD", "APPR", "ART", "NN", "$,", "PAV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Mit andern Schriftgelehrten nach hergebrachtem Brauch.\u00ab \u2013", "tokens": ["Mit", "an\u00b7dern", "Schrift\u00b7ge\u00b7lehr\u00b7ten", "nach", "her\u00b7ge\u00b7brach\u00b7tem", "Brauch", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.92": {"line.1": {"text": "\u00bbdu stehst in keinem Dienste? hast kein Gewerbe?\u00ab \u2013 \u00bbNein!", "tokens": ["\u00bb", "du", "stehst", "in", "kei\u00b7nem", "Diens\u00b7te", "?", "hast", "kein", "Ge\u00b7wer\u00b7be", "?", "\u00ab", "\u2013", "\u00bb", "Nein", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "VAFIN", "PIAT", "NN", "$.", "$(", "$(", "$(", "PTKANT", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ich kann und will nicht handeln, und mag nicht dienstbar sein.\u00ab \u2013", "tokens": ["Ich", "kann", "und", "will", "nicht", "han\u00b7deln", ",", "und", "mag", "nicht", "dienst\u00b7bar", "sein", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPER", "VMFIN", "KON", "VMFIN", "PTKNEG", "VVINF", "$,", "KON", "VMFIN", "PTKNEG", "ADJD", "VAINF", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u00bbund wir, nach hies'ger Ordnung, verbieten diese Stadt", "tokens": ["\u00bb", "und", "wir", ",", "nach", "hies'\u00b7ger", "Ord\u00b7nung", ",", "ver\u00b7bie\u00b7ten", "die\u00b7se", "Stadt"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "KON", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "VVFIN", "PDAT", "NN"], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dem \u00e4rgerlichen Neurer, der hier gel\u00e4stert hat.\u00ab", "tokens": ["Dem", "\u00e4r\u00b7ger\u00b7li\u00b7chen", "Neu\u00b7rer", ",", "der", "hier", "ge\u00b7l\u00e4s\u00b7tert", "hat", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "VVPP", "VAFIN", "$.", "$("], "meter": "-+-+-+-++-+-+", "measure": "unknown.measure.septa"}}, "stanza.93": {"line.1": {"text": "Darauf erhob sich Abba und sprach: \u00bbHartherzigkeit,", "tokens": ["Da\u00b7rauf", "er\u00b7hob", "sich", "Ab\u00b7ba", "und", "sprach", ":", "\u00bb", "Har\u00b7ther\u00b7zig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "NE", "KON", "VVFIN", "$.", "$(", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Du bist zur Ordnung worden, du herrschest hier zur Zeit!", "tokens": ["Du", "bist", "zur", "Ord\u00b7nung", "wor\u00b7den", ",", "du", "herr\u00b7schest", "hier", "zur", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "VAPP", "$,", "PPER", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und kennt ihr den Propheten Jeremia denn nicht,", "tokens": ["Und", "kennt", "ihr", "den", "Pro\u00b7phe\u00b7ten", "Je\u00b7re\u00b7mia", "denn", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "NE", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der so aus meinem Munde zu euch, ihr Starren, spricht:", "tokens": ["Der", "so", "aus", "mei\u00b7nem", "Mun\u00b7de", "zu", "euch", ",", "ihr", "Star\u00b7ren", ",", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "APPR", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.94": {"line.1": {"text": "\u203adie Missetat der Tochter von Sion, unerh\u00f6rt!", "tokens": ["\u203a", "die", "Mis\u00b7se\u00b7tat", "der", "Toch\u00b7ter", "von", "Si\u00b7on", ",", "un\u00b7er\u00b7h\u00f6rt", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ART", "NN", "ART", "NN", "APPR", "NE", "$,", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Verdunkelt Sodoms S\u00fcnde, die doch mein Grimm zerst\u00f6rt.\u2039", "tokens": ["Ver\u00b7dun\u00b7kelt", "So\u00b7doms", "S\u00fcn\u00b7de", ",", "die", "doch", "mein", "Grimm", "zer\u00b7st\u00f6rt", ".", "\u2039"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "NN", "$,", "PRELS", "ADV", "PPOSAT", "NE", "VVPP", "$.", "$("], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Die Schrift und die Propheten, die les ich Tag und Nacht,", "tokens": ["Die", "Schrift", "und", "die", "Pro\u00b7phe\u00b7ten", ",", "die", "les", "ich", "Tag", "und", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PRELS", "PIS", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und hab auch andre Worte zu eigen mir gemacht!", "tokens": ["Und", "hab", "auch", "and\u00b7re", "Wor\u00b7te", "zu", "ei\u00b7gen", "mir", "ge\u00b7macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJA", "NN", "PTKA", "ADJD", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.95": {"line.1": {"text": "\u203adu sollst dich nicht entsetzen, und sollst, du Menschenkind,", "tokens": ["\u203a", "du", "sollst", "dich", "nicht", "ent\u00b7set\u00b7zen", ",", "und", "sollst", ",", "du", "Men\u00b7schen\u00b7kind", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,", "KON", "VMFIN", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Vor ihnen dich nicht f\u00fcrchten, die mir abtr\u00fcnnig sind;", "tokens": ["Vor", "ih\u00b7nen", "dich", "nicht", "f\u00fcrch\u00b7ten", ",", "die", "mir", "ab\u00b7tr\u00fcn\u00b7nig", "sind", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PRF", "PTKNEG", "VVINF", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.3": {"text": "Du wohnst bei scharfen Dornen und Skorpionen dort,", "tokens": ["Du", "wohnst", "bei", "schar\u00b7fen", "Dor\u00b7nen", "und", "Skor\u00b7pi\u00b7o\u00b7nen", "dort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch sollst du dich nicht f\u00fcrchten, verk\u00fcndest du mein Wort.\u2039\u00ab", "tokens": ["Doch", "sollst", "du", "dich", "nicht", "f\u00fcrch\u00b7ten", ",", "ver\u00b7k\u00fcn\u00b7dest", "du", "mein", "Wort", ".", "\u2039", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.96": {"line.1": {"text": "Sie holten ihn am Abend wohl mit der Polizei,", "tokens": ["Sie", "hol\u00b7ten", "ihn", "am", "A\u00b7bend", "wohl", "mit", "der", "Po\u00b7li\u00b7zei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPRART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ihn auf die Post zu bringen, er rief den Freund herbei,", "tokens": ["Ihn", "auf", "die", "Post", "zu", "brin\u00b7gen", ",", "er", "rief", "den", "Freund", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der schafft' ihm einen Dienstschein, geschirmet war er so", "tokens": ["Der", "schafft'", "ihm", "ei\u00b7nen", "Dienst\u00b7schein", ",", "ge\u00b7schir\u00b7met", "war", "er", "so"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "$,", "VVPP", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vor seinen Widersachern, sie waren des nicht froh.", "tokens": ["Vor", "sei\u00b7nen", "Wi\u00b7der\u00b7sa\u00b7chern", ",", "sie", "wa\u00b7ren", "des", "nicht", "froh", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPER", "VAFIN", "ART", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.97": {"line.1": {"text": "Und eine Rechnung reichten zur Zahlung sie ihm dar,", "tokens": ["Und", "ei\u00b7ne", "Rech\u00b7nung", "reich\u00b7ten", "zur", "Zah\u00b7lung", "sie", "ihm", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "APPRART", "NN", "PPER", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wo Postgeld nebst der B\u00fctteln Geb\u00fchr verzeichnet war;", "tokens": ["Wo", "Post\u00b7geld", "nebst", "der", "B\u00fct\u00b7teln", "Ge\u00b7b\u00fchr", "ver\u00b7zeich\u00b7net", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er aber sprach und lachte: \u00bbGeduldet euch, ihr Herrn,", "tokens": ["Er", "a\u00b7ber", "sprach", "und", "lach\u00b7te", ":", "\u00bb", "Ge\u00b7dul\u00b7det", "euch", ",", "ihr", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "KON", "VVFIN", "$.", "$(", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Hier pa\u00dft wohl ein Geschichtchen, und ich erz\u00e4hl es gern:", "tokens": ["Hier", "pa\u00dft", "wohl", "ein", "Ge\u00b7schicht\u00b7chen", ",", "und", "ich", "er\u00b7z\u00e4hl", "es", "gern", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.98": {"line.1": {"text": "Den Unsern wird zu Lemberg ein kummervolles Los,", "tokens": ["Den", "Un\u00b7sern", "wird", "zu", "Lem\u00b7berg", "ein", "kum\u00b7mer\u00b7vol\u00b7les", "Los", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NE", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die jungen Herrn, die Sch\u00fcler sind ganz erbarmungslos,", "tokens": ["Die", "jun\u00b7gen", "Herrn", ",", "die", "Sch\u00fc\u00b7ler", "sind", "ganz", "er\u00b7bar\u00b7mungs\u00b7los", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den armen Unterdr\u00fcckten mi\u00dfhandeln sie und schm\u00e4hn,", "tokens": ["Den", "ar\u00b7men", "Un\u00b7ter\u00b7dr\u00fcck\u00b7ten", "mi\u00df\u00b7han\u00b7deln", "sie", "und", "schm\u00e4hn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und werfen ihn mit Steinen, wo immer sie ihn sehn.", "tokens": ["Und", "wer\u00b7fen", "ihn", "mit", "Stei\u00b7nen", ",", "wo", "im\u00b7mer", "sie", "ihn", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$,", "PWAV", "ADV", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.99": {"line.1": {"text": "Als einer, den sie schlugen, nah am Verscheiden war,", "tokens": ["Als", "ei\u00b7ner", ",", "den", "sie", "schlu\u00b7gen", ",", "nah", "am", "Ver\u00b7schei\u00b7den", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADJD", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Verma\u00df sich die Gemeinde, bedr\u00e4ngt von der Gefahr,", "tokens": ["Ver\u00b7ma\u00df", "sich", "die", "Ge\u00b7mein\u00b7de", ",", "be\u00b7dr\u00e4ngt", "von", "der", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den Jesuiten Obern zu klagen ihre Not;", "tokens": ["Den", "Je\u00b7su\u00b7i\u00b7ten", "O\u00b7bern", "zu", "kla\u00b7gen", "ih\u00b7re", "Not", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die haben unparteiisch erlassen ein Verbot:", "tokens": ["Die", "ha\u00b7ben", "un\u00b7par\u00b7tei\u00b7isch", "er\u00b7las\u00b7sen", "ein", "Ver\u00b7bot", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.100": {"line.1": {"text": "Es d\u00fcrfen nicht die Sch\u00fcler aus eitlem Zeitvertreib", "tokens": ["Es", "d\u00fcr\u00b7fen", "nicht", "die", "Sch\u00fc\u00b7ler", "aus", "eit\u00b7lem", "Zeit\u00b7ver\u00b7treib"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Juden so mi\u00dfhandeln, da\u00df sie an ihrem Leib", "tokens": ["Die", "Ju\u00b7den", "so", "mi\u00df\u00b7han\u00b7deln", ",", "da\u00df", "sie", "an", "ih\u00b7rem", "Leib"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF", "$,", "KOUS", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+--+---+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Besch\u00e4digt werden m\u00f6chten; es wird auch untersagt,", "tokens": ["Be\u00b7sch\u00e4\u00b7digt", "wer\u00b7den", "m\u00f6ch\u00b7ten", ";", "es", "wird", "auch", "un\u00b7ter\u00b7sagt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAINF", "VMFIN", "$.", "PPER", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Blutr\u00fcnstig sie zu schlagen, wie eben wird geklagt.", "tokens": ["Blut\u00b7r\u00fcns\u00b7tig", "sie", "zu", "schla\u00b7gen", ",", "wie", "e\u00b7ben", "wird", "ge\u00b7klagt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "PTKZU", "VVINF", "$,", "PWAV", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.101": {"line.1": {"text": "Ein arglos Schimpfen, Werfen, ein Sto\u00df und solcherlei,", "tokens": ["Ein", "arg\u00b7los", "Schimp\u00b7fen", ",", "Wer\u00b7fen", ",", "ein", "Sto\u00df", "und", "sol\u00b7cher\u00b7lei", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "NN", "$,", "ART", "NN", "KON", "PIAT", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Das m\u00fcssen sie erdulden und steht den Sch\u00fclern frei,", "tokens": ["Das", "m\u00fcs\u00b7sen", "sie", "er\u00b7dul\u00b7den", "und", "steht", "den", "Sch\u00fc\u00b7lern", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Weil mancher unter diesen ist guter Eltern Kind,", "tokens": ["Weil", "man\u00b7cher", "un\u00b7ter", "die\u00b7sen", "ist", "gu\u00b7ter", "El\u00b7tern", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PDS", "VAFIN", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und Juden doch am Ende nur eben Juden sind.", "tokens": ["Und", "Ju\u00b7den", "doch", "am", "En\u00b7de", "nur", "e\u00b7ben", "Ju\u00b7den", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "APPRART", "NN", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.102": {"line.1": {"text": "Ein Jud in diesen Tagen, der her die Stra\u00dfe kam,", "tokens": ["Ein", "Jud", "in", "die\u00b7sen", "Ta\u00b7gen", ",", "der", "her", "die", "Stra\u00b7\u00dfe", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bemerkte, da\u00df ein Sch\u00fcler ihn recht zum Ziele nahm,", "tokens": ["Be\u00b7merk\u00b7te", ",", "da\u00df", "ein", "Sch\u00fc\u00b7ler", "ihn", "recht", "zum", "Zie\u00b7le", "nahm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er b\u00fcckte sich bei Zeiten, und wich dem Stein noch aus,", "tokens": ["Er", "b\u00fcck\u00b7te", "sich", "bei", "Zei\u00b7ten", ",", "und", "wich", "dem", "Stein", "noch", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "NN", "$,", "KON", "VVFIN", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der klirrend flog ins Fenster dem n\u00e4chsten B\u00fcrgerhaus.", "tokens": ["Der", "klir\u00b7rend", "flog", "ins", "Fens\u00b7ter", "dem", "n\u00e4chs\u00b7ten", "B\u00fcr\u00b7ger\u00b7haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.103": {"line.1": {"text": "Die Scheibe war zerbrochen; der B\u00fcrger s\u00e4umte nicht,", "tokens": ["Die", "Schei\u00b7be", "war", "zer\u00b7bro\u00b7chen", ";", "der", "B\u00fcr\u00b7ger", "s\u00e4um\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und zog, Ersatz zu fodern, den Juden vor Gericht:", "tokens": ["Und", "zog", ",", "Er\u00b7satz", "zu", "fo\u00b7dern", ",", "den", "Ju\u00b7den", "vor", "Ge\u00b7richt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NN", "PTKZU", "VVINF", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "\u203adenn h\u00e4ttest du gestanden dem Wurf, wie sich's geb\u00fchrt,", "tokens": ["\u203a", "denn", "h\u00e4t\u00b7test", "du", "ge\u00b7stan\u00b7den", "dem", "Wurf", ",", "wie", "sich's", "ge\u00b7b\u00fchrt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "PPER", "VVPP", "ART", "NN", "$,", "PWAV", "PIS", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "So wurde von dem Steine mein Fenster nicht ber\u00fchrt.\u2039", "tokens": ["So", "wur\u00b7de", "von", "dem", "Stei\u00b7ne", "mein", "Fens\u00b7ter", "nicht", "be\u00b7r\u00fchrt", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "PTKNEG", "VVPP", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.104": {"line.1": {"text": "\u203aihr habt den Stein geworfen, ich habe mich geb\u00fcckt,", "tokens": ["\u203a", "ihr", "habt", "den", "Stein", "ge\u00b7wor\u00b7fen", ",", "ich", "ha\u00b7be", "mich", "ge\u00b7b\u00fcckt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "VVPP", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "So hat der Wurf die Scheibe des Nachbars nur zerst\u00fcckt;", "tokens": ["So", "hat", "der", "Wurf", "die", "Schei\u00b7be", "des", "Nach\u00b7bars", "nur", "zer\u00b7st\u00fcckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ich soll die Scheibe zahlen, das Recht, das eure, spricht's,", "tokens": ["Ich", "soll", "die", "Schei\u00b7be", "zah\u00b7len", ",", "das", "Recht", ",", "das", "eu\u00b7re", ",", "spricht's", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "VVINF", "$,", "ART", "NN", "$,", "PRELS", "PPOSAT", "$,", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Doch hat das Recht verloren, denn, seht! ich habe nichts.\u2039\u00ab", "tokens": ["Doch", "hat", "das", "Recht", "ver\u00b7lo\u00b7ren", ",", "denn", ",", "seht", "!", "ich", "ha\u00b7be", "nichts", ".", "\u2039", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "VVPP", "$,", "KON", "$,", "VVFIN", "$.", "PPER", "VAFIN", "PIS", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.105": {"line.1": {"text": "Als jene sich entfernet, verblieben noch die zwei", "tokens": ["Als", "je\u00b7ne", "sich", "ent\u00b7fer\u00b7net", ",", "ver\u00b7blie\u00b7ben", "noch", "die", "zwei"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PRF", "VVFIN", "$,", "VVFIN", "ADV", "ART", "CARD"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Im traulichen Gespr\u00e4che, sie dachten laut und frei;", "tokens": ["Im", "trau\u00b7li\u00b7chen", "Ge\u00b7spr\u00e4\u00b7che", ",", "sie", "dach\u00b7ten", "laut", "und", "frei", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Begegnen sich die Geister verwandt im Lichtrevier,", "tokens": ["Be\u00b7geg\u00b7nen", "sich", "die", "Geis\u00b7ter", "ver\u00b7wandt", "im", "Licht\u00b7re\u00b7vier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "NN", "VVPP", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das ist des Lebens Freude, das ist des Lebens Zier.", "tokens": ["Das", "ist", "des", "Le\u00b7bens", "Freu\u00b7de", ",", "das", "ist", "des", "Le\u00b7bens", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.106": {"line.1": {"text": "Und Abba zu dem Freunde: \u00bbBin friedlich ja gesinnt,", "tokens": ["Und", "Ab\u00b7ba", "zu", "dem", "Freun\u00b7de", ":", "\u00bb", "Bin", "fried\u00b7lich", "ja", "ge\u00b7sinnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "ART", "NN", "$.", "$(", "VAFIN", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Du siehst, da\u00df aller Orten sich Hader um mich spinnt;", "tokens": ["Du", "siehst", ",", "da\u00df", "al\u00b7ler", "Or\u00b7ten", "sich", "Ha\u00b7der", "um", "mich", "spinnt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIAT", "NN", "PRF", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Frei mu\u00df ich denken, sprechen und atmen Gottes Luft,", "tokens": ["Frei", "mu\u00df", "ich", "den\u00b7ken", ",", "spre\u00b7chen", "und", "at\u00b7men", "Got\u00b7tes", "Luft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "VVINF", "$,", "VVFIN", "KON", "ADJA", "NN", "NN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und wer die drei mir raubet, der legt mich in die Gruft.", "tokens": ["Und", "wer", "die", "drei", "mir", "rau\u00b7bet", ",", "der", "legt", "mich", "in", "die", "Gruft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "CARD", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.107": {"line.1": {"text": "Von hinnen will ich ziehen, den Wanderstab zur Hand", "tokens": ["Von", "hin\u00b7nen", "will", "ich", "zie\u00b7hen", ",", "den", "Wan\u00b7der\u00b7stab", "zur", "Hand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VMFIN", "PPER", "VVINF", "$,", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Land der Freiheit suchen, nach Holland, Engelland;", "tokens": ["Ein", "Land", "der", "Frei\u00b7heit", "su\u00b7chen", ",", "nach", "Hol\u00b7land", ",", "En\u00b7gel\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$,", "APPR", "NE", "$,", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Druck hat hier den Juden Bedr\u00fcckung auch gelehrt,", "tokens": ["Der", "Druck", "hat", "hier", "den", "Ju\u00b7den", "Be\u00b7dr\u00fc\u00b7ckung", "auch", "ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wohl wird er Duldung \u00fcben, wo Duldung er erf\u00e4hrt.\u00ab", "tokens": ["Wohl", "wird", "er", "Dul\u00b7dung", "\u00fc\u00b7ben", ",", "wo", "Dul\u00b7dung", "er", "er\u00b7f\u00e4hrt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "VVINF", "$,", "PWAV", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.108": {"line.1": {"text": "Und Mendelssohn dagegen und sch\u00fcttelte das Haupt:", "tokens": ["Und", "Men\u00b7dels\u00b7sohn", "da\u00b7ge\u00b7gen", "und", "sch\u00fct\u00b7tel\u00b7te", "das", "Haupt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PAV", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbdu liebewerter Schw\u00e4rmer, der noch an Duldung glaubt,", "tokens": ["\u00bb", "du", "lie\u00b7be\u00b7wer\u00b7ter", "Schw\u00e4r\u00b7mer", ",", "der", "noch", "an", "Dul\u00b7dung", "glaubt", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zeuch hin, dich blo\u00df zu geben auch dort der Eulenbrut!", "tokens": ["Zeuch", "hin", ",", "dich", "blo\u00df", "zu", "ge\u00b7ben", "auch", "dort", "der", "Eu\u00b7len\u00b7brut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "PPER", "ADV", "PTKZU", "VVINF", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Dein zugewognes Gl\u00fccksteil, das ist dein froher Mut.\u00ab \u2013", "tokens": ["Dein", "zu\u00b7ge\u00b7wog\u00b7nes", "Gl\u00fccks\u00b7teil", ",", "das", "ist", "dein", "fro\u00b7her", "Mut", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.109": {"line.1": {"text": "\u00bbmein zugewognes Gl\u00fccksteil, das ist die Liebe mein", "tokens": ["\u00bb", "mein", "zu\u00b7ge\u00b7wog\u00b7nes", "Gl\u00fccks\u00b7teil", ",", "das", "ist", "die", "Lie\u00b7be", "mein"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPOSAT", "ADJA", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "PPOSAT"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Zu meinem Volk; mein Glaube, zu bessern m\u00fcss' es sein;", "tokens": ["Zu", "mei\u00b7nem", "Volk", ";", "mein", "Glau\u00b7be", ",", "zu", "bes\u00b7sern", "m\u00fcss'", "es", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPOSAT", "NN", "$,", "PTKZU", "VVINF", "VMFIN", "PPER", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Mein Hoffen, mitzuwirken dazu mit Gut und Blut;", "tokens": ["Mein", "Hof\u00b7fen", ",", "mit\u00b7zu\u00b7wir\u00b7ken", "da\u00b7zu", "mit", "Gut", "und", "Blut", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PAV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Du nennst die drei zusammen, das ist mein froher Mut.\u00ab", "tokens": ["Du", "nennst", "die", "drei", "zu\u00b7sam\u00b7men", ",", "das", "ist", "mein", "fro\u00b7her", "Mut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "CARD", "PTKVZ", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.110": {"line.1": {"text": "Und frohen Mutes nahm er den Wanderstab zur Hand,", "tokens": ["Und", "fro\u00b7hen", "Mu\u00b7tes", "nahm", "er", "den", "Wan\u00b7der\u00b7stab", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und zog wohl in die Fremde, nach Holland, Engelland;", "tokens": ["Und", "zog", "wohl", "in", "die", "Frem\u00b7de", ",", "nach", "Hol\u00b7land", ",", "En\u00b7gel\u00b7land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,", "APPR", "NE", "$,", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Den blut'gen Welterobrer verfolgt die Sage nur,", "tokens": ["Den", "blut'\u00b7gen", "Wel\u00b7te\u00b7ro\u00b7brer", "ver\u00b7folgt", "die", "Sa\u00b7ge", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Vom Menschenfreund und Bettler verlieret sich die Spur.", "tokens": ["Vom", "Men\u00b7schen\u00b7freund", "und", "Bett\u00b7ler", "ver\u00b7lie\u00b7ret", "sich", "die", "Spur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.111": {"line.1": {"text": "Zur\u00fcck nach manchen Jahren gleich frohen Mutes kam", "tokens": ["Zu\u00b7r\u00fcck", "nach", "man\u00b7chen", "Jah\u00b7ren", "gleich", "fro\u00b7hen", "Mu\u00b7tes", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PIAT", "NN", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Er nach Berlin gewandert; sein rechter Arm war lahm;", "tokens": ["Er", "nach", "Ber\u00b7lin", "ge\u00b7wan\u00b7dert", ";", "sein", "rech\u00b7ter", "Arm", "war", "lahm", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NE", "VVPP", "$.", "PPOSAT", "ADJA", "NN", "VAFIN", "PTKVZ", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Und blind sein andres Auge, vernarbt sein Angesicht,", "tokens": ["Und", "blind", "sein", "and\u00b7res", "Au\u00b7ge", ",", "ver\u00b7narbt", "sein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein Herz allein, das alte, ver\u00e4ndert war es nicht.", "tokens": ["Sein", "Herz", "al\u00b7lein", ",", "das", "al\u00b7te", ",", "ver\u00b7\u00e4n\u00b7dert", "war", "es", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "$,", "ART", "ADJA", "$,", "VVPP", "VAFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.112": {"line.1": {"text": "So trat er freundlich l\u00e4chelnd vor Moses Mendelssohn:", "tokens": ["So", "trat", "er", "freund\u00b7lich", "l\u00e4\u00b7chelnd", "vor", "Mo\u00b7ses", "Men\u00b7dels\u00b7sohn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ADJD", "APPR", "NE", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "\u00bbwie dort es mir ergangen, du Kluger, siehst es schon;", "tokens": ["\u00bb", "wie", "dort", "es", "mir", "er\u00b7gan\u00b7gen", ",", "du", "Klu\u00b7ger", ",", "siehst", "es", "schon", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "ADV", "PPER", "PPER", "VVPP", "$,", "PPER", "NN", "$,", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sie haben mich geschm\u00e4het, mi\u00dfhandelt und verbannt,", "tokens": ["Sie", "ha\u00b7ben", "mich", "ge\u00b7schm\u00e4\u00b7het", ",", "mi\u00df\u00b7han\u00b7delt", "und", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "War ihnen Macht gegeben, sie h\u00e4tten mich verbrannt.\u00ab", "tokens": ["War", "ih\u00b7nen", "Macht", "ge\u00b7ge\u00b7ben", ",", "sie", "h\u00e4t\u00b7ten", "mich", "ver\u00b7brannt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "NN", "VVPP", "$,", "PPER", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+-+----+-+-+", "measure": "unknown.measure.penta"}}, "stanza.113": {"line.1": {"text": "Und wieder frohen Mutes, da ihn Berlin verstie\u00df,", "tokens": ["Und", "wie\u00b7der", "fro\u00b7hen", "Mu\u00b7tes", ",", "da", "ihn", "Ber\u00b7lin", "ver\u00b7stie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "$,", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Zog er nach seiner Heimat, die Ha\u00df ihm nur verhie\u00df,", "tokens": ["Zog", "er", "nach", "sei\u00b7ner", "Hei\u00b7mat", ",", "die", "Ha\u00df", "ihm", "nur", "ver\u00b7hie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da wallt' er r\u00fcst'gen Schrittes, ein Fremder, fort und fort,", "tokens": ["Da", "wallt'", "er", "r\u00fcst'\u00b7gen", "Schrit\u00b7tes", ",", "ein", "Frem\u00b7der", ",", "fort", "und", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,", "ART", "NN", "$,", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Versto\u00dfen, fluchbeladen, unst\u00e4t von Ort zu Ort.", "tokens": ["Ver\u00b7sto\u00b7\u00dfen", ",", "fluch\u00b7be\u00b7la\u00b7den", ",", "un\u00b7st\u00e4t", "von", "Ort", "zu", "Ort", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "ADJD", "APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.114": {"line.1": {"text": "Einst sucht' er wohl vergebens seit manchem Tag vielleicht,", "tokens": ["Einst", "sucht'", "er", "wohl", "ver\u00b7ge\u00b7bens", "seit", "man\u00b7chem", "Tag", "viel\u00b7leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "APPR", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wer ihm von seinem Brote das d\u00fcrft'ge St\u00fcck gereicht;", "tokens": ["Wer", "ihm", "von", "sei\u00b7nem", "Bro\u00b7te", "das", "d\u00fcrft'\u00b7ge", "St\u00fcck", "ge\u00b7reicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Der Scho\u00df der Mutter Erde empfing zur letzten Ruh", "tokens": ["Der", "Scho\u00df", "der", "Mut\u00b7ter", "Er\u00b7de", "emp\u00b7fing", "zur", "letz\u00b7ten", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "NN", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Sein graues Haupt, ihm fielen die m\u00fcden Augen zu.", "tokens": ["Sein", "grau\u00b7es", "Haupt", ",", "ihm", "fie\u00b7len", "die", "m\u00fc\u00b7den", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}}}}