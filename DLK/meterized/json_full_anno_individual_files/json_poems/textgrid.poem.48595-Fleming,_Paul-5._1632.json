{"textgrid.poem.48595": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "5. 1632", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als einsmals Krieg und Tod", "tokens": ["Als", "eins\u00b7mals", "Krieg", "und", "Tod"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "und f\u00fcr der gro\u00dfen Not", "tokens": ["und", "f\u00fcr", "der", "gro\u00b7\u00dfen", "Not"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die Schwestern zitternd flossen,", "tokens": ["die", "Schwes\u00b7tern", "zit\u00b7ternd", "flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "auch nun der Hirten Schaar", "tokens": ["auch", "nun", "der", "Hir\u00b7ten", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "fast ganz von dannen war", "tokens": ["fast", "ganz", "von", "dan\u00b7nen", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADV", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "aus Furchte der Gefahr:", "tokens": ["aus", "Furch\u00b7te", "der", "Ge\u00b7fahr", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "da sprach der ", "tokens": ["da", "sprach", "der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "\u00bbsind wir noch um den Flu\u00df,", "tokens": ["\u00bb", "sind", "wir", "noch", "um", "den", "Flu\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "den Hirt- und Heerden scheuen?", "tokens": ["den", "Hir\u00b7t", "und", "Heer\u00b7den", "scheu\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Freund, h\u00f6re doch mein Wort:", "tokens": ["Freund", ",", "h\u00f6\u00b7re", "doch", "mein", "Wort", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "la\u00df uns auch machen fort", "tokens": ["la\u00df", "uns", "auch", "ma\u00b7chen", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "PTKVZ"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.7": {"text": "an einen sichern Ort!\u00ab", "tokens": ["an", "ei\u00b7nen", "si\u00b7chern", "Ort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Wer gl\u00e4ubts, wie ", "tokens": ["Wer", "gl\u00e4ubts", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "sich \u00fcber dem betr\u00fcbte?", "tokens": ["sich", "\u00fc\u00b7ber", "dem", "be\u00b7tr\u00fcb\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbzieht\u00ab, sprach er, \u00bbihr darvon,", "tokens": ["\u00bb", "zieht", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "ihr", "dar\u00b7von", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die ich so innig liebte,", "tokens": ["die", "ich", "so", "in\u00b7nig", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "so mu\u00df ich trostlos hin", "tokens": ["so", "mu\u00df", "ich", "trost\u00b7los", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "zu meinem Tode ziehn,", "tokens": ["zu", "mei\u00b7nem", "To\u00b7de", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "eh' als ich unpa\u00df bin.", "tokens": ["eh'", "als", "ich", "un\u00b7pa\u00df", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Tut di\u00df, soll ja Eins sein:", "tokens": ["Tut", "di\u00df", ",", "soll", "ja", "Eins", "sein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "$,", "VMFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "la\u00dft mir alhier die Heerden,", "tokens": ["la\u00dft", "mir", "al\u00b7hier", "die", "Heer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "setzt sie zu Pf\u00e4nden ein,", "tokens": ["setzt", "sie", "zu", "Pf\u00e4n\u00b7den", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "da\u00df wir uns wieder werden!", "tokens": ["da\u00df", "wir", "uns", "wie\u00b7der", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was mein Verh\u00e4ngn\u00fc\u00df hier,", "tokens": ["Was", "mein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "wart' ich bei der Revier", "tokens": ["wart'", "ich", "bei", "der", "Re\u00b7vier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "und euer Gut mit mir.\u00ab", "tokens": ["und", "eu\u00b7er", "Gut", "mit", "mir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbmit Willen\u00ab! sprachen sie.", "tokens": ["\u00bb", "mit", "Wil\u00b7len", "\u00ab", "!", "spra\u00b7chen", "sie", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$(", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbwirstu uns nur erhalten,", "tokens": ["\u00bb", "wirs\u00b7tu", "uns", "nur", "er\u00b7hal\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wer achtet dieses Vieh?", "tokens": ["wer", "ach\u00b7tet", "die\u00b7ses", "Vieh", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Pan mag dar\u00fcber walten!\u00ab", "tokens": ["Pan", "mag", "da\u00b7r\u00fc\u00b7ber", "wal\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VMFIN", "PAV", "VVINF", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "So lie\u00df ihm an dem Flu\u00df", "tokens": ["So", "lie\u00df", "ihm", "an", "dem", "Flu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "ein Ieder samt dem Ku\u00df", "tokens": ["ein", "Ie\u00b7der", "samt", "dem", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ade, den letzten Gru\u00df.", "tokens": ["A\u00b7de", ",", "den", "letz\u00b7ten", "Gru\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.6": {"line.1": {"text": "Als einsmals Krieg und Tod", "tokens": ["Als", "eins\u00b7mals", "Krieg", "und", "Tod"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "die ", "tokens": ["die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "und f\u00fcr der gro\u00dfen Not", "tokens": ["und", "f\u00fcr", "der", "gro\u00b7\u00dfen", "Not"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die Schwestern zitternd flossen,", "tokens": ["die", "Schwes\u00b7tern", "zit\u00b7ternd", "flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "auch nun der Hirten Schaar", "tokens": ["auch", "nun", "der", "Hir\u00b7ten", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "fast ganz von dannen war", "tokens": ["fast", "ganz", "von", "dan\u00b7nen", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ADV", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "aus Furchte der Gefahr:", "tokens": ["aus", "Furch\u00b7te", "der", "Ge\u00b7fahr", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "da sprach der ", "tokens": ["da", "sprach", "der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "\u00bbsind wir noch um den Flu\u00df,", "tokens": ["\u00bb", "sind", "wir", "noch", "um", "den", "Flu\u00df", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "den Hirt- und Heerden scheuen?", "tokens": ["den", "Hir\u00b7t", "und", "Heer\u00b7den", "scheu\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Freund, h\u00f6re doch mein Wort:", "tokens": ["Freund", ",", "h\u00f6\u00b7re", "doch", "mein", "Wort", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "la\u00df uns auch machen fort", "tokens": ["la\u00df", "uns", "auch", "ma\u00b7chen", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "PTKVZ"], "meter": "---+-+", "measure": "unknown.measure.di"}, "line.7": {"text": "an einen sichern Ort!\u00ab", "tokens": ["an", "ei\u00b7nen", "si\u00b7chern", "Ort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Wer gl\u00e4ubts, wie ", "tokens": ["Wer", "gl\u00e4ubts", ",", "wie"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "PWAV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "sich \u00fcber dem betr\u00fcbte?", "tokens": ["sich", "\u00fc\u00b7ber", "dem", "be\u00b7tr\u00fcb\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbzieht\u00ab, sprach er, \u00bbihr darvon,", "tokens": ["\u00bb", "zieht", "\u00ab", ",", "sprach", "er", ",", "\u00bb", "ihr", "dar\u00b7von", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "PPER", "PAV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "die ich so innig liebte,", "tokens": ["die", "ich", "so", "in\u00b7nig", "lieb\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "so mu\u00df ich trostlos hin", "tokens": ["so", "mu\u00df", "ich", "trost\u00b7los", "hin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "zu meinem Tode ziehn,", "tokens": ["zu", "mei\u00b7nem", "To\u00b7de", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "eh' als ich unpa\u00df bin.", "tokens": ["eh'", "als", "ich", "un\u00b7pa\u00df", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Tut di\u00df, soll ja Eins sein:", "tokens": ["Tut", "di\u00df", ",", "soll", "ja", "Eins", "sein", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "$,", "VMFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "la\u00dft mir alhier die Heerden,", "tokens": ["la\u00dft", "mir", "al\u00b7hier", "die", "Heer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "ART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "setzt sie zu Pf\u00e4nden ein,", "tokens": ["setzt", "sie", "zu", "Pf\u00e4n\u00b7den", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "da\u00df wir uns wieder werden!", "tokens": ["da\u00df", "wir", "uns", "wie\u00b7der", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was mein Verh\u00e4ngn\u00fc\u00df hier,", "tokens": ["Was", "mein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "hier", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "wart' ich bei der Revier", "tokens": ["wart'", "ich", "bei", "der", "Re\u00b7vier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "und euer Gut mit mir.\u00ab", "tokens": ["und", "eu\u00b7er", "Gut", "mit", "mir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbmit Willen\u00ab! sprachen sie.", "tokens": ["\u00bb", "mit", "Wil\u00b7len", "\u00ab", "!", "spra\u00b7chen", "sie", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "$(", "$.", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbwirstu uns nur erhalten,", "tokens": ["\u00bb", "wirs\u00b7tu", "uns", "nur", "er\u00b7hal\u00b7ten", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wer achtet dieses Vieh?", "tokens": ["wer", "ach\u00b7tet", "die\u00b7ses", "Vieh", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Pan mag dar\u00fcber walten!\u00ab", "tokens": ["Pan", "mag", "da\u00b7r\u00fc\u00b7ber", "wal\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VMFIN", "PAV", "VVINF", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "So lie\u00df ihm an dem Flu\u00df", "tokens": ["So", "lie\u00df", "ihm", "an", "dem", "Flu\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "ein Ieder samt dem Ku\u00df", "tokens": ["ein", "Ie\u00b7der", "samt", "dem", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Ade, den letzten Gru\u00df.", "tokens": ["A\u00b7de", ",", "den", "letz\u00b7ten", "Gru\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}