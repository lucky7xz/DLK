{"dta.poem.20817": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "An den geneigten  \n Leser.", "genre": "Lyrik; Prosa; Drama", "period": "N.A.", "pub_year": "1679", "urn": "urn:nbn:de:kobv:b4-20289-1", "language": ["de:0.99"], "booktitle": "Hofmann von Hofmannswaldau, Christian: Deutsche Ubersetzungen und Gedichte. Breslau, 1679."}, "poem": {"stanza.1": {"line.1": {"text": "Swenne si stet gegen in ze Angesiht/", "tokens": ["Swen\u00b7ne", "si", "stet", "ge\u00b7gen", "in", "ze", "An\u00b7ge\u00b7siht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Und si in mit tr\u00f6gen giht/", "tokens": ["Und", "si", "in", "mit", "tr\u00f6\u00b7gen", "giht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "APPR", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Daz si in von Herze meine:", "tokens": ["Daz", "si", "in", "von", "Her\u00b7ze", "mei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "APPR", "VVFIN", "PPOSAT", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Swer disen zwein geverlih si/", "tokens": ["Swer", "di\u00b7sen", "zwein", "ge\u00b7ver\u00b7lih", "si", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.5": {"text": "Und wont mit valsher Hute bi/", "tokens": ["Und", "wont", "mit", "vals\u00b7her", "Hu\u00b7te", "bi", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der werde zeinem Steine.", "tokens": ["Der", "wer\u00b7de", "zei\u00b7nem", "Stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Indem sie gegen jhm jhr freundlich Angesicht/", "tokens": ["In\u00b7dem", "sie", "ge\u00b7gen", "jhm", "jhr", "freund\u00b7lich", "An\u00b7ge\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "PPER", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und den verliebten Glantz der Augen hat gericht/", "tokens": ["Und", "den", "ver\u00b7lieb\u00b7ten", "Glantz", "der", "Au\u00b7gen", "hat", "ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zum Zeichen/ da\u00df sie es von gantzem Hertzen meine/", "tokens": ["Zum", "Zei\u00b7chen", "/", "da\u00df", "sie", "es", "von", "gant\u00b7zem", "Hert\u00b7zen", "mei\u00b7ne", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "KOUS", "PPER", "PPER", "APPR", "ADJA", "NN", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer diesen Zwey zu wider ist/", "tokens": ["Wer", "die\u00b7sen", "Zwey", "zu", "wi\u00b7der", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "CARD", "PTKZU", "PTKVZ", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und brauchet jrgend arge List/", "tokens": ["Und", "brau\u00b7chet", "jr\u00b7gend", "ar\u00b7ge", "List", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der werde bald zu Steine.", "tokens": ["Der", "wer\u00b7de", "bald", "zu", "Stei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}