{"textgrid.poem.52896": {"metadata": {"author": {"name": "Dingelstedt, Franz von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Schlenderte eines Tags verlassen", "genre": "verse", "period": "N.A.", "pub_year": 1847, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Schlenderte eines Tags verlassen", "tokens": ["Schlen\u00b7der\u00b7te", "ei\u00b7nes", "Tags", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Umher in der Eschenheimer Gassen,", "tokens": ["Um\u00b7her", "in", "der", "E\u00b7schen\u00b7hei\u00b7mer", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und trat in einen Hof, darinnen stand", "tokens": ["Und", "trat", "in", "ei\u00b7nen", "Hof", ",", "da\u00b7rin\u00b7nen", "stand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein \u00d6sterreicher, Musket' in der Hand.", "tokens": ["Ein", "\u00d6s\u00b7ter\u00b7rei\u00b7cher", ",", "Mus\u00b7ket'", "in", "der", "Hand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Seh' mir die Treppen, H\u00f6fe, G\u00e4nge,", "tokens": ["Seh'", "mir", "die", "Trep\u00b7pen", ",", "H\u00f6\u00b7fe", ",", "G\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der best\u00e4ubten Fenster Menge", "tokens": ["Der", "be\u00b7st\u00e4ub\u00b7ten", "Fens\u00b7ter", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Recht neugierig und teilnehmend an,", "tokens": ["Recht", "neu\u00b7gie\u00b7rig", "und", "teil\u00b7neh\u00b7mend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Just wie nur ein Fremder gaffen kann.", "tokens": ["Just", "wie", "nur", "ein", "Frem\u00b7der", "gaf\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Kommt aus dem Haus mit leisen, raschen", "tokens": ["Kommt", "aus", "dem", "Haus", "mit", "lei\u00b7sen", ",", "ra\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "VVINF", "$,", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schritten ein Mann mit Akten in den Taschen,", "tokens": ["Schrit\u00b7ten", "ein", "Mann", "mit", "Ak\u00b7ten", "in", "den", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Den frag' ich mit einem Gru\u00dfe frank und frei:", "tokens": ["Den", "frag'", "ich", "mit", "ei\u00b7nem", "Gru\u00b7\u00dfe", "frank", "und", "frei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVIMP", "PPER", "APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was das f\u00fcr ein gro\u00dfes Haus hier sei?", "tokens": ["Was", "das", "f\u00fcr", "ein", "gro\u00b7\u00dfes", "Haus", "hier", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "APPR", "ART", "ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Das M\u00e4nnlein blinzt durch seine Brille", "tokens": ["Das", "M\u00e4nn\u00b7lein", "blinzt", "durch", "sei\u00b7ne", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mich an und hustet nach langer Stille:", "tokens": ["Mich", "an", "und", "hus\u00b7tet", "nach", "lan\u00b7ger", "Stil\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihnen das zu sagen, bin ich nicht kompetent;", "tokens": ["Ih\u00b7nen", "das", "zu", "sa\u00b7gen", ",", "bin", "ich", "nicht", "kom\u00b7pe\u00b7tent", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "PTKZU", "VVINF", "$,", "VAFIN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Sprach's, ging, machte sein Kompliment.", "tokens": ["Sprach's", ",", "ging", ",", "mach\u00b7te", "sein", "Kom\u00b7pli\u00b7ment", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "Nun hab' ich's gewu\u00dft, woran ich gewesen,", "tokens": ["Nun", "hab'", "ich's", "ge\u00b7wu\u00dft", ",", "wo\u00b7ran", "ich", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "$,", "PWAV", "PPER", "VAPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der \u00d6sterreicher aber, ohne viel Federlesen,", "tokens": ["Der", "\u00d6s\u00b7ter\u00b7rei\u00b7cher", "a\u00b7ber", ",", "oh\u00b7ne", "viel", "Fe\u00b7der\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kommt auf mich zu und fragt mich grob,", "tokens": ["Kommt", "auf", "mich", "zu", "und", "fragt", "mich", "grob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ich hier in dem Hause zu suchen hob?", "tokens": ["Was", "ich", "hier", "in", "dem", "Hau\u00b7se", "zu", "su\u00b7chen", "hob", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.6": {"line.1": {"text": "Gott sei Dank, hier hab' ich nichts zu suchen,", "tokens": ["Gott", "sei", "Dank", ",", "hier", "hab'", "ich", "nichts", "zu", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "ADV", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da fing der Holter an zu fluchen:", "tokens": ["Da", "fing", "der", "Hol\u00b7ter", "an", "zu", "flu\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dann gehn's Ihrer Wege als guter Christ,", "tokens": ["Dann", "gehn's", "Ih\u00b7rer", "We\u00b7ge", "als", "gu\u00b7ter", "Christ", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KOUS", "ADJA", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sehn ja, da\u00df hier nichts zu finden ist!", "tokens": ["Sehn", "ja", ",", "da\u00df", "hier", "nichts", "zu", "fin\u00b7den", "ist", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Schlenderte eines Tags verlassen", "tokens": ["Schlen\u00b7der\u00b7te", "ei\u00b7nes", "Tags", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Umher in der Eschenheimer Gassen,", "tokens": ["Um\u00b7her", "in", "der", "E\u00b7schen\u00b7hei\u00b7mer", "Gas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und trat in einen Hof, darinnen stand", "tokens": ["Und", "trat", "in", "ei\u00b7nen", "Hof", ",", "da\u00b7rin\u00b7nen", "stand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein \u00d6sterreicher, Musket' in der Hand.", "tokens": ["Ein", "\u00d6s\u00b7ter\u00b7rei\u00b7cher", ",", "Mus\u00b7ket'", "in", "der", "Hand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Seh' mir die Treppen, H\u00f6fe, G\u00e4nge,", "tokens": ["Seh'", "mir", "die", "Trep\u00b7pen", ",", "H\u00f6\u00b7fe", ",", "G\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der best\u00e4ubten Fenster Menge", "tokens": ["Der", "be\u00b7st\u00e4ub\u00b7ten", "Fens\u00b7ter", "Men\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Recht neugierig und teilnehmend an,", "tokens": ["Recht", "neu\u00b7gie\u00b7rig", "und", "teil\u00b7neh\u00b7mend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Just wie nur ein Fremder gaffen kann.", "tokens": ["Just", "wie", "nur", "ein", "Frem\u00b7der", "gaf\u00b7fen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Kommt aus dem Haus mit leisen, raschen", "tokens": ["Kommt", "aus", "dem", "Haus", "mit", "lei\u00b7sen", ",", "ra\u00b7schen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "VVINF", "$,", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schritten ein Mann mit Akten in den Taschen,", "tokens": ["Schrit\u00b7ten", "ein", "Mann", "mit", "Ak\u00b7ten", "in", "den", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Den frag' ich mit einem Gru\u00dfe frank und frei:", "tokens": ["Den", "frag'", "ich", "mit", "ei\u00b7nem", "Gru\u00b7\u00dfe", "frank", "und", "frei", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVIMP", "PPER", "APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was das f\u00fcr ein gro\u00dfes Haus hier sei?", "tokens": ["Was", "das", "f\u00fcr", "ein", "gro\u00b7\u00dfes", "Haus", "hier", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "APPR", "ART", "ADJA", "NN", "ADV", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Das M\u00e4nnlein blinzt durch seine Brille", "tokens": ["Das", "M\u00e4nn\u00b7lein", "blinzt", "durch", "sei\u00b7ne", "Bril\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mich an und hustet nach langer Stille:", "tokens": ["Mich", "an", "und", "hus\u00b7tet", "nach", "lan\u00b7ger", "Stil\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ihnen das zu sagen, bin ich nicht kompetent;", "tokens": ["Ih\u00b7nen", "das", "zu", "sa\u00b7gen", ",", "bin", "ich", "nicht", "kom\u00b7pe\u00b7tent", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PDS", "PTKZU", "VVINF", "$,", "VAFIN", "PPER", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Sprach's, ging, machte sein Kompliment.", "tokens": ["Sprach's", ",", "ging", ",", "mach\u00b7te", "sein", "Kom\u00b7pli\u00b7ment", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.11": {"line.1": {"text": "Nun hab' ich's gewu\u00dft, woran ich gewesen,", "tokens": ["Nun", "hab'", "ich's", "ge\u00b7wu\u00dft", ",", "wo\u00b7ran", "ich", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVPP", "$,", "PWAV", "PPER", "VAPP", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der \u00d6sterreicher aber, ohne viel Federlesen,", "tokens": ["Der", "\u00d6s\u00b7ter\u00b7rei\u00b7cher", "a\u00b7ber", ",", "oh\u00b7ne", "viel", "Fe\u00b7der\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Kommt auf mich zu und fragt mich grob,", "tokens": ["Kommt", "auf", "mich", "zu", "und", "fragt", "mich", "grob", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was ich hier in dem Hause zu suchen hob?", "tokens": ["Was", "ich", "hier", "in", "dem", "Hau\u00b7se", "zu", "su\u00b7chen", "hob", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}}, "stanza.12": {"line.1": {"text": "Gott sei Dank, hier hab' ich nichts zu suchen,", "tokens": ["Gott", "sei", "Dank", ",", "hier", "hab'", "ich", "nichts", "zu", "su\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "ADV", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Da fing der Holter an zu fluchen:", "tokens": ["Da", "fing", "der", "Hol\u00b7ter", "an", "zu", "flu\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dann gehn's Ihrer Wege als guter Christ,", "tokens": ["Dann", "gehn's", "Ih\u00b7rer", "We\u00b7ge", "als", "gu\u00b7ter", "Christ", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "KOUS", "ADJA", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sehn ja, da\u00df hier nichts zu finden ist!", "tokens": ["Sehn", "ja", ",", "da\u00df", "hier", "nichts", "zu", "fin\u00b7den", "ist", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KOUS", "ADV", "PIS", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}