{"dta.poem.10859": {"metadata": {"author": {"name": "Bodmer, Johann Jacob", "birth": "N.A.", "death": "N.A."}, "title": "I.   Der ruhms\u00fcchtige B\u00e4r.", "genre": "Lyrik; Prosa", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-200905198310", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ein auf den Ruhm erpichter B\u00e4r", "tokens": ["Ein", "auf", "den", "Ruhm", "er\u00b7pich\u00b7ter", "B\u00e4r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kam bey sich selbst auf die Gedancken,", "tokens": ["Kam", "bey", "sich", "selbst", "auf", "die", "Ge\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Die Nachwelt w\u00fcrd es ihm verdancken,", "tokens": ["Die", "Nach\u00b7welt", "w\u00fcrd", "es", "ihm", "ver\u00b7dan\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vern\u00e4hme sie, wie gro\u00df er einst gewesen w\u00e4r.", "tokens": ["Ver\u00b7n\u00e4h\u00b7me", "sie", ",", "wie", "gro\u00df", "er", "einst", "ge\u00b7we\u00b7sen", "w\u00e4r", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ADJD", "PPER", "ADV", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er sprach dar\u00fcber seine Jungen,", "tokens": ["Er", "sprach", "da\u00b7r\u00fc\u00b7ber", "sei\u00b7ne", "Jun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich sehe, sagt er, mich gezwungen,", "tokens": ["Ich", "se\u00b7he", ",", "sagt", "er", ",", "mich", "ge\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ich den grossen C\u00f6rper messe,", "tokens": ["Da\u00df", "ich", "den", "gros\u00b7sen", "C\u00f6r\u00b7per", "mes\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Damit ich dessen seltne Gr\u00f6sse", "tokens": ["Da\u00b7mit", "ich", "des\u00b7sen", "selt\u00b7ne", "Gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der Nachwelt so vor Augen lege,", "tokens": ["Der", "Nach\u00b7welt", "so", "vor", "Au\u00b7gen", "le\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df sie es deutlich fassen m\u00f6ge.", "tokens": ["Da\u00df", "sie", "es", "deut\u00b7lich", "fas\u00b7sen", "m\u00f6\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Jhm fielen gleich die Jungen bey", "tokens": ["Jhm", "fie\u00b7len", "gleich", "die", "Jun\u00b7gen", "bey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und schwuren: Ja, bey unsrer Treu,", "tokens": ["Und", "schwu\u00b7ren", ":", "Ja", ",", "bey", "uns\u00b7rer", "Treu", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PTKANT", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wir sahen auch schon viele B\u00e4ren;", "tokens": ["Wir", "sa\u00b7hen", "auch", "schon", "vie\u00b7le", "B\u00e4\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch, es wird noch lange w\u00e4hren,", "tokens": ["Je\u00b7doch", ",", "es", "wird", "noch", "lan\u00b7ge", "w\u00e4h\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Eh da\u00df in unserm K\u00f6nigreiche", "tokens": ["Eh", "da\u00df", "in", "un\u00b7serm", "K\u00f6\u00b7nig\u00b7rei\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Sich einer dir an Gr\u00f6sse gleiche.", "tokens": ["Sich", "ei\u00b7ner", "dir", "an", "Gr\u00f6s\u00b7se", "glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "PPER", "APPR", "NN", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Darum so sey darauf beflissen,", "tokens": ["Da\u00b7rum", "so", "sey", "da\u00b7rauf", "be\u00b7flis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df es die sp\u00e4ten Enckel wissen.", "tokens": ["Da\u00df", "es", "die", "sp\u00e4\u00b7ten", "En\u00b7ckel", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Alte dacht jetzt allgemach", "tokens": ["Der", "Al\u00b7te", "dacht", "jetzt", "all\u00b7ge\u00b7mach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem edlen Unternehmen nach,", "tokens": ["Dem", "ed\u00b7len", "Un\u00b7ter\u00b7neh\u00b7men", "nach", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und rief, als ers zuletzt erfunden,", "tokens": ["Und", "rief", ",", "als", "ers", "zu\u00b7letzt", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Indem die Kinder um ihn stuhnden:", "tokens": ["In\u00b7dem", "die", "Kin\u00b7der", "um", "ihn", "stuhn\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcrwahr es haben Kunst und Witz", "tokens": ["F\u00fcr\u00b7wahr", "es", "ha\u00b7ben", "Kunst", "und", "Witz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In meinem C\u00f6rper ihren Sitz!", "tokens": ["In", "mei\u00b7nem", "C\u00f6r\u00b7per", "ih\u00b7ren", "Sitz", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Gleich leget er sich in den Schnee,", "tokens": ["Gleich", "le\u00b7get", "er", "sich", "in", "den", "Schnee", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Er streckt die Pfoten in die H\u00f6h,", "tokens": ["Er", "streckt", "die", "Pfo\u00b7ten", "in", "die", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hei\u00dft die Kleinen auf ihn tretten;", "tokens": ["Und", "hei\u00dft", "die", "Klei\u00b7nen", "auf", "ihn", "tret\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dann sagt er: Jzo will ich wetten,", "tokens": ["Dann", "sagt", "er", ":", "Jzo", "will", "ich", "wet\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "NE", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "So sieht man Haut, so sieht man Haar,", "tokens": ["So", "sieht", "man", "Haut", ",", "so", "sieht", "man", "Haar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "$,", "ADV", "VVFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zusammt der Gr\u00f6sse sonnenklar.", "tokens": ["Zu\u00b7sammt", "der", "Gr\u00f6s\u00b7se", "son\u00b7nen\u00b7klar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kein F\u00fcrst hat noch in seinem Schild", "tokens": ["Kein", "F\u00fcrst", "hat", "noch", "in", "sei\u00b7nem", "Schild"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von einem B\u00e4r ein sch\u00f6ner Bild.", "tokens": ["Von", "ei\u00b7nem", "B\u00e4r", "ein", "sch\u00f6\u00b7ner", "Bild", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein jeder von den Jungen preist", "tokens": ["Ein", "je\u00b7der", "von", "den", "Jun\u00b7gen", "preist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des alten B\u00e4ren scharfen Geist,", "tokens": ["Des", "al\u00b7ten", "B\u00e4\u00b7ren", "schar\u00b7fen", "Geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Indem sie Bild und Gegenbild betrachten,", "tokens": ["In\u00b7dem", "sie", "Bild", "und", "Ge\u00b7gen\u00b7bild", "be\u00b7trach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und es des Urbilds w\u00fcrdig achten.", "tokens": ["Und", "es", "des", "Ur\u00b7bilds", "w\u00fcr\u00b7dig", "ach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein jeder sprach: Es ist gerathen,", "tokens": ["Ein", "je\u00b7der", "sprach", ":", "Es", "ist", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$.", "PPER", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcrwahr der Alte hats errathen.", "tokens": ["F\u00fcr\u00b7wahr", "der", "Al\u00b7te", "hats", "er\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie dachten nicht (ein B\u00e4r denckt nicht so weit,)", "tokens": ["Sie", "dach\u00b7ten", "nicht", "(", "ein", "B\u00e4r", "denckt", "nicht", "so", "weit", ",", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$(", "ART", "NN", "VVFIN", "PTKNEG", "ADV", "ADJD", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df dieses Meisterst\u00fcck trotz seiner W\u00fcrde,", "tokens": ["Da\u00df", "die\u00b7ses", "Meis\u00b7ter\u00b7st\u00fcck", "trotz", "sei\u00b7ner", "W\u00fcr\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Trotz aller seiner Aehnlichkeit,", "tokens": ["Trotz", "al\u00b7ler", "sei\u00b7ner", "A\u00b7ehn\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jm n\u00e4chsten Schnee versincken w\u00fcrde.", "tokens": ["Jm", "n\u00e4chs\u00b7ten", "Schnee", "ver\u00b7sin\u00b7cken", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es schneyte nicht sobald, als es verschwand;", "tokens": ["Es", "schney\u00b7te", "nicht", "so\u00b7bald", ",", "als", "es", "ver\u00b7schwand", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Witz, Kunst und Arbeit war vergebens angewandt.", "tokens": ["Witz", ",", "Kunst", "und", "Ar\u00b7beit", "war", "ver\u00b7ge\u00b7bens", "an\u00b7ge\u00b7wandt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}