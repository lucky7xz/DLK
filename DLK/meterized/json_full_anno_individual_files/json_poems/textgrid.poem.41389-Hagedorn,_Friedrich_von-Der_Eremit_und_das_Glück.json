{"textgrid.poem.41389": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "Der Eremit und das Gl\u00fcck", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es lebt ein Eremit, der, eitlem Zwange feind,", "tokens": ["Es", "lebt", "ein", "E\u00b7re\u00b7mit", ",", "der", ",", "eit\u00b7lem", "Zwan\u00b7ge", "feind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "$,", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kunst der schlauen Wollust lernet,", "tokens": ["Die", "Kunst", "der", "schlau\u00b7en", "Wol\u00b7lust", "ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die keine M\u00fche kennt, vom Ekel weit entfernet,", "tokens": ["Die", "kei\u00b7ne", "M\u00fc\u00b7he", "kennt", ",", "vom", "E\u00b7kel", "weit", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "APPRART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach dem Genusse sch\u00f6ner scheint.", "tokens": ["Nach", "dem", "Ge\u00b7nus\u00b7se", "sch\u00f6\u00b7ner", "scheint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Verzeiht es mir, erhabne Musens\u00f6hne,", "tokens": ["Ver\u00b7zeiht", "es", "mir", ",", "er\u00b7hab\u00b7ne", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr die schon unsre Pflicht den Lorbeerkranz bestellt,", "tokens": ["F\u00fcr", "die", "schon", "uns\u00b7re", "Pflicht", "den", "Lor\u00b7beer\u00b7kranz", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PPOSAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Held ist kein gelehrter Held;", "tokens": ["Mein", "Held", "ist", "kein", "ge\u00b7lehr\u00b7ter", "Held", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und er besa\u00df auf dieser Welt", "tokens": ["Und", "er", "be\u00b7sa\u00df", "auf", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nichts, als ein Buch, ein Glas, und eine Sch\u00f6ne.", "tokens": ["Nichts", ",", "als", "ein", "Buch", ",", "ein", "Glas", ",", "und", "ei\u00b7ne", "Sch\u00f6\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch diese drei, ihn zu erfreun,", "tokens": ["Doch", "die\u00b7se", "drei", ",", "ihn", "zu", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "CARD", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sind, wie man sagt, nur selten ungelesen,", "tokens": ["Sind", ",", "wie", "man", "sagt", ",", "nur", "sel\u00b7ten", "un\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Unangef\u00fcllt, und ungek\u00fc\u00dft gewesen.", "tokens": ["Un\u00b7an\u00b7ge\u00b7f\u00fcllt", ",", "und", "un\u00b7ge\u00b7k\u00fc\u00dft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Er lebet. Wie gar viel schlie\u00dft dieses Wort nicht ein!", "tokens": ["Er", "le\u00b7bet", ".", "Wie", "gar", "viel", "schlie\u00dft", "die\u00b7ses", "Wort", "nicht", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWAV", "ADV", "ADV", "VVFIN", "PDAT", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihr Weisen, saget mir, hei\u00dft leben mehr, als sein?", "tokens": ["Ihr", "Wei\u00b7sen", ",", "sa\u00b7get", "mir", ",", "hei\u00dft", "le\u00b7ben", "mehr", ",", "als", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "VVFIN", "ADV", "$,", "KOUS", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ihn h\u00e4lt ein Schieferdach vor Neid und Hohn verstecket.", "tokens": ["Ihn", "h\u00e4lt", "ein", "Schie\u00b7fer\u00b7dach", "vor", "Neid", "und", "Hohn", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Einst, als er unbesorgt bei seiner Phyllis sa\u00df,", "tokens": ["Einst", ",", "als", "er", "un\u00b7be\u00b7sorgt", "bei", "sei\u00b7ner", "Phyl\u00b7lis", "sa\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und so die Welt, wie ihn die Welt verga\u00df,", "tokens": ["Und", "so", "die", "Welt", ",", "wie", "ihn", "die", "Welt", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ward er um Mitternacht durch einen L\u00e4rm geschrecket.", "tokens": ["Ward", "er", "um", "Mit\u00b7ter\u00b7nacht", "durch", "ei\u00b7nen", "L\u00e4rm", "ge\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man klopft an seine Th\u00fcr. Er horcht. Wer ist's? Das Gl\u00fcck.", "tokens": ["Man", "klopft", "an", "sei\u00b7ne", "Th\u00fcr.", "Er", "horcht", ".", "Wer", "ist's", "?", "Das", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$.", "PWS", "VAFIN", "$.", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Macht auf! ich bin es selbst. Ihr selbst? Wer darf es wagen,", "tokens": ["Macht", "auf", "!", "ich", "bin", "es", "selbst", ".", "Ihr", "selbst", "?", "Wer", "darf", "es", "wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "ADV", "$.", "PPER", "ADV", "$.", "PWS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer ist so gro\u00df, nur einen Augenblick", "tokens": ["Wer", "ist", "so", "gro\u00df", ",", "nur", "ei\u00b7nen", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dem Gl\u00fcck, und was ihm folgt, die Einkehr abzuschlagen?", "tokens": ["Dem", "Gl\u00fcck", ",", "und", "was", "ihm", "folgt", ",", "die", "Ein\u00b7kehr", "ab\u00b7zu\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PWS", "PPER", "VVFIN", "$,", "PRELS", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ihr z\u00f6gert? macht uns auf! Der Eremite spricht:", "tokens": ["Ihr", "z\u00f6\u00b7gert", "?", "macht", "uns", "auf", "!", "Der", "E\u00b7re\u00b7mi\u00b7te", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Geht weiter, Freund, ich kenn' euch nicht,", "tokens": ["Geht", "wei\u00b7ter", ",", "Freund", ",", "ich", "kenn'", "euch", "nicht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Herberg ist zu klein, zu schlecht, euch zu empfangen.", "tokens": ["Die", "Her\u00b7berg", "ist", "zu", "klein", ",", "zu", "schlecht", ",", "euch", "zu", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ruhm, Ehre, Hoheit sind bei mir,", "tokens": ["Ruhm", ",", "Eh\u00b7re", ",", "Ho\u00b7heit", "sind", "bei", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erwiderte das Gl\u00fcck; sie kommen jetzt zu dir.", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "das", "Gl\u00fcck", ";", "sie", "kom\u00b7men", "jetzt", "zu", "dir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das ist mir wahrlich leid; es ist kein Platz allhier.", "tokens": ["Das", "ist", "mir", "wahr\u00b7lich", "leid", ";", "es", "ist", "kein", "Platz", "all\u00b7hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$.", "PPER", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bewirthe doch zum mindsten das Verlangen.", "tokens": ["Be\u00b7wirt\u00b7he", "doch", "zum", "minds\u00b7ten", "das", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Auch dieses wird, versetzt der Biedermann,", "tokens": ["Auch", "die\u00b7ses", "wird", ",", "ver\u00b7setzt", "der", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Hier diese Nacht kein Lager kriegen;", "tokens": ["Hier", "die\u00b7se", "Nacht", "kein", "La\u00b7ger", "krie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man trifft ein einzig Bett hier an;", "tokens": ["Man", "trifft", "ein", "ein\u00b7zig", "Bett", "hier", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJD", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und das geh\u00f6ret dem Vergn\u00fcgen.", "tokens": ["Und", "das", "ge\u00b7h\u00f6\u00b7ret", "dem", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Es lebt ein Eremit, der, eitlem Zwange feind,", "tokens": ["Es", "lebt", "ein", "E\u00b7re\u00b7mit", ",", "der", ",", "eit\u00b7lem", "Zwan\u00b7ge", "feind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "$,", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Kunst der schlauen Wollust lernet,", "tokens": ["Die", "Kunst", "der", "schlau\u00b7en", "Wol\u00b7lust", "ler\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die keine M\u00fche kennt, vom Ekel weit entfernet,", "tokens": ["Die", "kei\u00b7ne", "M\u00fc\u00b7he", "kennt", ",", "vom", "E\u00b7kel", "weit", "ent\u00b7fer\u00b7net", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,", "APPRART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nach dem Genusse sch\u00f6ner scheint.", "tokens": ["Nach", "dem", "Ge\u00b7nus\u00b7se", "sch\u00f6\u00b7ner", "scheint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "++-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Verzeiht es mir, erhabne Musens\u00f6hne,", "tokens": ["Ver\u00b7zeiht", "es", "mir", ",", "er\u00b7hab\u00b7ne", "Mu\u00b7sen\u00b7s\u00f6h\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr die schon unsre Pflicht den Lorbeerkranz bestellt,", "tokens": ["F\u00fcr", "die", "schon", "uns\u00b7re", "Pflicht", "den", "Lor\u00b7beer\u00b7kranz", "be\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PPOSAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mein Held ist kein gelehrter Held;", "tokens": ["Mein", "Held", "ist", "kein", "ge\u00b7lehr\u00b7ter", "Held", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und er besa\u00df auf dieser Welt", "tokens": ["Und", "er", "be\u00b7sa\u00df", "auf", "die\u00b7ser", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nichts, als ein Buch, ein Glas, und eine Sch\u00f6ne.", "tokens": ["Nichts", ",", "als", "ein", "Buch", ",", "ein", "Glas", ",", "und", "ei\u00b7ne", "Sch\u00f6\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Doch diese drei, ihn zu erfreun,", "tokens": ["Doch", "die\u00b7se", "drei", ",", "ihn", "zu", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "CARD", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sind, wie man sagt, nur selten ungelesen,", "tokens": ["Sind", ",", "wie", "man", "sagt", ",", "nur", "sel\u00b7ten", "un\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "PIS", "VVFIN", "$,", "ADV", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Unangef\u00fcllt, und ungek\u00fc\u00dft gewesen.", "tokens": ["Un\u00b7an\u00b7ge\u00b7f\u00fcllt", ",", "und", "un\u00b7ge\u00b7k\u00fc\u00dft", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Er lebet. Wie gar viel schlie\u00dft dieses Wort nicht ein!", "tokens": ["Er", "le\u00b7bet", ".", "Wie", "gar", "viel", "schlie\u00dft", "die\u00b7ses", "Wort", "nicht", "ein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PWAV", "ADV", "ADV", "VVFIN", "PDAT", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihr Weisen, saget mir, hei\u00dft leben mehr, als sein?", "tokens": ["Ihr", "Wei\u00b7sen", ",", "sa\u00b7get", "mir", ",", "hei\u00dft", "le\u00b7ben", "mehr", ",", "als", "sein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "VVFIN", "ADV", "$,", "KOUS", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Ihn h\u00e4lt ein Schieferdach vor Neid und Hohn verstecket.", "tokens": ["Ihn", "h\u00e4lt", "ein", "Schie\u00b7fer\u00b7dach", "vor", "Neid", "und", "Hohn", "ver\u00b7ste\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Einst, als er unbesorgt bei seiner Phyllis sa\u00df,", "tokens": ["Einst", ",", "als", "er", "un\u00b7be\u00b7sorgt", "bei", "sei\u00b7ner", "Phyl\u00b7lis", "sa\u00df", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und so die Welt, wie ihn die Welt verga\u00df,", "tokens": ["Und", "so", "die", "Welt", ",", "wie", "ihn", "die", "Welt", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ward er um Mitternacht durch einen L\u00e4rm geschrecket.", "tokens": ["Ward", "er", "um", "Mit\u00b7ter\u00b7nacht", "durch", "ei\u00b7nen", "L\u00e4rm", "ge\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man klopft an seine Th\u00fcr. Er horcht. Wer ist's? Das Gl\u00fcck.", "tokens": ["Man", "klopft", "an", "sei\u00b7ne", "Th\u00fcr.", "Er", "horcht", ".", "Wer", "ist's", "?", "Das", "Gl\u00fcck", "."], "token_info": ["word", "word", "word", "word", "abbreviation", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PPOSAT", "NN", "PPER", "VVFIN", "$.", "PWS", "VAFIN", "$.", "ART", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Macht auf! ich bin es selbst. Ihr selbst? Wer darf es wagen,", "tokens": ["Macht", "auf", "!", "ich", "bin", "es", "selbst", ".", "Ihr", "selbst", "?", "Wer", "darf", "es", "wa\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VAFIN", "PPER", "ADV", "$.", "PPER", "ADV", "$.", "PWS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer ist so gro\u00df, nur einen Augenblick", "tokens": ["Wer", "ist", "so", "gro\u00df", ",", "nur", "ei\u00b7nen", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dem Gl\u00fcck, und was ihm folgt, die Einkehr abzuschlagen?", "tokens": ["Dem", "Gl\u00fcck", ",", "und", "was", "ihm", "folgt", ",", "die", "Ein\u00b7kehr", "ab\u00b7zu\u00b7schla\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KON", "PWS", "PPER", "VVFIN", "$,", "PRELS", "PIS", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ihr z\u00f6gert? macht uns auf! Der Eremite spricht:", "tokens": ["Ihr", "z\u00f6\u00b7gert", "?", "macht", "uns", "auf", "!", "Der", "E\u00b7re\u00b7mi\u00b7te", "spricht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Geht weiter, Freund, ich kenn' euch nicht,", "tokens": ["Geht", "wei\u00b7ter", ",", "Freund", ",", "ich", "kenn'", "euch", "nicht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Die Herberg ist zu klein, zu schlecht, euch zu empfangen.", "tokens": ["Die", "Her\u00b7berg", "ist", "zu", "klein", ",", "zu", "schlecht", ",", "euch", "zu", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Ruhm, Ehre, Hoheit sind bei mir,", "tokens": ["Ruhm", ",", "Eh\u00b7re", ",", "Ho\u00b7heit", "sind", "bei", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "VAFIN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erwiderte das Gl\u00fcck; sie kommen jetzt zu dir.", "tokens": ["Er\u00b7wi\u00b7der\u00b7te", "das", "Gl\u00fcck", ";", "sie", "kom\u00b7men", "jetzt", "zu", "dir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das ist mir wahrlich leid; es ist kein Platz allhier.", "tokens": ["Das", "ist", "mir", "wahr\u00b7lich", "leid", ";", "es", "ist", "kein", "Platz", "all\u00b7hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJD", "$.", "PPER", "VAFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bewirthe doch zum mindsten das Verlangen.", "tokens": ["Be\u00b7wirt\u00b7he", "doch", "zum", "minds\u00b7ten", "das", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Auch dieses wird, versetzt der Biedermann,", "tokens": ["Auch", "die\u00b7ses", "wird", ",", "ver\u00b7setzt", "der", "Bie\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Hier diese Nacht kein Lager kriegen;", "tokens": ["Hier", "die\u00b7se", "Nacht", "kein", "La\u00b7ger", "krie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man trifft ein einzig Bett hier an;", "tokens": ["Man", "trifft", "ein", "ein\u00b7zig", "Bett", "hier", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJD", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und das geh\u00f6ret dem Vergn\u00fcgen.", "tokens": ["Und", "das", "ge\u00b7h\u00f6\u00b7ret", "dem", "Ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}