{"textgrid.poem.66887": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00dcber das schneewei\u00dfe Leichenfeld", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Eine Riesenhy\u00e4ne heult und bellt.", "tokens": ["Ei\u00b7ne", "Rie\u00b7sen\u00b7hy\u00b7\u00e4\u00b7ne", "heult", "und", "bellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Bellt und lacht und pfeift vor Entz\u00fccken,", "tokens": ["Bellt", "und", "lacht", "und", "pfeift", "vor", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wehrlos Volk zerri\u00df sie zu St\u00fccken.", "tokens": ["Wehr\u00b7los", "Volk", "zer\u00b7ri\u00df", "sie", "zu", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Pfeift und lacht und heult vor Lust,", "tokens": ["Pfeift", "und", "lacht", "und", "heult", "vor", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tot bi\u00df sie den S\u00e4ugling an Mutterbrust.", "tokens": ["Tot", "bi\u00df", "sie", "den", "S\u00e4ug\u00b7ling", "an", "Mut\u00b7ter\u00b7brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "W\u00fchlt und zerrt, sich satt zu weiden,", "tokens": ["W\u00fchlt", "und", "zerrt", ",", "sich", "satt", "zu", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fctend in dampfenden Eingeweiden ...", "tokens": ["W\u00fc\u00b7tend", "in", "damp\u00b7fen\u00b7den", "Ein\u00b7ge\u00b7wei\u00b7den", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Um das nackte Scheusal wie Furienhaar", "tokens": ["Um", "das", "nack\u00b7te", "Scheu\u00b7sal", "wie", "Fu\u00b7ri\u00b7en\u00b7haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN", "KOKOM", "NN"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Flattern blutige Gei\u00dfeln. Das Augenpaar", "tokens": ["Flat\u00b7tern", "blu\u00b7ti\u00b7ge", "Gei\u00b7\u00dfeln", ".", "Das", "Au\u00b7gen\u00b7paar"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJA", "NN", "$.", "ART", "NN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Funkelt feige voll t\u00fcckischem Feuer \u2013", "tokens": ["Fun\u00b7kelt", "fei\u00b7ge", "voll", "t\u00fc\u00b7cki\u00b7schem", "Feu\u00b7er", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Eine Krone klebt auf dem schmutzigen Ungeheuer.", "tokens": ["Ei\u00b7ne", "Kro\u00b7ne", "klebt", "auf", "dem", "schmut\u00b7zi\u00b7gen", "Un\u00b7ge\u00b7heu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Millionenm\u00fcndig Entsetzen gellt.", "tokens": ["Mil\u00b7li\u00b7o\u00b7nen\u00b7m\u00fcn\u00b7dig", "Ent\u00b7set\u00b7zen", "gellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VVPP", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Gierig das gr\u00e4\u00dfliche Ungeheuer", "tokens": ["Gie\u00b7rig", "das", "gr\u00e4\u00df\u00b7li\u00b7che", "Un\u00b7ge\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ART", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wittert nach allem, was Menschen teuer.", "tokens": ["Wit\u00b7tert", "nach", "al\u00b7lem", ",", "was", "Men\u00b7schen", "teu\u00b7er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "$,", "PWS", "NN", "ADJD", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.9": {"line.1": {"text": "Schnuppert ringsum, der Atem weht faul,", "tokens": ["Schnup\u00b7pert", "ring\u00b7sum", ",", "der", "A\u00b7tem", "weht", "faul", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nach dem Denker schnappt, nach dem Dichter sein Maul.", "tokens": ["Nach", "dem", "Den\u00b7ker", "schnappt", ",", "nach", "dem", "Dich\u00b7ter", "sein", "Maul", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Wo noch gl\u00fchende Pulse der Freiheit klopfen,", "tokens": ["Wo", "noch", "gl\u00fc\u00b7hen\u00b7de", "Pul\u00b7se", "der", "Frei\u00b7heit", "klop\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Saugt es sie aus bis zum letzten Tropfen.", "tokens": ["Saugt", "es", "sie", "aus", "bis", "zum", "letz\u00b7ten", "Trop\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.11": {"line.1": {"text": "Schlingt der Menschheit zuckendes Herz", "tokens": ["Schlingt", "der", "Menschheit", "zu\u00b7cken\u00b7des", "Herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Und schielt heuchlerisch himmelw\u00e4rts.", "tokens": ["Und", "schielt", "heuch\u00b7le\u00b7risch", "him\u00b7mel\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.12": {"line.1": {"text": "Die lechzende Zunge h\u00e4ngt aus dem Rachen,", "tokens": ["Die", "lech\u00b7zen\u00b7de", "Zun\u00b7ge", "h\u00e4ngt", "aus", "dem", "Ra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Bestie badet in blutroten Lachen.", "tokens": ["Die", "Be\u00b7stie", "ba\u00b7det", "in", "blut\u00b7ro\u00b7ten", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.13": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ragen Galgen und Kreuz der Welt.", "tokens": ["Ra\u00b7gen", "Gal\u00b7gen", "und", "Kreuz", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.14": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Eine Riesenhy\u00e4ne heult und bellt.", "tokens": ["Ei\u00b7ne", "Rie\u00b7sen\u00b7hy\u00b7\u00e4\u00b7ne", "heult", "und", "bellt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.15": {"line.1": {"text": "Bellt und lacht und pfeift vor Entz\u00fccken,", "tokens": ["Bellt", "und", "lacht", "und", "pfeift", "vor", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wehrlos Volk zerri\u00df sie zu St\u00fccken.", "tokens": ["Wehr\u00b7los", "Volk", "zer\u00b7ri\u00df", "sie", "zu", "St\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Pfeift und lacht und heult vor Lust,", "tokens": ["Pfeift", "und", "lacht", "und", "heult", "vor", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tot bi\u00df sie den S\u00e4ugling an Mutterbrust.", "tokens": ["Tot", "bi\u00df", "sie", "den", "S\u00e4ug\u00b7ling", "an", "Mut\u00b7ter\u00b7brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.17": {"line.1": {"text": "W\u00fchlt und zerrt, sich satt zu weiden,", "tokens": ["W\u00fchlt", "und", "zerrt", ",", "sich", "satt", "zu", "wei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PRF", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "W\u00fctend in dampfenden Eingeweiden ...", "tokens": ["W\u00fc\u00b7tend", "in", "damp\u00b7fen\u00b7den", "Ein\u00b7ge\u00b7wei\u00b7den", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$("], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.18": {"line.1": {"text": "Um das nackte Scheusal wie Furienhaar", "tokens": ["Um", "das", "nack\u00b7te", "Scheu\u00b7sal", "wie", "Fu\u00b7ri\u00b7en\u00b7haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "ADJA", "NN", "KOKOM", "NN"], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Flattern blutige Gei\u00dfeln. Das Augenpaar", "tokens": ["Flat\u00b7tern", "blu\u00b7ti\u00b7ge", "Gei\u00b7\u00dfeln", ".", "Das", "Au\u00b7gen\u00b7paar"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ADJA", "NN", "$.", "ART", "NN"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.19": {"line.1": {"text": "Funkelt feige voll t\u00fcckischem Feuer \u2013", "tokens": ["Fun\u00b7kelt", "fei\u00b7ge", "voll", "t\u00fc\u00b7cki\u00b7schem", "Feu\u00b7er", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Eine Krone klebt auf dem schmutzigen Ungeheuer.", "tokens": ["Ei\u00b7ne", "Kro\u00b7ne", "klebt", "auf", "dem", "schmut\u00b7zi\u00b7gen", "Un\u00b7ge\u00b7heu\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.20": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Millionenm\u00fcndig Entsetzen gellt.", "tokens": ["Mil\u00b7li\u00b7o\u00b7nen\u00b7m\u00fcn\u00b7dig", "Ent\u00b7set\u00b7zen", "gellt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VVPP", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.21": {"line.1": {"text": "Gierig das gr\u00e4\u00dfliche Ungeheuer", "tokens": ["Gie\u00b7rig", "das", "gr\u00e4\u00df\u00b7li\u00b7che", "Un\u00b7ge\u00b7heu\u00b7er"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ART", "ADJA", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Wittert nach allem, was Menschen teuer.", "tokens": ["Wit\u00b7tert", "nach", "al\u00b7lem", ",", "was", "Men\u00b7schen", "teu\u00b7er", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "$,", "PWS", "NN", "ADJD", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.22": {"line.1": {"text": "Schnuppert ringsum, der Atem weht faul,", "tokens": ["Schnup\u00b7pert", "ring\u00b7sum", ",", "der", "A\u00b7tem", "weht", "faul", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Nach dem Denker schnappt, nach dem Dichter sein Maul.", "tokens": ["Nach", "dem", "Den\u00b7ker", "schnappt", ",", "nach", "dem", "Dich\u00b7ter", "sein", "Maul", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}}, "stanza.23": {"line.1": {"text": "Wo noch gl\u00fchende Pulse der Freiheit klopfen,", "tokens": ["Wo", "noch", "gl\u00fc\u00b7hen\u00b7de", "Pul\u00b7se", "der", "Frei\u00b7heit", "klop\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADJA", "NN", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+--+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Saugt es sie aus bis zum letzten Tropfen.", "tokens": ["Saugt", "es", "sie", "aus", "bis", "zum", "letz\u00b7ten", "Trop\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.24": {"line.1": {"text": "Schlingt der Menschheit zuckendes Herz", "tokens": ["Schlingt", "der", "Menschheit", "zu\u00b7cken\u00b7des", "Herz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Und schielt heuchlerisch himmelw\u00e4rts.", "tokens": ["Und", "schielt", "heuch\u00b7le\u00b7risch", "him\u00b7mel\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.25": {"line.1": {"text": "Die lechzende Zunge h\u00e4ngt aus dem Rachen,", "tokens": ["Die", "lech\u00b7zen\u00b7de", "Zun\u00b7ge", "h\u00e4ngt", "aus", "dem", "Ra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Bestie badet in blutroten Lachen.", "tokens": ["Die", "Be\u00b7stie", "ba\u00b7det", "in", "blut\u00b7ro\u00b7ten", "La\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}}, "stanza.26": {"line.1": {"text": "\u00dcber das schneewei\u00dfe Leichenfeld", "tokens": ["\u00dc\u00b7ber", "das", "schnee\u00b7wei\u00b7\u00dfe", "Lei\u00b7chen\u00b7feld"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ragen Galgen und Kreuz der Welt.", "tokens": ["Ra\u00b7gen", "Gal\u00b7gen", "und", "Kreuz", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}