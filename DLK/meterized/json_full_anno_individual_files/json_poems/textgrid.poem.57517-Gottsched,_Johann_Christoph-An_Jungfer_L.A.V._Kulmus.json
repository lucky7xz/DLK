{"textgrid.poem.57517": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "An Jungfer L.A.V. Kulmus", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So willst du mir hinfort noch seltner schreiben?", "tokens": ["So", "willst", "du", "mir", "hin\u00b7fort", "noch", "selt\u00b7ner", "schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Victoria! mein Leben, Herz und Licht!", "tokens": ["Vic\u00b7to\u00b7ria", "!", "mein", "Le\u00b7ben", ",", "Herz", "und", "Licht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Soll mir dein Kiel die Antwort schuldig bleiben?", "tokens": ["Soll", "mir", "dein", "Kiel", "die", "Ant\u00b7wort", "schul\u00b7dig", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ach! strafe mich doch so empfindlich nicht!", "tokens": ["Ach", "!", "stra\u00b7fe", "mich", "doch", "so", "emp\u00b7find\u00b7lich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was hab ich denn versehen und verbrochen?", "tokens": ["Was", "hab", "ich", "denn", "ver\u00b7se\u00b7hen", "und", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verdammst du mich, ohn alle Missethat?", "tokens": ["Ver\u00b7dammst", "du", "mich", ",", "ohn", "al\u00b7le", "Mis\u00b7se\u00b7that", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "KOUI", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ach ja! mir ist mein Urtheil schon gesprochen,", "tokens": ["Ach", "ja", "!", "mir", "ist", "mein", "Ur\u00b7theil", "schon", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bevor man mir einmal die Schuld genennet hat.", "tokens": ["Be\u00b7vor", "man", "mir", "ein\u00b7mal", "die", "Schuld", "ge\u00b7nen\u00b7net", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+-++-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Ja, ja! so ists. Ich soll gemartert werden,", "tokens": ["Ja", ",", "ja", "!", "so", "ists", ".", "Ich", "soll", "ge\u00b7mar\u00b7tert", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "ADV", "VAFIN", "$.", "PPER", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dein eigner Kiel verk\u00fcndigt mir die Pein.", "tokens": ["Dein", "eig\u00b7ner", "Kiel", "ver\u00b7k\u00fcn\u00b7digt", "mir", "die", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fchlt nicht mein Herz schon Kummer und Beschwerden,", "tokens": ["F\u00fchlt", "nicht", "mein", "Herz", "schon", "Kum\u00b7mer", "und", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich von dir so weit getrennt mu\u00df seyn?", "tokens": ["Da\u00df", "ich", "von", "dir", "so", "weit", "ge\u00b7trennt", "mu\u00df", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADJD", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch nicht genug! Ein Weg von achtzig Meilen", "tokens": ["Doch", "nicht", "ge\u00b7nug", "!", "Ein", "Weg", "von", "acht\u00b7zig", "Mei\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "$.", "ART", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "L\u00e4\u00dft meinen Trieb noch gar zu stark und neu:", "tokens": ["L\u00e4\u00dft", "mei\u00b7nen", "Trieb", "noch", "gar", "zu", "stark", "und", "neu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Drum will man gar, da\u00df auch kein Blatt voll Zeilen", "tokens": ["Drum", "will", "man", "gar", ",", "da\u00df", "auch", "kein", "Blatt", "voll", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PIS", "ADV", "$,", "KOUS", "ADV", "PIAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Von deiner sch\u00f6nen Hand sein neuer Zunder sey.", "tokens": ["Von", "dei\u00b7ner", "sch\u00f6\u00b7nen", "Hand", "sein", "neu\u00b7er", "Zun\u00b7der", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "O sch\u00f6nste Hand! mein Labsal und Vergn\u00fcgen!", "tokens": ["O", "sch\u00f6ns\u00b7te", "Hand", "!", "mein", "Lab\u00b7sal", "und", "Ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie froh macht mich ein s\u00fc\u00dfer Brief von dir!", "tokens": ["Wie", "froh", "macht", "mich", "ein", "s\u00fc\u00b7\u00dfer", "Brief", "von", "dir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PRF", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum seh ich ihn, so la\u00df ich alles liegen,", "tokens": ["Kaum", "seh", "ich", "ihn", ",", "so", "la\u00df", "ich", "al\u00b7les", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ADV", "VVIMP", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und k\u00fc\u00df ihn oft mit l\u00fcsterner Begier.", "tokens": ["Und", "k\u00fc\u00df", "ihn", "oft", "mit", "l\u00fcs\u00b7ter\u00b7ner", "Be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich bebe recht vor sehnlichem Verlangen,", "tokens": ["Ich", "be\u00b7be", "recht", "vor", "sehn\u00b7li\u00b7chem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Sein Siegel geht mir stets zu langsam los:", "tokens": ["Sein", "Sie\u00b7gel", "geht", "mir", "stets", "zu", "lang\u00b7sam", "los", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn ich ihn zu lesen angefangen,", "tokens": ["Und", "wenn", "ich", "ihn", "zu", "le\u00b7sen", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Dann sitz ich, wie mich d\u00fcnkt, dem Gl\u00fccke selbst im Schoo\u00df.", "tokens": ["Dann", "sitz", "ich", ",", "wie", "mich", "d\u00fcnkt", ",", "dem", "Gl\u00fc\u00b7cke", "selbst", "im", "Schoo\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Da steht kein Wort, das nach der Einfalt schmecket,", "tokens": ["Da", "steht", "kein", "Wort", ",", "das", "nach", "der", "Ein\u00b7falt", "schme\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die M\u00e4nnern wohl sehr oft ein Schandfleck ist:", "tokens": ["Die", "M\u00e4n\u00b7nern", "wohl", "sehr", "oft", "ein", "Schand\u00b7fleck", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da wird dein Geist mir mehr und mehr entdecket,", "tokens": ["Da", "wird", "dein", "Geist", "mir", "mehr", "und", "mehr", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPER", "ADV", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Daran du doch ganz unvergleichlich bist.", "tokens": ["Da\u00b7ran", "du", "doch", "ganz", "un\u00b7ver\u00b7gleich\u00b7lich", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein kluger Scherz, ein ernsthaft edles Wesen,", "tokens": ["Ein", "klu\u00b7ger", "Scherz", ",", "ein", "ernst\u00b7haft", "ed\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "W\u00fcrzt \u00fcberall dein witzerf\u00fclltes Wort:", "tokens": ["W\u00fcrzt", "\u00fc\u00b7be\u00b7rall", "dein", "wit\u00b7zer\u00b7f\u00fcll\u00b7tes", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wann ichs denn wohl zehnmal durchgelesen,", "tokens": ["Und", "wann", "ichs", "denn", "wohl", "zehn\u00b7mal", "durch\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Dann leg ich erst das Blatt, und doch mit M\u00fche, fort.", "tokens": ["Dann", "leg", "ich", "erst", "das", "Blatt", ",", "und", "doch", "mit", "M\u00fc\u00b7he", ",", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KON", "ADV", "APPR", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was denkst du nun, bey diesen stillen Freuden?", "tokens": ["Was", "denkst", "du", "nun", ",", "bey", "die\u00b7sen", "stil\u00b7len", "Freu\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sprich, Engelskind! misg\u00f6nnst du mir die Lust?", "tokens": ["Sprich", ",", "En\u00b7gels\u00b7kind", "!", "mis\u00b7g\u00f6nnst", "du", "mir", "die", "Lust", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$.", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Erk\u00fchnt man sich, die\u00df Gl\u00fccke zu beneiden,", "tokens": ["Er\u00b7k\u00fchnt", "man", "sich", ",", "die\u00df", "Gl\u00fc\u00b7cke", "zu", "be\u00b7nei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "$,", "PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Das einzige, davon ich noch gewu\u00dft?", "tokens": ["Das", "ein\u00b7zi\u00b7ge", ",", "da\u00b7von", "ich", "noch", "ge\u00b7wu\u00dft", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "O! sinne nach, ob meiner zarten Liebe", "tokens": ["O", "!", "sin\u00b7ne", "nach", ",", "ob", "mei\u00b7ner", "zar\u00b7ten", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PTKVZ", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die Probe nicht zu hart und grausam sey?", "tokens": ["Die", "Pro\u00b7be", "nicht", "zu", "hart", "und", "grau\u00b7sam", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKA", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und mache doch die Neigung deiner Triebe,", "tokens": ["Und", "ma\u00b7che", "doch", "die", "Nei\u00b7gung", "dei\u00b7ner", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wie deinen muntern Kiel, von diesem Zwange frey.", "tokens": ["Wie", "dei\u00b7nen", "mun\u00b7tern", "Kiel", ",", "von", "die\u00b7sem", "Zwan\u00b7ge", "frey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Jedoch umsonst! Du schreibst es mir im Scherzen,", "tokens": ["Je\u00b7doch", "um\u00b7sonst", "!", "Du", "schreibst", "es", "mir", "im", "Scher\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "PPER", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du ehrst den Zwang, als eine theure Pflicht:", "tokens": ["Du", "ehrst", "den", "Zwang", ",", "als", "ei\u00b7ne", "theu\u00b7re", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wohlan! so rei\u00df dein Bild noch aus dem Herzen!", "tokens": ["Wo\u00b7hlan", "!", "so", "rei\u00df", "dein", "Bild", "noch", "aus", "dem", "Her\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn, wie es scheint, auch das g\u00f6nnt man mir nicht.", "tokens": ["Denn", ",", "wie", "es", "scheint", ",", "auch", "das", "g\u00f6nnt", "man", "mir", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "PDS", "VVFIN", "PIS", "PPER", "PTKNEG", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ach! merkst du nicht die List bey diesen R\u00e4nken?", "tokens": ["Ach", "!", "merkst", "du", "nicht", "die", "List", "bey", "die\u00b7sen", "R\u00e4n\u00b7ken", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wenn mir dein Kiel nur erstlich seltner schreibt:", "tokens": ["Wenn", "mir", "dein", "Kiel", "nur", "erst\u00b7lich", "selt\u00b7ner", "schreibt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So weis man schon, da\u00df auch im Angedenken,", "tokens": ["So", "weis", "man", "schon", ",", "da\u00df", "auch", "im", "An\u00b7ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PIS", "ADV", "$,", "KOUS", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Allm\u00e4hlich mir bey dir kein Pl\u00e4tzchen \u00fcbrig bleibt.", "tokens": ["All\u00b7m\u00e4h\u00b7lich", "mir", "bey", "dir", "kein", "Pl\u00e4tz\u00b7chen", "\u00fcb\u00b7rig", "bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.6": {"line.1": {"text": "Wie man die Glut von stark entbrannten Flammen", "tokens": ["Wie", "man", "die", "Glut", "von", "stark", "ent\u00b7brann\u00b7ten", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ART", "NN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht mit Gewalt auf einmal d\u00e4mpfen kann;", "tokens": ["Nicht", "mit", "Ge\u00b7walt", "auf", "ein\u00b7mal", "d\u00e4mp\u00b7fen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "APPR", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Hitze dr\u00e4ngt sich destomehr zusammen,", "tokens": ["Die", "Hit\u00b7ze", "dr\u00e4ngt", "sich", "des\u00b7to\u00b7mehr", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und facht sich nur um desto sch\u00e4rfer an:", "tokens": ["Und", "facht", "sich", "nur", "um", "des\u00b7to", "sch\u00e4r\u00b7fer", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch, will man nicht das wilde Feuer hegen,", "tokens": ["Doch", ",", "will", "man", "nicht", "das", "wil\u00b7de", "Feu\u00b7er", "he\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VMFIN", "PIS", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sucht man ihm die Nahrung zu entziehn;", "tokens": ["So", "sucht", "man", "ihm", "die", "Nah\u00b7rung", "zu", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da wird die Brunst sich von sich selbst schon legen,", "tokens": ["Da", "wird", "die", "Brunst", "sich", "von", "sich", "selbst", "schon", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "APPR", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und leichten Funken gleich in d\u00fcnner Luft entfliehn.", "tokens": ["Und", "leich\u00b7ten", "Fun\u00b7ken", "gleich", "in", "d\u00fcn\u00b7ner", "Luft", "ent\u00b7fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Erw\u00e4ge die\u00df, o englische Louise!", "tokens": ["Er\u00b7w\u00e4\u00b7ge", "die\u00df", ",", "o", "eng\u00b7li\u00b7sche", "Lou\u00b7i\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und denk einmal auf deine letzte Schrift!", "tokens": ["Und", "denk", "ein\u00b7mal", "auf", "dei\u00b7ne", "letz\u00b7te", "Schrift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie? wenn ich dich auf dein Versprechen wiese,", "tokens": ["Wie", "?", "wenn", "ich", "dich", "auf", "dein", "Ver\u00b7spre\u00b7chen", "wie\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Womit dein Schlu\u00df itzt schlecht zusammen trifft.", "tokens": ["Wo\u00b7mit", "dein", "Schlu\u00df", "itzt", "schlecht", "zu\u00b7sam\u00b7men", "trifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ist das die Huld, die du mir zugeschworen?", "tokens": ["Ist", "das", "die", "Huld", ",", "die", "du", "mir", "zu\u00b7ge\u00b7schwo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist das die Treu, die du mir zugesagt?", "tokens": ["Ist", "das", "die", "Treu", ",", "die", "du", "mir", "zu\u00b7ge\u00b7sagt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn hat dein Wort so bald die Kraft verlohren:", "tokens": ["Denn", "hat", "dein", "Wort", "so", "bald", "die", "Kraft", "ver\u00b7loh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So hast du mich dadurch aufs heftigste geplagt.", "tokens": ["So", "hast", "du", "mich", "da\u00b7durch", "aufs", "hef\u00b7tigs\u00b7te", "ge\u00b7plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PAV", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So schweige dann, und la\u00df mich gar verschmachten;", "tokens": ["So", "schwei\u00b7ge", "dann", ",", "und", "la\u00df", "mich", "gar", "ver\u00b7schmach\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KON", "VVIMP", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und mache mich zum Opfer deiner Pflicht:", "tokens": ["Und", "ma\u00b7che", "mich", "zum", "Op\u00b7fer", "dei\u00b7ner", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch willst du mich der Antwort unwerth achten;", "tokens": ["Doch", "willst", "du", "mich", "der", "Ant\u00b7wort", "un\u00b7werth", "ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So schweig ich doch von meiner Sehnsucht nicht.", "tokens": ["So", "schweig", "ich", "doch", "von", "mei\u00b7ner", "Sehn\u00b7sucht", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bey sp\u00e4ter Nacht will ich dich tr\u00e4umend plagen,", "tokens": ["Bey", "sp\u00e4\u00b7ter", "Nacht", "will", "ich", "dich", "tr\u00e4u\u00b7mend", "pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Im Wachen selbst dir stets vor Augen stehn;", "tokens": ["Im", "Wa\u00b7chen", "selbst", "dir", "stets", "vor", "Au\u00b7gen", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und dich, mein Licht! ohn Unterla\u00df befragen:", "tokens": ["Und", "dich", ",", "mein", "Licht", "!", "ohn", "Un\u00b7ter\u00b7la\u00df", "be\u00b7fra\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPOSAT", "NN", "$.", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "O Grausame! soll ich ohn alle Schuld vergehn?", "tokens": ["O", "Grau\u00b7sa\u00b7me", "!", "soll", "ich", "ohn", "al\u00b7le", "Schuld", "ver\u00b7gehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VMFIN", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Gehab dich also wohl. Du rauhes Pf\u00e4lzerland!", "tokens": ["Ge\u00b7hab", "dich", "al\u00b7so", "wohl", ".", "Du", "rau\u00b7hes", "Pf\u00e4l\u00b7zer\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "$.", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein Felsenreicher Grund ist mir nunmehr bekannt:", "tokens": ["Dein", "Fel\u00b7sen\u00b7rei\u00b7cher", "Grund", "ist", "mir", "nun\u00b7mehr", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bekannt, doch auch verha\u00dft. Von deinen harten Steinen", "tokens": ["Be\u00b7kannt", ",", "doch", "auch", "ver\u00b7ha\u00dft", ".", "Von", "dei\u00b7nen", "har\u00b7ten", "Stei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "ADV", "ADJD", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Komm ich, Gott Lob! die\u00dfmal annoch mit ganzen Beinen.", "tokens": ["Komm", "ich", ",", "Gott", "Lob", "!", "die\u00df\u00b7mal", "an\u00b7noch", "mit", "gan\u00b7zen", "Bei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "NN", "$.", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du, hohler Wege Schlund; du, steiler Berge Graus,", "tokens": ["Du", ",", "hoh\u00b7ler", "We\u00b7ge", "Schlund", ";", "du", ",", "stei\u00b7ler", "Ber\u00b7ge", "Graus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "NN", "$.", "PPER", "$,", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du, dicker W\u00e4lder Wust, du, kalter Winde Straus,", "tokens": ["Du", ",", "di\u00b7cker", "W\u00e4l\u00b7der", "Wust", ",", "du", ",", "kal\u00b7ter", "Win\u00b7de", "Straus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "NN", "$,", "PPER", "$,", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der du best\u00e4ndig scheinst, dem Sommer Trotz zu biethen,", "tokens": ["Der", "du", "be\u00b7st\u00e4n\u00b7dig", "scheinst", ",", "dem", "Som\u00b7mer", "Trotz", "zu", "bie\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Himmel wird vor euch mich k\u00fcnftig wohl beh\u00fcten.", "tokens": ["Der", "Him\u00b7mel", "wird", "vor", "euch", "mich", "k\u00fcnf\u00b7tig", "wohl", "be\u00b7h\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "PRF", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Begl\u00fccktes Vaterland! das mich zur Welt gebahr,", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Va\u00b7ter\u00b7land", "!", "das", "mich", "zur", "Welt", "ge\u00b7bahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gepriesne Mei\u00dfnerflur! wo ich l\u00e4ngst B\u00fcrger war,", "tokens": ["Ge\u00b7pri\u00b7es\u00b7ne", "Mei\u00df\u00b7ner\u00b7flur", "!", "wo", "ich", "l\u00e4ngst", "B\u00fcr\u00b7ger", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihr kennt die Plagen nicht, die uns allhier betreffen,", "tokens": ["Ihr", "kennt", "die", "Pla\u00b7gen", "nicht", ",", "die", "uns", "all\u00b7hier", "be\u00b7tref\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Berg und Th\u00e4ler uns auf langen Reisen \u00e4ffen.", "tokens": ["Wenn", "Berg", "und", "Th\u00e4\u00b7ler", "uns", "auf", "lan\u00b7gen", "Rei\u00b7sen", "\u00e4f\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bald steig ich Himmel an, wie, wider die Natur", "tokens": ["Bald", "steig", "ich", "Him\u00b7mel", "an", ",", "wie", ",", "wi\u00b7der", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PWAV", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Elias von der Welt mit Feuerrossen fuhr;", "tokens": ["E\u00b7lias", "von", "der", "Welt", "mit", "Feu\u00b7er\u00b7ros\u00b7sen", "fuhr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bald aber senk ich mich, wie Phaeton, hinwieder,", "tokens": ["Bald", "a\u00b7ber", "senk", "ich", "mich", ",", "wie", "Phae\u00b7ton", ",", "hin\u00b7wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "$,", "PWAV", "NE", "$,", "ADV", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Doch ohne mein Vergehn, in tiefe Gr\u00fcnde nieder.", "tokens": ["Doch", "oh\u00b7ne", "mein", "Ver\u00b7gehn", ",", "in", "tie\u00b7fe", "Gr\u00fcn\u00b7de", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "So weit mein Auge tr\u00e4gt, erblick ich Stein und Wald,", "tokens": ["So", "weit", "mein", "Au\u00b7ge", "tr\u00e4gt", ",", "er\u00b7blick", "ich", "Stein", "und", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "VVFIN", "$,", "VVIMP", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein w\u00fcstes, rauhes Land, der Faunen Aufenthalt;", "tokens": ["Ein", "w\u00fcs\u00b7tes", ",", "rau\u00b7hes", "Land", ",", "der", "Fau\u00b7nen", "Auf\u00b7ent\u00b7halt", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo kein gesittet Volk in sch\u00f6nen St\u00e4dten hauset,", "tokens": ["Wo", "kein", "ge\u00b7sit\u00b7tet", "Volk", "in", "sch\u00f6\u00b7nen", "St\u00e4d\u00b7ten", "hau\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "VVPP", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo, statt der Musen, Pan auf heischern R\u00f6hren brauset.", "tokens": ["Wo", ",", "statt", "der", "Mu\u00b7sen", ",", "Pan", "auf", "hei\u00b7schern", "R\u00f6h\u00b7ren", "brau\u00b7set", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUI", "ART", "NN", "$,", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Apollo wich mit Flei\u00df aus dieser frechen Flur,", "tokens": ["A\u00b7pol\u00b7lo", "wich", "mit", "Flei\u00df", "aus", "die\u00b7ser", "fre\u00b7chen", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Warum? sie wies ihm nicht die Sch\u00f6nheit der Natur.", "tokens": ["Wa\u00b7rum", "?", "sie", "wies", "ihm", "nicht", "die", "Sch\u00f6n\u00b7heit", "der", "Na\u00b7tur", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie ist der Schreibart gleich, die von den Alpen stammet,", "tokens": ["Sie", "ist", "der", "Schrei\u00b7bart", "gleich", ",", "die", "von", "den", "Al\u00b7pen", "stam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Rauh, h\u00f6ckricht, hart und steif; wie er sie stets verdammet.", "tokens": ["Rauh", ",", "h\u00f6c\u00b7kricht", ",", "hart", "und", "steif", ";", "wie", "er", "sie", "stets", "ver\u00b7dam\u00b7met", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$.", "PWAV", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was ist der Boden hier? Ein unfruchtbarer Thon,", "tokens": ["Was", "ist", "der", "Bo\u00b7den", "hier", "?", "Ein", "un\u00b7frucht\u00b7ba\u00b7rer", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Gras und Kr\u00e4uter ha\u00dft. Das Unkraut flieht ihn schon!", "tokens": ["Der", "Gras", "und", "Kr\u00e4u\u00b7ter", "ha\u00dft", ".", "Das", "Un\u00b7kraut", "flieht", "ihn", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein schlechter Distelbusch und scharfe Dornenhecken,", "tokens": ["Ein", "schlech\u00b7ter", "Dis\u00b7tel\u00b7busch", "und", "schar\u00b7fe", "Dor\u00b7nen\u00b7he\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ja, Schleeen wollen kaum den \u00f6den Grund bedecken.", "tokens": ["Ja", ",", "Schlee\u00b7en", "wol\u00b7len", "kaum", "den", "\u00f6\u00b7den", "Grund", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der arme Landmann pfl\u00fcgt des Landes mildern Theil;", "tokens": ["Der", "ar\u00b7me", "Land\u00b7mann", "pfl\u00fcgt", "des", "Lan\u00b7des", "mil\u00b7dern", "Theil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein die Pflugschaar f\u00fchlts, und st\u00fcmpfet sich in Eil.", "tokens": ["Al\u00b7lein", "die", "Pflug\u00b7schaar", "f\u00fchlts", ",", "und", "st\u00fcmp\u00b7fet", "sich", "in", "Eil", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man sieht den Acker kaum vor umgest\u00fcrzten Steinen,", "tokens": ["Man", "sieht", "den", "A\u00b7cker", "kaum", "vor", "um\u00b7ge\u00b7st\u00fcrz\u00b7ten", "Stei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als sollte noch einmal Deukalion erscheinen.", "tokens": ["Als", "soll\u00b7te", "noch", "ein\u00b7mal", "Deu\u00b7ka\u00b7li\u00b7on", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "ADV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "O k\u00e4m er doch nur bald! und Pyrrha noch dazu,", "tokens": ["O", "k\u00e4m", "er", "doch", "nur", "bald", "!", "und", "Pyrr\u00b7ha", "noch", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$.", "KON", "NE", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und br\u00e4chte jeden Stein aus der zu langen Ruh,", "tokens": ["Und", "br\u00e4ch\u00b7te", "je\u00b7den", "Stein", "aus", "der", "zu", "lan\u00b7gen", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPR", "ART", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und w\u00fcrf ihn hinter sich, der Menschen Zahl zu mehren:", "tokens": ["Und", "w\u00fcrf", "ihn", "hin\u00b7ter", "sich", ",", "der", "Men\u00b7schen", "Zahl", "zu", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PRF", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00fcrde doch die\u00df Land von neuen B\u00fcrgern h\u00f6ren.", "tokens": ["So", "w\u00fcr\u00b7de", "doch", "die\u00df", "Land", "von", "neu\u00b7en", "B\u00fcr\u00b7gern", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDS", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch leider! ist die\u00df Paar ins Fabelreich versenkt;", "tokens": ["Doch", "lei\u00b7der", "!", "ist", "die\u00df", "Paar", "ins", "Fa\u00b7bel\u00b7reich", "ver\u00b7senkt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "VAFIN", "PDS", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Himmel hat es nicht der neuern Zeit geschenkt.", "tokens": ["Der", "Him\u00b7mel", "hat", "es", "nicht", "der", "neu\u00b7ern", "Zeit", "ge\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist fast nichts seltsamers, als der Bewohner Spuren.", "tokens": ["Ist", "fast", "nichts", "selt\u00b7sa\u00b7mers", ",", "als", "der", "Be\u00b7woh\u00b7ner", "Spu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Kein Hirsch, kein feiges Reh, durchstreicht das freye Feld,", "tokens": ["Kein", "Hirsch", ",", "kein", "fei\u00b7ges", "Reh", ",", "durch\u00b7streicht", "das", "frey\u00b7e", "Feld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "ADJA", "NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Vogel nistet hier, dem jemand Netze stellt.", "tokens": ["Kein", "Vo\u00b7gel", "nis\u00b7tet", "hier", ",", "dem", "je\u00b7mand", "Net\u00b7ze", "stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "$,", "PRELS", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die S\u00e4ue w\u00fchlen nur, und wenig hagern Ziegen", "tokens": ["Die", "S\u00e4u\u00b7e", "w\u00fch\u00b7len", "nur", ",", "und", "we\u00b7nig", "ha\u00b7gern", "Zie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Thun d\u00fcrre Heiden kaum mit karger Kost ein Gn\u00fcgen.", "tokens": ["Thun", "d\u00fcr\u00b7re", "Hei\u00b7den", "kaum", "mit", "kar\u00b7ger", "Kost", "ein", "Gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein lumpicht Bettelvolk f\u00fcllt alle Stra\u00dfen an,", "tokens": ["Ein", "lum\u00b7picht", "Bet\u00b7tel\u00b7volk", "f\u00fcllt", "al\u00b7le", "Stra\u00b7\u00dfen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vor dem ein Reisender sich kaum noch retten kan;", "tokens": ["Vor", "dem", "ein", "Rei\u00b7sen\u00b7der", "sich", "kaum", "noch", "ret\u00b7ten", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PRF", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn die\u00df Zigeunerpack mit Weib und Kindern l\u00e4rmet,", "tokens": ["Wenn", "die\u00df", "Zi\u00b7geu\u00b7ner\u00b7pack", "mit", "Weib", "und", "Kin\u00b7dern", "l\u00e4r\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wilden Hummeln gleich um Pferd und Kutsche schw\u00e4rmet.", "tokens": ["Und", "wil\u00b7den", "Hum\u00b7meln", "gleich", "um", "Pferd", "und", "Kut\u00b7sche", "schw\u00e4r\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Ists Faulheit, die die\u00df Volk zum Bettelstabe treibt?", "tokens": ["Ists", "Faul\u00b7heit", ",", "die", "die\u00df", "Volk", "zum", "Bet\u00b7tel\u00b7sta\u00b7be", "treibt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PDS", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists Unart, die so gern beym M\u00fc\u00dfiggange bleibt?", "tokens": ["Ists", "Un\u00b7art", ",", "die", "so", "gern", "beym", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ge", "bleibt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo nicht, so ist es doch ein Schimpf der Policeyen,", "tokens": ["Wo", "nicht", ",", "so", "ist", "es", "doch", "ein", "Schimpf", "der", "Po\u00b7li\u00b7ce\u00b7yen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Die solch Gesindel nicht durch ihr Verboth zerstreuen.", "tokens": ["Die", "solch", "Ge\u00b7sin\u00b7del", "nicht", "durch", "ihr", "Ver\u00b7both", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Zucht- und Arbeithaus vertreibt die Krankheit leicht,", "tokens": ["Ein", "Zucht", "und", "Ar\u00b7beit\u00b7haus", "ver\u00b7treibt", "die", "Krank\u00b7heit", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die mancher Obrigkeit so gar unheilbar deucht.", "tokens": ["Die", "man\u00b7cher", "Ob\u00b7rig\u00b7keit", "so", "gar", "un\u00b7heil\u00b7bar", "deucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die ganze Staaten schimpft, und Fremden, die da reisen,", "tokens": ["Die", "gan\u00b7ze", "Staa\u00b7ten", "schimpft", ",", "und", "Frem\u00b7den", ",", "die", "da", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nur Elend, Angst und Noth des Landes pflegt zu weisen.", "tokens": ["Nur", "E\u00b7lend", ",", "Angst", "und", "Noth", "des", "Lan\u00b7des", "pflegt", "zu", "wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Behauptet, wie ihr wollt, ihr Weisen neuer Zeit,", "tokens": ["Be\u00b7haup\u00b7tet", ",", "wie", "ihr", "wollt", ",", "ihr", "Wei\u00b7sen", "neu\u00b7er", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die\u00df sey die beste Welt, nach sch\u00e4rfster M\u00f6glichkeit.", "tokens": ["Die\u00df", "sey", "die", "bes\u00b7te", "Welt", ",", "nach", "sch\u00e4rfs\u00b7ter", "M\u00f6g\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bevor ihr dieses lehrt, (so dacht ich oft mit Flehen)", "tokens": ["Be\u00b7vor", "ihr", "die\u00b7ses", "lehrt", ",", "(", "so", "dacht", "ich", "oft", "mit", "Fle\u00b7hen", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "$,", "$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "M\u00fc\u00dft ihr ein armes Land voll Berg und Bettler sehen.", "tokens": ["M\u00fc\u00dft", "ihr", "ein", "ar\u00b7mes", "Land", "voll", "Berg", "und", "Bett\u00b7ler", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kommt, seht nur erst allhier die wilden Klippen stehn,", "tokens": ["Kommt", ",", "seht", "nur", "erst", "all\u00b7hier", "die", "wil\u00b7den", "Klip\u00b7pen", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Felsen mit der Stirn bis in die Wolken gehn.", "tokens": ["Und", "Fel\u00b7sen", "mit", "der", "Stirn", "bis", "in", "die", "Wol\u00b7ken", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kommt, seht nur hin und her, die schlecht bewohnten Th\u00e4ler,", "tokens": ["Kommt", ",", "seht", "nur", "hin", "und", "her", ",", "die", "schlecht", "be\u00b7wohn\u00b7ten", "Th\u00e4\u00b7ler", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADV", "PTKVZ", "KON", "PTKVZ", "$,", "PRELS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sprecht ihr Zweifelsfrey: Die Welt ist voller Fehler!", "tokens": ["So", "sprecht", "ihr", "Zwei\u00b7fels\u00b7frey", ":", "Die", "Welt", "ist", "vol\u00b7ler", "Feh\u00b7ler", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "ART", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Wiewohl! so dacht ich nur aus Wahn und Ungeduld;", "tokens": ["Wie\u00b7wohl", "!", "so", "dacht", "ich", "nur", "aus", "Wahn", "und", "Un\u00b7ge\u00b7duld", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich, Sch\u00f6pffer der Natur! betrifft hier keine Schuld!", "tokens": ["Dich", ",", "Sch\u00f6pf\u00b7fer", "der", "Na\u00b7tur", "!", "be\u00b7tr\u00b7ifft", "hier", "kei\u00b7ne", "Schuld", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "ART", "NN", "$.", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dem Weltbau mangelt nichts an Sch\u00f6nheit im Verbinden,", "tokens": ["Dem", "Welt\u00b7bau", "man\u00b7gelt", "nichts", "an", "Sch\u00f6n\u00b7heit", "im", "Ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist in den Theilen gleich was fehlerhafts zu finden.", "tokens": ["Ist", "in", "den", "Thei\u00b7len", "gleich", "was", "feh\u00b7ler\u00b7hafts", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "PWS", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der steilen Berge Reih, die Deutschlands Mitte trennt,", "tokens": ["Der", "stei\u00b7len", "Ber\u00b7ge", "Reih", ",", "die", "Deutschlands", "Mit\u00b7te", "trennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und Vogtland, Frankenland und Oberpfalz durchrennt,", "tokens": ["Und", "Vogt\u00b7land", ",", "Fran\u00b7ken\u00b7land", "und", "O\u00b7berp\u00b7falz", "durch\u00b7rennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist unser Wasserschatz, daraus die B\u00e4che rinnen,", "tokens": ["Ist", "un\u00b7ser", "Was\u00b7ser\u00b7schatz", ",", "da\u00b7raus", "die", "B\u00e4\u00b7che", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wodurch so mancher Strom sein Wesen mu\u00df gewinnen.", "tokens": ["Wo\u00b7durch", "so", "man\u00b7cher", "Strom", "sein", "We\u00b7sen", "mu\u00df", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "So sah ich, wo zuerst der Plei\u00dfenstrom entspringt;", "tokens": ["So", "sah", "ich", ",", "wo", "zu\u00b7erst", "der", "Plei\u00b7\u00dfen\u00b7strom", "ent\u00b7springt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich sah der Elster Brunn, die Mei\u00dfens Flur durchschlingt;", "tokens": ["Ich", "sah", "der", "Els\u00b7ter", "Brunn", ",", "die", "Mei\u00b7\u00dfens", "Flur", "durch\u00b7schlingt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich sah der Mulden Strom in seinen ersten Quellen,", "tokens": ["Ich", "sah", "der", "Mul\u00b7den", "Strom", "in", "sei\u00b7nen", "ers\u00b7ten", "Quel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Nordw\u00e4rts ihren Lauf gewohnt sind fortzustellen.", "tokens": ["Die", "Nord\u00b7w\u00e4rts", "ih\u00b7ren", "Lauf", "ge\u00b7wohnt", "sind", "fort\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVPP", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sah den Egerflu\u00df zum Eibstrom Ostw\u00e4rts gehn,", "tokens": ["Ich", "sah", "den", "E\u00b7ger\u00b7flu\u00df", "zum", "Eib\u00b7strom", "Ost\u00b7w\u00e4rts", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und so, wie Saal und Mayn am Fichtelberg entstehn:", "tokens": ["Und", "so", ",", "wie", "Saal", "und", "Mayn", "am", "Fich\u00b7tel\u00b7berg", "ent\u00b7stehn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "NN", "KON", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hier quillt die Pegnitz auch, und S\u00fcdw\u00e4rts eilt die Naabe", "tokens": ["Hier", "quillt", "die", "Peg\u00b7nitz", "auch", ",", "und", "S\u00fcd\u00b7w\u00e4rts", "eilt", "die", "Naa\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zum gro\u00dfen Donaustrom, als ihrem nassen Grabe.", "tokens": ["Zum", "gro\u00b7\u00dfen", "Do\u00b7naus\u00b7trom", ",", "als", "ih\u00b7rem", "nas\u00b7sen", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Wo bleibt noch ausser dem, der kleinern Fl\u00fcsse Zahl,", "tokens": ["Wo", "bleibt", "noch", "aus\u00b7ser", "dem", ",", "der", "klei\u00b7nern", "Fl\u00fcs\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "ART", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die jeder Berg erzeugt, womit fast jedes Thal", "tokens": ["Die", "je\u00b7der", "Berg", "er\u00b7zeugt", ",", "wo\u00b7mit", "fast", "je\u00b7des", "Thal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "PWAV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier angeschw\u00e4ngert wird, die sich vom Nebel n\u00e4hren,", "tokens": ["Hier", "an\u00b7ge\u00b7schw\u00e4n\u00b7gert", "wird", ",", "die", "sich", "vom", "Ne\u00b7bel", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und von des Thaues Na\u00df, den Stein und Fels nicht zehren.", "tokens": ["Und", "von", "des", "Thau\u00b7es", "Na\u00df", ",", "den", "Stein", "und", "Fels", "nicht", "zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch f\u00e4llt ein Regengu\u00df, so schwillt die kleine Fluth,", "tokens": ["Doch", "f\u00e4llt", "ein", "Re\u00b7gen\u00b7gu\u00df", ",", "so", "schwillt", "die", "klei\u00b7ne", "Fluth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rei\u00dft Sand und Steine mit, der nahen Berge Brut;", "tokens": ["Rei\u00dft", "Sand", "und", "Stei\u00b7ne", "mit", ",", "der", "na\u00b7hen", "Ber\u00b7ge", "Brut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und treibt den feuchten Zoll nach L\u00e4ndern, D\u00f6rfern, St\u00e4dten,", "tokens": ["Und", "treibt", "den", "feuch\u00b7ten", "Zoll", "nach", "L\u00e4n\u00b7dern", ",", "D\u00f6r\u00b7fern", ",", "St\u00e4d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die t\u00e4glich um des Stroms erw\u00fcnschten Zuflu\u00df bethen.", "tokens": ["Die", "t\u00e4g\u00b7lich", "um", "des", "Stroms", "er\u00b7w\u00fcnschten", "Zu\u00b7flu\u00df", "be\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "So bleibt die Vorsicht auch bey scheinbarn M\u00e4ngeln gro\u00df:", "tokens": ["So", "bleibt", "die", "Vor\u00b7sicht", "auch", "bey", "schein\u00b7barn", "M\u00e4n\u00b7geln", "gro\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Ein Weiser spricht sie stets von allen Fehlern los.", "tokens": ["Ein", "Wei\u00b7ser", "spricht", "sie", "stets", "von", "al\u00b7len", "Feh\u00b7lern", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nur Thoren tadeln gern, was ihrer Einsicht weichet,", "tokens": ["Nur", "Tho\u00b7ren", "ta\u00b7deln", "gern", ",", "was", "ih\u00b7rer", "Ein\u00b7sicht", "wei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl dem, der forschend einst des Sch\u00f6pfers Spur erreichet!", "tokens": ["Wohl", "dem", ",", "der", "for\u00b7schend", "einst", "des", "Sch\u00f6p\u00b7fers", "Spur", "er\u00b7rei\u00b7chet", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ADJD", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die W\u00fcsten f\u00f6rdern selbst der h\u00f6chsten Weisheit Ziel,", "tokens": ["Die", "W\u00fcs\u00b7ten", "f\u00f6r\u00b7dern", "selbst", "der", "h\u00f6chs\u00b7ten", "Weis\u00b7heit", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie bleibt an Wundern reich, und treibt ihr altes Spiel,", "tokens": ["Sie", "bleibt", "an", "Wun\u00b7dern", "reich", ",", "und", "treibt", "ihr", "al\u00b7tes", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJD", "$,", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn sie besch\u00e4ftigt ist, auch in verborgnen Wegen,", "tokens": ["Wenn", "sie", "be\u00b7sch\u00e4f\u00b7tigt", "ist", ",", "auch", "in", "ver\u00b7borg\u00b7nen", "We\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Sterblichen zum Nutz, ihr Absehn darzulegen.", "tokens": ["Den", "Sterb\u00b7li\u00b7chen", "zum", "Nutz", ",", "ihr", "Ab\u00b7sehn", "dar\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Und wie? wohin verschickt ein hochgebirgigt Land", "tokens": ["Und", "wie", "?", "wo\u00b7hin", "ver\u00b7schickt", "ein", "hoch\u00b7ge\u00b7bir\u00b7gigt", "Land"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "$.", "PWAV", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch manchen Wolkengu\u00df und Schneegang Erd und Sand?", "tokens": ["Durch", "man\u00b7chen", "Wol\u00b7ken\u00b7gu\u00df", "und", "Schnee\u00b7gang", "Erd", "und", "Sand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die B\u00e4che zehren stets an den erweichten H\u00fcgeln,", "tokens": ["Die", "B\u00e4\u00b7che", "zeh\u00b7ren", "stets", "an", "den", "er\u00b7weich\u00b7ten", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-----+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Bis nackte Felsen sich in ihren Fluthen spiegeln.", "tokens": ["Bis", "nack\u00b7te", "Fel\u00b7sen", "sich", "in", "ih\u00b7ren", "Flut\u00b7hen", "spie\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo bleibt nun der Verlust, der niemals sich ersetzt?", "tokens": ["Wo", "bleibt", "nun", "der", "Ver\u00b7lust", ",", "der", "nie\u00b7mals", "sich", "er\u00b7setzt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er geht in Str\u00f6men fort, bis ihren Raub zuletzt", "tokens": ["Er", "geht", "in", "Str\u00f6\u00b7men", "fort", ",", "bis", "ih\u00b7ren", "Raub", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$,", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die weite See empf\u00e4ngt, die ihn an Ufer schwemmet,", "tokens": ["Die", "wei\u00b7te", "See", "emp\u00b7f\u00e4ngt", ",", "die", "ihn", "an", "U\u00b7fer", "schwem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Manch neues Eyland macht, und seichte K\u00fcsten d\u00e4mmet.", "tokens": ["Manch", "neu\u00b7es", "Ey\u00b7land", "macht", ",", "und", "seich\u00b7te", "K\u00fcs\u00b7ten", "d\u00e4m\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "O k\u00f6nnt ich die Gestalt des ganzen Erdballs sehn,", "tokens": ["O", "k\u00f6nnt", "ich", "die", "Ge\u00b7stalt", "des", "gan\u00b7zen", "Erd\u00b7balls", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bevor so mancher Ri\u00df in seinen Grund geschehn!", "tokens": ["Be\u00b7vor", "so", "man\u00b7cher", "Ri\u00df", "in", "sei\u00b7nen", "Grund", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Eh manche Wasserfluth den Boden durchgew\u00fchlet,", "tokens": ["Eh", "man\u00b7che", "Was\u00b7ser\u00b7fluth", "den", "Bo\u00b7den", "durch\u00b7ge\u00b7w\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Eh Regen, Flu\u00df und Bach die Felder ausgesp\u00fclet.", "tokens": ["Eh", "Re\u00b7gen", ",", "Flu\u00df", "und", "Bach", "die", "Fel\u00b7der", "aus\u00b7ge\u00b7sp\u00fc\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Mondenb\u00fcrger wi\u00dfts, viel besser, wie mich deucht,", "tokens": ["Ihr", "Mon\u00b7den\u00b7b\u00fcr\u00b7ger", "wi\u00dfts", ",", "viel", "bes\u00b7ser", ",", "wie", "mich", "deucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie unsrer Wohnung Bild sich sonst bey euch gezeigt.", "tokens": ["Wie", "uns\u00b7rer", "Woh\u00b7nung", "Bild", "sich", "sonst", "bey", "euch", "ge\u00b7zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "PRF", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Ihr sehts, wie nach und nach in Meeren, Str\u00f6men, L\u00e4ndern,", "tokens": ["Ihr", "sehts", ",", "wie", "nach", "und", "nach", "in", "Mee\u00b7ren", ",", "Str\u00f6\u00b7men", ",", "L\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "APPR", "KON", "APPR", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gestalt und Gr\u00e4nzen sich auf unsrer Kugel \u00e4ndern.", "tokens": ["Ge\u00b7stalt", "und", "Gr\u00e4n\u00b7zen", "sich", "auf", "uns\u00b7rer", "Ku\u00b7gel", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Wo Sodom vormals stund, steht itzt der todte See.", "tokens": ["Wo", "So\u00b7dom", "vor\u00b7mals", "stund", ",", "steht", "itzt", "der", "tod\u00b7te", "See", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "ADJD", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Im Mittelmeere stieg manch Eyland in die H\u00f6h.", "tokens": ["Im", "Mit\u00b7tel\u00b7mee\u00b7re", "stieg", "manch", "Ey\u00b7land", "in", "die", "H\u00f6h", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Trinakrien ward einst von W\u00e4lschland abgerissen,", "tokens": ["Tri\u00b7na\u00b7kri\u00b7en", "ward", "einst", "von", "W\u00e4l\u00b7schland", "ab\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und von Britannien will man ein gleiches wissen.", "tokens": ["Und", "von", "Bri\u00b7tan\u00b7ni\u00b7en", "will", "man", "ein", "glei\u00b7ches", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VMFIN", "PIS", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Atlantis sank ins Meer, die\u00df macht uns Plato kund:", "tokens": ["At\u00b7lan\u00b7tis", "sank", "ins", "Meer", ",", "die\u00df", "macht", "uns", "Pla\u00b7to", "kund", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$,", "PDS", "VVFIN", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Schweiz verschlang so Stadt als Berg ein Schlund.", "tokens": ["Und", "in", "der", "Schweiz", "ver\u00b7schlang", "so", "Stadt", "als", "Berg", "ein", "Schlund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NE", "VVFIN", "ADV", "NN", "KOUS", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auf hohen Alpen ist der Fische Rest vorhanden:", "tokens": ["Auf", "ho\u00b7hen", "Al\u00b7pen", "ist", "der", "Fi\u00b7sche", "Rest", "vor\u00b7han\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und neue Berge sind in W\u00e4lschland schon entstanden.", "tokens": ["Und", "neu\u00b7e", "Ber\u00b7ge", "sind", "in", "W\u00e4l\u00b7schland", "schon", "ent\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Wer weis, was diesen Berg, der itzt ein Auge schreckt,", "tokens": ["Wer", "weis", ",", "was", "die\u00b7sen", "Berg", ",", "der", "itzt", "ein", "Au\u00b7ge", "schreckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "PWS", "PDAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Fels, der ewig scheint, noch f\u00fcr ein Schicksal deckt?", "tokens": ["Den", "Fels", ",", "der", "e\u00b7wig", "scheint", ",", "noch", "f\u00fcr", "ein", "Schick\u00b7sal", "deckt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vieleicht wird hier, wo itzt die dicken Wolken stehen,", "tokens": ["Vie\u00b7leicht", "wird", "hier", ",", "wo", "itzt", "die", "di\u00b7cken", "Wol\u00b7ken", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PWAV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dereinst ein schweres Schiff mit vollen Segeln gehen.", "tokens": ["De\u00b7reinst", "ein", "schwe\u00b7res", "Schiff", "mit", "vol\u00b7len", "Se\u00b7geln", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier \u00e4ndert alles sich: nur in der kurzen Zeit,", "tokens": ["Hier", "\u00e4n\u00b7dert", "al\u00b7les", "sich", ":", "nur", "in", "der", "kur\u00b7zen", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "$.", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darinn ein Mensch hier wallt, scheints uns Best\u00e4ndigkeit:", "tokens": ["Da\u00b7rinn", "ein", "Mensch", "hier", "wallt", ",", "scheints", "uns", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So, wie die Motten auch, bevor sie sich verbrennen,", "tokens": ["So", ",", "wie", "die", "Mot\u00b7ten", "auch", ",", "be\u00b7vor", "sie", "sich", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Uns Sterbliche vieleicht, aus Irrthum, ewig nennen.", "tokens": ["Uns", "Sterb\u00b7li\u00b7che", "vie\u00b7leicht", ",", "aus", "Irr\u00b7thum", ",", "e\u00b7wig", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Sagt, die ihr der Natur bestimmtes Schicksal wi\u00dft,", "tokens": ["Sagt", ",", "die", "ihr", "der", "Na\u00b7tur", "be\u00b7stimm\u00b7tes", "Schick\u00b7sal", "wi\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie lange w\u00e4hrt es noch, bis alles eben ist?", "tokens": ["Wie", "lan\u00b7ge", "w\u00e4hrt", "es", "noch", ",", "bis", "al\u00b7les", "e\u00b7ben", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis aller Berge Sand und Staub die See getrunken,", "tokens": ["Bis", "al\u00b7ler", "Ber\u00b7ge", "Sand", "und", "Staub", "die", "See", "ge\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "KON", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und aller Felsen Klump im Boden ist versunken?", "tokens": ["Und", "al\u00b7ler", "Fel\u00b7sen", "Klump", "im", "Bo\u00b7den", "ist", "ver\u00b7sun\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NE", "APPRART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie flach, wie rund, wie sch\u00f6n, wird dann der Erdball seyn!", "tokens": ["Wie", "flach", ",", "wie", "rund", ",", "wie", "sch\u00f6n", ",", "wird", "dann", "der", "Erd\u00b7ball", "seyn", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "VAFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie wenig fragt alsdann der Mensch nach Fels und Stein!", "tokens": ["Wie", "we\u00b7nig", "fragt", "als\u00b7dann", "der", "Mensch", "nach", "Fels", "und", "Stein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auch Gemsen werden dann auf keinen Klippen wohnen,", "tokens": ["Auch", "Gem\u00b7sen", "wer\u00b7den", "dann", "auf", "kei\u00b7nen", "Klip\u00b7pen", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und selbst der J\u00e4ger wird sie mit der Jagd verschonen.", "tokens": ["Und", "selbst", "der", "J\u00e4\u00b7ger", "wird", "sie", "mit", "der", "Jagd", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Ein neues Paradies wird auf der Welt entstehn,", "tokens": ["Ein", "neu\u00b7es", "Pa\u00b7ra\u00b7dies", "wird", "auf", "der", "Welt", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und rings um ihren Ball in ebnen Fluren gehn.", "tokens": ["Und", "rings", "um", "ih\u00b7ren", "Ball", "in", "eb\u00b7nen", "Flu\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gesunde, reine Luft wird sie durchaus umgeben,", "tokens": ["Ge\u00b7sun\u00b7de", ",", "rei\u00b7ne", "Luft", "wird", "sie", "durc\u00b7haus", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und jeder wird so lang als jene V\u00e4ter leben.", "tokens": ["Und", "je\u00b7der", "wird", "so", "lang", "als", "je\u00b7ne", "V\u00e4\u00b7ter", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADJD", "KOKOM", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie vor der S\u00fcndfluth noch, als alles j\u00fcnger war,", "tokens": ["Wie", "vor", "der", "S\u00fcnd\u00b7fluth", "noch", ",", "als", "al\u00b7les", "j\u00fcn\u00b7ger", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die saftige Natur gesundre Kost gebahr:", "tokens": ["Die", "saf\u00b7ti\u00b7ge", "Na\u00b7tur", "ge\u00b7sund\u00b7re", "Kost", "ge\u00b7bahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So wird alsdann die Welt, wo nicht die Schl\u00fcsse tr\u00fcgen,", "tokens": ["So", "wird", "als\u00b7dann", "die", "Welt", ",", "wo", "nicht", "die", "Schl\u00fcs\u00b7se", "tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Viel kr\u00e4ftiger als itzt der Menschen Sinn vergn\u00fcgen.", "tokens": ["Viel", "kr\u00e4f\u00b7ti\u00b7ger", "als", "itzt", "der", "Men\u00b7schen", "Sinn", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Komm, angenehme Zeit! bechleunige den Lauf!", "tokens": ["Komm", ",", "an\u00b7ge\u00b7neh\u00b7me", "Zeit", "!", "bech\u00b7leu\u00b7ni\u00b7ge", "den", "Lauf", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mach alle L\u00e4nder glatt, heb alle H\u00fcgel auf!", "tokens": ["Mach", "al\u00b7le", "L\u00e4n\u00b7der", "glatt", ",", "heb", "al\u00b7le", "H\u00fc\u00b7gel", "auf", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "$,", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sich das Niederland in feuchten Fluren weidet,", "tokens": ["Wie", "sich", "das", "Nie\u00b7der\u00b7land", "in", "feuch\u00b7ten", "Flu\u00b7ren", "wei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unsrer Berge Graus kein einzigmal beneidet.", "tokens": ["Und", "uns\u00b7rer", "Ber\u00b7ge", "Graus", "kein", "ein\u00b7zig\u00b7mal", "be\u00b7nei\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "PIAT", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch du, o Vaterland! hegst Werker solcher Art,", "tokens": ["Auch", "du", ",", "o", "Va\u00b7ter\u00b7land", "!", "hegst", "Wer\u00b7ker", "sol\u00b7cher", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "FM", "NN", "$.", "VVFIN", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die dir der Vorsicht Gunst zum Theil schon aufgespart.", "tokens": ["Die", "dir", "der", "Vor\u00b7sicht", "Gunst", "zum", "Theil", "schon", "auf\u00b7ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "NN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wachsen j\u00e4hrlich zu! du wirst zum Schmuck der Erden,", "tokens": ["Sie", "wach\u00b7sen", "j\u00e4hr\u00b7lich", "zu", "!", "du", "wirst", "zum", "Schmuck", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ehr, als manch andres Land, ein fettes Gosen werden.", "tokens": ["Ehr", ",", "als", "manch", "and\u00b7res", "Land", ",", "ein", "fet\u00b7tes", "Go\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Was seh ich von der H\u00f6h, wo mich der Wagen tr\u00e4gt?", "tokens": ["Was", "seh", "ich", "von", "der", "H\u00f6h", ",", "wo", "mich", "der", "Wa\u00b7gen", "tr\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists nicht der Donaustrom, der sich vor Augen legt?", "tokens": ["Ists", "nicht", "der", "Do\u00b7naus\u00b7trom", ",", "der", "sich", "vor", "Au\u00b7gen", "legt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist das nicht ", "tokens": ["Ist", "das", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PDS", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "O ja! Seyd mir gegr\u00fc\u00dft; ihr beyde habt nichts gleiches!", "tokens": ["O", "ja", "!", "Seyd", "mir", "ge\u00b7gr\u00fc\u00dft", ";", "ihr", "bey\u00b7de", "habt", "nichts", "glei\u00b7ches", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "VAIMP", "PPER", "VVPP", "$.", "PPER", "PIS", "VAFIN", "PIS", "PIS", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Der Deutschen Fl\u00fcsse Haupt, und wahre K\u00f6niginn", "tokens": ["Der", "Deut\u00b7schen", "Fl\u00fcs\u00b7se", "Haupt", ",", "und", "wah\u00b7re", "K\u00f6\u00b7ni\u00b7ginn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Eilt hier getheilt vorbey, und fleu\u00dft ganz stolz dahin,", "tokens": ["Eilt", "hier", "ge\u00b7theilt", "vor\u00b7bey", ",", "und", "fleu\u00dft", "ganz", "stolz", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVPP", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}}, "stanza.29": {"line.1": {"text": "O nimm mich, werther Flu\u00df! und f\u00fchre mich mit dir!", "tokens": ["O", "nimm", "mich", ",", "wert\u00b7her", "Flu\u00df", "!", "und", "f\u00fch\u00b7re", "mich", "mit", "dir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVIMP", "PPER", "$,", "ADJA", "NN", "$.", "KON", "VVFIN", "PRF", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeige mir die Stadt, der Deutschen St\u00e4dte Zier.", "tokens": ["Und", "zei\u00b7ge", "mir", "die", "Stadt", ",", "der", "Deut\u00b7schen", "St\u00e4d\u00b7te", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr weichet auch Paris, und London, wenn sie will.", "tokens": ["Ihr", "wei\u00b7chet", "auch", "Pa\u00b7ris", ",", "und", "Lon\u00b7don", ",", "wenn", "sie", "will", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NE", "$,", "KON", "NE", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedoch, o Muse! schweig, von ihren Wundern still,", "tokens": ["Je\u00b7doch", ",", "o", "Mu\u00b7se", "!", "schweig", ",", "von", "ih\u00b7ren", "Wun\u00b7dern", "still", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "$.", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bis du sie selbst erblickst. Blick auf die nahen Mauren,", "tokens": ["Bis", "du", "sie", "selbst", "er\u00b7blickst", ".", "Blick", "auf", "die", "na\u00b7hen", "Mau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "$.", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Worinnen Freyheit, Recht, und Macht des Reiches dauren.", "tokens": ["Wo\u00b7rin\u00b7nen", "Frey\u00b7heit", ",", "Recht", ",", "und", "Macht", "des", "Rei\u00b7ches", "dau\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Der Deutschen H\u00e4upter Rath und Weisheit herrscht allda!", "tokens": ["Der", "Deut\u00b7schen", "H\u00e4up\u00b7ter", "Rath", "und", "Weis\u00b7heit", "herrscht", "all\u00b7da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So, wie man sonst in Rom den Staat vereinigt sah.", "tokens": ["So", ",", "wie", "man", "sonst", "in", "Rom", "den", "Staat", "ver\u00b7ei\u00b7nigt", "sah", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PIS", "ADV", "APPR", "NE", "ART", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es sind Gesandten hier, bereit in allen F\u00e4llen,", "tokens": ["Es", "sind", "Ge\u00b7sand\u00b7ten", "hier", ",", "be\u00b7reit", "in", "al\u00b7len", "F\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "$,", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der F\u00fcrsten Ansehn, Macht und Rechte darzustellen.", "tokens": ["Der", "F\u00fcrs\u00b7ten", "An\u00b7sehn", ",", "Macht", "und", "Rech\u00b7te", "dar\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr hohen Th\u00fcrme zwar, prangt nur durchs Alterthum:", "tokens": ["Ihr", "ho\u00b7hen", "Th\u00fcr\u00b7me", "zwar", ",", "prangt", "nur", "durchs", "Al\u00b7ter\u00b7thum", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "$,", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein auch dieses schw\u00e4cht nicht eurer W\u00fcrde Ruhm.", "tokens": ["Al\u00b7lein", "auch", "die\u00b7ses", "schw\u00e4cht", "nicht", "eu\u00b7rer", "W\u00fcr\u00b7de", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist doch das Capitol, wie wir in R\u00f6mern lesen,", "tokens": ["Ist", "doch", "das", "Ca\u00b7pi\u00b7tol", ",", "wie", "wir", "in", "R\u00f6\u00b7mern", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch, als es h\u00f6lzern war, das Haupt der Welt gewesen.", "tokens": ["Auch", ",", "als", "es", "h\u00f6l\u00b7zern", "war", ",", "das", "Haupt", "der", "Welt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVINF", "VAFIN", "$,", "ART", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "So willst du mir hinfort noch seltner schreiben?", "tokens": ["So", "willst", "du", "mir", "hin\u00b7fort", "noch", "selt\u00b7ner", "schrei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Victoria! mein Leben, Herz und Licht!", "tokens": ["Vic\u00b7to\u00b7ria", "!", "mein", "Le\u00b7ben", ",", "Herz", "und", "Licht", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PPOSAT", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Soll mir dein Kiel die Antwort schuldig bleiben?", "tokens": ["Soll", "mir", "dein", "Kiel", "die", "Ant\u00b7wort", "schul\u00b7dig", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ach! strafe mich doch so empfindlich nicht!", "tokens": ["Ach", "!", "stra\u00b7fe", "mich", "doch", "so", "emp\u00b7find\u00b7lich", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "ADV", "ADJD", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Was hab ich denn versehen und verbrochen?", "tokens": ["Was", "hab", "ich", "denn", "ver\u00b7se\u00b7hen", "und", "ver\u00b7bro\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verdammst du mich, ohn alle Missethat?", "tokens": ["Ver\u00b7dammst", "du", "mich", ",", "ohn", "al\u00b7le", "Mis\u00b7se\u00b7that", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "KOUI", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Ach ja! mir ist mein Urtheil schon gesprochen,", "tokens": ["Ach", "ja", "!", "mir", "ist", "mein", "Ur\u00b7theil", "schon", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bevor man mir einmal die Schuld genennet hat.", "tokens": ["Be\u00b7vor", "man", "mir", "ein\u00b7mal", "die", "Schuld", "ge\u00b7nen\u00b7net", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+-++-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "Ja, ja! so ists. Ich soll gemartert werden,", "tokens": ["Ja", ",", "ja", "!", "so", "ists", ".", "Ich", "soll", "ge\u00b7mar\u00b7tert", "wer\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "ADV", "VAFIN", "$.", "PPER", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dein eigner Kiel verk\u00fcndigt mir die Pein.", "tokens": ["Dein", "eig\u00b7ner", "Kiel", "ver\u00b7k\u00fcn\u00b7digt", "mir", "die", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fchlt nicht mein Herz schon Kummer und Beschwerden,", "tokens": ["F\u00fchlt", "nicht", "mein", "Herz", "schon", "Kum\u00b7mer", "und", "Be\u00b7schwer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "NN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df ich von dir so weit getrennt mu\u00df seyn?", "tokens": ["Da\u00df", "ich", "von", "dir", "so", "weit", "ge\u00b7trennt", "mu\u00df", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "ADJD", "VVPP", "VMFIN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch nicht genug! Ein Weg von achtzig Meilen", "tokens": ["Doch", "nicht", "ge\u00b7nug", "!", "Ein", "Weg", "von", "acht\u00b7zig", "Mei\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PTKNEG", "ADV", "$.", "ART", "NN", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "L\u00e4\u00dft meinen Trieb noch gar zu stark und neu:", "tokens": ["L\u00e4\u00dft", "mei\u00b7nen", "Trieb", "noch", "gar", "zu", "stark", "und", "neu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ADV", "PTKA", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Drum will man gar, da\u00df auch kein Blatt voll Zeilen", "tokens": ["Drum", "will", "man", "gar", ",", "da\u00df", "auch", "kein", "Blatt", "voll", "Zei\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PIS", "ADV", "$,", "KOUS", "ADV", "PIAT", "NN", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Von deiner sch\u00f6nen Hand sein neuer Zunder sey.", "tokens": ["Von", "dei\u00b7ner", "sch\u00f6\u00b7nen", "Hand", "sein", "neu\u00b7er", "Zun\u00b7der", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "O sch\u00f6nste Hand! mein Labsal und Vergn\u00fcgen!", "tokens": ["O", "sch\u00f6ns\u00b7te", "Hand", "!", "mein", "Lab\u00b7sal", "und", "Ver\u00b7gn\u00fc\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$.", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie froh macht mich ein s\u00fc\u00dfer Brief von dir!", "tokens": ["Wie", "froh", "macht", "mich", "ein", "s\u00fc\u00b7\u00dfer", "Brief", "von", "dir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PRF", "ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Kaum seh ich ihn, so la\u00df ich alles liegen,", "tokens": ["Kaum", "seh", "ich", "ihn", ",", "so", "la\u00df", "ich", "al\u00b7les", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$,", "ADV", "VVIMP", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und k\u00fc\u00df ihn oft mit l\u00fcsterner Begier.", "tokens": ["Und", "k\u00fc\u00df", "ihn", "oft", "mit", "l\u00fcs\u00b7ter\u00b7ner", "Be\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich bebe recht vor sehnlichem Verlangen,", "tokens": ["Ich", "be\u00b7be", "recht", "vor", "sehn\u00b7li\u00b7chem", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "Sein Siegel geht mir stets zu langsam los:", "tokens": ["Sein", "Sie\u00b7gel", "geht", "mir", "stets", "zu", "lang\u00b7sam", "los", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADV", "PTKA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wenn ich ihn zu lesen angefangen,", "tokens": ["Und", "wenn", "ich", "ihn", "zu", "le\u00b7sen", "an\u00b7ge\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "PTKZU", "VVINF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Dann sitz ich, wie mich d\u00fcnkt, dem Gl\u00fccke selbst im Schoo\u00df.", "tokens": ["Dann", "sitz", "ich", ",", "wie", "mich", "d\u00fcnkt", ",", "dem", "Gl\u00fc\u00b7cke", "selbst", "im", "Schoo\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,", "ART", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Da steht kein Wort, das nach der Einfalt schmecket,", "tokens": ["Da", "steht", "kein", "Wort", ",", "das", "nach", "der", "Ein\u00b7falt", "schme\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die M\u00e4nnern wohl sehr oft ein Schandfleck ist:", "tokens": ["Die", "M\u00e4n\u00b7nern", "wohl", "sehr", "oft", "ein", "Schand\u00b7fleck", "ist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Da wird dein Geist mir mehr und mehr entdecket,", "tokens": ["Da", "wird", "dein", "Geist", "mir", "mehr", "und", "mehr", "ent\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPER", "ADV", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Daran du doch ganz unvergleichlich bist.", "tokens": ["Da\u00b7ran", "du", "doch", "ganz", "un\u00b7ver\u00b7gleich\u00b7lich", "bist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein kluger Scherz, ein ernsthaft edles Wesen,", "tokens": ["Ein", "klu\u00b7ger", "Scherz", ",", "ein", "ernst\u00b7haft", "ed\u00b7les", "We\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "W\u00fcrzt \u00fcberall dein witzerf\u00fclltes Wort:", "tokens": ["W\u00fcrzt", "\u00fc\u00b7be\u00b7rall", "dein", "wit\u00b7zer\u00b7f\u00fcll\u00b7tes", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und wann ichs denn wohl zehnmal durchgelesen,", "tokens": ["Und", "wann", "ichs", "denn", "wohl", "zehn\u00b7mal", "durch\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Dann leg ich erst das Blatt, und doch mit M\u00fche, fort.", "tokens": ["Dann", "leg", "ich", "erst", "das", "Blatt", ",", "und", "doch", "mit", "M\u00fc\u00b7he", ",", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,", "KON", "ADV", "APPR", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was denkst du nun, bey diesen stillen Freuden?", "tokens": ["Was", "denkst", "du", "nun", ",", "bey", "die\u00b7sen", "stil\u00b7len", "Freu\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$,", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sprich, Engelskind! misg\u00f6nnst du mir die Lust?", "tokens": ["Sprich", ",", "En\u00b7gels\u00b7kind", "!", "mis\u00b7g\u00f6nnst", "du", "mir", "die", "Lust", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$,", "NN", "$.", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Erk\u00fchnt man sich, die\u00df Gl\u00fccke zu beneiden,", "tokens": ["Er\u00b7k\u00fchnt", "man", "sich", ",", "die\u00df", "Gl\u00fc\u00b7cke", "zu", "be\u00b7nei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "$,", "PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Das einzige, davon ich noch gewu\u00dft?", "tokens": ["Das", "ein\u00b7zi\u00b7ge", ",", "da\u00b7von", "ich", "noch", "ge\u00b7wu\u00dft", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PAV", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "O! sinne nach, ob meiner zarten Liebe", "tokens": ["O", "!", "sin\u00b7ne", "nach", ",", "ob", "mei\u00b7ner", "zar\u00b7ten", "Lie\u00b7be"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PTKVZ", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die Probe nicht zu hart und grausam sey?", "tokens": ["Die", "Pro\u00b7be", "nicht", "zu", "hart", "und", "grau\u00b7sam", "sey", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKA", "ADJD", "KON", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Und mache doch die Neigung deiner Triebe,", "tokens": ["Und", "ma\u00b7che", "doch", "die", "Nei\u00b7gung", "dei\u00b7ner", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Wie deinen muntern Kiel, von diesem Zwange frey.", "tokens": ["Wie", "dei\u00b7nen", "mun\u00b7tern", "Kiel", ",", "von", "die\u00b7sem", "Zwan\u00b7ge", "frey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Jedoch umsonst! Du schreibst es mir im Scherzen,", "tokens": ["Je\u00b7doch", "um\u00b7sonst", "!", "Du", "schreibst", "es", "mir", "im", "Scher\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$.", "PPER", "VVFIN", "PPER", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Du ehrst den Zwang, als eine theure Pflicht:", "tokens": ["Du", "ehrst", "den", "Zwang", ",", "als", "ei\u00b7ne", "theu\u00b7re", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wohlan! so rei\u00df dein Bild noch aus dem Herzen!", "tokens": ["Wo\u00b7hlan", "!", "so", "rei\u00df", "dein", "Bild", "noch", "aus", "dem", "Her\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VVFIN", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn, wie es scheint, auch das g\u00f6nnt man mir nicht.", "tokens": ["Denn", ",", "wie", "es", "scheint", ",", "auch", "das", "g\u00f6nnt", "man", "mir", "nicht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "VVFIN", "$,", "ADV", "PDS", "VVFIN", "PIS", "PPER", "PTKNEG", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ach! merkst du nicht die List bey diesen R\u00e4nken?", "tokens": ["Ach", "!", "merkst", "du", "nicht", "die", "List", "bey", "die\u00b7sen", "R\u00e4n\u00b7ken", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wenn mir dein Kiel nur erstlich seltner schreibt:", "tokens": ["Wenn", "mir", "dein", "Kiel", "nur", "erst\u00b7lich", "selt\u00b7ner", "schreibt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So weis man schon, da\u00df auch im Angedenken,", "tokens": ["So", "weis", "man", "schon", ",", "da\u00df", "auch", "im", "An\u00b7ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "PIS", "ADV", "$,", "KOUS", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Allm\u00e4hlich mir bey dir kein Pl\u00e4tzchen \u00fcbrig bleibt.", "tokens": ["All\u00b7m\u00e4h\u00b7lich", "mir", "bey", "dir", "kein", "Pl\u00e4tz\u00b7chen", "\u00fcb\u00b7rig", "bleibt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "APPR", "PPER", "PIAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}}, "stanza.36": {"line.1": {"text": "Wie man die Glut von stark entbrannten Flammen", "tokens": ["Wie", "man", "die", "Glut", "von", "stark", "ent\u00b7brann\u00b7ten", "Flam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ART", "NN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nicht mit Gewalt auf einmal d\u00e4mpfen kann;", "tokens": ["Nicht", "mit", "Ge\u00b7walt", "auf", "ein\u00b7mal", "d\u00e4mp\u00b7fen", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "APPR", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Hitze dr\u00e4ngt sich destomehr zusammen,", "tokens": ["Die", "Hit\u00b7ze", "dr\u00e4ngt", "sich", "des\u00b7to\u00b7mehr", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und facht sich nur um desto sch\u00e4rfer an:", "tokens": ["Und", "facht", "sich", "nur", "um", "des\u00b7to", "sch\u00e4r\u00b7fer", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch, will man nicht das wilde Feuer hegen,", "tokens": ["Doch", ",", "will", "man", "nicht", "das", "wil\u00b7de", "Feu\u00b7er", "he\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VMFIN", "PIS", "PTKNEG", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "So sucht man ihm die Nahrung zu entziehn;", "tokens": ["So", "sucht", "man", "ihm", "die", "Nah\u00b7rung", "zu", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da wird die Brunst sich von sich selbst schon legen,", "tokens": ["Da", "wird", "die", "Brunst", "sich", "von", "sich", "selbst", "schon", "le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PRF", "APPR", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und leichten Funken gleich in d\u00fcnner Luft entfliehn.", "tokens": ["Und", "leich\u00b7ten", "Fun\u00b7ken", "gleich", "in", "d\u00fcn\u00b7ner", "Luft", "ent\u00b7fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "Erw\u00e4ge die\u00df, o englische Louise!", "tokens": ["Er\u00b7w\u00e4\u00b7ge", "die\u00df", ",", "o", "eng\u00b7li\u00b7sche", "Lou\u00b7i\u00b7se", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und denk einmal auf deine letzte Schrift!", "tokens": ["Und", "denk", "ein\u00b7mal", "auf", "dei\u00b7ne", "letz\u00b7te", "Schrift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie? wenn ich dich auf dein Versprechen wiese,", "tokens": ["Wie", "?", "wenn", "ich", "dich", "auf", "dein", "Ver\u00b7spre\u00b7chen", "wie\u00b7se", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KOUS", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Womit dein Schlu\u00df itzt schlecht zusammen trifft.", "tokens": ["Wo\u00b7mit", "dein", "Schlu\u00df", "itzt", "schlecht", "zu\u00b7sam\u00b7men", "trifft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ADV", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ist das die Huld, die du mir zugeschworen?", "tokens": ["Ist", "das", "die", "Huld", ",", "die", "du", "mir", "zu\u00b7ge\u00b7schwo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ist das die Treu, die du mir zugesagt?", "tokens": ["Ist", "das", "die", "Treu", ",", "die", "du", "mir", "zu\u00b7ge\u00b7sagt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Denn hat dein Wort so bald die Kraft verlohren:", "tokens": ["Denn", "hat", "dein", "Wort", "so", "bald", "die", "Kraft", "ver\u00b7loh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So hast du mich dadurch aufs heftigste geplagt.", "tokens": ["So", "hast", "du", "mich", "da\u00b7durch", "aufs", "hef\u00b7tigs\u00b7te", "ge\u00b7plagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "PAV", "APPRART", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "So schweige dann, und la\u00df mich gar verschmachten;", "tokens": ["So", "schwei\u00b7ge", "dann", ",", "und", "la\u00df", "mich", "gar", "ver\u00b7schmach\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$,", "KON", "VVIMP", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und mache mich zum Opfer deiner Pflicht:", "tokens": ["Und", "ma\u00b7che", "mich", "zum", "Op\u00b7fer", "dei\u00b7ner", "Pflicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Doch willst du mich der Antwort unwerth achten;", "tokens": ["Doch", "willst", "du", "mich", "der", "Ant\u00b7wort", "un\u00b7werth", "ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So schweig ich doch von meiner Sehnsucht nicht.", "tokens": ["So", "schweig", "ich", "doch", "von", "mei\u00b7ner", "Sehn\u00b7sucht", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Bey sp\u00e4ter Nacht will ich dich tr\u00e4umend plagen,", "tokens": ["Bey", "sp\u00e4\u00b7ter", "Nacht", "will", "ich", "dich", "tr\u00e4u\u00b7mend", "pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VMFIN", "PPER", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Im Wachen selbst dir stets vor Augen stehn;", "tokens": ["Im", "Wa\u00b7chen", "selbst", "dir", "stets", "vor", "Au\u00b7gen", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und dich, mein Licht! ohn Unterla\u00df befragen:", "tokens": ["Und", "dich", ",", "mein", "Licht", "!", "ohn", "Un\u00b7ter\u00b7la\u00df", "be\u00b7fra\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPOSAT", "NN", "$.", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "O Grausame! soll ich ohn alle Schuld vergehn?", "tokens": ["O", "Grau\u00b7sa\u00b7me", "!", "soll", "ich", "ohn", "al\u00b7le", "Schuld", "ver\u00b7gehn", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VMFIN", "PPER", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Gehab dich also wohl. Du rauhes Pf\u00e4lzerland!", "tokens": ["Ge\u00b7hab", "dich", "al\u00b7so", "wohl", ".", "Du", "rau\u00b7hes", "Pf\u00e4l\u00b7zer\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "$.", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dein Felsenreicher Grund ist mir nunmehr bekannt:", "tokens": ["Dein", "Fel\u00b7sen\u00b7rei\u00b7cher", "Grund", "ist", "mir", "nun\u00b7mehr", "be\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bekannt, doch auch verha\u00dft. Von deinen harten Steinen", "tokens": ["Be\u00b7kannt", ",", "doch", "auch", "ver\u00b7ha\u00dft", ".", "Von", "dei\u00b7nen", "har\u00b7ten", "Stei\u00b7nen"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "ADV", "ADJD", "$.", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Komm ich, Gott Lob! die\u00dfmal annoch mit ganzen Beinen.", "tokens": ["Komm", "ich", ",", "Gott", "Lob", "!", "die\u00df\u00b7mal", "an\u00b7noch", "mit", "gan\u00b7zen", "Bei\u00b7nen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "NN", "NN", "$.", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du, hohler Wege Schlund; du, steiler Berge Graus,", "tokens": ["Du", ",", "hoh\u00b7ler", "We\u00b7ge", "Schlund", ";", "du", ",", "stei\u00b7ler", "Ber\u00b7ge", "Graus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "NN", "$.", "PPER", "$,", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du, dicker W\u00e4lder Wust, du, kalter Winde Straus,", "tokens": ["Du", ",", "di\u00b7cker", "W\u00e4l\u00b7der", "Wust", ",", "du", ",", "kal\u00b7ter", "Win\u00b7de", "Straus", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "NN", "$,", "PPER", "$,", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der du best\u00e4ndig scheinst, dem Sommer Trotz zu biethen,", "tokens": ["Der", "du", "be\u00b7st\u00e4n\u00b7dig", "scheinst", ",", "dem", "Som\u00b7mer", "Trotz", "zu", "bie\u00b7then", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Der Himmel wird vor euch mich k\u00fcnftig wohl beh\u00fcten.", "tokens": ["Der", "Him\u00b7mel", "wird", "vor", "euch", "mich", "k\u00fcnf\u00b7tig", "wohl", "be\u00b7h\u00fc\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "PPER", "PRF", "ADJD", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Begl\u00fccktes Vaterland! das mich zur Welt gebahr,", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Va\u00b7ter\u00b7land", "!", "das", "mich", "zur", "Welt", "ge\u00b7bahr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gepriesne Mei\u00dfnerflur! wo ich l\u00e4ngst B\u00fcrger war,", "tokens": ["Ge\u00b7pri\u00b7es\u00b7ne", "Mei\u00df\u00b7ner\u00b7flur", "!", "wo", "ich", "l\u00e4ngst", "B\u00fcr\u00b7ger", "war", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "PPER", "ADV", "NN", "VAFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ihr kennt die Plagen nicht, die uns allhier betreffen,", "tokens": ["Ihr", "kennt", "die", "Pla\u00b7gen", "nicht", ",", "die", "uns", "all\u00b7hier", "be\u00b7tref\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn Berg und Th\u00e4ler uns auf langen Reisen \u00e4ffen.", "tokens": ["Wenn", "Berg", "und", "Th\u00e4\u00b7ler", "uns", "auf", "lan\u00b7gen", "Rei\u00b7sen", "\u00e4f\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bald steig ich Himmel an, wie, wider die Natur", "tokens": ["Bald", "steig", "ich", "Him\u00b7mel", "an", ",", "wie", ",", "wi\u00b7der", "die", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "PWAV", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Elias von der Welt mit Feuerrossen fuhr;", "tokens": ["E\u00b7lias", "von", "der", "Welt", "mit", "Feu\u00b7er\u00b7ros\u00b7sen", "fuhr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Bald aber senk ich mich, wie Phaeton, hinwieder,", "tokens": ["Bald", "a\u00b7ber", "senk", "ich", "mich", ",", "wie", "Phae\u00b7ton", ",", "hin\u00b7wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "PRF", "$,", "PWAV", "NE", "$,", "ADV", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Doch ohne mein Vergehn, in tiefe Gr\u00fcnde nieder.", "tokens": ["Doch", "oh\u00b7ne", "mein", "Ver\u00b7gehn", ",", "in", "tie\u00b7fe", "Gr\u00fcn\u00b7de", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.41": {"line.1": {"text": "So weit mein Auge tr\u00e4gt, erblick ich Stein und Wald,", "tokens": ["So", "weit", "mein", "Au\u00b7ge", "tr\u00e4gt", ",", "er\u00b7blick", "ich", "Stein", "und", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPOSAT", "NN", "VVFIN", "$,", "VVIMP", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein w\u00fcstes, rauhes Land, der Faunen Aufenthalt;", "tokens": ["Ein", "w\u00fcs\u00b7tes", ",", "rau\u00b7hes", "Land", ",", "der", "Fau\u00b7nen", "Auf\u00b7ent\u00b7halt", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo kein gesittet Volk in sch\u00f6nen St\u00e4dten hauset,", "tokens": ["Wo", "kein", "ge\u00b7sit\u00b7tet", "Volk", "in", "sch\u00f6\u00b7nen", "St\u00e4d\u00b7ten", "hau\u00b7set", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "VVPP", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo, statt der Musen, Pan auf heischern R\u00f6hren brauset.", "tokens": ["Wo", ",", "statt", "der", "Mu\u00b7sen", ",", "Pan", "auf", "hei\u00b7schern", "R\u00f6h\u00b7ren", "brau\u00b7set", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUI", "ART", "NN", "$,", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Apollo wich mit Flei\u00df aus dieser frechen Flur,", "tokens": ["A\u00b7pol\u00b7lo", "wich", "mit", "Flei\u00df", "aus", "die\u00b7ser", "fre\u00b7chen", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Warum? sie wies ihm nicht die Sch\u00f6nheit der Natur.", "tokens": ["Wa\u00b7rum", "?", "sie", "wies", "ihm", "nicht", "die", "Sch\u00f6n\u00b7heit", "der", "Na\u00b7tur", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie ist der Schreibart gleich, die von den Alpen stammet,", "tokens": ["Sie", "ist", "der", "Schrei\u00b7bart", "gleich", ",", "die", "von", "den", "Al\u00b7pen", "stam\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Rauh, h\u00f6ckricht, hart und steif; wie er sie stets verdammet.", "tokens": ["Rauh", ",", "h\u00f6c\u00b7kricht", ",", "hart", "und", "steif", ";", "wie", "er", "sie", "stets", "ver\u00b7dam\u00b7met", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "ADJD", "KON", "ADJD", "$.", "PWAV", "PPER", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "Was ist der Boden hier? Ein unfruchtbarer Thon,", "tokens": ["Was", "ist", "der", "Bo\u00b7den", "hier", "?", "Ein", "un\u00b7frucht\u00b7ba\u00b7rer", "Thon", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "ADV", "$.", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Gras und Kr\u00e4uter ha\u00dft. Das Unkraut flieht ihn schon!", "tokens": ["Der", "Gras", "und", "Kr\u00e4u\u00b7ter", "ha\u00dft", ".", "Das", "Un\u00b7kraut", "flieht", "ihn", "schon", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein schlechter Distelbusch und scharfe Dornenhecken,", "tokens": ["Ein", "schlech\u00b7ter", "Dis\u00b7tel\u00b7busch", "und", "schar\u00b7fe", "Dor\u00b7nen\u00b7he\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ja, Schleeen wollen kaum den \u00f6den Grund bedecken.", "tokens": ["Ja", ",", "Schlee\u00b7en", "wol\u00b7len", "kaum", "den", "\u00f6\u00b7den", "Grund", "be\u00b7de\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VMFIN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der arme Landmann pfl\u00fcgt des Landes mildern Theil;", "tokens": ["Der", "ar\u00b7me", "Land\u00b7mann", "pfl\u00fcgt", "des", "Lan\u00b7des", "mil\u00b7dern", "Theil", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein die Pflugschaar f\u00fchlts, und st\u00fcmpfet sich in Eil.", "tokens": ["Al\u00b7lein", "die", "Pflug\u00b7schaar", "f\u00fchlts", ",", "und", "st\u00fcmp\u00b7fet", "sich", "in", "Eil", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Man sieht den Acker kaum vor umgest\u00fcrzten Steinen,", "tokens": ["Man", "sieht", "den", "A\u00b7cker", "kaum", "vor", "um\u00b7ge\u00b7st\u00fcrz\u00b7ten", "Stei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als sollte noch einmal Deukalion erscheinen.", "tokens": ["Als", "soll\u00b7te", "noch", "ein\u00b7mal", "Deu\u00b7ka\u00b7li\u00b7on", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "ADV", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "O k\u00e4m er doch nur bald! und Pyrrha noch dazu,", "tokens": ["O", "k\u00e4m", "er", "doch", "nur", "bald", "!", "und", "Pyrr\u00b7ha", "noch", "da\u00b7zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "ADV", "$.", "KON", "NE", "ADV", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und br\u00e4chte jeden Stein aus der zu langen Ruh,", "tokens": ["Und", "br\u00e4ch\u00b7te", "je\u00b7den", "Stein", "aus", "der", "zu", "lan\u00b7gen", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "APPR", "ART", "PTKZU", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und w\u00fcrf ihn hinter sich, der Menschen Zahl zu mehren:", "tokens": ["Und", "w\u00fcrf", "ihn", "hin\u00b7ter", "sich", ",", "der", "Men\u00b7schen", "Zahl", "zu", "meh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PRF", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00fcrde doch die\u00df Land von neuen B\u00fcrgern h\u00f6ren.", "tokens": ["So", "w\u00fcr\u00b7de", "doch", "die\u00df", "Land", "von", "neu\u00b7en", "B\u00fcr\u00b7gern", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PDS", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch leider! ist die\u00df Paar ins Fabelreich versenkt;", "tokens": ["Doch", "lei\u00b7der", "!", "ist", "die\u00df", "Paar", "ins", "Fa\u00b7bel\u00b7reich", "ver\u00b7senkt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "VAFIN", "PDS", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Himmel hat es nicht der neuern Zeit geschenkt.", "tokens": ["Der", "Him\u00b7mel", "hat", "es", "nicht", "der", "neu\u00b7ern", "Zeit", "ge\u00b7schenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist fast nichts seltsamers, als der Bewohner Spuren.", "tokens": ["Ist", "fast", "nichts", "selt\u00b7sa\u00b7mers", ",", "als", "der", "Be\u00b7woh\u00b7ner", "Spu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "ADV", "$,", "KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}}, "stanza.44": {"line.1": {"text": "Kein Hirsch, kein feiges Reh, durchstreicht das freye Feld,", "tokens": ["Kein", "Hirsch", ",", "kein", "fei\u00b7ges", "Reh", ",", "durch\u00b7streicht", "das", "frey\u00b7e", "Feld", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "ADJA", "NN", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kein Vogel nistet hier, dem jemand Netze stellt.", "tokens": ["Kein", "Vo\u00b7gel", "nis\u00b7tet", "hier", ",", "dem", "je\u00b7mand", "Net\u00b7ze", "stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "$,", "PRELS", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die S\u00e4ue w\u00fchlen nur, und wenig hagern Ziegen", "tokens": ["Die", "S\u00e4u\u00b7e", "w\u00fch\u00b7len", "nur", ",", "und", "we\u00b7nig", "ha\u00b7gern", "Zie\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "KON", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Thun d\u00fcrre Heiden kaum mit karger Kost ein Gn\u00fcgen.", "tokens": ["Thun", "d\u00fcr\u00b7re", "Hei\u00b7den", "kaum", "mit", "kar\u00b7ger", "Kost", "ein", "Gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "ADV", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein lumpicht Bettelvolk f\u00fcllt alle Stra\u00dfen an,", "tokens": ["Ein", "lum\u00b7picht", "Bet\u00b7tel\u00b7volk", "f\u00fcllt", "al\u00b7le", "Stra\u00b7\u00dfen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Vor dem ein Reisender sich kaum noch retten kan;", "tokens": ["Vor", "dem", "ein", "Rei\u00b7sen\u00b7der", "sich", "kaum", "noch", "ret\u00b7ten", "kan", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PRF", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn die\u00df Zigeunerpack mit Weib und Kindern l\u00e4rmet,", "tokens": ["Wenn", "die\u00df", "Zi\u00b7geu\u00b7ner\u00b7pack", "mit", "Weib", "und", "Kin\u00b7dern", "l\u00e4r\u00b7met", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und wilden Hummeln gleich um Pferd und Kutsche schw\u00e4rmet.", "tokens": ["Und", "wil\u00b7den", "Hum\u00b7meln", "gleich", "um", "Pferd", "und", "Kut\u00b7sche", "schw\u00e4r\u00b7met", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Ists Faulheit, die die\u00df Volk zum Bettelstabe treibt?", "tokens": ["Ists", "Faul\u00b7heit", ",", "die", "die\u00df", "Volk", "zum", "Bet\u00b7tel\u00b7sta\u00b7be", "treibt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "PDS", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists Unart, die so gern beym M\u00fc\u00dfiggange bleibt?", "tokens": ["Ists", "Un\u00b7art", ",", "die", "so", "gern", "beym", "M\u00fc\u00b7\u00dfig\u00b7gan\u00b7ge", "bleibt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PRELS", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo nicht, so ist es doch ein Schimpf der Policeyen,", "tokens": ["Wo", "nicht", ",", "so", "ist", "es", "doch", "ein", "Schimpf", "der", "Po\u00b7li\u00b7ce\u00b7yen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Die solch Gesindel nicht durch ihr Verboth zerstreuen.", "tokens": ["Die", "solch", "Ge\u00b7sin\u00b7del", "nicht", "durch", "ihr", "Ver\u00b7both", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein Zucht- und Arbeithaus vertreibt die Krankheit leicht,", "tokens": ["Ein", "Zucht", "und", "Ar\u00b7beit\u00b7haus", "ver\u00b7treibt", "die", "Krank\u00b7heit", "leicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die mancher Obrigkeit so gar unheilbar deucht.", "tokens": ["Die", "man\u00b7cher", "Ob\u00b7rig\u00b7keit", "so", "gar", "un\u00b7heil\u00b7bar", "deucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die ganze Staaten schimpft, und Fremden, die da reisen,", "tokens": ["Die", "gan\u00b7ze", "Staa\u00b7ten", "schimpft", ",", "und", "Frem\u00b7den", ",", "die", "da", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "KON", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nur Elend, Angst und Noth des Landes pflegt zu weisen.", "tokens": ["Nur", "E\u00b7lend", ",", "Angst", "und", "Noth", "des", "Lan\u00b7des", "pflegt", "zu", "wei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Behauptet, wie ihr wollt, ihr Weisen neuer Zeit,", "tokens": ["Be\u00b7haup\u00b7tet", ",", "wie", "ihr", "wollt", ",", "ihr", "Wei\u00b7sen", "neu\u00b7er", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VMFIN", "$,", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die\u00df sey die beste Welt, nach sch\u00e4rfster M\u00f6glichkeit.", "tokens": ["Die\u00df", "sey", "die", "bes\u00b7te", "Welt", ",", "nach", "sch\u00e4rfs\u00b7ter", "M\u00f6g\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bevor ihr dieses lehrt, (so dacht ich oft mit Flehen)", "tokens": ["Be\u00b7vor", "ihr", "die\u00b7ses", "lehrt", ",", "(", "so", "dacht", "ich", "oft", "mit", "Fle\u00b7hen", ")"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "$,", "$(", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "M\u00fc\u00dft ihr ein armes Land voll Berg und Bettler sehen.", "tokens": ["M\u00fc\u00dft", "ihr", "ein", "ar\u00b7mes", "Land", "voll", "Berg", "und", "Bett\u00b7ler", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kommt, seht nur erst allhier die wilden Klippen stehn,", "tokens": ["Kommt", ",", "seht", "nur", "erst", "all\u00b7hier", "die", "wil\u00b7den", "Klip\u00b7pen", "stehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADV", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und Felsen mit der Stirn bis in die Wolken gehn.", "tokens": ["Und", "Fel\u00b7sen", "mit", "der", "Stirn", "bis", "in", "die", "Wol\u00b7ken", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kommt, seht nur hin und her, die schlecht bewohnten Th\u00e4ler,", "tokens": ["Kommt", ",", "seht", "nur", "hin", "und", "her", ",", "die", "schlecht", "be\u00b7wohn\u00b7ten", "Th\u00e4\u00b7ler", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "ADV", "PTKVZ", "KON", "PTKVZ", "$,", "PRELS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So sprecht ihr Zweifelsfrey: Die Welt ist voller Fehler!", "tokens": ["So", "sprecht", "ihr", "Zwei\u00b7fels\u00b7frey", ":", "Die", "Welt", "ist", "vol\u00b7ler", "Feh\u00b7ler", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "ART", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Wiewohl! so dacht ich nur aus Wahn und Ungeduld;", "tokens": ["Wie\u00b7wohl", "!", "so", "dacht", "ich", "nur", "aus", "Wahn", "und", "Un\u00b7ge\u00b7duld", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$.", "ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dich, Sch\u00f6pffer der Natur! betrifft hier keine Schuld!", "tokens": ["Dich", ",", "Sch\u00f6pf\u00b7fer", "der", "Na\u00b7tur", "!", "be\u00b7tr\u00b7ifft", "hier", "kei\u00b7ne", "Schuld", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "ART", "NN", "$.", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dem Weltbau mangelt nichts an Sch\u00f6nheit im Verbinden,", "tokens": ["Dem", "Welt\u00b7bau", "man\u00b7gelt", "nichts", "an", "Sch\u00f6n\u00b7heit", "im", "Ver\u00b7bin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ist in den Theilen gleich was fehlerhafts zu finden.", "tokens": ["Ist", "in", "den", "Thei\u00b7len", "gleich", "was", "feh\u00b7ler\u00b7hafts", "zu", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "ADV", "PWS", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der steilen Berge Reih, die Deutschlands Mitte trennt,", "tokens": ["Der", "stei\u00b7len", "Ber\u00b7ge", "Reih", ",", "die", "Deutschlands", "Mit\u00b7te", "trennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und Vogtland, Frankenland und Oberpfalz durchrennt,", "tokens": ["Und", "Vogt\u00b7land", ",", "Fran\u00b7ken\u00b7land", "und", "O\u00b7berp\u00b7falz", "durch\u00b7rennt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist unser Wasserschatz, daraus die B\u00e4che rinnen,", "tokens": ["Ist", "un\u00b7ser", "Was\u00b7ser\u00b7schatz", ",", "da\u00b7raus", "die", "B\u00e4\u00b7che", "rin\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wodurch so mancher Strom sein Wesen mu\u00df gewinnen.", "tokens": ["Wo\u00b7durch", "so", "man\u00b7cher", "Strom", "sein", "We\u00b7sen", "mu\u00df", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "PPOSAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "So sah ich, wo zuerst der Plei\u00dfenstrom entspringt;", "tokens": ["So", "sah", "ich", ",", "wo", "zu\u00b7erst", "der", "Plei\u00b7\u00dfen\u00b7strom", "ent\u00b7springt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich sah der Elster Brunn, die Mei\u00dfens Flur durchschlingt;", "tokens": ["Ich", "sah", "der", "Els\u00b7ter", "Brunn", ",", "die", "Mei\u00b7\u00dfens", "Flur", "durch\u00b7schlingt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich sah der Mulden Strom in seinen ersten Quellen,", "tokens": ["Ich", "sah", "der", "Mul\u00b7den", "Strom", "in", "sei\u00b7nen", "ers\u00b7ten", "Quel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Nordw\u00e4rts ihren Lauf gewohnt sind fortzustellen.", "tokens": ["Die", "Nord\u00b7w\u00e4rts", "ih\u00b7ren", "Lauf", "ge\u00b7wohnt", "sind", "fort\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVPP", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich sah den Egerflu\u00df zum Eibstrom Ostw\u00e4rts gehn,", "tokens": ["Ich", "sah", "den", "E\u00b7ger\u00b7flu\u00df", "zum", "Eib\u00b7strom", "Ost\u00b7w\u00e4rts", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und so, wie Saal und Mayn am Fichtelberg entstehn:", "tokens": ["Und", "so", ",", "wie", "Saal", "und", "Mayn", "am", "Fich\u00b7tel\u00b7berg", "ent\u00b7stehn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "NN", "KON", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hier quillt die Pegnitz auch, und S\u00fcdw\u00e4rts eilt die Naabe", "tokens": ["Hier", "quillt", "die", "Peg\u00b7nitz", "auch", ",", "und", "S\u00fcd\u00b7w\u00e4rts", "eilt", "die", "Naa\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,", "KON", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zum gro\u00dfen Donaustrom, als ihrem nassen Grabe.", "tokens": ["Zum", "gro\u00b7\u00dfen", "Do\u00b7naus\u00b7trom", ",", "als", "ih\u00b7rem", "nas\u00b7sen", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Wo bleibt noch ausser dem, der kleinern Fl\u00fcsse Zahl,", "tokens": ["Wo", "bleibt", "noch", "aus\u00b7ser", "dem", ",", "der", "klei\u00b7nern", "Fl\u00fcs\u00b7se", "Zahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "APPR", "ART", "$,", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die jeder Berg erzeugt, womit fast jedes Thal", "tokens": ["Die", "je\u00b7der", "Berg", "er\u00b7zeugt", ",", "wo\u00b7mit", "fast", "je\u00b7des", "Thal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VVPP", "$,", "PWAV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier angeschw\u00e4ngert wird, die sich vom Nebel n\u00e4hren,", "tokens": ["Hier", "an\u00b7ge\u00b7schw\u00e4n\u00b7gert", "wird", ",", "die", "sich", "vom", "Ne\u00b7bel", "n\u00e4h\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$,", "PRELS", "PRF", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und von des Thaues Na\u00df, den Stein und Fels nicht zehren.", "tokens": ["Und", "von", "des", "Thau\u00b7es", "Na\u00df", ",", "den", "Stein", "und", "Fels", "nicht", "zeh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$,", "ART", "NN", "KON", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch f\u00e4llt ein Regengu\u00df, so schwillt die kleine Fluth,", "tokens": ["Doch", "f\u00e4llt", "ein", "Re\u00b7gen\u00b7gu\u00df", ",", "so", "schwillt", "die", "klei\u00b7ne", "Fluth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Rei\u00dft Sand und Steine mit, der nahen Berge Brut;", "tokens": ["Rei\u00dft", "Sand", "und", "Stei\u00b7ne", "mit", ",", "der", "na\u00b7hen", "Ber\u00b7ge", "Brut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und treibt den feuchten Zoll nach L\u00e4ndern, D\u00f6rfern, St\u00e4dten,", "tokens": ["Und", "treibt", "den", "feuch\u00b7ten", "Zoll", "nach", "L\u00e4n\u00b7dern", ",", "D\u00f6r\u00b7fern", ",", "St\u00e4d\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die t\u00e4glich um des Stroms erw\u00fcnschten Zuflu\u00df bethen.", "tokens": ["Die", "t\u00e4g\u00b7lich", "um", "des", "Stroms", "er\u00b7w\u00fcnschten", "Zu\u00b7flu\u00df", "be\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "So bleibt die Vorsicht auch bey scheinbarn M\u00e4ngeln gro\u00df:", "tokens": ["So", "bleibt", "die", "Vor\u00b7sicht", "auch", "bey", "schein\u00b7barn", "M\u00e4n\u00b7geln", "gro\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+++-+-+", "measure": "unknown.measure.septa"}, "line.2": {"text": "Ein Weiser spricht sie stets von allen Fehlern los.", "tokens": ["Ein", "Wei\u00b7ser", "spricht", "sie", "stets", "von", "al\u00b7len", "Feh\u00b7lern", "los", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nur Thoren tadeln gern, was ihrer Einsicht weichet,", "tokens": ["Nur", "Tho\u00b7ren", "ta\u00b7deln", "gern", ",", "was", "ih\u00b7rer", "Ein\u00b7sicht", "wei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "ADV", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohl dem, der forschend einst des Sch\u00f6pfers Spur erreichet!", "tokens": ["Wohl", "dem", ",", "der", "for\u00b7schend", "einst", "des", "Sch\u00f6p\u00b7fers", "Spur", "er\u00b7rei\u00b7chet", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$,", "PRELS", "ADJD", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die W\u00fcsten f\u00f6rdern selbst der h\u00f6chsten Weisheit Ziel,", "tokens": ["Die", "W\u00fcs\u00b7ten", "f\u00f6r\u00b7dern", "selbst", "der", "h\u00f6chs\u00b7ten", "Weis\u00b7heit", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie bleibt an Wundern reich, und treibt ihr altes Spiel,", "tokens": ["Sie", "bleibt", "an", "Wun\u00b7dern", "reich", ",", "und", "treibt", "ihr", "al\u00b7tes", "Spiel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJD", "$,", "KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn sie besch\u00e4ftigt ist, auch in verborgnen Wegen,", "tokens": ["Wenn", "sie", "be\u00b7sch\u00e4f\u00b7tigt", "ist", ",", "auch", "in", "ver\u00b7borg\u00b7nen", "We\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den Sterblichen zum Nutz, ihr Absehn darzulegen.", "tokens": ["Den", "Sterb\u00b7li\u00b7chen", "zum", "Nutz", ",", "ihr", "Ab\u00b7sehn", "dar\u00b7zu\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "PPOSAT", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Und wie? wohin verschickt ein hochgebirgigt Land", "tokens": ["Und", "wie", "?", "wo\u00b7hin", "ver\u00b7schickt", "ein", "hoch\u00b7ge\u00b7bir\u00b7gigt", "Land"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "$.", "PWAV", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch manchen Wolkengu\u00df und Schneegang Erd und Sand?", "tokens": ["Durch", "man\u00b7chen", "Wol\u00b7ken\u00b7gu\u00df", "und", "Schnee\u00b7gang", "Erd", "und", "Sand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die B\u00e4che zehren stets an den erweichten H\u00fcgeln,", "tokens": ["Die", "B\u00e4\u00b7che", "zeh\u00b7ren", "stets", "an", "den", "er\u00b7weich\u00b7ten", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-----+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Bis nackte Felsen sich in ihren Fluthen spiegeln.", "tokens": ["Bis", "nack\u00b7te", "Fel\u00b7sen", "sich", "in", "ih\u00b7ren", "Flut\u00b7hen", "spie\u00b7geln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo bleibt nun der Verlust, der niemals sich ersetzt?", "tokens": ["Wo", "bleibt", "nun", "der", "Ver\u00b7lust", ",", "der", "nie\u00b7mals", "sich", "er\u00b7setzt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er geht in Str\u00f6men fort, bis ihren Raub zuletzt", "tokens": ["Er", "geht", "in", "Str\u00f6\u00b7men", "fort", ",", "bis", "ih\u00b7ren", "Raub", "zu\u00b7letzt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$,", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die weite See empf\u00e4ngt, die ihn an Ufer schwemmet,", "tokens": ["Die", "wei\u00b7te", "See", "emp\u00b7f\u00e4ngt", ",", "die", "ihn", "an", "U\u00b7fer", "schwem\u00b7met", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Manch neues Eyland macht, und seichte K\u00fcsten d\u00e4mmet.", "tokens": ["Manch", "neu\u00b7es", "Ey\u00b7land", "macht", ",", "und", "seich\u00b7te", "K\u00fcs\u00b7ten", "d\u00e4m\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.52": {"line.1": {"text": "O k\u00f6nnt ich die Gestalt des ganzen Erdballs sehn,", "tokens": ["O", "k\u00f6nnt", "ich", "die", "Ge\u00b7stalt", "des", "gan\u00b7zen", "Erd\u00b7balls", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bevor so mancher Ri\u00df in seinen Grund geschehn!", "tokens": ["Be\u00b7vor", "so", "man\u00b7cher", "Ri\u00df", "in", "sei\u00b7nen", "Grund", "ge\u00b7schehn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Eh manche Wasserfluth den Boden durchgew\u00fchlet,", "tokens": ["Eh", "man\u00b7che", "Was\u00b7ser\u00b7fluth", "den", "Bo\u00b7den", "durch\u00b7ge\u00b7w\u00fch\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Eh Regen, Flu\u00df und Bach die Felder ausgesp\u00fclet.", "tokens": ["Eh", "Re\u00b7gen", ",", "Flu\u00df", "und", "Bach", "die", "Fel\u00b7der", "aus\u00b7ge\u00b7sp\u00fc\u00b7let", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr Mondenb\u00fcrger wi\u00dfts, viel besser, wie mich deucht,", "tokens": ["Ihr", "Mon\u00b7den\u00b7b\u00fcr\u00b7ger", "wi\u00dfts", ",", "viel", "bes\u00b7ser", ",", "wie", "mich", "deucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie unsrer Wohnung Bild sich sonst bey euch gezeigt.", "tokens": ["Wie", "uns\u00b7rer", "Woh\u00b7nung", "Bild", "sich", "sonst", "bey", "euch", "ge\u00b7zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "PRF", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.7": {"text": "Ihr sehts, wie nach und nach in Meeren, Str\u00f6men, L\u00e4ndern,", "tokens": ["Ihr", "sehts", ",", "wie", "nach", "und", "nach", "in", "Mee\u00b7ren", ",", "Str\u00f6\u00b7men", ",", "L\u00e4n\u00b7dern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "APPR", "KON", "APPR", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gestalt und Gr\u00e4nzen sich auf unsrer Kugel \u00e4ndern.", "tokens": ["Ge\u00b7stalt", "und", "Gr\u00e4n\u00b7zen", "sich", "auf", "uns\u00b7rer", "Ku\u00b7gel", "\u00e4n\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Wo Sodom vormals stund, steht itzt der todte See.", "tokens": ["Wo", "So\u00b7dom", "vor\u00b7mals", "stund", ",", "steht", "itzt", "der", "tod\u00b7te", "See", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "ADJD", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Im Mittelmeere stieg manch Eyland in die H\u00f6h.", "tokens": ["Im", "Mit\u00b7tel\u00b7mee\u00b7re", "stieg", "manch", "Ey\u00b7land", "in", "die", "H\u00f6h", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Trinakrien ward einst von W\u00e4lschland abgerissen,", "tokens": ["Tri\u00b7na\u00b7kri\u00b7en", "ward", "einst", "von", "W\u00e4l\u00b7schland", "ab\u00b7ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und von Britannien will man ein gleiches wissen.", "tokens": ["Und", "von", "Bri\u00b7tan\u00b7ni\u00b7en", "will", "man", "ein", "glei\u00b7ches", "wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VMFIN", "PIS", "ART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Atlantis sank ins Meer, die\u00df macht uns Plato kund:", "tokens": ["At\u00b7lan\u00b7tis", "sank", "ins", "Meer", ",", "die\u00df", "macht", "uns", "Pla\u00b7to", "kund", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$,", "PDS", "VVFIN", "PPER", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und in der Schweiz verschlang so Stadt als Berg ein Schlund.", "tokens": ["Und", "in", "der", "Schweiz", "ver\u00b7schlang", "so", "Stadt", "als", "Berg", "ein", "Schlund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NE", "VVFIN", "ADV", "NN", "KOUS", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auf hohen Alpen ist der Fische Rest vorhanden:", "tokens": ["Auf", "ho\u00b7hen", "Al\u00b7pen", "ist", "der", "Fi\u00b7sche", "Rest", "vor\u00b7han\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und neue Berge sind in W\u00e4lschland schon entstanden.", "tokens": ["Und", "neu\u00b7e", "Ber\u00b7ge", "sind", "in", "W\u00e4l\u00b7schland", "schon", "ent\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VAFIN", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Wer weis, was diesen Berg, der itzt ein Auge schreckt,", "tokens": ["Wer", "weis", ",", "was", "die\u00b7sen", "Berg", ",", "der", "itzt", "ein", "Au\u00b7ge", "schreckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "PWS", "PDAT", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den Fels, der ewig scheint, noch f\u00fcr ein Schicksal deckt?", "tokens": ["Den", "Fels", ",", "der", "e\u00b7wig", "scheint", ",", "noch", "f\u00fcr", "ein", "Schick\u00b7sal", "deckt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Vieleicht wird hier, wo itzt die dicken Wolken stehen,", "tokens": ["Vie\u00b7leicht", "wird", "hier", ",", "wo", "itzt", "die", "di\u00b7cken", "Wol\u00b7ken", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "$,", "PWAV", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dereinst ein schweres Schiff mit vollen Segeln gehen.", "tokens": ["De\u00b7reinst", "ein", "schwe\u00b7res", "Schiff", "mit", "vol\u00b7len", "Se\u00b7geln", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hier \u00e4ndert alles sich: nur in der kurzen Zeit,", "tokens": ["Hier", "\u00e4n\u00b7dert", "al\u00b7les", "sich", ":", "nur", "in", "der", "kur\u00b7zen", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PRF", "$.", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darinn ein Mensch hier wallt, scheints uns Best\u00e4ndigkeit:", "tokens": ["Da\u00b7rinn", "ein", "Mensch", "hier", "wallt", ",", "scheints", "uns", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So, wie die Motten auch, bevor sie sich verbrennen,", "tokens": ["So", ",", "wie", "die", "Mot\u00b7ten", "auch", ",", "be\u00b7vor", "sie", "sich", "ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "ADV", "$,", "KOUS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Uns Sterbliche vieleicht, aus Irrthum, ewig nennen.", "tokens": ["Uns", "Sterb\u00b7li\u00b7che", "vie\u00b7leicht", ",", "aus", "Irr\u00b7thum", ",", "e\u00b7wig", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "APPR", "NN", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Sagt, die ihr der Natur bestimmtes Schicksal wi\u00dft,", "tokens": ["Sagt", ",", "die", "ihr", "der", "Na\u00b7tur", "be\u00b7stimm\u00b7tes", "Schick\u00b7sal", "wi\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie lange w\u00e4hrt es noch, bis alles eben ist?", "tokens": ["Wie", "lan\u00b7ge", "w\u00e4hrt", "es", "noch", ",", "bis", "al\u00b7les", "e\u00b7ben", "ist", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Bis aller Berge Sand und Staub die See getrunken,", "tokens": ["Bis", "al\u00b7ler", "Ber\u00b7ge", "Sand", "und", "Staub", "die", "See", "ge\u00b7trun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "KON", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und aller Felsen Klump im Boden ist versunken?", "tokens": ["Und", "al\u00b7ler", "Fel\u00b7sen", "Klump", "im", "Bo\u00b7den", "ist", "ver\u00b7sun\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NE", "APPRART", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie flach, wie rund, wie sch\u00f6n, wird dann der Erdball seyn!", "tokens": ["Wie", "flach", ",", "wie", "rund", ",", "wie", "sch\u00f6n", ",", "wird", "dann", "der", "Erd\u00b7ball", "seyn", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "PWAV", "ADJD", "$,", "VAFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie wenig fragt alsdann der Mensch nach Fels und Stein!", "tokens": ["Wie", "we\u00b7nig", "fragt", "als\u00b7dann", "der", "Mensch", "nach", "Fels", "und", "Stein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Auch Gemsen werden dann auf keinen Klippen wohnen,", "tokens": ["Auch", "Gem\u00b7sen", "wer\u00b7den", "dann", "auf", "kei\u00b7nen", "Klip\u00b7pen", "woh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VAFIN", "ADV", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und selbst der J\u00e4ger wird sie mit der Jagd verschonen.", "tokens": ["Und", "selbst", "der", "J\u00e4\u00b7ger", "wird", "sie", "mit", "der", "Jagd", "ver\u00b7scho\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Ein neues Paradies wird auf der Welt entstehn,", "tokens": ["Ein", "neu\u00b7es", "Pa\u00b7ra\u00b7dies", "wird", "auf", "der", "Welt", "ent\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und rings um ihren Ball in ebnen Fluren gehn.", "tokens": ["Und", "rings", "um", "ih\u00b7ren", "Ball", "in", "eb\u00b7nen", "Flu\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gesunde, reine Luft wird sie durchaus umgeben,", "tokens": ["Ge\u00b7sun\u00b7de", ",", "rei\u00b7ne", "Luft", "wird", "sie", "durc\u00b7haus", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und jeder wird so lang als jene V\u00e4ter leben.", "tokens": ["Und", "je\u00b7der", "wird", "so", "lang", "als", "je\u00b7ne", "V\u00e4\u00b7ter", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ADV", "ADJD", "KOKOM", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie vor der S\u00fcndfluth noch, als alles j\u00fcnger war,", "tokens": ["Wie", "vor", "der", "S\u00fcnd\u00b7fluth", "noch", ",", "als", "al\u00b7les", "j\u00fcn\u00b7ger", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "$,", "KOUS", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die saftige Natur gesundre Kost gebahr:", "tokens": ["Die", "saf\u00b7ti\u00b7ge", "Na\u00b7tur", "ge\u00b7sund\u00b7re", "Kost", "ge\u00b7bahr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So wird alsdann die Welt, wo nicht die Schl\u00fcsse tr\u00fcgen,", "tokens": ["So", "wird", "als\u00b7dann", "die", "Welt", ",", "wo", "nicht", "die", "Schl\u00fcs\u00b7se", "tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PTKNEG", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Viel kr\u00e4ftiger als itzt der Menschen Sinn vergn\u00fcgen.", "tokens": ["Viel", "kr\u00e4f\u00b7ti\u00b7ger", "als", "itzt", "der", "Men\u00b7schen", "Sinn", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.57": {"line.1": {"text": "Komm, angenehme Zeit! bechleunige den Lauf!", "tokens": ["Komm", ",", "an\u00b7ge\u00b7neh\u00b7me", "Zeit", "!", "bech\u00b7leu\u00b7ni\u00b7ge", "den", "Lauf", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mach alle L\u00e4nder glatt, heb alle H\u00fcgel auf!", "tokens": ["Mach", "al\u00b7le", "L\u00e4n\u00b7der", "glatt", ",", "heb", "al\u00b7le", "H\u00fc\u00b7gel", "auf", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADJD", "$,", "VVFIN", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie sich das Niederland in feuchten Fluren weidet,", "tokens": ["Wie", "sich", "das", "Nie\u00b7der\u00b7land", "in", "feuch\u00b7ten", "Flu\u00b7ren", "wei\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und unsrer Berge Graus kein einzigmal beneidet.", "tokens": ["Und", "uns\u00b7rer", "Ber\u00b7ge", "Graus", "kein", "ein\u00b7zig\u00b7mal", "be\u00b7nei\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NE", "PIAT", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Auch du, o Vaterland! hegst Werker solcher Art,", "tokens": ["Auch", "du", ",", "o", "Va\u00b7ter\u00b7land", "!", "hegst", "Wer\u00b7ker", "sol\u00b7cher", "Art", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "FM", "NN", "$.", "VVFIN", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die dir der Vorsicht Gunst zum Theil schon aufgespart.", "tokens": ["Die", "dir", "der", "Vor\u00b7sicht", "Gunst", "zum", "Theil", "schon", "auf\u00b7ge\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "NN", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sie wachsen j\u00e4hrlich zu! du wirst zum Schmuck der Erden,", "tokens": ["Sie", "wach\u00b7sen", "j\u00e4hr\u00b7lich", "zu", "!", "du", "wirst", "zum", "Schmuck", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ehr, als manch andres Land, ein fettes Gosen werden.", "tokens": ["Ehr", ",", "als", "manch", "and\u00b7res", "Land", ",", "ein", "fet\u00b7tes", "Go\u00b7sen", "wer\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIAT", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Was seh ich von der H\u00f6h, wo mich der Wagen tr\u00e4gt?", "tokens": ["Was", "seh", "ich", "von", "der", "H\u00f6h", ",", "wo", "mich", "der", "Wa\u00b7gen", "tr\u00e4gt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists nicht der Donaustrom, der sich vor Augen legt?", "tokens": ["Ists", "nicht", "der", "Do\u00b7naus\u00b7trom", ",", "der", "sich", "vor", "Au\u00b7gen", "legt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist das nicht ", "tokens": ["Ist", "das", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PDS", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "O ja! Seyd mir gegr\u00fc\u00dft; ihr beyde habt nichts gleiches!", "tokens": ["O", "ja", "!", "Seyd", "mir", "ge\u00b7gr\u00fc\u00dft", ";", "ihr", "bey\u00b7de", "habt", "nichts", "glei\u00b7ches", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "VAIMP", "PPER", "VVPP", "$.", "PPER", "PIS", "VAFIN", "PIS", "PIS", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.5": {"text": "Der Deutschen Fl\u00fcsse Haupt, und wahre K\u00f6niginn", "tokens": ["Der", "Deut\u00b7schen", "Fl\u00fcs\u00b7se", "Haupt", ",", "und", "wah\u00b7re", "K\u00f6\u00b7ni\u00b7ginn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Eilt hier getheilt vorbey, und fleu\u00dft ganz stolz dahin,", "tokens": ["Eilt", "hier", "ge\u00b7theilt", "vor\u00b7bey", ",", "und", "fleu\u00dft", "ganz", "stolz", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVPP", "PTKVZ", "$,", "KON", "VVFIN", "ADV", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}}, "stanza.59": {"line.1": {"text": "O nimm mich, werther Flu\u00df! und f\u00fchre mich mit dir!", "tokens": ["O", "nimm", "mich", ",", "wert\u00b7her", "Flu\u00df", "!", "und", "f\u00fch\u00b7re", "mich", "mit", "dir", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVIMP", "PPER", "$,", "ADJA", "NN", "$.", "KON", "VVFIN", "PRF", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und zeige mir die Stadt, der Deutschen St\u00e4dte Zier.", "tokens": ["Und", "zei\u00b7ge", "mir", "die", "Stadt", ",", "der", "Deut\u00b7schen", "St\u00e4d\u00b7te", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ihr weichet auch Paris, und London, wenn sie will.", "tokens": ["Ihr", "wei\u00b7chet", "auch", "Pa\u00b7ris", ",", "und", "Lon\u00b7don", ",", "wenn", "sie", "will", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NE", "$,", "KON", "NE", "$,", "KOUS", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jedoch, o Muse! schweig, von ihren Wundern still,", "tokens": ["Je\u00b7doch", ",", "o", "Mu\u00b7se", "!", "schweig", ",", "von", "ih\u00b7ren", "Wun\u00b7dern", "still", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "FM", "NN", "$.", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Bis du sie selbst erblickst. Blick auf die nahen Mauren,", "tokens": ["Bis", "du", "sie", "selbst", "er\u00b7blickst", ".", "Blick", "auf", "die", "na\u00b7hen", "Mau\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVFIN", "$.", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Worinnen Freyheit, Recht, und Macht des Reiches dauren.", "tokens": ["Wo\u00b7rin\u00b7nen", "Frey\u00b7heit", ",", "Recht", ",", "und", "Macht", "des", "Rei\u00b7ches", "dau\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.60": {"line.1": {"text": "Der Deutschen H\u00e4upter Rath und Weisheit herrscht allda!", "tokens": ["Der", "Deut\u00b7schen", "H\u00e4up\u00b7ter", "Rath", "und", "Weis\u00b7heit", "herrscht", "all\u00b7da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So, wie man sonst in Rom den Staat vereinigt sah.", "tokens": ["So", ",", "wie", "man", "sonst", "in", "Rom", "den", "Staat", "ver\u00b7ei\u00b7nigt", "sah", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PIS", "ADV", "APPR", "NE", "ART", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es sind Gesandten hier, bereit in allen F\u00e4llen,", "tokens": ["Es", "sind", "Ge\u00b7sand\u00b7ten", "hier", ",", "be\u00b7reit", "in", "al\u00b7len", "F\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "ADV", "$,", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der F\u00fcrsten Ansehn, Macht und Rechte darzustellen.", "tokens": ["Der", "F\u00fcrs\u00b7ten", "An\u00b7sehn", ",", "Macht", "und", "Rech\u00b7te", "dar\u00b7zu\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihr hohen Th\u00fcrme zwar, prangt nur durchs Alterthum:", "tokens": ["Ihr", "ho\u00b7hen", "Th\u00fcr\u00b7me", "zwar", ",", "prangt", "nur", "durchs", "Al\u00b7ter\u00b7thum", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "$,", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein auch dieses schw\u00e4cht nicht eurer W\u00fcrde Ruhm.", "tokens": ["Al\u00b7lein", "auch", "die\u00b7ses", "schw\u00e4cht", "nicht", "eu\u00b7rer", "W\u00fcr\u00b7de", "Ruhm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PDS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ist doch das Capitol, wie wir in R\u00f6mern lesen,", "tokens": ["Ist", "doch", "das", "Ca\u00b7pi\u00b7tol", ",", "wie", "wir", "in", "R\u00f6\u00b7mern", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auch, als es h\u00f6lzern war, das Haupt der Welt gewesen.", "tokens": ["Auch", ",", "als", "es", "h\u00f6l\u00b7zern", "war", ",", "das", "Haupt", "der", "Welt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVINF", "VAFIN", "$,", "ART", "NN", "ART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}