{"textgrid.poem.41251": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie klug ist Cosmus von Gesicht!", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie klug ist Cosmus von Gesicht!", "tokens": ["Wie", "klug", "ist", "Cos\u00b7mus", "von", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man mu\u00df ihm etwas Stolz erlauben:", "tokens": ["Man", "mu\u00df", "ihm", "et\u00b7was", "Stolz", "er\u00b7lau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch alles, was er heute spricht,", "tokens": ["Doch", "al\u00b7les", ",", "was", "er", "heu\u00b7te", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Scheint ihm des Witzes Ruhm zu rauben.", "tokens": ["Scheint", "ihm", "des", "Wit\u00b7zes", "Ruhm", "zu", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist Cosmus klug? Ist er es nicht?", "tokens": ["Ist", "Cos\u00b7mus", "klug", "?", "Ist", "er", "es", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADJD", "$.", "VAFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ich werde seinen Worten glauben.", "tokens": ["Ich", "wer\u00b7de", "sei\u00b7nen", "Wor\u00b7ten", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie klug ist Cosmus von Gesicht!", "tokens": ["Wie", "klug", "ist", "Cos\u00b7mus", "von", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "NE", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man mu\u00df ihm etwas Stolz erlauben:", "tokens": ["Man", "mu\u00df", "ihm", "et\u00b7was", "Stolz", "er\u00b7lau\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch alles, was er heute spricht,", "tokens": ["Doch", "al\u00b7les", ",", "was", "er", "heu\u00b7te", "spricht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Scheint ihm des Witzes Ruhm zu rauben.", "tokens": ["Scheint", "ihm", "des", "Wit\u00b7zes", "Ruhm", "zu", "rau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist Cosmus klug? Ist er es nicht?", "tokens": ["Ist", "Cos\u00b7mus", "klug", "?", "Ist", "er", "es", "nicht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADJD", "$.", "VAFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Ich werde seinen Worten glauben.", "tokens": ["Ich", "wer\u00b7de", "sei\u00b7nen", "Wor\u00b7ten", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}