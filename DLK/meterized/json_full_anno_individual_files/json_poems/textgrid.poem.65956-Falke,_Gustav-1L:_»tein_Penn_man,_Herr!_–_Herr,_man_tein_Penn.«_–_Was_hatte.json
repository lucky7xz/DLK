{"textgrid.poem.65956": {"metadata": {"author": {"name": "Falke, Gustav", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbtein Penn man, Herr! \u2013 Herr, man tein Penn.\u00ab \u2013 Was hatte", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbtein Penn man, Herr! \u2013 Herr, man tein Penn.\u00ab \u2013 Was hatte", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u2013", "Herr", ",", "man", "tein", "Penn", ".", "\u00ab", "\u2013", "Was", "hat\u00b7te"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "NN", "$,", "PIS", "NN", "NE", "$.", "$(", "$(", "PWS", "VAFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Herz verh\u00e4rtet mir, dass rauh ich wehrte", "tokens": ["Das", "Herz", "ver\u00b7h\u00e4r\u00b7tet", "mir", ",", "dass", "rauh", "ich", "wehr\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUS", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit kaltem Nein? \u2013 \u00bbHerr, man tein Penn de Blomen.\u00ab", "tokens": ["Mit", "kal\u00b7tem", "Nein", "?", "\u2013", "\u00bb", "Herr", ",", "man", "tein", "Penn", "de", "Blo\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$(", "$(", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Kornblumen waren's, und das letzte Str\u00e4u\u00dfchen.", "tokens": ["Korn\u00b7blu\u00b7men", "wa\u00b7ren's", ",", "und", "das", "letz\u00b7te", "Str\u00e4u\u00df\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Und Angst im Herzen vor den Schelten, Schl\u00e4gen,", "tokens": ["Und", "Angst", "im", "Her\u00b7zen", "vor", "den", "Schel\u00b7ten", ",", "Schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die dein vielleicht zu Hause harrten, liefst du", "tokens": ["Die", "dein", "viel\u00b7leicht", "zu", "Hau\u00b7se", "harr\u00b7ten", ",", "liefst", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPOSAT", "ADV", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Ein Streckchen mit noch: \u00bbHerr, tein Penn man, Herr.\u00ab", "tokens": ["Ein", "Streck\u00b7chen", "mit", "noch", ":", "\u00bb", "Herr", ",", "tein", "Penn", "man", ",", "Herr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "$.", "$(", "NN", "$,", "FM", "FM", "PIS", "$,", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und schw\u00e4cher dann und sch\u00fcchtern von der Mitte", "tokens": ["Und", "schw\u00e4\u00b7cher", "dann", "und", "sch\u00fcch\u00b7tern", "von", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Des Fahrdamms klang es noch einmal: \u00bbTein Penn.\u00ab", "tokens": ["Des", "Fahr\u00b7damms", "klang", "es", "noch", "ein\u00b7mal", ":", "\u00bb", "Tein", "Penn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$.", "$(", "NN", "NE", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "War's Scham, einmal gesprochenes umzusto\u00dfen,", "tokens": ["Wa\u00b7r's", "Scham", ",", "ein\u00b7mal", "ge\u00b7spro\u00b7che\u00b7nes", "um\u00b7zu\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "ADV", "ADJA", "VVIZU", "$,"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Dass ich das schroffe Nein nicht widerrief?", "tokens": ["Dass", "ich", "das", "schrof\u00b7fe", "Nein", "nicht", "wi\u00b7der\u00b7rief", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War es das wunderliche F\u00fchlen wieder,", "tokens": ["War", "es", "das", "wun\u00b7der\u00b7li\u00b7che", "F\u00fch\u00b7len", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das nie mich ohn' Err\u00f6ten geben l\u00e4sst", "tokens": ["Das", "nie", "mich", "ohn'", "Er\u00b7r\u00f6\u00b7ten", "ge\u00b7ben", "l\u00e4sst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PPER", "APPR", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf offner Stra\u00dfe, vor der Leute Augen?", "tokens": ["Auf", "off\u00b7ner", "Stra\u00b7\u00dfe", ",", "vor", "der", "Leu\u00b7te", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Kommt an mein Haus. So zwischen Th\u00fcr und Pfosten,", "tokens": ["Kommt", "an", "mein", "Haus", ".", "So", "zwi\u00b7schen", "Th\u00fcr", "und", "Pfos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$.", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So durch die Spalte, zehnmal zehn \u00bbtein Penn,\u00ab", "tokens": ["So", "durch", "die", "Spal\u00b7te", ",", "zehn\u00b7mal", "zehn", "\u00bb", "tein", "Penn", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "CARD", "$(", "FM.la", "FM.la", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit frohem Herzschlag schnell und gern gegeben.", "tokens": ["Mit", "fro\u00b7hem", "Herz\u00b7schlag", "schnell", "und", "gern", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "War's das? Der Abend war doch schon so dunkel.", "tokens": ["Wa\u00b7r's", "das", "?", "Der", "A\u00b7bend", "war", "doch", "schon", "so", "dun\u00b7kel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$.", "ART", "NN", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Regen rieselte, und barfu\u00df standest", "tokens": ["Der", "Re\u00b7gen", "rie\u00b7sel\u00b7te", ",", "und", "bar\u00b7fu\u00df", "stan\u00b7dest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Im Schmutz der Stra\u00dfe du und batst \u00bbtein Penn\u00ab,", "tokens": ["Im", "Schmutz", "der", "Stra\u00b7\u00dfe", "du", "und", "batst", "\u00bb", "tein", "Penn", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PPER", "KON", "VVFIN", "$(", "FM.la", "FM.la", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und batst umsonst, indess an meinem Arm", "tokens": ["Und", "batst", "um\u00b7sonst", ",", "in\u00b7dess", "an", "mei\u00b7nem", "Arm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein liebes Wesen sprach von Eingemachtem,", "tokens": ["Ein", "lie\u00b7bes", "We\u00b7sen", "sprach", "von", "Ein\u00b7ge\u00b7mach\u00b7tem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Von Prei\u00dfelbeeren, Gurken und Gelee,", "tokens": ["Von", "Prei\u00b7\u00dfel\u00b7bee\u00b7ren", ",", "Gur\u00b7ken", "und", "Ge\u00b7lee", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und teurem Zucker. War mein Herz versteint,", "tokens": ["Und", "teu\u00b7rem", "Zu\u00b7cker", ".", "War", "mein", "Herz", "ver\u00b7steint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dass ich nicht gab? Nun h\u00f6r' ich bittend immer:", "tokens": ["Dass", "ich", "nicht", "gab", "?", "Nun", "h\u00f6r'", "ich", "bit\u00b7tend", "im\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "\u00bbtein Penn man, Herr!\u00ab und sch\u00e4me mich. Du aber,", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u00ab", "und", "sch\u00e4\u00b7me", "mich", ".", "Du", "a\u00b7ber", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "KON", "VVFIN", "PPER", "$.", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Wie oft umsonst noch, Kleiner, wirst du rufen:", "tokens": ["Wie", "oft", "um\u00b7sonst", "noch", ",", "Klei\u00b7ner", ",", "wirst", "du", "ru\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "ADV", "$,", "NN", "$,", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "\u00bbtein Penn man, Herr!\u00ab und mancher, der dich scheuchte", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u00ab", "und", "man\u00b7cher", ",", "der", "dich", "scheuch\u00b7te"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "KON", "PIS", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Mit barschem Nein, geht heim vielleicht und liest", "tokens": ["Mit", "bar\u00b7schem", "Nein", ",", "geht", "heim", "viel\u00b7leicht", "und", "liest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "PTKANT", "$,", "VVFIN", "PTKVZ", "ADV", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbbellamys R\u00fcckblick,\u00ab nickt und seufzt: \u00bbDer Tr\u00e4umer!", "tokens": ["\u00bb", "be\u00b7lla\u00b7mys", "R\u00fcck\u00b7blick", ",", "\u00ab", "nickt", "und", "seufzt", ":", "\u00bb", "Der", "Tr\u00e4u\u00b7mer", "!"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "$(", "VVFIN", "KON", "VVFIN", "$.", "$(", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ja, wenn wir Menschen keine \u2013 Menschen w\u00e4ren.\u00ab", "tokens": ["Ja", ",", "wenn", "wir", "Men\u00b7schen", "kei\u00b7ne", "\u2013", "Men\u00b7schen", "w\u00e4\u00b7ren", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "NN", "PIAT", "$(", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbtein Penn man, Herr! \u2013 Herr, man tein Penn.\u00ab \u2013 Was hatte", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u2013", "Herr", ",", "man", "tein", "Penn", ".", "\u00ab", "\u2013", "Was", "hat\u00b7te"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "NN", "$,", "PIS", "NN", "NE", "$.", "$(", "$(", "PWS", "VAFIN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das Herz verh\u00e4rtet mir, dass rauh ich wehrte", "tokens": ["Das", "Herz", "ver\u00b7h\u00e4r\u00b7tet", "mir", ",", "dass", "rauh", "ich", "wehr\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUS", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit kaltem Nein? \u2013 \u00bbHerr, man tein Penn de Blomen.\u00ab", "tokens": ["Mit", "kal\u00b7tem", "Nein", "?", "\u2013", "\u00bb", "Herr", ",", "man", "tein", "Penn", "de", "Blo\u00b7men", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "$(", "$(", "NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Kornblumen waren's, und das letzte Str\u00e4u\u00dfchen.", "tokens": ["Korn\u00b7blu\u00b7men", "wa\u00b7ren's", ",", "und", "das", "letz\u00b7te", "Str\u00e4u\u00df\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Und Angst im Herzen vor den Schelten, Schl\u00e4gen,", "tokens": ["Und", "Angst", "im", "Her\u00b7zen", "vor", "den", "Schel\u00b7ten", ",", "Schl\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "APPR", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die dein vielleicht zu Hause harrten, liefst du", "tokens": ["Die", "dein", "viel\u00b7leicht", "zu", "Hau\u00b7se", "harr\u00b7ten", ",", "liefst", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "PPOSAT", "ADV", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Ein Streckchen mit noch: \u00bbHerr, tein Penn man, Herr.\u00ab", "tokens": ["Ein", "Streck\u00b7chen", "mit", "noch", ":", "\u00bb", "Herr", ",", "tein", "Penn", "man", ",", "Herr", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "$.", "$(", "NN", "$,", "FM", "FM", "PIS", "$,", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und schw\u00e4cher dann und sch\u00fcchtern von der Mitte", "tokens": ["Und", "schw\u00e4\u00b7cher", "dann", "und", "sch\u00fcch\u00b7tern", "von", "der", "Mit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "ADV", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Des Fahrdamms klang es noch einmal: \u00bbTein Penn.\u00ab", "tokens": ["Des", "Fahr\u00b7damms", "klang", "es", "noch", "ein\u00b7mal", ":", "\u00bb", "Tein", "Penn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$.", "$(", "NN", "NE", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "War's Scham, einmal gesprochenes umzusto\u00dfen,", "tokens": ["Wa\u00b7r's", "Scham", ",", "ein\u00b7mal", "ge\u00b7spro\u00b7che\u00b7nes", "um\u00b7zu\u00b7sto\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "$,", "ADV", "ADJA", "VVIZU", "$,"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Dass ich das schroffe Nein nicht widerrief?", "tokens": ["Dass", "ich", "das", "schrof\u00b7fe", "Nein", "nicht", "wi\u00b7der\u00b7rief", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "War es das wunderliche F\u00fchlen wieder,", "tokens": ["War", "es", "das", "wun\u00b7der\u00b7li\u00b7che", "F\u00fch\u00b7len", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Das nie mich ohn' Err\u00f6ten geben l\u00e4sst", "tokens": ["Das", "nie", "mich", "ohn'", "Er\u00b7r\u00f6\u00b7ten", "ge\u00b7ben", "l\u00e4sst"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PPER", "APPR", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf offner Stra\u00dfe, vor der Leute Augen?", "tokens": ["Auf", "off\u00b7ner", "Stra\u00b7\u00dfe", ",", "vor", "der", "Leu\u00b7te", "Au\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Kommt an mein Haus. So zwischen Th\u00fcr und Pfosten,", "tokens": ["Kommt", "an", "mein", "Haus", ".", "So", "zwi\u00b7schen", "Th\u00fcr", "und", "Pfos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$.", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So durch die Spalte, zehnmal zehn \u00bbtein Penn,\u00ab", "tokens": ["So", "durch", "die", "Spal\u00b7te", ",", "zehn\u00b7mal", "zehn", "\u00bb", "tein", "Penn", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "CARD", "$(", "FM.la", "FM.la", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mit frohem Herzschlag schnell und gern gegeben.", "tokens": ["Mit", "fro\u00b7hem", "Herz\u00b7schlag", "schnell", "und", "gern", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "War's das? Der Abend war doch schon so dunkel.", "tokens": ["Wa\u00b7r's", "das", "?", "Der", "A\u00b7bend", "war", "doch", "schon", "so", "dun\u00b7kel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "$.", "ART", "NN", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$."], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Regen rieselte, und barfu\u00df standest", "tokens": ["Der", "Re\u00b7gen", "rie\u00b7sel\u00b7te", ",", "und", "bar\u00b7fu\u00df", "stan\u00b7dest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Im Schmutz der Stra\u00dfe du und batst \u00bbtein Penn\u00ab,", "tokens": ["Im", "Schmutz", "der", "Stra\u00b7\u00dfe", "du", "und", "batst", "\u00bb", "tein", "Penn", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PPER", "KON", "VVFIN", "$(", "FM.la", "FM.la", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und batst umsonst, indess an meinem Arm", "tokens": ["Und", "batst", "um\u00b7sonst", ",", "in\u00b7dess", "an", "mei\u00b7nem", "Arm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "$,", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ein liebes Wesen sprach von Eingemachtem,", "tokens": ["Ein", "lie\u00b7bes", "We\u00b7sen", "sprach", "von", "Ein\u00b7ge\u00b7mach\u00b7tem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Von Prei\u00dfelbeeren, Gurken und Gelee,", "tokens": ["Von", "Prei\u00b7\u00dfel\u00b7bee\u00b7ren", ",", "Gur\u00b7ken", "und", "Ge\u00b7lee", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und teurem Zucker. War mein Herz versteint,", "tokens": ["Und", "teu\u00b7rem", "Zu\u00b7cker", ".", "War", "mein", "Herz", "ver\u00b7steint", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$.", "VAFIN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dass ich nicht gab? Nun h\u00f6r' ich bittend immer:", "tokens": ["Dass", "ich", "nicht", "gab", "?", "Nun", "h\u00f6r'", "ich", "bit\u00b7tend", "im\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.9": {"text": "\u00bbtein Penn man, Herr!\u00ab und sch\u00e4me mich. Du aber,", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u00ab", "und", "sch\u00e4\u00b7me", "mich", ".", "Du", "a\u00b7ber", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "KON", "VVFIN", "PPER", "$.", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Wie oft umsonst noch, Kleiner, wirst du rufen:", "tokens": ["Wie", "oft", "um\u00b7sonst", "noch", ",", "Klei\u00b7ner", ",", "wirst", "du", "ru\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ADV", "ADV", "$,", "NN", "$,", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "\u00bbtein Penn man, Herr!\u00ab und mancher, der dich scheuchte", "tokens": ["\u00bb", "tein", "Penn", "man", ",", "Herr", "!", "\u00ab", "und", "man\u00b7cher", ",", "der", "dich", "scheuch\u00b7te"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM", "FM", "PIS", "$,", "NN", "$.", "$(", "KON", "PIS", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Mit barschem Nein, geht heim vielleicht und liest", "tokens": ["Mit", "bar\u00b7schem", "Nein", ",", "geht", "heim", "viel\u00b7leicht", "und", "liest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "PTKANT", "$,", "VVFIN", "PTKVZ", "ADV", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbbellamys R\u00fcckblick,\u00ab nickt und seufzt: \u00bbDer Tr\u00e4umer!", "tokens": ["\u00bb", "be\u00b7lla\u00b7mys", "R\u00fcck\u00b7blick", ",", "\u00ab", "nickt", "und", "seufzt", ":", "\u00bb", "Der", "Tr\u00e4u\u00b7mer", "!"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "$(", "VVFIN", "KON", "VVFIN", "$.", "$(", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Ja, wenn wir Menschen keine \u2013 Menschen w\u00e4ren.\u00ab", "tokens": ["Ja", ",", "wenn", "wir", "Men\u00b7schen", "kei\u00b7ne", "\u2013", "Men\u00b7schen", "w\u00e4\u00b7ren", ".", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "NN", "PIAT", "$(", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}