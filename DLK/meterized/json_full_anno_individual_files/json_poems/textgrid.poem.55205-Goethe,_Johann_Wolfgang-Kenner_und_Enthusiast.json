{"textgrid.poem.55205": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Kenner und Enthusiast", "genre": "verse", "period": "N.A.", "pub_year": 1774, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich f\u00fchrt einen Freund zum Maidel jung,", "tokens": ["Ich", "f\u00fchrt", "ei\u00b7nen", "Freund", "zum", "Mai\u00b7del", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollt ihm zu genie\u00dfen geben,", "tokens": ["Wollt", "ihm", "zu", "ge\u00b7nie\u00b7\u00dfen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was alles es h\u00e4tt, gar Freud genung,", "tokens": ["Was", "al\u00b7les", "es", "h\u00e4tt", ",", "gar", "Freud", "ge\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PPER", "VAFIN", "$,", "ADV", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Frisch junges, warmes Leben.", "tokens": ["Frisch", "jun\u00b7ges", ",", "war\u00b7mes", "Le\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wir fanden sie sitzen an ihrem Bett,", "tokens": ["Wir", "fan\u00b7den", "sie", "sit\u00b7zen", "an", "ih\u00b7rem", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "T\u00e4t sich auf ihr H\u00e4ndlein st\u00fctzen.", "tokens": ["T\u00e4t", "sich", "auf", "ihr", "H\u00e4nd\u00b7lein", "st\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der Herr, der macht' ihr ein Kompliment,", "tokens": ["Der", "Herr", ",", "der", "macht'", "ihr", "ein", "Kom\u00b7pli\u00b7ment", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "T\u00e4t gegen ihr \u00fcber sitzen.", "tokens": ["T\u00e4t", "ge\u00b7gen", "ihr", "\u00fc\u00b7ber", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Er spitzt die Nase, er sturt sie an,", "tokens": ["Er", "spitzt", "die", "Na\u00b7se", ",", "er", "sturt", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.10": {"text": "Betracht' sie her\u00fcber, hin\u00fcber:", "tokens": ["Be\u00b7tracht'", "sie", "her\u00b7\u00fc\u00b7ber", ",", "hin\u00b7\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "Und um mich war's gar bald getan,", "tokens": ["Und", "um", "mich", "wa\u00b7r's", "gar", "bald", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "Die Sinnen gingen mir \u00fcber.", "tokens": ["Die", "Sin\u00b7nen", "gin\u00b7gen", "mir", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Der liebe Herr f\u00fcr allen Dank", "tokens": ["Der", "lie\u00b7be", "Herr", "f\u00fcr", "al\u00b7len", "Dank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fchrt mich drauf in eine Ecken", "tokens": ["F\u00fchrt", "mich", "drauf", "in", "ei\u00b7ne", "E\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PAV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sagt, sie w\u00e4r doch allzu schlank", "tokens": ["Und", "sagt", ",", "sie", "w\u00e4r", "doch", "all\u00b7zu", "schlank"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00e4tt auch Sommerflecken.", "tokens": ["Und", "h\u00e4tt", "auch", "Som\u00b7mer\u00b7fle\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da nahm ich von meinem Kind Adieu,", "tokens": ["Da", "nahm", "ich", "von", "mei\u00b7nem", "Kind", "A\u00b7die\u00b7u", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und scheidend sah ich in die H\u00f6h:", "tokens": ["Und", "schei\u00b7dend", "sah", "ich", "in", "die", "H\u00f6h", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbach Herre Gott, ach Herre Gott,", "tokens": ["\u00bb", "ach", "Her\u00b7re", "Gott", ",", "ach", "Her\u00b7re", "Gott", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "NN", "$,", "XY", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erbarm dich doch des Herren!\u00ab", "tokens": ["Er\u00b7barm", "dich", "doch", "des", "Her\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Da f\u00fchrt ich ihn in die Galerie", "tokens": ["Da", "f\u00fchrt", "ich", "ihn", "in", "die", "Ga\u00b7le\u00b7rie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Voll Menschenglut und Geistes;", "tokens": ["Voll", "Men\u00b7schen\u00b7glut", "und", "Geis\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mir wird's da gleich, ich wei\u00df nicht wie,", "tokens": ["Mir", "wird's", "da", "gleich", ",", "ich", "wei\u00df", "nicht", "wie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein ganzes Herz zerrei\u00dft es.", "tokens": ["Mein", "gan\u00b7zes", "Herz", "zer\u00b7rei\u00dft", "es", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbo Maler! Maler!\u00ab rief ich laut,", "tokens": ["\u00bb", "o", "Ma\u00b7ler", "!", "Ma\u00b7ler", "!", "\u00ab", "rief", "ich", "laut", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$.", "NN", "$.", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbbelohn dir Gott dein Malen!", "tokens": ["\u00bb", "be\u00b7lohn", "dir", "Gott", "dein", "Ma\u00b7len", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und nur die allersch\u00f6nste Braut", "tokens": ["Und", "nur", "die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Braut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kann dich f\u00fcr uns bezahlen.\u00ab", "tokens": ["Kann", "dich", "f\u00fcr", "uns", "be\u00b7zah\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PRF", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und sieh, da ging mein Herr herum", "tokens": ["Und", "sieh", ",", "da", "ging", "mein", "Herr", "he\u00b7rum"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und stochert' sich die Z\u00e4hne,", "tokens": ["Und", "sto\u00b7chert'", "sich", "die", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Registriert' in Katalogum", "tokens": ["Re\u00b7gis\u00b7triert'", "in", "Ka\u00b7ta\u00b7lo\u00b7gum"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Mir meine G\u00f6tters\u00f6hne.", "tokens": ["Mir", "mei\u00b7ne", "G\u00f6t\u00b7ter\u00b7s\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mein Busen war so voll und bang,", "tokens": ["Mein", "Bu\u00b7sen", "war", "so", "voll", "und", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von hundert Welten tr\u00e4chtig;", "tokens": ["Von", "hun\u00b7dert", "Wel\u00b7ten", "tr\u00e4ch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ihm war bald was zu kurz, zu lang,", "tokens": ["Ihm", "war", "bald", "was", "zu", "kurz", ",", "zu", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "W\u00e4gt' alles gar bed\u00e4chtig.", "tokens": ["W\u00e4gt'", "al\u00b7les", "gar", "be\u00b7d\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Da warf ich in ein Eckchen mich,", "tokens": ["Da", "warf", "ich", "in", "ein", "Eck\u00b7chen", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Eingeweide brannten.", "tokens": ["Die", "Ein\u00b7ge\u00b7wei\u00b7de", "brann\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Um ihn versammelten M\u00e4nner sich,", "tokens": ["Um", "ihn", "ver\u00b7sam\u00b7mel\u00b7ten", "M\u00e4n\u00b7ner", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJA", "NN", "PRF", "$,"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die ihn einen Kenner nannten.", "tokens": ["Die", "ihn", "ei\u00b7nen", "Ken\u00b7ner", "nann\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ich f\u00fchrt einen Freund zum Maidel jung,", "tokens": ["Ich", "f\u00fchrt", "ei\u00b7nen", "Freund", "zum", "Mai\u00b7del", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wollt ihm zu genie\u00dfen geben,", "tokens": ["Wollt", "ihm", "zu", "ge\u00b7nie\u00b7\u00dfen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was alles es h\u00e4tt, gar Freud genung,", "tokens": ["Was", "al\u00b7les", "es", "h\u00e4tt", ",", "gar", "Freud", "ge\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "PPER", "VAFIN", "$,", "ADV", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Frisch junges, warmes Leben.", "tokens": ["Frisch", "jun\u00b7ges", ",", "war\u00b7mes", "Le\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wir fanden sie sitzen an ihrem Bett,", "tokens": ["Wir", "fan\u00b7den", "sie", "sit\u00b7zen", "an", "ih\u00b7rem", "Bett", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "T\u00e4t sich auf ihr H\u00e4ndlein st\u00fctzen.", "tokens": ["T\u00e4t", "sich", "auf", "ihr", "H\u00e4nd\u00b7lein", "st\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Der Herr, der macht' ihr ein Kompliment,", "tokens": ["Der", "Herr", ",", "der", "macht'", "ihr", "ein", "Kom\u00b7pli\u00b7ment", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "T\u00e4t gegen ihr \u00fcber sitzen.", "tokens": ["T\u00e4t", "ge\u00b7gen", "ihr", "\u00fc\u00b7ber", "sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "APPR", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Er spitzt die Nase, er sturt sie an,", "tokens": ["Er", "spitzt", "die", "Na\u00b7se", ",", "er", "sturt", "sie", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.10": {"text": "Betracht' sie her\u00fcber, hin\u00fcber:", "tokens": ["Be\u00b7tracht'", "sie", "her\u00b7\u00fc\u00b7ber", ",", "hin\u00b7\u00fc\u00b7ber", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "ADV", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "Und um mich war's gar bald getan,", "tokens": ["Und", "um", "mich", "wa\u00b7r's", "gar", "bald", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.12": {"text": "Die Sinnen gingen mir \u00fcber.", "tokens": ["Die", "Sin\u00b7nen", "gin\u00b7gen", "mir", "\u00fc\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Der liebe Herr f\u00fcr allen Dank", "tokens": ["Der", "lie\u00b7be", "Herr", "f\u00fcr", "al\u00b7len", "Dank"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fchrt mich drauf in eine Ecken", "tokens": ["F\u00fchrt", "mich", "drauf", "in", "ei\u00b7ne", "E\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "PAV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sagt, sie w\u00e4r doch allzu schlank", "tokens": ["Und", "sagt", ",", "sie", "w\u00e4r", "doch", "all\u00b7zu", "schlank"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PPER", "VAFIN", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und h\u00e4tt auch Sommerflecken.", "tokens": ["Und", "h\u00e4tt", "auch", "Som\u00b7mer\u00b7fle\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Da nahm ich von meinem Kind Adieu,", "tokens": ["Da", "nahm", "ich", "von", "mei\u00b7nem", "Kind", "A\u00b7die\u00b7u", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Und scheidend sah ich in die H\u00f6h:", "tokens": ["Und", "schei\u00b7dend", "sah", "ich", "in", "die", "H\u00f6h", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "\u00bbach Herre Gott, ach Herre Gott,", "tokens": ["\u00bb", "ach", "Her\u00b7re", "Gott", ",", "ach", "Her\u00b7re", "Gott", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "XY", "NN", "NN", "$,", "XY", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Erbarm dich doch des Herren!\u00ab", "tokens": ["Er\u00b7barm", "dich", "doch", "des", "Her\u00b7ren", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Da f\u00fchrt ich ihn in die Galerie", "tokens": ["Da", "f\u00fchrt", "ich", "ihn", "in", "die", "Ga\u00b7le\u00b7rie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Voll Menschenglut und Geistes;", "tokens": ["Voll", "Men\u00b7schen\u00b7glut", "und", "Geis\u00b7tes", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mir wird's da gleich, ich wei\u00df nicht wie,", "tokens": ["Mir", "wird's", "da", "gleich", ",", "ich", "wei\u00df", "nicht", "wie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "PPER", "VVFIN", "PTKNEG", "KOKOM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein ganzes Herz zerrei\u00dft es.", "tokens": ["Mein", "gan\u00b7zes", "Herz", "zer\u00b7rei\u00dft", "es", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbo Maler! Maler!\u00ab rief ich laut,", "tokens": ["\u00bb", "o", "Ma\u00b7ler", "!", "Ma\u00b7ler", "!", "\u00ab", "rief", "ich", "laut", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$.", "NN", "$.", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbbelohn dir Gott dein Malen!", "tokens": ["\u00bb", "be\u00b7lohn", "dir", "Gott", "dein", "Ma\u00b7len", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und nur die allersch\u00f6nste Braut", "tokens": ["Und", "nur", "die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Braut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kann dich f\u00fcr uns bezahlen.\u00ab", "tokens": ["Kann", "dich", "f\u00fcr", "uns", "be\u00b7zah\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VMFIN", "PRF", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und sieh, da ging mein Herr herum", "tokens": ["Und", "sieh", ",", "da", "ging", "mein", "Herr", "he\u00b7rum"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "ADV", "VVFIN", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und stochert' sich die Z\u00e4hne,", "tokens": ["Und", "sto\u00b7chert'", "sich", "die", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Registriert' in Katalogum", "tokens": ["Re\u00b7gis\u00b7triert'", "in", "Ka\u00b7ta\u00b7lo\u00b7gum"], "token_info": ["word", "word", "word"], "pos": ["NN", "APPR", "NE"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Mir meine G\u00f6tters\u00f6hne.", "tokens": ["Mir", "mei\u00b7ne", "G\u00f6t\u00b7ter\u00b7s\u00f6h\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mein Busen war so voll und bang,", "tokens": ["Mein", "Bu\u00b7sen", "war", "so", "voll", "und", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von hundert Welten tr\u00e4chtig;", "tokens": ["Von", "hun\u00b7dert", "Wel\u00b7ten", "tr\u00e4ch\u00b7tig", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Ihm war bald was zu kurz, zu lang,", "tokens": ["Ihm", "war", "bald", "was", "zu", "kurz", ",", "zu", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "W\u00e4gt' alles gar bed\u00e4chtig.", "tokens": ["W\u00e4gt'", "al\u00b7les", "gar", "be\u00b7d\u00e4ch\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Da warf ich in ein Eckchen mich,", "tokens": ["Da", "warf", "ich", "in", "ein", "Eck\u00b7chen", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Eingeweide brannten.", "tokens": ["Die", "Ein\u00b7ge\u00b7wei\u00b7de", "brann\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Um ihn versammelten M\u00e4nner sich,", "tokens": ["Um", "ihn", "ver\u00b7sam\u00b7mel\u00b7ten", "M\u00e4n\u00b7ner", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "ADJA", "NN", "PRF", "$,"], "meter": "++-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Die ihn einen Kenner nannten.", "tokens": ["Die", "ihn", "ei\u00b7nen", "Ken\u00b7ner", "nann\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}