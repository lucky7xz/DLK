{"textgrid.poem.53509": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der alte Fontane", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Damals, so in den achtziger Jahren,", "tokens": ["Da\u00b7mals", ",", "so", "in", "den", "acht\u00b7zi\u00b7ger", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "ist man noch nicht mit dem Auto gefahren;", "tokens": ["ist", "man", "noch", "nicht", "mit", "dem", "Au\u00b7to", "ge\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "alles ging seinen ruhigen Schritt,", "tokens": ["al\u00b7les", "ging", "sei\u00b7nen", "ru\u00b7hi\u00b7gen", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "und der alte Fontane ging ihn mit.", "tokens": ["und", "der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "ging", "ihn", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ein stilles Antlitz hatten die Tage:", "tokens": ["Ein", "stil\u00b7les", "Ant\u00b7litz", "hat\u00b7ten", "die", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Fr\u00fchmorgens bei Kroll, auf der Brunnenwaage", "tokens": ["Fr\u00fch\u00b7mor\u00b7gens", "bei", "Kroll", ",", "auf", "der", "Brun\u00b7nen\u00b7waa\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "$,", "APPR", "ART", "NN"], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "dann die Tiergartenpromenade", "tokens": ["dann", "die", "Tier\u00b7gar\u00b7ten\u00b7pro\u00b7me\u00b7na\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "--++-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "(\u00bbKannten Sie Strousberg? Schade, schade!\u00ab),", "tokens": ["(", "\u00bb", "Kann\u00b7ten", "Sie", "Strous\u00b7berg", "?", "Scha\u00b7de", ",", "scha\u00b7de", "!", "\u00ab", ")", ","], "token_info": ["punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "VMFIN", "PPER", "NE", "$.", "ADJD", "$,", "VVFIN", "$.", "$(", "$(", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "dann ins Gesch\u00e4ft oder ins B\u00fcro,", "tokens": ["dann", "ins", "Ge\u00b7sch\u00e4ft", "o\u00b7der", "ins", "B\u00fc\u00b7ro", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und das ging alle Vormittage so.", "tokens": ["und", "das", "ging", "al\u00b7le", "Vor\u00b7mit\u00b7ta\u00b7ge", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mittag zu Hause, friedliche Zeiten,", "tokens": ["Mit\u00b7tag", "zu", "Hau\u00b7se", ",", "fried\u00b7li\u00b7che", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "die Kinder machen Schularbeiten,", "tokens": ["die", "Kin\u00b7der", "ma\u00b7chen", "Schul\u00b7ar\u00b7bei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "ein kleines Nickerchen mit der Zigarre,", "tokens": ["ein", "klei\u00b7nes", "Ni\u00b7cker\u00b7chen", "mit", "der", "Zi\u00b7gar\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "und dann wieder in die gesch\u00e4ftliche Karre.", "tokens": ["und", "dann", "wie\u00b7der", "in", "die", "ge\u00b7sch\u00e4ft\u00b7li\u00b7che", "Kar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "Und war der Tag besonders sch\u00f6n,", "tokens": ["Und", "war", "der", "Tag", "be\u00b7son\u00b7ders", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "hie\u00df es: \u00bbIch habe den Kaiser gesehn!\u00ab \u2013", "tokens": ["hie\u00df", "es", ":", "\u00bb", "Ich", "ha\u00b7be", "den", "Kai\u00b7ser", "ge\u00b7sehn", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "VAFIN", "ART", "NN", "VVPP", "$.", "$(", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.17": {"text": "Alles so sauber und preu\u00dfisch und karg:", "tokens": ["Al\u00b7les", "so", "sau\u00b7ber", "und", "preu\u00b7\u00dfisch", "und", "karg", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.18": {"text": "der alte Fontane und seine Mark.", "tokens": ["der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "und", "sei\u00b7ne", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Aber Fontane und alle die Alten", "tokens": ["A\u00b7ber", "Fon\u00b7ta\u00b7ne", "und", "al\u00b7le", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "PIS", "ART", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.20": {"text": "konnten sich auch nicht ewig halten.", "tokens": ["konn\u00b7ten", "sich", "auch", "nicht", "e\u00b7wig", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Wollten noch so vieles erleben,", "tokens": ["Woll\u00b7ten", "noch", "so", "vie\u00b7les", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.22": {"text": "mu\u00dften doch gen Walhalla schweben.", "tokens": ["mu\u00df\u00b7ten", "doch", "gen", "Wal\u00b7hal\u00b7la", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.23": {"text": "Bis hin vor die Weltenesche sie ziehn,", "tokens": ["Bis", "hin", "vor", "die", "Wel\u00b7te\u00b7ne\u00b7sche", "sie", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.24": {"text": "da lagern sie sich um Vater Odin.", "tokens": ["da", "la\u00b7gern", "sie", "sich", "um", "Va\u00b7ter", "O\u00b7din", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "NE", "$."], "meter": "++--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Tick, tick,", "tokens": ["Tick", ",", "tick", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "drei\u00dfig Jahre sind ein Augenblick.", "tokens": ["drei\u00b7\u00dfig", "Jah\u00b7re", "sind", "ein", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Und als nun Michaelis den Abschied nahm,", "tokens": ["Und", "als", "nun", "Mic\u00b7ha\u00b7e\u00b7lis", "den", "Ab\u00b7schied", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "eine Sehnsucht \u00fcber Fontane kam,", "tokens": ["ei\u00b7ne", "Sehn\u00b7sucht", "\u00fc\u00b7ber", "Fon\u00b7ta\u00b7ne", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "und er sprach: \u00bbHerr, la\u00df mich auf Urlaub gehn,", "tokens": ["und", "er", "sprach", ":", "\u00bb", "Herr", ",", "la\u00df", "mich", "auf", "Ur\u00b7laub", "gehn", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NN", "$,", "VVIMP", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ich m\u00f6chte die Spree noch einmal sehn.", "tokens": ["ich", "m\u00f6ch\u00b7te", "die", "Spree", "noch", "ein\u00b7mal", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NE", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Spree, die Havel, die Nette, die Nuthe,", "tokens": ["Die", "Spree", ",", "die", "Ha\u00b7vel", ",", "die", "Net\u00b7te", ",", "die", "Nu\u00b7the", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "NE", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "den Schlachtensee und die R\u00e4uberkuthe;", "tokens": ["den", "Schlach\u00b7ten\u00b7see", "und", "die", "R\u00e4u\u00b7ber\u00b7ku\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "ich kenne mich aus, und habe ich Gl\u00fcck,", "tokens": ["ich", "ken\u00b7ne", "mich", "aus", ",", "und", "ha\u00b7be", "ich", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VAFIN", "PPER", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "bis Donnerstag bin ich wieder zur\u00fcck.\u00ab", "tokens": ["bis", "Don\u00b7ners\u00b7tag", "bin", "ich", "wie\u00b7der", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Odin hat huldvoll sich verneigt \u2013", "tokens": ["O\u00b7din", "hat", "huld\u00b7voll", "sich", "ver\u00b7neigt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "PRF", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der Alte zur Erde niedersteigt.", "tokens": ["der", "Al\u00b7te", "zur", "Er\u00b7de", "nie\u00b7ders\u00b7teigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und zun\u00e4chst in der Neumark, in der N\u00e4he von Bentschen,", "tokens": ["Und", "zu\u00b7n\u00e4chst", "in", "der", "Neu\u00b7mark", ",", "in", "der", "N\u00e4\u00b7he", "von", "Bent\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "landet er. \u00bbHimmel, was sind das f\u00fcr Menschen!\u00ab", "tokens": ["lan\u00b7det", "er", ".", "\u00bb", "Him\u00b7mel", ",", "was", "sind", "das", "f\u00fcr", "Men\u00b7schen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "NN", "$,", "PWS", "VAFIN", "PDS", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.13": {"text": "Und er spricht hinter Schwiebus und hinter Zielenzig:", "tokens": ["Und", "er", "spricht", "hin\u00b7ter", "Schwie\u00b7bus", "und", "hin\u00b7ter", "Zie\u00b7len\u00b7zig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.14": {"text": "\u00bbdickk\u00f6pfe, Hamster! und so was nennt sich", "tokens": ["\u00bb", "dick\u00b7k\u00f6p\u00b7fe", ",", "Hams\u00b7ter", "!", "und", "so", "was", "nennt", "sich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "NN", "$.", "KON", "ADV", "PWS", "VVFIN", "PRF"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.15": {"text": "nun M\u00e4rker \u2013 wir wollen westw\u00e4rts ziehn!\u00ab", "tokens": ["nun", "M\u00e4r\u00b7ker", "\u2013", "wir", "wol\u00b7len", "west\u00b7w\u00e4rts", "ziehn", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NN", "$(", "PPER", "VMFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Und so westw\u00e4rts kommt er nach Berlin.", "tokens": ["Und", "so", "west\u00b7w\u00e4rts", "kommt", "er", "nach", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Da ist ein Schleichen und Drehen und Schieben,", "tokens": ["Da", "ist", "ein", "Schlei\u00b7chen", "und", "Dre\u00b7hen", "und", "Schie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "wo ist das alte Berlin geblieben?", "tokens": ["wo", "ist", "das", "al\u00b7te", "Ber\u00b7lin", "ge\u00b7blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NE", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Einer dr\u00e4ngt immer den andern weg:", "tokens": ["Ei\u00b7ner", "dr\u00e4ngt", "im\u00b7mer", "den", "an\u00b7dern", "weg", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "\u00bbharn Se nich greifbaren Schweinespeck?\u00ab", "tokens": ["\u00bb", "harn", "Se", "nich", "greif\u00b7ba\u00b7ren", "Schwei\u00b7nes\u00b7peck", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "PTKNEG", "ADJA", "NN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.21": {"text": "Und ein Dicker steht mitten auf dem Damm", "tokens": ["Und", "ein", "Di\u00b7cker", "steht", "mit\u00b7ten", "auf", "dem", "Damm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "und philosophiert \u00fcber P\u00f6kelkamm.", "tokens": ["und", "phi\u00b7lo\u00b7so\u00b7phiert", "\u00fc\u00b7ber", "P\u00f6\u00b7kel\u00b7kamm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Sie treten sich an die Schienenbeine,", "tokens": ["Sie", "tre\u00b7ten", "sich", "an", "die", "Schie\u00b7nen\u00b7bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "die j\u00fcngeren Herren spielen \u203aMeine \u2013 Deine\u2039,", "tokens": ["die", "j\u00fcn\u00b7ge\u00b7ren", "Her\u00b7ren", "spie\u00b7len", "\u203a", "Mei\u00b7ne", "\u2013", "Dei\u00b7ne", "\u2039", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "PPOSAT", "$(", "PPOSAT", "$(", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "sie verkaufen Frauen und Gold und Eier", "tokens": ["sie", "ver\u00b7kau\u00b7fen", "Frau\u00b7en", "und", "Gold", "und", "Ei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.26": {"text": "und alles um die paar lumpigen Dreier.", "tokens": ["und", "al\u00b7les", "um", "die", "paar", "lum\u00b7pi\u00b7gen", "Drei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Golden leuchtet ein Kirchturmknopf \u2013 \u2013", "tokens": ["Gol\u00b7den", "leuch\u00b7tet", "ein", "Kirch\u00b7turm\u00b7knopf", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$(", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.4": {"line.1": {"text": "Und der Alte sch\u00fcttelt schweigend den Kopf,", "tokens": ["Und", "der", "Al\u00b7te", "sch\u00fct\u00b7telt", "schwei\u00b7gend", "den", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "freiwillig k\u00fcrzt er den Urlaub ab,", "tokens": ["frei\u00b7wil\u00b7lig", "k\u00fcrzt", "er", "den", "Ur\u00b7laub", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "in wilde Karriere f\u00e4llt sein R\u00fcckzugstrab.", "tokens": ["in", "wil\u00b7de", "Kar\u00b7rie\u00b7re", "f\u00e4llt", "sein", "R\u00fcck\u00b7zugs\u00b7trab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sein R\u00fcckmarsch ist ein verzweifeltes Fliehn.", "tokens": ["Sein", "R\u00fcck\u00b7marsch", "ist", "ein", "ver\u00b7zwei\u00b7fel\u00b7tes", "Fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbwie war es?\u00ab fragt teilnahmsvoll Odin.", "tokens": ["\u00bb", "wie", "war", "es", "?", "\u00ab", "fragt", "teil\u00b7nahms\u00b7voll", "O\u00b7din", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "PPER", "$.", "$(", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und der alte Fontane stottert beklommen:", "tokens": ["Und", "der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "stot\u00b7tert", "be\u00b7klom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbgott, ist die Gegend runtergekommen!\u00ab", "tokens": ["\u00bb", "gott", ",", "ist", "die", "Ge\u00b7gend", "run\u00b7ter\u00b7ge\u00b7kom\u00b7men", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "VAFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Damals, so in den achtziger Jahren,", "tokens": ["Da\u00b7mals", ",", "so", "in", "den", "acht\u00b7zi\u00b7ger", "Jah\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "ist man noch nicht mit dem Auto gefahren;", "tokens": ["ist", "man", "noch", "nicht", "mit", "dem", "Au\u00b7to", "ge\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.3": {"text": "alles ging seinen ruhigen Schritt,", "tokens": ["al\u00b7les", "ging", "sei\u00b7nen", "ru\u00b7hi\u00b7gen", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "und der alte Fontane ging ihn mit.", "tokens": ["und", "der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "ging", "ihn", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Ein stilles Antlitz hatten die Tage:", "tokens": ["Ein", "stil\u00b7les", "Ant\u00b7litz", "hat\u00b7ten", "die", "Ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Fr\u00fchmorgens bei Kroll, auf der Brunnenwaage", "tokens": ["Fr\u00fch\u00b7mor\u00b7gens", "bei", "Kroll", ",", "auf", "der", "Brun\u00b7nen\u00b7waa\u00b7ge"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "$,", "APPR", "ART", "NN"], "meter": "+---+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.7": {"text": "dann die Tiergartenpromenade", "tokens": ["dann", "die", "Tier\u00b7gar\u00b7ten\u00b7pro\u00b7me\u00b7na\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "--++-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "(\u00bbKannten Sie Strousberg? Schade, schade!\u00ab),", "tokens": ["(", "\u00bb", "Kann\u00b7ten", "Sie", "Strous\u00b7berg", "?", "Scha\u00b7de", ",", "scha\u00b7de", "!", "\u00ab", ")", ","], "token_info": ["punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "VMFIN", "PPER", "NE", "$.", "ADJD", "$,", "VVFIN", "$.", "$(", "$(", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "dann ins Gesch\u00e4ft oder ins B\u00fcro,", "tokens": ["dann", "ins", "Ge\u00b7sch\u00e4ft", "o\u00b7der", "ins", "B\u00fc\u00b7ro", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und das ging alle Vormittage so.", "tokens": ["und", "das", "ging", "al\u00b7le", "Vor\u00b7mit\u00b7ta\u00b7ge", "so", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PIAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Mittag zu Hause, friedliche Zeiten,", "tokens": ["Mit\u00b7tag", "zu", "Hau\u00b7se", ",", "fried\u00b7li\u00b7che", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "die Kinder machen Schularbeiten,", "tokens": ["die", "Kin\u00b7der", "ma\u00b7chen", "Schul\u00b7ar\u00b7bei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "ein kleines Nickerchen mit der Zigarre,", "tokens": ["ein", "klei\u00b7nes", "Ni\u00b7cker\u00b7chen", "mit", "der", "Zi\u00b7gar\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "und dann wieder in die gesch\u00e4ftliche Karre.", "tokens": ["und", "dann", "wie\u00b7der", "in", "die", "ge\u00b7sch\u00e4ft\u00b7li\u00b7che", "Kar\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.15": {"text": "Und war der Tag besonders sch\u00f6n,", "tokens": ["Und", "war", "der", "Tag", "be\u00b7son\u00b7ders", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "hie\u00df es: \u00bbIch habe den Kaiser gesehn!\u00ab \u2013", "tokens": ["hie\u00df", "es", ":", "\u00bb", "Ich", "ha\u00b7be", "den", "Kai\u00b7ser", "ge\u00b7sehn", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "PPER", "VAFIN", "ART", "NN", "VVPP", "$.", "$(", "$("], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.17": {"text": "Alles so sauber und preu\u00dfisch und karg:", "tokens": ["Al\u00b7les", "so", "sau\u00b7ber", "und", "preu\u00b7\u00dfisch", "und", "karg", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.18": {"text": "der alte Fontane und seine Mark.", "tokens": ["der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "und", "sei\u00b7ne", "Mark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Aber Fontane und alle die Alten", "tokens": ["A\u00b7ber", "Fon\u00b7ta\u00b7ne", "und", "al\u00b7le", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "KON", "PIS", "ART", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.20": {"text": "konnten sich auch nicht ewig halten.", "tokens": ["konn\u00b7ten", "sich", "auch", "nicht", "e\u00b7wig", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Wollten noch so vieles erleben,", "tokens": ["Woll\u00b7ten", "noch", "so", "vie\u00b7les", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ADV", "PIS", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.22": {"text": "mu\u00dften doch gen Walhalla schweben.", "tokens": ["mu\u00df\u00b7ten", "doch", "gen", "Wal\u00b7hal\u00b7la", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NE", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.23": {"text": "Bis hin vor die Weltenesche sie ziehn,", "tokens": ["Bis", "hin", "vor", "die", "Wel\u00b7te\u00b7ne\u00b7sche", "sie", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.24": {"text": "da lagern sie sich um Vater Odin.", "tokens": ["da", "la\u00b7gern", "sie", "sich", "um", "Va\u00b7ter", "O\u00b7din", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "NN", "NE", "$."], "meter": "++--+-+-+-", "measure": "trochaic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Tick, tick,", "tokens": ["Tick", ",", "tick", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "drei\u00dfig Jahre sind ein Augenblick.", "tokens": ["drei\u00b7\u00dfig", "Jah\u00b7re", "sind", "ein", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Und als nun Michaelis den Abschied nahm,", "tokens": ["Und", "als", "nun", "Mic\u00b7ha\u00b7e\u00b7lis", "den", "Ab\u00b7schied", "nahm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "eine Sehnsucht \u00fcber Fontane kam,", "tokens": ["ei\u00b7ne", "Sehn\u00b7sucht", "\u00fc\u00b7ber", "Fon\u00b7ta\u00b7ne", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "und er sprach: \u00bbHerr, la\u00df mich auf Urlaub gehn,", "tokens": ["und", "er", "sprach", ":", "\u00bb", "Herr", ",", "la\u00df", "mich", "auf", "Ur\u00b7laub", "gehn", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NN", "$,", "VVIMP", "PPER", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ich m\u00f6chte die Spree noch einmal sehn.", "tokens": ["ich", "m\u00f6ch\u00b7te", "die", "Spree", "noch", "ein\u00b7mal", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NE", "ADV", "ADV", "VVINF", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die Spree, die Havel, die Nette, die Nuthe,", "tokens": ["Die", "Spree", ",", "die", "Ha\u00b7vel", ",", "die", "Net\u00b7te", ",", "die", "Nu\u00b7the", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "NE", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "den Schlachtensee und die R\u00e4uberkuthe;", "tokens": ["den", "Schlach\u00b7ten\u00b7see", "und", "die", "R\u00e4u\u00b7ber\u00b7ku\u00b7the", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "ich kenne mich aus, und habe ich Gl\u00fcck,", "tokens": ["ich", "ken\u00b7ne", "mich", "aus", ",", "und", "ha\u00b7be", "ich", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VAFIN", "PPER", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "bis Donnerstag bin ich wieder zur\u00fcck.\u00ab", "tokens": ["bis", "Don\u00b7ners\u00b7tag", "bin", "ich", "wie\u00b7der", "zu\u00b7r\u00fcck", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Odin hat huldvoll sich verneigt \u2013", "tokens": ["O\u00b7din", "hat", "huld\u00b7voll", "sich", "ver\u00b7neigt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADJD", "PRF", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "der Alte zur Erde niedersteigt.", "tokens": ["der", "Al\u00b7te", "zur", "Er\u00b7de", "nie\u00b7ders\u00b7teigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Und zun\u00e4chst in der Neumark, in der N\u00e4he von Bentschen,", "tokens": ["Und", "zu\u00b7n\u00e4chst", "in", "der", "Neu\u00b7mark", ",", "in", "der", "N\u00e4\u00b7he", "von", "Bent\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$,", "APPR", "ART", "NN", "APPR", "NE", "$,"], "meter": "--+--+-+-+--+-", "measure": "anapaest.di.plus"}, "line.12": {"text": "landet er. \u00bbHimmel, was sind das f\u00fcr Menschen!\u00ab", "tokens": ["lan\u00b7det", "er", ".", "\u00bb", "Him\u00b7mel", ",", "was", "sind", "das", "f\u00fcr", "Men\u00b7schen", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "NN", "$,", "PWS", "VAFIN", "PDS", "APPR", "NN", "$.", "$("], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.13": {"text": "Und er spricht hinter Schwiebus und hinter Zielenzig:", "tokens": ["Und", "er", "spricht", "hin\u00b7ter", "Schwie\u00b7bus", "und", "hin\u00b7ter", "Zie\u00b7len\u00b7zig", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.14": {"text": "\u00bbdickk\u00f6pfe, Hamster! und so was nennt sich", "tokens": ["\u00bb", "dick\u00b7k\u00f6p\u00b7fe", ",", "Hams\u00b7ter", "!", "und", "so", "was", "nennt", "sich"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "$,", "NN", "$.", "KON", "ADV", "PWS", "VVFIN", "PRF"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.15": {"text": "nun M\u00e4rker \u2013 wir wollen westw\u00e4rts ziehn!\u00ab", "tokens": ["nun", "M\u00e4r\u00b7ker", "\u2013", "wir", "wol\u00b7len", "west\u00b7w\u00e4rts", "ziehn", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "NN", "$(", "PPER", "VMFIN", "ADV", "VVINF", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Und so westw\u00e4rts kommt er nach Berlin.", "tokens": ["Und", "so", "west\u00b7w\u00e4rts", "kommt", "er", "nach", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.17": {"text": "Da ist ein Schleichen und Drehen und Schieben,", "tokens": ["Da", "ist", "ein", "Schlei\u00b7chen", "und", "Dre\u00b7hen", "und", "Schie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "wo ist das alte Berlin geblieben?", "tokens": ["wo", "ist", "das", "al\u00b7te", "Ber\u00b7lin", "ge\u00b7blie\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NE", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Einer dr\u00e4ngt immer den andern weg:", "tokens": ["Ei\u00b7ner", "dr\u00e4ngt", "im\u00b7mer", "den", "an\u00b7dern", "weg", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.20": {"text": "\u00bbharn Se nich greifbaren Schweinespeck?\u00ab", "tokens": ["\u00bb", "harn", "Se", "nich", "greif\u00b7ba\u00b7ren", "Schwei\u00b7nes\u00b7peck", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "PTKNEG", "ADJA", "NN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.21": {"text": "Und ein Dicker steht mitten auf dem Damm", "tokens": ["Und", "ein", "Di\u00b7cker", "steht", "mit\u00b7ten", "auf", "dem", "Damm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.22": {"text": "und philosophiert \u00fcber P\u00f6kelkamm.", "tokens": ["und", "phi\u00b7lo\u00b7so\u00b7phiert", "\u00fc\u00b7ber", "P\u00f6\u00b7kel\u00b7kamm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Sie treten sich an die Schienenbeine,", "tokens": ["Sie", "tre\u00b7ten", "sich", "an", "die", "Schie\u00b7nen\u00b7bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "die j\u00fcngeren Herren spielen \u203aMeine \u2013 Deine\u2039,", "tokens": ["die", "j\u00fcn\u00b7ge\u00b7ren", "Her\u00b7ren", "spie\u00b7len", "\u203a", "Mei\u00b7ne", "\u2013", "Dei\u00b7ne", "\u2039", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$(", "PPOSAT", "$(", "PPOSAT", "$(", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.25": {"text": "sie verkaufen Frauen und Gold und Eier", "tokens": ["sie", "ver\u00b7kau\u00b7fen", "Frau\u00b7en", "und", "Gold", "und", "Ei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "KON", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.26": {"text": "und alles um die paar lumpigen Dreier.", "tokens": ["und", "al\u00b7les", "um", "die", "paar", "lum\u00b7pi\u00b7gen", "Drei\u00b7er", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Golden leuchtet ein Kirchturmknopf \u2013 \u2013", "tokens": ["Gol\u00b7den", "leuch\u00b7tet", "ein", "Kirch\u00b7turm\u00b7knopf", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$(", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Und der Alte sch\u00fcttelt schweigend den Kopf,", "tokens": ["Und", "der", "Al\u00b7te", "sch\u00fct\u00b7telt", "schwei\u00b7gend", "den", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "freiwillig k\u00fcrzt er den Urlaub ab,", "tokens": ["frei\u00b7wil\u00b7lig", "k\u00fcrzt", "er", "den", "Ur\u00b7laub", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "in wilde Karriere f\u00e4llt sein R\u00fcckzugstrab.", "tokens": ["in", "wil\u00b7de", "Kar\u00b7rie\u00b7re", "f\u00e4llt", "sein", "R\u00fcck\u00b7zugs\u00b7trab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Sein R\u00fcckmarsch ist ein verzweifeltes Fliehn.", "tokens": ["Sein", "R\u00fcck\u00b7marsch", "ist", "ein", "ver\u00b7zwei\u00b7fel\u00b7tes", "Fliehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "\u00bbwie war es?\u00ab fragt teilnahmsvoll Odin.", "tokens": ["\u00bb", "wie", "war", "es", "?", "\u00ab", "fragt", "teil\u00b7nahms\u00b7voll", "O\u00b7din", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KOKOM", "VAFIN", "PPER", "$.", "$(", "VVFIN", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und der alte Fontane stottert beklommen:", "tokens": ["Und", "der", "al\u00b7te", "Fon\u00b7ta\u00b7ne", "stot\u00b7tert", "be\u00b7klom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "--+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "\u00bbgott, ist die Gegend runtergekommen!\u00ab", "tokens": ["\u00bb", "gott", ",", "ist", "die", "Ge\u00b7gend", "run\u00b7ter\u00b7ge\u00b7kom\u00b7men", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$,", "VAFIN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}}}}