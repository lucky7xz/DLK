{"textgrid.poem.57310": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00dcber alles Zornentflammende raget es hoch empor,", "genre": "verse", "period": "N.A.", "pub_year": 1778, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00dcber alles Zornentflammende raget es hoch empor,", "tokens": ["\u00dc\u00b7ber", "al\u00b7les", "Zor\u00b7nent\u00b7flam\u00b7men\u00b7de", "ra\u00b7get", "es", "hoch", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Welches ich sah, und nach dess Anblick", "tokens": ["Wel\u00b7ches", "ich", "sah", ",", "und", "nach", "dess", "An\u00b7blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Ich kaum entronnen bin", "tokens": ["Ich", "kaum", "ent\u00b7ron\u00b7nen", "bin"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Zu werden ein Menschenfeind.", "tokens": ["Zu", "wer\u00b7den", "ein", "Men\u00b7schen\u00b7feind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Verderber ist er der Menschenhass", "tokens": ["Ver\u00b7der\u00b7ber", "ist", "er", "der", "Men\u00b7schen\u00b7hass"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem, welcher durch ihn vergramt;", "tokens": ["Dem", ",", "wel\u00b7cher", "durch", "ihn", "ver\u00b7gramt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und dem, den er trift,", "tokens": ["Und", "dem", ",", "den", "er", "trift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "F\u00fcrchterlich, f\u00fcrchterlich!", "tokens": ["F\u00fcrch\u00b7ter\u00b7lich", ",", "f\u00fcrch\u00b7ter\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.3": {"line.1": {"text": "Er ist es, der immer Greuel", "tokens": ["Er", "ist", "es", ",", "der", "im\u00b7mer", "Greu\u00b7el"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "ADV", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Meiner ganzen Seele war:", "tokens": ["Mei\u00b7ner", "gan\u00b7zen", "See\u00b7le", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dennoch bin ich kaum", "tokens": ["Und", "den\u00b7noch", "bin", "ich", "kaum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dem Ungeheuer entflohn.", "tokens": ["Dem", "Un\u00b7ge\u00b7heu\u00b7er", "ent\u00b7flohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Denn ihr w\u00fcthet einher, klaget an,", "tokens": ["Denn", "ihr", "w\u00fct\u00b7het", "ein\u00b7her", ",", "kla\u00b7get", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Vor euch selbst, Dess Vorsehung,", "tokens": ["Vor", "euch", "selbst", ",", "Dess", "Vor\u00b7se\u00b7hung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llt Endurtheil \u00fcber Den,", "tokens": ["F\u00e4llt", "End\u00b7urt\u00b7heil", "\u00fc\u00b7ber", "Den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Welcher die Orione,", "tokens": ["Wel\u00b7cher", "die", "O\u00b7rio\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Des Leun Herz, die hohe Wagschaal,", "tokens": ["Des", "Leun", "Herz", ",", "die", "ho\u00b7he", "Wag\u00b7schaal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Den Adler, die Urne, den Lichtaltar,", "tokens": ["Den", "Ad\u00b7ler", ",", "die", "Ur\u00b7ne", ",", "den", "Lich\u00b7tal\u00b7tar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die Ros' in dem Kranz', auch unsre Rose", "tokens": ["Die", "Ros'", "in", "dem", "Kranz'", ",", "auch", "uns\u00b7re", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gemacht hat, bev\u00f6lkert hat!", "tokens": ["Ge\u00b7macht", "hat", ",", "be\u00b7v\u00f6l\u00b7kert", "hat", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Denn ihr andern kriechet einher, vertheidiget,", "tokens": ["Denn", "ihr", "an\u00b7dern", "krie\u00b7chet", "ein\u00b7her", ",", "ver\u00b7thei\u00b7di\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VVFIN", "PTKVZ", "$,", "VVFIN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Vor jener Gericht, Dess Vorsehung,", "tokens": ["Vor", "je\u00b7ner", "Ge\u00b7richt", ",", "Dess", "Vor\u00b7se\u00b7hung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den, der gemacht hat", "tokens": ["Den", ",", "der", "ge\u00b7macht", "hat"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "VVPP", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Die Sterne des leuchtenden Pfades, bev\u00f6lkert hat!", "tokens": ["Die", "Ster\u00b7ne", "des", "leuch\u00b7ten\u00b7den", "Pfa\u00b7des", ",", "be\u00b7v\u00f6l\u00b7kert", "hat", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}}, "stanza.7": {"line.1": {"text": "Vertheidigt? ha, ihr entschuldigt!", "tokens": ["Ver\u00b7thei\u00b7digt", "?", "ha", ",", "ihr", "ent\u00b7schul\u00b7digt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$.", "NE", "$,", "PPER", "VVPP", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Mit schwachen Gr\u00fcnden, oder, mit th\u00f6richten,", "tokens": ["Mit", "schwa\u00b7chen", "Gr\u00fcn\u00b7den", ",", "o\u00b7der", ",", "mit", "th\u00f6\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "$,", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Dingen, die ihr in der Wirklichkeiten Reih", "tokens": ["Mit", "Din\u00b7gen", ",", "die", "ihr", "in", "der", "Wirk\u00b7lich\u00b7kei\u00b7ten", "Reih"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hineinl\u00fcgt, entschuldigt ihr.", "tokens": ["Hin\u00b7ein\u00b7l\u00fcgt", ",", "ent\u00b7schul\u00b7digt", "ihr", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Auch vor euch mag ich Seinen Namen nicht nennen!", "tokens": ["Auch", "vor", "euch", "mag", "ich", "Sei\u00b7nen", "Na\u00b7men", "nicht", "nen\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+----", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Des tiefen Untersuchers Geist, der Ihn", "tokens": ["Des", "tie\u00b7fen", "Un\u00b7ter\u00b7su\u00b7chers", "Geist", ",", "der", "Ihn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Niemals anders, als, mit feyrlichem Ernst", "tokens": ["Nie\u00b7mals", "an\u00b7ders", ",", "als", ",", "mit", "feyr\u00b7li\u00b7chem", "Ernst"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "In sich versenkt,", "tokens": ["In", "sich", "ver\u00b7senkt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVPP", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Als, nach frommen Schweigen,", "tokens": ["Als", ",", "nach", "from\u00b7men", "Schwei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als mit entbl\u00f6sstem Haupt', aussprach,", "tokens": ["Als", "mit", "ent\u00b7bl\u00f6ss\u00b7tem", "Haupt'", ",", "aus\u00b7sprach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der grosse Todte m\u00f6chte mir erscheinen,", "tokens": ["Der", "gros\u00b7se", "Tod\u00b7te", "m\u00f6ch\u00b7te", "mir", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und der Nennung mich zeihn.", "tokens": ["Und", "der", "Nen\u00b7nung", "mich", "zeihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.10": {"line.1": {"text": "Einer Meinung gl\u00fchendes Bild", "tokens": ["Ei\u00b7ner", "Mei\u00b7nung", "gl\u00fc\u00b7hen\u00b7des", "Bild"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schwebt mir, (o w\u00e4re sie Wahn!) vor der Stirn;", "tokens": ["Schwebt", "mir", ",", "(", "o", "w\u00e4\u00b7re", "sie", "Wahn", "!", ")", "vor", "der", "Stirn", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "FM", "VAFIN", "PPER", "NN", "$.", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und nur wenige Zweifel", "tokens": ["Und", "nur", "we\u00b7ni\u00b7ge", "Zwei\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Widersprechen ihr laut.", "tokens": ["Wi\u00b7der\u00b7spre\u00b7chen", "ihr", "laut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.11": {"line.1": {"text": "Sollten Seelen,", "tokens": ["Soll\u00b7ten", "See\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Die (wendet euch, h\u00f6rt mich nicht!) Gott", "tokens": ["Die", "(", "wen\u00b7det", "euch", ",", "h\u00f6rt", "mich", "nicht", "!", ")", "Gott"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Anklagen, richten, entschuldigen,", "tokens": ["An\u00b7kla\u00b7gen", ",", "rich\u00b7ten", ",", "ent\u00b7schul\u00b7di\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Diese Seelen unsterblich seyn?", "tokens": ["Die\u00b7se", "See\u00b7len", "uns\u00b7terb\u00b7lich", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "VAINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.12": {"line.1": {"text": "\u00dcber alles Zornentflammende raget es hoch empor,", "tokens": ["\u00dc\u00b7ber", "al\u00b7les", "Zor\u00b7nent\u00b7flam\u00b7men\u00b7de", "ra\u00b7get", "es", "hoch", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+--+--+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Welches ich sah, und nach dess Anblick", "tokens": ["Wel\u00b7ches", "ich", "sah", ",", "und", "nach", "dess", "An\u00b7blick"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Ich kaum entronnen bin", "tokens": ["Ich", "kaum", "ent\u00b7ron\u00b7nen", "bin"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Zu werden ein Menschenfeind.", "tokens": ["Zu", "wer\u00b7den", "ein", "Men\u00b7schen\u00b7feind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Verderber ist er der Menschenhass", "tokens": ["Ver\u00b7der\u00b7ber", "ist", "er", "der", "Men\u00b7schen\u00b7hass"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dem, welcher durch ihn vergramt;", "tokens": ["Dem", ",", "wel\u00b7cher", "durch", "ihn", "ver\u00b7gramt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und dem, den er trift,", "tokens": ["Und", "dem", ",", "den", "er", "trift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "F\u00fcrchterlich, f\u00fcrchterlich!", "tokens": ["F\u00fcrch\u00b7ter\u00b7lich", ",", "f\u00fcrch\u00b7ter\u00b7lich", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.14": {"line.1": {"text": "Er ist es, der immer Greuel", "tokens": ["Er", "ist", "es", ",", "der", "im\u00b7mer", "Greu\u00b7el"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "ADV", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Meiner ganzen Seele war:", "tokens": ["Mei\u00b7ner", "gan\u00b7zen", "See\u00b7le", "war", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und dennoch bin ich kaum", "tokens": ["Und", "den\u00b7noch", "bin", "ich", "kaum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Dem Ungeheuer entflohn.", "tokens": ["Dem", "Un\u00b7ge\u00b7heu\u00b7er", "ent\u00b7flohn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Denn ihr w\u00fcthet einher, klaget an,", "tokens": ["Denn", "ihr", "w\u00fct\u00b7het", "ein\u00b7her", ",", "kla\u00b7get", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKVZ", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Vor euch selbst, Dess Vorsehung,", "tokens": ["Vor", "euch", "selbst", ",", "Dess", "Vor\u00b7se\u00b7hung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "F\u00e4llt Endurtheil \u00fcber Den,", "tokens": ["F\u00e4llt", "End\u00b7urt\u00b7heil", "\u00fc\u00b7ber", "Den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Welcher die Orione,", "tokens": ["Wel\u00b7cher", "die", "O\u00b7rio\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PWAT", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Des Leun Herz, die hohe Wagschaal,", "tokens": ["Des", "Leun", "Herz", ",", "die", "ho\u00b7he", "Wag\u00b7schaal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Den Adler, die Urne, den Lichtaltar,", "tokens": ["Den", "Ad\u00b7ler", ",", "die", "Ur\u00b7ne", ",", "den", "Lich\u00b7tal\u00b7tar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die Ros' in dem Kranz', auch unsre Rose", "tokens": ["Die", "Ros'", "in", "dem", "Kranz'", ",", "auch", "uns\u00b7re", "Ro\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "ADV", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gemacht hat, bev\u00f6lkert hat!", "tokens": ["Ge\u00b7macht", "hat", ",", "be\u00b7v\u00f6l\u00b7kert", "hat", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Denn ihr andern kriechet einher, vertheidiget,", "tokens": ["Denn", "ihr", "an\u00b7dern", "krie\u00b7chet", "ein\u00b7her", ",", "ver\u00b7thei\u00b7di\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "PIS", "VVFIN", "PTKVZ", "$,", "VVFIN", "$,"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Vor jener Gericht, Dess Vorsehung,", "tokens": ["Vor", "je\u00b7ner", "Ge\u00b7richt", ",", "Dess", "Vor\u00b7se\u00b7hung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den, der gemacht hat", "tokens": ["Den", ",", "der", "ge\u00b7macht", "hat"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "VVPP", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Die Sterne des leuchtenden Pfades, bev\u00f6lkert hat!", "tokens": ["Die", "Ster\u00b7ne", "des", "leuch\u00b7ten\u00b7den", "Pfa\u00b7des", ",", "be\u00b7v\u00f6l\u00b7kert", "hat", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,", "VVPP", "VAFIN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}}, "stanza.18": {"line.1": {"text": "Vertheidigt? ha, ihr entschuldigt!", "tokens": ["Ver\u00b7thei\u00b7digt", "?", "ha", ",", "ihr", "ent\u00b7schul\u00b7digt", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$.", "NE", "$,", "PPER", "VVPP", "$."], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Mit schwachen Gr\u00fcnden, oder, mit th\u00f6richten,", "tokens": ["Mit", "schwa\u00b7chen", "Gr\u00fcn\u00b7den", ",", "o\u00b7der", ",", "mit", "th\u00f6\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "KON", "$,", "APPR", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Dingen, die ihr in der Wirklichkeiten Reih", "tokens": ["Mit", "Din\u00b7gen", ",", "die", "ihr", "in", "der", "Wirk\u00b7lich\u00b7kei\u00b7ten", "Reih"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hineinl\u00fcgt, entschuldigt ihr.", "tokens": ["Hin\u00b7ein\u00b7l\u00fcgt", ",", "ent\u00b7schul\u00b7digt", "ihr", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Auch vor euch mag ich Seinen Namen nicht nennen!", "tokens": ["Auch", "vor", "euch", "mag", "ich", "Sei\u00b7nen", "Na\u00b7men", "nicht", "nen\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VMFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+----", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Des tiefen Untersuchers Geist, der Ihn", "tokens": ["Des", "tie\u00b7fen", "Un\u00b7ter\u00b7su\u00b7chers", "Geist", ",", "der", "Ihn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Niemals anders, als, mit feyrlichem Ernst", "tokens": ["Nie\u00b7mals", "an\u00b7ders", ",", "als", ",", "mit", "feyr\u00b7li\u00b7chem", "Ernst"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "$,", "APPR", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "In sich versenkt,", "tokens": ["In", "sich", "ver\u00b7senkt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVPP", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.20": {"line.1": {"text": "Als, nach frommen Schweigen,", "tokens": ["Als", ",", "nach", "from\u00b7men", "Schwei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Als mit entbl\u00f6sstem Haupt', aussprach,", "tokens": ["Als", "mit", "ent\u00b7bl\u00f6ss\u00b7tem", "Haupt'", ",", "aus\u00b7sprach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der grosse Todte m\u00f6chte mir erscheinen,", "tokens": ["Der", "gros\u00b7se", "Tod\u00b7te", "m\u00f6ch\u00b7te", "mir", "er\u00b7schei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und der Nennung mich zeihn.", "tokens": ["Und", "der", "Nen\u00b7nung", "mich", "zeihn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.21": {"line.1": {"text": "Einer Meinung gl\u00fchendes Bild", "tokens": ["Ei\u00b7ner", "Mei\u00b7nung", "gl\u00fc\u00b7hen\u00b7des", "Bild"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schwebt mir, (o w\u00e4re sie Wahn!) vor der Stirn;", "tokens": ["Schwebt", "mir", ",", "(", "o", "w\u00e4\u00b7re", "sie", "Wahn", "!", ")", "vor", "der", "Stirn", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "FM", "VAFIN", "PPER", "NN", "$.", "$(", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und nur wenige Zweifel", "tokens": ["Und", "nur", "we\u00b7ni\u00b7ge", "Zwei\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "PIAT", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Widersprechen ihr laut.", "tokens": ["Wi\u00b7der\u00b7spre\u00b7chen", "ihr", "laut", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.22": {"line.1": {"text": "Sollten Seelen,", "tokens": ["Soll\u00b7ten", "See\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Die (wendet euch, h\u00f6rt mich nicht!) Gott", "tokens": ["Die", "(", "wen\u00b7det", "euch", ",", "h\u00f6rt", "mich", "nicht", "!", ")", "Gott"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Anklagen, richten, entschuldigen,", "tokens": ["An\u00b7kla\u00b7gen", ",", "rich\u00b7ten", ",", "ent\u00b7schul\u00b7di\u00b7gen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVPP", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Diese Seelen unsterblich seyn?", "tokens": ["Die\u00b7se", "See\u00b7len", "uns\u00b7terb\u00b7lich", "seyn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADJD", "VAINF", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}}}}