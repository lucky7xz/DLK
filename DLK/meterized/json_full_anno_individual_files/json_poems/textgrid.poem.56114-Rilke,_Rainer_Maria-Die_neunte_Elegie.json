{"textgrid.poem.56114": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Die neunte Elegie", "genre": "verse", "period": "N.A.", "pub_year": 1917, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Warum, wenn es angeht, also die Frist des Daseins", "tokens": ["Wa\u00b7rum", ",", "wenn", "es", "an\u00b7geht", ",", "al\u00b7so", "die", "Frist", "des", "Da\u00b7seins"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+--+----+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "hinzubringen, als Lorbeer, ein wenig dunkler als alles", "tokens": ["hin\u00b7zu\u00b7brin\u00b7gen", ",", "als", "Lor\u00b7beer", ",", "ein", "we\u00b7nig", "dunk\u00b7ler", "als", "al\u00b7les"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "NN", "$,", "ART", "PIAT", "ADJA", "KOUS", "PIS"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "andere Gr\u00fcn, mit kleinen Wellen an jedem", "tokens": ["an\u00b7de\u00b7re", "Gr\u00fcn", ",", "mit", "klei\u00b7nen", "Wel\u00b7len", "an", "je\u00b7dem"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "APPR", "ADJA", "NN", "APPR", "PIAT"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Blattrand (wie eines Windes L\u00e4cheln) \u2013: warum dann", "tokens": ["Blatt\u00b7rand", "(", "wie", "ei\u00b7nes", "Win\u00b7des", "L\u00e4\u00b7cheln", ")", "\u2013", ":", "wa\u00b7rum", "dann"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["NE", "$(", "KOKOM", "ART", "NN", "NN", "$(", "$(", "$.", "PWAV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Menschliches m\u00fcssen \u2013 und, Schicksal vermeidend,", "tokens": ["Menschli\u00b7ches", "m\u00fcs\u00b7sen", "\u2013", "und", ",", "Schick\u00b7sal", "ver\u00b7mei\u00b7dend", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$(", "KON", "$,", "NN", "VVPP", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "sich sehnen nach Schicksal?...", "tokens": ["sich", "seh\u00b7nen", "nach", "Schick\u00b7sal", "?", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Oh, ", "tokens": ["Oh", ","], "token_info": ["word", "punct"], "pos": ["ITJ", "$,"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "dieser voreilige Vorteil eines nahen Verlusts.", "tokens": ["die\u00b7ser", "vor\u00b7ei\u00b7li\u00b7ge", "Vor\u00b7teil", "ei\u00b7nes", "na\u00b7hen", "Ver\u00b7lusts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nicht aus Neugier, oder zur \u00dcbung des Herzens,", "tokens": ["Nicht", "aus", "Neu\u00b7gier", ",", "o\u00b7der", "zur", "\u00dc\u00b7bung", "des", "Her\u00b7zens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "das auch im Lorbeer ", "tokens": ["das", "auch", "im", "Lor\u00b7beer"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPRART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Aber weil Hiersein viel ist, und weil uns scheinbar", "tokens": ["A\u00b7ber", "weil", "Hier\u00b7sein", "viel", "ist", ",", "und", "weil", "uns", "schein\u00b7bar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ADV", "VAFIN", "$,", "KON", "KOUS", "PPER", "ADJD"], "meter": "+-++--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "alles das Hiesige braucht, dieses Schwindende, das", "tokens": ["al\u00b7les", "das", "Hie\u00b7si\u00b7ge", "braucht", ",", "die\u00b7ses", "Schwin\u00b7den\u00b7de", ",", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PIS", "ART", "NN", "VVFIN", "$,", "PDAT", "NN", "$,", "PRELS"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.3": {"text": "seltsam uns angeht. Uns, die Schwindendsten. ", "tokens": ["selt\u00b7sam", "uns", "an\u00b7geht", ".", "Uns", ",", "die", "Schwin\u00b7dends\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "$.", "PPER", "$,", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "jedes, nur ", "tokens": ["je\u00b7des", ",", "nur"], "token_info": ["word", "punct", "word"], "pos": ["PIAT", "$,", "ADV"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Und so dr\u00e4ngen wir uns und wollen es leisten,", "tokens": ["Und", "so", "dr\u00e4n\u00b7gen", "wir", "uns", "und", "wol\u00b7len", "es", "leis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "wollens enthalten in unsern einfachen H\u00e4nden,", "tokens": ["wol\u00b7lens", "ent\u00b7hal\u00b7ten", "in", "un\u00b7sern", "ein\u00b7fa\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.3": {"text": "im \u00fcberf\u00fcllteren Blick und im sprachlosen Herzen.", "tokens": ["im", "\u00fc\u00b7berf\u00b7\u00fcll\u00b7te\u00b7ren", "Blick", "und", "im", "sprach\u00b7lo\u00b7sen", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wollen es werden. \u2013 Wem es geben? Am liebsten", "tokens": ["Wol\u00b7len", "es", "wer\u00b7den", ".", "\u2013", "Wem", "es", "ge\u00b7ben", "?", "Am", "liebs\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "VAINF", "$.", "$(", "PWS", "PPER", "VVINF", "$.", "APPRART", "ADJA"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "alles behalten f\u00fcr immer... Ach, in den andern Bezug,", "tokens": ["al\u00b7les", "be\u00b7hal\u00b7ten", "f\u00fcr", "im\u00b7mer", "...", "Ach", ",", "in", "den", "an\u00b7dern", "Be\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "APPR", "ADV", "$(", "ITJ", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+--+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "wehe, was nimmt man hin\u00fcber? Nicht das Anschaun, das hier", "tokens": ["we\u00b7he", ",", "was", "nimmt", "man", "hin\u00b7\u00fc\u00b7ber", "?", "Nicht", "das", "An\u00b7schaun", ",", "das", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "$,", "PWS", "VVFIN", "PIS", "ADV", "$.", "PTKNEG", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.7": {"text": "langsam erlernte, und kein hier Ereignetes. Keins.", "tokens": ["lang\u00b7sam", "er\u00b7lern\u00b7te", ",", "und", "kein", "hier", "Er\u00b7eig\u00b7ne\u00b7tes", ".", "Keins", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "KON", "PIAT", "ADV", "NN", "$.", "NN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.8": {"text": "Also die Schmerzen. Also vor allem das Schwersein,", "tokens": ["Al\u00b7so", "die", "Schmer\u00b7zen", ".", "Al\u00b7so", "vor", "al\u00b7lem", "das", "Schwer\u00b7sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$.", "ADV", "APPR", "PIS", "ART", "NN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "also der Liebe lange Erfahrung, \u2013 also", "tokens": ["al\u00b7so", "der", "Lie\u00b7be", "lan\u00b7ge", "Er\u00b7fah\u00b7rung", ",", "\u2013", "al\u00b7so"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,", "$(", "ADV"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "lauter Uns\u00e4gliches. Aber sp\u00e4ter,", "tokens": ["lau\u00b7ter", "Un\u00b7s\u00e4g\u00b7li\u00b7ches", ".", "A\u00b7ber", "sp\u00e4\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "KON", "ADJD", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.11": {"text": "unter den Sternen, was solls: ", "tokens": ["un\u00b7ter", "den", "Ster\u00b7nen", ",", "was", "solls", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWS", "VMFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.12": {"text": "Bringt doch der Wanderer auch vom Hange des Bergrands", "tokens": ["Bringt", "doch", "der", "Wan\u00b7de\u00b7rer", "auch", "vom", "Han\u00b7ge", "des", "Ber\u00b7grands"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.13": {"text": "nicht eine Hand voll Erde ins Tal, die Allen uns\u00e4gliche, sondern", "tokens": ["nicht", "ei\u00b7ne", "Hand", "voll", "Er\u00b7de", "ins", "Tal", ",", "die", "Al\u00b7len", "un\u00b7s\u00e4g\u00b7li\u00b7che", ",", "son\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PTKNEG", "ART", "NN", "ADJD", "NN", "APPRART", "NN", "$,", "PRELS", "PIAT", "ADJA", "$,", "KON"], "meter": "++-+-+--+-+-++--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.14": {"text": "ein erworbenes Wort, reines, den gelben und blaun", "tokens": ["ein", "er\u00b7wor\u00b7be\u00b7nes", "Wort", ",", "rei\u00b7nes", ",", "den", "gel\u00b7ben", "und", "blaun"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "$,", "ART", "ADJA", "KON", "VVINF"], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Enzian. Sind wir vielleicht ", "tokens": ["En\u00b7zi\u00b7an", ".", "Sind", "wir", "viel\u00b7leicht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Br\u00fccke, Brunnen, Tor, Krug, Obstbaum, Fenster, \u2013", "tokens": ["Br\u00fc\u00b7cke", ",", "Brun\u00b7nen", ",", "Tor", ",", "Krug", ",", "Obst\u00b7baum", ",", "Fens\u00b7ter", ",", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "h\u00f6chstens: S\u00e4ule, Turm.... aber zu ", "tokens": ["h\u00f6chs\u00b7tens", ":", "S\u00e4u\u00b7le", ",", "Turm", "....", "a\u00b7ber", "zu"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "$.", "NN", "$,", "NN", "$.", "ADV", "APPR"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "oh zu sagen so, wie selber die Dinge niemals", "tokens": ["oh", "zu", "sa\u00b7gen", "so", ",", "wie", "sel\u00b7ber", "die", "Din\u00b7ge", "nie\u00b7mals"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "ADV", "$,", "PWAV", "ADV", "ART", "NN", "ADV"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "innig meinten zu sein. Ist nicht die heimliche List", "tokens": ["in\u00b7nig", "mein\u00b7ten", "zu", "sein", ".", "Ist", "nicht", "die", "heim\u00b7li\u00b7che", "List"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PTKZU", "VAINF", "$.", "VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "dieser verschwiegenen Erde, wenn sie die Liebenden dr\u00e4ngt,", "tokens": ["die\u00b7ser", "ver\u00b7schwie\u00b7ge\u00b7nen", "Er\u00b7de", ",", "wenn", "sie", "die", "Lie\u00b7ben\u00b7den", "dr\u00e4ngt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+--+--+", "measure": "dactylic.di.plus"}, "line.21": {"text": "da\u00df sich in ihrem Gef\u00fchl jedes und jedes entz\u00fcckt?", "tokens": ["da\u00df", "sich", "in", "ih\u00b7rem", "Ge\u00b7f\u00fchl", "je\u00b7des", "und", "je\u00b7des", "ent\u00b7z\u00fcckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PPOSAT", "NN", "PIAT", "KON", "PIAT", "VVPP", "$."], "meter": "-+-+---+--+--+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Schwelle: was ists f\u00fcr zwei", "tokens": ["Schwel\u00b7le", ":", "was", "ists", "f\u00fcr", "zwei"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PWS", "VAFIN", "APPR", "CARD"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.23": {"text": "Liebende, da\u00df sie die eigne \u00e4ltere Schwelle der T\u00fcr", "tokens": ["Lie\u00b7ben\u00b7de", ",", "da\u00df", "sie", "die", "eig\u00b7ne", "\u00e4l\u00b7te\u00b7re", "Schwel\u00b7le", "der", "T\u00fcr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "ADJA", "ADJA", "NN", "ART", "NN"], "meter": "+--+--+-+--+--+", "measure": "dactylic.di.plus"}, "line.24": {"text": "ein wenig verbrauchen, auch sie, nach den vielen vorher", "tokens": ["ein", "we\u00b7nig", "ver\u00b7brau\u00b7chen", ",", "auch", "sie", ",", "nach", "den", "vie\u00b7len", "vor\u00b7her"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVINF", "$,", "ADV", "PPER", "$,", "APPR", "ART", "PIAT", "ADJA"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "und vor den K\u00fcnftigen ...., leicht.", "tokens": ["und", "vor", "den", "K\u00fcnf\u00b7ti\u00b7gen", "....", ",", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "$,", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "Sprich und bekenn. Mehr als je", "tokens": ["Sprich", "und", "be\u00b7kenn", ".", "Mehr", "als", "je"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "KON", "VVFIN", "$.", "PIAT", "KOKOM", "ADV"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "fallen die Dinge dahin, die erlebbaren, denn,", "tokens": ["fal\u00b7len", "die", "Din\u00b7ge", "da\u00b7hin", ",", "die", "er\u00b7leb\u00b7ba\u00b7ren", ",", "denn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PAV", "$,", "PRELS", "VVINF", "$,", "KON", "$,"], "meter": "+--+--+---+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "was sie verdr\u00e4ngend ersetzt, ist ein Tun ohne Bild.", "tokens": ["was", "sie", "ver\u00b7dr\u00e4n\u00b7gend", "er\u00b7setzt", ",", "ist", "ein", "Tun", "oh\u00b7ne", "Bild", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$,", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Tun unter Krusten, die willig zerspringen, sobald", "tokens": ["Tun", "un\u00b7ter", "Krus\u00b7ten", ",", "die", "wil\u00b7lig", "zer\u00b7sprin\u00b7gen", ",", "so\u00b7bald"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NE", "APPR", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,", "KOUS"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.5": {"text": "innen das Handeln entw\u00e4chst und sich anders begrenzt.", "tokens": ["in\u00b7nen", "das", "Han\u00b7deln", "ent\u00b7w\u00e4chst", "und", "sich", "an\u00b7ders", "be\u00b7grenzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "PRF", "ADV", "VVPP", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.6": {"text": "Zwischen den H\u00e4mmern besteht", "tokens": ["Zwi\u00b7schen", "den", "H\u00e4m\u00b7mern", "be\u00b7steht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "unser Herz, wie die Zunge", "tokens": ["un\u00b7ser", "Herz", ",", "wie", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "zwischen den Z\u00e4hnen, die doch,", "tokens": ["zwi\u00b7schen", "den", "Z\u00e4h\u00b7nen", ",", "die", "doch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "dennoch, die preisende bleibt.", "tokens": ["den\u00b7noch", ",", "die", "prei\u00b7sen\u00b7de", "bleibt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVFIN", "$."], "meter": "---+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Preise dem Engel die Welt, nicht die uns\u00e4gliche, ", "tokens": ["Prei\u00b7se", "dem", "En\u00b7gel", "die", "Welt", ",", "nicht", "die", "un\u00b7s\u00e4g\u00b7li\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,", "PTKNEG", "ART", "ADJA", "$,"], "meter": "+--+--+-+-+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "kannst du nicht gro\u00dftun mit herrlich Erf\u00fchltem; im Weltall,", "tokens": ["kannst", "du", "nicht", "gro\u00df\u00b7tun", "mit", "herr\u00b7lich", "Er\u00b7f\u00fchl\u00b7tem", ";", "im", "Wel\u00b7tall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "APPR", "ADJD", "NN", "$.", "APPRART", "NN", "$,"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.3": {"text": "wo er f\u00fchlender f\u00fchlt, bist du ein Neuling. Drum zeig", "tokens": ["wo", "er", "f\u00fch\u00b7len\u00b7der", "f\u00fchlt", ",", "bist", "du", "ein", "Neu\u00b7ling", ".", "Drum", "zeig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "ART", "NN", "$.", "PAV", "VVFIN"], "meter": "+-+--+-+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "ihm das Einfache, das, von Geschlecht zu Geschlechtern gestaltet,", "tokens": ["ihm", "das", "Ein\u00b7fa\u00b7che", ",", "das", ",", "von", "Ge\u00b7schlecht", "zu", "Ge\u00b7schlech\u00b7tern", "ge\u00b7stal\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "PDS", "$,", "APPR", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "als ein Unsriges lebt, neben der Hand und im Blick.", "tokens": ["als", "ein", "Uns\u00b7ri\u00b7ges", "lebt", ",", "ne\u00b7ben", "der", "Hand", "und", "im", "Blick", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Sag ihm die Dinge. Er wird staunender stehn; wie du standest", "tokens": ["Sag", "ihm", "die", "Din\u00b7ge", ".", "Er", "wird", "stau\u00b7nen\u00b7der", "stehn", ";", "wie", "du", "stan\u00b7dest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "$.", "PPER", "VAFIN", "ADJD", "VVINF", "$.", "PWAV", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.7": {"text": "bei dem Seiler in Rom, oder beim T\u00f6pfer am Nil.", "tokens": ["bei", "dem", "Sei\u00b7ler", "in", "Rom", ",", "o\u00b7der", "beim", "T\u00f6p\u00b7fer", "am", "Nil", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$,", "KON", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Zeig ihm, wie gl\u00fccklich ein Ding sein kann, wie schuldlos und unser,", "tokens": ["Zeig", "ihm", ",", "wie", "gl\u00fcck\u00b7lich", "ein", "Ding", "sein", "kann", ",", "wie", "schuld\u00b7los", "und", "un\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "PWAV", "ADJD", "ART", "NN", "VAINF", "VMFIN", "$,", "PWAV", "ADJD", "KON", "PPOSAT", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "wie selbst das klagende Leid rein zur Gestalt sich entschlie\u00dft,", "tokens": ["wie", "selbst", "das", "kla\u00b7gen\u00b7de", "Leid", "rein", "zur", "Ge\u00b7stalt", "sich", "ent\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ADJD", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+--+---+--+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "dient als ein Ding, oder stirbt in ein Ding \u2013, und jenseits", "tokens": ["dient", "als", "ein", "Ding", ",", "o\u00b7der", "stirbt", "in", "ein", "Ding", "\u2013", ",", "und", "jen\u00b7seits"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "$,", "KON", "VVFIN", "APPR", "ART", "NN", "$(", "$,", "KON", "ADV"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.11": {"text": "selig der Geige entgeht. \u2013 Und diese, von Hingang", "tokens": ["se\u00b7lig", "der", "Gei\u00b7ge", "ent\u00b7geht", ".", "\u2013", "Und", "die\u00b7se", ",", "von", "Hin\u00b7gang"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$.", "$(", "KON", "PDS", "$,", "APPR", "NN"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.12": {"text": "lebenden Dinge verstehn, da\u00df du sie r\u00fchmst; verg\u00e4nglich,", "tokens": ["le\u00b7ben\u00b7den", "Din\u00b7ge", "ver\u00b7stehn", ",", "da\u00df", "du", "sie", "r\u00fchmst", ";", "ver\u00b7g\u00e4ng\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$.", "ADJD", "$,"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.13": {"text": "traun sie ein Rettendes uns, den Verg\u00e4nglichsten, zu.", "tokens": ["traun", "sie", "ein", "Ret\u00b7ten\u00b7des", "uns", ",", "den", "Ver\u00b7g\u00e4ng\u00b7lichs\u00b7ten", ",", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPER", "$,", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.14": {"text": "Wollen, wir sollen sie ganz im unsichtbarn Herzen verwandeln", "tokens": ["Wol\u00b7len", ",", "wir", "sol\u00b7len", "sie", "ganz", "im", "un\u00b7sicht\u00b7barn", "Her\u00b7zen", "ver\u00b7wan\u00b7deln"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "APPRART", "PPOSAT", "NN", "VVINF"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.15": {"text": "in \u2013 o unendlich \u2013 in uns! Wer wir am Ende auch seien.", "tokens": ["in", "\u2013", "o", "un\u00b7end\u00b7lich", "\u2013", "in", "uns", "!", "Wer", "wir", "am", "En\u00b7de", "auch", "sei\u00b7en", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "FM", "ADJD", "$(", "APPR", "PPER", "$.", "PWS", "PPER", "APPRART", "NN", "ADV", "VAFIN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}}, "stanza.7": {"line.1": {"text": "Erde, ist es nicht dies, was du willst: ", "tokens": ["Er\u00b7de", ",", "ist", "es", "nicht", "dies", ",", "was", "du", "willst", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "PTKNEG", "PDS", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "in uns erstehn? \u2013 Ist es dein Traum nicht,", "tokens": ["in", "uns", "er\u00b7stehn", "?", "\u2013", "Ist", "es", "dein", "Traum", "nicht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$.", "$(", "VAFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+++", "measure": "unknown.measure.hexa"}, "line.3": {"text": "einmal unsichtbar zu sein? \u2013 Erde! unsichtbar!", "tokens": ["ein\u00b7mal", "un\u00b7sicht\u00b7bar", "zu", "sein", "?", "\u2013", "Er\u00b7de", "!", "un\u00b7sicht\u00b7bar", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "$.", "$(", "NN", "$.", "ADJD", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Was, wenn Verwandlung nicht, ist dein dr\u00e4ngender Auftrag?", "tokens": ["Was", ",", "wenn", "Ver\u00b7wand\u00b7lung", "nicht", ",", "ist", "dein", "dr\u00e4n\u00b7gen\u00b7der", "Auf\u00b7trag", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUS", "NN", "PTKNEG", "$,", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Erde, du liebe, ich will. Oh glaub, es bed\u00fcrfte", "tokens": ["Er\u00b7de", ",", "du", "lie\u00b7be", ",", "ich", "will", ".", "Oh", "glaub", ",", "es", "be\u00b7d\u00fcrf\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "$.", "ITJ", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "nicht deiner Fr\u00fchlinge mehr, mich dir zu gewinnen \u2013,", "tokens": ["nicht", "dei\u00b7ner", "Fr\u00fch\u00b7lin\u00b7ge", "mehr", ",", "mich", "dir", "zu", "ge\u00b7win\u00b7nen", "\u2013", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "ADV", "$,", "PPER", "PPER", "PTKZU", "VVINF", "$(", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "ach, ein einziger ist schon dem Blute zu viel.", "tokens": ["ach", ",", "ein", "ein\u00b7zi\u00b7ger", "ist", "schon", "dem", "Blu\u00b7te", "zu", "viel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "$,", "ART", "ADJA", "VAFIN", "ADV", "ART", "NN", "APPR", "PIS", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Namenlos bin ich zu dir entschlossen, von weit her.", "tokens": ["Na\u00b7men\u00b7los", "bin", "ich", "zu", "dir", "ent\u00b7schlos\u00b7sen", ",", "von", "weit", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,", "APPR", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.9": {"text": "Immer warst du im Recht, und dein heiliger Einfall", "tokens": ["Im\u00b7mer", "warst", "du", "im", "Recht", ",", "und", "dein", "hei\u00b7li\u00b7ger", "Ein\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "ist der vertrauliche Tod.", "tokens": ["ist", "der", "ver\u00b7trau\u00b7li\u00b7che", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.8": {"line.1": {"text": "Siehe, ich lebe. Woraus? Weder Kindheit noch Zukunft", "tokens": ["Sie\u00b7he", ",", "ich", "le\u00b7be", ".", "Wo\u00b7raus", "?", "We\u00b7der", "Kind\u00b7heit", "noch", "Zu\u00b7kunft"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "PPER", "VVFIN", "$.", "PWAV", "$.", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "werden weniger ....... \u00dcberz\u00e4hliges Dasein", "tokens": ["wer\u00b7den", "we\u00b7ni\u00b7ger", ".......", "\u00dc\u00b7berz\u00b7\u00e4h\u00b7li\u00b7ges", "Da\u00b7sein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "$(", "ADJA", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "entspringt mir im Herzen.", "tokens": ["ent\u00b7springt", "mir", "im", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.9": {"line.1": {"text": "Warum, wenn es angeht, also die Frist des Daseins", "tokens": ["Wa\u00b7rum", ",", "wenn", "es", "an\u00b7geht", ",", "al\u00b7so", "die", "Frist", "des", "Da\u00b7seins"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+--+----+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "hinzubringen, als Lorbeer, ein wenig dunkler als alles", "tokens": ["hin\u00b7zu\u00b7brin\u00b7gen", ",", "als", "Lor\u00b7beer", ",", "ein", "we\u00b7nig", "dunk\u00b7ler", "als", "al\u00b7les"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "$,", "KOUS", "NN", "$,", "ART", "PIAT", "ADJA", "KOUS", "PIS"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "andere Gr\u00fcn, mit kleinen Wellen an jedem", "tokens": ["an\u00b7de\u00b7re", "Gr\u00fcn", ",", "mit", "klei\u00b7nen", "Wel\u00b7len", "an", "je\u00b7dem"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "APPR", "ADJA", "NN", "APPR", "PIAT"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.4": {"text": "Blattrand (wie eines Windes L\u00e4cheln) \u2013: warum dann", "tokens": ["Blatt\u00b7rand", "(", "wie", "ei\u00b7nes", "Win\u00b7des", "L\u00e4\u00b7cheln", ")", "\u2013", ":", "wa\u00b7rum", "dann"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word"], "pos": ["NE", "$(", "KOKOM", "ART", "NN", "NN", "$(", "$(", "$.", "PWAV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Menschliches m\u00fcssen \u2013 und, Schicksal vermeidend,", "tokens": ["Menschli\u00b7ches", "m\u00fcs\u00b7sen", "\u2013", "und", ",", "Schick\u00b7sal", "ver\u00b7mei\u00b7dend", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "$(", "KON", "$,", "NN", "VVPP", "$,"], "meter": "+-+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "sich sehnen nach Schicksal?...", "tokens": ["sich", "seh\u00b7nen", "nach", "Schick\u00b7sal", "?", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "ADV", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Oh, ", "tokens": ["Oh", ","], "token_info": ["word", "punct"], "pos": ["ITJ", "$,"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "dieser voreilige Vorteil eines nahen Verlusts.", "tokens": ["die\u00b7ser", "vor\u00b7ei\u00b7li\u00b7ge", "Vor\u00b7teil", "ei\u00b7nes", "na\u00b7hen", "Ver\u00b7lusts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nicht aus Neugier, oder zur \u00dcbung des Herzens,", "tokens": ["Nicht", "aus", "Neu\u00b7gier", ",", "o\u00b7der", "zur", "\u00dc\u00b7bung", "des", "Her\u00b7zens", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "KON", "APPRART", "NN", "ART", "NN", "$,"], "meter": "+-+-+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "das auch im Lorbeer ", "tokens": ["das", "auch", "im", "Lor\u00b7beer"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPRART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Aber weil Hiersein viel ist, und weil uns scheinbar", "tokens": ["A\u00b7ber", "weil", "Hier\u00b7sein", "viel", "ist", ",", "und", "weil", "uns", "schein\u00b7bar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ADV", "ADV", "VAFIN", "$,", "KON", "KOUS", "PPER", "ADJD"], "meter": "+-++--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "alles das Hiesige braucht, dieses Schwindende, das", "tokens": ["al\u00b7les", "das", "Hie\u00b7si\u00b7ge", "braucht", ",", "die\u00b7ses", "Schwin\u00b7den\u00b7de", ",", "das"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PIS", "ART", "NN", "VVFIN", "$,", "PDAT", "NN", "$,", "PRELS"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.3": {"text": "seltsam uns angeht. Uns, die Schwindendsten. ", "tokens": ["selt\u00b7sam", "uns", "an\u00b7geht", ".", "Uns", ",", "die", "Schwin\u00b7dends\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VVFIN", "$.", "PPER", "$,", "ART", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "jedes, nur ", "tokens": ["je\u00b7des", ",", "nur"], "token_info": ["word", "punct", "word"], "pos": ["PIAT", "$,", "ADV"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "Und so dr\u00e4ngen wir uns und wollen es leisten,", "tokens": ["Und", "so", "dr\u00e4n\u00b7gen", "wir", "uns", "und", "wol\u00b7len", "es", "leis\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "KON", "VMFIN", "PPER", "VVINF", "$,"], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "wollens enthalten in unsern einfachen H\u00e4nden,", "tokens": ["wol\u00b7lens", "ent\u00b7hal\u00b7ten", "in", "un\u00b7sern", "ein\u00b7fa\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.3": {"text": "im \u00fcberf\u00fcllteren Blick und im sprachlosen Herzen.", "tokens": ["im", "\u00fc\u00b7berf\u00b7\u00fcll\u00b7te\u00b7ren", "Blick", "und", "im", "sprach\u00b7lo\u00b7sen", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "KON", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Wollen es werden. \u2013 Wem es geben? Am liebsten", "tokens": ["Wol\u00b7len", "es", "wer\u00b7den", ".", "\u2013", "Wem", "es", "ge\u00b7ben", "?", "Am", "liebs\u00b7ten"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "VAINF", "$.", "$(", "PWS", "PPER", "VVINF", "$.", "APPRART", "ADJA"], "meter": "+--+-+-+--+-", "measure": "iambic.penta.invert"}, "line.5": {"text": "alles behalten f\u00fcr immer... Ach, in den andern Bezug,", "tokens": ["al\u00b7les", "be\u00b7hal\u00b7ten", "f\u00fcr", "im\u00b7mer", "...", "Ach", ",", "in", "den", "an\u00b7dern", "Be\u00b7zug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "APPR", "ADV", "$(", "ITJ", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+--+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "wehe, was nimmt man hin\u00fcber? Nicht das Anschaun, das hier", "tokens": ["we\u00b7he", ",", "was", "nimmt", "man", "hin\u00b7\u00fc\u00b7ber", "?", "Nicht", "das", "An\u00b7schaun", ",", "das", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "$,", "PWS", "VVFIN", "PIS", "ADV", "$.", "PTKNEG", "ART", "NN", "$,", "PRELS", "ADV"], "meter": "+--+--+-+-+--+", "measure": "dactylic.di.plus"}, "line.7": {"text": "langsam erlernte, und kein hier Ereignetes. Keins.", "tokens": ["lang\u00b7sam", "er\u00b7lern\u00b7te", ",", "und", "kein", "hier", "Er\u00b7eig\u00b7ne\u00b7tes", ".", "Keins", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJD", "VVFIN", "$,", "KON", "PIAT", "ADV", "NN", "$.", "NN", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.8": {"text": "Also die Schmerzen. Also vor allem das Schwersein,", "tokens": ["Al\u00b7so", "die", "Schmer\u00b7zen", ".", "Al\u00b7so", "vor", "al\u00b7lem", "das", "Schwer\u00b7sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$.", "ADV", "APPR", "PIS", "ART", "NN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "also der Liebe lange Erfahrung, \u2013 also", "tokens": ["al\u00b7so", "der", "Lie\u00b7be", "lan\u00b7ge", "Er\u00b7fah\u00b7rung", ",", "\u2013", "al\u00b7so"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "ART", "NN", "ADJA", "NN", "$,", "$(", "ADV"], "meter": "+--+-+--+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "lauter Uns\u00e4gliches. Aber sp\u00e4ter,", "tokens": ["lau\u00b7ter", "Un\u00b7s\u00e4g\u00b7li\u00b7ches", ".", "A\u00b7ber", "sp\u00e4\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "$.", "KON", "ADJD", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.11": {"text": "unter den Sternen, was solls: ", "tokens": ["un\u00b7ter", "den", "Ster\u00b7nen", ",", "was", "solls", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PWS", "VMFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.12": {"text": "Bringt doch der Wanderer auch vom Hange des Bergrands", "tokens": ["Bringt", "doch", "der", "Wan\u00b7de\u00b7rer", "auch", "vom", "Han\u00b7ge", "des", "Ber\u00b7grands"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "APPRART", "NN", "ART", "NN"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.13": {"text": "nicht eine Hand voll Erde ins Tal, die Allen uns\u00e4gliche, sondern", "tokens": ["nicht", "ei\u00b7ne", "Hand", "voll", "Er\u00b7de", "ins", "Tal", ",", "die", "Al\u00b7len", "un\u00b7s\u00e4g\u00b7li\u00b7che", ",", "son\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PTKNEG", "ART", "NN", "ADJD", "NN", "APPRART", "NN", "$,", "PRELS", "PIAT", "ADJA", "$,", "KON"], "meter": "++-+-+--+-+-++--+-", "measure": "trochaic.octa.plus.relaxed"}, "line.14": {"text": "ein erworbenes Wort, reines, den gelben und blaun", "tokens": ["ein", "er\u00b7wor\u00b7be\u00b7nes", "Wort", ",", "rei\u00b7nes", ",", "den", "gel\u00b7ben", "und", "blaun"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ADJA", "$,", "ART", "ADJA", "KON", "VVINF"], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}, "line.15": {"text": "Enzian. Sind wir vielleicht ", "tokens": ["En\u00b7zi\u00b7an", ".", "Sind", "wir", "viel\u00b7leicht"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$.", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.16": {"text": "Br\u00fccke, Brunnen, Tor, Krug, Obstbaum, Fenster, \u2013", "tokens": ["Br\u00fc\u00b7cke", ",", "Brun\u00b7nen", ",", "Tor", ",", "Krug", ",", "Obst\u00b7baum", ",", "Fens\u00b7ter", ",", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "h\u00f6chstens: S\u00e4ule, Turm.... aber zu ", "tokens": ["h\u00f6chs\u00b7tens", ":", "S\u00e4u\u00b7le", ",", "Turm", "....", "a\u00b7ber", "zu"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "$.", "NN", "$,", "NN", "$.", "ADV", "APPR"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "oh zu sagen so, wie selber die Dinge niemals", "tokens": ["oh", "zu", "sa\u00b7gen", "so", ",", "wie", "sel\u00b7ber", "die", "Din\u00b7ge", "nie\u00b7mals"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "ADV", "$,", "PWAV", "ADV", "ART", "NN", "ADV"], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "innig meinten zu sein. Ist nicht die heimliche List", "tokens": ["in\u00b7nig", "mein\u00b7ten", "zu", "sein", ".", "Ist", "nicht", "die", "heim\u00b7li\u00b7che", "List"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PTKZU", "VAINF", "$.", "VAFIN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "+-+--++--+--+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "dieser verschwiegenen Erde, wenn sie die Liebenden dr\u00e4ngt,", "tokens": ["die\u00b7ser", "ver\u00b7schwie\u00b7ge\u00b7nen", "Er\u00b7de", ",", "wenn", "sie", "die", "Lie\u00b7ben\u00b7den", "dr\u00e4ngt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+-+--+--+", "measure": "dactylic.di.plus"}, "line.21": {"text": "da\u00df sich in ihrem Gef\u00fchl jedes und jedes entz\u00fcckt?", "tokens": ["da\u00df", "sich", "in", "ih\u00b7rem", "Ge\u00b7f\u00fchl", "je\u00b7des", "und", "je\u00b7des", "ent\u00b7z\u00fcckt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPR", "PPOSAT", "NN", "PIAT", "KON", "PIAT", "VVPP", "$."], "meter": "-+-+---+--+--+", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Schwelle: was ists f\u00fcr zwei", "tokens": ["Schwel\u00b7le", ":", "was", "ists", "f\u00fcr", "zwei"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "PWS", "VAFIN", "APPR", "CARD"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.23": {"text": "Liebende, da\u00df sie die eigne \u00e4ltere Schwelle der T\u00fcr", "tokens": ["Lie\u00b7ben\u00b7de", ",", "da\u00df", "sie", "die", "eig\u00b7ne", "\u00e4l\u00b7te\u00b7re", "Schwel\u00b7le", "der", "T\u00fcr"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "ART", "ADJA", "ADJA", "NN", "ART", "NN"], "meter": "+--+--+-+--+--+", "measure": "dactylic.di.plus"}, "line.24": {"text": "ein wenig verbrauchen, auch sie, nach den vielen vorher", "tokens": ["ein", "we\u00b7nig", "ver\u00b7brau\u00b7chen", ",", "auch", "sie", ",", "nach", "den", "vie\u00b7len", "vor\u00b7her"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVINF", "$,", "ADV", "PPER", "$,", "APPR", "ART", "PIAT", "ADJA"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "und vor den K\u00fcnftigen ...., leicht.", "tokens": ["und", "vor", "den", "K\u00fcnf\u00b7ti\u00b7gen", "....", ",", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$.", "$,", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Sprich und bekenn. Mehr als je", "tokens": ["Sprich", "und", "be\u00b7kenn", ".", "Mehr", "als", "je"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVIMP", "KON", "VVFIN", "$.", "PIAT", "KOKOM", "ADV"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "fallen die Dinge dahin, die erlebbaren, denn,", "tokens": ["fal\u00b7len", "die", "Din\u00b7ge", "da\u00b7hin", ",", "die", "er\u00b7leb\u00b7ba\u00b7ren", ",", "denn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PAV", "$,", "PRELS", "VVINF", "$,", "KON", "$,"], "meter": "+--+--+---+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "was sie verdr\u00e4ngend ersetzt, ist ein Tun ohne Bild.", "tokens": ["was", "sie", "ver\u00b7dr\u00e4n\u00b7gend", "er\u00b7setzt", ",", "ist", "ein", "Tun", "oh\u00b7ne", "Bild", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVPP", "$,", "VAFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Tun unter Krusten, die willig zerspringen, sobald", "tokens": ["Tun", "un\u00b7ter", "Krus\u00b7ten", ",", "die", "wil\u00b7lig", "zer\u00b7sprin\u00b7gen", ",", "so\u00b7bald"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["NE", "APPR", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,", "KOUS"], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.5": {"text": "innen das Handeln entw\u00e4chst und sich anders begrenzt.", "tokens": ["in\u00b7nen", "das", "Han\u00b7deln", "ent\u00b7w\u00e4chst", "und", "sich", "an\u00b7ders", "be\u00b7grenzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "PRF", "ADV", "VVPP", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.6": {"text": "Zwischen den H\u00e4mmern besteht", "tokens": ["Zwi\u00b7schen", "den", "H\u00e4m\u00b7mern", "be\u00b7steht"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.7": {"text": "unser Herz, wie die Zunge", "tokens": ["un\u00b7ser", "Herz", ",", "wie", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.8": {"text": "zwischen den Z\u00e4hnen, die doch,", "tokens": ["zwi\u00b7schen", "den", "Z\u00e4h\u00b7nen", ",", "die", "doch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.9": {"text": "dennoch, die preisende bleibt.", "tokens": ["den\u00b7noch", ",", "die", "prei\u00b7sen\u00b7de", "bleibt", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVFIN", "$."], "meter": "---+--+", "measure": "iambic.di.chol"}}, "stanza.14": {"line.1": {"text": "Preise dem Engel die Welt, nicht die uns\u00e4gliche, ", "tokens": ["Prei\u00b7se", "dem", "En\u00b7gel", "die", "Welt", ",", "nicht", "die", "un\u00b7s\u00e4g\u00b7li\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$,", "PTKNEG", "ART", "ADJA", "$,"], "meter": "+--+--+-+-+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "kannst du nicht gro\u00dftun mit herrlich Erf\u00fchltem; im Weltall,", "tokens": ["kannst", "du", "nicht", "gro\u00df\u00b7tun", "mit", "herr\u00b7lich", "Er\u00b7f\u00fchl\u00b7tem", ";", "im", "Wel\u00b7tall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PTKNEG", "ADJD", "APPR", "ADJD", "NN", "$.", "APPRART", "NN", "$,"], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.3": {"text": "wo er f\u00fchlender f\u00fchlt, bist du ein Neuling. Drum zeig", "tokens": ["wo", "er", "f\u00fch\u00b7len\u00b7der", "f\u00fchlt", ",", "bist", "du", "ein", "Neu\u00b7ling", ".", "Drum", "zeig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "PPER", "ART", "NN", "$.", "PAV", "VVFIN"], "meter": "+-+--+-+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "ihm das Einfache, das, von Geschlecht zu Geschlechtern gestaltet,", "tokens": ["ihm", "das", "Ein\u00b7fa\u00b7che", ",", "das", ",", "von", "Ge\u00b7schlecht", "zu", "Ge\u00b7schlech\u00b7tern", "ge\u00b7stal\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,", "PDS", "$,", "APPR", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "--+--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.5": {"text": "als ein Unsriges lebt, neben der Hand und im Blick.", "tokens": ["als", "ein", "Uns\u00b7ri\u00b7ges", "lebt", ",", "ne\u00b7ben", "der", "Hand", "und", "im", "Blick", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "KON", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Sag ihm die Dinge. Er wird staunender stehn; wie du standest", "tokens": ["Sag", "ihm", "die", "Din\u00b7ge", ".", "Er", "wird", "stau\u00b7nen\u00b7der", "stehn", ";", "wie", "du", "stan\u00b7dest"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "ART", "NN", "$.", "PPER", "VAFIN", "ADJD", "VVINF", "$.", "PWAV", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.7": {"text": "bei dem Seiler in Rom, oder beim T\u00f6pfer am Nil.", "tokens": ["bei", "dem", "Sei\u00b7ler", "in", "Rom", ",", "o\u00b7der", "beim", "T\u00f6p\u00b7fer", "am", "Nil", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NE", "$,", "KON", "APPRART", "NN", "APPRART", "NN", "$."], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.8": {"text": "Zeig ihm, wie gl\u00fccklich ein Ding sein kann, wie schuldlos und unser,", "tokens": ["Zeig", "ihm", ",", "wie", "gl\u00fcck\u00b7lich", "ein", "Ding", "sein", "kann", ",", "wie", "schuld\u00b7los", "und", "un\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "PWAV", "ADJD", "ART", "NN", "VAINF", "VMFIN", "$,", "PWAV", "ADJD", "KON", "PPOSAT", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "wie selbst das klagende Leid rein zur Gestalt sich entschlie\u00dft,", "tokens": ["wie", "selbst", "das", "kla\u00b7gen\u00b7de", "Leid", "rein", "zur", "Ge\u00b7stalt", "sich", "ent\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "ADJD", "APPRART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+--+---+--+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "dient als ein Ding, oder stirbt in ein Ding \u2013, und jenseits", "tokens": ["dient", "als", "ein", "Ding", ",", "o\u00b7der", "stirbt", "in", "ein", "Ding", "\u2013", ",", "und", "jen\u00b7seits"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "$,", "KON", "VVFIN", "APPR", "ART", "NN", "$(", "$,", "KON", "ADV"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.11": {"text": "selig der Geige entgeht. \u2013 Und diese, von Hingang", "tokens": ["se\u00b7lig", "der", "Gei\u00b7ge", "ent\u00b7geht", ".", "\u2013", "Und", "die\u00b7se", ",", "von", "Hin\u00b7gang"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$.", "$(", "KON", "PDS", "$,", "APPR", "NN"], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.12": {"text": "lebenden Dinge verstehn, da\u00df du sie r\u00fchmst; verg\u00e4nglich,", "tokens": ["le\u00b7ben\u00b7den", "Din\u00b7ge", "ver\u00b7stehn", ",", "da\u00df", "du", "sie", "r\u00fchmst", ";", "ver\u00b7g\u00e4ng\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$.", "ADJD", "$,"], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.13": {"text": "traun sie ein Rettendes uns, den Verg\u00e4nglichsten, zu.", "tokens": ["traun", "sie", "ein", "Ret\u00b7ten\u00b7des", "uns", ",", "den", "Ver\u00b7g\u00e4ng\u00b7lichs\u00b7ten", ",", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PPER", "$,", "ART", "NN", "$,", "PTKVZ", "$."], "meter": "+--+--+--+--+", "measure": "dactylic.penta"}, "line.14": {"text": "Wollen, wir sollen sie ganz im unsichtbarn Herzen verwandeln", "tokens": ["Wol\u00b7len", ",", "wir", "sol\u00b7len", "sie", "ganz", "im", "un\u00b7sicht\u00b7barn", "Her\u00b7zen", "ver\u00b7wan\u00b7deln"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VMFIN", "PPER", "ADV", "APPRART", "PPOSAT", "NN", "VVINF"], "meter": "+--+--+-+--+--+-", "measure": "hexameter"}, "line.15": {"text": "in \u2013 o unendlich \u2013 in uns! Wer wir am Ende auch seien.", "tokens": ["in", "\u2013", "o", "un\u00b7end\u00b7lich", "\u2013", "in", "uns", "!", "Wer", "wir", "am", "En\u00b7de", "auch", "sei\u00b7en", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$(", "FM", "ADJD", "$(", "APPR", "PPER", "$.", "PWS", "PPER", "APPRART", "NN", "ADV", "VAFIN", "$."], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}}, "stanza.15": {"line.1": {"text": "Erde, ist es nicht dies, was du willst: ", "tokens": ["Er\u00b7de", ",", "ist", "es", "nicht", "dies", ",", "was", "du", "willst", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "PPER", "PTKNEG", "PDS", "$,", "PWS", "PPER", "VMFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "in uns erstehn? \u2013 Ist es dein Traum nicht,", "tokens": ["in", "uns", "er\u00b7stehn", "?", "\u2013", "Ist", "es", "dein", "Traum", "nicht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$.", "$(", "VAFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "+-+-+-+++", "measure": "unknown.measure.hexa"}, "line.3": {"text": "einmal unsichtbar zu sein? \u2013 Erde! unsichtbar!", "tokens": ["ein\u00b7mal", "un\u00b7sicht\u00b7bar", "zu", "sein", "?", "\u2013", "Er\u00b7de", "!", "un\u00b7sicht\u00b7bar", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VAINF", "$.", "$(", "NN", "$.", "ADJD", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Was, wenn Verwandlung nicht, ist dein dr\u00e4ngender Auftrag?", "tokens": ["Was", ",", "wenn", "Ver\u00b7wand\u00b7lung", "nicht", ",", "ist", "dein", "dr\u00e4n\u00b7gen\u00b7der", "Auf\u00b7trag", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "$,", "KOUS", "NN", "PTKNEG", "$,", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Erde, du liebe, ich will. Oh glaub, es bed\u00fcrfte", "tokens": ["Er\u00b7de", ",", "du", "lie\u00b7be", ",", "ich", "will", ".", "Oh", "glaub", ",", "es", "be\u00b7d\u00fcrf\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PPER", "VVFIN", "$,", "PPER", "VMFIN", "$.", "ITJ", "VVFIN", "$,", "PPER", "VVFIN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.6": {"text": "nicht deiner Fr\u00fchlinge mehr, mich dir zu gewinnen \u2013,", "tokens": ["nicht", "dei\u00b7ner", "Fr\u00fch\u00b7lin\u00b7ge", "mehr", ",", "mich", "dir", "zu", "ge\u00b7win\u00b7nen", "\u2013", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "ADV", "$,", "PPER", "PPER", "PTKZU", "VVINF", "$(", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "ach, ein einziger ist schon dem Blute zu viel.", "tokens": ["ach", ",", "ein", "ein\u00b7zi\u00b7ger", "ist", "schon", "dem", "Blu\u00b7te", "zu", "viel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "$,", "ART", "ADJA", "VAFIN", "ADV", "ART", "NN", "APPR", "PIS", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.8": {"text": "Namenlos bin ich zu dir entschlossen, von weit her.", "tokens": ["Na\u00b7men\u00b7los", "bin", "ich", "zu", "dir", "ent\u00b7schlos\u00b7sen", ",", "von", "weit", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$,", "APPR", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.9": {"text": "Immer warst du im Recht, und dein heiliger Einfall", "tokens": ["Im\u00b7mer", "warst", "du", "im", "Recht", ",", "und", "dein", "hei\u00b7li\u00b7ger", "Ein\u00b7fall"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPRART", "NN", "$,", "KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+--+--+--+-", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "ist der vertrauliche Tod.", "tokens": ["ist", "der", "ver\u00b7trau\u00b7li\u00b7che", "Tod", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.16": {"line.1": {"text": "Siehe, ich lebe. Woraus? Weder Kindheit noch Zukunft", "tokens": ["Sie\u00b7he", ",", "ich", "le\u00b7be", ".", "Wo\u00b7raus", "?", "We\u00b7der", "Kind\u00b7heit", "noch", "Zu\u00b7kunft"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["VVIMP", "$,", "PPER", "VVFIN", "$.", "PWAV", "$.", "KON", "NN", "ADV", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "werden weniger ....... \u00dcberz\u00e4hliges Dasein", "tokens": ["wer\u00b7den", "we\u00b7ni\u00b7ger", ".......", "\u00dc\u00b7berz\u00b7\u00e4h\u00b7li\u00b7ges", "Da\u00b7sein"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ADV", "$(", "ADJA", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "entspringt mir im Herzen.", "tokens": ["ent\u00b7springt", "mir", "im", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}}}}