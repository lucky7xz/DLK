{"textgrid.poem.40010": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als ich, im Garten, j\u00fcngst durch dicke Erlen gieng,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als ich, im Garten, j\u00fcngst durch dicke Erlen gieng,", "tokens": ["Als", "ich", ",", "im", "Gar\u00b7ten", ",", "j\u00fcngst", "durch", "di\u00b7cke", "Er\u00b7len", "gieng", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPRART", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit ge\u00f6ffneter, drauf schnell geschloss'ner Hand,", "tokens": ["Und", "mit", "ge\u00b7\u00f6ff\u00b7ne\u00b7ter", ",", "drauf", "schnell", "ge\u00b7schloss'\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "$,", "PAV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Sommer-V\u00f6gelchen, das flatternd floge, fieng;", "tokens": ["Ein", "Som\u00b7mer\u00b7V\u00f6\u00b7gel\u00b7chen", ",", "das", "flat\u00b7ternd", "flo\u00b7ge", ",", "fi\u00b7eng", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Erstarrete mein Aug', es stutzte der Verstand,", "tokens": ["Er\u00b7star\u00b7re\u00b7te", "mein", "Aug'", ",", "es", "stutz\u00b7te", "der", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da ich dasselbige so sch\u00f6n, so Wunder-sch\u00f6n,", "tokens": ["Da", "ich", "das\u00b7sel\u00b7bi\u00b7ge", "so", "sch\u00f6n", ",", "so", "Wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So herrlich ausgeziert, so reich an Farben, fand.", "tokens": ["So", "herr\u00b7lich", "aus\u00b7ge\u00b7ziert", ",", "so", "reich", "an", "Far\u00b7ben", ",", "fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "ADV", "ADJD", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Gewi\u00df man kann nichts sch\u00f6ners sehn:", "tokens": ["Ge\u00b7wi\u00df", "man", "kann", "nichts", "sch\u00f6\u00b7ners", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Roth besch\u00e4mt den funckelnden Carmin,", "tokens": ["Sein", "Roth", "be\u00b7sch\u00e4mt", "den", "fun\u00b7ckeln\u00b7den", "Car\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es sticht sein Blau Sapphir und Lasul aus,", "tokens": ["Es", "sticht", "sein", "Blau", "Sap\u00b7phir", "und", "La\u00b7sul", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NE", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es reichet an sein Gr\u00fcn kein Gr\u00fcn,", "tokens": ["Es", "rei\u00b7chet", "an", "sein", "Gr\u00fcn", "kein", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn's gleich auf Silber liegt; und kurtz: kein Bluhmen-Straus,", "tokens": ["Wenn's", "gleich", "auf", "Sil\u00b7ber", "liegt", ";", "und", "kurtz", ":", "kein", "Bluh\u00b7men\u00b7Straus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "VVFIN", "$.", "KON", "ADJD", "$.", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein wiederscheinender beaugter Pfauen-Schwantz", "tokens": ["Kein", "wie\u00b7der\u00b7schei\u00b7nen\u00b7der", "be\u00b7aug\u00b7ter", "Pfau\u00b7en\u00b7Schwantz"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hat solchen holden Schmuck, hat so viel Glantz.", "tokens": ["Hat", "sol\u00b7chen", "hol\u00b7den", "Schmuck", ",", "hat", "so", "viel", "Glantz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$,", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ja, was mich vor Vergn\u00fcgen fast erschreckte,", "tokens": ["Ja", ",", "was", "mich", "vor", "Ver\u00b7gn\u00fc\u00b7gen", "fast", "er\u00b7schreck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "PRF", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "War, als ich deutlich, hell und rein", "tokens": ["War", ",", "als", "ich", "deut\u00b7lich", ",", "hell", "und", "rein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fcnf, acht und neun,", "tokens": ["F\u00fcnf", ",", "acht", "und", "neun", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "$,", "CARD", "KON", "CARD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "In netten Ziefern, drauf entdeckte.", "tokens": ["In", "net\u00b7ten", "Zie\u00b7fern", ",", "drauf", "ent\u00b7deck\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ich dachte, was in dieser Zahl", "tokens": ["Ich", "dach\u00b7te", ",", "was", "in", "die\u00b7ser", "Zahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Doch wohl f\u00fcr ein Geheimni\u00df steckte;", "tokens": ["Doch", "wohl", "f\u00fcr", "ein", "Ge\u00b7heim\u00b7ni\u00df", "steck\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Schlo\u00df aber, wie schon oftermahl:", "tokens": ["Schlo\u00df", "a\u00b7ber", ",", "wie", "schon", "of\u00b7ter\u00b7mahl", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PWAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Drauf schenckt' ich ihm die Freyheit wieder,", "tokens": ["Drauf", "schen\u00b7ckt'", "ich", "ihm", "die", "Frey\u00b7heit", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und sprach, mit Andachts-vollem Sinn:", "tokens": ["Und", "sprach", ",", "mit", "An\u00b7dachts\u00b7vol\u00b7lem", "Sinn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Flieg, liebstes V\u00f6gelchen, flieg, sch\u00f6nstes Thierchen, hin!", "tokens": ["Flieg", ",", "liebs\u00b7tes", "V\u00f6\u00b7gel\u00b7chen", ",", "flieg", ",", "sch\u00f6ns\u00b7tes", "Thier\u00b7chen", ",", "hin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Breit aus dein lehrendes Gefieder,", "tokens": ["Breit", "aus", "dein", "leh\u00b7ren\u00b7des", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und la\u00df der gantz verblendten Welt,", "tokens": ["Und", "la\u00df", "der", "gantz", "ver\u00b7blend\u00b7ten", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Leidenschaften blo\u00df f\u00fcr ihre G\u00f6tzen h\u00e4lt,", "tokens": ["Die", "Lei\u00b7den\u00b7schaf\u00b7ten", "blo\u00df", "f\u00fcr", "ih\u00b7re", "G\u00f6t\u00b7zen", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die zwar verborgene, doch unleugbare Spur", "tokens": ["Die", "zwar", "ver\u00b7bor\u00b7ge\u00b7ne", ",", "doch", "un\u00b7leug\u00b7ba\u00b7re", "Spur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+---+---+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Vom all-erf\u00fcllenden, allm\u00e4cht'gen Wunder-Wesen,", "tokens": ["Vom", "all\u00b7er\u00b7f\u00fcl\u00b7len\u00b7den", ",", "all\u00b7m\u00e4cht'\u00b7gen", "Wun\u00b7der\u00b7We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als auf zwey Bl\u00e4tterchen des Buchs der Creatur,", "tokens": ["Als", "auf", "zwey", "Bl\u00e4t\u00b7ter\u00b7chen", "des", "Buchs", "der", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "CARD", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "In bunter Schrift, auf deinen Fl\u00fcgeln, lesen.", "tokens": ["In", "bun\u00b7ter", "Schrift", ",", "auf", "dei\u00b7nen", "Fl\u00fc\u00b7geln", ",", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Als ich, im Garten, j\u00fcngst durch dicke Erlen gieng,", "tokens": ["Als", "ich", ",", "im", "Gar\u00b7ten", ",", "j\u00fcngst", "durch", "di\u00b7cke", "Er\u00b7len", "gieng", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPRART", "NN", "$,", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und mit ge\u00f6ffneter, drauf schnell geschloss'ner Hand,", "tokens": ["Und", "mit", "ge\u00b7\u00f6ff\u00b7ne\u00b7ter", ",", "drauf", "schnell", "ge\u00b7schloss'\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "$,", "PAV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Sommer-V\u00f6gelchen, das flatternd floge, fieng;", "tokens": ["Ein", "Som\u00b7mer\u00b7V\u00f6\u00b7gel\u00b7chen", ",", "das", "flat\u00b7ternd", "flo\u00b7ge", ",", "fi\u00b7eng", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+---+-+-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Erstarrete mein Aug', es stutzte der Verstand,", "tokens": ["Er\u00b7star\u00b7re\u00b7te", "mein", "Aug'", ",", "es", "stutz\u00b7te", "der", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da ich dasselbige so sch\u00f6n, so Wunder-sch\u00f6n,", "tokens": ["Da", "ich", "das\u00b7sel\u00b7bi\u00b7ge", "so", "sch\u00f6n", ",", "so", "Wun\u00b7der\u00b7sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So herrlich ausgeziert, so reich an Farben, fand.", "tokens": ["So", "herr\u00b7lich", "aus\u00b7ge\u00b7ziert", ",", "so", "reich", "an", "Far\u00b7ben", ",", "fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "ADV", "ADJD", "APPR", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Gewi\u00df man kann nichts sch\u00f6ners sehn:", "tokens": ["Ge\u00b7wi\u00df", "man", "kann", "nichts", "sch\u00f6\u00b7ners", "sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sein Roth besch\u00e4mt den funckelnden Carmin,", "tokens": ["Sein", "Roth", "be\u00b7sch\u00e4mt", "den", "fun\u00b7ckeln\u00b7den", "Car\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Es sticht sein Blau Sapphir und Lasul aus,", "tokens": ["Es", "sticht", "sein", "Blau", "Sap\u00b7phir", "und", "La\u00b7sul", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "NE", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Es reichet an sein Gr\u00fcn kein Gr\u00fcn,", "tokens": ["Es", "rei\u00b7chet", "an", "sein", "Gr\u00fcn", "kein", "Gr\u00fcn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn's gleich auf Silber liegt; und kurtz: kein Bluhmen-Straus,", "tokens": ["Wenn's", "gleich", "auf", "Sil\u00b7ber", "liegt", ";", "und", "kurtz", ":", "kein", "Bluh\u00b7men\u00b7Straus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "NN", "VVFIN", "$.", "KON", "ADJD", "$.", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Kein wiederscheinender beaugter Pfauen-Schwantz", "tokens": ["Kein", "wie\u00b7der\u00b7schei\u00b7nen\u00b7der", "be\u00b7aug\u00b7ter", "Pfau\u00b7en\u00b7Schwantz"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hat solchen holden Schmuck, hat so viel Glantz.", "tokens": ["Hat", "sol\u00b7chen", "hol\u00b7den", "Schmuck", ",", "hat", "so", "viel", "Glantz", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "ADJA", "NN", "$,", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ja, was mich vor Vergn\u00fcgen fast erschreckte,", "tokens": ["Ja", ",", "was", "mich", "vor", "Ver\u00b7gn\u00fc\u00b7gen", "fast", "er\u00b7schreck\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "PRF", "APPR", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "War, als ich deutlich, hell und rein", "tokens": ["War", ",", "als", "ich", "deut\u00b7lich", ",", "hell", "und", "rein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "KOUS", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fcnf, acht und neun,", "tokens": ["F\u00fcnf", ",", "acht", "und", "neun", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "$,", "CARD", "KON", "CARD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.11": {"text": "In netten Ziefern, drauf entdeckte.", "tokens": ["In", "net\u00b7ten", "Zie\u00b7fern", ",", "drauf", "ent\u00b7deck\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Ich dachte, was in dieser Zahl", "tokens": ["Ich", "dach\u00b7te", ",", "was", "in", "die\u00b7ser", "Zahl"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Doch wohl f\u00fcr ein Geheimni\u00df steckte;", "tokens": ["Doch", "wohl", "f\u00fcr", "ein", "Ge\u00b7heim\u00b7ni\u00df", "steck\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Schlo\u00df aber, wie schon oftermahl:", "tokens": ["Schlo\u00df", "a\u00b7ber", ",", "wie", "schon", "of\u00b7ter\u00b7mahl", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PWAV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Drauf schenckt' ich ihm die Freyheit wieder,", "tokens": ["Drauf", "schen\u00b7ckt'", "ich", "ihm", "die", "Frey\u00b7heit", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Und sprach, mit Andachts-vollem Sinn:", "tokens": ["Und", "sprach", ",", "mit", "An\u00b7dachts\u00b7vol\u00b7lem", "Sinn", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Flieg, liebstes V\u00f6gelchen, flieg, sch\u00f6nstes Thierchen, hin!", "tokens": ["Flieg", ",", "liebs\u00b7tes", "V\u00f6\u00b7gel\u00b7chen", ",", "flieg", ",", "sch\u00f6ns\u00b7tes", "Thier\u00b7chen", ",", "hin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "VVFIN", "$,", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Breit aus dein lehrendes Gefieder,", "tokens": ["Breit", "aus", "dein", "leh\u00b7ren\u00b7des", "Ge\u00b7fie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und la\u00df der gantz verblendten Welt,", "tokens": ["Und", "la\u00df", "der", "gantz", "ver\u00b7blend\u00b7ten", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Leidenschaften blo\u00df f\u00fcr ihre G\u00f6tzen h\u00e4lt,", "tokens": ["Die", "Lei\u00b7den\u00b7schaf\u00b7ten", "blo\u00df", "f\u00fcr", "ih\u00b7re", "G\u00f6t\u00b7zen", "h\u00e4lt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die zwar verborgene, doch unleugbare Spur", "tokens": ["Die", "zwar", "ver\u00b7bor\u00b7ge\u00b7ne", ",", "doch", "un\u00b7leug\u00b7ba\u00b7re", "Spur"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "ADJA", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+---+---+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Vom all-erf\u00fcllenden, allm\u00e4cht'gen Wunder-Wesen,", "tokens": ["Vom", "all\u00b7er\u00b7f\u00fcl\u00b7len\u00b7den", ",", "all\u00b7m\u00e4cht'\u00b7gen", "Wun\u00b7der\u00b7We\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Als auf zwey Bl\u00e4tterchen des Buchs der Creatur,", "tokens": ["Als", "auf", "zwey", "Bl\u00e4t\u00b7ter\u00b7chen", "des", "Buchs", "der", "Crea\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "CARD", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "In bunter Schrift, auf deinen Fl\u00fcgeln, lesen.", "tokens": ["In", "bun\u00b7ter", "Schrift", ",", "auf", "dei\u00b7nen", "Fl\u00fc\u00b7geln", ",", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}