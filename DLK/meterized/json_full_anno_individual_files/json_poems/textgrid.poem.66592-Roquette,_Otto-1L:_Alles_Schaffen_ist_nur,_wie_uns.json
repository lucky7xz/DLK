{"textgrid.poem.66592": {"metadata": {"author": {"name": "Roquette, Otto", "birth": "N.A.", "death": "N.A."}, "title": "1L: Alles Schaffen ist nur, wie uns", "genre": "verse", "period": "N.A.", "pub_year": 1860, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Alles Schaffen ist nur, wie uns", "tokens": ["Al\u00b7les", "Schaf\u00b7fen", "ist", "nur", ",", "wie", "uns"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$,", "PWAV", "PPER"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die Kritik bewiesen, R\u00fcckschritt;", "tokens": ["Die", "Kri\u00b7tik", "be\u00b7wie\u00b7sen", ",", "R\u00fcck\u00b7schritt", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Somit, Freund, gedruckt, gebunden,", "tokens": ["So\u00b7mit", ",", "Freund", ",", "ge\u00b7druckt", ",", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Send' ich dir auch diesen R\u00fcckschritt!", "tokens": ["Send'", "ich", "dir", "auch", "die\u00b7sen", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Schilt man Adams ersten Schritt aus", "tokens": ["Schilt", "man", "A\u00b7dams", "ers\u00b7ten", "Schritt", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "NE", "ADJA", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmelsparadiesen: R\u00fcckschritt,", "tokens": ["Him\u00b7mel\u00b7spa\u00b7ra\u00b7die\u00b7sen", ":", "R\u00fcck\u00b7schritt", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War auch der einst schnupfenlosen", "tokens": ["War", "auch", "der", "einst", "schnup\u00b7fen\u00b7lo\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eva erstes Niesen R\u00fcckschritt.", "tokens": ["E\u00b7va", "ers\u00b7tes", "Nie\u00b7sen", "R\u00fcck\u00b7schritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ja die Menschheit ging im Krebsgang,", "tokens": ["Ja", "die", "Menschheit", "ging", "im", "Krebs\u00b7gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Seit zuerst sie bliesen: R\u00fcckschritt!", "tokens": ["Seit", "zu\u00b7erst", "sie", "blie\u00b7sen", ":", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "VVFIN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was gethan ward und geschaffen,", "tokens": ["Was", "ge\u00b7than", "ward", "und", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist geh\u00e4uft ein Riesenr\u00fcckschritt.", "tokens": ["Ist", "ge\u00b7h\u00e4uft", "ein", "Rie\u00b7sen\u00b7r\u00fcck\u00b7schritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Lautet somit barsch auch mir mein", "tokens": ["Lau\u00b7tet", "so\u00b7mit", "barsch", "auch", "mir", "mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ADV", "PPER", "PPOSAT"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Spr\u00fcchlein der Assisen: R\u00fcckschritt!", "tokens": ["Spr\u00fcch\u00b7lein", "der", "As\u00b7si\u00b7sen", ":", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "R\u00fcck' ich unber\u00fcckt vom Fleck doch,", "tokens": ["R\u00fcck", "ich", "un\u00b7be\u00b7r\u00fcckt", "vom", "Fleck", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und so sei gepriesen, R\u00fcckschritt!", "tokens": ["Und", "so", "sei", "ge\u00b7prie\u00b7sen", ",", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "VVPP", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Alles Schaffen ist nur, wie uns", "tokens": ["Al\u00b7les", "Schaf\u00b7fen", "ist", "nur", ",", "wie", "uns"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$,", "PWAV", "PPER"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Die Kritik bewiesen, R\u00fcckschritt;", "tokens": ["Die", "Kri\u00b7tik", "be\u00b7wie\u00b7sen", ",", "R\u00fcck\u00b7schritt", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Somit, Freund, gedruckt, gebunden,", "tokens": ["So\u00b7mit", ",", "Freund", ",", "ge\u00b7druckt", ",", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VVPP", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Send' ich dir auch diesen R\u00fcckschritt!", "tokens": ["Send'", "ich", "dir", "auch", "die\u00b7sen", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Schilt man Adams ersten Schritt aus", "tokens": ["Schilt", "man", "A\u00b7dams", "ers\u00b7ten", "Schritt", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "NE", "ADJA", "NN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Himmelsparadiesen: R\u00fcckschritt,", "tokens": ["Him\u00b7mel\u00b7spa\u00b7ra\u00b7die\u00b7sen", ":", "R\u00fcck\u00b7schritt", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$.", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "War auch der einst schnupfenlosen", "tokens": ["War", "auch", "der", "einst", "schnup\u00b7fen\u00b7lo\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eva erstes Niesen R\u00fcckschritt.", "tokens": ["E\u00b7va", "ers\u00b7tes", "Nie\u00b7sen", "R\u00fcck\u00b7schritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ja die Menschheit ging im Krebsgang,", "tokens": ["Ja", "die", "Menschheit", "ging", "im", "Krebs\u00b7gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Seit zuerst sie bliesen: R\u00fcckschritt!", "tokens": ["Seit", "zu\u00b7erst", "sie", "blie\u00b7sen", ":", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADV", "PPER", "VVFIN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was gethan ward und geschaffen,", "tokens": ["Was", "ge\u00b7than", "ward", "und", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVPP", "VAFIN", "KON", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist geh\u00e4uft ein Riesenr\u00fcckschritt.", "tokens": ["Ist", "ge\u00b7h\u00e4uft", "ein", "Rie\u00b7sen\u00b7r\u00fcck\u00b7schritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "ART", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.8": {"line.1": {"text": "Lautet somit barsch auch mir mein", "tokens": ["Lau\u00b7tet", "so\u00b7mit", "barsch", "auch", "mir", "mein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ADV", "PPER", "PPOSAT"], "meter": "+---+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Spr\u00fcchlein der Assisen: R\u00fcckschritt!", "tokens": ["Spr\u00fcch\u00b7lein", "der", "As\u00b7si\u00b7sen", ":", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "ART", "NN", "$.", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "R\u00fcck' ich unber\u00fcckt vom Fleck doch,", "tokens": ["R\u00fcck", "ich", "un\u00b7be\u00b7r\u00fcckt", "vom", "Fleck", "doch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "APPRART", "NN", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und so sei gepriesen, R\u00fcckschritt!", "tokens": ["Und", "so", "sei", "ge\u00b7prie\u00b7sen", ",", "R\u00fcck\u00b7schritt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "VVPP", "$,", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}