{"textgrid.poem.55600": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als noch, verkannt und sehr gering,", "genre": "verse", "period": "N.A.", "pub_year": 1797, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als noch, verkannt und sehr gering,", "tokens": ["Als", "noch", ",", "ver\u00b7kannt", "und", "sehr", "ge\u00b7ring", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "VVPP", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unser Herr auf der Erde ging", "tokens": ["Un\u00b7ser", "Herr", "auf", "der", "Er\u00b7de", "ging"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und viele J\u00fcnger sich zu ihm fanden,", "tokens": ["Und", "vie\u00b7le", "J\u00fcn\u00b7ger", "sich", "zu", "ihm", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die sehr selten sein Wort verstanden,", "tokens": ["Die", "sehr", "sel\u00b7ten", "sein", "Wort", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Liebt' er sich gar \u00fcber die Ma\u00dfen,", "tokens": ["Liebt'", "er", "sich", "gar", "\u00fc\u00b7ber", "die", "Ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Seinen Hof zu halten auf der Stra\u00dfen,", "tokens": ["Sei\u00b7nen", "Hof", "zu", "hal\u00b7ten", "auf", "der", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Weil unter des Himmels Angesicht", "tokens": ["Weil", "un\u00b7ter", "des", "Him\u00b7mels", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Man immer besser und freier spricht.", "tokens": ["Man", "im\u00b7mer", "bes\u00b7ser", "und", "frei\u00b7er", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Er lie\u00df sie da die h\u00f6chsten Lehren", "tokens": ["Er", "lie\u00df", "sie", "da", "die", "h\u00f6chs\u00b7ten", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Aus seinem heiligen Munde h\u00f6ren;", "tokens": ["Aus", "sei\u00b7nem", "hei\u00b7li\u00b7gen", "Mun\u00b7de", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Besonders durch Gleichnis und Exempel", "tokens": ["Be\u00b7son\u00b7ders", "durch", "Gleich\u00b7nis", "und", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Macht' er einen jeden Markt zum Tempel.", "tokens": ["Macht'", "er", "ei\u00b7nen", "je\u00b7den", "Markt", "zum", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "So schlendert' er in Geistes Ruh", "tokens": ["So", "schlen\u00b7dert'", "er", "in", "Geis\u00b7tes", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihnen einst einem St\u00e4dtchen zu,", "tokens": ["Mit", "ih\u00b7nen", "einst", "ei\u00b7nem", "St\u00e4dt\u00b7chen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sah etwas blinken auf der Stra\u00df,", "tokens": ["Sah", "et\u00b7was", "blin\u00b7ken", "auf", "der", "Stra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ein zerbrochen Hufeisen was.", "tokens": ["Das", "ein", "zer\u00b7bro\u00b7chen", "Huf\u00b7ei\u00b7sen", "was", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "PWS", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Er sagte zu Sankt Peter drauf:", "tokens": ["Er", "sag\u00b7te", "zu", "Sankt", "Pe\u00b7ter", "drauf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKZU", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbheb doch einmal das Eisen auf!\u00ab", "tokens": ["\u00bb", "heb", "doch", "ein\u00b7mal", "das", "Ei\u00b7sen", "auf", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sankt Peter war nicht aufger\u00e4umt,", "tokens": ["Sankt", "Pe\u00b7ter", "war", "nicht", "auf\u00b7ge\u00b7r\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er hatte soeben im Gehen getr\u00e4umt,", "tokens": ["Er", "hat\u00b7te", "soe\u00b7ben", "im", "Ge\u00b7hen", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "So was vom Regiment der Welt,", "tokens": ["So", "was", "vom", "Re\u00b7gi\u00b7ment", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Was einem jeden wohlgef\u00e4llt:", "tokens": ["Was", "ei\u00b7nem", "je\u00b7den", "wohl\u00b7ge\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "PIAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Denn im Kopf hat das keine Schranken;", "tokens": ["Denn", "im", "Kopf", "hat", "das", "kei\u00b7ne", "Schran\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "ART", "PIAT", "NN", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das waren so seine liebsten Gedanken.", "tokens": ["Das", "wa\u00b7ren", "so", "sei\u00b7ne", "liebs\u00b7ten", "Ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nun war der Fund ihm viel zu klein,", "tokens": ["Nun", "war", "der", "Fund", "ihm", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00e4tte m\u00fcssen Kron und Zepter sein;", "tokens": ["H\u00e4t\u00b7te", "m\u00fcs\u00b7sen", "Kron", "und", "Zep\u00b7ter", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "NE", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Aber wie sollt er seinen R\u00fccken", "tokens": ["A\u00b7ber", "wie", "sollt", "er", "sei\u00b7nen", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Nach einem halben Hufeisen b\u00fccken?", "tokens": ["Nach", "ei\u00b7nem", "hal\u00b7ben", "Huf\u00b7ei\u00b7sen", "b\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Er also sich zur Seite kehrt", "tokens": ["Er", "al\u00b7so", "sich", "zur", "Sei\u00b7te", "kehrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PRF", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und tut, als h\u00e4tt er's nicht geh\u00f6rt.", "tokens": ["Und", "tut", ",", "als", "h\u00e4tt", "er's", "nicht", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOKOM", "VAFIN", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Herr, nach seiner Langmut, drauf", "tokens": ["Der", "Herr", ",", "nach", "sei\u00b7ner", "Lang\u00b7mut", ",", "drauf"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hebt selber das Hufeisen auf", "tokens": ["Hebt", "sel\u00b7ber", "das", "Huf\u00b7ei\u00b7sen", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und tut auch weiter nicht dergleichen.", "tokens": ["Und", "tut", "auch", "wei\u00b7ter", "nicht", "derg\u00b7lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PTKNEG", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als sie nun bald die Stadt erreichen,", "tokens": ["Als", "sie", "nun", "bald", "die", "Stadt", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geht er vor eines Schmiedes T\u00fcr,", "tokens": ["Geht", "er", "vor", "ei\u00b7nes", "Schmie\u00b7des", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nimmt von dem Mann drei Pfennig daf\u00fcr.", "tokens": ["Nimmt", "von", "dem", "Mann", "drei", "Pfen\u00b7nig", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "CARD", "NN", "PAV", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und als sie \u00fcber den Markt nun gehen,", "tokens": ["Und", "als", "sie", "\u00fc\u00b7ber", "den", "Markt", "nun", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Sieht er daselbst sch\u00f6ne Kirschen stehen,", "tokens": ["Sieht", "er", "da\u00b7selbst", "sch\u00f6\u00b7ne", "Kir\u00b7schen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Kauft ihr' so wenig oder so viel,", "tokens": ["Kauft", "ih\u00b7r'", "so", "we\u00b7nig", "o\u00b7der", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "KON", "ADV", "ADV", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Als man f\u00fcr einen Dreier geben will,", "tokens": ["Als", "man", "f\u00fcr", "ei\u00b7nen", "Drei\u00b7er", "ge\u00b7ben", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die er sodann nach seiner Art", "tokens": ["Die", "er", "so\u00b7dann", "nach", "sei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ruhig im \u00c4rmel aufbewahrt.", "tokens": ["Ru\u00b7hig", "im", "\u00c4r\u00b7mel", "auf\u00b7be\u00b7wahrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Nun ging's zum andern Tor hinaus,", "tokens": ["Nun", "ging's", "zum", "an\u00b7dern", "Tor", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "APZR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Wies und Felder ohne Haus,", "tokens": ["Durch", "Wies", "und", "Fel\u00b7der", "oh\u00b7ne", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch war der Weg von B\u00e4umen blo\u00df;", "tokens": ["Auch", "war", "der", "Weg", "von", "B\u00e4u\u00b7men", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sonne schien, die Hitz war gro\u00df,", "tokens": ["Die", "Son\u00b7ne", "schien", ",", "die", "Hitz", "war", "gro\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So da\u00df man viel an solcher St\u00e4tt", "tokens": ["So", "da\u00df", "man", "viel", "an", "sol\u00b7cher", "St\u00e4tt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr einen Trunk Wasser gegeben h\u00e4tt.", "tokens": ["F\u00fcr", "ei\u00b7nen", "Trunk", "Was\u00b7ser", "ge\u00b7ge\u00b7ben", "h\u00e4tt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der Herr geht immer voraus vor allen,", "tokens": ["Der", "Herr", "geht", "im\u00b7mer", "vo\u00b7raus", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "L\u00e4\u00dft unversehens eine Kirsche fallen.", "tokens": ["L\u00e4\u00dft", "un\u00b7ver\u00b7se\u00b7hens", "ei\u00b7ne", "Kir\u00b7sche", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sankt Peter war gleich dahinter her,", "tokens": ["Sankt", "Pe\u00b7ter", "war", "gleich", "da\u00b7hin\u00b7ter", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "ADV", "PAV", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Als wenn es ein goldner Apfel w\u00e4r;", "tokens": ["Als", "wenn", "es", "ein", "gold\u00b7ner", "Ap\u00b7fel", "w\u00e4r", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Das Beerlein schmeckte seinem Gaum.", "tokens": ["Das", "Be\u00b7er\u00b7lein", "schmeck\u00b7te", "sei\u00b7nem", "Gaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Der Herr, nach einem kleinen Raum,", "tokens": ["Der", "Herr", ",", "nach", "ei\u00b7nem", "klei\u00b7nen", "Raum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein ander Kirschlein zur Erde schickt,", "tokens": ["Ein", "an\u00b7der", "Kir\u00b7schlein", "zur", "Er\u00b7de", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Wornach Sankt Peter schnell sich b\u00fcckt.", "tokens": ["Wor\u00b7nach", "Sankt", "Pe\u00b7ter", "schnell", "sich", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So l\u00e4\u00dft der Herr ihn seinen R\u00fccken", "tokens": ["So", "l\u00e4\u00dft", "der", "Herr", "ihn", "sei\u00b7nen", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Gar vielmal nach den Kirschen b\u00fccken.", "tokens": ["Gar", "viel\u00b7mal", "nach", "den", "Kir\u00b7schen", "b\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Das dauert eine ganze Zeit.", "tokens": ["Das", "dau\u00b7ert", "ei\u00b7ne", "gan\u00b7ze", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dann sprach der Herr mit Heiterkeit:", "tokens": ["Dann", "sprach", "der", "Herr", "mit", "Hei\u00b7ter\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbt\u00e4tst du zur rechten Zeit dich regen,", "tokens": ["\u00bb", "t\u00e4tst", "du", "zur", "rech\u00b7ten", "Zeit", "dich", "re\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "H\u00e4ttst du's bequemer haben m\u00f6gen.", "tokens": ["H\u00e4ttst", "du's", "be\u00b7que\u00b7mer", "ha\u00b7ben", "m\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "VAINF", "VMFIN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.21": {"text": "Wer geringe Ding wenig acht',", "tokens": ["Wer", "ge\u00b7rin\u00b7ge", "Ding", "we\u00b7nig", "acht'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Sich um geringere M\u00fche macht.\u00ab", "tokens": ["Sich", "um", "ge\u00b7rin\u00b7ge\u00b7re", "M\u00fc\u00b7he", "macht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Als noch, verkannt und sehr gering,", "tokens": ["Als", "noch", ",", "ver\u00b7kannt", "und", "sehr", "ge\u00b7ring", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "VVPP", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Unser Herr auf der Erde ging", "tokens": ["Un\u00b7ser", "Herr", "auf", "der", "Er\u00b7de", "ging"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und viele J\u00fcnger sich zu ihm fanden,", "tokens": ["Und", "vie\u00b7le", "J\u00fcn\u00b7ger", "sich", "zu", "ihm", "fan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die sehr selten sein Wort verstanden,", "tokens": ["Die", "sehr", "sel\u00b7ten", "sein", "Wort", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Liebt' er sich gar \u00fcber die Ma\u00dfen,", "tokens": ["Liebt'", "er", "sich", "gar", "\u00fc\u00b7ber", "die", "Ma\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Seinen Hof zu halten auf der Stra\u00dfen,", "tokens": ["Sei\u00b7nen", "Hof", "zu", "hal\u00b7ten", "auf", "der", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "Weil unter des Himmels Angesicht", "tokens": ["Weil", "un\u00b7ter", "des", "Him\u00b7mels", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Man immer besser und freier spricht.", "tokens": ["Man", "im\u00b7mer", "bes\u00b7ser", "und", "frei\u00b7er", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Er lie\u00df sie da die h\u00f6chsten Lehren", "tokens": ["Er", "lie\u00df", "sie", "da", "die", "h\u00f6chs\u00b7ten", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Aus seinem heiligen Munde h\u00f6ren;", "tokens": ["Aus", "sei\u00b7nem", "hei\u00b7li\u00b7gen", "Mun\u00b7de", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Besonders durch Gleichnis und Exempel", "tokens": ["Be\u00b7son\u00b7ders", "durch", "Gleich\u00b7nis", "und", "Ex\u00b7em\u00b7pel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Macht' er einen jeden Markt zum Tempel.", "tokens": ["Macht'", "er", "ei\u00b7nen", "je\u00b7den", "Markt", "zum", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "PIAT", "NN", "APPRART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "So schlendert' er in Geistes Ruh", "tokens": ["So", "schlen\u00b7dert'", "er", "in", "Geis\u00b7tes", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihnen einst einem St\u00e4dtchen zu,", "tokens": ["Mit", "ih\u00b7nen", "einst", "ei\u00b7nem", "St\u00e4dt\u00b7chen", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sah etwas blinken auf der Stra\u00df,", "tokens": ["Sah", "et\u00b7was", "blin\u00b7ken", "auf", "der", "Stra\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das ein zerbrochen Hufeisen was.", "tokens": ["Das", "ein", "zer\u00b7bro\u00b7chen", "Huf\u00b7ei\u00b7sen", "was", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "ADJA", "NN", "PWS", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Er sagte zu Sankt Peter drauf:", "tokens": ["Er", "sag\u00b7te", "zu", "Sankt", "Pe\u00b7ter", "drauf", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKZU", "VVFIN", "NE", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbheb doch einmal das Eisen auf!\u00ab", "tokens": ["\u00bb", "heb", "doch", "ein\u00b7mal", "das", "Ei\u00b7sen", "auf", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sankt Peter war nicht aufger\u00e4umt,", "tokens": ["Sankt", "Pe\u00b7ter", "war", "nicht", "auf\u00b7ge\u00b7r\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Er hatte soeben im Gehen getr\u00e4umt,", "tokens": ["Er", "hat\u00b7te", "soe\u00b7ben", "im", "Ge\u00b7hen", "ge\u00b7tr\u00e4umt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "So was vom Regiment der Welt,", "tokens": ["So", "was", "vom", "Re\u00b7gi\u00b7ment", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Was einem jeden wohlgef\u00e4llt:", "tokens": ["Was", "ei\u00b7nem", "je\u00b7den", "wohl\u00b7ge\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "PIAT", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Denn im Kopf hat das keine Schranken;", "tokens": ["Denn", "im", "Kopf", "hat", "das", "kei\u00b7ne", "Schran\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VAFIN", "ART", "PIAT", "NN", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Das waren so seine liebsten Gedanken.", "tokens": ["Das", "wa\u00b7ren", "so", "sei\u00b7ne", "liebs\u00b7ten", "Ge\u00b7dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Nun war der Fund ihm viel zu klein,", "tokens": ["Nun", "war", "der", "Fund", "ihm", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00e4tte m\u00fcssen Kron und Zepter sein;", "tokens": ["H\u00e4t\u00b7te", "m\u00fcs\u00b7sen", "Kron", "und", "Zep\u00b7ter", "sein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "NE", "KON", "NN", "VAINF", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Aber wie sollt er seinen R\u00fccken", "tokens": ["A\u00b7ber", "wie", "sollt", "er", "sei\u00b7nen", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "VMFIN", "PPER", "PPOSAT", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Nach einem halben Hufeisen b\u00fccken?", "tokens": ["Nach", "ei\u00b7nem", "hal\u00b7ben", "Huf\u00b7ei\u00b7sen", "b\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Er also sich zur Seite kehrt", "tokens": ["Er", "al\u00b7so", "sich", "zur", "Sei\u00b7te", "kehrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PRF", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und tut, als h\u00e4tt er's nicht geh\u00f6rt.", "tokens": ["Und", "tut", ",", "als", "h\u00e4tt", "er's", "nicht", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOKOM", "VAFIN", "PIS", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der Herr, nach seiner Langmut, drauf", "tokens": ["Der", "Herr", ",", "nach", "sei\u00b7ner", "Lang\u00b7mut", ",", "drauf"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hebt selber das Hufeisen auf", "tokens": ["Hebt", "sel\u00b7ber", "das", "Huf\u00b7ei\u00b7sen", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und tut auch weiter nicht dergleichen.", "tokens": ["Und", "tut", "auch", "wei\u00b7ter", "nicht", "derg\u00b7lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PTKNEG", "PIS", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Als sie nun bald die Stadt erreichen,", "tokens": ["Als", "sie", "nun", "bald", "die", "Stadt", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Geht er vor eines Schmiedes T\u00fcr,", "tokens": ["Geht", "er", "vor", "ei\u00b7nes", "Schmie\u00b7des", "T\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nimmt von dem Mann drei Pfennig daf\u00fcr.", "tokens": ["Nimmt", "von", "dem", "Mann", "drei", "Pfen\u00b7nig", "da\u00b7f\u00fcr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "CARD", "NN", "PAV", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Und als sie \u00fcber den Markt nun gehen,", "tokens": ["Und", "als", "sie", "\u00fc\u00b7ber", "den", "Markt", "nun", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Sieht er daselbst sch\u00f6ne Kirschen stehen,", "tokens": ["Sieht", "er", "da\u00b7selbst", "sch\u00f6\u00b7ne", "Kir\u00b7schen", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Kauft ihr' so wenig oder so viel,", "tokens": ["Kauft", "ih\u00b7r'", "so", "we\u00b7nig", "o\u00b7der", "so", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "KON", "ADV", "ADV", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.10": {"text": "Als man f\u00fcr einen Dreier geben will,", "tokens": ["Als", "man", "f\u00fcr", "ei\u00b7nen", "Drei\u00b7er", "ge\u00b7ben", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Die er sodann nach seiner Art", "tokens": ["Die", "er", "so\u00b7dann", "nach", "sei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Ruhig im \u00c4rmel aufbewahrt.", "tokens": ["Ru\u00b7hig", "im", "\u00c4r\u00b7mel", "auf\u00b7be\u00b7wahrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Nun ging's zum andern Tor hinaus,", "tokens": ["Nun", "ging's", "zum", "an\u00b7dern", "Tor", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN", "APZR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Wies und Felder ohne Haus,", "tokens": ["Durch", "Wies", "und", "Fel\u00b7der", "oh\u00b7ne", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auch war der Weg von B\u00e4umen blo\u00df;", "tokens": ["Auch", "war", "der", "Weg", "von", "B\u00e4u\u00b7men", "blo\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sonne schien, die Hitz war gro\u00df,", "tokens": ["Die", "Son\u00b7ne", "schien", ",", "die", "Hitz", "war", "gro\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So da\u00df man viel an solcher St\u00e4tt", "tokens": ["So", "da\u00df", "man", "viel", "an", "sol\u00b7cher", "St\u00e4tt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PIS", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr einen Trunk Wasser gegeben h\u00e4tt.", "tokens": ["F\u00fcr", "ei\u00b7nen", "Trunk", "Was\u00b7ser", "ge\u00b7ge\u00b7ben", "h\u00e4tt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Der Herr geht immer voraus vor allen,", "tokens": ["Der", "Herr", "geht", "im\u00b7mer", "vo\u00b7raus", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "L\u00e4\u00dft unversehens eine Kirsche fallen.", "tokens": ["L\u00e4\u00dft", "un\u00b7ver\u00b7se\u00b7hens", "ei\u00b7ne", "Kir\u00b7sche", "fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sankt Peter war gleich dahinter her,", "tokens": ["Sankt", "Pe\u00b7ter", "war", "gleich", "da\u00b7hin\u00b7ter", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "ADV", "PAV", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Als wenn es ein goldner Apfel w\u00e4r;", "tokens": ["Als", "wenn", "es", "ein", "gold\u00b7ner", "Ap\u00b7fel", "w\u00e4r", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Das Beerlein schmeckte seinem Gaum.", "tokens": ["Das", "Be\u00b7er\u00b7lein", "schmeck\u00b7te", "sei\u00b7nem", "Gaum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Der Herr, nach einem kleinen Raum,", "tokens": ["Der", "Herr", ",", "nach", "ei\u00b7nem", "klei\u00b7nen", "Raum", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Ein ander Kirschlein zur Erde schickt,", "tokens": ["Ein", "an\u00b7der", "Kir\u00b7schlein", "zur", "Er\u00b7de", "schickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Wornach Sankt Peter schnell sich b\u00fcckt.", "tokens": ["Wor\u00b7nach", "Sankt", "Pe\u00b7ter", "schnell", "sich", "b\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "ADJD", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So l\u00e4\u00dft der Herr ihn seinen R\u00fccken", "tokens": ["So", "l\u00e4\u00dft", "der", "Herr", "ihn", "sei\u00b7nen", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Gar vielmal nach den Kirschen b\u00fccken.", "tokens": ["Gar", "viel\u00b7mal", "nach", "den", "Kir\u00b7schen", "b\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Das dauert eine ganze Zeit.", "tokens": ["Das", "dau\u00b7ert", "ei\u00b7ne", "gan\u00b7ze", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Dann sprach der Herr mit Heiterkeit:", "tokens": ["Dann", "sprach", "der", "Herr", "mit", "Hei\u00b7ter\u00b7keit", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "\u00bbt\u00e4tst du zur rechten Zeit dich regen,", "tokens": ["\u00bb", "t\u00e4tst", "du", "zur", "rech\u00b7ten", "Zeit", "dich", "re\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "PPER", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "H\u00e4ttst du's bequemer haben m\u00f6gen.", "tokens": ["H\u00e4ttst", "du's", "be\u00b7que\u00b7mer", "ha\u00b7ben", "m\u00f6\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "VAINF", "VMFIN", "$."], "meter": "---+-+-+-", "measure": "unknown.measure.tri"}, "line.21": {"text": "Wer geringe Ding wenig acht',", "tokens": ["Wer", "ge\u00b7rin\u00b7ge", "Ding", "we\u00b7nig", "acht'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.22": {"text": "Sich um geringere M\u00fche macht.\u00ab", "tokens": ["Sich", "um", "ge\u00b7rin\u00b7ge\u00b7re", "M\u00fc\u00b7he", "macht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}