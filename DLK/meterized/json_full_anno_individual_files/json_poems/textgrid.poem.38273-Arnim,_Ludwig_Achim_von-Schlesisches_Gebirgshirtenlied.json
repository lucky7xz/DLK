{"textgrid.poem.38273": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Schlesisches Gebirgshirtenlied", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich ging ins V\u00e4ters G\u00e4rtela,", "tokens": ["Ich", "ging", "ins", "V\u00e4\u00b7ters", "G\u00e4r\u00b7te\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich l\u00e4ht mich nider, \u00e4 schlief;", "tokens": ["Ich", "l\u00e4ht", "mich", "ni\u00b7der", ",", "\u00e4", "schlief", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da tr\u00e4umte mir \u00e4 Tr\u00e4umela,", "tokens": ["Da", "tr\u00e4um\u00b7te", "mir", "\u00e4", "Tr\u00e4u\u00b7me\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "As schneit es \u00fcber mich.", "tokens": ["As", "schneit", "es", "\u00fc\u00b7ber", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Un do ich nu erwachte,", "tokens": ["Un", "do", "ich", "nu", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Do w\u00e4r es aber nich,", "tokens": ["Do", "w\u00e4r", "es", "a\u00b7ber", "nich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00e4rens rutha Rusel\u00e4,", "tokens": ["So", "w\u00e4\u00b7rens", "ru\u00b7tha", "Ru\u00b7se\u00b7l\u00e4", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die bl\u00fchta \u00fcber mich.", "tokens": ["Die", "bl\u00fch\u00b7ta", "\u00fc\u00b7ber", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ich br\u00e4hch mir anes \u00e4be,", "tokens": ["Ich", "br\u00e4hch", "mir", "a\u00b7nes", "\u00e4\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu anen Ehrenkranz;", "tokens": ["Zu", "a\u00b7nen", "Eh\u00b7ren\u00b7kranz", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich n\u00e4hms der Liebsta mitte,", "tokens": ["Ich", "n\u00e4hms", "der", "Liebs\u00b7ta", "mit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu anen Ehrentanz.", "tokens": ["Zu", "a\u00b7nen", "Eh\u00b7ren\u00b7tanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "An do der Tanz im Besta war,", "tokens": ["An", "do", "der", "Tanz", "im", "Be\u00b7sta", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Do war d\u00e4s Giga aus,", "tokens": ["Do", "war", "d\u00e4s", "Gi\u00b7ga", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Do soll ich m'r nu mein Schatz heimf\u00fchre,", "tokens": ["Do", "soll", "ich", "m'r", "nu", "mein", "Schatz", "heim\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "An h\u00e4hs kein ehga Haus.", "tokens": ["An", "h\u00e4hs", "kein", "eh\u00b7ga", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "A H\u00e4usla will ich mir baua,", "tokens": ["A", "H\u00e4us\u00b7la", "will", "ich", "mir", "bau\u00b7a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "PPER", "PPER", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von Ruhs an Rosmarin;", "tokens": ["Von", "Ruhs", "an", "Ros\u00b7ma\u00b7rin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An will mirs wohl bestecka,", "tokens": ["An", "will", "mirs", "wohl", "be\u00b7stec\u00b7ka", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VMFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit ruthan Ruislan schien.", "tokens": ["Mit", "rut\u00b7han", "Ruis\u00b7lan", "schien", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Un wenn ich's nu war fert'g han,", "tokens": ["Un", "wenn", "ich's", "nu", "war", "fert'g", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PIS", "ADV", "VAFIN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beschar mir Gott was 'nein,", "tokens": ["Be\u00b7schar", "mir", "Gott", "was", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PWS", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Das ich zu Jauhr k\u00e4nn spreche:", "tokens": ["Das", "ich", "zu", "Jauhr", "k\u00e4nn", "spre\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das H\u00e4usla das ist mein!", "tokens": ["Das", "H\u00e4us\u00b7la", "das", "ist", "mein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich ging ins V\u00e4ters G\u00e4rtela,", "tokens": ["Ich", "ging", "ins", "V\u00e4\u00b7ters", "G\u00e4r\u00b7te\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich l\u00e4ht mich nider, \u00e4 schlief;", "tokens": ["Ich", "l\u00e4ht", "mich", "ni\u00b7der", ",", "\u00e4", "schlief", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADJD", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Da tr\u00e4umte mir \u00e4 Tr\u00e4umela,", "tokens": ["Da", "tr\u00e4um\u00b7te", "mir", "\u00e4", "Tr\u00e4u\u00b7me\u00b7la", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "As schneit es \u00fcber mich.", "tokens": ["As", "schneit", "es", "\u00fc\u00b7ber", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Un do ich nu erwachte,", "tokens": ["Un", "do", "ich", "nu", "er\u00b7wach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Do w\u00e4r es aber nich,", "tokens": ["Do", "w\u00e4r", "es", "a\u00b7ber", "nich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00e4rens rutha Rusel\u00e4,", "tokens": ["So", "w\u00e4\u00b7rens", "ru\u00b7tha", "Ru\u00b7se\u00b7l\u00e4", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die bl\u00fchta \u00fcber mich.", "tokens": ["Die", "bl\u00fch\u00b7ta", "\u00fc\u00b7ber", "mich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ich br\u00e4hch mir anes \u00e4be,", "tokens": ["Ich", "br\u00e4hch", "mir", "a\u00b7nes", "\u00e4\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu anen Ehrenkranz;", "tokens": ["Zu", "a\u00b7nen", "Eh\u00b7ren\u00b7kranz", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich n\u00e4hms der Liebsta mitte,", "tokens": ["Ich", "n\u00e4hms", "der", "Liebs\u00b7ta", "mit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu anen Ehrentanz.", "tokens": ["Zu", "a\u00b7nen", "Eh\u00b7ren\u00b7tanz", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "An do der Tanz im Besta war,", "tokens": ["An", "do", "der", "Tanz", "im", "Be\u00b7sta", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ART", "NN", "APPRART", "NN", "VAFIN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Do war d\u00e4s Giga aus,", "tokens": ["Do", "war", "d\u00e4s", "Gi\u00b7ga", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Do soll ich m'r nu mein Schatz heimf\u00fchre,", "tokens": ["Do", "soll", "ich", "m'r", "nu", "mein", "Schatz", "heim\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "An h\u00e4hs kein ehga Haus.", "tokens": ["An", "h\u00e4hs", "kein", "eh\u00b7ga", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "A H\u00e4usla will ich mir baua,", "tokens": ["A", "H\u00e4us\u00b7la", "will", "ich", "mir", "bau\u00b7a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VMFIN", "PPER", "PPER", "NE", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Von Ruhs an Rosmarin;", "tokens": ["Von", "Ruhs", "an", "Ros\u00b7ma\u00b7rin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "An will mirs wohl bestecka,", "tokens": ["An", "will", "mirs", "wohl", "be\u00b7stec\u00b7ka", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VMFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit ruthan Ruislan schien.", "tokens": ["Mit", "rut\u00b7han", "Ruis\u00b7lan", "schien", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Un wenn ich's nu war fert'g han,", "tokens": ["Un", "wenn", "ich's", "nu", "war", "fert'g", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PIS", "ADV", "VAFIN", "ADJD", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Beschar mir Gott was 'nein,", "tokens": ["Be\u00b7schar", "mir", "Gott", "was", "'n\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "NN", "PWS", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Das ich zu Jauhr k\u00e4nn spreche:", "tokens": ["Das", "ich", "zu", "Jauhr", "k\u00e4nn", "spre\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das H\u00e4usla das ist mein!", "tokens": ["Das", "H\u00e4us\u00b7la", "das", "ist", "mein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PDS", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}