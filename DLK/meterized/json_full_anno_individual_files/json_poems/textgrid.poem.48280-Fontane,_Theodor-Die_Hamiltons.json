{"textgrid.poem.48280": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Die Hamiltons", "genre": "verse", "period": "N.A.", "pub_year": 1851, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lord William kam zu sterben,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "kam", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Lord William Hamilton;", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "Ha\u00b7mil\u00b7ton", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er spricht zu seinem Sohne:", "tokens": ["Er", "spricht", "zu", "sei\u00b7nem", "Soh\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbnun h\u00f6re mich an, Sir John!", "tokens": ["\u00bb", "nun", "h\u00f6\u00b7re", "mich", "an", ",", "Sir", "John", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich lasse dir Land und Leute,", "tokens": ["Ich", "las\u00b7se", "dir", "Land", "und", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Unsren Namen und unsren Ruhm,", "tokens": ["Un\u00b7sren", "Na\u00b7men", "und", "un\u00b7sren", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und ich lasse dir, mehr als alles,", "tokens": ["Und", "ich", "las\u00b7se", "dir", ",", "mehr", "als", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ADV", "KOUS", "PIS", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Dieser Locke Heiligtum.", "tokens": ["Die\u00b7ser", "Lo\u00b7cke", "Hei\u00b7lig\u00b7tum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich sah die Locke fallen,", "tokens": ["Ich", "sah", "die", "Lo\u00b7cke", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich h\u00f6rte der Schere Schnitt \u2013", "tokens": ["Ich", "h\u00f6r\u00b7te", "der", "Sche\u00b7re", "Schnitt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und als Maria gebetet,", "tokens": ["Und", "als", "Ma\u00b7ria", "ge\u00b7be\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da betete leis ich mit.", "tokens": ["Da", "be\u00b7te\u00b7te", "leis", "ich", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPER", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Da hab' ich still geschworen:", "tokens": ["Da", "hab'", "ich", "still", "ge\u00b7schwo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu tragen in Leid und Lust,", "tokens": ["Zu", "tra\u00b7gen", "in", "Leid", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu tragen in Jubel und Tr\u00e4nen", "tokens": ["Zu", "tra\u00b7gen", "in", "Ju\u00b7bel", "und", "Tr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Diese Locke auf der Brust.", "tokens": ["Die\u00b7se", "Lo\u00b7cke", "auf", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich hab' sie in Tr\u00e4nen getragen", "tokens": ["Ich", "hab'", "sie", "in", "Tr\u00e4\u00b7nen", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und lass' erst im Tode davon \u2013", "tokens": ["Und", "lass'", "erst", "im", "To\u00b7de", "da\u00b7von", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "PAV", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "F\u00fcr die Stuarts zu leben und sterben,", "tokens": ["F\u00fcr", "die", "Stu\u00b7arts", "zu", "le\u00b7ben", "und", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "KON", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Das schw\u00f6r' auch du, Sir John.\u00ab", "tokens": ["Das", "schw\u00f6r'", "auch", "du", ",", "Sir", "John", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "$,", "NN", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Lord William hat es gesprochen,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "hat", "es", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sir John hat's treu gemeint:", "tokens": ["Sir", "John", "hat's", "treu", "ge\u00b7meint", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erst barg er still die Locke,", "tokens": ["Erst", "barg", "er", "still", "die", "Lo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dann hat er still geweint.", "tokens": ["Dann", "hat", "er", "still", "ge\u00b7weint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Er trug sie zwanzig Jahre,", "tokens": ["Er", "trug", "sie", "zwan\u00b7zig", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und als sein St\u00fcndlein kam,", "tokens": ["Und", "als", "sein", "St\u00fcnd\u00b7lein", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er mit des Vaters Worten", "tokens": ["Er", "mit", "des", "Va\u00b7ters", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Locke vom Herzen nahm.", "tokens": ["Die", "Lo\u00b7cke", "vom", "Her\u00b7zen", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Er gab sie seinem Sohne,", "tokens": ["Er", "gab", "sie", "sei\u00b7nem", "Soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und der Sohn dem Enkel dann,", "tokens": ["Und", "der", "Sohn", "dem", "En\u00b7kel", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr Erbteil war die Treue", "tokens": ["Ihr", "Erb\u00b7teil", "war", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und der Locke Talisman.", "tokens": ["Und", "der", "Lo\u00b7cke", "Ta\u00b7lis\u00b7man", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.9": {"line.1": {"text": "Und als auf blinkendem Zelter", "tokens": ["Und", "als", "auf", "blin\u00b7ken\u00b7dem", "Zel\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "K\u00f6nig James gen London zog,", "tokens": ["K\u00f6\u00b7nig", "Ja\u00b7mes", "gen", "Lon\u00b7don", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "VVFIN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Und als auf schwarzem Schafotte", "tokens": ["Und", "als", "auf", "schwar\u00b7zem", "Scha\u00b7fot\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Karls Haupt vom Rumpfe flog,", "tokens": ["Karls", "Haupt", "vom", "Rump\u00b7fe", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und als an der Boyne wieder", "tokens": ["Und", "als", "an", "der", "Boy\u00b7ne", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbstuart\u00ab das Feldgeschrei, \u2013", "tokens": ["\u00bb", "stu\u00b7art", "\u00ab", "das", "Feld\u00b7ge\u00b7schrei", ",", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$(", "ART", "NN", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In Lust und Leid, die Locke", "tokens": ["In", "Lust", "und", "Leid", ",", "die", "Lo\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und die Hamiltons waren dabei.", "tokens": ["Und", "die", "Ha\u00b7mil\u00b7tons", "wa\u00b7ren", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "VAFIN", "PAV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.11": {"line.1": {"text": "Und waren dabei zuletzt auch,", "tokens": ["Und", "wa\u00b7ren", "da\u00b7bei", "zu\u00b7letzt", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als auf Cullodens Plan", "tokens": ["Als", "auf", "Cul\u00b7lo\u00b7dens", "Plan"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ihre Augen das Distelbanner", "tokens": ["Ih\u00b7re", "Au\u00b7gen", "das", "Dis\u00b7tel\u00b7ban\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Noch einmal flattern sahn.", "tokens": ["Noch", "ein\u00b7mal", "flat\u00b7tern", "sahn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "'s war wieder ein Lord William", "tokens": ["'s", "war", "wie\u00b7der", "ein", "Lord", "Wil\u00b7li\u00b7am"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und wieder ein Sir John,", "tokens": ["Und", "wie\u00b7der", "ein", "Sir", "John", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Alter und ein Junger,", "tokens": ["Ein", "Al\u00b7ter", "und", "ein", "Jun\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch jeder ein Hamilton.", "tokens": ["Doch", "je\u00b7der", "ein", "Ha\u00b7mil\u00b7ton", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NE", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Der Junge focht zu Fu\u00dfe,", "tokens": ["Der", "Jun\u00b7ge", "focht", "zu", "Fu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Alte focht zu Ro\u00df,", "tokens": ["Der", "Al\u00b7te", "focht", "zu", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis eine englische Kugel", "tokens": ["Bis", "ei\u00b7ne", "eng\u00b7li\u00b7sche", "Ku\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihn aus dem Sattel scho\u00df.", "tokens": ["Ihn", "aus", "dem", "Sat\u00b7tel", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Hin reicht' er seinem Sohne", "tokens": ["Hin", "reicht'", "er", "sei\u00b7nem", "Soh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Locke, rot von Blut,", "tokens": ["Die", "Lo\u00b7cke", ",", "rot", "von", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er hatte nicht Zeit zu sprechen,", "tokens": ["Er", "hat\u00b7te", "nicht", "Zeit", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er sprach nur: \u00bbWahre sie gut!\u00ab", "tokens": ["Er", "sprach", "nur", ":", "\u00bb", "Wah\u00b7re", "sie", "gut", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "$(", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.15": {"line.1": {"text": "Er wahrte sie gut, der Junge,", "tokens": ["Er", "wahr\u00b7te", "sie", "gut", ",", "der", "Jun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Manchen Mond und manches Jahr,", "tokens": ["Man\u00b7chen", "Mond", "und", "man\u00b7ches", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Junge ward ein Alter \u2013", "tokens": ["Der", "Jun\u00b7ge", "ward", "ein", "Al\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Herz blieb, wie es war.", "tokens": ["Das", "Herz", "blieb", ",", "wie", "es", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und als in letzten Tagen", "tokens": ["Und", "als", "in", "letz\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihm Kunde kam ins Haus:", "tokens": ["Ihm", "Kun\u00b7de", "kam", "ins", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbsie trugen im fernen S\u00fcden", "tokens": ["\u00bb", "sie", "tru\u00b7gen", "im", "fer\u00b7nen", "S\u00fc\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}, "stanza.17": {"line.1": {"text": "Da sprach er, als er sterbend", "tokens": ["Da", "sprach", "er", ",", "als", "er", "ster\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Seinem Sohne die Locke gab:", "tokens": ["Sei\u00b7nem", "Soh\u00b7ne", "die", "Lo\u00b7cke", "gab", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbdie Stuarts sind gestorben,", "tokens": ["\u00bb", "die", "Stu\u00b7arts", "sind", "ge\u00b7stor\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch die Treue kennt kein Grab.\u00ab", "tokens": ["Doch", "die", "Treu\u00b7e", "kennt", "kein", "Grab", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Und siehe, die Hamiltons wahren", "tokens": ["Und", "sie\u00b7he", ",", "die", "Ha\u00b7mil\u00b7tons", "wah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bis heut ihren alten Ruhm,", "tokens": ["Bis", "heut", "ih\u00b7ren", "al\u00b7ten", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch eines mehr als alles:", "tokens": ["Doch", "ei\u00b7nes", "mehr", "als", "al\u00b7les", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "KOKOM", "PIS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Locke Heiligtum.", "tokens": ["Der", "Lo\u00b7cke", "Hei\u00b7lig\u00b7tum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Lord William kam zu sterben,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "kam", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Lord William Hamilton;", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "Ha\u00b7mil\u00b7ton", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er spricht zu seinem Sohne:", "tokens": ["Er", "spricht", "zu", "sei\u00b7nem", "Soh\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbnun h\u00f6re mich an, Sir John!", "tokens": ["\u00bb", "nun", "h\u00f6\u00b7re", "mich", "an", ",", "Sir", "John", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "NN", "NE", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Ich lasse dir Land und Leute,", "tokens": ["Ich", "las\u00b7se", "dir", "Land", "und", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Unsren Namen und unsren Ruhm,", "tokens": ["Un\u00b7sren", "Na\u00b7men", "und", "un\u00b7sren", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Und ich lasse dir, mehr als alles,", "tokens": ["Und", "ich", "las\u00b7se", "dir", ",", "mehr", "als", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$,", "ADV", "KOUS", "PIS", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Dieser Locke Heiligtum.", "tokens": ["Die\u00b7ser", "Lo\u00b7cke", "Hei\u00b7lig\u00b7tum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Ich sah die Locke fallen,", "tokens": ["Ich", "sah", "die", "Lo\u00b7cke", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich h\u00f6rte der Schere Schnitt \u2013", "tokens": ["Ich", "h\u00f6r\u00b7te", "der", "Sche\u00b7re", "Schnitt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und als Maria gebetet,", "tokens": ["Und", "als", "Ma\u00b7ria", "ge\u00b7be\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da betete leis ich mit.", "tokens": ["Da", "be\u00b7te\u00b7te", "leis", "ich", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "PPER", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Da hab' ich still geschworen:", "tokens": ["Da", "hab'", "ich", "still", "ge\u00b7schwo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu tragen in Leid und Lust,", "tokens": ["Zu", "tra\u00b7gen", "in", "Leid", "und", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu tragen in Jubel und Tr\u00e4nen", "tokens": ["Zu", "tra\u00b7gen", "in", "Ju\u00b7bel", "und", "Tr\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "APPR", "NN", "KON", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Diese Locke auf der Brust.", "tokens": ["Die\u00b7se", "Lo\u00b7cke", "auf", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ich hab' sie in Tr\u00e4nen getragen", "tokens": ["Ich", "hab'", "sie", "in", "Tr\u00e4\u00b7nen", "ge\u00b7tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "NN", "VVPP"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Und lass' erst im Tode davon \u2013", "tokens": ["Und", "lass'", "erst", "im", "To\u00b7de", "da\u00b7von", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "PAV", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "F\u00fcr die Stuarts zu leben und sterben,", "tokens": ["F\u00fcr", "die", "Stu\u00b7arts", "zu", "le\u00b7ben", "und", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF", "KON", "VVINF", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.4": {"text": "Das schw\u00f6r' auch du, Sir John.\u00ab", "tokens": ["Das", "schw\u00f6r'", "auch", "du", ",", "Sir", "John", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "$,", "NN", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Lord William hat es gesprochen,", "tokens": ["Lord", "Wil\u00b7li\u00b7am", "hat", "es", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Sir John hat's treu gemeint:", "tokens": ["Sir", "John", "hat's", "treu", "ge\u00b7meint", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erst barg er still die Locke,", "tokens": ["Erst", "barg", "er", "still", "die", "Lo\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dann hat er still geweint.", "tokens": ["Dann", "hat", "er", "still", "ge\u00b7weint", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Er trug sie zwanzig Jahre,", "tokens": ["Er", "trug", "sie", "zwan\u00b7zig", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und als sein St\u00fcndlein kam,", "tokens": ["Und", "als", "sein", "St\u00fcnd\u00b7lein", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er mit des Vaters Worten", "tokens": ["Er", "mit", "des", "Va\u00b7ters", "Wor\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Locke vom Herzen nahm.", "tokens": ["Die", "Lo\u00b7cke", "vom", "Her\u00b7zen", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.26": {"line.1": {"text": "Er gab sie seinem Sohne,", "tokens": ["Er", "gab", "sie", "sei\u00b7nem", "Soh\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und der Sohn dem Enkel dann,", "tokens": ["Und", "der", "Sohn", "dem", "En\u00b7kel", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr Erbteil war die Treue", "tokens": ["Ihr", "Erb\u00b7teil", "war", "die", "Treu\u00b7e"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und der Locke Talisman.", "tokens": ["Und", "der", "Lo\u00b7cke", "Ta\u00b7lis\u00b7man", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NE", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.27": {"line.1": {"text": "Und als auf blinkendem Zelter", "tokens": ["Und", "als", "auf", "blin\u00b7ken\u00b7dem", "Zel\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "K\u00f6nig James gen London zog,", "tokens": ["K\u00f6\u00b7nig", "Ja\u00b7mes", "gen", "Lon\u00b7don", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "VVFIN", "$,"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.3": {"text": "Und als auf schwarzem Schafotte", "tokens": ["Und", "als", "auf", "schwar\u00b7zem", "Scha\u00b7fot\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Karls Haupt vom Rumpfe flog,", "tokens": ["Karls", "Haupt", "vom", "Rump\u00b7fe", "flog", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Und als an der Boyne wieder", "tokens": ["Und", "als", "an", "der", "Boy\u00b7ne", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbstuart\u00ab das Feldgeschrei, \u2013", "tokens": ["\u00bb", "stu\u00b7art", "\u00ab", "das", "Feld\u00b7ge\u00b7schrei", ",", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADJD", "$(", "ART", "NN", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "In Lust und Leid, die Locke", "tokens": ["In", "Lust", "und", "Leid", ",", "die", "Lo\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und die Hamiltons waren dabei.", "tokens": ["Und", "die", "Ha\u00b7mil\u00b7tons", "wa\u00b7ren", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "VAFIN", "PAV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.29": {"line.1": {"text": "Und waren dabei zuletzt auch,", "tokens": ["Und", "wa\u00b7ren", "da\u00b7bei", "zu\u00b7letzt", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADV", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als auf Cullodens Plan", "tokens": ["Als", "auf", "Cul\u00b7lo\u00b7dens", "Plan"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "NN"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ihre Augen das Distelbanner", "tokens": ["Ih\u00b7re", "Au\u00b7gen", "das", "Dis\u00b7tel\u00b7ban\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Noch einmal flattern sahn.", "tokens": ["Noch", "ein\u00b7mal", "flat\u00b7tern", "sahn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "'s war wieder ein Lord William", "tokens": ["'s", "war", "wie\u00b7der", "ein", "Lord", "Wil\u00b7li\u00b7am"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und wieder ein Sir John,", "tokens": ["Und", "wie\u00b7der", "ein", "Sir", "John", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Alter und ein Junger,", "tokens": ["Ein", "Al\u00b7ter", "und", "ein", "Jun\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch jeder ein Hamilton.", "tokens": ["Doch", "je\u00b7der", "ein", "Ha\u00b7mil\u00b7ton", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ART", "NE", "$."], "meter": "-+--++-", "measure": "iambic.tri.relaxed"}}, "stanza.31": {"line.1": {"text": "Der Junge focht zu Fu\u00dfe,", "tokens": ["Der", "Jun\u00b7ge", "focht", "zu", "Fu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Alte focht zu Ro\u00df,", "tokens": ["Der", "Al\u00b7te", "focht", "zu", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis eine englische Kugel", "tokens": ["Bis", "ei\u00b7ne", "eng\u00b7li\u00b7sche", "Ku\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihn aus dem Sattel scho\u00df.", "tokens": ["Ihn", "aus", "dem", "Sat\u00b7tel", "scho\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Hin reicht' er seinem Sohne", "tokens": ["Hin", "reicht'", "er", "sei\u00b7nem", "Soh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die Locke, rot von Blut,", "tokens": ["Die", "Lo\u00b7cke", ",", "rot", "von", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er hatte nicht Zeit zu sprechen,", "tokens": ["Er", "hat\u00b7te", "nicht", "Zeit", "zu", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er sprach nur: \u00bbWahre sie gut!\u00ab", "tokens": ["Er", "sprach", "nur", ":", "\u00bb", "Wah\u00b7re", "sie", "gut", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "$(", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.33": {"line.1": {"text": "Er wahrte sie gut, der Junge,", "tokens": ["Er", "wahr\u00b7te", "sie", "gut", ",", "der", "Jun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$,", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Manchen Mond und manches Jahr,", "tokens": ["Man\u00b7chen", "Mond", "und", "man\u00b7ches", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Junge ward ein Alter \u2013", "tokens": ["Der", "Jun\u00b7ge", "ward", "ein", "Al\u00b7ter", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das Herz blieb, wie es war.", "tokens": ["Das", "Herz", "blieb", ",", "wie", "es", "war", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PWAV", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Und als in letzten Tagen", "tokens": ["Und", "als", "in", "letz\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ihm Kunde kam ins Haus:", "tokens": ["Ihm", "Kun\u00b7de", "kam", "ins", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbsie trugen im fernen S\u00fcden", "tokens": ["\u00bb", "sie", "tru\u00b7gen", "im", "fer\u00b7nen", "S\u00fc\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}, "stanza.35": {"line.1": {"text": "Da sprach er, als er sterbend", "tokens": ["Da", "sprach", "er", ",", "als", "er", "ster\u00b7bend"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Seinem Sohne die Locke gab:", "tokens": ["Sei\u00b7nem", "Soh\u00b7ne", "die", "Lo\u00b7cke", "gab", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbdie Stuarts sind gestorben,", "tokens": ["\u00bb", "die", "Stu\u00b7arts", "sind", "ge\u00b7stor\u00b7ben", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch die Treue kennt kein Grab.\u00ab", "tokens": ["Doch", "die", "Treu\u00b7e", "kennt", "kein", "Grab", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIAT", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Und siehe, die Hamiltons wahren", "tokens": ["Und", "sie\u00b7he", ",", "die", "Ha\u00b7mil\u00b7tons", "wah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bis heut ihren alten Ruhm,", "tokens": ["Bis", "heut", "ih\u00b7ren", "al\u00b7ten", "Ruhm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch eines mehr als alles:", "tokens": ["Doch", "ei\u00b7nes", "mehr", "als", "al\u00b7les", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIAT", "KOKOM", "PIS", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Locke Heiligtum.", "tokens": ["Der", "Lo\u00b7cke", "Hei\u00b7lig\u00b7tum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}