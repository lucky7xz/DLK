{"textgrid.poem.54031": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Aus!", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Einmal m\u00fcssen zwei auseinandergehn;", "tokens": ["Ein\u00b7mal", "m\u00fcs\u00b7sen", "zwei", "aus\u00b7ein\u00b7an\u00b7der\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "CARD", "VVIZU", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "einmal will einer den andern nicht mehr verstehn \u2013 \u2013", "tokens": ["ein\u00b7mal", "will", "ei\u00b7ner", "den", "an\u00b7dern", "nicht", "mehr", "ver\u00b7stehn", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "ADJA", "PTKNEG", "ADV", "VVINF", "$(", "$("], "meter": "---+--+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "einmal gabelt sich jeder Weg \u2013 und jeder geht allein \u2013", "tokens": ["ein\u00b7mal", "ga\u00b7belt", "sich", "je\u00b7der", "Weg", "\u2013", "und", "je\u00b7der", "geht", "al\u00b7lein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIAT", "NN", "$(", "KON", "PIS", "VVFIN", "ADV", "$("], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "wer ist daran schuld?", "tokens": ["wer", "ist", "da\u00b7ran", "schuld", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PAV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Es gibt keine Schuld. Es gibt nur den Ablauf der Zeit.", "tokens": ["Es", "gibt", "kei\u00b7ne", "Schuld", ".", "Es", "gibt", "nur", "den", "Ab\u00b7lauf", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Solche Stra\u00dfen schneiden sich in der Unendlichkeit.", "tokens": ["Sol\u00b7che", "Stra\u00b7\u00dfen", "schnei\u00b7den", "sich", "in", "der", "Un\u00b7end\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Jedes tr\u00e4gt den andern mit sich herum \u2013", "tokens": ["Je\u00b7des", "tr\u00e4gt", "den", "an\u00b7dern", "mit", "sich", "he\u00b7rum", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "APPR", "PRF", "APZR", "$("], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "etwas bleibt immer zur\u00fcck.", "tokens": ["et\u00b7was", "bleibt", "im\u00b7mer", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.3": {"line.1": {"text": "Einmal hat es euch zusammengesp\u00fclt,", "tokens": ["Ein\u00b7mal", "hat", "es", "euch", "zu\u00b7sam\u00b7men\u00b7ge\u00b7sp\u00fclt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "ihr habt euch erhitzt, seid zusammengeschmolzen, und dann erk\u00fchlt \u2013", "tokens": ["ihr", "habt", "euch", "er\u00b7hitzt", ",", "seid", "zu\u00b7sam\u00b7men\u00b7ge\u00b7schmol\u00b7zen", ",", "und", "dann", "er\u00b7k\u00fchlt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "$,", "VAFIN", "VVINF", "$,", "KON", "ADV", "VVFIN", "$("], "meter": "-+--+--+--+--+-+", "measure": "amphibrach.penta.plus"}, "line.3": {"text": "Ihr wart euer Kind. Jede H\u00e4lfte sinkt nun herab \u2013:", "tokens": ["Ihr", "wart", "eu\u00b7er", "Kind", ".", "Je\u00b7de", "H\u00e4lf\u00b7te", "sinkt", "nun", "her\u00b7ab", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "PIAT", "NN", "VVFIN", "ADV", "ADV", "$(", "$."], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "ein neuer Mensch.", "tokens": ["ein", "neu\u00b7er", "Mensch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Jeder geht seinem kleinen Schicksal zu.", "tokens": ["Je\u00b7der", "geht", "sei\u00b7nem", "klei\u00b7nen", "Schick\u00b7sal", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Leben ist Wandlung. Jedes Ich sucht ein Du.", "tokens": ["Le\u00b7ben", "ist", "Wand\u00b7lung", ".", "Je\u00b7des", "Ich", "sucht", "ein", "Du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$.", "PIS", "PPER", "VVFIN", "ART", "PPER", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Jeder sucht seine Zukunft. Und geht nun mit stockendem Fu\u00df,", "tokens": ["Je\u00b7der", "sucht", "sei\u00b7ne", "Zu\u00b7kunft", ".", "Und", "geht", "nun", "mit", "sto\u00b7cken\u00b7dem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$.", "KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-++-+--+--+--+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "vorw\u00e4rtsgerissen vom Willen, ohne Erkl\u00e4rung und ohne Gru\u00df", "tokens": ["vor\u00b7w\u00e4rts\u00b7ge\u00b7ris\u00b7sen", "vom", "Wil\u00b7len", ",", "oh\u00b7ne", "Er\u00b7kl\u00e4\u00b7rung", "und", "oh\u00b7ne", "Gru\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "APPRART", "NN", "$,", "KOUI", "NN", "KON", "APPR", "NN"], "meter": "+--+--+-+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "in ein fernes Land.", "tokens": ["in", "ein", "fer\u00b7nes", "Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Einmal m\u00fcssen zwei auseinandergehn;", "tokens": ["Ein\u00b7mal", "m\u00fcs\u00b7sen", "zwei", "aus\u00b7ein\u00b7an\u00b7der\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "CARD", "VVIZU", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "einmal will einer den andern nicht mehr verstehn \u2013 \u2013", "tokens": ["ein\u00b7mal", "will", "ei\u00b7ner", "den", "an\u00b7dern", "nicht", "mehr", "ver\u00b7stehn", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ART", "ADJA", "PTKNEG", "ADV", "VVINF", "$(", "$("], "meter": "---+--+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "einmal gabelt sich jeder Weg \u2013 und jeder geht allein \u2013", "tokens": ["ein\u00b7mal", "ga\u00b7belt", "sich", "je\u00b7der", "Weg", "\u2013", "und", "je\u00b7der", "geht", "al\u00b7lein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PIAT", "NN", "$(", "KON", "PIS", "VVFIN", "ADV", "$("], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "wer ist daran schuld?", "tokens": ["wer", "ist", "da\u00b7ran", "schuld", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PAV", "ADJD", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Es gibt keine Schuld. Es gibt nur den Ablauf der Zeit.", "tokens": ["Es", "gibt", "kei\u00b7ne", "Schuld", ".", "Es", "gibt", "nur", "den", "Ab\u00b7lauf", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Solche Stra\u00dfen schneiden sich in der Unendlichkeit.", "tokens": ["Sol\u00b7che", "Stra\u00b7\u00dfen", "schnei\u00b7den", "sich", "in", "der", "Un\u00b7end\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Jedes tr\u00e4gt den andern mit sich herum \u2013", "tokens": ["Je\u00b7des", "tr\u00e4gt", "den", "an\u00b7dern", "mit", "sich", "he\u00b7rum", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "APPR", "PRF", "APZR", "$("], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "etwas bleibt immer zur\u00fcck.", "tokens": ["et\u00b7was", "bleibt", "im\u00b7mer", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Einmal hat es euch zusammengesp\u00fclt,", "tokens": ["Ein\u00b7mal", "hat", "es", "euch", "zu\u00b7sam\u00b7men\u00b7ge\u00b7sp\u00fclt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "ihr habt euch erhitzt, seid zusammengeschmolzen, und dann erk\u00fchlt \u2013", "tokens": ["ihr", "habt", "euch", "er\u00b7hitzt", ",", "seid", "zu\u00b7sam\u00b7men\u00b7ge\u00b7schmol\u00b7zen", ",", "und", "dann", "er\u00b7k\u00fchlt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVFIN", "$,", "VAFIN", "VVINF", "$,", "KON", "ADV", "VVFIN", "$("], "meter": "-+--+--+--+--+-+", "measure": "amphibrach.penta.plus"}, "line.3": {"text": "Ihr wart euer Kind. Jede H\u00e4lfte sinkt nun herab \u2013:", "tokens": ["Ihr", "wart", "eu\u00b7er", "Kind", ".", "Je\u00b7de", "H\u00e4lf\u00b7te", "sinkt", "nun", "her\u00b7ab", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$.", "PIAT", "NN", "VVFIN", "ADV", "ADV", "$(", "$."], "meter": "-+--+--+-+--+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "ein neuer Mensch.", "tokens": ["ein", "neu\u00b7er", "Mensch", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Jeder geht seinem kleinen Schicksal zu.", "tokens": ["Je\u00b7der", "geht", "sei\u00b7nem", "klei\u00b7nen", "Schick\u00b7sal", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Leben ist Wandlung. Jedes Ich sucht ein Du.", "tokens": ["Le\u00b7ben", "ist", "Wand\u00b7lung", ".", "Je\u00b7des", "Ich", "sucht", "ein", "Du", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$.", "PIS", "PPER", "VVFIN", "ART", "PPER", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Jeder sucht seine Zukunft. Und geht nun mit stockendem Fu\u00df,", "tokens": ["Je\u00b7der", "sucht", "sei\u00b7ne", "Zu\u00b7kunft", ".", "Und", "geht", "nun", "mit", "sto\u00b7cken\u00b7dem", "Fu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$.", "KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "+-++-+--+--+--+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "vorw\u00e4rtsgerissen vom Willen, ohne Erkl\u00e4rung und ohne Gru\u00df", "tokens": ["vor\u00b7w\u00e4rts\u00b7ge\u00b7ris\u00b7sen", "vom", "Wil\u00b7len", ",", "oh\u00b7ne", "Er\u00b7kl\u00e4\u00b7rung", "und", "oh\u00b7ne", "Gru\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVPP", "APPRART", "NN", "$,", "KOUI", "NN", "KON", "APPR", "NN"], "meter": "+--+--+-+--+--+-+", "measure": "dactylic.di.plus"}, "line.5": {"text": "in ein fernes Land.", "tokens": ["in", "ein", "fer\u00b7nes", "Land", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}