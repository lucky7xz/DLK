{"textgrid.poem.49610": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Der Tanz", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Tanzen gilt als ein Vergn\u00fcgen,", "tokens": ["Das", "Tan\u00b7zen", "gilt", "als", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bei dem sich zwei zusammenf\u00fcgen,", "tokens": ["Bei", "dem", "sich", "zwei", "zu\u00b7sam\u00b7men\u00b7f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und sich \u2013 statt gradeaus zu gehen \u2013", "tokens": ["Und", "sich", "\u2013", "statt", "gra\u00b7de\u00b7aus", "zu", "ge\u00b7hen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$(", "APPR", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach links und rechts im Kreise drehen.", "tokens": ["Nach", "links", "und", "rechts", "im", "Krei\u00b7se", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "KON", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wenn wir sein Wesen recht erkennen,", "tokens": ["Wenn", "wir", "sein", "We\u00b7sen", "recht", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird man das Tanzen Arbeit nennen,", "tokens": ["Wird", "man", "das", "Tan\u00b7zen", "Ar\u00b7beit", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man hat den triftigsten Beweis", "tokens": ["Man", "hat", "den", "trif\u00b7tigs\u00b7ten", "Be\u00b7weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "In dem dabei vergossnen Schwei\u00df.", "tokens": ["In", "dem", "da\u00b7bei", "ver\u00b7goss\u00b7nen", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PAV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Hier untersucht nun der Gelehrte:", "tokens": ["Hier", "un\u00b7ter\u00b7sucht", "nun", "der", "Ge\u00b7lehr\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zum ersten schafft sie keine Werte,", "tokens": ["Zum", "ers\u00b7ten", "schafft", "sie", "kei\u00b7ne", "Wer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zum zweiten aber hat davon", "tokens": ["Zum", "zwei\u00b7ten", "a\u00b7ber", "hat", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "ADV", "VAFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Arbeitnehmer keinen Lohn.", "tokens": ["Der", "Ar\u00b7beit\u00b7neh\u00b7mer", "kei\u00b7nen", "Lohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Er dreht von acht bis morgens f\u00fcnfe", "tokens": ["Er", "dreht", "von", "acht", "bis", "mor\u00b7gens", "f\u00fcn\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "CARD", "APPR", "ADV", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und immer gratis eine Nymphe.", "tokens": ["Und", "im\u00b7mer", "gra\u00b7tis", "ei\u00b7ne", "Nym\u00b7phe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "Dies bildet doch ein Unikum!", "tokens": ["Dies", "bil\u00b7det", "doch", "ein", "U\u00b7ni\u00b7kum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und deshalb frage ich: warum?", "tokens": ["Und", "des\u00b7halb", "fra\u00b7ge", "ich", ":", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Erfolgt es wirklich unentgeltlich?", "tokens": ["Er\u00b7folgt", "es", "wirk\u00b7lich", "un\u00b7ent\u00b7gelt\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geschieht es nicht doch vorbeh\u00e4ltlich?", "tokens": ["Ge\u00b7schieht", "es", "nicht", "doch", "vor\u00b7be\u00b7h\u00e4lt\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Entledigt man sich seines Speckes", "tokens": ["Ent\u00b7le\u00b7digt", "man", "sich", "sei\u00b7nes", "Spe\u00b7ckes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz ohne Hinblick eines Zweckes?", "tokens": ["Ganz", "oh\u00b7ne", "Hin\u00b7blick", "ei\u00b7nes", "Zwe\u00b7ckes", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Hier ist der Angelpunkt der Frage,", "tokens": ["Hier", "ist", "der", "An\u00b7gel\u00b7punkt", "der", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihre L\u00f6sung tritt zutage:", "tokens": ["Und", "ih\u00b7re", "L\u00f6\u00b7sung", "tritt", "zu\u00b7ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der T\u00e4nzer leistet nur so viel", "tokens": ["Der", "T\u00e4n\u00b7zer", "leis\u00b7tet", "nur", "so", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Hoffnung auf ein Nebenziel.", "tokens": ["In", "Hoff\u00b7nung", "auf", "ein", "Ne\u00b7ben\u00b7ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es kann sich jede Nymphe denken,", "tokens": ["Es", "kann", "sich", "je\u00b7de", "Nym\u00b7phe", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn M\u00e4nner sie im Kreise schwenken,", "tokens": ["Wenn", "M\u00e4n\u00b7ner", "sie", "im", "Krei\u00b7se", "schwen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So hofft er schlie\u00dflich, da\u00df vielleicht", "tokens": ["So", "hofft", "er", "schlie\u00df\u00b7lich", ",", "da\u00df", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er das Betreffende erreicht.", "tokens": ["Er", "das", "Be\u00b7tref\u00b7fen\u00b7de", "er\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Es gibt nat\u00fcrlich Unterschiede:", "tokens": ["Es", "gibt", "na\u00b7t\u00fcr\u00b7lich", "Un\u00b7ter\u00b7schie\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der eine sucht es bona fide,", "tokens": ["Der", "ei\u00b7ne", "sucht", "es", "bo\u00b7na", "fi\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der andre will als Schmetterling", "tokens": ["Der", "and\u00b7re", "will", "als", "Schmet\u00b7ter\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VMFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Blume ohne Ehering.", "tokens": ["Die", "Blu\u00b7me", "oh\u00b7ne", "E\u00b7he\u00b7ring", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Im B\u00fcrger- und Familienkr\u00e4nzchen", "tokens": ["Im", "B\u00fcr\u00b7ger", "und", "Fa\u00b7mi\u00b7li\u00b7en\u00b7kr\u00e4nz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "TRUNC", "KON", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Verbirgt der Teufel schlau sein Schw\u00e4nzchen,", "tokens": ["Ver\u00b7birgt", "der", "Teu\u00b7fel", "schlau", "sein", "Schw\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch ist die Mutter nah dabei,", "tokens": ["Auch", "ist", "die", "Mut\u00b7ter", "nah", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit es niemals l\u00fcstern sei.", "tokens": ["Da\u00b7mit", "es", "nie\u00b7mals", "l\u00fcs\u00b7tern", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Man h\u00e4lt sich zart in der Bewegung,", "tokens": ["Man", "h\u00e4lt", "sich", "zart", "in", "der", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man unterdr\u00fcckt die schlimmste Regung", "tokens": ["Man", "un\u00b7ter\u00b7dr\u00fcckt", "die", "schlimms\u00b7te", "Re\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und ist voll Ernst, indem man spricht", "tokens": ["Und", "ist", "voll", "Ernst", ",", "in\u00b7dem", "man", "spricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "NN", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Ideal, Beruf und Pflicht.", "tokens": ["Von", "I\u00b7deal", ",", "Be\u00b7ruf", "und", "Pflicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Beim Walzer h\u00e4lt man sich manierlich,", "tokens": ["Beim", "Wal\u00b7zer", "h\u00e4lt", "man", "sich", "ma\u00b7nier\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PRF", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nie leidenschaftlich, immer zierlich.", "tokens": ["Nie", "lei\u00b7den\u00b7schaft\u00b7lich", ",", "im\u00b7mer", "zier\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Zeichen, da\u00df man sich was denkt,", "tokens": ["Das", "Zei\u00b7chen", ",", "da\u00df", "man", "sich", "was", "denkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "PRF", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist auf den H\u00e4ndedruck beschr\u00e4nkt.", "tokens": ["Ist", "auf", "den", "H\u00e4n\u00b7de\u00b7druck", "be\u00b7schr\u00e4nkt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Auge schweift voll Seelenadel", "tokens": ["Das", "Au\u00b7ge", "schweift", "voll", "See\u00b7le\u00b7na\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kaum einmal auf die Busennadel,", "tokens": ["Kaum", "ein\u00b7mal", "auf", "die", "Bu\u00b7sen\u00b7na\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und st\u00f6\u00dft im Drehen Bein an Bein,", "tokens": ["Und", "st\u00f6\u00dft", "im", "Dre\u00b7hen", "Bein", "an", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mu\u00df es unversehens sein.", "tokens": ["So", "mu\u00df", "es", "un\u00b7ver\u00b7se\u00b7hens", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Der Ball der gut erzognen T\u00f6chter", "tokens": ["Der", "Ball", "der", "gut", "er\u00b7zog\u00b7nen", "T\u00f6ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dient auch zum Finden der Geschlechter,", "tokens": ["Dient", "auch", "zum", "Fin\u00b7den", "der", "Ge\u00b7schlech\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch sucht hier alles die Partie;", "tokens": ["Doch", "sucht", "hier", "al\u00b7les", "die", "Par\u00b7tie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sinnenfreude sucht man nie.", "tokens": ["Die", "Sin\u00b7nen\u00b7freu\u00b7de", "sucht", "man", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Die M\u00e4dchen sind blo\u00df \u00bbheimzuf\u00fchren\u00ab", "tokens": ["Die", "M\u00e4d\u00b7chen", "sind", "blo\u00df", "\u00bb", "heim\u00b7zu\u00b7f\u00fch\u00b7ren", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$(", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und deshalb ausgestellt. Ber\u00fchren", "tokens": ["Und", "des\u00b7halb", "aus\u00b7ge\u00b7stellt", ".", "Be\u00b7r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PAV", "VVPP", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Darf sie der K\u00e4ufer hinterdrein.", "tokens": ["Darf", "sie", "der", "K\u00e4u\u00b7fer", "hin\u00b7ter\u00b7drein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So ist 's reell und sittenrein.", "tokens": ["So", "ist", "'s", "re\u00b7ell", "und", "sit\u00b7ten\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Wie anders denkt man auf dem Lande", "tokens": ["Wie", "an\u00b7ders", "denkt", "man", "auf", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beim kernhaft echten Bauernstande!", "tokens": ["Beim", "kern\u00b7haft", "ech\u00b7ten", "Bau\u00b7ern\u00b7stan\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier pr\u00fcft man erst den Vorgeschmack", "tokens": ["Hier", "pr\u00fcft", "man", "erst", "den", "Vor\u00b7ge\u00b7schmack"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kauft die Katze nicht im Sack.", "tokens": ["Und", "kauft", "die", "Kat\u00b7ze", "nicht", "im", "Sack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Hier kann man schon den Zweck verstehen,", "tokens": ["Hier", "kann", "man", "schon", "den", "Zweck", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sich im Dorf die Paare drehen.", "tokens": ["Wenn", "sich", "im", "Dorf", "die", "Paa\u00b7re", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des biedern Burschen gro\u00dfe Hand", "tokens": ["Des", "bie\u00b7dern", "Bur\u00b7schen", "gro\u00b7\u00dfe", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ruht auf dem sch\u00f6nsten Gegenstand.", "tokens": ["Ruht", "auf", "dem", "sch\u00f6ns\u00b7ten", "Ge\u00b7gen\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dort, wo es sich nach hinten rundet,", "tokens": ["Dort", ",", "wo", "es", "sich", "nach", "hin\u00b7ten", "run\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PRF", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat er durch festen Griff erkundet,", "tokens": ["Hat", "er", "durch", "fes\u00b7ten", "Griff", "er\u00b7kun\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df mancherlei vorhanden ist,", "tokens": ["Da\u00df", "man\u00b7cher\u00b7lei", "vor\u00b7han\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was er nicht gerne hier vermi\u00dft.", "tokens": ["Was", "er", "nicht", "ger\u00b7ne", "hier", "ver\u00b7mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sein starker Druck gilt ihr als Zeichen,", "tokens": ["Sein", "star\u00b7ker", "Druck", "gilt", "ihr", "als", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er m\u00f6chte erst noch mehr erreichen.", "tokens": ["Er", "m\u00f6ch\u00b7te", "erst", "noch", "mehr", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie lacht. Geschlossen ist der Bund.", "tokens": ["Sie", "lacht", ".", "Ge\u00b7schlos\u00b7sen", "ist", "der", "Bund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich hei\u00dfe dieses kerngesund.", "tokens": ["Ich", "hei\u00b7\u00dfe", "die\u00b7ses", "kern\u00b7ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Hat sie ein nettes Tanzvergn\u00fcgen,", "tokens": ["Hat", "sie", "ein", "net\u00b7tes", "Tanz\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum soll er nicht seines kriegen?", "tokens": ["Wa\u00b7rum", "soll", "er", "nicht", "sei\u00b7nes", "krie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "PPOSAT", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und trinkt sie mit von seinem Bier,", "tokens": ["Und", "trinkt", "sie", "mit", "von", "sei\u00b7nem", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So w\u00e4r' es auch nicht sch\u00f6n von ihr.", "tokens": ["So", "w\u00e4r'", "es", "auch", "nicht", "sch\u00f6n", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Ja, meine Herren, das ist sicher", "tokens": ["Ja", ",", "mei\u00b7ne", "Her\u00b7ren", ",", "das", "ist", "si\u00b7cher"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Viel edler und viel s\u00e4uberlicher,", "tokens": ["Viel", "ed\u00b7ler", "und", "viel", "s\u00e4u\u00b7ber\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als, den ich oben erst beschrieb,", "tokens": ["Als", ",", "den", "ich", "o\u00b7ben", "erst", "be\u00b7schrieb", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Heirats- und Versorgungstrieb!", "tokens": ["Der", "Hei\u00b7rats", "und", "Ver\u00b7sor\u00b7gungs\u00b7trieb", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und sprecht mir nicht von Ehrbegriffen!", "tokens": ["Und", "sprecht", "mir", "nicht", "von", "Ehr\u00b7be\u00b7grif\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aufs Standesamt ist schon gepfiffen,", "tokens": ["Aufs", "Stan\u00b7des\u00b7amt", "ist", "schon", "ge\u00b7pfif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Natur gen\u00fcgt uns auch allein;", "tokens": ["Na\u00b7tur", "ge\u00b7n\u00fcgt", "uns", "auch", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht alles mu\u00df gestempelt sein.", "tokens": ["Nicht", "al\u00b7les", "mu\u00df", "ge\u00b7stem\u00b7pelt", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "In Schwabing auf dem Bauernballe", "tokens": ["In", "Schwa\u00b7bing", "auf", "dem", "Bau\u00b7ern\u00b7bal\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Begegnet man dem gleichen Falle.", "tokens": ["Be\u00b7geg\u00b7net", "man", "dem", "glei\u00b7chen", "Fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das K\u00fcnstlervolk denkt auch so gro\u00df", "tokens": ["Das", "K\u00fcnst\u00b7ler\u00b7volk", "denkt", "auch", "so", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ehebundsbed\u00fcrfnislos.", "tokens": ["Und", "e\u00b7he\u00b7bunds\u00b7be\u00b7d\u00fcrf\u00b7nis\u00b7los", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Dem Malweib in Reformkost\u00fcmen", "tokens": ["Dem", "Mal\u00b7weib", "in", "Re\u00b7form\u00b7kos\u00b7t\u00fc\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ist das besonders nachzur\u00fchmen.", "tokens": ["Ist", "das", "be\u00b7son\u00b7ders", "nach\u00b7zu\u00b7r\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Malerin braucht kein Papier,", "tokens": ["Die", "Ma\u00b7le\u00b7rin", "braucht", "kein", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Amor kommt auch so zu ihr.", "tokens": ["Der", "A\u00b7mor", "kommt", "auch", "so", "zu", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Sie geht zum Ball als G\u00e4nseliesel;", "tokens": ["Sie", "geht", "zum", "Ball", "als", "G\u00e4n\u00b7se\u00b7lie\u00b7sel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "In kurzen Hosen kommt der Hiesel,", "tokens": ["In", "kur\u00b7zen", "Ho\u00b7sen", "kommt", "der", "Hie\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit rauhem Griffe packt er sie", "tokens": ["Mit", "rau\u00b7hem", "Grif\u00b7fe", "packt", "er", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hat schon ihre Sympathie.", "tokens": ["Und", "hat", "schon", "ih\u00b7re", "Sym\u00b7pa\u00b7thie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ein Juhschrei und ein falscher Schnalzer,", "tokens": ["Ein", "Juhsc\u00b7hrei", "und", "ein", "fal\u00b7scher", "Schnal\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Dann dreht er sie im wilden Walzer,", "tokens": ["Dann", "dreht", "er", "sie", "im", "wil\u00b7den", "Wal\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und merkt beim ersten Schritt: Wie nett!", "tokens": ["Und", "merkt", "beim", "ers\u00b7ten", "Schritt", ":", "Wie", "nett", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$.", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das M\u00e4del tr\u00e4gt ja kein Korsett!", "tokens": ["Das", "M\u00e4\u00b7del", "tr\u00e4gt", "ja", "kein", "Kor\u00b7sett", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Und was ihm da entgegenschwabbelt,", "tokens": ["Und", "was", "ihm", "da", "ent\u00b7ge\u00b7gen\u00b7schwab\u00b7belt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wunderh\u00fcbsch; das kribbelt, krabbelt", "tokens": ["Ist", "wun\u00b7der\u00b7h\u00fcbsch", ";", "das", "krib\u00b7belt", ",", "krab\u00b7belt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$.", "PDS", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und macht ihm einen Hochgenu\u00df,", "tokens": ["Und", "macht", "ihm", "ei\u00b7nen", "Hoch\u00b7ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er sie schleunigst k\u00fcssen mu\u00df.", "tokens": ["Da\u00df", "er", "sie", "schleu\u00b7nigst", "k\u00fcs\u00b7sen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Und rechts und links ein wildes Stampfen,", "tokens": ["Und", "rechts", "und", "links", "ein", "wil\u00b7des", "Stamp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Paare drehn, die Paare dampfen,", "tokens": ["Die", "Paa\u00b7re", "drehn", ",", "die", "Paa\u00b7re", "damp\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beim Liesel h\u00fcpft es hin und her,", "tokens": ["Beim", "Lie\u00b7sel", "h\u00fcpft", "es", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hiesel spannt 's und freut sich sehr.", "tokens": ["Der", "Hie\u00b7sel", "spannt", "'s", "und", "freut", "sich", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PRF", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.28": {"line.1": {"text": "Die rechte Hand verirrt sich schmeichelnd,", "tokens": ["Die", "rech\u00b7te", "Hand", "ver\u00b7irrt", "sich", "schmei\u00b7chelnd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz unvermerkt den Busen streichelnd,", "tokens": ["Ganz", "un\u00b7ver\u00b7merkt", "den", "Bu\u00b7sen", "strei\u00b7chelnd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Liesel duldet 's ohne Groll,", "tokens": ["Und", "Lie\u00b7sel", "dul\u00b7det", "'s", "oh\u00b7ne", "Groll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sie schaut verwirrt und seelenvoll.", "tokens": ["Sie", "schaut", "ver\u00b7wirrt", "und", "see\u00b7len\u00b7voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Die Tour ist aus. Die Malerinnen", "tokens": ["Die", "Tour", "ist", "aus", ".", "Die", "Ma\u00b7le\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind nun schon alle fast von Sinnen,", "tokens": ["Sind", "nun", "schon", "al\u00b7le", "fast", "von", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Liebe schwillt, die Sehnsucht platzt,", "tokens": ["Die", "Lie\u00b7be", "schwillt", ",", "die", "Sehn\u00b7sucht", "platzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Lippe fest auf Lippe schmatzt.", "tokens": ["Da\u00df", "Lip\u00b7pe", "fest", "auf", "Lip\u00b7pe", "schmatzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Dann eine Ma\u00df in Kellerr\u00e4umen;", "tokens": ["Dann", "ei\u00b7ne", "Ma\u00df", "in", "Kel\u00b7ler\u00b7r\u00e4u\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man hei\u00dft den Zustand \u00bbSelig tr\u00e4umen\u00ab,", "tokens": ["Man", "hei\u00dft", "den", "Zu\u00b7stand", "\u00bb", "Se\u00b7lig", "tr\u00e4u\u00b7men", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$(", "ADJD", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er ihr Bein ber\u00fchrt, damit", "tokens": ["Wenn", "er", "ihr", "Bein", "be\u00b7r\u00fchrt", ",", "da\u00b7mit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$,", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ihn auf seinen Plattfu\u00df tritt.", "tokens": ["Sie", "ihn", "auf", "sei\u00b7nen", "Platt\u00b7fu\u00df", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Schon wird sie k\u00fchn und ausgelassen", "tokens": ["Schon", "wird", "sie", "k\u00fchn", "und", "aus\u00b7ge\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und l\u00e4\u00dft ihn dies und jenes fassen.", "tokens": ["Und", "l\u00e4\u00dft", "ihn", "dies", "und", "je\u00b7nes", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "KON", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie schmilzt in hei\u00dfem Liebesdurst,", "tokens": ["Sie", "schmilzt", "in", "hei\u00b7\u00dfem", "Lie\u00b7bes\u00b7durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Ehrbegriff ist ihr schon wurst.", "tokens": ["Der", "Ehr\u00b7be\u00b7griff", "ist", "ihr", "schon", "wurst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Und wird der Hiesel sie verstehen,", "tokens": ["Und", "wird", "der", "Hie\u00b7sel", "sie", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dann kann er jetzt nach Hause gehen.", "tokens": ["Dann", "kann", "er", "jetzt", "nach", "Hau\u00b7se", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt erlebt ein \u00c4rgernis", "tokens": ["Die", "Welt", "er\u00b7lebt", "ein", "\u00c4r\u00b7ger\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit S\u00fcndenfall und Apfelbi\u00df.", "tokens": ["Mit", "S\u00fcn\u00b7den\u00b7fall", "und", "Ap\u00b7fel\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Sie schleichen still im Morgend\u00e4mmern", "tokens": ["Sie", "schlei\u00b7chen", "still", "im", "Mor\u00b7gen\u00b7d\u00e4m\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Schwabing. Ihre Pulse h\u00e4mmern,", "tokens": ["Durch", "Schwa\u00b7bing", ".", "Ih\u00b7re", "Pul\u00b7se", "h\u00e4m\u00b7mern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie stehen schon vor seinem Haus.", "tokens": ["Sie", "ste\u00b7hen", "schon", "vor", "sei\u00b7nem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schutzengel, komm! Sonst ist es aus.", "tokens": ["Schut\u00b7zen\u00b7gel", ",", "komm", "!", "Sonst", "ist", "es", "aus", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.34": {"line.1": {"text": "Der Engel, ach! ist ausgeblieben,", "tokens": ["Der", "En\u00b7gel", ",", "ach", "!", "ist", "aus\u00b7ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "$.", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das andre denkt euch, meine Lieben!", "tokens": ["Das", "and\u00b7re", "denkt", "euch", ",", "mei\u00b7ne", "Lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "$,", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Im vierten Stock ein Atelier", "tokens": ["Im", "vier\u00b7ten", "Stock", "ein", "A\u00b7te\u00b7lier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und blo\u00df ein schmales Bett \u2013 adje!", "tokens": ["Und", "blo\u00df", "ein", "schma\u00b7les", "Bett", "\u2013", "ad\u00b7je", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Das Tanzen gilt als ein Vergn\u00fcgen,", "tokens": ["Das", "Tan\u00b7zen", "gilt", "als", "ein", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bei dem sich zwei zusammenf\u00fcgen,", "tokens": ["Bei", "dem", "sich", "zwei", "zu\u00b7sam\u00b7men\u00b7f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "CARD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und sich \u2013 statt gradeaus zu gehen \u2013", "tokens": ["Und", "sich", "\u2013", "statt", "gra\u00b7de\u00b7aus", "zu", "ge\u00b7hen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "$(", "APPR", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nach links und rechts im Kreise drehen.", "tokens": ["Nach", "links", "und", "rechts", "im", "Krei\u00b7se", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "KON", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Wenn wir sein Wesen recht erkennen,", "tokens": ["Wenn", "wir", "sein", "We\u00b7sen", "recht", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wird man das Tanzen Arbeit nennen,", "tokens": ["Wird", "man", "das", "Tan\u00b7zen", "Ar\u00b7beit", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Man hat den triftigsten Beweis", "tokens": ["Man", "hat", "den", "trif\u00b7tigs\u00b7ten", "Be\u00b7weis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "In dem dabei vergossnen Schwei\u00df.", "tokens": ["In", "dem", "da\u00b7bei", "ver\u00b7goss\u00b7nen", "Schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PAV", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Hier untersucht nun der Gelehrte:", "tokens": ["Hier", "un\u00b7ter\u00b7sucht", "nun", "der", "Ge\u00b7lehr\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Zum ersten schafft sie keine Werte,", "tokens": ["Zum", "ers\u00b7ten", "schafft", "sie", "kei\u00b7ne", "Wer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zum zweiten aber hat davon", "tokens": ["Zum", "zwei\u00b7ten", "a\u00b7ber", "hat", "da\u00b7von"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "ADV", "VAFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Arbeitnehmer keinen Lohn.", "tokens": ["Der", "Ar\u00b7beit\u00b7neh\u00b7mer", "kei\u00b7nen", "Lohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Er dreht von acht bis morgens f\u00fcnfe", "tokens": ["Er", "dreht", "von", "acht", "bis", "mor\u00b7gens", "f\u00fcn\u00b7fe"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "CARD", "APPR", "ADV", "CARD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und immer gratis eine Nymphe.", "tokens": ["Und", "im\u00b7mer", "gra\u00b7tis", "ei\u00b7ne", "Nym\u00b7phe", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.3": {"text": "Dies bildet doch ein Unikum!", "tokens": ["Dies", "bil\u00b7det", "doch", "ein", "U\u00b7ni\u00b7kum", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und deshalb frage ich: warum?", "tokens": ["Und", "des\u00b7halb", "fra\u00b7ge", "ich", ":", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PPER", "$.", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Erfolgt es wirklich unentgeltlich?", "tokens": ["Er\u00b7folgt", "es", "wirk\u00b7lich", "un\u00b7ent\u00b7gelt\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geschieht es nicht doch vorbeh\u00e4ltlich?", "tokens": ["Ge\u00b7schieht", "es", "nicht", "doch", "vor\u00b7be\u00b7h\u00e4lt\u00b7lich", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Entledigt man sich seines Speckes", "tokens": ["Ent\u00b7le\u00b7digt", "man", "sich", "sei\u00b7nes", "Spe\u00b7ckes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz ohne Hinblick eines Zweckes?", "tokens": ["Ganz", "oh\u00b7ne", "Hin\u00b7blick", "ei\u00b7nes", "Zwe\u00b7ckes", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Hier ist der Angelpunkt der Frage,", "tokens": ["Hier", "ist", "der", "An\u00b7gel\u00b7punkt", "der", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihre L\u00f6sung tritt zutage:", "tokens": ["Und", "ih\u00b7re", "L\u00f6\u00b7sung", "tritt", "zu\u00b7ta\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der T\u00e4nzer leistet nur so viel", "tokens": ["Der", "T\u00e4n\u00b7zer", "leis\u00b7tet", "nur", "so", "viel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Hoffnung auf ein Nebenziel.", "tokens": ["In", "Hoff\u00b7nung", "auf", "ein", "Ne\u00b7ben\u00b7ziel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Es kann sich jede Nymphe denken,", "tokens": ["Es", "kann", "sich", "je\u00b7de", "Nym\u00b7phe", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn M\u00e4nner sie im Kreise schwenken,", "tokens": ["Wenn", "M\u00e4n\u00b7ner", "sie", "im", "Krei\u00b7se", "schwen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So hofft er schlie\u00dflich, da\u00df vielleicht", "tokens": ["So", "hofft", "er", "schlie\u00df\u00b7lich", ",", "da\u00df", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "KOUS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er das Betreffende erreicht.", "tokens": ["Er", "das", "Be\u00b7tref\u00b7fen\u00b7de", "er\u00b7reicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Es gibt nat\u00fcrlich Unterschiede:", "tokens": ["Es", "gibt", "na\u00b7t\u00fcr\u00b7lich", "Un\u00b7ter\u00b7schie\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der eine sucht es bona fide,", "tokens": ["Der", "ei\u00b7ne", "sucht", "es", "bo\u00b7na", "fi\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der andre will als Schmetterling", "tokens": ["Der", "and\u00b7re", "will", "als", "Schmet\u00b7ter\u00b7ling"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VMFIN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Blume ohne Ehering.", "tokens": ["Die", "Blu\u00b7me", "oh\u00b7ne", "E\u00b7he\u00b7ring", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Im B\u00fcrger- und Familienkr\u00e4nzchen", "tokens": ["Im", "B\u00fcr\u00b7ger", "und", "Fa\u00b7mi\u00b7li\u00b7en\u00b7kr\u00e4nz\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "TRUNC", "KON", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Verbirgt der Teufel schlau sein Schw\u00e4nzchen,", "tokens": ["Ver\u00b7birgt", "der", "Teu\u00b7fel", "schlau", "sein", "Schw\u00e4nz\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch ist die Mutter nah dabei,", "tokens": ["Auch", "ist", "die", "Mut\u00b7ter", "nah", "da\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit es niemals l\u00fcstern sei.", "tokens": ["Da\u00b7mit", "es", "nie\u00b7mals", "l\u00fcs\u00b7tern", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Man h\u00e4lt sich zart in der Bewegung,", "tokens": ["Man", "h\u00e4lt", "sich", "zart", "in", "der", "Be\u00b7we\u00b7gung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man unterdr\u00fcckt die schlimmste Regung", "tokens": ["Man", "un\u00b7ter\u00b7dr\u00fcckt", "die", "schlimms\u00b7te", "Re\u00b7gung"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und ist voll Ernst, indem man spricht", "tokens": ["Und", "ist", "voll", "Ernst", ",", "in\u00b7dem", "man", "spricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VAFIN", "ADJD", "NN", "$,", "KOUS", "PIS", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Ideal, Beruf und Pflicht.", "tokens": ["Von", "I\u00b7deal", ",", "Be\u00b7ruf", "und", "Pflicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.45": {"line.1": {"text": "Beim Walzer h\u00e4lt man sich manierlich,", "tokens": ["Beim", "Wal\u00b7zer", "h\u00e4lt", "man", "sich", "ma\u00b7nier\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PIS", "PRF", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nie leidenschaftlich, immer zierlich.", "tokens": ["Nie", "lei\u00b7den\u00b7schaft\u00b7lich", ",", "im\u00b7mer", "zier\u00b7lich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Zeichen, da\u00df man sich was denkt,", "tokens": ["Das", "Zei\u00b7chen", ",", "da\u00df", "man", "sich", "was", "denkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "PRF", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist auf den H\u00e4ndedruck beschr\u00e4nkt.", "tokens": ["Ist", "auf", "den", "H\u00e4n\u00b7de\u00b7druck", "be\u00b7schr\u00e4nkt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Das Auge schweift voll Seelenadel", "tokens": ["Das", "Au\u00b7ge", "schweift", "voll", "See\u00b7le\u00b7na\u00b7del"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Kaum einmal auf die Busennadel,", "tokens": ["Kaum", "ein\u00b7mal", "auf", "die", "Bu\u00b7sen\u00b7na\u00b7del", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und st\u00f6\u00dft im Drehen Bein an Bein,", "tokens": ["Und", "st\u00f6\u00dft", "im", "Dre\u00b7hen", "Bein", "an", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So mu\u00df es unversehens sein.", "tokens": ["So", "mu\u00df", "es", "un\u00b7ver\u00b7se\u00b7hens", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Der Ball der gut erzognen T\u00f6chter", "tokens": ["Der", "Ball", "der", "gut", "er\u00b7zog\u00b7nen", "T\u00f6ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dient auch zum Finden der Geschlechter,", "tokens": ["Dient", "auch", "zum", "Fin\u00b7den", "der", "Ge\u00b7schlech\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch sucht hier alles die Partie;", "tokens": ["Doch", "sucht", "hier", "al\u00b7les", "die", "Par\u00b7tie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIS", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sinnenfreude sucht man nie.", "tokens": ["Die", "Sin\u00b7nen\u00b7freu\u00b7de", "sucht", "man", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Die M\u00e4dchen sind blo\u00df \u00bbheimzuf\u00fchren\u00ab", "tokens": ["Die", "M\u00e4d\u00b7chen", "sind", "blo\u00df", "\u00bb", "heim\u00b7zu\u00b7f\u00fch\u00b7ren", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$(", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und deshalb ausgestellt. Ber\u00fchren", "tokens": ["Und", "des\u00b7halb", "aus\u00b7ge\u00b7stellt", ".", "Be\u00b7r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "PAV", "VVPP", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Darf sie der K\u00e4ufer hinterdrein.", "tokens": ["Darf", "sie", "der", "K\u00e4u\u00b7fer", "hin\u00b7ter\u00b7drein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So ist 's reell und sittenrein.", "tokens": ["So", "ist", "'s", "re\u00b7ell", "und", "sit\u00b7ten\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.49": {"line.1": {"text": "Wie anders denkt man auf dem Lande", "tokens": ["Wie", "an\u00b7ders", "denkt", "man", "auf", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Beim kernhaft echten Bauernstande!", "tokens": ["Beim", "kern\u00b7haft", "ech\u00b7ten", "Bau\u00b7ern\u00b7stan\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hier pr\u00fcft man erst den Vorgeschmack", "tokens": ["Hier", "pr\u00fcft", "man", "erst", "den", "Vor\u00b7ge\u00b7schmack"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kauft die Katze nicht im Sack.", "tokens": ["Und", "kauft", "die", "Kat\u00b7ze", "nicht", "im", "Sack", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Hier kann man schon den Zweck verstehen,", "tokens": ["Hier", "kann", "man", "schon", "den", "Zweck", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn sich im Dorf die Paare drehen.", "tokens": ["Wenn", "sich", "im", "Dorf", "die", "Paa\u00b7re", "dre\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "APPRART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des biedern Burschen gro\u00dfe Hand", "tokens": ["Des", "bie\u00b7dern", "Bur\u00b7schen", "gro\u00b7\u00dfe", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ruht auf dem sch\u00f6nsten Gegenstand.", "tokens": ["Ruht", "auf", "dem", "sch\u00f6ns\u00b7ten", "Ge\u00b7gen\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Dort, wo es sich nach hinten rundet,", "tokens": ["Dort", ",", "wo", "es", "sich", "nach", "hin\u00b7ten", "run\u00b7det", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "PRF", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hat er durch festen Griff erkundet,", "tokens": ["Hat", "er", "durch", "fes\u00b7ten", "Griff", "er\u00b7kun\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df mancherlei vorhanden ist,", "tokens": ["Da\u00df", "man\u00b7cher\u00b7lei", "vor\u00b7han\u00b7den", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was er nicht gerne hier vermi\u00dft.", "tokens": ["Was", "er", "nicht", "ger\u00b7ne", "hier", "ver\u00b7mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PTKNEG", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Sein starker Druck gilt ihr als Zeichen,", "tokens": ["Sein", "star\u00b7ker", "Druck", "gilt", "ihr", "als", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er m\u00f6chte erst noch mehr erreichen.", "tokens": ["Er", "m\u00f6ch\u00b7te", "erst", "noch", "mehr", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie lacht. Geschlossen ist der Bund.", "tokens": ["Sie", "lacht", ".", "Ge\u00b7schlos\u00b7sen", "ist", "der", "Bund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich hei\u00dfe dieses kerngesund.", "tokens": ["Ich", "hei\u00b7\u00dfe", "die\u00b7ses", "kern\u00b7ge\u00b7sund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Hat sie ein nettes Tanzvergn\u00fcgen,", "tokens": ["Hat", "sie", "ein", "net\u00b7tes", "Tanz\u00b7ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Warum soll er nicht seines kriegen?", "tokens": ["Wa\u00b7rum", "soll", "er", "nicht", "sei\u00b7nes", "krie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "PPOSAT", "VVINF", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Und trinkt sie mit von seinem Bier,", "tokens": ["Und", "trinkt", "sie", "mit", "von", "sei\u00b7nem", "Bier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So w\u00e4r' es auch nicht sch\u00f6n von ihr.", "tokens": ["So", "w\u00e4r'", "es", "auch", "nicht", "sch\u00f6n", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Ja, meine Herren, das ist sicher", "tokens": ["Ja", ",", "mei\u00b7ne", "Her\u00b7ren", ",", "das", "ist", "si\u00b7cher"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,", "PDS", "VAFIN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Viel edler und viel s\u00e4uberlicher,", "tokens": ["Viel", "ed\u00b7ler", "und", "viel", "s\u00e4u\u00b7ber\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als, den ich oben erst beschrieb,", "tokens": ["Als", ",", "den", "ich", "o\u00b7ben", "erst", "be\u00b7schrieb", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PRELS", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Heirats- und Versorgungstrieb!", "tokens": ["Der", "Hei\u00b7rats", "und", "Ver\u00b7sor\u00b7gungs\u00b7trieb", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Und sprecht mir nicht von Ehrbegriffen!", "tokens": ["Und", "sprecht", "mir", "nicht", "von", "Ehr\u00b7be\u00b7grif\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Aufs Standesamt ist schon gepfiffen,", "tokens": ["Aufs", "Stan\u00b7des\u00b7amt", "ist", "schon", "ge\u00b7pfif\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Natur gen\u00fcgt uns auch allein;", "tokens": ["Na\u00b7tur", "ge\u00b7n\u00fcgt", "uns", "auch", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht alles mu\u00df gestempelt sein.", "tokens": ["Nicht", "al\u00b7les", "mu\u00df", "ge\u00b7stem\u00b7pelt", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "In Schwabing auf dem Bauernballe", "tokens": ["In", "Schwa\u00b7bing", "auf", "dem", "Bau\u00b7ern\u00b7bal\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Begegnet man dem gleichen Falle.", "tokens": ["Be\u00b7geg\u00b7net", "man", "dem", "glei\u00b7chen", "Fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das K\u00fcnstlervolk denkt auch so gro\u00df", "tokens": ["Das", "K\u00fcnst\u00b7ler\u00b7volk", "denkt", "auch", "so", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und ehebundsbed\u00fcrfnislos.", "tokens": ["Und", "e\u00b7he\u00b7bunds\u00b7be\u00b7d\u00fcrf\u00b7nis\u00b7los", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Dem Malweib in Reformkost\u00fcmen", "tokens": ["Dem", "Mal\u00b7weib", "in", "Re\u00b7form\u00b7kos\u00b7t\u00fc\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Ist das besonders nachzur\u00fchmen.", "tokens": ["Ist", "das", "be\u00b7son\u00b7ders", "nach\u00b7zu\u00b7r\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Malerin braucht kein Papier,", "tokens": ["Die", "Ma\u00b7le\u00b7rin", "braucht", "kein", "Pa\u00b7pier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Amor kommt auch so zu ihr.", "tokens": ["Der", "A\u00b7mor", "kommt", "auch", "so", "zu", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Sie geht zum Ball als G\u00e4nseliesel;", "tokens": ["Sie", "geht", "zum", "Ball", "als", "G\u00e4n\u00b7se\u00b7lie\u00b7sel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "In kurzen Hosen kommt der Hiesel,", "tokens": ["In", "kur\u00b7zen", "Ho\u00b7sen", "kommt", "der", "Hie\u00b7sel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Mit rauhem Griffe packt er sie", "tokens": ["Mit", "rau\u00b7hem", "Grif\u00b7fe", "packt", "er", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und hat schon ihre Sympathie.", "tokens": ["Und", "hat", "schon", "ih\u00b7re", "Sym\u00b7pa\u00b7thie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Ein Juhschrei und ein falscher Schnalzer,", "tokens": ["Ein", "Juhsc\u00b7hrei", "und", "ein", "fal\u00b7scher", "Schnal\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.2": {"text": "Dann dreht er sie im wilden Walzer,", "tokens": ["Dann", "dreht", "er", "sie", "im", "wil\u00b7den", "Wal\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und merkt beim ersten Schritt: Wie nett!", "tokens": ["Und", "merkt", "beim", "ers\u00b7ten", "Schritt", ":", "Wie", "nett", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "ADJA", "NN", "$.", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das M\u00e4del tr\u00e4gt ja kein Korsett!", "tokens": ["Das", "M\u00e4\u00b7del", "tr\u00e4gt", "ja", "kein", "Kor\u00b7sett", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Und was ihm da entgegenschwabbelt,", "tokens": ["Und", "was", "ihm", "da", "ent\u00b7ge\u00b7gen\u00b7schwab\u00b7belt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ist wunderh\u00fcbsch; das kribbelt, krabbelt", "tokens": ["Ist", "wun\u00b7der\u00b7h\u00fcbsch", ";", "das", "krib\u00b7belt", ",", "krab\u00b7belt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$.", "PDS", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und macht ihm einen Hochgenu\u00df,", "tokens": ["Und", "macht", "ihm", "ei\u00b7nen", "Hoch\u00b7ge\u00b7nu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df er sie schleunigst k\u00fcssen mu\u00df.", "tokens": ["Da\u00df", "er", "sie", "schleu\u00b7nigst", "k\u00fcs\u00b7sen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Und rechts und links ein wildes Stampfen,", "tokens": ["Und", "rechts", "und", "links", "ein", "wil\u00b7des", "Stamp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Paare drehn, die Paare dampfen,", "tokens": ["Die", "Paa\u00b7re", "drehn", ",", "die", "Paa\u00b7re", "damp\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Beim Liesel h\u00fcpft es hin und her,", "tokens": ["Beim", "Lie\u00b7sel", "h\u00fcpft", "es", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Hiesel spannt 's und freut sich sehr.", "tokens": ["Der", "Hie\u00b7sel", "spannt", "'s", "und", "freut", "sich", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "VVFIN", "PRF", "ADV", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.62": {"line.1": {"text": "Die rechte Hand verirrt sich schmeichelnd,", "tokens": ["Die", "rech\u00b7te", "Hand", "ver\u00b7irrt", "sich", "schmei\u00b7chelnd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz unvermerkt den Busen streichelnd,", "tokens": ["Ganz", "un\u00b7ver\u00b7merkt", "den", "Bu\u00b7sen", "strei\u00b7chelnd", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Liesel duldet 's ohne Groll,", "tokens": ["Und", "Lie\u00b7sel", "dul\u00b7det", "'s", "oh\u00b7ne", "Groll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Sie schaut verwirrt und seelenvoll.", "tokens": ["Sie", "schaut", "ver\u00b7wirrt", "und", "see\u00b7len\u00b7voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Die Tour ist aus. Die Malerinnen", "tokens": ["Die", "Tour", "ist", "aus", ".", "Die", "Ma\u00b7le\u00b7rin\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PTKVZ", "$.", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind nun schon alle fast von Sinnen,", "tokens": ["Sind", "nun", "schon", "al\u00b7le", "fast", "von", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Liebe schwillt, die Sehnsucht platzt,", "tokens": ["Die", "Lie\u00b7be", "schwillt", ",", "die", "Sehn\u00b7sucht", "platzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df Lippe fest auf Lippe schmatzt.", "tokens": ["Da\u00df", "Lip\u00b7pe", "fest", "auf", "Lip\u00b7pe", "schmatzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Dann eine Ma\u00df in Kellerr\u00e4umen;", "tokens": ["Dann", "ei\u00b7ne", "Ma\u00df", "in", "Kel\u00b7ler\u00b7r\u00e4u\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Man hei\u00dft den Zustand \u00bbSelig tr\u00e4umen\u00ab,", "tokens": ["Man", "hei\u00dft", "den", "Zu\u00b7stand", "\u00bb", "Se\u00b7lig", "tr\u00e4u\u00b7men", "\u00ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$(", "ADJD", "VVINF", "$(", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er ihr Bein ber\u00fchrt, damit", "tokens": ["Wenn", "er", "ihr", "Bein", "be\u00b7r\u00fchrt", ",", "da\u00b7mit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVPP", "$,", "KOUS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie ihn auf seinen Plattfu\u00df tritt.", "tokens": ["Sie", "ihn", "auf", "sei\u00b7nen", "Platt\u00b7fu\u00df", "tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Schon wird sie k\u00fchn und ausgelassen", "tokens": ["Schon", "wird", "sie", "k\u00fchn", "und", "aus\u00b7ge\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und l\u00e4\u00dft ihn dies und jenes fassen.", "tokens": ["Und", "l\u00e4\u00dft", "ihn", "dies", "und", "je\u00b7nes", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PDS", "KON", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie schmilzt in hei\u00dfem Liebesdurst,", "tokens": ["Sie", "schmilzt", "in", "hei\u00b7\u00dfem", "Lie\u00b7bes\u00b7durst", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Ehrbegriff ist ihr schon wurst.", "tokens": ["Der", "Ehr\u00b7be\u00b7griff", "ist", "ihr", "schon", "wurst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Und wird der Hiesel sie verstehen,", "tokens": ["Und", "wird", "der", "Hie\u00b7sel", "sie", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dann kann er jetzt nach Hause gehen.", "tokens": ["Dann", "kann", "er", "jetzt", "nach", "Hau\u00b7se", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt erlebt ein \u00c4rgernis", "tokens": ["Die", "Welt", "er\u00b7lebt", "ein", "\u00c4r\u00b7ger\u00b7nis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit S\u00fcndenfall und Apfelbi\u00df.", "tokens": ["Mit", "S\u00fcn\u00b7den\u00b7fall", "und", "Ap\u00b7fel\u00b7bi\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Sie schleichen still im Morgend\u00e4mmern", "tokens": ["Sie", "schlei\u00b7chen", "still", "im", "Mor\u00b7gen\u00b7d\u00e4m\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch Schwabing. Ihre Pulse h\u00e4mmern,", "tokens": ["Durch", "Schwa\u00b7bing", ".", "Ih\u00b7re", "Pul\u00b7se", "h\u00e4m\u00b7mern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie stehen schon vor seinem Haus.", "tokens": ["Sie", "ste\u00b7hen", "schon", "vor", "sei\u00b7nem", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Schutzengel, komm! Sonst ist es aus.", "tokens": ["Schut\u00b7zen\u00b7gel", ",", "komm", "!", "Sonst", "ist", "es", "aus", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.68": {"line.1": {"text": "Der Engel, ach! ist ausgeblieben,", "tokens": ["Der", "En\u00b7gel", ",", "ach", "!", "ist", "aus\u00b7ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "$.", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Das andre denkt euch, meine Lieben!", "tokens": ["Das", "and\u00b7re", "denkt", "euch", ",", "mei\u00b7ne", "Lie\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "$,", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Im vierten Stock ein Atelier", "tokens": ["Im", "vier\u00b7ten", "Stock", "ein", "A\u00b7te\u00b7lier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und blo\u00df ein schmales Bett \u2013 adje!", "tokens": ["Und", "blo\u00df", "ein", "schma\u00b7les", "Bett", "\u2013", "ad\u00b7je", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}