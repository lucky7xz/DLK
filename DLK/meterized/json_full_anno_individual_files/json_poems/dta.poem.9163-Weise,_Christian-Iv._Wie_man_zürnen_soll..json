{"dta.poem.9163": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Iv.  \n Wie man z\u00fcrnen soll.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.57", "cy:0.42"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Maedgen wiltu b\u00f6se seyn", "tokens": ["Maed\u00b7gen", "wil\u00b7tu", "b\u00f6\u00b7se", "seyn"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "So bi\u00df es immerhin/", "tokens": ["So", "bi\u00df", "es", "im\u00b7mer\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Gleich bilde dir nicht ein/", "tokens": ["Gleich", "bil\u00b7de", "dir", "nicht", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df ich auch b\u00f6se bin.", "tokens": ["Da\u00df", "ich", "auch", "b\u00f6\u00b7se", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn seh ich zwar", "tokens": ["Denn", "seh", "ich", "zwar"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Offt gantz und gar", "tokens": ["Offt", "gantz", "und", "gar"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "KON", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Als wie die theure zeit/", "tokens": ["Als", "wie", "die", "theu\u00b7re", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "So ist mein hertz", "tokens": ["So", "ist", "mein", "hertz"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Doch ohne schertz", "tokens": ["Doch", "oh\u00b7ne", "schertz"], "token_info": ["word", "word", "word"], "pos": ["KON", "APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Noch voller Freundlichkeit.", "tokens": ["Noch", "vol\u00b7ler", "Freund\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "2. Ach wie wolt ich b\u00f6se seyn", "tokens": ["Ach", "wie", "wolt", "ich", "b\u00f6\u00b7se", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "PWAV", "VMFIN", "PPER", "ADJD", "VAINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auff dich du loses kind?", "tokens": ["Auff", "dich", "du", "lo\u00b7ses", "kind", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich bin fromm und du bist fein/", "tokens": ["Ich", "bin", "fromm", "und", "du", "bist", "fein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "PPER", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Drum bin ich gut gesinnt/", "tokens": ["Drum", "bin", "ich", "gut", "ge\u00b7sinnt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und nimmst du dir", "tokens": ["Und", "nimmst", "du", "dir"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Gleich manchmal f\u00fcr", "tokens": ["Gleich", "manch\u00b7mal", "f\u00fcr"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "APPR"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Fein sauer aussehn/", "tokens": ["Fein", "sau\u00b7er", "aus\u00b7sehn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVINF", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.8": {"text": "So denck ich das", "tokens": ["So", "denck", "ich", "das"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVIMP", "PPER", "ART"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Es ist zum spa\u00df/", "tokens": ["Es", "ist", "zum", "spa\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Und nicht aus ernst geschehn.", "tokens": ["Und", "nicht", "aus", "ernst", "ge\u00b7schehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "APPR", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "3. M\u00e4dgen ich bin dir verpflicht", "tokens": ["M\u00e4d\u00b7gen", "ich", "bin", "dir", "ver\u00b7pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "VAFIN", "PPER", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und bin von hertzen gut/", "tokens": ["Und", "bin", "von", "hert\u00b7zen", "gut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Einer andern schenck ichs nicht/", "tokens": ["Ei\u00b7ner", "an\u00b7dern", "schenck", "ichs", "nicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVFIN", "PIS", "PTKNEG", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wann sie was eckel thut/", "tokens": ["Wann", "sie", "was", "ec\u00b7kel", "thut", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PIS", "ADJD", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ach immer hin/", "tokens": ["Ach", "im\u00b7mer", "hin", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "PTKVZ", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.6": {"text": "Ein falscher sinn", "tokens": ["Ein", "fal\u00b7scher", "sinn"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Der kommt bey mir gar nicht an", "tokens": ["Der", "kommt", "bey", "mir", "gar", "nicht", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "APPR", "PPER", "ADV", "PTKNEG", "PTKVZ"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ich th\u00e4te dreyn", "tokens": ["Ich", "th\u00e4\u00b7te", "dreyn"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "CARD"], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Auffs b\u00f6se seyn/", "tokens": ["Auffs", "b\u00f6\u00b7se", "seyn", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VAINF", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Trotz wers nicht lassen kan!", "tokens": ["Trotz", "wers", "nicht", "las\u00b7sen", "kan", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}}}}