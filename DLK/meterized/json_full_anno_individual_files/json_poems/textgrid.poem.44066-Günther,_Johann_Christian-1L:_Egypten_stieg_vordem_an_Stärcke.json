{"textgrid.poem.44066": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Egypten stieg vordem an St\u00e4rcke", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Egypten stieg vordem an St\u00e4rcke", "tokens": ["E\u00b7gyp\u00b7ten", "stieg", "vor\u00b7dem", "an", "St\u00e4r\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So wie an Ehrgeiz und Verstand", "tokens": ["So", "wie", "an", "Ehr\u00b7geiz", "und", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und legte Reichthum, Sinn und Hand", "tokens": ["Und", "leg\u00b7te", "Reicht\u00b7hum", ",", "Sinn", "und", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An lauter seltne Wunderwercke,", "tokens": ["An", "lau\u00b7ter", "selt\u00b7ne", "Wun\u00b7der\u00b7wer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von welchen noch der halbe Rest", "tokens": ["Von", "wel\u00b7chen", "noch", "der", "hal\u00b7be", "Rest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und manche tief verfallne Mauer", "tokens": ["Und", "man\u00b7che", "tief", "ver\u00b7fall\u00b7ne", "Mau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht sonder einen heilgen Schauer", "tokens": ["Nicht", "son\u00b7der", "ei\u00b7nen", "heil\u00b7gen", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die alte Gr\u00f6\u00dfe kennen l\u00e4st.", "tokens": ["Die", "al\u00b7te", "Gr\u00f6\u00b7\u00dfe", "ken\u00b7nen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Baukunst seltnes Meisterst\u00fccke", "tokens": ["Der", "Bau\u00b7kunst", "selt\u00b7nes", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War \u00fcberhaupt der Tempelpracht;", "tokens": ["War", "\u00fc\u00b7ber\u00b7haupt", "der", "Tem\u00b7pel\u00b7pracht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die D\u00e4cher warfen in der Nacht", "tokens": ["Die", "D\u00e4\u00b7cher", "war\u00b7fen", "in", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Sternen ihren Schein zur\u00fccke;", "tokens": ["Den", "Ster\u00b7nen", "ih\u00b7ren", "Schein", "zu\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Werth, Arbeit, Marmor und Metall", "tokens": ["Werth", ",", "Ar\u00b7beit", ",", "Mar\u00b7mor", "und", "Me\u00b7tall"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vermehlten ihre Kostbarkeiten", "tokens": ["Ver\u00b7mehl\u00b7ten", "ih\u00b7re", "Kost\u00b7bar\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und trozten fast auf allen Seiten", "tokens": ["Und", "troz\u00b7ten", "fast", "auf", "al\u00b7len", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sowohl die Sch\u00f6nheit als den Fall.", "tokens": ["So\u00b7wohl", "die", "Sch\u00f6n\u00b7heit", "als", "den", "Fall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Strahlt au\u00dfen so ein Lustgepr\u00e4nge,", "tokens": ["Strahlt", "au\u00b7\u00dfen", "so", "ein", "Lust\u00b7ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie herrlich wird's von innen seyn!", "tokens": ["Wie", "herr\u00b7lich", "wird's", "von", "in\u00b7nen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "APPR", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt mit, last sehn! Was nimmt euch ein?", "tokens": ["Kommt", "mit", ",", "last", "sehn", "!", "Was", "nimmt", "euch", "ein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "VVINF", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Eckel vor der G\u00f6zen Menge.", "tokens": ["Ein", "E\u00b7ckel", "vor", "der", "G\u00f6\u00b7zen", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht ein scheuslich Afenbild", "tokens": ["Hier", "steht", "ein", "scheus\u00b7lich", "A\u00b7fen\u00b7bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nebst Fischen, Kazen, Hund- und Ziegen,", "tokens": ["Nebst", "Fi\u00b7schen", ",", "Ka\u00b7zen", ",", "Hun\u00b7d", "und", "Zie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dort seht ihr einen Pfafen liegen,", "tokens": ["Dort", "seht", "ihr", "ei\u00b7nen", "Pfa\u00b7fen", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den Blut und Sof mit Andacht f\u00fcllt.", "tokens": ["Den", "Blut", "und", "Sof", "mit", "An\u00b7dacht", "f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ihr flieht mit Grauen aus dem Tempel.", "tokens": ["Ihr", "flieht", "mit", "Grau\u00b7en", "aus", "dem", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ach, aber flieht doch selbst aus euch:", "tokens": ["Ach", ",", "a\u00b7ber", "flieht", "doch", "selbst", "aus", "euch", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr seyd dem G\u00f6zenhause gleich,", "tokens": ["Ihr", "seyd", "dem", "G\u00f6\u00b7zen\u00b7hau\u00b7se", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr seht und seyd auch ein Exempel.", "tokens": ["Ihr", "seht", "und", "seyd", "auch", "ein", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Euch Heuchler fahr ich christlich an,", "tokens": ["Euch", "Heuch\u00b7ler", "fahr", "ich", "christ\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Euch, euch, ihr \u00fcbert\u00fcnchten W\u00e4nde,", "tokens": ["Euch", ",", "euch", ",", "ihr", "\u00fc\u00b7ber\u00b7t\u00fcnch\u00b7ten", "W\u00e4n\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Euch, derer Schmincke b\u00f6ser H\u00e4nde", "tokens": ["Euch", ",", "de\u00b7rer", "Schmin\u00b7cke", "b\u00f6\u00b7ser", "H\u00e4n\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PDS", "NN", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die Lauge nicht vertragen kan.", "tokens": ["Die", "Lau\u00b7ge", "nicht", "ver\u00b7tra\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ihr schmeichelt mit gela\u00dfnen Blicken,", "tokens": ["Ihr", "schmei\u00b7chelt", "mit", "ge\u00b7la\u00df\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr gebt Gedult und Sanftmuth vor", "tokens": ["Ihr", "gebt", "Ge\u00b7dult", "und", "Sanft\u00b7muth", "vor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wist des P\u00f6bels Herz und Ohr", "tokens": ["Und", "wist", "des", "P\u00f6\u00b7bels", "Herz", "und", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit holder Andacht zu ber\u00fccken;", "tokens": ["Mit", "hol\u00b7der", "An\u00b7dacht", "zu", "be\u00b7r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr puzet Canzel und Altar,", "tokens": ["Ihr", "pu\u00b7zet", "Can\u00b7zel", "und", "Al\u00b7tar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Last Arm- und Wittwenh\u00e4user bauen,", "tokens": ["Last", "Ar\u00b7m", "und", "Witt\u00b7wen\u00b7h\u00e4u\u00b7ser", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "TRUNC", "KON", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ihr bethet, singt und weint als Frauen", "tokens": ["Ihr", "be\u00b7thet", ",", "singt", "und", "weint", "als", "Frau\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "KOUS", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Und bannt die Kezer alle Jahr.", "tokens": ["Und", "bannt", "die", "Ke\u00b7zer", "al\u00b7le", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wie steht es aber um die Herzen?", "tokens": ["Wie", "steht", "es", "a\u00b7ber", "um", "die", "Her\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da nisten Unvers\u00f6hnligkeit,", "tokens": ["Da", "nis\u00b7ten", "Un\u00b7ver\u00b7s\u00f6hn\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ha\u00df, Hochmuth, Zwietracht, Zorn und Streit.", "tokens": ["Ha\u00df", ",", "Hoch\u00b7muth", ",", "Zwiet\u00b7racht", ",", "Zorn", "und", "Streit", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So fahrt nur fort, mit Gott zu scherzen!", "tokens": ["So", "fahrt", "nur", "fort", ",", "mit", "Gott", "zu", "scher\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr seyd der Rache nicht zu klug;", "tokens": ["Ihr", "seyd", "der", "Ra\u00b7che", "nicht", "zu", "klug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie wird euch, ohne zu verkennen,", "tokens": ["Sie", "wird", "euch", ",", "oh\u00b7ne", "zu", "ver\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Larven vom Gesichte brennen,", "tokens": ["Die", "Lar\u00b7ven", "vom", "Ge\u00b7sich\u00b7te", "bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und dies noch allzeit fr\u00fch genug.", "tokens": ["Und", "dies", "noch", "all\u00b7zeit", "fr\u00fch", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es sind zwar alles schwere S\u00fcnden,", "tokens": ["Es", "sind", "zwar", "al\u00b7les", "schwe\u00b7re", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und keine scheint so schlecht und klein,", "tokens": ["Und", "kei\u00b7ne", "scheint", "so", "schlecht", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie mu\u00df des Todes schuldig seyn", "tokens": ["Sie", "mu\u00df", "des", "To\u00b7des", "schul\u00b7dig", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und unbereut die H\u00f6lle finden;", "tokens": ["Und", "un\u00b7be\u00b7reut", "die", "H\u00f6l\u00b7le", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch eures Lasters Wichtigkeit,", "tokens": ["Doch", "eu\u00b7res", "Las\u00b7ters", "Wich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr aufgeblasnen Pharis\u00e4er,", "tokens": ["Ihr", "auf\u00b7ge\u00b7blas\u00b7nen", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Geht darum tausend Stafeln h\u00f6her,", "tokens": ["Geht", "da\u00b7rum", "tau\u00b7send", "Sta\u00b7feln", "h\u00f6\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil keine Be\u00dfrung Trost verleiht.", "tokens": ["Weil", "kei\u00b7ne", "Be\u00df\u00b7rung", "Trost", "ver\u00b7leiht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Du Abgrund von des H\u00f6chsten Gnade,", "tokens": ["Du", "Ab\u00b7grund", "von", "des", "H\u00f6chs\u00b7ten", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Geist des Trostes und Gebeths,", "tokens": ["Du", "Geist", "des", "Tros\u00b7tes", "und", "Ge\u00b7beths", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erinnre mich doch jezt und stets", "tokens": ["E\u00b7rinn\u00b7re", "mich", "doch", "jezt", "und", "stets"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Reinigung vom S\u00fcndenbade.", "tokens": ["Der", "Rei\u00b7ni\u00b7gung", "vom", "S\u00fcn\u00b7den\u00b7ba\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Herz wird vor dein Heiligthum", "tokens": ["Mein", "Herz", "wird", "vor", "dein", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als ein befleckt Gef\u00e4\u00df erfunden,", "tokens": ["Als", "ein", "be\u00b7fleckt", "Ge\u00b7f\u00e4\u00df", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVPP", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum wasch es in des Heilands Wunden", "tokens": ["Drum", "wasch", "es", "in", "des", "Hei\u00b7lands", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und geu\u00df es durch dein Feuer um.", "tokens": ["Und", "geu\u00df", "es", "durch", "dein", "Feu\u00b7er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Egypten stieg vordem an St\u00e4rcke", "tokens": ["E\u00b7gyp\u00b7ten", "stieg", "vor\u00b7dem", "an", "St\u00e4r\u00b7cke"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So wie an Ehrgeiz und Verstand", "tokens": ["So", "wie", "an", "Ehr\u00b7geiz", "und", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und legte Reichthum, Sinn und Hand", "tokens": ["Und", "leg\u00b7te", "Reicht\u00b7hum", ",", "Sinn", "und", "Hand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An lauter seltne Wunderwercke,", "tokens": ["An", "lau\u00b7ter", "selt\u00b7ne", "Wun\u00b7der\u00b7wer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von welchen noch der halbe Rest", "tokens": ["Von", "wel\u00b7chen", "noch", "der", "hal\u00b7be", "Rest"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und manche tief verfallne Mauer", "tokens": ["Und", "man\u00b7che", "tief", "ver\u00b7fall\u00b7ne", "Mau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht sonder einen heilgen Schauer", "tokens": ["Nicht", "son\u00b7der", "ei\u00b7nen", "heil\u00b7gen", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die alte Gr\u00f6\u00dfe kennen l\u00e4st.", "tokens": ["Die", "al\u00b7te", "Gr\u00f6\u00b7\u00dfe", "ken\u00b7nen", "l\u00e4st", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Der Baukunst seltnes Meisterst\u00fccke", "tokens": ["Der", "Bau\u00b7kunst", "selt\u00b7nes", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War \u00fcberhaupt der Tempelpracht;", "tokens": ["War", "\u00fc\u00b7ber\u00b7haupt", "der", "Tem\u00b7pel\u00b7pracht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die D\u00e4cher warfen in der Nacht", "tokens": ["Die", "D\u00e4\u00b7cher", "war\u00b7fen", "in", "der", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Sternen ihren Schein zur\u00fccke;", "tokens": ["Den", "Ster\u00b7nen", "ih\u00b7ren", "Schein", "zu\u00b7r\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Werth, Arbeit, Marmor und Metall", "tokens": ["Werth", ",", "Ar\u00b7beit", ",", "Mar\u00b7mor", "und", "Me\u00b7tall"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vermehlten ihre Kostbarkeiten", "tokens": ["Ver\u00b7mehl\u00b7ten", "ih\u00b7re", "Kost\u00b7bar\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und trozten fast auf allen Seiten", "tokens": ["Und", "troz\u00b7ten", "fast", "auf", "al\u00b7len", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sowohl die Sch\u00f6nheit als den Fall.", "tokens": ["So\u00b7wohl", "die", "Sch\u00f6n\u00b7heit", "als", "den", "Fall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Strahlt au\u00dfen so ein Lustgepr\u00e4nge,", "tokens": ["Strahlt", "au\u00b7\u00dfen", "so", "ein", "Lust\u00b7ge\u00b7pr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie herrlich wird's von innen seyn!", "tokens": ["Wie", "herr\u00b7lich", "wird's", "von", "in\u00b7nen", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "APPR", "ADV", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt mit, last sehn! Was nimmt euch ein?", "tokens": ["Kommt", "mit", ",", "last", "sehn", "!", "Was", "nimmt", "euch", "ein", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "VVFIN", "VVINF", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Eckel vor der G\u00f6zen Menge.", "tokens": ["Ein", "E\u00b7ckel", "vor", "der", "G\u00f6\u00b7zen", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht ein scheuslich Afenbild", "tokens": ["Hier", "steht", "ein", "scheus\u00b7lich", "A\u00b7fen\u00b7bild"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nebst Fischen, Kazen, Hund- und Ziegen,", "tokens": ["Nebst", "Fi\u00b7schen", ",", "Ka\u00b7zen", ",", "Hun\u00b7d", "und", "Zie\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Dort seht ihr einen Pfafen liegen,", "tokens": ["Dort", "seht", "ihr", "ei\u00b7nen", "Pfa\u00b7fen", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Den Blut und Sof mit Andacht f\u00fcllt.", "tokens": ["Den", "Blut", "und", "Sof", "mit", "An\u00b7dacht", "f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ihr flieht mit Grauen aus dem Tempel.", "tokens": ["Ihr", "flieht", "mit", "Grau\u00b7en", "aus", "dem", "Tem\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ach, aber flieht doch selbst aus euch:", "tokens": ["Ach", ",", "a\u00b7ber", "flieht", "doch", "selbst", "aus", "euch", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr seyd dem G\u00f6zenhause gleich,", "tokens": ["Ihr", "seyd", "dem", "G\u00f6\u00b7zen\u00b7hau\u00b7se", "gleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr seht und seyd auch ein Exempel.", "tokens": ["Ihr", "seht", "und", "seyd", "auch", "ein", "Ex\u00b7em\u00b7pel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Euch Heuchler fahr ich christlich an,", "tokens": ["Euch", "Heuch\u00b7ler", "fahr", "ich", "christ\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Euch, euch, ihr \u00fcbert\u00fcnchten W\u00e4nde,", "tokens": ["Euch", ",", "euch", ",", "ihr", "\u00fc\u00b7ber\u00b7t\u00fcnch\u00b7ten", "W\u00e4n\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PPER", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Euch, derer Schmincke b\u00f6ser H\u00e4nde", "tokens": ["Euch", ",", "de\u00b7rer", "Schmin\u00b7cke", "b\u00f6\u00b7ser", "H\u00e4n\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "PDS", "NN", "ADJA", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Die Lauge nicht vertragen kan.", "tokens": ["Die", "Lau\u00b7ge", "nicht", "ver\u00b7tra\u00b7gen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ihr schmeichelt mit gela\u00dfnen Blicken,", "tokens": ["Ihr", "schmei\u00b7chelt", "mit", "ge\u00b7la\u00df\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr gebt Gedult und Sanftmuth vor", "tokens": ["Ihr", "gebt", "Ge\u00b7dult", "und", "Sanft\u00b7muth", "vor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wist des P\u00f6bels Herz und Ohr", "tokens": ["Und", "wist", "des", "P\u00f6\u00b7bels", "Herz", "und", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit holder Andacht zu ber\u00fccken;", "tokens": ["Mit", "hol\u00b7der", "An\u00b7dacht", "zu", "be\u00b7r\u00fc\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr puzet Canzel und Altar,", "tokens": ["Ihr", "pu\u00b7zet", "Can\u00b7zel", "und", "Al\u00b7tar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Last Arm- und Wittwenh\u00e4user bauen,", "tokens": ["Last", "Ar\u00b7m", "und", "Witt\u00b7wen\u00b7h\u00e4u\u00b7ser", "bau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "TRUNC", "KON", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Ihr bethet, singt und weint als Frauen", "tokens": ["Ihr", "be\u00b7thet", ",", "singt", "und", "weint", "als", "Frau\u00b7en"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "KOUS", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.8": {"text": "Und bannt die Kezer alle Jahr.", "tokens": ["Und", "bannt", "die", "Ke\u00b7zer", "al\u00b7le", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wie steht es aber um die Herzen?", "tokens": ["Wie", "steht", "es", "a\u00b7ber", "um", "die", "Her\u00b7zen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da nisten Unvers\u00f6hnligkeit,", "tokens": ["Da", "nis\u00b7ten", "Un\u00b7ver\u00b7s\u00f6hn\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ha\u00df, Hochmuth, Zwietracht, Zorn und Streit.", "tokens": ["Ha\u00df", ",", "Hoch\u00b7muth", ",", "Zwiet\u00b7racht", ",", "Zorn", "und", "Streit", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So fahrt nur fort, mit Gott zu scherzen!", "tokens": ["So", "fahrt", "nur", "fort", ",", "mit", "Gott", "zu", "scher\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PTKVZ", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr seyd der Rache nicht zu klug;", "tokens": ["Ihr", "seyd", "der", "Ra\u00b7che", "nicht", "zu", "klug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie wird euch, ohne zu verkennen,", "tokens": ["Sie", "wird", "euch", ",", "oh\u00b7ne", "zu", "ver\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die Larven vom Gesichte brennen,", "tokens": ["Die", "Lar\u00b7ven", "vom", "Ge\u00b7sich\u00b7te", "bren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und dies noch allzeit fr\u00fch genug.", "tokens": ["Und", "dies", "noch", "all\u00b7zeit", "fr\u00fch", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Es sind zwar alles schwere S\u00fcnden,", "tokens": ["Es", "sind", "zwar", "al\u00b7les", "schwe\u00b7re", "S\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und keine scheint so schlecht und klein,", "tokens": ["Und", "kei\u00b7ne", "scheint", "so", "schlecht", "und", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie mu\u00df des Todes schuldig seyn", "tokens": ["Sie", "mu\u00df", "des", "To\u00b7des", "schul\u00b7dig", "seyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADJD", "VAINF"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und unbereut die H\u00f6lle finden;", "tokens": ["Und", "un\u00b7be\u00b7reut", "die", "H\u00f6l\u00b7le", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Doch eures Lasters Wichtigkeit,", "tokens": ["Doch", "eu\u00b7res", "Las\u00b7ters", "Wich\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr aufgeblasnen Pharis\u00e4er,", "tokens": ["Ihr", "auf\u00b7ge\u00b7blas\u00b7nen", "Pha\u00b7ri\u00b7s\u00e4\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Geht darum tausend Stafeln h\u00f6her,", "tokens": ["Geht", "da\u00b7rum", "tau\u00b7send", "Sta\u00b7feln", "h\u00f6\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PAV", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Weil keine Be\u00dfrung Trost verleiht.", "tokens": ["Weil", "kei\u00b7ne", "Be\u00df\u00b7rung", "Trost", "ver\u00b7leiht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Du Abgrund von des H\u00f6chsten Gnade,", "tokens": ["Du", "Ab\u00b7grund", "von", "des", "H\u00f6chs\u00b7ten", "Gna\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du Geist des Trostes und Gebeths,", "tokens": ["Du", "Geist", "des", "Tros\u00b7tes", "und", "Ge\u00b7beths", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erinnre mich doch jezt und stets", "tokens": ["E\u00b7rinn\u00b7re", "mich", "doch", "jezt", "und", "stets"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Reinigung vom S\u00fcndenbade.", "tokens": ["Der", "Rei\u00b7ni\u00b7gung", "vom", "S\u00fcn\u00b7den\u00b7ba\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Herz wird vor dein Heiligthum", "tokens": ["Mein", "Herz", "wird", "vor", "dein", "Hei\u00b7lig\u00b7thum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Als ein befleckt Gef\u00e4\u00df erfunden,", "tokens": ["Als", "ein", "be\u00b7fleckt", "Ge\u00b7f\u00e4\u00df", "er\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVPP", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Drum wasch es in des Heilands Wunden", "tokens": ["Drum", "wasch", "es", "in", "des", "Hei\u00b7lands", "Wun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und geu\u00df es durch dein Feuer um.", "tokens": ["Und", "geu\u00df", "es", "durch", "dein", "Feu\u00b7er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}