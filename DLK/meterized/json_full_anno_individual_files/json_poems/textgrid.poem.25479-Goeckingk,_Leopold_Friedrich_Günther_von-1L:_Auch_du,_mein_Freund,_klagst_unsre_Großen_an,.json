{"textgrid.poem.25479": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auch du, mein Freund, klagst unsre Gro\u00dfen an,", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auch du, mein Freund, klagst unsre Gro\u00dfen an,", "tokens": ["Auch", "du", ",", "mein", "Freund", ",", "klagst", "uns\u00b7re", "Gro\u00b7\u00dfen", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df sie so kalt f\u00fcr Deutschlands K\u00fcnste bleiben?", "tokens": ["Da\u00df", "sie", "so", "kalt", "f\u00fcr", "Deutschlands", "K\u00fcns\u00b7te", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Nun, immerhin! denn was liegt mir daran?", "tokens": ["Nun", ",", "im\u00b7mer\u00b7hin", "!", "denn", "was", "liegt", "mir", "da\u00b7ran", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "KON", "PWS", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich werde nie f\u00fcr unsre Gro\u00dfen schreiben.", "tokens": ["Ich", "wer\u00b7de", "nie", "f\u00fcr", "uns\u00b7re", "Gro\u00b7\u00dfen", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch, da\u00df f\u00fcr uns ihr Kaltsinn Ungl\u00fcck sey,", "tokens": ["Doch", ",", "da\u00df", "f\u00fcr", "uns", "ihr", "Kal\u00b7tsinn", "Un\u00b7gl\u00fcck", "sey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "APPR", "PPER", "PPOSAT", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Davon wirst du mich schwerlich \u00fcberzeugen.", "tokens": ["Da\u00b7von", "wirst", "du", "mich", "schwer\u00b7lich", "\u00fc\u00b7berz\u00b7eu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Hier mach' ich wider dich Parthei,", "tokens": ["Hier", "mach'", "ich", "wi\u00b7der", "dich", "Part\u00b7hei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich m\u00fc\u00dfte sonst an meiner Zweifelei", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "sonst", "an", "mei\u00b7ner", "Zwei\u00b7fe\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Mit Hiob bersten, sollt' ich schweigen.", "tokens": ["Mit", "Hiob", "bers\u00b7ten", ",", "sollt'", "ich", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Du tr\u00e4umtest da gar einen sch\u00f6nen Traum!", "tokens": ["Du", "tr\u00e4um\u00b7test", "da", "gar", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Traum", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Entschlie\u00dfen konnt' ich erst mich kaum,", "tokens": ["Ent\u00b7schlie\u00b7\u00dfen", "konnt'", "ich", "erst", "mich", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ADV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die rosenfarbnen Bilder zu zerstreuen;", "tokens": ["Die", "ro\u00b7sen\u00b7farb\u00b7nen", "Bil\u00b7der", "zu", "zer\u00b7streu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Doch, bist du wach, und du befindest dich", "tokens": ["Doch", ",", "bist", "du", "wach", ",", "und", "du", "be\u00b7fin\u00b7dest", "dich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "VAFIN", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Nur halb so wohl dabei, als ich,", "tokens": ["Nur", "halb", "so", "wohl", "da\u00b7bei", ",", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "PAV", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So wirst du sicher mir verzeihen.", "tokens": ["So", "wirst", "du", "si\u00b7cher", "mir", "ver\u00b7zei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "La\u00df alles das die Gro\u00dfen wirklich thun,", "tokens": ["La\u00df", "al\u00b7les", "das", "die", "Gro\u00b7\u00dfen", "wirk\u00b7lich", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "ART", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Was sie in deinem Traume thaten;", "tokens": ["Was", "sie", "in", "dei\u00b7nem", "Trau\u00b7me", "tha\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Dann hat ein jeder Weiser zwar ein Huhn", "tokens": ["Dann", "hat", "ein", "je\u00b7der", "Wei\u00b7ser", "zwar", "ein", "Huhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "PIAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "In seinem Topf', der itzt zu kochen und zu braten", "tokens": ["In", "sei\u00b7nem", "Topf'", ",", "der", "itzt", "zu", "ko\u00b7chen", "und", "zu", "bra\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Oft kaum ein Ey im Hause hat:", "tokens": ["Oft", "kaum", "ein", "Ey", "im", "Hau\u00b7se", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Doch ach! nun schrein in allen Staaten", "tokens": ["Doch", "ach", "!", "nun", "schrein", "in", "al\u00b7len", "Staa\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Auch alle Schmierer: Macht uns satt!", "tokens": ["Auch", "al\u00b7le", "Schmie\u00b7rer", ":", "Macht", "uns", "satt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Des Schreibens ist schon itzt kein Ende,", "tokens": ["Des", "Schrei\u00b7bens", "ist", "schon", "itzt", "kein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und doch: wie wenig w\u00e4chst den Lesern der Verstand!", "tokens": ["Und", "doch", ":", "wie", "we\u00b7nig", "w\u00e4chst", "den", "Le\u00b7sern", "der", "Ver\u00b7stand", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWAV", "PIS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das macht, es schreiben, Freund! schon itzt ", "tokens": ["Das", "macht", ",", "es", "schrei\u00b7ben", ",", "Freund", "!", "schon", "itzt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VVINF", "$,", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Erstaune nicht, und frag' mich nicht warum?", "tokens": ["Er\u00b7stau\u00b7ne", "nicht", ",", "und", "frag'", "mich", "nicht", "wa\u00b7rum", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "KON", "VVIMP", "PPER", "PTKNEG", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "F\u00e4llt der Geschmack von unserm Publikum", "tokens": ["F\u00e4llt", "der", "Ge\u00b7schmack", "von", "un\u00b7serm", "Pub\u00b7li\u00b7kum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.28": {"text": "Mitunter nicht auf Spinnen, Kr\u00f6ten, Aeser?", "tokens": ["Mi\u00b7tun\u00b7ter", "nicht", "auf", "Spin\u00b7nen", ",", "Kr\u00f6\u00b7ten", ",", "A\u00b7e\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Wie f\u00e4nde sonst, es sey auch noch so dumm,", "tokens": ["Wie", "f\u00e4n\u00b7de", "sonst", ",", "es", "sey", "auch", "noch", "so", "dumm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Ein jedes Werklein seine Leser?", "tokens": ["Ein", "je\u00b7des", "Wer\u00b7klein", "sei\u00b7ne", "Le\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.31": {"text": "Trotz allen Schreibern aller Erden,", "tokens": ["Trotz", "al\u00b7len", "Schrei\u00b7bern", "al\u00b7ler", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Wird doch das Publikum nicht klug,", "tokens": ["Wird", "doch", "das", "Pub\u00b7li\u00b7kum", "nicht", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Bis alle Buchh\u00e4ndler zu edlen Weisen werden:", "tokens": ["Bis", "al\u00b7le", "Buch\u00b7h\u00e4nd\u00b7ler", "zu", "ed\u00b7len", "Wei\u00b7sen", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Nicht wahr, nun hast du schon genug?", "tokens": ["Nicht", "wahr", ",", "nun", "hast", "du", "schon", "ge\u00b7nug", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Wir lesen alle mit einander,", "tokens": ["Wir", "le\u00b7sen", "al\u00b7le", "mit", "ein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Allein das wie? und was? bek\u00fcmmert etwa drei", "tokens": ["Al\u00b7lein", "das", "wie", "?", "und", "was", "?", "be\u00b7k\u00fcm\u00b7mert", "et\u00b7wa", "drei"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "PWAV", "$.", "KON", "PWS", "$.", "VVFIN", "ADV", "CARD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Von Tausenden. Was wagt nun Mops dabei,", "tokens": ["Von", "Tau\u00b7sen\u00b7den", ".", "Was", "wagt", "nun", "Mops", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PWS", "VVFIN", "ADV", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Druckt er die Reime von Talander?", "tokens": ["Druckt", "er", "die", "Rei\u00b7me", "von", "Ta\u00b7lan\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.39": {"text": "Verlieren kann er nichts, weil jeder Thor", "tokens": ["Ver\u00b7lie\u00b7ren", "kann", "er", "nichts", ",", "weil", "je\u00b7der", "Thor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PIS", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Gewi\u00df dreihundert K\u00e4ufer findet,", "tokens": ["Ge\u00b7wi\u00df", "drei\u00b7hun\u00b7dert", "K\u00e4u\u00b7fer", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Gewinnen aber leicht, da itzt noch, wie zuvor,", "tokens": ["Ge\u00b7win\u00b7nen", "a\u00b7ber", "leicht", ",", "da", "itzt", "noch", ",", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "$,", "KOUS", "ADV", "ADV", "$,", "PWAV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Aus allen Laden schnell die ", "tokens": ["Aus", "al\u00b7len", "La\u00b7den", "schnell", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADJD", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Mag die Kritik sich heiser schrein,", "tokens": ["Mag", "die", "Kri\u00b7tik", "sich", "hei\u00b7ser", "schrein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PRF", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Sie wird die Zahl der Schmierer nicht vermindern.", "tokens": ["Sie", "wird", "die", "Zahl", "der", "Schmie\u00b7rer", "nicht", "ver\u00b7min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Das Publikum will unterhalten seyn,", "tokens": ["Das", "Pub\u00b7li\u00b7kum", "will", "un\u00b7ter\u00b7hal\u00b7ten", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Und die\u00df besteht fast blo\u00df aus alten Kindern.", "tokens": ["Und", "die\u00df", "be\u00b7steht", "fast", "blo\u00df", "aus", "al\u00b7ten", "Kin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.47": {"text": "Ist's nun so leicht, durch N\u00fcrenberger Tand", "tokens": ["Ist's", "nun", "so", "leicht", ",", "durch", "N\u00fc\u00b7ren\u00b7ber\u00b7ger", "Tand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Den Kindern ihre Zeit vertreiben,", "tokens": ["Den", "Kin\u00b7dern", "ih\u00b7re", "Zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Wie leicht l\u00e4\u00dft dann nicht der Verstand", "tokens": ["Wie", "leicht", "l\u00e4\u00dft", "dann", "nicht", "der", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.50": {"text": "Durch Klang der Louisdor in des Verlegers Hand,", "tokens": ["Durch", "Klang", "der", "Lou\u00b7is\u00b7dor", "in", "des", "Ver\u00b7le\u00b7gers", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NE", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ja selbst die Furcht vor Schande, sich bet\u00e4uben.", "tokens": ["Ja", "selbst", "die", "Furcht", "vor", "Schan\u00b7de", ",", "sich", "be\u00b7t\u00e4u\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "APPR", "NN", "$,", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Aus neun und neunzigen das hundertste zu schreiben:", "tokens": ["Aus", "neun", "und", "neun\u00b7zi\u00b7gen", "das", "hun\u00b7derts\u00b7te", "zu", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "KON", "ADJA", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.53": {"text": "Das ist die wahre B\u00fcchermacher-Kunst!", "tokens": ["Das", "ist", "die", "wah\u00b7re", "B\u00fc\u00b7cher\u00b7ma\u00b7cher\u00b7Kunst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Wo w\u00fcrden sonst von Hundert wohl \u2013 mit Gunst!", "tokens": ["Wo", "w\u00fcr\u00b7den", "sonst", "von", "Hun\u00b7dert", "wohl", "\u2013", "mit", "Gunst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "APPR", "NE", "ADV", "$(", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Ihr B\u00fcchermacher! \u2013 neun und neunzig bleiben?", "tokens": ["Ihr", "B\u00fc\u00b7cher\u00b7ma\u00b7cher", "!", "\u2013", "neun", "und", "neun\u00b7zig", "blei\u00b7ben", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "$(", "CARD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.56": {"text": "Freund! wenn du kannst, so schlie\u00dfe du", "tokens": ["Freund", "!", "wenn", "du", "kannst", ",", "so", "schlie\u00b7\u00dfe", "du"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "VMFIN", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "Noch heute, allen Klugen, allen Dummen,", "tokens": ["Noch", "heu\u00b7te", ",", "al\u00b7len", "Klu\u00b7gen", ",", "al\u00b7len", "Dum\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Die B\u00fcchers\u00e4l' auf deiner ", "tokens": ["Die", "B\u00fc\u00b7cher\u00b7s\u00e4l'", "auf", "dei\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.59": {"text": "Wie werden dann in einem Nu", "tokens": ["Wie", "wer\u00b7den", "dann", "in", "ei\u00b7nem", "Nu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "APPR", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Ein Schock Autoren schier verstummen;", "tokens": ["Ein", "Schock", "Au\u00b7to\u00b7ren", "schier", "ver\u00b7stum\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Indessen, wie einst Salomo,", "tokens": ["In\u00b7des\u00b7sen", ",", "wie", "einst", "Sa\u00b7lo\u00b7mo", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Ein W** sich, durch sich, noch Weisheit wird erwerben.", "tokens": ["Ein", "W", "*", "*", "sich", ",", "durch", "sich", ",", "noch", "Weis\u00b7heit", "wird", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "XY", "XY", "XY", "PRF", "$,", "APPR", "PRF", "$,", "ADV", "NN", "VAFIN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.63": {"text": "Studirte jener itzt noch so,", "tokens": ["Stu\u00b7dir\u00b7te", "je\u00b7ner", "itzt", "noch", "so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "F\u00fcr Lohn, so m\u00fc\u00dfte Salomo", "tokens": ["F\u00fcr", "Lohn", ",", "so", "m\u00fc\u00df\u00b7te", "Sa\u00b7lo\u00b7mo"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "VMFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Nun freilich wohl f\u00fcr Hunger sterben.", "tokens": ["Nun", "frei\u00b7lich", "wohl", "f\u00fcr", "Hun\u00b7ger", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Doch auch nur leben sollte man,", "tokens": ["Doch", "auch", "nur", "le\u00b7ben", "soll\u00b7te", "man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "VMFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Um zu studiren; nicht studiren,", "tokens": ["Um", "zu", "stu\u00b7di\u00b7ren", ";", "nicht", "stu\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "$.", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Um nur zu leben. Denn was kann", "tokens": ["Um", "nur", "zu", "le\u00b7ben", ".", "Denn", "was", "kann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "ADV", "PTKZU", "VVINF", "$.", "KON", "PWS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Der arme Wicht f\u00fcr Zeit verlieren,", "tokens": ["Der", "ar\u00b7me", "Wicht", "f\u00fcr", "Zeit", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.70": {"text": "Der mit dem Abend' kaum sein Tagelohn gewann?", "tokens": ["Der", "mit", "dem", "A\u00b7bend'", "kaum", "sein", "Ta\u00b7ge\u00b7lohn", "ge\u00b7wann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Gerade de\u00dfhalb, sagst du zwar,", "tokens": ["Ge\u00b7ra\u00b7de", "de\u00df\u00b7halb", ",", "sagst", "du", "zwar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "M\u00fc\u00dft' ihm der F\u00fcrst ein Jahrgeld geben;", "tokens": ["M\u00fc\u00dft'", "ihm", "der", "F\u00fcrst", "ein", "Jahr\u00b7geld", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Doch, lieber Freund, wenn erst, wie offenbar,", "tokens": ["Doch", ",", "lie\u00b7ber", "Freund", ",", "wenn", "erst", ",", "wie", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "NN", "$,", "KOUS", "ADV", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.74": {"text": "Vier tausend Schmierer mehr nach einem Jahrgeld' streben:", "tokens": ["Vier", "tau\u00b7send", "Schmie\u00b7rer", "mehr", "nach", "ei\u00b7nem", "Jahr\u00b7geld'", "stre\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Was wird am End' aus unserm Publikum?", "tokens": ["Was", "wird", "am", "End'", "aus", "un\u00b7serm", "Pub\u00b7li\u00b7kum", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.76": {"text": "Recht viel ist zwar daran nicht zu verderben,", "tokens": ["Recht", "viel", "ist", "zwar", "da\u00b7ran", "nicht", "zu", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "ADV", "PAV", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.77": {"text": "Doch lies't sich itzt ein Theil davon nur dumm,", "tokens": ["Doch", "lies't", "sich", "itzt", "ein", "Theil", "da\u00b7von", "nur", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.78": {"text": "Dann w\u00fcrde gar ein Theil vom Lesen sterben.", "tokens": ["Dann", "w\u00fcr\u00b7de", "gar", "ein", "Theil", "vom", "Le\u00b7sen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.79": {"text": "Wer Anlag' hat zu einem weisen Mann',", "tokens": ["Wer", "An\u00b7lag'", "hat", "zu", "ei\u00b7nem", "wei\u00b7sen", "Mann'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.80": {"text": "Wird leicht es ganz durch die Sokraten dann,", "tokens": ["Wird", "leicht", "es", "ganz", "durch", "die", "Sok\u00b7ra\u00b7ten", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.81": {"text": "Und f\u00fchlt er Hang zu einem Thoren,", "tokens": ["Und", "f\u00fchlt", "er", "Hang", "zu", "ei\u00b7nem", "Tho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.82": {"text": "So zerren die Sophisten dran,", "tokens": ["So", "zer\u00b7ren", "die", "So\u00b7phis\u00b7ten", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "Bis er den Wunsch nach Weisheit selbst verloren.", "tokens": ["Bis", "er", "den", "Wunsch", "nach", "Weis\u00b7heit", "selbst", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.84": {"text": "Wie wenig neigen, wenn der Bart", "tokens": ["Wie", "we\u00b7nig", "nei\u00b7gen", ",", "wenn", "der", "Bart"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "Beim J\u00fcngling' keimt, sich auf der Weisen Seite;", "tokens": ["Beim", "J\u00fcng\u00b7ling'", "keimt", ",", "sich", "auf", "der", "Wei\u00b7sen", "Sei\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.86": {"text": "Die \u00fcbrigen, (wie ihr genug erfahrt,)", "tokens": ["Die", "\u00fcb\u00b7ri\u00b7gen", ",", "(", "wie", "ihr", "ge\u00b7nug", "er\u00b7fahrt", ",", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "$,", "$(", "PWAV", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Sind ganz gewi\u00df der Schmierer Beute.", "tokens": ["Sind", "ganz", "ge\u00b7wi\u00df", "der", "Schmie\u00b7rer", "Beu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Wenn alle nur, die so sich stumpf", "tokens": ["Wenn", "al\u00b7le", "nur", ",", "die", "so", "sich", "stumpf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "$,", "PRELS", "ADV", "PRF", "ADJD"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.89": {"text": "Am Geist' und Herzen lasen, einen Strumpf", "tokens": ["Am", "Geist'", "und", "Her\u00b7zen", "la\u00b7sen", ",", "ei\u00b7nen", "Strumpf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "KON", "NN", "VVINF", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.90": {"text": "Inde\u00df gestrickt, ein Paar Manschetten", "tokens": ["In\u00b7de\u00df", "ge\u00b7strickt", ",", "ein", "Paar", "Man\u00b7schet\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVPP", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.91": {"text": "Gen\u00e4het, oder den Verstand", "tokens": ["Ge\u00b7n\u00e4\u00b7het", ",", "o\u00b7der", "den", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.92": {"text": "Von einer Fabel nur erkl\u00e4rt dem Sohne h\u00e4tten:", "tokens": ["Von", "ei\u00b7ner", "Fa\u00b7bel", "nur", "er\u00b7kl\u00e4rt", "dem", "Soh\u00b7ne", "h\u00e4t\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Welch ein Gewinn f\u00fcrs Vaterland!", "tokens": ["Welch", "ein", "Ge\u00b7winn", "f\u00fcrs", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "Und h\u00e4tten die vier tausend Schmierer nur", "tokens": ["Und", "h\u00e4t\u00b7ten", "die", "vier", "tau\u00b7send", "Schmie\u00b7rer", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "CARD", "CARD", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Vom Acker Steine aufgelesen,", "tokens": ["Vom", "A\u00b7cker", "Stei\u00b7ne", "auf\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Inde\u00df ein b\u00f6ser Geist in ihre Finger fuhr,", "tokens": ["In\u00b7de\u00df", "ein", "b\u00f6\u00b7ser", "Geist", "in", "ih\u00b7re", "Fin\u00b7ger", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "So w\u00e4r's doch etwas noch gewesen!", "tokens": ["So", "w\u00e4r's", "doch", "et\u00b7was", "noch", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Nimm alle die vier tausend leere K\u00f6pfe,", "tokens": ["Nimm", "al\u00b7le", "die", "vier", "tau\u00b7send", "lee\u00b7re", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "ART", "CARD", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "Ein Jahrgeld macht nicht einen guten draus;", "tokens": ["Ein", "Jahr\u00b7geld", "macht", "nicht", "ei\u00b7nen", "gu\u00b7ten", "draus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "ADJA", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.100": {"text": "Denn Ewigkeit bek\u00fcmmert die Gesch\u00f6pfe", "tokens": ["Denn", "E\u00b7wig\u00b7keit", "be\u00b7k\u00fcm\u00b7mert", "die", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.101": {"text": "Nicht halb so sehr, als ein Verleger-Schmaus.", "tokens": ["Nicht", "halb", "so", "sehr", ",", "als", "ein", "Ver\u00b7le\u00b7ger\u00b7Schmaus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "ADV", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.102": {"text": "Der aber, Freund, in dem ein Funken gl\u00fchet,", "tokens": ["Der", "a\u00b7ber", ",", "Freund", ",", "in", "dem", "ein", "Fun\u00b7ken", "gl\u00fc\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.103": {"text": "L\u00f6scht ihn, sey er auch arm, durch keine Thr\u00e4nen aus.", "tokens": ["L\u00f6scht", "ihn", ",", "sey", "er", "auch", "arm", ",", "durch", "kei\u00b7ne", "Thr\u00e4\u00b7nen", "aus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$,", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.104": {"text": "Er brennt, eh' sich's die karge Welt versiehet,", "tokens": ["Er", "brennt", ",", "eh'", "sich's", "die", "kar\u00b7ge", "Welt", "ver\u00b7sie\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.105": {"text": "Einst lichterloh aus ihm heraus.", "tokens": ["Einst", "lich\u00b7ter\u00b7loh", "aus", "ihm", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "Wer eine Ilias vielleicht gesungen h\u00e4tte,", "tokens": ["Wer", "ei\u00b7ne", "I\u00b7lias", "viel\u00b7leicht", "ge\u00b7sun\u00b7gen", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.107": {"text": "Singt freilich kaum noch dann und wann ein Lied,", "tokens": ["Singt", "frei\u00b7lich", "kaum", "noch", "dann", "und", "wann", "ein", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "ADV", "KON", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.108": {"text": "Wenn er an eine Sklavenkette", "tokens": ["Wenn", "er", "an", "ei\u00b7ne", "Skla\u00b7ven\u00b7ket\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.109": {"text": "Sich Tag und Nacht gefesselt sieht.", "tokens": ["Sich", "Tag", "und", "Nacht", "ge\u00b7fes\u00b7selt", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "KON", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Dann aber nehm' ein B\u00fcrger unsers Reiches", "tokens": ["Dann", "a\u00b7ber", "nehm'", "ein", "B\u00fcr\u00b7ger", "un\u00b7sers", "Rei\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.111": {"text": "Die Kett' ihm ab, und sey sein Freund durch That,", "tokens": ["Die", "Kett'", "ihm", "ab", ",", "und", "sey", "sein", "Freund", "durch", "That", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$,", "KON", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.112": {"text": "Und thu' zuerst im deutschen Reich' ein gleiches,", "tokens": ["Und", "thu'", "zu\u00b7erst", "im", "deut\u00b7schen", "Reich'", "ein", "glei\u00b7ches", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.113": {"text": "Als oft Brittanien schon that.", "tokens": ["Als", "oft", "Brit\u00b7ta\u00b7ni\u00b7en", "schon", "that", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "Kein Gro\u00dfer l\u00f6se sie; denn die Trompeten", "tokens": ["Kein", "Gro\u00b7\u00dfer", "l\u00f6\u00b7se", "sie", ";", "denn", "die", "Trom\u00b7pe\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.115": {"text": "Der Fama, sagen sonst ein wahres Ungl\u00fcck an.", "tokens": ["Der", "Fa\u00b7ma", ",", "sa\u00b7gen", "sonst", "ein", "wah\u00b7res", "Un\u00b7gl\u00fcck", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Zur Klippe wird ein Jahrgehalt, woran", "tokens": ["Zur", "Klip\u00b7pe", "wird", "ein", "Jahr\u00b7ge\u00b7halt", ",", "wo\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.117": {"text": "Das Gl\u00fcck von hundert ampelnden Poeten", "tokens": ["Das", "Gl\u00fcck", "von", "hun\u00b7dert", "am\u00b7peln\u00b7den", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.118": {"text": "Zerscheitert.", "tokens": ["Zer\u00b7schei\u00b7tert", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.119": {"text": "\u00bbnun, so la\u00df sie scheitern, Freund!", "tokens": ["\u00bb", "nun", ",", "so", "la\u00df", "sie", "schei\u00b7tern", ",", "Freund", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "VVIMP", "PPER", "VVINF", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.120": {"text": "Soll wohl ein Staat, so n\u00fctzlich ihm es scheint,", "tokens": ["Soll", "wohl", "ein", "Staat", ",", "so", "n\u00fctz\u00b7lich", "ihm", "es", "scheint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "$,", "ADV", "ADJD", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.121": {"text": "Schon darum keinen Preis aus seinen Sch\u00e4tzen", "tokens": ["Schon", "da\u00b7rum", "kei\u00b7nen", "Preis", "aus", "sei\u00b7nen", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.122": {"text": "Auf eine neue Durchfahrt setzen,", "tokens": ["Auf", "ei\u00b7ne", "neu\u00b7e", "Durch\u00b7fahrt", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.123": {"text": "Weil manches Schiff dar\u00fcber sinken kann?", "tokens": ["Weil", "man\u00b7ches", "Schiff", "da\u00b7r\u00fc\u00b7ber", "sin\u00b7ken", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PAV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.124": {"text": "Von allen menschlichen Gesetzen", "tokens": ["Von", "al\u00b7len", "menschli\u00b7chen", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.125": {"text": "Steht ja das Wohl des Staates obenan!\u00ab", "tokens": ["Steht", "ja", "das", "Wohl", "des", "Staa\u00b7tes", "o\u00b7be\u00b7nan", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.126": {"text": "Du nimmst das Wort mir aus dem Munde;", "tokens": ["Du", "nimmst", "das", "Wort", "mir", "aus", "dem", "Mun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.127": {"text": "Denn grade die\u00df hielt ich zur Antwort schon", "tokens": ["Denn", "gra\u00b7de", "die\u00df", "hielt", "ich", "zur", "Ant\u00b7wort", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PDS", "VVFIN", "PPER", "APPRART", "NN", "ADV"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.128": {"text": "F\u00fcr dich bereit. Ich wei\u00df es, denn die Kunde", "tokens": ["F\u00fcr", "dich", "be\u00b7reit", ".", "Ich", "wei\u00df", "es", ",", "denn", "die", "Kun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.129": {"text": "Der Vorzeit lehrt es: da\u00df f\u00fcr Thron", "tokens": ["Der", "Vor\u00b7zeit", "lehrt", "es", ":", "da\u00df", "f\u00fcr", "Thron"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.130": {"text": "Und H\u00fctte, Welt und Nachwelt, keiner,", "tokens": ["Und", "H\u00fct\u00b7te", ",", "Welt", "und", "Nach\u00b7welt", ",", "kei\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "$,", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.131": {"text": "Der auf dem Thron' nicht sitzt, so segnend werden kann,", "tokens": ["Der", "auf", "dem", "Thron'", "nicht", "sitzt", ",", "so", "seg\u00b7nend", "wer\u00b7den", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "$,", "ADV", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Als der erhabnen Weisen Einer,", "tokens": ["Als", "der", "er\u00b7hab\u00b7nen", "Wei\u00b7sen", "Ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.133": {"text": "Der sich das Herz des Volks gewann.", "tokens": ["Der", "sich", "das", "Herz", "des", "Volks", "ge\u00b7wann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Wenn f\u00fcr Germanien, in jedem Fach'", "tokens": ["Wenn", "f\u00fcr", "Ger\u00b7ma\u00b7ni\u00b7en", ",", "in", "je\u00b7dem", "Fach'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.135": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.136": {"text": "Der F\u00fcrsten und der B\u00fcrger, nach und nach", "tokens": ["Der", "F\u00fcrs\u00b7ten", "und", "der", "B\u00fcr\u00b7ger", ",", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.137": {"text": "Der Dunse Schmiererein verschw\u00e4nden:", "tokens": ["Der", "Dun\u00b7se", "Schmie\u00b7rer\u00b7ein", "ver\u00b7schw\u00e4n\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.138": {"text": "Dann w\u00fcrde, Freund, das Gl\u00fcck des Publikum,", "tokens": ["Dann", "w\u00fcr\u00b7de", ",", "Freund", ",", "das", "Gl\u00fcck", "des", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.139": {"text": "(itzt kaum ein Baum mit Bl\u00e4ttervollen Zweigen)", "tokens": ["(", "itzt", "kaum", "ein", "Baum", "mit", "Bl\u00e4t\u00b7ter\u00b7vol\u00b7len", "Zwei\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.140": {"text": "Mehr Fr\u00fccht' in einem Jahre zeigen,", "tokens": ["Mehr", "Fr\u00fccht'", "in", "ei\u00b7nem", "Jah\u00b7re", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.141": {"text": "Als itzt in einem Sekulum.", "tokens": ["Als", "itzt", "in", "ei\u00b7nem", "Se\u00b7ku\u00b7lum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.142": {"text": "Was itzt ein Denker baut, das rei\u00dft ein Schmierer ein;", "tokens": ["Was", "itzt", "ein", "Den\u00b7ker", "baut", ",", "das", "rei\u00dft", "ein", "Schmie\u00b7rer", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Das letzte Wort wird auch dem Narrn das wahrste seyn,", "tokens": ["Das", "letz\u00b7te", "Wort", "wird", "auch", "dem", "Narrn", "das", "wahrs\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Und dieses mag der Schmierer leicht behalten.", "tokens": ["Und", "die\u00b7ses", "mag", "der", "Schmie\u00b7rer", "leicht", "be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.145": {"text": "Das wahre Publikum, das Publikum der Alten,", "tokens": ["Das", "wah\u00b7re", "Pub\u00b7li\u00b7kum", ",", "das", "Pub\u00b7li\u00b7kum", "der", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Der unsichtbaren Kirche gleich,", "tokens": ["Der", "un\u00b7sicht\u00b7ba\u00b7ren", "Kir\u00b7che", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.147": {"text": "Hat keine Macht; zerstreut durchs ganze Reich,", "tokens": ["Hat", "kei\u00b7ne", "Macht", ";", "zer\u00b7streut", "durchs", "gan\u00b7ze", "Reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$.", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.148": {"text": "Triffst du vielleicht auf ganze Meilen", "tokens": ["Triffst", "du", "viel\u00b7leicht", "auf", "gan\u00b7ze", "Mei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.149": {"text": "Kein Mitglied dieses H\u00e4ufchens an,", "tokens": ["Kein", "Mit\u00b7glied", "die\u00b7ses", "H\u00e4uf\u00b7chens", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.150": {"text": "Dein volles Herz mit ihm zu theilen.", "tokens": ["Dein", "vol\u00b7les", "Herz", "mit", "ihm", "zu", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.151": {"text": "Doch immer besser, Freund! als da\u00df die Kircheneulen", "tokens": ["Doch", "im\u00b7mer", "bes\u00b7ser", ",", "Freund", "!", "als", "da\u00df", "die", "Kir\u00b7che\u00b7neu\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "NN", "$.", "KOKOM", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.153": {"text": "Als da\u00df ein ", "tokens": ["Als", "da\u00df", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOUS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.154": {"text": "Inde\u00df es Kl\u00fcgern oft durchs Dach ins St\u00fcbchen schneit;", "tokens": ["In\u00b7de\u00df", "es", "Kl\u00fc\u00b7gern", "oft", "durchs", "Dach", "ins", "St\u00fcb\u00b7chen", "schneit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Als da\u00df ein ", "tokens": ["Als", "da\u00df", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOUS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.156": {"text": "Nach der ", "tokens": ["Nach", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.157": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.158": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.159": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.160": {"text": "Inde\u00df er selbst, f\u00fcr Gold, der Eitelkeit", "tokens": ["In\u00b7de\u00df", "er", "selbst", ",", "f\u00fcr", "Gold", ",", "der", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.161": {"text": "Mit vollen H\u00e4nden Weihrauch streut.", "tokens": ["Mit", "vol\u00b7len", "H\u00e4n\u00b7den", "Weih\u00b7rauch", "streut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "In Frankreich suchte sonst der Schmeichler und der Duns", "tokens": ["In", "Fran\u00b7kreich", "such\u00b7te", "sonst", "der", "Schmeich\u00b7ler", "und", "der", "Duns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Nur Goldsand in der Hippokrene;", "tokens": ["Nur", "Gold\u00b7sand", "in", "der", "Hip\u00b7po\u00b7kre\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.164": {"text": "Wir hatten nie Auguste und M\u00e4cene,", "tokens": ["Wir", "hat\u00b7ten", "nie", "Au\u00b7gus\u00b7te", "und", "M\u00e4\u00b7ce\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.165": {"text": "Das was wir sind, sind wir allein durch uns.", "tokens": ["Das", "was", "wir", "sind", ",", "sind", "wir", "al\u00b7lein", "durch", "uns", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VAFIN", "$,", "VAFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Ein wahres Gl\u00fcck! denn es ist mit der Kunst", "tokens": ["Ein", "wah\u00b7res", "Gl\u00fcck", "!", "denn", "es", "ist", "mit", "der", "Kunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KON", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.167": {"text": "Wie mit der Tugend; wer nicht beide", "tokens": ["Wie", "mit", "der", "Tu\u00b7gend", ";", "wer", "nicht", "bei\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "$.", "PWS", "PTKNEG", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Um ihrer willen liebt, nur liebt um F\u00fcrstengunst,", "tokens": ["Um", "ih\u00b7rer", "wil\u00b7len", "liebt", ",", "nur", "liebt", "um", "F\u00fcrs\u00b7ten\u00b7gunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Der f\u00fchlt ihr Aeu\u00dfres nur, nicht ihre innre Freude.", "tokens": ["Der", "f\u00fchlt", "ihr", "A\u00b7e\u00b7u\u00df\u00b7res", "nur", ",", "nicht", "ih\u00b7re", "inn\u00b7re", "Freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ADV", "$,", "PTKNEG", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.170": {"text": "Ein wahres Gl\u00fcck! Weil das, was tief vergraben", "tokens": ["Ein", "wah\u00b7res", "Gl\u00fcck", "!", "Weil", "das", ",", "was", "tief", "ver\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KOUS", "PDS", "$,", "PRELS", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.171": {"text": "Im Schutte der Barbaren lag,", "tokens": ["Im", "Schut\u00b7te", "der", "Bar\u00b7ba\u00b7ren", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.172": {"text": "Der Menschheit \u00e4ltesten Vertrag,", "tokens": ["Der", "Menschheit", "\u00e4l\u00b7tes\u00b7ten", "Ver\u00b7trag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.173": {"text": "Wir dadurch blo\u00df, hervorgezogen haben.", "tokens": ["Wir", "da\u00b7durch", "blo\u00df", ",", "her\u00b7vor\u00b7ge\u00b7zo\u00b7gen", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PAV", "ADV", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.174": {"text": "Wo, wie in Gallien, Verdienst nur Einen Richter,", "tokens": ["Wo", ",", "wie", "in", "Gal\u00b7li\u00b7en", ",", "Ver\u00b7dienst", "nur", "Ei\u00b7nen", "Rich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "APPR", "NE", "$,", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und diesen oft zum Feind' die Wahrheit hat,", "tokens": ["Und", "die\u00b7sen", "oft", "zum", "Feind'", "die", "Wahr\u00b7heit", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "APPRART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.176": {"text": "Da schleppt man selbst den Lieblingsdichter", "tokens": ["Da", "schleppt", "man", "selbst", "den", "Lieb\u00b7lings\u00b7dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.177": {"text": "Um ein, gelesnes nur, nicht selbst geschriebnes Blatt", "tokens": ["Um", "ein", ",", "ge\u00b7les\u00b7nes", "nur", ",", "nicht", "selbst", "ge\u00b7schrieb\u00b7nes", "Blatt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "PTKVZ", "$,", "ADJA", "ADV", "$,", "PTKNEG", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "In die Bastille", "tokens": ["In", "die", "Bas\u00b7til\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.179": {"text": "Vor dem durch Titel, Orden oder Summen", "tokens": ["Vor", "dem", "durch", "Ti\u00b7tel", ",", "Or\u00b7den", "o\u00b7der", "Sum\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.180": {"text": "Gedungnen Schreiber, Stadt und Land;", "tokens": ["Ge\u00b7dung\u00b7nen", "Schrei\u00b7ber", ",", "Stadt", "und", "Land", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.181": {"text": "Da wag' es, Freund, und trag die Fahne", "tokens": ["Da", "wag'", "es", ",", "Freund", ",", "und", "trag", "die", "Fah\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.182": {"text": "Der Wahrheit, wenn du sie verbrannt", "tokens": ["Der", "Wahr\u00b7heit", ",", "wenn", "du", "sie", "ver\u00b7brannt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.183": {"text": "Willst sehn, und gib, wie die ", "tokens": ["Willst", "sehn", ",", "und", "gib", ",", "wie", "die"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "KON", "VVIMP", "$,", "PWAV", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.184": {"text": "Selbst deinen Kopf in Henkers Hand.", "tokens": ["Selbst", "dei\u00b7nen", "Kopf", "in", "Hen\u00b7kers", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.185": {"text": "Nicht so bei uns! Denn wer in Franken", "tokens": ["Nicht", "so", "bei", "uns", "!", "Denn", "wer", "in", "Fran\u00b7ken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "PPER", "$.", "KON", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.186": {"text": "Nicht schw\u00e4rmen darf, der mag's in Preu\u00dfen thun.", "tokens": ["Nicht", "schw\u00e4r\u00b7men", "darf", ",", "der", "mag's", "in", "Preu\u00b7\u00dfen", "thun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "$,", "PRELS", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.187": {"text": "Die Meinungen und die Gedanken", "tokens": ["Die", "Mei\u00b7nun\u00b7gen", "und", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.188": {"text": "L\u00e4\u00dft ", "tokens": ["L\u00e4\u00dft"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.189": {"text": "Denn, wie sein Beispiel selbst beweist,", "tokens": ["Denn", ",", "wie", "sein", "Bei\u00b7spiel", "selbst", "be\u00b7weist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.190": {"text": "Des Denkers und des Forschers Geist", "tokens": ["Des", "Den\u00b7kers", "und", "des", "For\u00b7schers", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.191": {"text": "Kennt, gleich der Ewigkeit, nicht Stillstand und nicht Schranken.", "tokens": ["Kennt", ",", "gleich", "der", "E\u00b7wig\u00b7keit", ",", "nicht", "Still\u00b7stand", "und", "nicht", "Schran\u00b7ken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ART", "NN", "$,", "PTKNEG", "NN", "KON", "PTKNEG", "NN", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.192": {"text": "Auf ferner denn zum allgemeinen Krieg'", "tokens": ["Auf", "fer\u00b7ner", "denn", "zum", "all\u00b7ge\u00b7mei\u00b7nen", "Krieg'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.193": {"text": "Um Wahrheit! nicht um Gold, um Titel und um B\u00e4nder!", "tokens": ["Um", "Wahr\u00b7heit", "!", "nicht", "um", "Gold", ",", "um", "Ti\u00b7tel", "und", "um", "B\u00e4n\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$.", "PTKNEG", "APPR", "NN", "$,", "KOUI", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Wir haben keine Jahrgeldspender,", "tokens": ["Wir", "ha\u00b7ben", "kei\u00b7ne", "Jahr\u00b7geld\u00b7spen\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.195": {"text": "Doch unser war am \u00f6ftersten der Sieg!", "tokens": ["Doch", "un\u00b7ser", "war", "am", "\u00f6f\u00b7ters\u00b7ten", "der", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VAFIN", "APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Auch du, mein Freund, klagst unsre Gro\u00dfen an,", "tokens": ["Auch", "du", ",", "mein", "Freund", ",", "klagst", "uns\u00b7re", "Gro\u00b7\u00dfen", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$,", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df sie so kalt f\u00fcr Deutschlands K\u00fcnste bleiben?", "tokens": ["Da\u00df", "sie", "so", "kalt", "f\u00fcr", "Deutschlands", "K\u00fcns\u00b7te", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Nun, immerhin! denn was liegt mir daran?", "tokens": ["Nun", ",", "im\u00b7mer\u00b7hin", "!", "denn", "was", "liegt", "mir", "da\u00b7ran", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "KON", "PWS", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich werde nie f\u00fcr unsre Gro\u00dfen schreiben.", "tokens": ["Ich", "wer\u00b7de", "nie", "f\u00fcr", "uns\u00b7re", "Gro\u00b7\u00dfen", "schrei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Doch, da\u00df f\u00fcr uns ihr Kaltsinn Ungl\u00fcck sey,", "tokens": ["Doch", ",", "da\u00df", "f\u00fcr", "uns", "ihr", "Kal\u00b7tsinn", "Un\u00b7gl\u00fcck", "sey", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "APPR", "PPER", "PPOSAT", "NN", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Davon wirst du mich schwerlich \u00fcberzeugen.", "tokens": ["Da\u00b7von", "wirst", "du", "mich", "schwer\u00b7lich", "\u00fc\u00b7berz\u00b7eu\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Hier mach' ich wider dich Parthei,", "tokens": ["Hier", "mach'", "ich", "wi\u00b7der", "dich", "Part\u00b7hei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich m\u00fc\u00dfte sonst an meiner Zweifelei", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "sonst", "an", "mei\u00b7ner", "Zwei\u00b7fe\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Mit Hiob bersten, sollt' ich schweigen.", "tokens": ["Mit", "Hiob", "bers\u00b7ten", ",", "sollt'", "ich", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Du tr\u00e4umtest da gar einen sch\u00f6nen Traum!", "tokens": ["Du", "tr\u00e4um\u00b7test", "da", "gar", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Traum", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Entschlie\u00dfen konnt' ich erst mich kaum,", "tokens": ["Ent\u00b7schlie\u00b7\u00dfen", "konnt'", "ich", "erst", "mich", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "ADV", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die rosenfarbnen Bilder zu zerstreuen;", "tokens": ["Die", "ro\u00b7sen\u00b7farb\u00b7nen", "Bil\u00b7der", "zu", "zer\u00b7streu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Doch, bist du wach, und du befindest dich", "tokens": ["Doch", ",", "bist", "du", "wach", ",", "und", "du", "be\u00b7fin\u00b7dest", "dich"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "VAFIN", "PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Nur halb so wohl dabei, als ich,", "tokens": ["Nur", "halb", "so", "wohl", "da\u00b7bei", ",", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "ADV", "PAV", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So wirst du sicher mir verzeihen.", "tokens": ["So", "wirst", "du", "si\u00b7cher", "mir", "ver\u00b7zei\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "La\u00df alles das die Gro\u00dfen wirklich thun,", "tokens": ["La\u00df", "al\u00b7les", "das", "die", "Gro\u00b7\u00dfen", "wirk\u00b7lich", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "ART", "ART", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Was sie in deinem Traume thaten;", "tokens": ["Was", "sie", "in", "dei\u00b7nem", "Trau\u00b7me", "tha\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Dann hat ein jeder Weiser zwar ein Huhn", "tokens": ["Dann", "hat", "ein", "je\u00b7der", "Wei\u00b7ser", "zwar", "ein", "Huhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "PIAT", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "In seinem Topf', der itzt zu kochen und zu braten", "tokens": ["In", "sei\u00b7nem", "Topf'", ",", "der", "itzt", "zu", "ko\u00b7chen", "und", "zu", "bra\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Oft kaum ein Ey im Hause hat:", "tokens": ["Oft", "kaum", "ein", "Ey", "im", "Hau\u00b7se", "hat", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Doch ach! nun schrein in allen Staaten", "tokens": ["Doch", "ach", "!", "nun", "schrein", "in", "al\u00b7len", "Staa\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "XY", "$.", "ADV", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Auch alle Schmierer: Macht uns satt!", "tokens": ["Auch", "al\u00b7le", "Schmie\u00b7rer", ":", "Macht", "uns", "satt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "NN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Des Schreibens ist schon itzt kein Ende,", "tokens": ["Des", "Schrei\u00b7bens", "ist", "schon", "itzt", "kein", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "Und doch: wie wenig w\u00e4chst den Lesern der Verstand!", "tokens": ["Und", "doch", ":", "wie", "we\u00b7nig", "w\u00e4chst", "den", "Le\u00b7sern", "der", "Ver\u00b7stand", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWAV", "PIS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Das macht, es schreiben, Freund! schon itzt ", "tokens": ["Das", "macht", ",", "es", "schrei\u00b7ben", ",", "Freund", "!", "schon", "itzt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PPER", "VVINF", "$,", "NN", "$.", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Erstaune nicht, und frag' mich nicht warum?", "tokens": ["Er\u00b7stau\u00b7ne", "nicht", ",", "und", "frag'", "mich", "nicht", "wa\u00b7rum", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "KON", "VVIMP", "PPER", "PTKNEG", "PWAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "F\u00e4llt der Geschmack von unserm Publikum", "tokens": ["F\u00e4llt", "der", "Ge\u00b7schmack", "von", "un\u00b7serm", "Pub\u00b7li\u00b7kum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.28": {"text": "Mitunter nicht auf Spinnen, Kr\u00f6ten, Aeser?", "tokens": ["Mi\u00b7tun\u00b7ter", "nicht", "auf", "Spin\u00b7nen", ",", "Kr\u00f6\u00b7ten", ",", "A\u00b7e\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "PTKNEG", "APPR", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.29": {"text": "Wie f\u00e4nde sonst, es sey auch noch so dumm,", "tokens": ["Wie", "f\u00e4n\u00b7de", "sonst", ",", "es", "sey", "auch", "noch", "so", "dumm", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Ein jedes Werklein seine Leser?", "tokens": ["Ein", "je\u00b7des", "Wer\u00b7klein", "sei\u00b7ne", "Le\u00b7ser", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.31": {"text": "Trotz allen Schreibern aller Erden,", "tokens": ["Trotz", "al\u00b7len", "Schrei\u00b7bern", "al\u00b7ler", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Wird doch das Publikum nicht klug,", "tokens": ["Wird", "doch", "das", "Pub\u00b7li\u00b7kum", "nicht", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Bis alle Buchh\u00e4ndler zu edlen Weisen werden:", "tokens": ["Bis", "al\u00b7le", "Buch\u00b7h\u00e4nd\u00b7ler", "zu", "ed\u00b7len", "Wei\u00b7sen", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Nicht wahr, nun hast du schon genug?", "tokens": ["Nicht", "wahr", ",", "nun", "hast", "du", "schon", "ge\u00b7nug", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADV", "VAFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Wir lesen alle mit einander,", "tokens": ["Wir", "le\u00b7sen", "al\u00b7le", "mit", "ein\u00b7an\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PRF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.36": {"text": "Allein das wie? und was? bek\u00fcmmert etwa drei", "tokens": ["Al\u00b7lein", "das", "wie", "?", "und", "was", "?", "be\u00b7k\u00fcm\u00b7mert", "et\u00b7wa", "drei"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "PWAV", "$.", "KON", "PWS", "$.", "VVFIN", "ADV", "CARD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Von Tausenden. Was wagt nun Mops dabei,", "tokens": ["Von", "Tau\u00b7sen\u00b7den", ".", "Was", "wagt", "nun", "Mops", "da\u00b7bei", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "PWS", "VVFIN", "ADV", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Druckt er die Reime von Talander?", "tokens": ["Druckt", "er", "die", "Rei\u00b7me", "von", "Ta\u00b7lan\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.39": {"text": "Verlieren kann er nichts, weil jeder Thor", "tokens": ["Ver\u00b7lie\u00b7ren", "kann", "er", "nichts", ",", "weil", "je\u00b7der", "Thor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VMFIN", "PPER", "PIS", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.40": {"text": "Gewi\u00df dreihundert K\u00e4ufer findet,", "tokens": ["Ge\u00b7wi\u00df", "drei\u00b7hun\u00b7dert", "K\u00e4u\u00b7fer", "fin\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Gewinnen aber leicht, da itzt noch, wie zuvor,", "tokens": ["Ge\u00b7win\u00b7nen", "a\u00b7ber", "leicht", ",", "da", "itzt", "noch", ",", "wie", "zu\u00b7vor", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "$,", "KOUS", "ADV", "ADV", "$,", "PWAV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Aus allen Laden schnell die ", "tokens": ["Aus", "al\u00b7len", "La\u00b7den", "schnell", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADJD", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.43": {"text": "Mag die Kritik sich heiser schrein,", "tokens": ["Mag", "die", "Kri\u00b7tik", "sich", "hei\u00b7ser", "schrein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PRF", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Sie wird die Zahl der Schmierer nicht vermindern.", "tokens": ["Sie", "wird", "die", "Zahl", "der", "Schmie\u00b7rer", "nicht", "ver\u00b7min\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Das Publikum will unterhalten seyn,", "tokens": ["Das", "Pub\u00b7li\u00b7kum", "will", "un\u00b7ter\u00b7hal\u00b7ten", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.46": {"text": "Und die\u00df besteht fast blo\u00df aus alten Kindern.", "tokens": ["Und", "die\u00df", "be\u00b7steht", "fast", "blo\u00df", "aus", "al\u00b7ten", "Kin\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.47": {"text": "Ist's nun so leicht, durch N\u00fcrenberger Tand", "tokens": ["Ist's", "nun", "so", "leicht", ",", "durch", "N\u00fc\u00b7ren\u00b7ber\u00b7ger", "Tand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Den Kindern ihre Zeit vertreiben,", "tokens": ["Den", "Kin\u00b7dern", "ih\u00b7re", "Zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Wie leicht l\u00e4\u00dft dann nicht der Verstand", "tokens": ["Wie", "leicht", "l\u00e4\u00dft", "dann", "nicht", "der", "Ver\u00b7stand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "ADV", "PTKNEG", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.50": {"text": "Durch Klang der Louisdor in des Verlegers Hand,", "tokens": ["Durch", "Klang", "der", "Lou\u00b7is\u00b7dor", "in", "des", "Ver\u00b7le\u00b7gers", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NE", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Ja selbst die Furcht vor Schande, sich bet\u00e4uben.", "tokens": ["Ja", "selbst", "die", "Furcht", "vor", "Schan\u00b7de", ",", "sich", "be\u00b7t\u00e4u\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "ART", "NN", "APPR", "NN", "$,", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Aus neun und neunzigen das hundertste zu schreiben:", "tokens": ["Aus", "neun", "und", "neun\u00b7zi\u00b7gen", "das", "hun\u00b7derts\u00b7te", "zu", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "KON", "ADJA", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.53": {"text": "Das ist die wahre B\u00fcchermacher-Kunst!", "tokens": ["Das", "ist", "die", "wah\u00b7re", "B\u00fc\u00b7cher\u00b7ma\u00b7cher\u00b7Kunst", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Wo w\u00fcrden sonst von Hundert wohl \u2013 mit Gunst!", "tokens": ["Wo", "w\u00fcr\u00b7den", "sonst", "von", "Hun\u00b7dert", "wohl", "\u2013", "mit", "Gunst", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ADV", "APPR", "NE", "ADV", "$(", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.55": {"text": "Ihr B\u00fcchermacher! \u2013 neun und neunzig bleiben?", "tokens": ["Ihr", "B\u00fc\u00b7cher\u00b7ma\u00b7cher", "!", "\u2013", "neun", "und", "neun\u00b7zig", "blei\u00b7ben", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "$(", "CARD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.56": {"text": "Freund! wenn du kannst, so schlie\u00dfe du", "tokens": ["Freund", "!", "wenn", "du", "kannst", ",", "so", "schlie\u00b7\u00dfe", "du"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "KOUS", "PPER", "VMFIN", "$,", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.57": {"text": "Noch heute, allen Klugen, allen Dummen,", "tokens": ["Noch", "heu\u00b7te", ",", "al\u00b7len", "Klu\u00b7gen", ",", "al\u00b7len", "Dum\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.58": {"text": "Die B\u00fcchers\u00e4l' auf deiner ", "tokens": ["Die", "B\u00fc\u00b7cher\u00b7s\u00e4l'", "auf", "dei\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.59": {"text": "Wie werden dann in einem Nu", "tokens": ["Wie", "wer\u00b7den", "dann", "in", "ei\u00b7nem", "Nu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ADV", "APPR", "ART", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Ein Schock Autoren schier verstummen;", "tokens": ["Ein", "Schock", "Au\u00b7to\u00b7ren", "schier", "ver\u00b7stum\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.61": {"text": "Indessen, wie einst Salomo,", "tokens": ["In\u00b7des\u00b7sen", ",", "wie", "einst", "Sa\u00b7lo\u00b7mo", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ADV", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "Ein W** sich, durch sich, noch Weisheit wird erwerben.", "tokens": ["Ein", "W", "*", "*", "sich", ",", "durch", "sich", ",", "noch", "Weis\u00b7heit", "wird", "er\u00b7wer\u00b7ben", "."], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "XY", "XY", "XY", "PRF", "$,", "APPR", "PRF", "$,", "ADV", "NN", "VAFIN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.63": {"text": "Studirte jener itzt noch so,", "tokens": ["Stu\u00b7dir\u00b7te", "je\u00b7ner", "itzt", "noch", "so", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "F\u00fcr Lohn, so m\u00fc\u00dfte Salomo", "tokens": ["F\u00fcr", "Lohn", ",", "so", "m\u00fc\u00df\u00b7te", "Sa\u00b7lo\u00b7mo"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "ADV", "VMFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Nun freilich wohl f\u00fcr Hunger sterben.", "tokens": ["Nun", "frei\u00b7lich", "wohl", "f\u00fcr", "Hun\u00b7ger", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.66": {"text": "Doch auch nur leben sollte man,", "tokens": ["Doch", "auch", "nur", "le\u00b7ben", "soll\u00b7te", "man", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VVINF", "VMFIN", "PIS", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Um zu studiren; nicht studiren,", "tokens": ["Um", "zu", "stu\u00b7di\u00b7ren", ";", "nicht", "stu\u00b7di\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "PTKZU", "VVINF", "$.", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Um nur zu leben. Denn was kann", "tokens": ["Um", "nur", "zu", "le\u00b7ben", ".", "Denn", "was", "kann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "ADV", "PTKZU", "VVINF", "$.", "KON", "PWS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Der arme Wicht f\u00fcr Zeit verlieren,", "tokens": ["Der", "ar\u00b7me", "Wicht", "f\u00fcr", "Zeit", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.70": {"text": "Der mit dem Abend' kaum sein Tagelohn gewann?", "tokens": ["Der", "mit", "dem", "A\u00b7bend'", "kaum", "sein", "Ta\u00b7ge\u00b7lohn", "ge\u00b7wann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Gerade de\u00dfhalb, sagst du zwar,", "tokens": ["Ge\u00b7ra\u00b7de", "de\u00df\u00b7halb", ",", "sagst", "du", "zwar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.72": {"text": "M\u00fc\u00dft' ihm der F\u00fcrst ein Jahrgeld geben;", "tokens": ["M\u00fc\u00dft'", "ihm", "der", "F\u00fcrst", "ein", "Jahr\u00b7geld", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "Doch, lieber Freund, wenn erst, wie offenbar,", "tokens": ["Doch", ",", "lie\u00b7ber", "Freund", ",", "wenn", "erst", ",", "wie", "of\u00b7fen\u00b7bar", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "NN", "$,", "KOUS", "ADV", "$,", "PWAV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.74": {"text": "Vier tausend Schmierer mehr nach einem Jahrgeld' streben:", "tokens": ["Vier", "tau\u00b7send", "Schmie\u00b7rer", "mehr", "nach", "ei\u00b7nem", "Jahr\u00b7geld'", "stre\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Was wird am End' aus unserm Publikum?", "tokens": ["Was", "wird", "am", "End'", "aus", "un\u00b7serm", "Pub\u00b7li\u00b7kum", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.76": {"text": "Recht viel ist zwar daran nicht zu verderben,", "tokens": ["Recht", "viel", "ist", "zwar", "da\u00b7ran", "nicht", "zu", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "ADV", "PAV", "PTKNEG", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.77": {"text": "Doch lies't sich itzt ein Theil davon nur dumm,", "tokens": ["Doch", "lies't", "sich", "itzt", "ein", "Theil", "da\u00b7von", "nur", "dumm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ART", "NN", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.78": {"text": "Dann w\u00fcrde gar ein Theil vom Lesen sterben.", "tokens": ["Dann", "w\u00fcr\u00b7de", "gar", "ein", "Theil", "vom", "Le\u00b7sen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.79": {"text": "Wer Anlag' hat zu einem weisen Mann',", "tokens": ["Wer", "An\u00b7lag'", "hat", "zu", "ei\u00b7nem", "wei\u00b7sen", "Mann'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.80": {"text": "Wird leicht es ganz durch die Sokraten dann,", "tokens": ["Wird", "leicht", "es", "ganz", "durch", "die", "Sok\u00b7ra\u00b7ten", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.81": {"text": "Und f\u00fchlt er Hang zu einem Thoren,", "tokens": ["Und", "f\u00fchlt", "er", "Hang", "zu", "ei\u00b7nem", "Tho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.82": {"text": "So zerren die Sophisten dran,", "tokens": ["So", "zer\u00b7ren", "die", "So\u00b7phis\u00b7ten", "dran", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "Bis er den Wunsch nach Weisheit selbst verloren.", "tokens": ["Bis", "er", "den", "Wunsch", "nach", "Weis\u00b7heit", "selbst", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.84": {"text": "Wie wenig neigen, wenn der Bart", "tokens": ["Wie", "we\u00b7nig", "nei\u00b7gen", ",", "wenn", "der", "Bart"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "Beim J\u00fcngling' keimt, sich auf der Weisen Seite;", "tokens": ["Beim", "J\u00fcng\u00b7ling'", "keimt", ",", "sich", "auf", "der", "Wei\u00b7sen", "Sei\u00b7te", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.86": {"text": "Die \u00fcbrigen, (wie ihr genug erfahrt,)", "tokens": ["Die", "\u00fcb\u00b7ri\u00b7gen", ",", "(", "wie", "ihr", "ge\u00b7nug", "er\u00b7fahrt", ",", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "$,", "$(", "PWAV", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Sind ganz gewi\u00df der Schmierer Beute.", "tokens": ["Sind", "ganz", "ge\u00b7wi\u00df", "der", "Schmie\u00b7rer", "Beu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.88": {"text": "Wenn alle nur, die so sich stumpf", "tokens": ["Wenn", "al\u00b7le", "nur", ",", "die", "so", "sich", "stumpf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "ADV", "$,", "PRELS", "ADV", "PRF", "ADJD"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.89": {"text": "Am Geist' und Herzen lasen, einen Strumpf", "tokens": ["Am", "Geist'", "und", "Her\u00b7zen", "la\u00b7sen", ",", "ei\u00b7nen", "Strumpf"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "KON", "NN", "VVINF", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.90": {"text": "Inde\u00df gestrickt, ein Paar Manschetten", "tokens": ["In\u00b7de\u00df", "ge\u00b7strickt", ",", "ein", "Paar", "Man\u00b7schet\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VVPP", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.91": {"text": "Gen\u00e4het, oder den Verstand", "tokens": ["Ge\u00b7n\u00e4\u00b7het", ",", "o\u00b7der", "den", "Ver\u00b7stand"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.92": {"text": "Von einer Fabel nur erkl\u00e4rt dem Sohne h\u00e4tten:", "tokens": ["Von", "ei\u00b7ner", "Fa\u00b7bel", "nur", "er\u00b7kl\u00e4rt", "dem", "Soh\u00b7ne", "h\u00e4t\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Welch ein Gewinn f\u00fcrs Vaterland!", "tokens": ["Welch", "ein", "Ge\u00b7winn", "f\u00fcrs", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "Und h\u00e4tten die vier tausend Schmierer nur", "tokens": ["Und", "h\u00e4t\u00b7ten", "die", "vier", "tau\u00b7send", "Schmie\u00b7rer", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "CARD", "CARD", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Vom Acker Steine aufgelesen,", "tokens": ["Vom", "A\u00b7cker", "Stei\u00b7ne", "auf\u00b7ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.96": {"text": "Inde\u00df ein b\u00f6ser Geist in ihre Finger fuhr,", "tokens": ["In\u00b7de\u00df", "ein", "b\u00f6\u00b7ser", "Geist", "in", "ih\u00b7re", "Fin\u00b7ger", "fuhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "So w\u00e4r's doch etwas noch gewesen!", "tokens": ["So", "w\u00e4r's", "doch", "et\u00b7was", "noch", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Nimm alle die vier tausend leere K\u00f6pfe,", "tokens": ["Nimm", "al\u00b7le", "die", "vier", "tau\u00b7send", "lee\u00b7re", "K\u00f6p\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "ART", "CARD", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.99": {"text": "Ein Jahrgeld macht nicht einen guten draus;", "tokens": ["Ein", "Jahr\u00b7geld", "macht", "nicht", "ei\u00b7nen", "gu\u00b7ten", "draus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKNEG", "ART", "ADJA", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.100": {"text": "Denn Ewigkeit bek\u00fcmmert die Gesch\u00f6pfe", "tokens": ["Denn", "E\u00b7wig\u00b7keit", "be\u00b7k\u00fcm\u00b7mert", "die", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.101": {"text": "Nicht halb so sehr, als ein Verleger-Schmaus.", "tokens": ["Nicht", "halb", "so", "sehr", ",", "als", "ein", "Ver\u00b7le\u00b7ger\u00b7Schmaus", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "ADV", "ADV", "$,", "KOUS", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.102": {"text": "Der aber, Freund, in dem ein Funken gl\u00fchet,", "tokens": ["Der", "a\u00b7ber", ",", "Freund", ",", "in", "dem", "ein", "Fun\u00b7ken", "gl\u00fc\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.103": {"text": "L\u00f6scht ihn, sey er auch arm, durch keine Thr\u00e4nen aus.", "tokens": ["L\u00f6scht", "ihn", ",", "sey", "er", "auch", "arm", ",", "durch", "kei\u00b7ne", "Thr\u00e4\u00b7nen", "aus", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$,", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.104": {"text": "Er brennt, eh' sich's die karge Welt versiehet,", "tokens": ["Er", "brennt", ",", "eh'", "sich's", "die", "kar\u00b7ge", "Welt", "ver\u00b7sie\u00b7het", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.105": {"text": "Einst lichterloh aus ihm heraus.", "tokens": ["Einst", "lich\u00b7ter\u00b7loh", "aus", "ihm", "he\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.106": {"text": "Wer eine Ilias vielleicht gesungen h\u00e4tte,", "tokens": ["Wer", "ei\u00b7ne", "I\u00b7lias", "viel\u00b7leicht", "ge\u00b7sun\u00b7gen", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.107": {"text": "Singt freilich kaum noch dann und wann ein Lied,", "tokens": ["Singt", "frei\u00b7lich", "kaum", "noch", "dann", "und", "wann", "ein", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "ADV", "KON", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.108": {"text": "Wenn er an eine Sklavenkette", "tokens": ["Wenn", "er", "an", "ei\u00b7ne", "Skla\u00b7ven\u00b7ket\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.109": {"text": "Sich Tag und Nacht gefesselt sieht.", "tokens": ["Sich", "Tag", "und", "Nacht", "ge\u00b7fes\u00b7selt", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "KON", "NN", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.110": {"text": "Dann aber nehm' ein B\u00fcrger unsers Reiches", "tokens": ["Dann", "a\u00b7ber", "nehm'", "ein", "B\u00fcr\u00b7ger", "un\u00b7sers", "Rei\u00b7ches"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.111": {"text": "Die Kett' ihm ab, und sey sein Freund durch That,", "tokens": ["Die", "Kett'", "ihm", "ab", ",", "und", "sey", "sein", "Freund", "durch", "That", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "PTKVZ", "$,", "KON", "VAFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.112": {"text": "Und thu' zuerst im deutschen Reich' ein gleiches,", "tokens": ["Und", "thu'", "zu\u00b7erst", "im", "deut\u00b7schen", "Reich'", "ein", "glei\u00b7ches", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "ADJA", "NN", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.113": {"text": "Als oft Brittanien schon that.", "tokens": ["Als", "oft", "Brit\u00b7ta\u00b7ni\u00b7en", "schon", "that", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "Kein Gro\u00dfer l\u00f6se sie; denn die Trompeten", "tokens": ["Kein", "Gro\u00b7\u00dfer", "l\u00f6\u00b7se", "sie", ";", "denn", "die", "Trom\u00b7pe\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "$.", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.115": {"text": "Der Fama, sagen sonst ein wahres Ungl\u00fcck an.", "tokens": ["Der", "Fa\u00b7ma", ",", "sa\u00b7gen", "sonst", "ein", "wah\u00b7res", "Un\u00b7gl\u00fcck", "an", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Zur Klippe wird ein Jahrgehalt, woran", "tokens": ["Zur", "Klip\u00b7pe", "wird", "ein", "Jahr\u00b7ge\u00b7halt", ",", "wo\u00b7ran"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,", "PWAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.117": {"text": "Das Gl\u00fcck von hundert ampelnden Poeten", "tokens": ["Das", "Gl\u00fcck", "von", "hun\u00b7dert", "am\u00b7peln\u00b7den", "Po\u00b7et\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.118": {"text": "Zerscheitert.", "tokens": ["Zer\u00b7schei\u00b7tert", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.119": {"text": "\u00bbnun, so la\u00df sie scheitern, Freund!", "tokens": ["\u00bb", "nun", ",", "so", "la\u00df", "sie", "schei\u00b7tern", ",", "Freund", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADV", "$,", "ADV", "VVIMP", "PPER", "VVINF", "$,", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.120": {"text": "Soll wohl ein Staat, so n\u00fctzlich ihm es scheint,", "tokens": ["Soll", "wohl", "ein", "Staat", ",", "so", "n\u00fctz\u00b7lich", "ihm", "es", "scheint", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "$,", "ADV", "ADJD", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.121": {"text": "Schon darum keinen Preis aus seinen Sch\u00e4tzen", "tokens": ["Schon", "da\u00b7rum", "kei\u00b7nen", "Preis", "aus", "sei\u00b7nen", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.122": {"text": "Auf eine neue Durchfahrt setzen,", "tokens": ["Auf", "ei\u00b7ne", "neu\u00b7e", "Durch\u00b7fahrt", "set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.123": {"text": "Weil manches Schiff dar\u00fcber sinken kann?", "tokens": ["Weil", "man\u00b7ches", "Schiff", "da\u00b7r\u00fc\u00b7ber", "sin\u00b7ken", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PAV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.124": {"text": "Von allen menschlichen Gesetzen", "tokens": ["Von", "al\u00b7len", "menschli\u00b7chen", "Ge\u00b7set\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.125": {"text": "Steht ja das Wohl des Staates obenan!\u00ab", "tokens": ["Steht", "ja", "das", "Wohl", "des", "Staa\u00b7tes", "o\u00b7be\u00b7nan", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.126": {"text": "Du nimmst das Wort mir aus dem Munde;", "tokens": ["Du", "nimmst", "das", "Wort", "mir", "aus", "dem", "Mun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.127": {"text": "Denn grade die\u00df hielt ich zur Antwort schon", "tokens": ["Denn", "gra\u00b7de", "die\u00df", "hielt", "ich", "zur", "Ant\u00b7wort", "schon"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PDS", "VVFIN", "PPER", "APPRART", "NN", "ADV"], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.128": {"text": "F\u00fcr dich bereit. Ich wei\u00df es, denn die Kunde", "tokens": ["F\u00fcr", "dich", "be\u00b7reit", ".", "Ich", "wei\u00df", "es", ",", "denn", "die", "Kun\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPER", "ADJD", "$.", "PPER", "VVFIN", "PPER", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.129": {"text": "Der Vorzeit lehrt es: da\u00df f\u00fcr Thron", "tokens": ["Der", "Vor\u00b7zeit", "lehrt", "es", ":", "da\u00df", "f\u00fcr", "Thron"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.130": {"text": "Und H\u00fctte, Welt und Nachwelt, keiner,", "tokens": ["Und", "H\u00fct\u00b7te", ",", "Welt", "und", "Nach\u00b7welt", ",", "kei\u00b7ner", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "$,", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.131": {"text": "Der auf dem Thron' nicht sitzt, so segnend werden kann,", "tokens": ["Der", "auf", "dem", "Thron'", "nicht", "sitzt", ",", "so", "seg\u00b7nend", "wer\u00b7den", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "PTKNEG", "VVFIN", "$,", "ADV", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Als der erhabnen Weisen Einer,", "tokens": ["Als", "der", "er\u00b7hab\u00b7nen", "Wei\u00b7sen", "Ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.133": {"text": "Der sich das Herz des Volks gewann.", "tokens": ["Der", "sich", "das", "Herz", "des", "Volks", "ge\u00b7wann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Wenn f\u00fcr Germanien, in jedem Fach'", "tokens": ["Wenn", "f\u00fcr", "Ger\u00b7ma\u00b7ni\u00b7en", ",", "in", "je\u00b7dem", "Fach'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "APPR", "NE", "$,", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.135": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.136": {"text": "Der F\u00fcrsten und der B\u00fcrger, nach und nach", "tokens": ["Der", "F\u00fcrs\u00b7ten", "und", "der", "B\u00fcr\u00b7ger", ",", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "APPR", "KON", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.137": {"text": "Der Dunse Schmiererein verschw\u00e4nden:", "tokens": ["Der", "Dun\u00b7se", "Schmie\u00b7rer\u00b7ein", "ver\u00b7schw\u00e4n\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.138": {"text": "Dann w\u00fcrde, Freund, das Gl\u00fcck des Publikum,", "tokens": ["Dann", "w\u00fcr\u00b7de", ",", "Freund", ",", "das", "Gl\u00fcck", "des", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "$,", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.139": {"text": "(itzt kaum ein Baum mit Bl\u00e4ttervollen Zweigen)", "tokens": ["(", "itzt", "kaum", "ein", "Baum", "mit", "Bl\u00e4t\u00b7ter\u00b7vol\u00b7len", "Zwei\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "APPR", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.140": {"text": "Mehr Fr\u00fccht' in einem Jahre zeigen,", "tokens": ["Mehr", "Fr\u00fccht'", "in", "ei\u00b7nem", "Jah\u00b7re", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.141": {"text": "Als itzt in einem Sekulum.", "tokens": ["Als", "itzt", "in", "ei\u00b7nem", "Se\u00b7ku\u00b7lum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.142": {"text": "Was itzt ein Denker baut, das rei\u00dft ein Schmierer ein;", "tokens": ["Was", "itzt", "ein", "Den\u00b7ker", "baut", ",", "das", "rei\u00dft", "ein", "Schmie\u00b7rer", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "Das letzte Wort wird auch dem Narrn das wahrste seyn,", "tokens": ["Das", "letz\u00b7te", "Wort", "wird", "auch", "dem", "Narrn", "das", "wahrs\u00b7te", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "ART", "ADJA", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Und dieses mag der Schmierer leicht behalten.", "tokens": ["Und", "die\u00b7ses", "mag", "der", "Schmie\u00b7rer", "leicht", "be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.145": {"text": "Das wahre Publikum, das Publikum der Alten,", "tokens": ["Das", "wah\u00b7re", "Pub\u00b7li\u00b7kum", ",", "das", "Pub\u00b7li\u00b7kum", "der", "Al\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Der unsichtbaren Kirche gleich,", "tokens": ["Der", "un\u00b7sicht\u00b7ba\u00b7ren", "Kir\u00b7che", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.147": {"text": "Hat keine Macht; zerstreut durchs ganze Reich,", "tokens": ["Hat", "kei\u00b7ne", "Macht", ";", "zer\u00b7streut", "durchs", "gan\u00b7ze", "Reich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$.", "VVPP", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.148": {"text": "Triffst du vielleicht auf ganze Meilen", "tokens": ["Triffst", "du", "viel\u00b7leicht", "auf", "gan\u00b7ze", "Mei\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.149": {"text": "Kein Mitglied dieses H\u00e4ufchens an,", "tokens": ["Kein", "Mit\u00b7glied", "die\u00b7ses", "H\u00e4uf\u00b7chens", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PDAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.150": {"text": "Dein volles Herz mit ihm zu theilen.", "tokens": ["Dein", "vol\u00b7les", "Herz", "mit", "ihm", "zu", "thei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.151": {"text": "Doch immer besser, Freund! als da\u00df die Kircheneulen", "tokens": ["Doch", "im\u00b7mer", "bes\u00b7ser", ",", "Freund", "!", "als", "da\u00df", "die", "Kir\u00b7che\u00b7neu\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "$,", "NN", "$.", "KOKOM", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.152": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.153": {"text": "Als da\u00df ein ", "tokens": ["Als", "da\u00df", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOUS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.154": {"text": "Inde\u00df es Kl\u00fcgern oft durchs Dach ins St\u00fcbchen schneit;", "tokens": ["In\u00b7de\u00df", "es", "Kl\u00fc\u00b7gern", "oft", "durchs", "Dach", "ins", "St\u00fcb\u00b7chen", "schneit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "APPRART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.155": {"text": "Als da\u00df ein ", "tokens": ["Als", "da\u00df", "ein"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "KOUS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.156": {"text": "Nach der ", "tokens": ["Nach", "der"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.157": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.158": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.159": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.160": {"text": "Inde\u00df er selbst, f\u00fcr Gold, der Eitelkeit", "tokens": ["In\u00b7de\u00df", "er", "selbst", ",", "f\u00fcr", "Gold", ",", "der", "Ei\u00b7tel\u00b7keit"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "$,", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.161": {"text": "Mit vollen H\u00e4nden Weihrauch streut.", "tokens": ["Mit", "vol\u00b7len", "H\u00e4n\u00b7den", "Weih\u00b7rauch", "streut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "In Frankreich suchte sonst der Schmeichler und der Duns", "tokens": ["In", "Fran\u00b7kreich", "such\u00b7te", "sonst", "der", "Schmeich\u00b7ler", "und", "der", "Duns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Nur Goldsand in der Hippokrene;", "tokens": ["Nur", "Gold\u00b7sand", "in", "der", "Hip\u00b7po\u00b7kre\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.164": {"text": "Wir hatten nie Auguste und M\u00e4cene,", "tokens": ["Wir", "hat\u00b7ten", "nie", "Au\u00b7gus\u00b7te", "und", "M\u00e4\u00b7ce\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.165": {"text": "Das was wir sind, sind wir allein durch uns.", "tokens": ["Das", "was", "wir", "sind", ",", "sind", "wir", "al\u00b7lein", "durch", "uns", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRELS", "PPER", "VAFIN", "$,", "VAFIN", "PPER", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.166": {"text": "Ein wahres Gl\u00fcck! denn es ist mit der Kunst", "tokens": ["Ein", "wah\u00b7res", "Gl\u00fcck", "!", "denn", "es", "ist", "mit", "der", "Kunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KON", "PPER", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.167": {"text": "Wie mit der Tugend; wer nicht beide", "tokens": ["Wie", "mit", "der", "Tu\u00b7gend", ";", "wer", "nicht", "bei\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "$.", "PWS", "PTKNEG", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.168": {"text": "Um ihrer willen liebt, nur liebt um F\u00fcrstengunst,", "tokens": ["Um", "ih\u00b7rer", "wil\u00b7len", "liebt", ",", "nur", "liebt", "um", "F\u00fcrs\u00b7ten\u00b7gunst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "$,", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "Der f\u00fchlt ihr Aeu\u00dfres nur, nicht ihre innre Freude.", "tokens": ["Der", "f\u00fchlt", "ihr", "A\u00b7e\u00b7u\u00df\u00b7res", "nur", ",", "nicht", "ih\u00b7re", "inn\u00b7re", "Freu\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ADV", "$,", "PTKNEG", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.170": {"text": "Ein wahres Gl\u00fcck! Weil das, was tief vergraben", "tokens": ["Ein", "wah\u00b7res", "Gl\u00fcck", "!", "Weil", "das", ",", "was", "tief", "ver\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KOUS", "PDS", "$,", "PRELS", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.171": {"text": "Im Schutte der Barbaren lag,", "tokens": ["Im", "Schut\u00b7te", "der", "Bar\u00b7ba\u00b7ren", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.172": {"text": "Der Menschheit \u00e4ltesten Vertrag,", "tokens": ["Der", "Menschheit", "\u00e4l\u00b7tes\u00b7ten", "Ver\u00b7trag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.173": {"text": "Wir dadurch blo\u00df, hervorgezogen haben.", "tokens": ["Wir", "da\u00b7durch", "blo\u00df", ",", "her\u00b7vor\u00b7ge\u00b7zo\u00b7gen", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "PAV", "ADV", "$,", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.174": {"text": "Wo, wie in Gallien, Verdienst nur Einen Richter,", "tokens": ["Wo", ",", "wie", "in", "Gal\u00b7li\u00b7en", ",", "Ver\u00b7dienst", "nur", "Ei\u00b7nen", "Rich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "PWAV", "APPR", "NE", "$,", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Und diesen oft zum Feind' die Wahrheit hat,", "tokens": ["Und", "die\u00b7sen", "oft", "zum", "Feind'", "die", "Wahr\u00b7heit", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "APPRART", "NN", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.176": {"text": "Da schleppt man selbst den Lieblingsdichter", "tokens": ["Da", "schleppt", "man", "selbst", "den", "Lieb\u00b7lings\u00b7dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.177": {"text": "Um ein, gelesnes nur, nicht selbst geschriebnes Blatt", "tokens": ["Um", "ein", ",", "ge\u00b7les\u00b7nes", "nur", ",", "nicht", "selbst", "ge\u00b7schrieb\u00b7nes", "Blatt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUI", "PTKVZ", "$,", "ADJA", "ADV", "$,", "PTKNEG", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "In die Bastille", "tokens": ["In", "die", "Bas\u00b7til\u00b7le"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.179": {"text": "Vor dem durch Titel, Orden oder Summen", "tokens": ["Vor", "dem", "durch", "Ti\u00b7tel", ",", "Or\u00b7den", "o\u00b7der", "Sum\u00b7men"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.180": {"text": "Gedungnen Schreiber, Stadt und Land;", "tokens": ["Ge\u00b7dung\u00b7nen", "Schrei\u00b7ber", ",", "Stadt", "und", "Land", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.181": {"text": "Da wag' es, Freund, und trag die Fahne", "tokens": ["Da", "wag'", "es", ",", "Freund", ",", "und", "trag", "die", "Fah\u00b7ne"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NN", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.182": {"text": "Der Wahrheit, wenn du sie verbrannt", "tokens": ["Der", "Wahr\u00b7heit", ",", "wenn", "du", "sie", "ver\u00b7brannt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.183": {"text": "Willst sehn, und gib, wie die ", "tokens": ["Willst", "sehn", ",", "und", "gib", ",", "wie", "die"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "KON", "VVIMP", "$,", "PWAV", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.184": {"text": "Selbst deinen Kopf in Henkers Hand.", "tokens": ["Selbst", "dei\u00b7nen", "Kopf", "in", "Hen\u00b7kers", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPR", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.185": {"text": "Nicht so bei uns! Denn wer in Franken", "tokens": ["Nicht", "so", "bei", "uns", "!", "Denn", "wer", "in", "Fran\u00b7ken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "APPR", "PPER", "$.", "KON", "PWS", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.186": {"text": "Nicht schw\u00e4rmen darf, der mag's in Preu\u00dfen thun.", "tokens": ["Nicht", "schw\u00e4r\u00b7men", "darf", ",", "der", "mag's", "in", "Preu\u00b7\u00dfen", "thun", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "$,", "PRELS", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.187": {"text": "Die Meinungen und die Gedanken", "tokens": ["Die", "Mei\u00b7nun\u00b7gen", "und", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.188": {"text": "L\u00e4\u00dft ", "tokens": ["L\u00e4\u00dft"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.189": {"text": "Denn, wie sein Beispiel selbst beweist,", "tokens": ["Denn", ",", "wie", "sein", "Bei\u00b7spiel", "selbst", "be\u00b7weist", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.190": {"text": "Des Denkers und des Forschers Geist", "tokens": ["Des", "Den\u00b7kers", "und", "des", "For\u00b7schers", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.191": {"text": "Kennt, gleich der Ewigkeit, nicht Stillstand und nicht Schranken.", "tokens": ["Kennt", ",", "gleich", "der", "E\u00b7wig\u00b7keit", ",", "nicht", "Still\u00b7stand", "und", "nicht", "Schran\u00b7ken", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "ART", "NN", "$,", "PTKNEG", "NN", "KON", "PTKNEG", "NN", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.192": {"text": "Auf ferner denn zum allgemeinen Krieg'", "tokens": ["Auf", "fer\u00b7ner", "denn", "zum", "all\u00b7ge\u00b7mei\u00b7nen", "Krieg'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.193": {"text": "Um Wahrheit! nicht um Gold, um Titel und um B\u00e4nder!", "tokens": ["Um", "Wahr\u00b7heit", "!", "nicht", "um", "Gold", ",", "um", "Ti\u00b7tel", "und", "um", "B\u00e4n\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$.", "PTKNEG", "APPR", "NN", "$,", "KOUI", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Wir haben keine Jahrgeldspender,", "tokens": ["Wir", "ha\u00b7ben", "kei\u00b7ne", "Jahr\u00b7geld\u00b7spen\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.195": {"text": "Doch unser war am \u00f6ftersten der Sieg!", "tokens": ["Doch", "un\u00b7ser", "war", "am", "\u00f6f\u00b7ters\u00b7ten", "der", "Sieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VAFIN", "APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}