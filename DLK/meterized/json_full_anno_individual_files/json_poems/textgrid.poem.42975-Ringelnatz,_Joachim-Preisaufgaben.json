{"textgrid.poem.42975": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Preisaufgaben", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Es ki mo no to ne", "tokens": ["Das", "Es", "ki", "mo", "no", "to", "ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "FM", "FM", "FM", "FM", "FM"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Besteht aus f\u00fcnfmal Wort.", "tokens": ["Be\u00b7steht", "aus", "f\u00fcnf\u00b7mal", "Wort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und eine Kaffeebohne", "tokens": ["Und", "ei\u00b7ne", "Kaf\u00b7fee\u00b7boh\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Treibt niemals Pferdesport.", "tokens": ["Treibt", "nie\u00b7mals", "Pfer\u00b7des\u00b7port", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Man soll nicht Pferde reizen.", "tokens": ["Man", "soll", "nicht", "Pfer\u00b7de", "rei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Pferd ist keine Kuh.", "tokens": ["Ein", "Pferd", "ist", "kei\u00b7ne", "Kuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Aale Beine spreizen,", "tokens": ["Wenn", "Aa\u00b7le", "Bei\u00b7ne", "sprei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sieht niemals jemand zu.", "tokens": ["Sieht", "nie\u00b7mals", "je\u00b7mand", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Je mand ar in der br\u00fcs te,", "tokens": ["Je", "mand", "ar", "in", "der", "br\u00fcs", "te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Recht sauber eingeh\u00fcllt,", "tokens": ["Recht", "sau\u00b7ber", "ein\u00b7ge\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erregen oft Gel\u00fcste,", "tokens": ["Er\u00b7re\u00b7gen", "oft", "Ge\u00b7l\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die manches gern erf\u00fcllt.", "tokens": ["Die", "man\u00b7ches", "gern", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Man ches ter ho sen il es \u2013,", "tokens": ["Man", "ches", "ter", "ho", "sen", "il", "es", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "FM", "FM", "FM", "FM", "FM", "PPER", "$(", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Geht vieles stumpf einher.", "tokens": ["Geht", "vie\u00b7les", "stumpf", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Quatsch gibt den Dummen vieles,", "tokens": ["Quatsch", "gibt", "den", "Dum\u00b7men", "vie\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gibt Klugen manchmal mehr.", "tokens": ["Gibt", "Klu\u00b7gen", "manch\u00b7mal", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Das Es ki mo no to ne", "tokens": ["Das", "Es", "ki", "mo", "no", "to", "ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPER", "FM", "FM", "FM", "FM", "FM"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Besteht aus f\u00fcnfmal Wort.", "tokens": ["Be\u00b7steht", "aus", "f\u00fcnf\u00b7mal", "Wort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und eine Kaffeebohne", "tokens": ["Und", "ei\u00b7ne", "Kaf\u00b7fee\u00b7boh\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Treibt niemals Pferdesport.", "tokens": ["Treibt", "nie\u00b7mals", "Pfer\u00b7des\u00b7port", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Man soll nicht Pferde reizen.", "tokens": ["Man", "soll", "nicht", "Pfer\u00b7de", "rei\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PTKNEG", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Pferd ist keine Kuh.", "tokens": ["Ein", "Pferd", "ist", "kei\u00b7ne", "Kuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Aale Beine spreizen,", "tokens": ["Wenn", "Aa\u00b7le", "Bei\u00b7ne", "sprei\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sieht niemals jemand zu.", "tokens": ["Sieht", "nie\u00b7mals", "je\u00b7mand", "zu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Je mand ar in der br\u00fcs te,", "tokens": ["Je", "mand", "ar", "in", "der", "br\u00fcs", "te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "ADJD", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Recht sauber eingeh\u00fcllt,", "tokens": ["Recht", "sau\u00b7ber", "ein\u00b7ge\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Erregen oft Gel\u00fcste,", "tokens": ["Er\u00b7re\u00b7gen", "oft", "Ge\u00b7l\u00fcs\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die manches gern erf\u00fcllt.", "tokens": ["Die", "man\u00b7ches", "gern", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Man ches ter ho sen il es \u2013,", "tokens": ["Man", "ches", "ter", "ho", "sen", "il", "es", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "FM", "FM", "FM", "FM", "FM", "PPER", "$(", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Geht vieles stumpf einher.", "tokens": ["Geht", "vie\u00b7les", "stumpf", "ein\u00b7her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Quatsch gibt den Dummen vieles,", "tokens": ["Quatsch", "gibt", "den", "Dum\u00b7men", "vie\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gibt Klugen manchmal mehr.", "tokens": ["Gibt", "Klu\u00b7gen", "manch\u00b7mal", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}