{"textgrid.poem.34476": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf einem breiten Wege schritt ich hin,", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf einem breiten Wege schritt ich hin,", "tokens": ["Auf", "ei\u00b7nem", "brei\u00b7ten", "We\u00b7ge", "schritt", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der grad und lang vor mir hinaus sich dehnte,", "tokens": ["der", "grad", "und", "lang", "vor", "mir", "hin\u00b7aus", "sich", "dehn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "APPR", "PPER", "APZR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "zur Stadt hinaus, durch niedre, letzte H\u00fctten.", "tokens": ["zur", "Stadt", "hin\u00b7aus", ",", "durch", "nied\u00b7re", ",", "letz\u00b7te", "H\u00fct\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "$,", "APPR", "PIS", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich sah der Sonne, wie sie sank, ins Auge:", "tokens": ["Ich", "sah", "der", "Son\u00b7ne", ",", "wie", "sie", "sank", ",", "ins", "Au\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dort hinten, wo der Weg den H\u00fcgel anstieg,", "tokens": ["dort", "hin\u00b7ten", ",", "wo", "der", "Weg", "den", "H\u00fc\u00b7gel", "an\u00b7stieg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "da stand sie vor mir, drohend, roth und stumm.", "tokens": ["da", "stand", "sie", "vor", "mir", ",", "dro\u00b7hend", ",", "roth", "und", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "$,", "VVPP", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sie bannte mich mit ihren letzten Strahlen,", "tokens": ["Sie", "bann\u00b7te", "mich", "mit", "ih\u00b7ren", "letz\u00b7ten", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und wie ich wollte, konnt ich meine Blicke", "tokens": ["und", "wie", "ich", "woll\u00b7te", ",", "konnt", "ich", "mei\u00b7ne", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VMFIN", "$,", "VMFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "dem Blick des Gluthenauges nicht entwinden.", "tokens": ["dem", "Blick", "des", "Glu\u00b7then\u00b7au\u00b7ges", "nicht", "ent\u00b7win\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da sank sie hinter jenen langen H\u00fcgeln,", "tokens": ["Da", "sank", "sie", "hin\u00b7ter", "je\u00b7nen", "lan\u00b7gen", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die weit und breit den Horizont umgrenzten,", "tokens": ["die", "weit", "und", "breit", "den", "Ho\u00b7ri\u00b7zont", "um\u00b7grenz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und es verwaisten meine beiden Augen.", "tokens": ["und", "es", "ver\u00b7wais\u00b7ten", "mei\u00b7ne", "bei\u00b7den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ein unerkl\u00e4rtes Bangen fasste mich,", "tokens": ["Ein", "un\u00b7er\u00b7kl\u00e4r\u00b7tes", "Ban\u00b7gen", "fass\u00b7te", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "es flitterten die farbigen Sonnenbilder", "tokens": ["es", "flit\u00b7ter\u00b7ten", "die", "far\u00b7bi\u00b7gen", "Son\u00b7nen\u00b7bil\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "um mich herum: sie mehrten meine Angst.", "tokens": ["um", "mich", "he\u00b7rum", ":", "sie", "mehr\u00b7ten", "mei\u00b7ne", "Angst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PTKVZ", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Der Schatten einer Toten! Und so bunt!", "tokens": ["Der", "Schat\u00b7ten", "ei\u00b7ner", "To\u00b7ten", "!", "Und", "so", "bunt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Tanz! Und \u00fcberall muss ich sehn,", "tokens": ["Ein", "Tanz", "!", "Und", "\u00fc\u00b7be\u00b7rall", "muss", "ich", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "wohin ich blicke \u2013 dieses leere Bild!", "tokens": ["wo\u00b7hin", "ich", "bli\u00b7cke", "\u2013", "die\u00b7ses", "lee\u00b7re", "Bild", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$(", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Da war es mir, als h\u00e4tt ich ganz verloren", "tokens": ["Da", "war", "es", "mir", ",", "als", "h\u00e4tt", "ich", "ganz", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus meiner Hand die Z\u00fcgel meines Willens", "tokens": ["aus", "mei\u00b7ner", "Hand", "die", "Z\u00fc\u00b7gel", "mei\u00b7nes", "Wil\u00b7lens"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und w\u00fcrde nun von fremdem Zwang geleitet.", "tokens": ["und", "w\u00fcr\u00b7de", "nun", "von", "frem\u00b7dem", "Zwang", "ge\u00b7lei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "In eine niedre H\u00fctte trat ich ein,", "tokens": ["In", "ei\u00b7ne", "nied\u00b7re", "H\u00fct\u00b7te", "trat", "ich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und hinter mir zog ich die Th\u00fcre zu,", "tokens": ["und", "hin\u00b7ter", "mir", "zog", "ich", "die", "Th\u00fc\u00b7re", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ich war allein im fremden, dunklen Raum.", "tokens": ["ich", "war", "al\u00b7lein", "im", "frem\u00b7den", ",", "dunk\u00b7len", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Gedankenlos stand ich geraume Zeit,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7los", "stand", "ich", "ge\u00b7rau\u00b7me", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ganz still, mit angehaltnem Athem. Vor mir", "tokens": ["ganz", "still", ",", "mit", "an\u00b7ge\u00b7halt\u00b7nem", "A\u00b7them", ".", "Vor", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "$.", "APPR", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "das kleine Fenster .. draussen Abendhelle ..?", "tokens": ["das", "klei\u00b7ne", "Fens\u00b7ter", "..", "draus\u00b7sen", "A\u00b7bend\u00b7hel\u00b7le", "..", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADJA", "NN", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "War ich nicht jemals schon, vor langer Zeit,", "tokens": ["War", "ich", "nicht", "je\u00b7mals", "schon", ",", "vor", "lan\u00b7ger", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "einmal in solchem Halblicht dagestanden?", "tokens": ["ein\u00b7mal", "in", "sol\u00b7chem", "Halb\u00b7licht", "da\u00b7ge\u00b7stan\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich wars .. ich wars .. ich wusst es wohl .. doch wann? \u2013", "tokens": ["Ich", "wars", "..", "ich", "wars", "..", "ich", "wusst", "es", "wohl", "..", "doch", "wann", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "$.", "PPER", "VAFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$(", "KON", "PWAV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Die m\u00fcden H\u00fcgel dehnten sich dahinten", "tokens": ["Die", "m\u00fc\u00b7den", "H\u00fc\u00b7gel", "dehn\u00b7ten", "sich", "da\u00b7hin\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "PAV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und dr\u00fcber lagen Sonnen-abschieds-lichter", "tokens": ["und", "dr\u00fc\u00b7ber", "la\u00b7gen", "Son\u00b7nen\u00b7ab\u00b7schieds\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie Lippen, die beim Sterbekuss erblassen.", "tokens": ["wie", "Lip\u00b7pen", ",", "die", "beim", "Ster\u00b7be\u00b7kuss", "er\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Vorn, draussen unterm Fenster spielten Kinder", "tokens": ["Vorn", ",", "draus\u00b7sen", "un\u00b7term", "Fens\u00b7ter", "spiel\u00b7ten", "Kin\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "APPRART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "am Brunnen. Still, geheimnissstill die Luft,", "tokens": ["am", "Brun\u00b7nen", ".", "Still", ",", "ge\u00b7heim\u00b7niss\u00b7still", "die", "Luft", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die abendk\u00fchl durchs offne Fenster wehte. \u2013", "tokens": ["die", "a\u00b7bend\u00b7k\u00fchl", "durchs", "off\u00b7ne", "Fens\u00b7ter", "weh\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Verlass mich nicht! Verlass mich nicht, o Gott", "tokens": ["Ver\u00b7lass", "mich", "nicht", "!", "Ver\u00b7lass", "mich", "nicht", ",", "o", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "PTKNEG", "$.", "VVFIN", "PPER", "PTKNEG", "$,", "FM", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich schrak zusammen, als ich diese Worte", "tokens": ["Ich", "schrak", "zu\u00b7sam\u00b7men", ",", "als", "ich", "die\u00b7se", "Wor\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ganz nah \u2013 so j\u00e4h \u2013 so angstvoll st\u00f6hnen h\u00f6rte.", "tokens": ["ganz", "nah", "\u2013", "so", "j\u00e4h", "\u2013", "so", "angst\u00b7voll", "st\u00f6h\u00b7nen", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "ADJD", "$(", "ADV", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Beim Eintritt hatte mein geblendet Auge", "tokens": ["Beim", "Ein\u00b7tritt", "hat\u00b7te", "mein", "ge\u00b7blen\u00b7det", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPOSAT", "VVPP", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Bett dort vor dem Fenster nicht erkannt:", "tokens": ["ein", "Bett", "dort", "vor", "dem", "Fens\u00b7ter", "nicht", "er\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "daher die Stimme. Und ein junges Weib", "tokens": ["da\u00b7her", "die", "Stim\u00b7me", ".", "Und", "ein", "jun\u00b7ges", "Weib"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "$.", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "fuhr von den Kissen auf. Es strich die Haare,", "tokens": ["fuhr", "von", "den", "Kis\u00b7sen", "auf", ".", "Es", "strich", "die", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die langen, blassen, d\u00fcnnen aus der Stirne.", "tokens": ["die", "lan\u00b7gen", ",", "blas\u00b7sen", ",", "d\u00fcn\u00b7nen", "aus", "der", "Stir\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Da sah sie mich\u2013und nickte stumm mir zu", "tokens": ["Da", "sah", "sie", "mich", "\u2013", "und", "nick\u00b7te", "stumm", "mir", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$(", "KON", "VVFIN", "ADJD", "PPER", "PTKZU"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und streckte gr\u00fcssend ihre Hand nach mir.", "tokens": ["und", "streck\u00b7te", "gr\u00fcs\u00b7send", "ih\u00b7re", "Hand", "nach", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPOSAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus ihrem schmalen Kopfe, der sich dunkel", "tokens": ["Aus", "ih\u00b7rem", "schma\u00b7len", "Kop\u00b7fe", ",", "der", "sich", "dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "vom Himmel abhob in des Fensters Rahmen,", "tokens": ["vom", "Him\u00b7mel", "ab\u00b7hob", "in", "des", "Fens\u00b7ters", "Rah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "herleuchteten zwei grosse, heisse Augen.", "tokens": ["her\u00b7leuch\u00b7te\u00b7ten", "zwei", "gros\u00b7se", ",", "heis\u00b7se", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Aufathmend, wie getr\u00f6stet, sprach sie leise:", "tokens": ["Auf\u00b7ath\u00b7mend", ",", "wie", "ge\u00b7tr\u00f6s\u00b7tet", ",", "sprach", "sie", "lei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "VVPP", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Ich wusste, dass du zu mir kommen w\u00fcrdest.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "du", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7dest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Komm n\u00e4her, ja? Ich kann so laut nicht sprechen.", "tokens": ["Komm", "n\u00e4\u00b7her", ",", "ja", "?", "Ich", "kann", "so", "laut", "nicht", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "ADV", "$.", "PPER", "VMFIN", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Setz dich zu mir aufs Bett. Hier ist noch Platz.", "tokens": ["Setz", "dich", "zu", "mir", "aufs", "Bett", ".", "Hier", "ist", "noch", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPRART", "NN", "$.", "ADV", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich bin so mager \u2013 sieh nur meinen Arm!", "tokens": ["Ich", "bin", "so", "ma\u00b7ger", "\u2013", "sieh", "nur", "mei\u00b7nen", "Arm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$(", "VVIMP", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Und sie entbl\u00f6sste ihn und hob ihn auf.", "tokens": ["Und", "sie", "ent\u00b7bl\u00f6ss\u00b7te", "ihn", "und", "hob", "ihn", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich trat heran und setzte mich aufs Bett", "tokens": ["Ich", "trat", "he\u00b7ran", "und", "setz\u00b7te", "mich", "aufs", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und fasste diesen bleichen, schmalen Arm", "tokens": ["und", "fass\u00b7te", "die\u00b7sen", "blei\u00b7chen", ",", "schma\u00b7len", "Arm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und schaute in ihr junges, krankes Antlitz,", "tokens": ["und", "schau\u00b7te", "in", "ihr", "jun\u00b7ges", ",", "kran\u00b7kes", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "vom D\u00e4mmer draussen ungewiss beleuchtet.", "tokens": ["vom", "D\u00e4m\u00b7mer", "draus\u00b7sen", "un\u00b7ge\u00b7wiss", "be\u00b7leuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Der Sturm und jedes Ungemach der Welt,", "tokens": ["Der", "Sturm", "und", "je\u00b7des", "Un\u00b7ge\u00b7mach", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "stillfressend Feuer zehrender Leidenschaft ...", "tokens": ["still\u00b7fres\u00b7send", "Feu\u00b7er", "zeh\u00b7ren\u00b7der", "Lei\u00b7den\u00b7schaft", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das Kind des Armen, kaum zum Weib erbl\u00fcht,", "tokens": ["Das", "Kind", "des", "Ar\u00b7men", ",", "kaum", "zum", "Weib", "er\u00b7bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dem Noth und tiefes Leid die Brust zerst\u00f6rt.", "tokens": ["dem", "Noth", "und", "tie\u00b7fes", "Leid", "die", "Brust", "zer\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Ich wusste, dass du zu mir kommen w\u00fcrdest.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "du", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7dest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lass deine Hand mich k\u00fcssen \u2013 wehr dich nicht!", "tokens": ["Lass", "dei\u00b7ne", "Hand", "mich", "k\u00fcs\u00b7sen", "\u2013", "wehr", "dich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PPER", "VVINF", "$(", "VVIMP", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O nein! Warum? Kennst du nicht meine Schuld?", "tokens": ["O", "nein", "!", "Wa\u00b7rum", "?", "Kennst", "du", "nicht", "mei\u00b7ne", "Schuld", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "PWAV", "$.", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Du bist nicht stolz, du st\u00f6sst mich nicht von dir:", "tokens": ["Du", "bist", "nicht", "stolz", ",", "du", "st\u00f6sst", "mich", "nicht", "von", "dir", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "du hast mir ja vergeben \u2013 hast du ", "tokens": ["du", "hast", "mir", "ja", "ver\u00b7ge\u00b7ben", "\u2013", "hast", "du"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$(", "VAFIN", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.20": {"line.1": {"text": "Wie f\u00fcrchterliche Angst kams \u00fcber sie.", "tokens": ["Wie", "f\u00fcrch\u00b7ter\u00b7li\u00b7che", "Angst", "kams", "\u00fc\u00b7ber", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da gab ich willenlos die Hand ihr hin.", "tokens": ["Da", "gab", "ich", "wil\u00b7len\u00b7los", "die", "Hand", "ihr", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "So. \u2013 Lass mir deine Hand. \u2013 Lass mich sie k\u00fcssen. \u2013", "tokens": ["So", ".", "\u2013", "Lass", "mir", "dei\u00b7ne", "Hand", ".", "\u2013", "Lass", "mich", "sie", "k\u00fcs\u00b7sen", ".", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "VVIMP", "PPER", "PPOSAT", "NN", "$.", "$(", "VVIMP", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jetzt stirbt der Leib \u2013 zunichte wird der Leib \u2013", "tokens": ["Jetzt", "stirbt", "der", "Leib", "\u2013", "zu\u00b7nich\u00b7te", "wird", "der", "Leib", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "VVFIN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zu Staub. Du musst ihn an den Sohlen dulden. \u2013", "tokens": ["zu", "Staub", ".", "Du", "musst", "ihn", "an", "den", "Soh\u00b7len", "dul\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er st\u00f6rt dich nicht. \u2013 Lass ihn \u2013 lass ihn da unten ...", "tokens": ["Er", "st\u00f6rt", "dich", "nicht", ".", "\u2013", "Lass", "ihn", "\u2013", "lass", "ihn", "da", "un\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "VVIMP", "PPER", "$(", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.22": {"line.1": {"text": "Sie fiel im Sitzen in sich selbst zusammen.", "tokens": ["Sie", "fiel", "im", "Sit\u00b7zen", "in", "sich", "selbst", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Schauer zuckte durch die matten Glieder,", "tokens": ["Ein", "Schau\u00b7er", "zuck\u00b7te", "durch", "die", "mat\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "es sank der Kopf nach vorn \u2013 da raffte sie", "tokens": ["es", "sank", "der", "Kopf", "nach", "vorn", "\u2013", "da", "raff\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADV", "$(", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sich wieder auf und sah mir bang ins Auge:", "tokens": ["sich", "wie\u00b7der", "auf", "und", "sah", "mir", "bang", "ins", "Au\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Du musst mich an den beiden Armen halten.", "tokens": ["Du", "musst", "mich", "an", "den", "bei\u00b7den", "Ar\u00b7men", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So. \u2013 Hoch! \u2013 Ich falle sonst zur\u00fcck ins Kissen.", "tokens": ["So", ".", "\u2013", "Hoch", "!", "\u2013", "Ich", "fal\u00b7le", "sonst", "zu\u00b7r\u00fcck", "ins", "Kis\u00b7sen", "."], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "$(", "ADJD", "$.", "$(", "PPER", "VVFIN", "ADV", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da ist es dunkel. \u2013 Und ich muss noch aufrecht \u2013", "tokens": ["Da", "ist", "es", "dun\u00b7kel", ".", "\u2013", "Und", "ich", "muss", "noch", "auf\u00b7recht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$.", "$(", "KON", "PPER", "VMFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "hier \u2013 halte mich \u2013 hier oben ists noch hell.", "tokens": ["hier", "\u2013", "hal\u00b7te", "mich", "\u2013", "hier", "o\u00b7ben", "ists", "noch", "hell", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "PPER", "$(", "ADV", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Sieh jene dunkle, schwere Wolkenmasse!", "tokens": ["Sieh", "je\u00b7ne", "dunk\u00b7le", ",", "schwe\u00b7re", "Wol\u00b7ken\u00b7mas\u00b7se", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PDAT", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie will sich langsam auf die H\u00fcgel legen \u2013", "tokens": ["Sie", "will", "sich", "lang\u00b7sam", "auf", "die", "H\u00fc\u00b7gel", "le\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sie zieht so still \u2013 so sicher \u2013 so gewiss.", "tokens": ["sie", "zieht", "so", "still", "\u2013", "so", "si\u00b7cher", "\u2013", "so", "ge\u00b7wiss", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$(", "ADV", "ADJD", "$(", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das ist der Tod. H\u00f6r mich: ich muss dir sagen ...", "tokens": ["Das", "ist", "der", "Tod", ".", "H\u00f6r", "mich", ":", "ich", "muss", "dir", "sa\u00b7gen", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "NE", "PPER", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Wie du, so ist auch er hereingetreten", "tokens": ["Wie", "du", ",", "so", "ist", "auch", "er", "her\u00b7ein\u00b7ge\u00b7tre\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "$,", "ADV", "VAFIN", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "einmal \u2013 einmal, an einem M\u00e4rzenmorgen.", "tokens": ["ein\u00b7mal", "\u2013", "ein\u00b7mal", ",", "an", "ei\u00b7nem", "M\u00e4r\u00b7zen\u00b7mor\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Er kam nicht fremd. Ich hatte ihn erwartet.", "tokens": ["Er", "kam", "nicht", "fremd", ".", "Ich", "hat\u00b7te", "ihn", "er\u00b7war\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich wusste, dass er zu mir kommen w\u00fcrde.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "er", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Und immer wieder ist er dann gekommen.", "tokens": ["Und", "im\u00b7mer", "wie\u00b7der", "ist", "er", "dann", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu seinem Eigen hat er mich erworben:", "tokens": ["Zu", "sei\u00b7nem", "Ei\u00b7gen", "hat", "er", "mich", "er\u00b7wor\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mein Leib ward sein, und meine Seele sein,", "tokens": ["mein", "Leib", "ward", "sein", ",", "und", "mei\u00b7ne", "See\u00b7le", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VAINF", "$,", "KON", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "kein andrer hat ihn je darum betrogen.", "tokens": ["kein", "an\u00b7drer", "hat", "ihn", "je", "da\u00b7rum", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIS", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Da hat er sich .. gefreut, als er gewahrte,", "tokens": ["Da", "hat", "er", "sich", "..", "ge\u00b7freut", ",", "als", "er", "ge\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "$.", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dass ich an ihm nur hing und ihn nur sah,", "tokens": ["dass", "ich", "an", "ihm", "nur", "hing", "und", "ihn", "nur", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VVFIN", "KON", "PPER", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "und dass ich nur f\u00fcr ihn noch leben konnte.", "tokens": ["und", "dass", "ich", "nur", "f\u00fcr", "ihn", "noch", "le\u00b7ben", "konn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und .. meine Stirne hat er da gek\u00fcsst.", "tokens": ["Und", "..", "mei\u00b7ne", "Stir\u00b7ne", "hat", "er", "da", "ge\u00b7k\u00fcsst", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Und eines Tages ist er auch gekommen", "tokens": ["Und", "ei\u00b7nes", "Ta\u00b7ges", "ist", "er", "auch", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und hat mich lang gelobt, dass ich so gut", "tokens": ["und", "hat", "mich", "lang", "ge\u00b7lobt", ",", "dass", "ich", "so", "gut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und treu geworden \u2013 und noch vieles Andre", "tokens": ["und", "treu", "ge\u00b7wor\u00b7den", "\u2013", "und", "noch", "vie\u00b7les", "And\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAPP", "$(", "KON", "ADV", "PIS", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hat er zu mir gesprochen \u2013 bis ich still,", "tokens": ["hat", "er", "zu", "mir", "ge\u00b7spro\u00b7chen", "\u2013", "bis", "ich", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$(", "KON", "PPER", "PTKVZ", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.5": {"text": "ganz still geworden war \u2013 und kaum noch h\u00f6rte \u2013", "tokens": ["ganz", "still", "ge\u00b7wor\u00b7den", "war", "\u2013", "und", "kaum", "noch", "h\u00f6r\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAPP", "VAFIN", "$(", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und hat auch Geld auf meinen Tisch gelegt \u2013", "tokens": ["und", "hat", "auch", "Geld", "auf", "mei\u00b7nen", "Tisch", "ge\u00b7legt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und hat geweint \u2013 glaub ich \u2013 und ist gegangen.", "tokens": ["und", "hat", "ge\u00b7weint", "\u2013", "glaub", "ich", "\u2013", "und", "ist", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "$(", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Da wandte sie die Augen von mir ab.", "tokens": ["Da", "wand\u00b7te", "sie", "die", "Au\u00b7gen", "von", "mir", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie wurden starr und wurden immer gr\u00f6sser.", "tokens": ["Sie", "wur\u00b7den", "starr", "und", "wur\u00b7den", "im\u00b7mer", "gr\u00f6s\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie schauten bang, erwartungsbang hinaus,", "tokens": ["Sie", "schau\u00b7ten", "bang", ",", "er\u00b7war\u00b7tungs\u00b7bang", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "hinaus nach jenen mattges\u00e4umten H\u00fcgeln ...", "tokens": ["hin\u00b7aus", "nach", "je\u00b7nen", "matt\u00b7ge\u00b7s\u00e4um\u00b7ten", "H\u00fc\u00b7geln", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APZR", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Dort! Dort! so keuchte sie und riss den Arm", "tokens": ["Dort", "!", "Dort", "!", "so", "keuch\u00b7te", "sie", "und", "riss", "den", "Arm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "$.", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus meiner Hand: Dort! Sieh: da schreitet er,", "tokens": ["aus", "mei\u00b7ner", "Hand", ":", "Dort", "!", "Sieh", ":", "da", "schrei\u00b7tet", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "$.", "NE", "$.", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "gross, \u00fcbergross! Auf seinen Armen \u2013 sieh! \u2013", "tokens": ["gross", ",", "\u00fc\u00b7berg\u00b7ross", "!", "Auf", "sei\u00b7nen", "Ar\u00b7men", "\u2013", "sieh", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$.", "APPR", "PPOSAT", "NN", "$(", "VVIMP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Im Glanze, jubelnd, die Gl\u00fcckselige! \u2013", "tokens": ["Im", "Glan\u00b7ze", ",", "ju\u00b7belnd", ",", "die", "Gl\u00fcck\u00b7se\u00b7li\u00b7ge", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "VVPP", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er weidet seinen Blick an ihrem Lachen,", "tokens": ["Er", "wei\u00b7det", "sei\u00b7nen", "Blick", "an", "ih\u00b7rem", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "an ihrem zarten Wuchs, an ihrer Seide.", "tokens": ["an", "ih\u00b7rem", "zar\u00b7ten", "Wuchs", ",", "an", "ih\u00b7rer", "Sei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er geht! \u2013 Er geht! \u2013 Er ist so gross \u2013 so \u00fcbergross \u2013 \u2013", "tokens": ["Er", "geht", "!", "\u2013", "Er", "geht", "!", "\u2013", "Er", "ist", "so", "gross", "\u2013", "so", "\u00fc\u00b7berg\u00b7ross", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$(", "ADV", "ADV", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Sie sank zur\u00fcck. Es zuckten ihre Glieder.", "tokens": ["Sie", "sank", "zu\u00b7r\u00fcck", ".", "Es", "zuck\u00b7ten", "ih\u00b7re", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich beugte mich ersch\u00fcttert \u00fcber sie", "tokens": ["Ich", "beug\u00b7te", "mich", "er\u00b7sch\u00fct\u00b7tert", "\u00fc\u00b7ber", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und lauschte bang den schweren Athemz\u00fcgen.", "tokens": ["und", "lauschte", "bang", "den", "schwe\u00b7ren", "A\u00b7them\u00b7z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Im Todeskampfe hielt ich ihre H\u00e4nde.", "tokens": ["Im", "To\u00b7des\u00b7kamp\u00b7fe", "hielt", "ich", "ih\u00b7re", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Hingebung, selbstvernichtend, qualdurchstr\u00f6mt", "tokens": ["Hin\u00b7ge\u00b7bung", ",", "selbst\u00b7ver\u00b7nich\u00b7tend", ",", "qual\u00b7durch\u00b7str\u00f6mt"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJD", "$,", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "verkl\u00e4rte hoheitsvoll ihr brechend Auge.", "tokens": ["ver\u00b7kl\u00e4r\u00b7te", "ho\u00b7heits\u00b7voll", "ihr", "bre\u00b7chend", "Au\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Auf ihre Lippen presst ich meine Lippen,", "tokens": ["Auf", "ih\u00b7re", "Lip\u00b7pen", "presst", "ich", "mei\u00b7ne", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "um sie zu w\u00e4rmen, hauchte meinen Athem", "tokens": ["um", "sie", "zu", "w\u00e4r\u00b7men", ",", "hauch\u00b7te", "mei\u00b7nen", "A\u00b7them"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ihr in den Mund \u2013 so haben wir gerungen", "tokens": ["ihr", "in", "den", "Mund", "\u2013", "so", "ha\u00b7ben", "wir", "ge\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "$(", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "hart, Brust an Brust, mit jenem d\u00fcstren Freunde", "tokens": ["hart", ",", "Brust", "an", "Brust", ",", "mit", "je\u00b7nem", "d\u00fcst\u00b7ren", "Freun\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "APPR", "NN", "$,", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "der Menschen ...", "tokens": ["der", "Men\u00b7schen", "..."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.12": {"text": "Ich dr\u00fcckte ihr die kalten Augen zu.", "tokens": ["Ich", "dr\u00fcck\u00b7te", "ihr", "die", "kal\u00b7ten", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Als ich den thr\u00e4nenleeren Blick dann wieder", "tokens": ["Als", "ich", "den", "thr\u00e4\u00b7nen\u00b7lee\u00b7ren", "Blick", "dann", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "hinaus zum Fenster lenkte, nach den H\u00fcgeln,", "tokens": ["hin\u00b7aus", "zum", "Fens\u00b7ter", "lenk\u00b7te", ",", "nach", "den", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "da war das letzte Abendgelb verloschen \u2013", "tokens": ["da", "war", "das", "letz\u00b7te", "A\u00b7bend\u00b7gelb", "ver\u00b7lo\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "es war die Wolkenlast herabgesunken \u2013", "tokens": ["es", "war", "die", "Wol\u00b7ken\u00b7last", "her\u00b7ab\u00b7ge\u00b7sun\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ausbreitete die Nacht die schwarzen Schwingen.", "tokens": ["aus\u00b7brei\u00b7te\u00b7te", "die", "Nacht", "die", "schwar\u00b7zen", "Schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Auf einem breiten Wege schritt ich hin,", "tokens": ["Auf", "ei\u00b7nem", "brei\u00b7ten", "We\u00b7ge", "schritt", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der grad und lang vor mir hinaus sich dehnte,", "tokens": ["der", "grad", "und", "lang", "vor", "mir", "hin\u00b7aus", "sich", "dehn\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJD", "APPR", "PPER", "APZR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "zur Stadt hinaus, durch niedre, letzte H\u00fctten.", "tokens": ["zur", "Stadt", "hin\u00b7aus", ",", "durch", "nied\u00b7re", ",", "letz\u00b7te", "H\u00fct\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "$,", "APPR", "PIS", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Ich sah der Sonne, wie sie sank, ins Auge:", "tokens": ["Ich", "sah", "der", "Son\u00b7ne", ",", "wie", "sie", "sank", ",", "ins", "Au\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dort hinten, wo der Weg den H\u00fcgel anstieg,", "tokens": ["dort", "hin\u00b7ten", ",", "wo", "der", "Weg", "den", "H\u00fc\u00b7gel", "an\u00b7stieg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "da stand sie vor mir, drohend, roth und stumm.", "tokens": ["da", "stand", "sie", "vor", "mir", ",", "dro\u00b7hend", ",", "roth", "und", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPER", "$,", "VVPP", "$,", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Sie bannte mich mit ihren letzten Strahlen,", "tokens": ["Sie", "bann\u00b7te", "mich", "mit", "ih\u00b7ren", "letz\u00b7ten", "Strah\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und wie ich wollte, konnt ich meine Blicke", "tokens": ["und", "wie", "ich", "woll\u00b7te", ",", "konnt", "ich", "mei\u00b7ne", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "VMFIN", "$,", "VMFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "dem Blick des Gluthenauges nicht entwinden.", "tokens": ["dem", "Blick", "des", "Glu\u00b7then\u00b7au\u00b7ges", "nicht", "ent\u00b7win\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "Da sank sie hinter jenen langen H\u00fcgeln,", "tokens": ["Da", "sank", "sie", "hin\u00b7ter", "je\u00b7nen", "lan\u00b7gen", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "die weit und breit den Horizont umgrenzten,", "tokens": ["die", "weit", "und", "breit", "den", "Ho\u00b7ri\u00b7zont", "um\u00b7grenz\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und es verwaisten meine beiden Augen.", "tokens": ["und", "es", "ver\u00b7wais\u00b7ten", "mei\u00b7ne", "bei\u00b7den", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.37": {"line.1": {"text": "Ein unerkl\u00e4rtes Bangen fasste mich,", "tokens": ["Ein", "un\u00b7er\u00b7kl\u00e4r\u00b7tes", "Ban\u00b7gen", "fass\u00b7te", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "es flitterten die farbigen Sonnenbilder", "tokens": ["es", "flit\u00b7ter\u00b7ten", "die", "far\u00b7bi\u00b7gen", "Son\u00b7nen\u00b7bil\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "um mich herum: sie mehrten meine Angst.", "tokens": ["um", "mich", "he\u00b7rum", ":", "sie", "mehr\u00b7ten", "mei\u00b7ne", "Angst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "PTKVZ", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Der Schatten einer Toten! Und so bunt!", "tokens": ["Der", "Schat\u00b7ten", "ei\u00b7ner", "To\u00b7ten", "!", "Und", "so", "bunt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Tanz! Und \u00fcberall muss ich sehn,", "tokens": ["Ein", "Tanz", "!", "Und", "\u00fc\u00b7be\u00b7rall", "muss", "ich", "sehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "KON", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "wohin ich blicke \u2013 dieses leere Bild!", "tokens": ["wo\u00b7hin", "ich", "bli\u00b7cke", "\u2013", "die\u00b7ses", "lee\u00b7re", "Bild", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$(", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Da war es mir, als h\u00e4tt ich ganz verloren", "tokens": ["Da", "war", "es", "mir", ",", "als", "h\u00e4tt", "ich", "ganz", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus meiner Hand die Z\u00fcgel meines Willens", "tokens": ["aus", "mei\u00b7ner", "Hand", "die", "Z\u00fc\u00b7gel", "mei\u00b7nes", "Wil\u00b7lens"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und w\u00fcrde nun von fremdem Zwang geleitet.", "tokens": ["und", "w\u00fcr\u00b7de", "nun", "von", "frem\u00b7dem", "Zwang", "ge\u00b7lei\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "In eine niedre H\u00fctte trat ich ein,", "tokens": ["In", "ei\u00b7ne", "nied\u00b7re", "H\u00fct\u00b7te", "trat", "ich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und hinter mir zog ich die Th\u00fcre zu,", "tokens": ["und", "hin\u00b7ter", "mir", "zog", "ich", "die", "Th\u00fc\u00b7re", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ich war allein im fremden, dunklen Raum.", "tokens": ["ich", "war", "al\u00b7lein", "im", "frem\u00b7den", ",", "dunk\u00b7len", "Raum", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPRART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Gedankenlos stand ich geraume Zeit,", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7los", "stand", "ich", "ge\u00b7rau\u00b7me", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ganz still, mit angehaltnem Athem. Vor mir", "tokens": ["ganz", "still", ",", "mit", "an\u00b7ge\u00b7halt\u00b7nem", "A\u00b7them", ".", "Vor", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "$.", "APPR", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "das kleine Fenster .. draussen Abendhelle ..?", "tokens": ["das", "klei\u00b7ne", "Fens\u00b7ter", "..", "draus\u00b7sen", "A\u00b7bend\u00b7hel\u00b7le", "..", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADJA", "NN", "$.", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.42": {"line.1": {"text": "War ich nicht jemals schon, vor langer Zeit,", "tokens": ["War", "ich", "nicht", "je\u00b7mals", "schon", ",", "vor", "lan\u00b7ger", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "einmal in solchem Halblicht dagestanden?", "tokens": ["ein\u00b7mal", "in", "sol\u00b7chem", "Halb\u00b7licht", "da\u00b7ge\u00b7stan\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich wars .. ich wars .. ich wusst es wohl .. doch wann? \u2013", "tokens": ["Ich", "wars", "..", "ich", "wars", "..", "ich", "wusst", "es", "wohl", "..", "doch", "wann", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "$.", "PPER", "VAFIN", "$.", "PPER", "VVFIN", "PPER", "ADV", "$(", "KON", "PWAV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Die m\u00fcden H\u00fcgel dehnten sich dahinten", "tokens": ["Die", "m\u00fc\u00b7den", "H\u00fc\u00b7gel", "dehn\u00b7ten", "sich", "da\u00b7hin\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "PAV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und dr\u00fcber lagen Sonnen-abschieds-lichter", "tokens": ["und", "dr\u00fc\u00b7ber", "la\u00b7gen", "Son\u00b7nen\u00b7ab\u00b7schieds\u00b7lich\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie Lippen, die beim Sterbekuss erblassen.", "tokens": ["wie", "Lip\u00b7pen", ",", "die", "beim", "Ster\u00b7be\u00b7kuss", "er\u00b7blas\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Vorn, draussen unterm Fenster spielten Kinder", "tokens": ["Vorn", ",", "draus\u00b7sen", "un\u00b7term", "Fens\u00b7ter", "spiel\u00b7ten", "Kin\u00b7der"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "APPRART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "am Brunnen. Still, geheimnissstill die Luft,", "tokens": ["am", "Brun\u00b7nen", ".", "Still", ",", "ge\u00b7heim\u00b7niss\u00b7still", "die", "Luft", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die abendk\u00fchl durchs offne Fenster wehte. \u2013", "tokens": ["die", "a\u00b7bend\u00b7k\u00fchl", "durchs", "off\u00b7ne", "Fens\u00b7ter", "weh\u00b7te", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "APPRART", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Verlass mich nicht! Verlass mich nicht, o Gott", "tokens": ["Ver\u00b7lass", "mich", "nicht", "!", "Ver\u00b7lass", "mich", "nicht", ",", "o", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "PTKNEG", "$.", "VVFIN", "PPER", "PTKNEG", "$,", "FM", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich schrak zusammen, als ich diese Worte", "tokens": ["Ich", "schrak", "zu\u00b7sam\u00b7men", ",", "als", "ich", "die\u00b7se", "Wor\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "PPER", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ganz nah \u2013 so j\u00e4h \u2013 so angstvoll st\u00f6hnen h\u00f6rte.", "tokens": ["ganz", "nah", "\u2013", "so", "j\u00e4h", "\u2013", "so", "angst\u00b7voll", "st\u00f6h\u00b7nen", "h\u00f6r\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "ADV", "ADJD", "$(", "ADV", "ADJD", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "Beim Eintritt hatte mein geblendet Auge", "tokens": ["Beim", "Ein\u00b7tritt", "hat\u00b7te", "mein", "ge\u00b7blen\u00b7det", "Au\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPOSAT", "VVPP", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ein Bett dort vor dem Fenster nicht erkannt:", "tokens": ["ein", "Bett", "dort", "vor", "dem", "Fens\u00b7ter", "nicht", "er\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "daher die Stimme. Und ein junges Weib", "tokens": ["da\u00b7her", "die", "Stim\u00b7me", ".", "Und", "ein", "jun\u00b7ges", "Weib"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "$.", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "fuhr von den Kissen auf. Es strich die Haare,", "tokens": ["fuhr", "von", "den", "Kis\u00b7sen", "auf", ".", "Es", "strich", "die", "Haa\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die langen, blassen, d\u00fcnnen aus der Stirne.", "tokens": ["die", "lan\u00b7gen", ",", "blas\u00b7sen", ",", "d\u00fcn\u00b7nen", "aus", "der", "Stir\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVINF", "$,", "PRELS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.47": {"line.1": {"text": "Da sah sie mich\u2013und nickte stumm mir zu", "tokens": ["Da", "sah", "sie", "mich", "\u2013", "und", "nick\u00b7te", "stumm", "mir", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "$(", "KON", "VVFIN", "ADJD", "PPER", "PTKZU"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und streckte gr\u00fcssend ihre Hand nach mir.", "tokens": ["und", "streck\u00b7te", "gr\u00fcs\u00b7send", "ih\u00b7re", "Hand", "nach", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "PPOSAT", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus ihrem schmalen Kopfe, der sich dunkel", "tokens": ["Aus", "ih\u00b7rem", "schma\u00b7len", "Kop\u00b7fe", ",", "der", "sich", "dun\u00b7kel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "vom Himmel abhob in des Fensters Rahmen,", "tokens": ["vom", "Him\u00b7mel", "ab\u00b7hob", "in", "des", "Fens\u00b7ters", "Rah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "herleuchteten zwei grosse, heisse Augen.", "tokens": ["her\u00b7leuch\u00b7te\u00b7ten", "zwei", "gros\u00b7se", ",", "heis\u00b7se", "Au\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "CARD", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Aufathmend, wie getr\u00f6stet, sprach sie leise:", "tokens": ["Auf\u00b7ath\u00b7mend", ",", "wie", "ge\u00b7tr\u00f6s\u00b7tet", ",", "sprach", "sie", "lei\u00b7se", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "VVPP", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Ich wusste, dass du zu mir kommen w\u00fcrdest.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "du", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7dest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Komm n\u00e4her, ja? Ich kann so laut nicht sprechen.", "tokens": ["Komm", "n\u00e4\u00b7her", ",", "ja", "?", "Ich", "kann", "so", "laut", "nicht", "spre\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "ADV", "$.", "PPER", "VMFIN", "ADV", "ADJD", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Setz dich zu mir aufs Bett. Hier ist noch Platz.", "tokens": ["Setz", "dich", "zu", "mir", "aufs", "Bett", ".", "Hier", "ist", "noch", "Platz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "APPRART", "NN", "$.", "ADV", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich bin so mager \u2013 sieh nur meinen Arm!", "tokens": ["Ich", "bin", "so", "ma\u00b7ger", "\u2013", "sieh", "nur", "mei\u00b7nen", "Arm", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$(", "VVIMP", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Und sie entbl\u00f6sste ihn und hob ihn auf.", "tokens": ["Und", "sie", "ent\u00b7bl\u00f6ss\u00b7te", "ihn", "und", "hob", "ihn", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich trat heran und setzte mich aufs Bett", "tokens": ["Ich", "trat", "he\u00b7ran", "und", "setz\u00b7te", "mich", "aufs", "Bett"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und fasste diesen bleichen, schmalen Arm", "tokens": ["und", "fass\u00b7te", "die\u00b7sen", "blei\u00b7chen", ",", "schma\u00b7len", "Arm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PDAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und schaute in ihr junges, krankes Antlitz,", "tokens": ["und", "schau\u00b7te", "in", "ihr", "jun\u00b7ges", ",", "kran\u00b7kes", "Ant\u00b7litz", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "vom D\u00e4mmer draussen ungewiss beleuchtet.", "tokens": ["vom", "D\u00e4m\u00b7mer", "draus\u00b7sen", "un\u00b7ge\u00b7wiss", "be\u00b7leuch\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Der Sturm und jedes Ungemach der Welt,", "tokens": ["Der", "Sturm", "und", "je\u00b7des", "Un\u00b7ge\u00b7mach", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "stillfressend Feuer zehrender Leidenschaft ...", "tokens": ["still\u00b7fres\u00b7send", "Feu\u00b7er", "zeh\u00b7ren\u00b7der", "Lei\u00b7den\u00b7schaft", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das Kind des Armen, kaum zum Weib erbl\u00fcht,", "tokens": ["Das", "Kind", "des", "Ar\u00b7men", ",", "kaum", "zum", "Weib", "er\u00b7bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dem Noth und tiefes Leid die Brust zerst\u00f6rt.", "tokens": ["dem", "Noth", "und", "tie\u00b7fes", "Leid", "die", "Brust", "zer\u00b7st\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADJA", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Ich wusste, dass du zu mir kommen w\u00fcrdest.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "du", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7dest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lass deine Hand mich k\u00fcssen \u2013 wehr dich nicht!", "tokens": ["Lass", "dei\u00b7ne", "Hand", "mich", "k\u00fcs\u00b7sen", "\u2013", "wehr", "dich", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PPER", "VVINF", "$(", "VVIMP", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O nein! Warum? Kennst du nicht meine Schuld?", "tokens": ["O", "nein", "!", "Wa\u00b7rum", "?", "Kennst", "du", "nicht", "mei\u00b7ne", "Schuld", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKANT", "$.", "PWAV", "$.", "VVFIN", "PPER", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Du bist nicht stolz, du st\u00f6sst mich nicht von dir:", "tokens": ["Du", "bist", "nicht", "stolz", ",", "du", "st\u00f6sst", "mich", "nicht", "von", "dir", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "du hast mir ja vergeben \u2013 hast du ", "tokens": ["du", "hast", "mir", "ja", "ver\u00b7ge\u00b7ben", "\u2013", "hast", "du"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "VVPP", "$(", "VAFIN", "PPER"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.52": {"line.1": {"text": "Wie f\u00fcrchterliche Angst kams \u00fcber sie.", "tokens": ["Wie", "f\u00fcrch\u00b7ter\u00b7li\u00b7che", "Angst", "kams", "\u00fc\u00b7ber", "sie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da gab ich willenlos die Hand ihr hin.", "tokens": ["Da", "gab", "ich", "wil\u00b7len\u00b7los", "die", "Hand", "ihr", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "So. \u2013 Lass mir deine Hand. \u2013 Lass mich sie k\u00fcssen. \u2013", "tokens": ["So", ".", "\u2013", "Lass", "mir", "dei\u00b7ne", "Hand", ".", "\u2013", "Lass", "mich", "sie", "k\u00fcs\u00b7sen", ".", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "$.", "$(", "VVIMP", "PPER", "PPOSAT", "NN", "$.", "$(", "VVIMP", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Jetzt stirbt der Leib \u2013 zunichte wird der Leib \u2013", "tokens": ["Jetzt", "stirbt", "der", "Leib", "\u2013", "zu\u00b7nich\u00b7te", "wird", "der", "Leib", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "VVFIN", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zu Staub. Du musst ihn an den Sohlen dulden. \u2013", "tokens": ["zu", "Staub", ".", "Du", "musst", "ihn", "an", "den", "Soh\u00b7len", "dul\u00b7den", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "$.", "PPER", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er st\u00f6rt dich nicht. \u2013 Lass ihn \u2013 lass ihn da unten ...", "tokens": ["Er", "st\u00f6rt", "dich", "nicht", ".", "\u2013", "Lass", "ihn", "\u2013", "lass", "ihn", "da", "un\u00b7ten", "..."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "VVIMP", "PPER", "$(", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.54": {"line.1": {"text": "Sie fiel im Sitzen in sich selbst zusammen.", "tokens": ["Sie", "fiel", "im", "Sit\u00b7zen", "in", "sich", "selbst", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "PRF", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Schauer zuckte durch die matten Glieder,", "tokens": ["Ein", "Schau\u00b7er", "zuck\u00b7te", "durch", "die", "mat\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "es sank der Kopf nach vorn \u2013 da raffte sie", "tokens": ["es", "sank", "der", "Kopf", "nach", "vorn", "\u2013", "da", "raff\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADV", "$(", "ADV", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "sich wieder auf und sah mir bang ins Auge:", "tokens": ["sich", "wie\u00b7der", "auf", "und", "sah", "mir", "bang", "ins", "Au\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "PTKVZ", "KON", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Du musst mich an den beiden Armen halten.", "tokens": ["Du", "musst", "mich", "an", "den", "bei\u00b7den", "Ar\u00b7men", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So. \u2013 Hoch! \u2013 Ich falle sonst zur\u00fcck ins Kissen.", "tokens": ["So", ".", "\u2013", "Hoch", "!", "\u2013", "Ich", "fal\u00b7le", "sonst", "zu\u00b7r\u00fcck", "ins", "Kis\u00b7sen", "."], "token_info": ["word", "punct", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "$(", "ADJD", "$.", "$(", "PPER", "VVFIN", "ADV", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da ist es dunkel. \u2013 Und ich muss noch aufrecht \u2013", "tokens": ["Da", "ist", "es", "dun\u00b7kel", ".", "\u2013", "Und", "ich", "muss", "noch", "auf\u00b7recht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$.", "$(", "KON", "PPER", "VMFIN", "ADV", "ADJD", "$("], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "hier \u2013 halte mich \u2013 hier oben ists noch hell.", "tokens": ["hier", "\u2013", "hal\u00b7te", "mich", "\u2013", "hier", "o\u00b7ben", "ists", "noch", "hell", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "VVFIN", "PPER", "$(", "ADV", "ADV", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "Sieh jene dunkle, schwere Wolkenmasse!", "tokens": ["Sieh", "je\u00b7ne", "dunk\u00b7le", ",", "schwe\u00b7re", "Wol\u00b7ken\u00b7mas\u00b7se", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PDAT", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie will sich langsam auf die H\u00fcgel legen \u2013", "tokens": ["Sie", "will", "sich", "lang\u00b7sam", "auf", "die", "H\u00fc\u00b7gel", "le\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PRF", "ADJD", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sie zieht so still \u2013 so sicher \u2013 so gewiss.", "tokens": ["sie", "zieht", "so", "still", "\u2013", "so", "si\u00b7cher", "\u2013", "so", "ge\u00b7wiss", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$(", "ADV", "ADJD", "$(", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Das ist der Tod. H\u00f6r mich: ich muss dir sagen ...", "tokens": ["Das", "ist", "der", "Tod", ".", "H\u00f6r", "mich", ":", "ich", "muss", "dir", "sa\u00b7gen", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$.", "NE", "PPER", "$.", "PPER", "VMFIN", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Wie du, so ist auch er hereingetreten", "tokens": ["Wie", "du", ",", "so", "ist", "auch", "er", "her\u00b7ein\u00b7ge\u00b7tre\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "$,", "ADV", "VAFIN", "ADV", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "einmal \u2013 einmal, an einem M\u00e4rzenmorgen.", "tokens": ["ein\u00b7mal", "\u2013", "ein\u00b7mal", ",", "an", "ei\u00b7nem", "M\u00e4r\u00b7zen\u00b7mor\u00b7gen", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "$,", "APPR", "ART", "NN", "$."], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Er kam nicht fremd. Ich hatte ihn erwartet.", "tokens": ["Er", "kam", "nicht", "fremd", ".", "Ich", "hat\u00b7te", "ihn", "er\u00b7war\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ADJD", "$.", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ich wusste, dass er zu mir kommen w\u00fcrde.", "tokens": ["Ich", "wuss\u00b7te", ",", "dass", "er", "zu", "mir", "kom\u00b7men", "w\u00fcr\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Und immer wieder ist er dann gekommen.", "tokens": ["Und", "im\u00b7mer", "wie\u00b7der", "ist", "er", "dann", "ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Zu seinem Eigen hat er mich erworben:", "tokens": ["Zu", "sei\u00b7nem", "Ei\u00b7gen", "hat", "er", "mich", "er\u00b7wor\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "mein Leib ward sein, und meine Seele sein,", "tokens": ["mein", "Leib", "ward", "sein", ",", "und", "mei\u00b7ne", "See\u00b7le", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VAINF", "$,", "KON", "PPOSAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "kein andrer hat ihn je darum betrogen.", "tokens": ["kein", "an\u00b7drer", "hat", "ihn", "je", "da\u00b7rum", "be\u00b7tro\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIS", "VAFIN", "PPER", "ADV", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.59": {"line.1": {"text": "Da hat er sich .. gefreut, als er gewahrte,", "tokens": ["Da", "hat", "er", "sich", "..", "ge\u00b7freut", ",", "als", "er", "ge\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "$.", "VVPP", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dass ich an ihm nur hing und ihn nur sah,", "tokens": ["dass", "ich", "an", "ihm", "nur", "hing", "und", "ihn", "nur", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "ADV", "VVFIN", "KON", "PPER", "ADV", "VVFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "und dass ich nur f\u00fcr ihn noch leben konnte.", "tokens": ["und", "dass", "ich", "nur", "f\u00fcr", "ihn", "noch", "le\u00b7ben", "konn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und .. meine Stirne hat er da gek\u00fcsst.", "tokens": ["Und", "..", "mei\u00b7ne", "Stir\u00b7ne", "hat", "er", "da", "ge\u00b7k\u00fcsst", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PPOSAT", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Und eines Tages ist er auch gekommen", "tokens": ["Und", "ei\u00b7nes", "Ta\u00b7ges", "ist", "er", "auch", "ge\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und hat mich lang gelobt, dass ich so gut", "tokens": ["und", "hat", "mich", "lang", "ge\u00b7lobt", ",", "dass", "ich", "so", "gut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "VVPP", "$,", "KOUS", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und treu geworden \u2013 und noch vieles Andre", "tokens": ["und", "treu", "ge\u00b7wor\u00b7den", "\u2013", "und", "noch", "vie\u00b7les", "And\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAPP", "$(", "KON", "ADV", "PIS", "PIS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "hat er zu mir gesprochen \u2013 bis ich still,", "tokens": ["hat", "er", "zu", "mir", "ge\u00b7spro\u00b7chen", "\u2013", "bis", "ich", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPER", "VVPP", "$(", "KON", "PPER", "PTKVZ", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.5": {"text": "ganz still geworden war \u2013 und kaum noch h\u00f6rte \u2013", "tokens": ["ganz", "still", "ge\u00b7wor\u00b7den", "war", "\u2013", "und", "kaum", "noch", "h\u00f6r\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAPP", "VAFIN", "$(", "KON", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und hat auch Geld auf meinen Tisch gelegt \u2013", "tokens": ["und", "hat", "auch", "Geld", "auf", "mei\u00b7nen", "Tisch", "ge\u00b7legt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und hat geweint \u2013 glaub ich \u2013 und ist gegangen.", "tokens": ["und", "hat", "ge\u00b7weint", "\u2013", "glaub", "ich", "\u2013", "und", "ist", "ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "$(", "KON", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.61": {"line.1": {"text": "Da wandte sie die Augen von mir ab.", "tokens": ["Da", "wand\u00b7te", "sie", "die", "Au\u00b7gen", "von", "mir", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie wurden starr und wurden immer gr\u00f6sser.", "tokens": ["Sie", "wur\u00b7den", "starr", "und", "wur\u00b7den", "im\u00b7mer", "gr\u00f6s\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "KON", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie schauten bang, erwartungsbang hinaus,", "tokens": ["Sie", "schau\u00b7ten", "bang", ",", "er\u00b7war\u00b7tungs\u00b7bang", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "hinaus nach jenen mattges\u00e4umten H\u00fcgeln ...", "tokens": ["hin\u00b7aus", "nach", "je\u00b7nen", "matt\u00b7ge\u00b7s\u00e4um\u00b7ten", "H\u00fc\u00b7geln", "..."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APZR", "APPR", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.62": {"line.1": {"text": "Dort! Dort! so keuchte sie und riss den Arm", "tokens": ["Dort", "!", "Dort", "!", "so", "keuch\u00b7te", "sie", "und", "riss", "den", "Arm"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "$.", "ADV", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus meiner Hand: Dort! Sieh: da schreitet er,", "tokens": ["aus", "mei\u00b7ner", "Hand", ":", "Dort", "!", "Sieh", ":", "da", "schrei\u00b7tet", "er", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "$.", "NE", "$.", "ADV", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "gross, \u00fcbergross! Auf seinen Armen \u2013 sieh! \u2013", "tokens": ["gross", ",", "\u00fc\u00b7berg\u00b7ross", "!", "Auf", "sei\u00b7nen", "Ar\u00b7men", "\u2013", "sieh", "!", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$.", "APPR", "PPOSAT", "NN", "$(", "VVIMP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Im Glanze, jubelnd, die Gl\u00fcckselige! \u2013", "tokens": ["Im", "Glan\u00b7ze", ",", "ju\u00b7belnd", ",", "die", "Gl\u00fcck\u00b7se\u00b7li\u00b7ge", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "$,", "VVPP", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Er weidet seinen Blick an ihrem Lachen,", "tokens": ["Er", "wei\u00b7det", "sei\u00b7nen", "Blick", "an", "ih\u00b7rem", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "an ihrem zarten Wuchs, an ihrer Seide.", "tokens": ["an", "ih\u00b7rem", "zar\u00b7ten", "Wuchs", ",", "an", "ih\u00b7rer", "Sei\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er geht! \u2013 Er geht! \u2013 Er ist so gross \u2013 so \u00fcbergross \u2013 \u2013", "tokens": ["Er", "geht", "!", "\u2013", "Er", "geht", "!", "\u2013", "Er", "ist", "so", "gross", "\u2013", "so", "\u00fc\u00b7berg\u00b7ross", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "ADV", "ADJD", "$(", "ADV", "ADV", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.63": {"line.1": {"text": "Sie sank zur\u00fcck. Es zuckten ihre Glieder.", "tokens": ["Sie", "sank", "zu\u00b7r\u00fcck", ".", "Es", "zuck\u00b7ten", "ih\u00b7re", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich beugte mich ersch\u00fcttert \u00fcber sie", "tokens": ["Ich", "beug\u00b7te", "mich", "er\u00b7sch\u00fct\u00b7tert", "\u00fc\u00b7ber", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVPP", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und lauschte bang den schweren Athemz\u00fcgen.", "tokens": ["und", "lauschte", "bang", "den", "schwe\u00b7ren", "A\u00b7them\u00b7z\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Im Todeskampfe hielt ich ihre H\u00e4nde.", "tokens": ["Im", "To\u00b7des\u00b7kamp\u00b7fe", "hielt", "ich", "ih\u00b7re", "H\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Hingebung, selbstvernichtend, qualdurchstr\u00f6mt", "tokens": ["Hin\u00b7ge\u00b7bung", ",", "selbst\u00b7ver\u00b7nich\u00b7tend", ",", "qual\u00b7durch\u00b7str\u00f6mt"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NN", "$,", "ADJD", "$,", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "verkl\u00e4rte hoheitsvoll ihr brechend Auge.", "tokens": ["ver\u00b7kl\u00e4r\u00b7te", "ho\u00b7heits\u00b7voll", "ihr", "bre\u00b7chend", "Au\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Auf ihre Lippen presst ich meine Lippen,", "tokens": ["Auf", "ih\u00b7re", "Lip\u00b7pen", "presst", "ich", "mei\u00b7ne", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "um sie zu w\u00e4rmen, hauchte meinen Athem", "tokens": ["um", "sie", "zu", "w\u00e4r\u00b7men", ",", "hauch\u00b7te", "mei\u00b7nen", "A\u00b7them"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ihr in den Mund \u2013 so haben wir gerungen", "tokens": ["ihr", "in", "den", "Mund", "\u2013", "so", "ha\u00b7ben", "wir", "ge\u00b7run\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "$(", "ADV", "VAFIN", "PPER", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "hart, Brust an Brust, mit jenem d\u00fcstren Freunde", "tokens": ["hart", ",", "Brust", "an", "Brust", ",", "mit", "je\u00b7nem", "d\u00fcst\u00b7ren", "Freun\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "APPR", "NN", "$,", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "der Menschen ...", "tokens": ["der", "Men\u00b7schen", "..."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.12": {"text": "Ich dr\u00fcckte ihr die kalten Augen zu.", "tokens": ["Ich", "dr\u00fcck\u00b7te", "ihr", "die", "kal\u00b7ten", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.64": {"line.1": {"text": "Als ich den thr\u00e4nenleeren Blick dann wieder", "tokens": ["Als", "ich", "den", "thr\u00e4\u00b7nen\u00b7lee\u00b7ren", "Blick", "dann", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "hinaus zum Fenster lenkte, nach den H\u00fcgeln,", "tokens": ["hin\u00b7aus", "zum", "Fens\u00b7ter", "lenk\u00b7te", ",", "nach", "den", "H\u00fc\u00b7geln", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "da war das letzte Abendgelb verloschen \u2013", "tokens": ["da", "war", "das", "letz\u00b7te", "A\u00b7bend\u00b7gelb", "ver\u00b7lo\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "es war die Wolkenlast herabgesunken \u2013", "tokens": ["es", "war", "die", "Wol\u00b7ken\u00b7last", "her\u00b7ab\u00b7ge\u00b7sun\u00b7ken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ausbreitete die Nacht die schwarzen Schwingen.", "tokens": ["aus\u00b7brei\u00b7te\u00b7te", "die", "Nacht", "die", "schwar\u00b7zen", "Schwin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}