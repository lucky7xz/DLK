{"textgrid.poem.55398": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Byrons Don Juan", "genre": "verse", "period": "N.A.", "pub_year": 1820, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mir fehlt ein Held! \u2013 \u00bbEin Held, er sollte fehlen,", "tokens": ["Mir", "fehlt", "ein", "Held", "!", "\u2013", "\u00bb", "Ein", "Held", ",", "er", "soll\u00b7te", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$(", "$(", "ART", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da Jahr und Monat neu vom Neusten spricht?\u00ab", "tokens": ["Da", "Jahr", "und", "Mo\u00b7nat", "neu", "vom", "Neus\u00b7ten", "spricht", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Zeitungsschreiber mag sich schmeichelnd qu\u00e4len,", "tokens": ["Ein", "Zei\u00b7tungs\u00b7schrei\u00b7ber", "mag", "sich", "schmei\u00b7chelnd", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So sagt die Zeit: es sei der rechte nicht.", "tokens": ["So", "sagt", "die", "Zeit", ":", "es", "sei", "der", "rech\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von solchen mag ich wahrlich nichts erz\u00e4hlen,", "tokens": ["Von", "sol\u00b7chen", "mag", "ich", "wahr\u00b7lich", "nichts", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da nehm ich mir Freund Juan ins Gesicht;", "tokens": ["Da", "nehm", "ich", "mir", "Freund", "Juan", "ins", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "NE", "APPRART", "NN", "$."], "meter": "-+-+++--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Wir haben in der Oper ihn gesehen,", "tokens": ["Wir", "ha\u00b7ben", "in", "der", "O\u00b7per", "ihn", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Fr\u00fcher als billig war, zum Teufel gehen.", "tokens": ["Fr\u00fc\u00b7her", "als", "bil\u00b7lig", "war", ",", "zum", "Teu\u00b7fel", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJD", "VAFIN", "$,", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Vernon, der Metzger Cumberland und Wolfe so mit,", "tokens": ["Ver\u00b7non", ",", "der", "Metz\u00b7ger", "Cum\u00b7ber\u00b7land", "und", "Wol\u00b7fe", "so", "mit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "KON", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Auch Hawke, Prinz Ferdinand, Burgoyne aufs beste,", "tokens": ["Auch", "Haw\u00b7ke", ",", "Prinz", "Fer\u00b7di\u00b7nand", ",", "Bur\u00b7goy\u00b7ne", "aufs", "bes\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "NN", "NE", "$,", "NE", "APPRART", "ADJA", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Keppel und Howe, sie hatten ihre Feste", "tokens": ["Kep\u00b7pel", "und", "Ho\u00b7we", ",", "sie", "hat\u00b7ten", "ih\u00b7re", "Fes\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Wie Wellesley jetzt \u2013 Der K\u00f6nige Schattenschritt", "tokens": ["Wie", "Wel\u00b7les\u00b7ley", "jetzt", "\u2013", "Der", "K\u00f6\u00b7ni\u00b7ge", "Schat\u00b7ten\u00b7schritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NN", "ADV", "$(", "ART", "NN", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Vom Stamme Bancos \u2013 Raben aus ", "tokens": ["Vom", "Stam\u00b7me", "Ban\u00b7cos", "\u2013", "Ra\u00b7ben", "aus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "NE", "$(", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Ruhm, die Lust zu herrschen rei\u00dft sie mit.", "tokens": ["Der", "Ruhm", ",", "die", "Lust", "zu", "herr\u00b7schen", "rei\u00dft", "sie", "mit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dumouriez', Bonapartes Kampfgewinsten,", "tokens": ["Du\u00b7mou\u00b7rie\u00b7z'", ",", "Bo\u00b7na\u00b7par\u00b7tes", "Kampf\u00b7ge\u00b7wins\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die Zeitung steht den Herren gleich zu Diensten.", "tokens": ["Die", "Zei\u00b7tung", "steht", "den", "Her\u00b7ren", "gleich", "zu", "Diens\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Barnave kennt und Brissot die Geschichte,", "tokens": ["Bar\u00b7na\u00b7ve", "kennt", "und", "Bris\u00b7sot", "die", "Ge\u00b7schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Condorcet, Mirabeau und P\u00e9tion auch;", "tokens": ["Con\u00b7dor\u00b7cet", ",", "Mi\u00b7ra\u00b7bea\u00b7u", "und", "P\u00e9ti\u00b7on", "auch", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "NN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Cloots, Danton, Marat litten viel Ger\u00fcchte,", "tokens": ["Cloots", ",", "Dan\u00b7ton", ",", "Ma\u00b7rat", "lit\u00b7ten", "viel", "Ge\u00b7r\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Selbst Lafayette, er ging beinahe in Rauch,", "tokens": ["Selbst", "La\u00b7fay\u00b7et\u00b7te", ",", "er", "ging", "bei\u00b7na\u00b7he", "in", "Rauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Dann Joubert, Hoche, vom Milit\u00e4r-Verpflichte,", "tokens": ["Dann", "Jou\u00b7bert", ",", "Ho\u00b7che", ",", "vom", "Mi\u00b7li\u00b7t\u00e4\u00b7rVer\u00b7pflich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Lannes, Desaix, Moreau. Es war der Brauch", "tokens": ["Lan\u00b7nes", ",", "De\u00b7saix", ",", "Mo\u00b7re\u00b7au", ".", "Es", "war", "der", "Brauch"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Zu ihrer Zeit, an ihnen viel zu preisen;", "tokens": ["Zu", "ih\u00b7rer", "Zeit", ",", "an", "ih\u00b7nen", "viel", "zu", "prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch will das nichts f\u00fcr meine Lieder hei\u00dfen.", "tokens": ["Doch", "will", "das", "nichts", "f\u00fcr", "mei\u00b7ne", "Lie\u00b7der", "hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PDS", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Nelson war unser Kriegsgott, ohne Frage,", "tokens": ["Nel\u00b7son", "war", "un\u00b7ser", "Kriegs\u00b7gott", ",", "oh\u00b7ne", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Und ist es noch dem herzlichsten Bekenntnis;", "tokens": ["Und", "ist", "es", "noch", "dem", "herz\u00b7lichs\u00b7ten", "Be\u00b7kennt\u00b7nis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Doch von Trafalgar t\u00f6net kaum die Sage,", "tokens": ["Doch", "von", "Tra\u00b7fal\u00b7gar", "t\u00f6\u00b7net", "kaum", "die", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Und so ist Flut und Ebbe wetterwendisch.", "tokens": ["Und", "so", "ist", "Flut", "und", "Eb\u00b7be", "wet\u00b7ter\u00b7wen\u00b7disch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn die Armee ist popular zu Tage", "tokens": ["Denn", "die", "Ar\u00b7mee", "ist", "po\u00b7pu\u00b7lar", "zu", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Und mit dem Seevolk nicht im Einverst\u00e4ndnis;", "tokens": ["Und", "mit", "dem", "See\u00b7volk", "nicht", "im", "Ein\u00b7ver\u00b7st\u00e4nd\u00b7nis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKNEG", "APPRART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Der Prinz ist f\u00fcr den Landdienst, und indessen", "tokens": ["Der", "Prinz", "ist", "f\u00fcr", "den", "Land\u00b7dienst", ",", "und", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sind Duncan, Nelson, Howe, sie sind vergessen.", "tokens": ["Sind", "Dun\u00b7can", ",", "Nel\u00b7son", ",", "Ho\u00b7we", ",", "sie", "sind", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "$,", "NE", "$,", "NE", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Vor Agamemnon lebten manche Braven,", "tokens": ["Vor", "A\u00b7ga\u00b7mem\u00b7non", "leb\u00b7ten", "man\u00b7che", "Bra\u00b7ven", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "So wie nachher, von Sinn und hoher Kraft;", "tokens": ["So", "wie", "nach\u00b7her", ",", "von", "Sinn", "und", "ho\u00b7her", "Kraft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "$,", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie wirkten viel, sind unber\u00fchmt entschlafen,", "tokens": ["Sie", "wirk\u00b7ten", "viel", ",", "sind", "un\u00b7be\u00b7r\u00fchmt", "ent\u00b7schla\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da kein Poet ihr Leben weiter schafft.", "tokens": ["Da", "kein", "Po\u00b7et", "ihr", "Le\u00b7ben", "wei\u00b7ter", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von unsern Helden m\u00f6cht ich niemand strafen,", "tokens": ["Von", "un\u00b7sern", "Hel\u00b7den", "m\u00f6cht", "ich", "nie\u00b7mand", "stra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da jeder sich am Tag zusammenrafft;", "tokens": ["Da", "je\u00b7der", "sich", "am", "Tag", "zu\u00b7sam\u00b7men\u00b7rafft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr mein Gedicht w\u00fc\u00dft ich mir aber keinen", "tokens": ["F\u00fcr", "mein", "Ge\u00b7dicht", "w\u00fc\u00dft", "ich", "mir", "a\u00b7ber", "kei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "ADV", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und nenne so Don Juan mein, den Meinen.", "tokens": ["Und", "nen\u00b7ne", "so", "Don", "Juan", "mein", ",", "den", "Mei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NE", "NE", "PPOSAT", "$,", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Mir fehlt ein Held! \u2013 \u00bbEin Held, er sollte fehlen,", "tokens": ["Mir", "fehlt", "ein", "Held", "!", "\u2013", "\u00bb", "Ein", "Held", ",", "er", "soll\u00b7te", "feh\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$(", "$(", "ART", "NN", "$,", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da Jahr und Monat neu vom Neusten spricht?\u00ab", "tokens": ["Da", "Jahr", "und", "Mo\u00b7nat", "neu", "vom", "Neus\u00b7ten", "spricht", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein Zeitungsschreiber mag sich schmeichelnd qu\u00e4len,", "tokens": ["Ein", "Zei\u00b7tungs\u00b7schrei\u00b7ber", "mag", "sich", "schmei\u00b7chelnd", "qu\u00e4\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "So sagt die Zeit: es sei der rechte nicht.", "tokens": ["So", "sagt", "die", "Zeit", ":", "es", "sei", "der", "rech\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ART", "ADJA", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von solchen mag ich wahrlich nichts erz\u00e4hlen,", "tokens": ["Von", "sol\u00b7chen", "mag", "ich", "wahr\u00b7lich", "nichts", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da nehm ich mir Freund Juan ins Gesicht;", "tokens": ["Da", "nehm", "ich", "mir", "Freund", "Juan", "ins", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "NN", "NE", "APPRART", "NN", "$."], "meter": "-+-+++--+", "measure": "iambic.penta.chol"}, "line.7": {"text": "Wir haben in der Oper ihn gesehen,", "tokens": ["Wir", "ha\u00b7ben", "in", "der", "O\u00b7per", "ihn", "ge\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Fr\u00fcher als billig war, zum Teufel gehen.", "tokens": ["Fr\u00fc\u00b7her", "als", "bil\u00b7lig", "war", ",", "zum", "Teu\u00b7fel", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ADJD", "VAFIN", "$,", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Vernon, der Metzger Cumberland und Wolfe so mit,", "tokens": ["Ver\u00b7non", ",", "der", "Metz\u00b7ger", "Cum\u00b7ber\u00b7land", "und", "Wol\u00b7fe", "so", "mit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "ADJA", "NN", "KON", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Auch Hawke, Prinz Ferdinand, Burgoyne aufs beste,", "tokens": ["Auch", "Haw\u00b7ke", ",", "Prinz", "Fer\u00b7di\u00b7nand", ",", "Bur\u00b7goy\u00b7ne", "aufs", "bes\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "NN", "NE", "$,", "NE", "APPRART", "ADJA", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Keppel und Howe, sie hatten ihre Feste", "tokens": ["Kep\u00b7pel", "und", "Ho\u00b7we", ",", "sie", "hat\u00b7ten", "ih\u00b7re", "Fes\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "KON", "NE", "$,", "PPER", "VAFIN", "PPOSAT", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Wie Wellesley jetzt \u2013 Der K\u00f6nige Schattenschritt", "tokens": ["Wie", "Wel\u00b7les\u00b7ley", "jetzt", "\u2013", "Der", "K\u00f6\u00b7ni\u00b7ge", "Schat\u00b7ten\u00b7schritt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "NN", "ADV", "$(", "ART", "NN", "NN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Vom Stamme Bancos \u2013 Raben aus ", "tokens": ["Vom", "Stam\u00b7me", "Ban\u00b7cos", "\u2013", "Ra\u00b7ben", "aus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "NE", "$(", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Ruhm, die Lust zu herrschen rei\u00dft sie mit.", "tokens": ["Der", "Ruhm", ",", "die", "Lust", "zu", "herr\u00b7schen", "rei\u00dft", "sie", "mit", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Dumouriez', Bonapartes Kampfgewinsten,", "tokens": ["Du\u00b7mou\u00b7rie\u00b7z'", ",", "Bo\u00b7na\u00b7par\u00b7tes", "Kampf\u00b7ge\u00b7wins\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Die Zeitung steht den Herren gleich zu Diensten.", "tokens": ["Die", "Zei\u00b7tung", "steht", "den", "Her\u00b7ren", "gleich", "zu", "Diens\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Barnave kennt und Brissot die Geschichte,", "tokens": ["Bar\u00b7na\u00b7ve", "kennt", "und", "Bris\u00b7sot", "die", "Ge\u00b7schich\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Condorcet, Mirabeau und P\u00e9tion auch;", "tokens": ["Con\u00b7dor\u00b7cet", ",", "Mi\u00b7ra\u00b7bea\u00b7u", "und", "P\u00e9ti\u00b7on", "auch", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "KON", "NN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Cloots, Danton, Marat litten viel Ger\u00fcchte,", "tokens": ["Cloots", ",", "Dan\u00b7ton", ",", "Ma\u00b7rat", "lit\u00b7ten", "viel", "Ge\u00b7r\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Selbst Lafayette, er ging beinahe in Rauch,", "tokens": ["Selbst", "La\u00b7fay\u00b7et\u00b7te", ",", "er", "ging", "bei\u00b7na\u00b7he", "in", "Rauch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "PPER", "VVFIN", "ADV", "APPR", "NN", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Dann Joubert, Hoche, vom Milit\u00e4r-Verpflichte,", "tokens": ["Dann", "Jou\u00b7bert", ",", "Ho\u00b7che", ",", "vom", "Mi\u00b7li\u00b7t\u00e4\u00b7rVer\u00b7pflich\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NE", "$,", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Lannes, Desaix, Moreau. Es war der Brauch", "tokens": ["Lan\u00b7nes", ",", "De\u00b7saix", ",", "Mo\u00b7re\u00b7au", ".", "Es", "war", "der", "Brauch"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "$.", "PPER", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.7": {"text": "Zu ihrer Zeit, an ihnen viel zu preisen;", "tokens": ["Zu", "ih\u00b7rer", "Zeit", ",", "an", "ih\u00b7nen", "viel", "zu", "prei\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch will das nichts f\u00fcr meine Lieder hei\u00dfen.", "tokens": ["Doch", "will", "das", "nichts", "f\u00fcr", "mei\u00b7ne", "Lie\u00b7der", "hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PDS", "PIS", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Nelson war unser Kriegsgott, ohne Frage,", "tokens": ["Nel\u00b7son", "war", "un\u00b7ser", "Kriegs\u00b7gott", ",", "oh\u00b7ne", "Fra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,", "KOUI", "NN", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Und ist es noch dem herzlichsten Bekenntnis;", "tokens": ["Und", "ist", "es", "noch", "dem", "herz\u00b7lichs\u00b7ten", "Be\u00b7kennt\u00b7nis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Doch von Trafalgar t\u00f6net kaum die Sage,", "tokens": ["Doch", "von", "Tra\u00b7fal\u00b7gar", "t\u00f6\u00b7net", "kaum", "die", "Sa\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.4": {"text": "Und so ist Flut und Ebbe wetterwendisch.", "tokens": ["Und", "so", "ist", "Flut", "und", "Eb\u00b7be", "wet\u00b7ter\u00b7wen\u00b7disch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Denn die Armee ist popular zu Tage", "tokens": ["Denn", "die", "Ar\u00b7mee", "ist", "po\u00b7pu\u00b7lar", "zu", "Ta\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VAFIN", "ADJD", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Und mit dem Seevolk nicht im Einverst\u00e4ndnis;", "tokens": ["Und", "mit", "dem", "See\u00b7volk", "nicht", "im", "Ein\u00b7ver\u00b7st\u00e4nd\u00b7nis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKNEG", "APPRART", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.7": {"text": "Der Prinz ist f\u00fcr den Landdienst, und indessen", "tokens": ["Der", "Prinz", "ist", "f\u00fcr", "den", "Land\u00b7dienst", ",", "und", "in\u00b7des\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,", "KON", "ADV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sind Duncan, Nelson, Howe, sie sind vergessen.", "tokens": ["Sind", "Dun\u00b7can", ",", "Nel\u00b7son", ",", "Ho\u00b7we", ",", "sie", "sind", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "$,", "NE", "$,", "NE", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Vor Agamemnon lebten manche Braven,", "tokens": ["Vor", "A\u00b7ga\u00b7mem\u00b7non", "leb\u00b7ten", "man\u00b7che", "Bra\u00b7ven", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "So wie nachher, von Sinn und hoher Kraft;", "tokens": ["So", "wie", "nach\u00b7her", ",", "von", "Sinn", "und", "ho\u00b7her", "Kraft", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ADV", "$,", "APPR", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie wirkten viel, sind unber\u00fchmt entschlafen,", "tokens": ["Sie", "wirk\u00b7ten", "viel", ",", "sind", "un\u00b7be\u00b7r\u00fchmt", "ent\u00b7schla\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Da kein Poet ihr Leben weiter schafft.", "tokens": ["Da", "kein", "Po\u00b7et", "ihr", "Le\u00b7ben", "wei\u00b7ter", "schafft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von unsern Helden m\u00f6cht ich niemand strafen,", "tokens": ["Von", "un\u00b7sern", "Hel\u00b7den", "m\u00f6cht", "ich", "nie\u00b7mand", "stra\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da jeder sich am Tag zusammenrafft;", "tokens": ["Da", "je\u00b7der", "sich", "am", "Tag", "zu\u00b7sam\u00b7men\u00b7rafft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "F\u00fcr mein Gedicht w\u00fc\u00dft ich mir aber keinen", "tokens": ["F\u00fcr", "mein", "Ge\u00b7dicht", "w\u00fc\u00dft", "ich", "mir", "a\u00b7ber", "kei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "ADV", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und nenne so Don Juan mein, den Meinen.", "tokens": ["Und", "nen\u00b7ne", "so", "Don", "Juan", "mein", ",", "den", "Mei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "NE", "NE", "PPOSAT", "$,", "ART", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}}}}