{"textgrid.poem.59975": {"metadata": {"author": {"name": "Herwegh, Georg", "birth": "N.A.", "death": "N.A."}, "title": "F\u00fcr Polen", "genre": "verse", "period": "N.A.", "pub_year": 1846, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Lied vom Rhein \u2013 es klang so hell", "tokens": ["Das", "Lied", "vom", "Rhein", "\u2013", "es", "klang", "so", "hell"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE", "$(", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im S\u00fcden gestern noch und Norden;", "tokens": ["Im", "S\u00fc\u00b7den", "ge\u00b7stern", "noch", "und", "Nor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wie ist das Wei\u00dfe doch so schnell", "tokens": ["Wie", "ist", "das", "Wei\u00b7\u00dfe", "doch", "so", "schnell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Deutschland wieder schwarz geworden!", "tokens": ["In", "Deutschland", "wie\u00b7der", "schwarz", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADJD", "VAPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Wo stob er hin, der S\u00e4ngerchor?", "tokens": ["Wo", "stob", "er", "hin", ",", "der", "S\u00e4n\u00b7ge\u00b7rchor", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und warum schweigt er heut so stille?", "tokens": ["Und", "wa\u00b7rum", "schweigt", "er", "heut", "so", "stil\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ach! er erschien, ach! er verlor", "tokens": ["Ach", "!", "er", "er\u00b7schien", ",", "ach", "!", "er", "ver\u00b7lor"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ITJ", "$.", "PPER", "VVFIN", "$,", "ITJ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich \u2013 immer nach der Herren Wille.", "tokens": ["Sich", "\u2013", "im\u00b7mer", "nach", "der", "Her\u00b7ren", "Wil\u00b7le", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$(", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Was gestern Recht war f\u00fcr den Rhein,", "tokens": ["Was", "ge\u00b7stern", "Recht", "war", "f\u00fcr", "den", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VAFIN", "APPR", "ART", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ist's heute nicht auch Recht f\u00fcr Polen?", "tokens": ["Ist's", "heu\u00b7te", "nicht", "auch", "Recht", "f\u00fcr", "Po\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "ADV", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Soll Polen nicht auch Polen sein,", "tokens": ["Soll", "Po\u00b7len", "nicht", "auch", "Po\u00b7len", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADV", "NE", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil wir als R\u00e4uber mitgestohlen?", "tokens": ["Weil", "wir", "als", "R\u00e4u\u00b7ber", "mit\u00b7ge\u00b7stoh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ist F\u00fcrstenwort solch Zauberwort,", "tokens": ["Ist", "F\u00fcrs\u00b7ten\u00b7wort", "solch", "Zau\u00b7ber\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df es kann Tag in Nacht verkehren?", "tokens": ["Da\u00df", "es", "kann", "Tag", "in", "Nacht", "ver\u00b7keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sind Herz und Hirn bei uns verdorrt?", "tokens": ["Sind", "Herz", "und", "Hirn", "bei", "uns", "ver\u00b7dorrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4\u00dft Vernunft sich so entehren?", "tokens": ["Und", "l\u00e4\u00dft", "Ver\u00b7nunft", "sich", "so", "en\u00b7teh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Verga\u00dfet ihr das Einmaleins,", "tokens": ["Ver\u00b7ga\u00b7\u00dfet", "ihr", "das", "Ein\u00b7mal\u00b7eins", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr unergr\u00fcndlich tiefen Denker,", "tokens": ["Ihr", "un\u00b7er\u00b7gr\u00fcnd\u00b7lich", "tie\u00b7fen", "Den\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Zionsw\u00e4chter unsres Rheins", "tokens": ["Ihr", "Zi\u00b7ons\u00b7w\u00e4ch\u00b7ter", "uns\u00b7res", "Rheins"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder fremden Freiheit Henker!", "tokens": ["Und", "je\u00b7der", "frem\u00b7den", "Frei\u00b7heit", "Hen\u00b7ker", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "O deutsches Volk, das hoffend dr\u00e4ngt", "tokens": ["O", "deut\u00b7sches", "Volk", ",", "das", "hof\u00b7fend", "dr\u00e4ngt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich an der reichen Zukunft Schwelle,", "tokens": ["Sich", "an", "der", "rei\u00b7chen", "Zu\u00b7kunft", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was auch die Sterne dir verh\u00e4ngt,", "tokens": ["Was", "auch", "die", "Ster\u00b7ne", "dir", "ver\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sei nicht des Zaren Spie\u00dfgeselle!", "tokens": ["Sei", "nicht", "des", "Za\u00b7ren", "Spie\u00df\u00b7ge\u00b7sel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Horch auf den Sturm, der neu erbraust,", "tokens": ["Horch", "auf", "den", "Sturm", ",", "der", "neu", "er\u00b7braust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Auch deine Frucht vom Baum zu sch\u00fctteln,", "tokens": ["Auch", "dei\u00b7ne", "Frucht", "vom", "Baum", "zu", "sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Eh eisige Barbarenfaust", "tokens": ["Eh", "ei\u00b7si\u00b7ge", "Bar\u00b7ba\u00b7ren\u00b7faust"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Dich wird aus deinen Tr\u00e4umen r\u00fctteln!", "tokens": ["Dich", "wird", "aus", "dei\u00b7nen", "Tr\u00e4u\u00b7men", "r\u00fct\u00b7teln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Tritt nicht, was du bei dir ges\u00e4t,", "tokens": ["Tritt", "nicht", ",", "was", "du", "bei", "dir", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In fremdem Land mit Rosseshufen;", "tokens": ["In", "frem\u00b7dem", "Land", "mit", "Ros\u00b7ses\u00b7hu\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht deine eigne Majest\u00e4t", "tokens": ["Nicht", "dei\u00b7ne", "eig\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In V\u00f6lkern, die nach Freiheit rufen!", "tokens": ["In", "V\u00f6l\u00b7kern", ",", "die", "nach", "Frei\u00b7heit", "ru\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du suchst dich selbst aus tiefem Grund", "tokens": ["Du", "suchst", "dich", "selbst", "aus", "tie\u00b7fem", "Grund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der harten Knechtschaft aufzuschwingen,", "tokens": ["Der", "har\u00b7ten", "Knecht\u00b7schaft", "auf\u00b7zu\u00b7schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Willst du dein Joch zur selben Stund", "tokens": ["Willst", "du", "dein", "Joch", "zur", "sel\u00b7ben", "Stund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den andern auf den Nacken zwingen?", "tokens": ["Den", "an\u00b7dern", "auf", "den", "Na\u00b7cken", "zwin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Soll noch einmal im wilden Streit", "tokens": ["Soll", "noch", "ein\u00b7mal", "im", "wil\u00b7den", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinmorden unsrer Kinder Lanze", "tokens": ["Hin\u00b7mor\u00b7den", "uns\u00b7rer", "Kin\u00b7der", "Lan\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die ewige Gerechtigkeit", "tokens": ["Die", "e\u00b7wi\u00b7ge", "Ge\u00b7rech\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem alten Gleichgewichtspopanze?", "tokens": ["Dem", "al\u00b7ten", "Gleich\u00b7ge\u00b7wichts\u00b7po\u00b7pan\u00b7ze", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Weh \u00fcber uns in solchem Krieg!", "tokens": ["Weh", "\u00fc\u00b7ber", "uns", "in", "sol\u00b7chem", "Krieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir wandeln keine Ruhmesbahnen.", "tokens": ["Wir", "wan\u00b7deln", "kei\u00b7ne", "Ruh\u00b7mes\u00b7bah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich rufe: den Emp\u00f6rern Sieg!", "tokens": ["Ich", "ru\u00b7fe", ":", "den", "Em\u00b7p\u00f6\u00b7rern", "Sieg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und jede Schmach auf deutsche Fahnen!", "tokens": ["Und", "je\u00b7de", "Schmach", "auf", "deut\u00b7sche", "Fah\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Das Lied vom Rhein \u2013 es klang so hell", "tokens": ["Das", "Lied", "vom", "Rhein", "\u2013", "es", "klang", "so", "hell"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NE", "$(", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im S\u00fcden gestern noch und Norden;", "tokens": ["Im", "S\u00fc\u00b7den", "ge\u00b7stern", "noch", "und", "Nor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "KON", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Wie ist das Wei\u00dfe doch so schnell", "tokens": ["Wie", "ist", "das", "Wei\u00b7\u00dfe", "doch", "so", "schnell"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Deutschland wieder schwarz geworden!", "tokens": ["In", "Deutschland", "wie\u00b7der", "schwarz", "ge\u00b7wor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "ADJD", "VAPP", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Wo stob er hin, der S\u00e4ngerchor?", "tokens": ["Wo", "stob", "er", "hin", ",", "der", "S\u00e4n\u00b7ge\u00b7rchor", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und warum schweigt er heut so stille?", "tokens": ["Und", "wa\u00b7rum", "schweigt", "er", "heut", "so", "stil\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ach! er erschien, ach! er verlor", "tokens": ["Ach", "!", "er", "er\u00b7schien", ",", "ach", "!", "er", "ver\u00b7lor"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ITJ", "$.", "PPER", "VVFIN", "$,", "ITJ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich \u2013 immer nach der Herren Wille.", "tokens": ["Sich", "\u2013", "im\u00b7mer", "nach", "der", "Her\u00b7ren", "Wil\u00b7le", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$(", "ADV", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Was gestern Recht war f\u00fcr den Rhein,", "tokens": ["Was", "ge\u00b7stern", "Recht", "war", "f\u00fcr", "den", "Rhein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJA", "NN", "VAFIN", "APPR", "ART", "NE", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ist's heute nicht auch Recht f\u00fcr Polen?", "tokens": ["Ist's", "heu\u00b7te", "nicht", "auch", "Recht", "f\u00fcr", "Po\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "ADV", "NN", "APPR", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Soll Polen nicht auch Polen sein,", "tokens": ["Soll", "Po\u00b7len", "nicht", "auch", "Po\u00b7len", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PTKNEG", "ADV", "NE", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Weil wir als R\u00e4uber mitgestohlen?", "tokens": ["Weil", "wir", "als", "R\u00e4u\u00b7ber", "mit\u00b7ge\u00b7stoh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOUS", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ist F\u00fcrstenwort solch Zauberwort,", "tokens": ["Ist", "F\u00fcrs\u00b7ten\u00b7wort", "solch", "Zau\u00b7ber\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df es kann Tag in Nacht verkehren?", "tokens": ["Da\u00df", "es", "kann", "Tag", "in", "Nacht", "ver\u00b7keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sind Herz und Hirn bei uns verdorrt?", "tokens": ["Sind", "Herz", "und", "Hirn", "bei", "uns", "ver\u00b7dorrt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und l\u00e4\u00dft Vernunft sich so entehren?", "tokens": ["Und", "l\u00e4\u00dft", "Ver\u00b7nunft", "sich", "so", "en\u00b7teh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Verga\u00dfet ihr das Einmaleins,", "tokens": ["Ver\u00b7ga\u00b7\u00dfet", "ihr", "das", "Ein\u00b7mal\u00b7eins", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr unergr\u00fcndlich tiefen Denker,", "tokens": ["Ihr", "un\u00b7er\u00b7gr\u00fcnd\u00b7lich", "tie\u00b7fen", "Den\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ihr Zionsw\u00e4chter unsres Rheins", "tokens": ["Ihr", "Zi\u00b7ons\u00b7w\u00e4ch\u00b7ter", "uns\u00b7res", "Rheins"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jeder fremden Freiheit Henker!", "tokens": ["Und", "je\u00b7der", "frem\u00b7den", "Frei\u00b7heit", "Hen\u00b7ker", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "O deutsches Volk, das hoffend dr\u00e4ngt", "tokens": ["O", "deut\u00b7sches", "Volk", ",", "das", "hof\u00b7fend", "dr\u00e4ngt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$,", "PRELS", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sich an der reichen Zukunft Schwelle,", "tokens": ["Sich", "an", "der", "rei\u00b7chen", "Zu\u00b7kunft", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Was auch die Sterne dir verh\u00e4ngt,", "tokens": ["Was", "auch", "die", "Ster\u00b7ne", "dir", "ver\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sei nicht des Zaren Spie\u00dfgeselle!", "tokens": ["Sei", "nicht", "des", "Za\u00b7ren", "Spie\u00df\u00b7ge\u00b7sel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Horch auf den Sturm, der neu erbraust,", "tokens": ["Horch", "auf", "den", "Sturm", ",", "der", "neu", "er\u00b7braust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Auch deine Frucht vom Baum zu sch\u00fctteln,", "tokens": ["Auch", "dei\u00b7ne", "Frucht", "vom", "Baum", "zu", "sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Eh eisige Barbarenfaust", "tokens": ["Eh", "ei\u00b7si\u00b7ge", "Bar\u00b7ba\u00b7ren\u00b7faust"], "token_info": ["word", "word", "word"], "pos": ["NN", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Dich wird aus deinen Tr\u00e4umen r\u00fctteln!", "tokens": ["Dich", "wird", "aus", "dei\u00b7nen", "Tr\u00e4u\u00b7men", "r\u00fct\u00b7teln", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Tritt nicht, was du bei dir ges\u00e4t,", "tokens": ["Tritt", "nicht", ",", "was", "du", "bei", "dir", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWS", "PPER", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In fremdem Land mit Rosseshufen;", "tokens": ["In", "frem\u00b7dem", "Land", "mit", "Ros\u00b7ses\u00b7hu\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nicht deine eigne Majest\u00e4t", "tokens": ["Nicht", "dei\u00b7ne", "eig\u00b7ne", "Ma\u00b7jes\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKNEG", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In V\u00f6lkern, die nach Freiheit rufen!", "tokens": ["In", "V\u00f6l\u00b7kern", ",", "die", "nach", "Frei\u00b7heit", "ru\u00b7fen", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Du suchst dich selbst aus tiefem Grund", "tokens": ["Du", "suchst", "dich", "selbst", "aus", "tie\u00b7fem", "Grund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der harten Knechtschaft aufzuschwingen,", "tokens": ["Der", "har\u00b7ten", "Knecht\u00b7schaft", "auf\u00b7zu\u00b7schwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Willst du dein Joch zur selben Stund", "tokens": ["Willst", "du", "dein", "Joch", "zur", "sel\u00b7ben", "Stund"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den andern auf den Nacken zwingen?", "tokens": ["Den", "an\u00b7dern", "auf", "den", "Na\u00b7cken", "zwin\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Soll noch einmal im wilden Streit", "tokens": ["Soll", "noch", "ein\u00b7mal", "im", "wil\u00b7den", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hinmorden unsrer Kinder Lanze", "tokens": ["Hin\u00b7mor\u00b7den", "uns\u00b7rer", "Kin\u00b7der", "Lan\u00b7ze"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die ewige Gerechtigkeit", "tokens": ["Die", "e\u00b7wi\u00b7ge", "Ge\u00b7rech\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem alten Gleichgewichtspopanze?", "tokens": ["Dem", "al\u00b7ten", "Gleich\u00b7ge\u00b7wichts\u00b7po\u00b7pan\u00b7ze", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Weh \u00fcber uns in solchem Krieg!", "tokens": ["Weh", "\u00fc\u00b7ber", "uns", "in", "sol\u00b7chem", "Krieg", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir wandeln keine Ruhmesbahnen.", "tokens": ["Wir", "wan\u00b7deln", "kei\u00b7ne", "Ruh\u00b7mes\u00b7bah\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich rufe: den Emp\u00f6rern Sieg!", "tokens": ["Ich", "ru\u00b7fe", ":", "den", "Em\u00b7p\u00f6\u00b7rern", "Sieg", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "NN", "$."], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.4": {"text": "Und jede Schmach auf deutsche Fahnen!", "tokens": ["Und", "je\u00b7de", "Schmach", "auf", "deut\u00b7sche", "Fah\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}