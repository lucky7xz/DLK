{"textgrid.poem.63950": {"metadata": {"author": {"name": "Zachari\u00e4, Justus Friedrich Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich m\u00f6chte doch wohl von dir wissen,", "genre": "verse", "period": "N.A.", "pub_year": 1751, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich m\u00f6chte doch wohl von dir wissen,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "doch", "wohl", "von", "dir", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(hub einst, gedrungen vom Gewissen,", "tokens": ["(", "hub", "einst", ",", "ge\u00b7drun\u00b7gen", "vom", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Fuchs zu einem Habicht an)", "tokens": ["Der", "Fuchs", "zu", "ei\u00b7nem", "Ha\u00b7bicht", "an", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was dir das Taubenvolk gethan,", "tokens": ["Was", "dir", "das", "Tau\u00b7ben\u00b7volk", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df du so oft auf sie ergrimmst,", "tokens": ["Da\u00df", "du", "so", "oft", "auf", "sie", "er\u00b7grimmst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sie zu deinem Raube nimmst?", "tokens": ["Und", "sie", "zu", "dei\u00b7nem", "Rau\u00b7be", "nimmst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Habicht sprach: Kann dir's wohl sagen!", "tokens": ["Der", "Ha\u00b7bicht", "sprach", ":", "Kann", "dir's", "wohl", "sa\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man hat das Amt mir aufgetragen,", "tokens": ["Man", "hat", "das", "Amt", "mir", "auf\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auf Recht und Billigkeit zu sehn;", "tokens": ["Auf", "Recht", "und", "Bil\u00b7lig\u00b7keit", "zu", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als Richter jegliches Vergehn", "tokens": ["Als", "Rich\u00b7ter", "jeg\u00b7li\u00b7ches", "Ver\u00b7gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Scharf zu bestrafen; ohne Schonen", "tokens": ["Scharf", "zu", "be\u00b7stra\u00b7fen", ";", "oh\u00b7ne", "Scho\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Jedwedem nach Verdienst zu lohnen.", "tokens": ["Jed\u00b7we\u00b7dem", "nach", "Ver\u00b7dienst", "zu", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Man mu\u00df den Tauben strenge seyn,", "tokens": ["Man", "mu\u00df", "den", "Tau\u00b7ben", "stren\u00b7ge", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVFIN", "VAINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Sie fressen Waizen, Erbsen, Lein", "tokens": ["Sie", "fres\u00b7sen", "Wai\u00b7zen", ",", "Erb\u00b7sen", ",", "Lein"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und lie\u00dfe man sie stets so walten,", "tokens": ["Und", "lie\u00b7\u00dfe", "man", "sie", "stets", "so", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Der Landmann w\u00fcrde nichts behalten,", "tokens": ["Der", "Land\u00b7mann", "w\u00fcr\u00b7de", "nichts", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Gut! (sprach der Fuchs) das Ding hat Schein;", "tokens": ["Gut", "!", "(", "sprach", "der", "Fuchs", ")", "das", "Ding", "hat", "Schein", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "VVFIN", "ART", "NE", "$(", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Doch warum strafst du nicht den Weih'n,", "tokens": ["Doch", "wa\u00b7rum", "strafst", "du", "nicht", "den", "Weih'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und Geier, Adler, Trappen, Raben,", "tokens": ["Und", "Gei\u00b7er", ",", "Ad\u00b7ler", ",", "Trap\u00b7pen", ",", "Ra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die so viel Korn zu Schande traben?", "tokens": ["Die", "so", "viel", "Korn", "zu", "Schan\u00b7de", "tra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Die armen Tauben trifft dein Mord,", "tokens": ["Die", "ar\u00b7men", "Tau\u00b7ben", "trifft", "dein", "Mord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und jenen sagst du nicht ein Wort.", "tokens": ["Und", "je\u00b7nen", "sagst", "du", "nicht", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die sind zu stark, (erwiedert ihm", "tokens": ["Die", "sind", "zu", "stark", ",", "(", "er\u00b7wie\u00b7dert", "ihm"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "PTKA", "ADJD", "$,", "$(", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Der Habicht) voller Ungest\u00fcm", "tokens": ["Der", "Ha\u00b7bicht", ")", "vol\u00b7ler", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "W\u00fcrd' ihre Wuth vereint mich bei\u00dfen,", "tokens": ["W\u00fcrd'", "ih\u00b7re", "Wuth", "ver\u00b7eint", "mich", "bei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Und mich vielleicht in St\u00fccken rei\u00dfen.", "tokens": ["Und", "mich", "viel\u00b7leicht", "in", "St\u00fc\u00b7cken", "rei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Du strafst ja auch den armen Hasen,", "tokens": ["Du", "strafst", "ja", "auch", "den", "ar\u00b7men", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Der auf dem allgemeinen Rasen", "tokens": ["Der", "auf", "dem", "all\u00b7ge\u00b7mei\u00b7nen", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Sonst nichts als Gras und Kr\u00e4uter i\u00dft,", "tokens": ["Sonst", "nichts", "als", "Gras", "und", "Kr\u00e4u\u00b7ter", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Und schonst des Wolfs, der L\u00e4mmer fri\u00dft!", "tokens": ["Und", "schonst", "des", "Wolfs", ",", "der", "L\u00e4m\u00b7mer", "fri\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Wir sind hierin wohl gleiche Br\u00fcder;", "tokens": ["Wir", "sind", "hie\u00b7rin", "wohl", "glei\u00b7che", "Br\u00fc\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Man schonet uns, wir schonen wieder.", "tokens": ["Man", "scho\u00b7net", "uns", ",", "wir", "scho\u00b7nen", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ich m\u00f6chte doch wohl von dir wissen,", "tokens": ["Ich", "m\u00f6ch\u00b7te", "doch", "wohl", "von", "dir", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "(hub einst, gedrungen vom Gewissen,", "tokens": ["(", "hub", "einst", ",", "ge\u00b7drun\u00b7gen", "vom", "Ge\u00b7wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "VVPP", "APPRART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Der Fuchs zu einem Habicht an)", "tokens": ["Der", "Fuchs", "zu", "ei\u00b7nem", "Ha\u00b7bicht", "an", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was dir das Taubenvolk gethan,", "tokens": ["Was", "dir", "das", "Tau\u00b7ben\u00b7volk", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df du so oft auf sie ergrimmst,", "tokens": ["Da\u00df", "du", "so", "oft", "auf", "sie", "er\u00b7grimmst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und sie zu deinem Raube nimmst?", "tokens": ["Und", "sie", "zu", "dei\u00b7nem", "Rau\u00b7be", "nimmst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Habicht sprach: Kann dir's wohl sagen!", "tokens": ["Der", "Ha\u00b7bicht", "sprach", ":", "Kann", "dir's", "wohl", "sa\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VMFIN", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Man hat das Amt mir aufgetragen,", "tokens": ["Man", "hat", "das", "Amt", "mir", "auf\u00b7ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Auf Recht und Billigkeit zu sehn;", "tokens": ["Auf", "Recht", "und", "Bil\u00b7lig\u00b7keit", "zu", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Als Richter jegliches Vergehn", "tokens": ["Als", "Rich\u00b7ter", "jeg\u00b7li\u00b7ches", "Ver\u00b7gehn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Scharf zu bestrafen; ohne Schonen", "tokens": ["Scharf", "zu", "be\u00b7stra\u00b7fen", ";", "oh\u00b7ne", "Scho\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "PTKZU", "VVINF", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Jedwedem nach Verdienst zu lohnen.", "tokens": ["Jed\u00b7we\u00b7dem", "nach", "Ver\u00b7dienst", "zu", "loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Man mu\u00df den Tauben strenge seyn,", "tokens": ["Man", "mu\u00df", "den", "Tau\u00b7ben", "stren\u00b7ge", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "NN", "VVFIN", "VAINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.14": {"text": "Sie fressen Waizen, Erbsen, Lein", "tokens": ["Sie", "fres\u00b7sen", "Wai\u00b7zen", ",", "Erb\u00b7sen", ",", "Lein"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "NN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Und lie\u00dfe man sie stets so walten,", "tokens": ["Und", "lie\u00b7\u00dfe", "man", "sie", "stets", "so", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Der Landmann w\u00fcrde nichts behalten,", "tokens": ["Der", "Land\u00b7mann", "w\u00fcr\u00b7de", "nichts", "be\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Gut! (sprach der Fuchs) das Ding hat Schein;", "tokens": ["Gut", "!", "(", "sprach", "der", "Fuchs", ")", "das", "Ding", "hat", "Schein", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "$(", "VVFIN", "ART", "NE", "$(", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Doch warum strafst du nicht den Weih'n,", "tokens": ["Doch", "wa\u00b7rum", "strafst", "du", "nicht", "den", "Weih'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und Geier, Adler, Trappen, Raben,", "tokens": ["Und", "Gei\u00b7er", ",", "Ad\u00b7ler", ",", "Trap\u00b7pen", ",", "Ra\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Die so viel Korn zu Schande traben?", "tokens": ["Die", "so", "viel", "Korn", "zu", "Schan\u00b7de", "tra\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Die armen Tauben trifft dein Mord,", "tokens": ["Die", "ar\u00b7men", "Tau\u00b7ben", "trifft", "dein", "Mord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Und jenen sagst du nicht ein Wort.", "tokens": ["Und", "je\u00b7nen", "sagst", "du", "nicht", "ein", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die sind zu stark, (erwiedert ihm", "tokens": ["Die", "sind", "zu", "stark", ",", "(", "er\u00b7wie\u00b7dert", "ihm"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "PTKA", "ADJD", "$,", "$(", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Der Habicht) voller Ungest\u00fcm", "tokens": ["Der", "Ha\u00b7bicht", ")", "vol\u00b7ler", "Un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "W\u00fcrd' ihre Wuth vereint mich bei\u00dfen,", "tokens": ["W\u00fcrd'", "ih\u00b7re", "Wuth", "ver\u00b7eint", "mich", "bei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Und mich vielleicht in St\u00fccken rei\u00dfen.", "tokens": ["Und", "mich", "viel\u00b7leicht", "in", "St\u00fc\u00b7cken", "rei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Du strafst ja auch den armen Hasen,", "tokens": ["Du", "strafst", "ja", "auch", "den", "ar\u00b7men", "Ha\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Der auf dem allgemeinen Rasen", "tokens": ["Der", "auf", "dem", "all\u00b7ge\u00b7mei\u00b7nen", "Ra\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Sonst nichts als Gras und Kr\u00e4uter i\u00dft,", "tokens": ["Sonst", "nichts", "als", "Gras", "und", "Kr\u00e4u\u00b7ter", "i\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Und schonst des Wolfs, der L\u00e4mmer fri\u00dft!", "tokens": ["Und", "schonst", "des", "Wolfs", ",", "der", "L\u00e4m\u00b7mer", "fri\u00dft", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Wir sind hierin wohl gleiche Br\u00fcder;", "tokens": ["Wir", "sind", "hie\u00b7rin", "wohl", "glei\u00b7che", "Br\u00fc\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Man schonet uns, wir schonen wieder.", "tokens": ["Man", "scho\u00b7net", "uns", ",", "wir", "scho\u00b7nen", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}