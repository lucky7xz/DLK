{"textgrid.poem.44393": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Asmund und Asvit", "genre": "verse", "period": "N.A.", "pub_year": 1822, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch F\u00fchnen zieht, aus fernem Land,", "tokens": ["Durch", "F\u00fch\u00b7nen", "zieht", ",", "aus", "fer\u00b7nem", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schwedenk\u00f6nig, Alf genannt.", "tokens": ["Ein", "Schwe\u00b7den\u00b7k\u00f6\u00b7nig", ",", "Alf", "ge\u00b7nannt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hinter ihm sein streitbar Heer,", "tokens": ["Und", "hin\u00b7ter", "ihm", "sein", "streit\u00b7bar", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Beut und Ruhm und Wunden schwer.", "tokens": ["Von", "Beut", "und", "Ruhm", "und", "Wun\u00b7den", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "An einem Steine m\u00e4chtig gro\u00df", "tokens": ["An", "ei\u00b7nem", "Stei\u00b7ne", "m\u00e4ch\u00b7tig", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt an der Marschall, h\u00e4lt der Tro\u00df,", "tokens": ["H\u00e4lt", "an", "der", "Mar\u00b7schall", ",", "h\u00e4lt", "der", "Tro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erst lockt das Mahl, dann locket Ruh,", "tokens": ["Erst", "lockt", "das", "Mahl", ",", "dann", "lo\u00b7cket", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die m\u00fcden Augen fallen zu.", "tokens": ["Die", "m\u00fc\u00b7den", "Au\u00b7gen", "fal\u00b7len", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Den K\u00f6nig nur aus Schwedenland", "tokens": ["Den", "K\u00f6\u00b7nig", "nur", "aus", "Schwe\u00b7den\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schlaf allein nicht \u00fcbermannt,", "tokens": ["Der", "Schlaf", "al\u00b7lein", "nicht", "\u00fc\u00b7berm\u00b7annt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gedankenvoll in seinem Sinn", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", "in", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geht unterm Sternenlicht er hin.", "tokens": ["Geht", "un\u00b7term", "Ster\u00b7nen\u00b7licht", "er", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Da schl\u00e4gt ein \u00c4chzen an sein Ohr,", "tokens": ["Da", "schl\u00e4gt", "ein", "\u00c4ch\u00b7zen", "an", "sein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Scheints doch, es kam vom Stein hervor,", "tokens": ["Scheints", "doch", ",", "es", "kam", "vom", "Stein", "her\u00b7vor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der schattend bei dem Lager stand,", "tokens": ["Der", "schat\u00b7tend", "bei", "dem", "La\u00b7ger", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Denkmal, schauend in das Land.", "tokens": ["Ein", "Denk\u00b7mal", ",", "schau\u00b7end", "in", "das", "Land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der K\u00f6nig weckt den m\u00fcden Harst,", "tokens": ["Der", "K\u00f6\u00b7nig", "weckt", "den", "m\u00fc\u00b7den", "Harst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Schwert wird Spaten, Dolch wird Karst,", "tokens": ["Das", "Schwert", "wird", "Spa\u00b7ten", ",", "Dolch", "wird", "Karst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles gr\u00e4bt und folgt dem Ton,", "tokens": ["Und", "al\u00b7les", "gr\u00e4bt", "und", "folgt", "dem", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der nah schon \u00e4chzt und n\u00e4her schon.", "tokens": ["Der", "nah", "schon", "\u00e4chzt", "und", "n\u00e4\u00b7her", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ADJD", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Sieh, ein Gew\u00f6lb von Mauerstein,", "tokens": ["Sieh", ",", "ein", "Ge\u00b7w\u00f6lb", "von", "Mau\u00b7er\u00b7stein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sto\u00dfen drauf, sie schlagens ein.", "tokens": ["Sie", "sto\u00b7\u00dfen", "drauf", ",", "sie", "schla\u00b7gens", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da schimmert Licht und dritterselb", "tokens": ["Da", "schim\u00b7mert", "Licht", "und", "drit\u00b7ter\u00b7selb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Steigt Alf hinab ins Grabgew\u00f6lb.", "tokens": ["Steigt", "Alf", "hin\u00b7ab", "ins", "Grab\u00b7ge\u00b7w\u00f6lb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}, "stanza.8": {"line.1": {"text": "Durch F\u00fchnen zieht, aus fernem Land,", "tokens": ["Durch", "F\u00fch\u00b7nen", "zieht", ",", "aus", "fer\u00b7nem", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Schwedenk\u00f6nig, Alf genannt.", "tokens": ["Ein", "Schwe\u00b7den\u00b7k\u00f6\u00b7nig", ",", "Alf", "ge\u00b7nannt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "NE", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hinter ihm sein streitbar Heer,", "tokens": ["Und", "hin\u00b7ter", "ihm", "sein", "streit\u00b7bar", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "PPOSAT", "ADJD", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Beut und Ruhm und Wunden schwer.", "tokens": ["Von", "Beut", "und", "Ruhm", "und", "Wun\u00b7den", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "An einem Steine m\u00e4chtig gro\u00df", "tokens": ["An", "ei\u00b7nem", "Stei\u00b7ne", "m\u00e4ch\u00b7tig", "gro\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt an der Marschall, h\u00e4lt der Tro\u00df,", "tokens": ["H\u00e4lt", "an", "der", "Mar\u00b7schall", ",", "h\u00e4lt", "der", "Tro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Erst lockt das Mahl, dann locket Ruh,", "tokens": ["Erst", "lockt", "das", "Mahl", ",", "dann", "lo\u00b7cket", "Ruh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "ADV", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die m\u00fcden Augen fallen zu.", "tokens": ["Die", "m\u00fc\u00b7den", "Au\u00b7gen", "fal\u00b7len", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Den K\u00f6nig nur aus Schwedenland", "tokens": ["Den", "K\u00f6\u00b7nig", "nur", "aus", "Schwe\u00b7den\u00b7land"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Schlaf allein nicht \u00fcbermannt,", "tokens": ["Der", "Schlaf", "al\u00b7lein", "nicht", "\u00fc\u00b7berm\u00b7annt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gedankenvoll in seinem Sinn", "tokens": ["Ge\u00b7dan\u00b7ken\u00b7voll", "in", "sei\u00b7nem", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geht unterm Sternenlicht er hin.", "tokens": ["Geht", "un\u00b7term", "Ster\u00b7nen\u00b7licht", "er", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Da schl\u00e4gt ein \u00c4chzen an sein Ohr,", "tokens": ["Da", "schl\u00e4gt", "ein", "\u00c4ch\u00b7zen", "an", "sein", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Scheints doch, es kam vom Stein hervor,", "tokens": ["Scheints", "doch", ",", "es", "kam", "vom", "Stein", "her\u00b7vor", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PPER", "VVFIN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der schattend bei dem Lager stand,", "tokens": ["Der", "schat\u00b7tend", "bei", "dem", "La\u00b7ger", "stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Denkmal, schauend in das Land.", "tokens": ["Ein", "Denk\u00b7mal", ",", "schau\u00b7end", "in", "das", "Land", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der K\u00f6nig weckt den m\u00fcden Harst,", "tokens": ["Der", "K\u00f6\u00b7nig", "weckt", "den", "m\u00fc\u00b7den", "Harst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Schwert wird Spaten, Dolch wird Karst,", "tokens": ["Das", "Schwert", "wird", "Spa\u00b7ten", ",", "Dolch", "wird", "Karst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$,", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und alles gr\u00e4bt und folgt dem Ton,", "tokens": ["Und", "al\u00b7les", "gr\u00e4bt", "und", "folgt", "dem", "Ton", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der nah schon \u00e4chzt und n\u00e4her schon.", "tokens": ["Der", "nah", "schon", "\u00e4chzt", "und", "n\u00e4\u00b7her", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADV", "ADJD", "KON", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Sieh, ein Gew\u00f6lb von Mauerstein,", "tokens": ["Sieh", ",", "ein", "Ge\u00b7w\u00f6lb", "von", "Mau\u00b7er\u00b7stein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie sto\u00dfen drauf, sie schlagens ein.", "tokens": ["Sie", "sto\u00b7\u00dfen", "drauf", ",", "sie", "schla\u00b7gens", "ein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da schimmert Licht und dritterselb", "tokens": ["Da", "schim\u00b7mert", "Licht", "und", "drit\u00b7ter\u00b7selb"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Steigt Alf hinab ins Grabgew\u00f6lb.", "tokens": ["Steigt", "Alf", "hin\u00b7ab", "ins", "Grab\u00b7ge\u00b7w\u00f6lb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "...", "tokens": ["..."], "token_info": ["punct"], "pos": ["$("]}}}}}