{"textgrid.poem.42470": {"metadata": {"author": {"name": "Liliencron, Detlev von", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbertrag es wie ein Mann!\u00ab h\u00f6r ich euch sagen;", "genre": "verse", "period": "N.A.", "pub_year": 1876, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbertrag es wie ein Mann!\u00ab h\u00f6r ich euch sagen;", "tokens": ["\u00bb", "er\u00b7trag", "es", "wie", "ein", "Mann", "!", "\u00ab", "h\u00f6r", "ich", "euch", "sa\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$.", "$(", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbund spring nicht in die Wellen, das ist feige.\u00ab", "tokens": ["\u00bb", "und", "spring", "nicht", "in", "die", "Wel\u00b7len", ",", "das", "ist", "fei\u00b7ge", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "PDS", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Soll nun den Ekel trinken bis zur Neige;", "tokens": ["Soll", "nun", "den", "E\u00b7kel", "trin\u00b7ken", "bis", "zur", "Nei\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soll klagen nicht, verzagen nicht \u2013 nur tragen.", "tokens": ["Soll", "kla\u00b7gen", "nicht", ",", "ver\u00b7za\u00b7gen", "nicht", "\u2013", "nur", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PTKNEG", "$,", "VVFIN", "PTKNEG", "$(", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Gew\u00fcrgt von Armut und verbannt,", "tokens": ["Ge\u00b7w\u00fcrgt", "von", "Ar\u00b7mut", "und", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verschlei\u00df ich meine Manneskraft,", "tokens": ["Ver\u00b7schlei\u00df", "ich", "mei\u00b7ne", "Man\u00b7nes\u00b7kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein feiler Sklav; und nicht mehr schafft", "tokens": ["Ein", "fei\u00b7ler", "Sklav", ";", "und", "nicht", "mehr", "schafft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KON", "PTKNEG", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein freier Arm f\u00fcrs Vaterland.", "tokens": ["Mein", "frei\u00b7er", "Arm", "f\u00fcrs", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es klingen mir die Lieder in den Ohren,", "tokens": ["Es", "klin\u00b7gen", "mir", "die", "Lie\u00b7der", "in", "den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die ich so oft mit Freunden hab gesungen.", "tokens": ["Die", "ich", "so", "oft", "mit", "Freun\u00b7den", "hab", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bblieb Vaterland!\u00ab Das hat nun ausgeklungen.", "tokens": ["\u00bb", "lieb", "Va\u00b7ter\u00b7land", "!", "\u00ab", "Das", "hat", "nun", "aus\u00b7ge\u00b7klun\u00b7gen", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "$(", "PDS", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht fass ichs, da\u00df ich all das hab verloren.", "tokens": ["Nicht", "fass", "ichs", ",", "da\u00df", "ich", "all", "das", "hab", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PIS", "$,", "KOUS", "PPER", "PIAT", "PDS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbertrag, ertrag es als ein Mann.\u00ab", "tokens": ["\u00bb", "er\u00b7trag", ",", "er\u00b7trag", "es", "als", "ein", "Mann", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PPER", "KOUS", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erb\u00e4rmlich feiges Memmenwort!", "tokens": ["Er\u00b7b\u00e4rm\u00b7lich", "fei\u00b7ges", "Mem\u00b7men\u00b7wort", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vollstrecke endlich doch den Mord \u2013", "tokens": ["Voll\u00b7stre\u00b7cke", "end\u00b7lich", "doch", "den", "Mord", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und la\u00df die Toren schwatzen dann.", "tokens": ["Und", "la\u00df", "die", "To\u00b7ren", "schwat\u00b7zen", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u00bbertrag es wie ein Mann!\u00ab h\u00f6r ich euch sagen;", "tokens": ["\u00bb", "er\u00b7trag", "es", "wie", "ein", "Mann", "!", "\u00ab", "h\u00f6r", "ich", "euch", "sa\u00b7gen", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$.", "$(", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbund spring nicht in die Wellen, das ist feige.\u00ab", "tokens": ["\u00bb", "und", "spring", "nicht", "in", "die", "Wel\u00b7len", ",", "das", "ist", "fei\u00b7ge", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "PTKNEG", "APPR", "ART", "NN", "$,", "PDS", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Soll nun den Ekel trinken bis zur Neige;", "tokens": ["Soll", "nun", "den", "E\u00b7kel", "trin\u00b7ken", "bis", "zur", "Nei\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "VVFIN", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Soll klagen nicht, verzagen nicht \u2013 nur tragen.", "tokens": ["Soll", "kla\u00b7gen", "nicht", ",", "ver\u00b7za\u00b7gen", "nicht", "\u2013", "nur", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PTKNEG", "$,", "VVFIN", "PTKNEG", "$(", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Gew\u00fcrgt von Armut und verbannt,", "tokens": ["Ge\u00b7w\u00fcrgt", "von", "Ar\u00b7mut", "und", "ver\u00b7bannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verschlei\u00df ich meine Manneskraft,", "tokens": ["Ver\u00b7schlei\u00df", "ich", "mei\u00b7ne", "Man\u00b7nes\u00b7kraft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein feiler Sklav; und nicht mehr schafft", "tokens": ["Ein", "fei\u00b7ler", "Sklav", ";", "und", "nicht", "mehr", "schafft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "KON", "PTKNEG", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein freier Arm f\u00fcrs Vaterland.", "tokens": ["Mein", "frei\u00b7er", "Arm", "f\u00fcrs", "Va\u00b7ter\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es klingen mir die Lieder in den Ohren,", "tokens": ["Es", "klin\u00b7gen", "mir", "die", "Lie\u00b7der", "in", "den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die ich so oft mit Freunden hab gesungen.", "tokens": ["Die", "ich", "so", "oft", "mit", "Freun\u00b7den", "hab", "ge\u00b7sun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bblieb Vaterland!\u00ab Das hat nun ausgeklungen.", "tokens": ["\u00bb", "lieb", "Va\u00b7ter\u00b7land", "!", "\u00ab", "Das", "hat", "nun", "aus\u00b7ge\u00b7klun\u00b7gen", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "$.", "$(", "PDS", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Nicht fass ichs, da\u00df ich all das hab verloren.", "tokens": ["Nicht", "fass", "ichs", ",", "da\u00df", "ich", "all", "das", "hab", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PIS", "$,", "KOUS", "PPER", "PIAT", "PDS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "\u00bbertrag, ertrag es als ein Mann.\u00ab", "tokens": ["\u00bb", "er\u00b7trag", ",", "er\u00b7trag", "es", "als", "ein", "Mann", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "VVFIN", "PPER", "KOUS", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erb\u00e4rmlich feiges Memmenwort!", "tokens": ["Er\u00b7b\u00e4rm\u00b7lich", "fei\u00b7ges", "Mem\u00b7men\u00b7wort", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vollstrecke endlich doch den Mord \u2013", "tokens": ["Voll\u00b7stre\u00b7cke", "end\u00b7lich", "doch", "den", "Mord", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und la\u00df die Toren schwatzen dann.", "tokens": ["Und", "la\u00df", "die", "To\u00b7ren", "schwat\u00b7zen", "dann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}