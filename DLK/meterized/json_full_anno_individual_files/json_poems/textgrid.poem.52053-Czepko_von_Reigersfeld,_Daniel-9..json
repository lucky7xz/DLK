{"textgrid.poem.52053": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "9.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du sprichst ich h\u00e4tte nichts gelernt als Verse schreiben,", "tokens": ["Du", "sprichst", "ich", "h\u00e4t\u00b7te", "nichts", "ge\u00b7lernt", "als", "Ver\u00b7se", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "PIS", "VVPP", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit denen niemand ihm den Hunger kan vertreiben:", "tokens": ["Mit", "de\u00b7nen", "nie\u00b7mand", "ihm", "den", "Hun\u00b7ger", "kan", "ver\u00b7trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hergegen bl\u00e4st dich auff das grosse Schreiber Ammt,", "tokens": ["Her\u00b7ge\u00b7gen", "bl\u00e4st", "dich", "auff", "das", "gros\u00b7se", "Schrei\u00b7ber", "Ammt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und durch die Wissenschafft h\u00f6nst du uns allesammt.", "tokens": ["Und", "durch", "die", "Wis\u00b7sen\u00b7schafft", "h\u00f6nst", "du", "uns", "al\u00b7le\u00b7sammt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Es ist wol wahr, ich kan die Leute nicht verjagen,", "tokens": ["Es", "ist", "wol", "wahr", ",", "ich", "kan", "die", "Leu\u00b7te", "nicht", "ver\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht f\u00e4lschlich schwehrn, nicht Geld in fremden Schreibtisch tragen:", "tokens": ["Nicht", "f\u00e4lschlich", "schwehrn", ",", "nicht", "Geld", "in", "frem\u00b7den", "Schreib\u00b7tisch", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "$,", "PTKNEG", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Indem ich aber wei\u00df, acht ich mich hochgelehrt,", "tokens": ["In\u00b7dem", "ich", "a\u00b7ber", "wei\u00df", ",", "acht", "ich", "mich", "hoch\u00b7ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "CARD", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohin mit seinem Geld ein solcher Mann geh\u00f6rt.", "tokens": ["Wo\u00b7hin", "mit", "sei\u00b7nem", "Geld", "ein", "sol\u00b7cher", "Mann", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPOSAT", "NN", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Nun Juncker nicht zu stoltz: Du must mich nicht verachten,", "tokens": ["Nun", "Jun\u00b7cker", "nicht", "zu", "stoltz", ":", "Du", "must", "mich", "nicht", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PTKNEG", "PTKA", "ADJD", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Verse hei\u00dfen mich nach Ruhm und Ehre trachten:", "tokens": ["Die", "Ver\u00b7se", "hei\u00b7\u00dfen", "mich", "nach", "Ruhm", "und", "Eh\u00b7re", "trach\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der H\u00f6chste wird mich f\u00fchrn in seinen Himmel ein,", "tokens": ["Der", "H\u00f6chs\u00b7te", "wird", "mich", "f\u00fchrn", "in", "sei\u00b7nen", "Him\u00b7mel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn deine Goldne Kett einmahl wird eisern seyn.", "tokens": ["Wenn", "dei\u00b7ne", "Gold\u00b7ne", "Kett", "ein\u00b7mahl", "wird", "ei\u00b7sern", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Du sprichst ich h\u00e4tte nichts gelernt als Verse schreiben,", "tokens": ["Du", "sprichst", "ich", "h\u00e4t\u00b7te", "nichts", "ge\u00b7lernt", "als", "Ver\u00b7se", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "PIS", "VVPP", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit denen niemand ihm den Hunger kan vertreiben:", "tokens": ["Mit", "de\u00b7nen", "nie\u00b7mand", "ihm", "den", "Hun\u00b7ger", "kan", "ver\u00b7trei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hergegen bl\u00e4st dich auff das grosse Schreiber Ammt,", "tokens": ["Her\u00b7ge\u00b7gen", "bl\u00e4st", "dich", "auff", "das", "gros\u00b7se", "Schrei\u00b7ber", "Ammt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "NE", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Und durch die Wissenschafft h\u00f6nst du uns allesammt.", "tokens": ["Und", "durch", "die", "Wis\u00b7sen\u00b7schafft", "h\u00f6nst", "du", "uns", "al\u00b7le\u00b7sammt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Es ist wol wahr, ich kan die Leute nicht verjagen,", "tokens": ["Es", "ist", "wol", "wahr", ",", "ich", "kan", "die", "Leu\u00b7te", "nicht", "ver\u00b7ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VMFIN", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht f\u00e4lschlich schwehrn, nicht Geld in fremden Schreibtisch tragen:", "tokens": ["Nicht", "f\u00e4lschlich", "schwehrn", ",", "nicht", "Geld", "in", "frem\u00b7den", "Schreib\u00b7tisch", "tra\u00b7gen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "$,", "PTKNEG", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Indem ich aber wei\u00df, acht ich mich hochgelehrt,", "tokens": ["In\u00b7dem", "ich", "a\u00b7ber", "wei\u00df", ",", "acht", "ich", "mich", "hoch\u00b7ge\u00b7lehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$,", "CARD", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wohin mit seinem Geld ein solcher Mann geh\u00f6rt.", "tokens": ["Wo\u00b7hin", "mit", "sei\u00b7nem", "Geld", "ein", "sol\u00b7cher", "Mann", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "PPOSAT", "NN", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Nun Juncker nicht zu stoltz: Du must mich nicht verachten,", "tokens": ["Nun", "Jun\u00b7cker", "nicht", "zu", "stoltz", ":", "Du", "must", "mich", "nicht", "ver\u00b7ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PTKNEG", "PTKA", "ADJD", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Verse hei\u00dfen mich nach Ruhm und Ehre trachten:", "tokens": ["Die", "Ver\u00b7se", "hei\u00b7\u00dfen", "mich", "nach", "Ruhm", "und", "Eh\u00b7re", "trach\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der H\u00f6chste wird mich f\u00fchrn in seinen Himmel ein,", "tokens": ["Der", "H\u00f6chs\u00b7te", "wird", "mich", "f\u00fchrn", "in", "sei\u00b7nen", "Him\u00b7mel", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn deine Goldne Kett einmahl wird eisern seyn.", "tokens": ["Wenn", "dei\u00b7ne", "Gold\u00b7ne", "Kett", "ein\u00b7mahl", "wird", "ei\u00b7sern", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "VAFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}