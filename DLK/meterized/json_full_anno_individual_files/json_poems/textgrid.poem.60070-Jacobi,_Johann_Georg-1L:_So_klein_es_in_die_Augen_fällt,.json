{"textgrid.poem.60070": {"metadata": {"author": {"name": "Jacobi, Johann Georg", "birth": "N.A.", "death": "N.A."}, "title": "1L: So klein es in die Augen f\u00e4llt,", "genre": "verse", "period": "N.A.", "pub_year": 1777, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So klein es in die Augen f\u00e4llt,", "tokens": ["So", "klein", "es", "in", "die", "Au\u00b7gen", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jedes Sternchen eine Welt?", "tokens": ["Ein", "je\u00b7des", "Stern\u00b7chen", "ei\u00b7ne", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Himmel, gro\u00df genug, uns allesammt zu fassen?", "tokens": ["Ein", "Him\u00b7mel", ",", "gro\u00df", "ge\u00b7nug", ",", "uns", "al\u00b7le\u00b7sammt", "zu", "fas\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "ADV", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ich soll, wie ein Engel sch\u00f6n,", "tokens": ["Und", "ich", "soll", ",", "wie", "ein", "En\u00b7gel", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "$,", "PWAV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Sternen einst zu Sternen gehn,", "tokens": ["Von", "Ster\u00b7nen", "einst", "zu", "Ster\u00b7nen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Alles, Alles da besehn;", "tokens": ["Und", "Al\u00b7les", ",", "Al\u00b7les", "da", "be\u00b7sehn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcberall mich sehen lassen?", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "mich", "se\u00b7hen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "So klein es in die Augen f\u00e4llt,", "tokens": ["So", "klein", "es", "in", "die", "Au\u00b7gen", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein jedes Sternchen eine Welt?", "tokens": ["Ein", "je\u00b7des", "Stern\u00b7chen", "ei\u00b7ne", "Welt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Himmel, gro\u00df genug, uns allesammt zu fassen?", "tokens": ["Ein", "Him\u00b7mel", ",", "gro\u00df", "ge\u00b7nug", ",", "uns", "al\u00b7le\u00b7sammt", "zu", "fas\u00b7sen", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "ADV", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ich soll, wie ein Engel sch\u00f6n,", "tokens": ["Und", "ich", "soll", ",", "wie", "ein", "En\u00b7gel", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "$,", "PWAV", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von Sternen einst zu Sternen gehn,", "tokens": ["Von", "Ster\u00b7nen", "einst", "zu", "Ster\u00b7nen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Alles, Alles da besehn;", "tokens": ["Und", "Al\u00b7les", ",", "Al\u00b7les", "da", "be\u00b7sehn", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PIS", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcberall mich sehen lassen?", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "mich", "se\u00b7hen", "las\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}