{"textgrid.poem.56861": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wir sind zwei Rosen,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir sind zwei Rosen,", "tokens": ["Wir", "sind", "zwei", "Ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "dar\u00fcber der Sturm fuhr", "tokens": ["da\u00b7r\u00fc\u00b7ber", "der", "Sturm", "fuhr"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "und sie abri\u00df.", "tokens": ["und", "sie", "ab\u00b7ri\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Gemeinsam", "tokens": ["Ge\u00b7mein\u00b7sam"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "wirbeln sie nun", "tokens": ["wir\u00b7beln", "sie", "nun"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "den Weg entlang,", "tokens": ["den", "Weg", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "und ihre Bl\u00e4tter", "tokens": ["und", "ih\u00b7re", "Bl\u00e4t\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "wehn durcheinander.", "tokens": ["wehn", "durch\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Heimatlose,", "tokens": ["Hei\u00b7mat\u00b7lo\u00b7se", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "tanzen und fliehn sie,", "tokens": ["tan\u00b7zen", "und", "fliehn", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "KON", "VVFIN", "PPER", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "nur f\u00fcr einander", "tokens": ["nur", "f\u00fcr", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "PRF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "duftend und leuchtend,", "tokens": ["duf\u00b7tend", "und", "leuch\u00b7tend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "den Weg der Liebe \u2013:", "tokens": ["den", "Weg", "der", "Lie\u00b7be", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Bis sie am Abend", "tokens": ["Bis", "sie", "am", "A\u00b7bend"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "der gro\u00dfe Feger", "tokens": ["der", "gro\u00b7\u00dfe", "Fe\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "l\u00e4chelnd", "tokens": ["l\u00e4\u00b7chelnd"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "auf seine Schaufel nimmt.", "tokens": ["auf", "sei\u00b7ne", "Schau\u00b7fel", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir sind zwei Rosen,", "tokens": ["Wir", "sind", "zwei", "Ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "dar\u00fcber der Sturm fuhr", "tokens": ["da\u00b7r\u00fc\u00b7ber", "der", "Sturm", "fuhr"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "VVFIN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "und sie abri\u00df.", "tokens": ["und", "sie", "ab\u00b7ri\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Gemeinsam", "tokens": ["Ge\u00b7mein\u00b7sam"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "wirbeln sie nun", "tokens": ["wir\u00b7beln", "sie", "nun"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "den Weg entlang,", "tokens": ["den", "Weg", "ent\u00b7lang", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "und ihre Bl\u00e4tter", "tokens": ["und", "ih\u00b7re", "Bl\u00e4t\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.5": {"text": "wehn durcheinander.", "tokens": ["wehn", "durch\u00b7ein\u00b7an\u00b7der", "."], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.7": {"line.1": {"text": "Heimatlose,", "tokens": ["Hei\u00b7mat\u00b7lo\u00b7se", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "tanzen und fliehn sie,", "tokens": ["tan\u00b7zen", "und", "fliehn", "sie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVINF", "KON", "VVFIN", "PPER", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "nur f\u00fcr einander", "tokens": ["nur", "f\u00fcr", "ein\u00b7an\u00b7der"], "token_info": ["word", "word", "word"], "pos": ["ADV", "APPR", "PRF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "duftend und leuchtend,", "tokens": ["duf\u00b7tend", "und", "leuch\u00b7tend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "den Weg der Liebe \u2013:", "tokens": ["den", "Weg", "der", "Lie\u00b7be", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "$(", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Bis sie am Abend", "tokens": ["Bis", "sie", "am", "A\u00b7bend"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "der gro\u00dfe Feger", "tokens": ["der", "gro\u00b7\u00dfe", "Fe\u00b7ger"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "l\u00e4chelnd", "tokens": ["l\u00e4\u00b7chelnd"], "token_info": ["word"], "pos": ["ADJD"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "auf seine Schaufel nimmt.", "tokens": ["auf", "sei\u00b7ne", "Schau\u00b7fel", "nimmt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}