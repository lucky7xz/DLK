{"textgrid.poem.49701": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Hilfe", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6rt mich, den S\u00e4nger mit dem dumpfen Tone!", "tokens": ["H\u00f6rt", "mich", ",", "den", "S\u00e4n\u00b7ger", "mit", "dem", "dum\u00b7pfen", "To\u00b7ne", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Stimme zittert und die Tr\u00e4ne rinnt:", "tokens": ["Die", "Stim\u00b7me", "zit\u00b7tert", "und", "die", "Tr\u00e4\u00b7ne", "rinnt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der, wo noch glaubt, die Menschen sind nicht ohne,", "tokens": ["Der", ",", "wo", "noch", "glaubt", ",", "die", "Men\u00b7schen", "sind", "nicht", "oh\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ADV", "VVFIN", "$,", "ART", "NN", "VAFIN", "PTKNEG", "APPR", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr B\u00fcrger, h\u00f6rt mich! \u2013 der ist falsch gesinnt.", "tokens": ["Ihr", "B\u00fcr\u00b7ger", ",", "h\u00f6rt", "mich", "!", "\u2013", "der", "ist", "falsch", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$.", "$(", "PDS", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich sag' euch heute nur so viel wie dies:", "tokens": ["Ich", "sag'", "euch", "heu\u00b7te", "nur", "so", "viel", "wie", "dies", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PIAT", "KOKOM", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das deutsche Volk ist wirklich \u00e4u\u00dferst mies.", "tokens": ["Das", "deut\u00b7sche", "Volk", "ist", "wirk\u00b7lich", "\u00e4u\u00b7\u00dferst", "mies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Wo sind die Sitten? Wo die guten Zeiten,", "tokens": ["Wo", "sind", "die", "Sit\u00b7ten", "?", "Wo", "die", "gu\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$.", "PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da ganz submissest jedermann erstarb?", "tokens": ["Da", "ganz", "sub\u00b7mis\u00b7sest", "je\u00b7der\u00b7mann", "er\u00b7starb", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Im tiefsten Kote vor den F\u00fcrstlichkeiten", "tokens": ["Im", "tiefs\u00b7ten", "Ko\u00b7te", "vor", "den", "F\u00fcrst\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Devotest bittend um ein Gr\u00fc\u00dfchen warb?", "tokens": ["De\u00b7vo\u00b7test", "bit\u00b7tend", "um", "ein", "Gr\u00fc\u00df\u00b7chen", "warb", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fcr hohe Gnaden ist man nicht mehr reif,", "tokens": ["F\u00fcr", "ho\u00b7he", "Gna\u00b7den", "ist", "man", "nicht", "mehr", "reif", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PIS", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und die Carnallje h\u00e4lt den Nacken steif.", "tokens": ["Und", "die", "Car\u00b7nall\u00b7je", "h\u00e4lt", "den", "Na\u00b7cken", "steif", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Begegnen heute uns des Hofes Chaisen", "tokens": ["Be\u00b7geg\u00b7nen", "heu\u00b7te", "uns", "des", "Ho\u00b7fes", "Chai\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Der J\u00e4ger vorne, hinten der Lakai \u2013,", "tokens": ["\u2013", "Der", "J\u00e4\u00b7ger", "vor\u00b7ne", ",", "hin\u00b7ten", "der", "La\u00b7kai", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ADV", "$,", "ADV", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tut mancher so, als w\u00e4r's ihm wurscht gewesen,", "tokens": ["Tut", "man\u00b7cher", "so", ",", "als", "w\u00e4r's", "ihm", "wurscht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und fragt noch staunend: \u00bbWas ist da dabei?\u00ab", "tokens": ["Und", "fragt", "noch", "stau\u00b7nend", ":", "\u00bb", "Was", "ist", "da", "da\u00b7bei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$.", "$(", "PWS", "VAFIN", "ADV", "PAV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So merkt man deutlich, wie der Zeiten Zahn", "tokens": ["So", "merkt", "man", "deut\u00b7lich", ",", "wie", "der", "Zei\u00b7ten", "Zahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bedenklich nagte an dem Untertan.", "tokens": ["Be\u00b7denk\u00b7lich", "nag\u00b7te", "an", "dem", "Un\u00b7ter\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Der F\u00fcrsten Worte waren einst geh\u00fctet", "tokens": ["Der", "F\u00fcrs\u00b7ten", "Wor\u00b7te", "wa\u00b7ren", "einst", "ge\u00b7h\u00fc\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von der Beh\u00f6rde wie ein gold'ner Schatz,", "tokens": ["Von", "der", "Be\u00b7h\u00f6r\u00b7de", "wie", "ein", "gold'\u00b7ner", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wurden laut in alle Welt get\u00fctet.", "tokens": ["Und", "wur\u00b7den", "laut", "in", "al\u00b7le", "Welt", "ge\u00b7t\u00fc\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Heut' streicht man oft den allersch\u00f6nsten Satz.", "tokens": ["Heut'", "streicht", "man", "oft", "den", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Satz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn von Beamten schon so was geschah,", "tokens": ["Wenn", "von", "Be\u00b7am\u00b7ten", "schon", "so", "was", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ADV", "ADV", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was soll man denken? Und was sagt man da?", "tokens": ["Was", "soll", "man", "den\u00b7ken", "?", "Und", "was", "sagt", "man", "da", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "VVINF", "$.", "KON", "PWS", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und erst die Jugend! O die deutsche Jugend!", "tokens": ["Und", "erst", "die", "Ju\u00b7gend", "!", "O", "die", "deut\u00b7sche", "Ju\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jeder jammert, der sie etwas kennt,", "tokens": ["Ein", "je\u00b7der", "jam\u00b7mert", ",", "der", "sie", "et\u00b7was", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie hat nicht diese, hat nicht jene Tugend", "tokens": ["Sie", "hat", "nicht", "die\u00b7se", ",", "hat", "nicht", "je\u00b7ne", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "PDS", "$,", "VAFIN", "PTKNEG", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und hat zum Hunnenkrieger kein Talent.", "tokens": ["Und", "hat", "zum", "Hun\u00b7nen\u00b7krie\u00b7ger", "kein", "Ta\u00b7lent", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf gute Lehren sagt sie h\u00f6chstens: \u00bbSchrumm!\u00ab", "tokens": ["Auf", "gu\u00b7te", "Leh\u00b7ren", "sagt", "sie", "h\u00f6chs\u00b7tens", ":", "\u00bb", "Schrumm", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$.", "$(", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ist schon lange nicht mehr halb so dumm.", "tokens": ["Und", "ist", "schon", "lan\u00b7ge", "nicht", "mehr", "halb", "so", "dumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Das Anseh'n schwindet; helfen wir dem siechen!", "tokens": ["Das", "An\u00b7seh'n", "schwin\u00b7det", ";", "hel\u00b7fen", "wir", "dem", "sie\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VVFIN", "PPER", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verz\u00f6gern br\u00e4chte schreckliche Gefahr.", "tokens": ["Ver\u00b7z\u00f6\u00b7gern", "br\u00e4ch\u00b7te", "schreck\u00b7li\u00b7che", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O lernet wieder auf dem Bauch zu kriechen", "tokens": ["O", "ler\u00b7net", "wie\u00b7der", "auf", "dem", "Bauch", "zu", "krie\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und katzebuckeln, wie es fr\u00fcher war.", "tokens": ["Und", "kat\u00b7ze\u00b7bu\u00b7ckeln", ",", "wie", "es", "fr\u00fc\u00b7her", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr werdet sehen, wie dies allen frommt,", "tokens": ["Ihr", "wer\u00b7det", "se\u00b7hen", ",", "wie", "dies", "al\u00b7len", "frommt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVINF", "$,", "PWAV", "PDS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und wie das deutsche Volk zu Ehren kommt.", "tokens": ["Und", "wie", "das", "deut\u00b7sche", "Volk", "zu", "Eh\u00b7ren", "kommt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "H\u00f6rt mich, den S\u00e4nger mit dem dumpfen Tone!", "tokens": ["H\u00f6rt", "mich", ",", "den", "S\u00e4n\u00b7ger", "mit", "dem", "dum\u00b7pfen", "To\u00b7ne", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "$,", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Stimme zittert und die Tr\u00e4ne rinnt:", "tokens": ["Die", "Stim\u00b7me", "zit\u00b7tert", "und", "die", "Tr\u00e4\u00b7ne", "rinnt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der, wo noch glaubt, die Menschen sind nicht ohne,", "tokens": ["Der", ",", "wo", "noch", "glaubt", ",", "die", "Men\u00b7schen", "sind", "nicht", "oh\u00b7ne", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ADV", "VVFIN", "$,", "ART", "NN", "VAFIN", "PTKNEG", "APPR", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihr B\u00fcrger, h\u00f6rt mich! \u2013 der ist falsch gesinnt.", "tokens": ["Ihr", "B\u00fcr\u00b7ger", ",", "h\u00f6rt", "mich", "!", "\u2013", "der", "ist", "falsch", "ge\u00b7sinnt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "$.", "$(", "PDS", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ich sag' euch heute nur so viel wie dies:", "tokens": ["Ich", "sag'", "euch", "heu\u00b7te", "nur", "so", "viel", "wie", "dies", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PIAT", "KOKOM", "PDS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das deutsche Volk ist wirklich \u00e4u\u00dferst mies.", "tokens": ["Das", "deut\u00b7sche", "Volk", "ist", "wirk\u00b7lich", "\u00e4u\u00b7\u00dferst", "mies", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Wo sind die Sitten? Wo die guten Zeiten,", "tokens": ["Wo", "sind", "die", "Sit\u00b7ten", "?", "Wo", "die", "gu\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$.", "PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da ganz submissest jedermann erstarb?", "tokens": ["Da", "ganz", "sub\u00b7mis\u00b7sest", "je\u00b7der\u00b7mann", "er\u00b7starb", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Im tiefsten Kote vor den F\u00fcrstlichkeiten", "tokens": ["Im", "tiefs\u00b7ten", "Ko\u00b7te", "vor", "den", "F\u00fcrst\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Devotest bittend um ein Gr\u00fc\u00dfchen warb?", "tokens": ["De\u00b7vo\u00b7test", "bit\u00b7tend", "um", "ein", "Gr\u00fc\u00df\u00b7chen", "warb", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fcr hohe Gnaden ist man nicht mehr reif,", "tokens": ["F\u00fcr", "ho\u00b7he", "Gna\u00b7den", "ist", "man", "nicht", "mehr", "reif", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "PIS", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und die Carnallje h\u00e4lt den Nacken steif.", "tokens": ["Und", "die", "Car\u00b7nall\u00b7je", "h\u00e4lt", "den", "Na\u00b7cken", "steif", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Begegnen heute uns des Hofes Chaisen", "tokens": ["Be\u00b7geg\u00b7nen", "heu\u00b7te", "uns", "des", "Ho\u00b7fes", "Chai\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u2013 Der J\u00e4ger vorne, hinten der Lakai \u2013,", "tokens": ["\u2013", "Der", "J\u00e4\u00b7ger", "vor\u00b7ne", ",", "hin\u00b7ten", "der", "La\u00b7kai", "\u2013", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "ADV", "$,", "ADV", "ART", "NN", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Tut mancher so, als w\u00e4r's ihm wurscht gewesen,", "tokens": ["Tut", "man\u00b7cher", "so", ",", "als", "w\u00e4r's", "ihm", "wurscht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PIAT", "ADV", "$,", "KOKOM", "VAFIN", "PPER", "VAFIN", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und fragt noch staunend: \u00bbWas ist da dabei?\u00ab", "tokens": ["Und", "fragt", "noch", "stau\u00b7nend", ":", "\u00bb", "Was", "ist", "da", "da\u00b7bei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$.", "$(", "PWS", "VAFIN", "ADV", "PAV", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "So merkt man deutlich, wie der Zeiten Zahn", "tokens": ["So", "merkt", "man", "deut\u00b7lich", ",", "wie", "der", "Zei\u00b7ten", "Zahn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "ADJD", "$,", "PWAV", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Bedenklich nagte an dem Untertan.", "tokens": ["Be\u00b7denk\u00b7lich", "nag\u00b7te", "an", "dem", "Un\u00b7ter\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Der F\u00fcrsten Worte waren einst geh\u00fctet", "tokens": ["Der", "F\u00fcrs\u00b7ten", "Wor\u00b7te", "wa\u00b7ren", "einst", "ge\u00b7h\u00fc\u00b7tet"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von der Beh\u00f6rde wie ein gold'ner Schatz,", "tokens": ["Von", "der", "Be\u00b7h\u00f6r\u00b7de", "wie", "ein", "gold'\u00b7ner", "Schatz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wurden laut in alle Welt get\u00fctet.", "tokens": ["Und", "wur\u00b7den", "laut", "in", "al\u00b7le", "Welt", "ge\u00b7t\u00fc\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADJD", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Heut' streicht man oft den allersch\u00f6nsten Satz.", "tokens": ["Heut'", "streicht", "man", "oft", "den", "al\u00b7ler\u00b7sch\u00f6ns\u00b7ten", "Satz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wenn von Beamten schon so was geschah,", "tokens": ["Wenn", "von", "Be\u00b7am\u00b7ten", "schon", "so", "was", "ge\u00b7schah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "ADV", "ADV", "PWS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was soll man denken? Und was sagt man da?", "tokens": ["Was", "soll", "man", "den\u00b7ken", "?", "Und", "was", "sagt", "man", "da", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PIS", "VVINF", "$.", "KON", "PWS", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Und erst die Jugend! O die deutsche Jugend!", "tokens": ["Und", "erst", "die", "Ju\u00b7gend", "!", "O", "die", "deut\u00b7sche", "Ju\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "NE", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein jeder jammert, der sie etwas kennt,", "tokens": ["Ein", "je\u00b7der", "jam\u00b7mert", ",", "der", "sie", "et\u00b7was", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie hat nicht diese, hat nicht jene Tugend", "tokens": ["Sie", "hat", "nicht", "die\u00b7se", ",", "hat", "nicht", "je\u00b7ne", "Tu\u00b7gend"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "PDS", "$,", "VAFIN", "PTKNEG", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und hat zum Hunnenkrieger kein Talent.", "tokens": ["Und", "hat", "zum", "Hun\u00b7nen\u00b7krie\u00b7ger", "kein", "Ta\u00b7lent", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf gute Lehren sagt sie h\u00f6chstens: \u00bbSchrumm!\u00ab", "tokens": ["Auf", "gu\u00b7te", "Leh\u00b7ren", "sagt", "sie", "h\u00f6chs\u00b7tens", ":", "\u00bb", "Schrumm", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$.", "$(", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ist schon lange nicht mehr halb so dumm.", "tokens": ["Und", "ist", "schon", "lan\u00b7ge", "nicht", "mehr", "halb", "so", "dumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "PTKNEG", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Das Anseh'n schwindet; helfen wir dem siechen!", "tokens": ["Das", "An\u00b7seh'n", "schwin\u00b7det", ";", "hel\u00b7fen", "wir", "dem", "sie\u00b7chen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "VVFIN", "PPER", "ART", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Verz\u00f6gern br\u00e4chte schreckliche Gefahr.", "tokens": ["Ver\u00b7z\u00f6\u00b7gern", "br\u00e4ch\u00b7te", "schreck\u00b7li\u00b7che", "Ge\u00b7fahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O lernet wieder auf dem Bauch zu kriechen", "tokens": ["O", "ler\u00b7net", "wie\u00b7der", "auf", "dem", "Bauch", "zu", "krie\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und katzebuckeln, wie es fr\u00fcher war.", "tokens": ["Und", "kat\u00b7ze\u00b7bu\u00b7ckeln", ",", "wie", "es", "fr\u00fc\u00b7her", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Ihr werdet sehen, wie dies allen frommt,", "tokens": ["Ihr", "wer\u00b7det", "se\u00b7hen", ",", "wie", "dies", "al\u00b7len", "frommt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVINF", "$,", "PWAV", "PDS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und wie das deutsche Volk zu Ehren kommt.", "tokens": ["Und", "wie", "das", "deut\u00b7sche", "Volk", "zu", "Eh\u00b7ren", "kommt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}