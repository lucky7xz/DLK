{"textgrid.poem.49722": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Jeanne d' Arc", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbnu is se selig,\u00ab sprach Herr Meier,", "tokens": ["\u00bb", "nu", "is", "se", "se\u00b7lig", ",", "\u00ab", "sprach", "Herr", "Mei\u00b7er", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "FM", "FM", "ADJD", "$,", "$(", "VVFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er in seiner Zeitung fand,", "tokens": ["Als", "er", "in", "sei\u00b7ner", "Zei\u00b7tung", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df man mit einer gro\u00dfen Feier", "tokens": ["Da\u00df", "man", "mit", "ei\u00b7ner", "gro\u00b7\u00dfen", "Fei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Johanna an den Himmel band.", "tokens": ["Jo\u00b7han\u00b7na", "an", "den", "Him\u00b7mel", "band", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbnu ja! Ich habe nischt dagegen,", "tokens": ["\u00bb", "nu", "ja", "!", "Ich", "ha\u00b7be", "nischt", "da\u00b7ge\u00b7gen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "PPER", "VAFIN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie soll nun endlich selig sein,", "tokens": ["Sie", "soll", "nun", "end\u00b7lich", "se\u00b7lig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dreimal heilig meinetwegen,", "tokens": ["Und", "drei\u00b7mal", "hei\u00b7lig", "mei\u00b7net\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Wunder wirken mits Jebein!", "tokens": ["Und", "Wun\u00b7der", "wir\u00b7ken", "mits", "Je\u00b7bein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wozu das in die Zeitung drucken?", "tokens": ["Wo\u00b7zu", "das", "in", "die", "Zei\u00b7tung", "dru\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind doch viel zu uffgekl\u00e4rt,", "tokens": ["Wir", "sind", "doch", "viel", "zu", "uff\u00b7ge\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um so was Altes noch zu schlucken,", "tokens": ["Um", "so", "was", "Al\u00b7tes", "noch", "zu", "schlu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PWS", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Ding hat lang genug gew\u00e4hrt!\u00ab", "tokens": ["Das", "Ding", "hat", "lang", "ge\u00b7nug", "ge\u00b7w\u00e4hrt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Sie sollten nicht dar\u00fcber lachen \u2013 \u2013", "tokens": ["Sie", "soll\u00b7ten", "nicht", "da\u00b7r\u00fc\u00b7ber", "la\u00b7chen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist ein bi\u00dfchen mehr daran;", "tokens": ["Es", "ist", "ein", "bi\u00df\u00b7chen", "mehr", "da\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIS", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Blo\u00df um 'ne Heilige zu machen,", "tokens": ["Blo\u00df", "um", "'ne", "Hei\u00b7li\u00b7ge", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Strengt sich die Kirche nicht mehr an.", "tokens": ["Strengt", "sich", "die", "Kir\u00b7che", "nicht", "mehr", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "Sie hat hier einen Trick gefunden,", "tokens": ["Sie", "hat", "hier", "ei\u00b7nen", "Trick", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil 's ihr schon lang am Herzen liegt,", "tokens": ["Weil", "'s", "ihr", "schon", "lang", "am", "Her\u00b7zen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie sie den Besten ihrer Kunden", "tokens": ["Wie", "sie", "den", "Bes\u00b7ten", "ih\u00b7rer", "Kun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ihren Laden wieder kriegt.", "tokens": ["In", "ih\u00b7ren", "La\u00b7den", "wie\u00b7der", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbnu is se selig,\u00ab sprach Herr Meier,", "tokens": ["\u00bb", "nu", "is", "se", "se\u00b7lig", ",", "\u00ab", "sprach", "Herr", "Mei\u00b7er", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "FM", "FM", "ADJD", "$,", "$(", "VVFIN", "NN", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er in seiner Zeitung fand,", "tokens": ["Als", "er", "in", "sei\u00b7ner", "Zei\u00b7tung", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df man mit einer gro\u00dfen Feier", "tokens": ["Da\u00df", "man", "mit", "ei\u00b7ner", "gro\u00b7\u00dfen", "Fei\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Johanna an den Himmel band.", "tokens": ["Jo\u00b7han\u00b7na", "an", "den", "Him\u00b7mel", "band", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "\u00bbnu ja! Ich habe nischt dagegen,", "tokens": ["\u00bb", "nu", "ja", "!", "Ich", "ha\u00b7be", "nischt", "da\u00b7ge\u00b7gen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "PPER", "VAFIN", "PTKNEG", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie soll nun endlich selig sein,", "tokens": ["Sie", "soll", "nun", "end\u00b7lich", "se\u00b7lig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und dreimal heilig meinetwegen,", "tokens": ["Und", "drei\u00b7mal", "hei\u00b7lig", "mei\u00b7net\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und Wunder wirken mits Jebein!", "tokens": ["Und", "Wun\u00b7der", "wir\u00b7ken", "mits", "Je\u00b7bein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "APPR", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wozu das in die Zeitung drucken?", "tokens": ["Wo\u00b7zu", "das", "in", "die", "Zei\u00b7tung", "dru\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir sind doch viel zu uffgekl\u00e4rt,", "tokens": ["Wir", "sind", "doch", "viel", "zu", "uff\u00b7ge\u00b7kl\u00e4rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um so was Altes noch zu schlucken,", "tokens": ["Um", "so", "was", "Al\u00b7tes", "noch", "zu", "schlu\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "PWS", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das Ding hat lang genug gew\u00e4hrt!\u00ab", "tokens": ["Das", "Ding", "hat", "lang", "ge\u00b7nug", "ge\u00b7w\u00e4hrt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie sollten nicht dar\u00fcber lachen \u2013 \u2013", "tokens": ["Sie", "soll\u00b7ten", "nicht", "da\u00b7r\u00fc\u00b7ber", "la\u00b7chen", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "PAV", "VVINF", "$(", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Es ist ein bi\u00dfchen mehr daran;", "tokens": ["Es", "ist", "ein", "bi\u00df\u00b7chen", "mehr", "da\u00b7ran", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PIS", "ADV", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Blo\u00df um 'ne Heilige zu machen,", "tokens": ["Blo\u00df", "um", "'ne", "Hei\u00b7li\u00b7ge", "zu", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Strengt sich die Kirche nicht mehr an.", "tokens": ["Strengt", "sich", "die", "Kir\u00b7che", "nicht", "mehr", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKNEG", "ADV", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Sie hat hier einen Trick gefunden,", "tokens": ["Sie", "hat", "hier", "ei\u00b7nen", "Trick", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil 's ihr schon lang am Herzen liegt,", "tokens": ["Weil", "'s", "ihr", "schon", "lang", "am", "Her\u00b7zen", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie sie den Besten ihrer Kunden", "tokens": ["Wie", "sie", "den", "Bes\u00b7ten", "ih\u00b7rer", "Kun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In ihren Laden wieder kriegt.", "tokens": ["In", "ih\u00b7ren", "La\u00b7den", "wie\u00b7der", "kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}