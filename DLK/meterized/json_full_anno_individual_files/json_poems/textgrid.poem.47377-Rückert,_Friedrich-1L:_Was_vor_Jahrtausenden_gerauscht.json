{"textgrid.poem.47377": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was vor Jahrtausenden gerauscht", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was vor Jahrtausenden gerauscht", "tokens": ["Was", "vor", "Jahr\u00b7tau\u00b7sen\u00b7den", "ge\u00b7rauscht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Wipfel ind'scher Palmen,", "tokens": ["Im", "Wip\u00b7fel", "in\u00b7d'\u00b7scher", "Pal\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie wird es heut von dir erlauscht", "tokens": ["Wie", "wird", "es", "heut", "von", "dir", "er\u00b7lauscht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Strohdach nord'scher Halmen!", "tokens": ["Im", "Stroh\u00b7dach", "nord'\u00b7scher", "Hal\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein Palmenblatt, vom Sturm verweht,", "tokens": ["Ein", "Pal\u00b7men\u00b7blatt", ",", "vom", "Sturm", "ver\u00b7weht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward hergef\u00fchrt von Schiffern,", "tokens": ["Ward", "her\u00b7ge\u00b7f\u00fchrt", "von", "Schif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und seinen heil'gen Schriftzug, seht,", "tokens": ["Und", "sei\u00b7nen", "heil'\u00b7gen", "Schrift\u00b7zug", ",", "seht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn lernt' ich zu entziffern.", "tokens": ["Ihn", "lernt'", "ich", "zu", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Darein ist ganz mein Geist versenkt,", "tokens": ["Da\u00b7rein", "ist", "ganz", "mein", "Geist", "ver\u00b7senkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der, ohne zu beachten,", "tokens": ["Der", ",", "oh\u00b7ne", "zu", "be\u00b7ach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was hier die Menschen thun, nur denkt,", "tokens": ["Was", "hier", "die", "Men\u00b7schen", "thun", ",", "nur", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was dort die Menschen dachten.", "tokens": ["Was", "dort", "die", "Men\u00b7schen", "dach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und so, wiewohl das Alte st\u00e4rkt,", "tokens": ["Und", "so", ",", "wie\u00b7wohl", "das", "Al\u00b7te", "st\u00e4rkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Neue zu verstehen,", "tokens": ["Das", "Neu\u00b7e", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wird doch viel Neues unbemerkt", "tokens": ["Wird", "doch", "viel", "Neu\u00b7es", "un\u00b7be\u00b7merkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An mir vor\u00fcbergehen.", "tokens": ["An", "mir", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Bemerken werden die es schon,", "tokens": ["Be\u00b7mer\u00b7ken", "wer\u00b7den", "die", "es", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die laut am Markte walten,", "tokens": ["Die", "laut", "am", "Mark\u00b7te", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vom Volk beklatscht; ein stiller Lohn", "tokens": ["Vom", "Volk", "be\u00b7klatscht", ";", "ein", "stil\u00b7ler", "Lohn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir doch vorbehalten.", "tokens": ["Ist", "mir", "doch", "vor\u00b7be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Da\u00df \u00fcber ihrer Bildung Gang", "tokens": ["Da\u00df", "\u00fc\u00b7ber", "ih\u00b7rer", "Bil\u00b7dung", "Gang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschheit sich verst\u00e4nd'ge,", "tokens": ["Die", "Menschheit", "sich", "ver\u00b7st\u00e4n\u00b7d'\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dazu wirkt jeder Urweltsklang,", "tokens": ["Da\u00b7zu", "wirkt", "je\u00b7der", "Ur\u00b7welt\u00b7sklang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den ich verdeutschend b\u00e4nd'ge.", "tokens": ["Den", "ich", "ver\u00b7deut\u00b7schend", "b\u00e4n\u00b7d'\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was vor Jahrtausenden gerauscht", "tokens": ["Was", "vor", "Jahr\u00b7tau\u00b7sen\u00b7den", "ge\u00b7rauscht"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "APPR", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Wipfel ind'scher Palmen,", "tokens": ["Im", "Wip\u00b7fel", "in\u00b7d'\u00b7scher", "Pal\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Wie wird es heut von dir erlauscht", "tokens": ["Wie", "wird", "es", "heut", "von", "dir", "er\u00b7lauscht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Strohdach nord'scher Halmen!", "tokens": ["Im", "Stroh\u00b7dach", "nord'\u00b7scher", "Hal\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ein Palmenblatt, vom Sturm verweht,", "tokens": ["Ein", "Pal\u00b7men\u00b7blatt", ",", "vom", "Sturm", "ver\u00b7weht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward hergef\u00fchrt von Schiffern,", "tokens": ["Ward", "her\u00b7ge\u00b7f\u00fchrt", "von", "Schif\u00b7fern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und seinen heil'gen Schriftzug, seht,", "tokens": ["Und", "sei\u00b7nen", "heil'\u00b7gen", "Schrift\u00b7zug", ",", "seht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihn lernt' ich zu entziffern.", "tokens": ["Ihn", "lernt'", "ich", "zu", "ent\u00b7zif\u00b7fern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Darein ist ganz mein Geist versenkt,", "tokens": ["Da\u00b7rein", "ist", "ganz", "mein", "Geist", "ver\u00b7senkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der, ohne zu beachten,", "tokens": ["Der", ",", "oh\u00b7ne", "zu", "be\u00b7ach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was hier die Menschen thun, nur denkt,", "tokens": ["Was", "hier", "die", "Men\u00b7schen", "thun", ",", "nur", "denkt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVINF", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was dort die Menschen dachten.", "tokens": ["Was", "dort", "die", "Men\u00b7schen", "dach\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Und so, wiewohl das Alte st\u00e4rkt,", "tokens": ["Und", "so", ",", "wie\u00b7wohl", "das", "Al\u00b7te", "st\u00e4rkt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Neue zu verstehen,", "tokens": ["Das", "Neu\u00b7e", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wird doch viel Neues unbemerkt", "tokens": ["Wird", "doch", "viel", "Neu\u00b7es", "un\u00b7be\u00b7merkt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An mir vor\u00fcbergehen.", "tokens": ["An", "mir", "vor\u00b7\u00fc\u00b7ber\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Bemerken werden die es schon,", "tokens": ["Be\u00b7mer\u00b7ken", "wer\u00b7den", "die", "es", "schon", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die laut am Markte walten,", "tokens": ["Die", "laut", "am", "Mark\u00b7te", "wal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vom Volk beklatscht; ein stiller Lohn", "tokens": ["Vom", "Volk", "be\u00b7klatscht", ";", "ein", "stil\u00b7ler", "Lohn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist mir doch vorbehalten.", "tokens": ["Ist", "mir", "doch", "vor\u00b7be\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Da\u00df \u00fcber ihrer Bildung Gang", "tokens": ["Da\u00df", "\u00fc\u00b7ber", "ih\u00b7rer", "Bil\u00b7dung", "Gang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschheit sich verst\u00e4nd'ge,", "tokens": ["Die", "Menschheit", "sich", "ver\u00b7st\u00e4n\u00b7d'\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Dazu wirkt jeder Urweltsklang,", "tokens": ["Da\u00b7zu", "wirkt", "je\u00b7der", "Ur\u00b7welt\u00b7sklang", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den ich verdeutschend b\u00e4nd'ge.", "tokens": ["Den", "ich", "ver\u00b7deut\u00b7schend", "b\u00e4n\u00b7d'\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVPP", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}