{"dta.poem.20506": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Verliebte Arien.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Dorinde soll ich denn verbrennen/", "tokens": ["Do\u00b7rin\u00b7de", "soll", "ich", "denn", "ver\u00b7bren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und gar zu aschen seyn gemacht/", "tokens": ["Und", "gar", "zu", "asc\u00b7hen", "seyn", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich mu\u00df dich endlich grausam nennen/", "tokens": ["Ich", "mu\u00df", "dich", "end\u00b7lich", "grau\u00b7sam", "nen\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ob sonst dein wesen lieblich lacht;", "tokens": ["Ob", "sonst", "dein", "we\u00b7sen", "lieb\u00b7lich", "lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Theils wilstu sch\u00f6nen rosen gleichen/", "tokens": ["Theils", "wils\u00b7tu", "sch\u00f6\u00b7nen", "ro\u00b7sen", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "VVINF", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Theils auch den nesseln selbst nicht weichen.", "tokens": ["Theils", "auch", "den", "nes\u00b7seln", "selbst", "nicht", "wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "+----+-+-", "measure": "dactylic.init"}}, "stanza.2": {"line.1": {"text": "Dein auge will magnetisch heissen/", "tokens": ["Dein", "au\u00b7ge", "will", "mag\u00b7ne\u00b7tisch", "heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dein sinn ist gar ein demant-stein/", "tokens": ["Dein", "sinn", "ist", "gar", "ein", "de\u00b7mant\u00b7stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dein antlitz will vom feuer gleissen/", "tokens": ["Dein", "ant\u00b7litz", "will", "vom", "feu\u00b7er", "gleis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dein hertze ey\u00df und eisen seyn/", "tokens": ["Dein", "hert\u00b7ze", "ey\u00df", "und", "ei\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "KON", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dein blick/ darff ich dich recht abmahlen/", "tokens": ["Dein", "blick", "/", "darff", "ich", "dich", "recht", "ab\u00b7mah\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "VMFIN", "PPER", "PRF", "ADJD", "VVINF", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.6": {"text": "Hegt was von basilisken strahlen.", "tokens": ["Hegt", "was", "von", "ba\u00b7si\u00b7lis\u00b7ken", "strah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.3": {"line.1": {"text": "Verzeihe/ wo ich was verbreche/", "tokens": ["Ver\u00b7zei\u00b7he", "/", "wo", "ich", "was", "ver\u00b7bre\u00b7che", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAV", "PPER", "PIS", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Denn ein verliebter irret leicht/", "tokens": ["Denn", "ein", "ver\u00b7lieb\u00b7ter", "ir\u00b7ret", "leicht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wo ich zu harte worte spreche/", "tokens": ["Wo", "ich", "zu", "har\u00b7te", "wor\u00b7te", "spre\u00b7che", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "So hat sie deine h\u00e4rt gezeugt;", "tokens": ["So", "hat", "sie", "dei\u00b7ne", "h\u00e4rt", "ge\u00b7zeugt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erwege selbst/ ob deine sinnen", "tokens": ["Er\u00b7we\u00b7ge", "selbst", "/", "ob", "dei\u00b7ne", "sin\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ADV", "$(", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Durch einen seuffzer zu gewinnen.", "tokens": ["Durch", "ei\u00b7nen", "seuff\u00b7zer", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Man schl\u00e4gt auff einem weichen k\u00fcssen", "tokens": ["Man", "schl\u00e4gt", "auff", "ei\u00b7nem", "wei\u00b7chen", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den h\u00e4rtsten feuerstein entzwey/", "tokens": ["Den", "h\u00e4rts\u00b7ten", "feu\u00b7ers\u00b7tein", "ent\u00b7zwey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die perle pfleget zu zerfliessen/", "tokens": ["Die", "per\u00b7le", "pfle\u00b7get", "zu", "zer\u00b7flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bringt man ihr scharffen e\u00dfig bey/", "tokens": ["Bringt", "man", "ihr", "scharf\u00b7fen", "e\u00b7\u00dfig", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "VVFIN", "ADJD", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und meiner thr\u00e4nen heisser regen", "tokens": ["Und", "mei\u00b7ner", "thr\u00e4\u00b7nen", "heis\u00b7ser", "re\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "ADJA", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Kan dich Dorinde nicht bewegen.", "tokens": ["Kan", "dich", "Do\u00b7rin\u00b7de", "nicht", "be\u00b7we\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "NE", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Dorinde habe denn erbarmen/", "tokens": ["Do\u00b7rin\u00b7de", "ha\u00b7be", "denn", "er\u00b7bar\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und sey nicht meine m\u00f6rderinn/", "tokens": ["Und", "sey", "nicht", "mei\u00b7ne", "m\u00f6r\u00b7de\u00b7rinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was qv\u00e4lt dein sch\u00f6ner grimm mich armen/", "tokens": ["Was", "qv\u00e4lt", "dein", "sch\u00f6\u00b7ner", "grimm", "mich", "ar\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPOSAT", "ADJA", "VVFIN", "PPER", "ADJA", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der ich bereits ein schatten bin/", "tokens": ["Der", "ich", "be\u00b7reits", "ein", "schat\u00b7ten", "bin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Verwandle doch dein ey\u00df in flammen/", "tokens": ["Ver\u00b7wand\u00b7le", "doch", "dein", "ey\u00df", "in", "flam\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und schlag mit meiner glut zusammen.", "tokens": ["Und", "schlag", "mit", "mei\u00b7ner", "glut", "zu\u00b7sam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Als g\u00f6ttin will ich dich verehren/", "tokens": ["Als", "g\u00f6t\u00b7tin", "will", "ich", "dich", "ver\u00b7eh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VMFIN", "PPER", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Nimm nur mein hertz zum weyrauch an/", "tokens": ["Nimm", "nur", "mein", "hertz", "zum", "wey\u00b7rauch", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PPOSAT", "NN", "APPRART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und la\u00df das f\u00fcsse wort mich h\u00f6ren:", "tokens": ["Und", "la\u00df", "das", "f\u00fcs\u00b7se", "wort", "mich", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Das man gehaste lieben kan/", "tokens": ["Das", "man", "ge\u00b7has\u00b7te", "lie\u00b7ben", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "ADJA", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wirstu recht der sonne gleichen/", "tokens": ["So", "wirs\u00b7tu", "recht", "der", "son\u00b7ne", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die schw\u00e4rtzen kan und wieder bleichen.", "tokens": ["Die", "schw\u00e4rt\u00b7zen", "kan", "und", "wie\u00b7der", "blei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "KON", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}