{"textgrid.poem.64206": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Cuculus Canorus", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Noch liegt ein leiser Hauch von Schnee", "tokens": ["Noch", "liegt", "ein", "lei\u00b7ser", "Hauch", "von", "Schnee"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hoch in des Bergwalds Schatten:", "tokens": ["Hoch", "in", "des", "Berg\u00b7walds", "Schat\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch warm schon auf die Matten,", "tokens": ["Doch", "warm", "schon", "auf", "die", "Mat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom sonn'gen B\u00fchl herab zum See,", "tokens": ["Vom", "sonn'\u00b7gen", "B\u00fchl", "her\u00b7ab", "zum", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Scheint der April so helle:", "tokens": ["Scheint", "der", "Ap\u00b7ril", "so", "hel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJA", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Hinfort! Aus finstrer Zelle!", "tokens": ["Hin\u00b7fort", "!", "Aus", "finst\u00b7rer", "Zel\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ei sieh! Ihr gl\u00e4nzt am alten Ort,", "tokens": ["Ei", "sieh", "!", "Ihr", "gl\u00e4nzt", "am", "al\u00b7ten", "Ort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr goldnes Fr\u00fchlingsw\u00f6lklein,", "tokens": ["Ihr", "gold\u00b7nes", "Fr\u00fch\u00b7lings\u00b7w\u00f6lk\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Schl\u00fcsselblumenv\u00f6lklein:", "tokens": ["Ihr", "Schl\u00fcs\u00b7sel\u00b7blu\u00b7men\u00b7v\u00f6l\u00b7klein", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Als Knabe schon brach ich euch dort:", "tokens": ["Als", "Kna\u00b7be", "schon", "brach", "ich", "euch", "dort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Drum la\u00dft's euch nicht gereuen,", "tokens": ["Drum", "la\u00dft's", "euch", "nicht", "ge\u00b7reu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Den Graubart zu erfreuen.", "tokens": ["Den", "Grau\u00b7bart", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Hier stand ich einst \u2013 ich wei\u00df den Tag \u2013", "tokens": ["Hier", "stand", "ich", "einst", "\u2013", "ich", "wei\u00df", "den", "Tag", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sann, wie lang's noch w\u00e4hre,", "tokens": ["Und", "sann", ",", "wie", "lang's", "noch", "w\u00e4h\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bis da\u00df mir Siegesehre", "tokens": ["Bis", "da\u00df", "mir", "Sie\u00b7ge\u00b7seh\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erw\u00fcrbe meiner Harfe Schlag, \u2013", "tokens": ["Er\u00b7w\u00fcr\u00b7be", "mei\u00b7ner", "Har\u00b7fe", "Schlag", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als aus des Bergwalds Tiefen", "tokens": ["Als", "aus", "des", "Berg\u00b7walds", "Tie\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zwei Kuckuck pl\u00f6tzlich riefen.", "tokens": ["Zwei", "Ku\u00b7ckuck", "pl\u00f6tz\u00b7lich", "rie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "\u00bbei, zukunftweiser Vogelmund,\u00ab", "tokens": ["\u00bb", "ei", ",", "zu\u00b7kunft\u00b7wei\u00b7ser", "Vo\u00b7gel\u00b7mund", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So fragt' ich bei den zweien \u2013", "tokens": ["So", "fragt'", "ich", "bei", "den", "zwei\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "CARD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbnun sollt ihr prophezeien!", "tokens": ["\u00bb", "nun", "sollt", "ihr", "pro\u00b7phe\u00b7zei\u00b7en", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie viele Jahr noch \u2013 tut mir's kund! \u2013", "tokens": ["Wie", "vie\u00b7le", "Jahr", "noch", "\u2013", "tut", "mir's", "kund", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "$(", "VVFIN", "NE", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis eine Frau viel sch\u00f6ne", "tokens": ["Bis", "ei\u00b7ne", "Frau", "viel", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mit S\u00e4ngerkranz mich kr\u00f6ne?\u00ab", "tokens": ["Mit", "S\u00e4n\u00b7ger\u00b7kranz", "mich", "kr\u00f6\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Eins \u2013 zwei \u2013 und drei! \u2013 Da ward es still:", "tokens": ["Eins", "\u2013", "zwei", "\u2013", "und", "drei", "!", "\u2013", "Da", "ward", "es", "still", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "CARD", "$(", "KON", "CARD", "$.", "$(", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Laut mehr scholl vom Walde.", "tokens": ["Kein", "Laut", "mehr", "scholl", "vom", "Wal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich jauchzte: \u00bbWie? So balde!", "tokens": ["Ich", "jauchz\u00b7te", ":", "\u00bb", "Wie", "?", "So", "bal\u00b7de", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWAV", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch heut' hebt an der Schalk April,", "tokens": ["Doch", "heut'", "hebt", "an", "der", "Schalk", "Ap\u00b7ril", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da mag es wohl sich f\u00fcgen,", "tokens": ["Da", "mag", "es", "wohl", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df lose V\u00f6gel l\u00fcgen.\u00ab", "tokens": ["Da\u00df", "lo\u00b7se", "V\u00f6\u00b7gel", "l\u00fc\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Doch nein! Die V\u00f6gel logen nicht:", "tokens": ["Doch", "nein", "!", "Die", "V\u00f6\u00b7gel", "lo\u00b7gen", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch schwanden nicht drei Jahre,", "tokens": ["Noch", "schwan\u00b7den", "nicht", "drei", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da lag im braunen Haare", "tokens": ["Da", "lag", "im", "brau\u00b7nen", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Kranz mir f\u00fcr mein Lenzgedicht:", "tokens": ["Ein", "Kranz", "mir", "f\u00fcr", "mein", "Lenz\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mehr Gl\u00fcck als laute Preise", "tokens": ["Mehr", "Gl\u00fcck", "als", "lau\u00b7te", "Prei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KOKOM", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bot mir die Herrin leise.", "tokens": ["Bot", "mir", "die", "Her\u00b7rin", "lei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.7": {"line.1": {"text": "Hier ist der Ort: heut' liegt er still:", "tokens": ["Hier", "ist", "der", "Ort", ":", "heut'", "liegt", "er", "still", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Laut sonst durch alle Str\u00e4uche", "tokens": ["Laut", "sonst", "durch", "al\u00b7le", "Str\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "PIAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ertost der Ruf der G\u00e4uche:", "tokens": ["Er\u00b7tost", "der", "Ruf", "der", "G\u00e4u\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Heut' schweigt er, da ich forschen will,", "tokens": ["Heut'", "schweigt", "er", ",", "da", "ich", "for\u00b7schen", "will", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u2013 Nicht mein noch \u00fcbrig Alter:", "tokens": ["\u2013", "Nicht", "mein", "noch", "\u00fcb\u00b7rig", "Al\u00b7ter", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "PPOSAT", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zum Tod bereit steht Walther. \u2013", "tokens": ["Zum", "Tod", "be\u00b7reit", "steht", "Walt\u00b7her", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Nein: wie viel Jahr nach Walthers Tod", "tokens": ["Nein", ":", "wie", "viel", "Jahr", "nach", "Walt\u00b7hers", "Tod"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "PWAV", "PIAT", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch Walthers Lieder leben?", "tokens": ["Noch", "Walt\u00b7hers", "Lie\u00b7der", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hei Gott! Da ruft er eben!", "tokens": ["Hei", "Gott", "!", "Da", "ruft", "er", "e\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das schallt, das hallt! Nun hat's nicht Not.", "tokens": ["Das", "schallt", ",", "das", "hallt", "!", "Nun", "hat's", "nicht", "Not", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PDS", "VVFIN", "$.", "ADV", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Viel hundert! Schweig, du Chorus!", "tokens": ["Viel", "hun\u00b7dert", "!", "Schweig", ",", "du", "Cho\u00b7rus", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "CARD", "$.", "VVFIN", "$,", "PPER", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Dank, Cuculus Canorus!", "tokens": ["Dank", ",", "Cu\u00b7cu\u00b7lus", "Ca\u00b7no\u00b7rus", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Noch liegt ein leiser Hauch von Schnee", "tokens": ["Noch", "liegt", "ein", "lei\u00b7ser", "Hauch", "von", "Schnee"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hoch in des Bergwalds Schatten:", "tokens": ["Hoch", "in", "des", "Berg\u00b7walds", "Schat\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch warm schon auf die Matten,", "tokens": ["Doch", "warm", "schon", "auf", "die", "Mat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom sonn'gen B\u00fchl herab zum See,", "tokens": ["Vom", "sonn'\u00b7gen", "B\u00fchl", "her\u00b7ab", "zum", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Scheint der April so helle:", "tokens": ["Scheint", "der", "Ap\u00b7ril", "so", "hel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJA", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "Hinfort! Aus finstrer Zelle!", "tokens": ["Hin\u00b7fort", "!", "Aus", "finst\u00b7rer", "Zel\u00b7le", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ei sieh! Ihr gl\u00e4nzt am alten Ort,", "tokens": ["Ei", "sieh", "!", "Ihr", "gl\u00e4nzt", "am", "al\u00b7ten", "Ort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr goldnes Fr\u00fchlingsw\u00f6lklein,", "tokens": ["Ihr", "gold\u00b7nes", "Fr\u00fch\u00b7lings\u00b7w\u00f6lk\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Schl\u00fcsselblumenv\u00f6lklein:", "tokens": ["Ihr", "Schl\u00fcs\u00b7sel\u00b7blu\u00b7men\u00b7v\u00f6l\u00b7klein", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Als Knabe schon brach ich euch dort:", "tokens": ["Als", "Kna\u00b7be", "schon", "brach", "ich", "euch", "dort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Drum la\u00dft's euch nicht gereuen,", "tokens": ["Drum", "la\u00dft's", "euch", "nicht", "ge\u00b7reu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Den Graubart zu erfreuen.", "tokens": ["Den", "Grau\u00b7bart", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Hier stand ich einst \u2013 ich wei\u00df den Tag \u2013", "tokens": ["Hier", "stand", "ich", "einst", "\u2013", "ich", "wei\u00df", "den", "Tag", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$(", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und sann, wie lang's noch w\u00e4hre,", "tokens": ["Und", "sann", ",", "wie", "lang's", "noch", "w\u00e4h\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bis da\u00df mir Siegesehre", "tokens": ["Bis", "da\u00df", "mir", "Sie\u00b7ge\u00b7seh\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PPER", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Erw\u00fcrbe meiner Harfe Schlag, \u2013", "tokens": ["Er\u00b7w\u00fcr\u00b7be", "mei\u00b7ner", "Har\u00b7fe", "Schlag", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als aus des Bergwalds Tiefen", "tokens": ["Als", "aus", "des", "Berg\u00b7walds", "Tie\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zwei Kuckuck pl\u00f6tzlich riefen.", "tokens": ["Zwei", "Ku\u00b7ckuck", "pl\u00f6tz\u00b7lich", "rie\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbei, zukunftweiser Vogelmund,\u00ab", "tokens": ["\u00bb", "ei", ",", "zu\u00b7kunft\u00b7wei\u00b7ser", "Vo\u00b7gel\u00b7mund", ",", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ITJ", "$,", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So fragt' ich bei den zweien \u2013", "tokens": ["So", "fragt'", "ich", "bei", "den", "zwei\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "CARD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbnun sollt ihr prophezeien!", "tokens": ["\u00bb", "nun", "sollt", "ihr", "pro\u00b7phe\u00b7zei\u00b7en", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie viele Jahr noch \u2013 tut mir's kund! \u2013", "tokens": ["Wie", "vie\u00b7le", "Jahr", "noch", "\u2013", "tut", "mir's", "kund", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADV", "$(", "VVFIN", "NE", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis eine Frau viel sch\u00f6ne", "tokens": ["Bis", "ei\u00b7ne", "Frau", "viel", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Mit S\u00e4ngerkranz mich kr\u00f6ne?\u00ab", "tokens": ["Mit", "S\u00e4n\u00b7ger\u00b7kranz", "mich", "kr\u00f6\u00b7ne", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Eins \u2013 zwei \u2013 und drei! \u2013 Da ward es still:", "tokens": ["Eins", "\u2013", "zwei", "\u2013", "und", "drei", "!", "\u2013", "Da", "ward", "es", "still", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "CARD", "$(", "KON", "CARD", "$.", "$(", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Laut mehr scholl vom Walde.", "tokens": ["Kein", "Laut", "mehr", "scholl", "vom", "Wal\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "APPR", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich jauchzte: \u00bbWie? So balde!", "tokens": ["Ich", "jauchz\u00b7te", ":", "\u00bb", "Wie", "?", "So", "bal\u00b7de", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWAV", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch heut' hebt an der Schalk April,", "tokens": ["Doch", "heut'", "hebt", "an", "der", "Schalk", "Ap\u00b7ril", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da mag es wohl sich f\u00fcgen,", "tokens": ["Da", "mag", "es", "wohl", "sich", "f\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Da\u00df lose V\u00f6gel l\u00fcgen.\u00ab", "tokens": ["Da\u00df", "lo\u00b7se", "V\u00f6\u00b7gel", "l\u00fc\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Doch nein! Die V\u00f6gel logen nicht:", "tokens": ["Doch", "nein", "!", "Die", "V\u00f6\u00b7gel", "lo\u00b7gen", "nicht", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "ART", "NN", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch schwanden nicht drei Jahre,", "tokens": ["Noch", "schwan\u00b7den", "nicht", "drei", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da lag im braunen Haare", "tokens": ["Da", "lag", "im", "brau\u00b7nen", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Kranz mir f\u00fcr mein Lenzgedicht:", "tokens": ["Ein", "Kranz", "mir", "f\u00fcr", "mein", "Lenz\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mehr Gl\u00fcck als laute Preise", "tokens": ["Mehr", "Gl\u00fcck", "als", "lau\u00b7te", "Prei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KOKOM", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Bot mir die Herrin leise.", "tokens": ["Bot", "mir", "die", "Her\u00b7rin", "lei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.15": {"line.1": {"text": "Hier ist der Ort: heut' liegt er still:", "tokens": ["Hier", "ist", "der", "Ort", ":", "heut'", "liegt", "er", "still", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Laut sonst durch alle Str\u00e4uche", "tokens": ["Laut", "sonst", "durch", "al\u00b7le", "Str\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "PIAT", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ertost der Ruf der G\u00e4uche:", "tokens": ["Er\u00b7tost", "der", "Ruf", "der", "G\u00e4u\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Heut' schweigt er, da ich forschen will,", "tokens": ["Heut'", "schweigt", "er", ",", "da", "ich", "for\u00b7schen", "will", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "\u2013 Nicht mein noch \u00fcbrig Alter:", "tokens": ["\u2013", "Nicht", "mein", "noch", "\u00fcb\u00b7rig", "Al\u00b7ter", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKNEG", "PPOSAT", "ADV", "ADJD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Zum Tod bereit steht Walther. \u2013", "tokens": ["Zum", "Tod", "be\u00b7reit", "steht", "Walt\u00b7her", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVFIN", "NE", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Nein: wie viel Jahr nach Walthers Tod", "tokens": ["Nein", ":", "wie", "viel", "Jahr", "nach", "Walt\u00b7hers", "Tod"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "PWAV", "PIAT", "NN", "APPR", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Noch Walthers Lieder leben?", "tokens": ["Noch", "Walt\u00b7hers", "Lie\u00b7der", "le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hei Gott! Da ruft er eben!", "tokens": ["Hei", "Gott", "!", "Da", "ruft", "er", "e\u00b7ben", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das schallt, das hallt! Nun hat's nicht Not.", "tokens": ["Das", "schallt", ",", "das", "hallt", "!", "Nun", "hat's", "nicht", "Not", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "PDS", "VVFIN", "$.", "ADV", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Viel hundert! Schweig, du Chorus!", "tokens": ["Viel", "hun\u00b7dert", "!", "Schweig", ",", "du", "Cho\u00b7rus", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "CARD", "$.", "VVFIN", "$,", "PPER", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Dank, Cuculus Canorus!", "tokens": ["Dank", ",", "Cu\u00b7cu\u00b7lus", "Ca\u00b7no\u00b7rus", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NE", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}