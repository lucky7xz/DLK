{"textgrid.poem.53990": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "In aller Eile", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u2013 \u00bbAlso ich telefoniere hier von der Post \u2013", "tokens": ["\u2013", "\u00bb", "Al\u00b7so", "ich", "te\u00b7le\u00b7fo\u00b7nie\u00b7re", "hier", "von", "der", "Post", "\u2013"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "ADV", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "+-+---+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "vor der Zelle stehn schon Leute \u2013", "tokens": ["vor", "der", "Zel\u00b7le", "stehn", "schon", "Leu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ich fahre nach Lichterfelde-Ost", "tokens": ["ich", "fah\u00b7re", "nach", "Lich\u00b7ter\u00b7fel\u00b7de\u00b7Ost"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und erledige die Sache noch heute.", "tokens": ["und", "er\u00b7le\u00b7di\u00b7ge", "die", "Sa\u00b7che", "noch", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Was ich sagen wollte . . . Warum warn Sie gestern nicht da?", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "Wa\u00b7rum", "warn", "Sie", "ge\u00b7stern", "nicht", "da", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PWAV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "auf der Modenschau?", "tokens": ["auf", "der", "Mo\u00b7den\u00b7schau", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Ich war mit der Putti . . . wissen Sie . . . na . . .", "tokens": ["Ich", "war", "mit", "der", "Put\u00b7ti", ".", ".", ".", "wis\u00b7sen", "Sie", ".", ".", ".", "na", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "$.", "$.", "$.", "VVFIN", "PPER", "$.", "$.", "$.", "ITJ", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "H\u00e4nde hat die Frau \u2013!", "tokens": ["H\u00e4n\u00b7de", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.2": {"line.1": {"text": "Wiesner \u2013? Erz\u00e4hlen Sie mir doch nichts \u2013", "tokens": ["Wies\u00b7ner", "\u2013", "?", "Er\u00b7z\u00e4h\u00b7len", "Sie", "mir", "doch", "nichts", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "$.", "NN", "PPER", "PPER", "ADV", "PIS", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "das nehm ich auf mein Eid \u2013!", "tokens": ["das", "nehm", "ich", "auf", "mein", "Eid", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bitte! Nach Ansicht des Gerichts", "tokens": ["Bit\u00b7te", "!", "Nach", "An\u00b7sicht", "des", "Ge\u00b7richts"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "APPR", "NN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "hab ich dazu immer noch Zeit!", "tokens": ["hab", "ich", "da\u00b7zu", "im\u00b7mer", "noch", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "ADV", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Was ich sagen wollte . . . Wir gehn Sonnabend aus \u2013", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "Wir", "gehn", "Sonn\u00b7a\u00b7bend", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VVFIN", "NN", "PTKVZ", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mit ihrem Freund? Na, so blau!", "tokens": ["Mit", "ih\u00b7rem", "Freund", "?", "Na", ",", "so", "blau", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ITJ", "$,", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Die nehm ich glatt mit mir nach Haus \u2013", "tokens": ["Die", "nehm", "ich", "glatt", "mit", "mir", "nach", "Haus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Augen hat die Frau \u2013!", "tokens": ["Au\u00b7gen", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Die Wechsel sind . . . na, wie finden Sie das?", "tokens": ["Die", "Wech\u00b7sel", "sind", ".", ".", ".", "na", ",", "wie", "fin\u00b7den", "Sie", "das", "?"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "$.", "$.", "ITJ", "$,", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die klopfen ans Fenster, weil ich", "tokens": ["Die", "klop\u00b7fen", "ans", "Fens\u00b7ter", ",", "weil", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "$,", "KOUS", "PPER"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "hier spreche \u2013 ich erz\u00e4hl Ihnen pers\u00f6nlich noch was,", "tokens": ["hier", "spre\u00b7che", "\u2013", "ich", "er\u00b7z\u00e4hl", "Ih\u00b7nen", "per\u00b7s\u00f6n\u00b7lich", "noch", "was", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "ADV", "PIS", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "ich bin n\u00e4mlich furchtbar eilig.", "tokens": ["ich", "bin", "n\u00e4m\u00b7lich", "furcht\u00b7bar", "ei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ich sagen wollte . . . ich bin derartig scharf . . .", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "ich", "bin", "der\u00b7ar\u00b7tig", "scharf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VAFIN", "ADJD", "VVFIN", "$.", "$.", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Nat\u00fcrlich! Wei\u00df ich genau,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "!", "Wei\u00df", "ich", "ge\u00b7nau", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "was ein Schentelm\u00e4n sich erlauben darf . . .", "tokens": ["was", "ein", "Schen\u00b7tel\u00b7m\u00e4n", "sich", "er\u00b7lau\u00b7ben", "darf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "ART", "NN", "PRF", "VVINF", "VMFIN", "$.", "$.", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Einen R\u00fccken hat die Frau \u2013!", "tokens": ["Ei\u00b7nen", "R\u00fc\u00b7cken", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.4": {"line.1": {"text": "Wir legen die Schecks . . . hallo? . . . unterbrochen . . .", "tokens": ["Wir", "le\u00b7gen", "die", "Schecks", ".", ".", ".", "hal\u00b7lo", "?", ".", ".", ".", "un\u00b7ter\u00b7bro\u00b7chen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$.", "$.", "FM.la", "$.", "$.", "$.", "$.", "VVPP", "$.", "$.", "$."], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich habe doch noch gar nicht gesprochen . . . !", "tokens": ["Ich", "ha\u00b7be", "doch", "noch", "gar", "nicht", "ge\u00b7spro\u00b7chen", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PTKNEG", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Na, denn nicht.", "tokens": ["Na", ",", "denn", "nicht", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PTKNEG", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nur keine falsche Hast!", "tokens": ["Nur", "kei\u00b7ne", "fal\u00b7sche", "Hast", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich spreche hier, solange 's mir pa\u00dft!", "tokens": ["Ich", "spre\u00b7che", "hier", ",", "so\u00b7lan\u00b7ge", "'s", "mir", "pa\u00dft", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "L\u00fcmmel.", "tokens": ["L\u00fcm\u00b7mel", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Ja \u2013! Nein \u2013!", "tokens": ["Ja", "\u2013", "!", "Nein", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["PTKANT", "$(", "$.", "PTKANT", "$(", "$."], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Na, da gehn Sie doch rein!", "tokens": ["Na", ",", "da", "gehn", "Sie", "doch", "rein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Eine Luft wie in einem Schwitzkastenbad . . .", "tokens": ["Ei\u00b7ne", "Luft", "wie", "in", "ei\u00b7nem", "Schwitz\u00b7kas\u00b7ten\u00b7bad", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "ART", "NN", "$.", "$.", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Was der schon zu telefonieren hat \u2013", "tokens": ["Was", "der", "schon", "zu", "te\u00b7le\u00b7fo\u00b7nie\u00b7ren", "hat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADV", "PTKZU", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "L\u00fcmmel.\u00ab", "tokens": ["L\u00fcm\u00b7mel", ".", "\u00ab"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}, "stanza.5": {"line.1": {"text": "\u2013 \u00bbAlso ich telefoniere hier von der Post \u2013", "tokens": ["\u2013", "\u00bb", "Al\u00b7so", "ich", "te\u00b7le\u00b7fo\u00b7nie\u00b7re", "hier", "von", "der", "Post", "\u2013"], "token_info": ["punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "$(", "ADV", "PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$("], "meter": "+-+---+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "vor der Zelle stehn schon Leute \u2013", "tokens": ["vor", "der", "Zel\u00b7le", "stehn", "schon", "Leu\u00b7te", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ich fahre nach Lichterfelde-Ost", "tokens": ["ich", "fah\u00b7re", "nach", "Lich\u00b7ter\u00b7fel\u00b7de\u00b7Ost"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und erledige die Sache noch heute.", "tokens": ["und", "er\u00b7le\u00b7di\u00b7ge", "die", "Sa\u00b7che", "noch", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Was ich sagen wollte . . . Warum warn Sie gestern nicht da?", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "Wa\u00b7rum", "warn", "Sie", "ge\u00b7stern", "nicht", "da", "?"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PWAV", "VAFIN", "PPER", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "auf der Modenschau?", "tokens": ["auf", "der", "Mo\u00b7den\u00b7schau", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Ich war mit der Putti . . . wissen Sie . . . na . . .", "tokens": ["Ich", "war", "mit", "der", "Put\u00b7ti", ".", ".", ".", "wis\u00b7sen", "Sie", ".", ".", ".", "na", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "$.", "$.", "$.", "VVFIN", "PPER", "$.", "$.", "$.", "ITJ", "$.", "$.", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "H\u00e4nde hat die Frau \u2013!", "tokens": ["H\u00e4n\u00b7de", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Wiesner \u2013? Erz\u00e4hlen Sie mir doch nichts \u2013", "tokens": ["Wies\u00b7ner", "\u2013", "?", "Er\u00b7z\u00e4h\u00b7len", "Sie", "mir", "doch", "nichts", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "$.", "NN", "PPER", "PPER", "ADV", "PIS", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "das nehm ich auf mein Eid \u2013!", "tokens": ["das", "nehm", "ich", "auf", "mein", "Eid", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$(", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bitte! Nach Ansicht des Gerichts", "tokens": ["Bit\u00b7te", "!", "Nach", "An\u00b7sicht", "des", "Ge\u00b7richts"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$.", "APPR", "NN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "hab ich dazu immer noch Zeit!", "tokens": ["hab", "ich", "da\u00b7zu", "im\u00b7mer", "noch", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PAV", "ADV", "ADV", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Was ich sagen wollte . . . Wir gehn Sonnabend aus \u2013", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "Wir", "gehn", "Sonn\u00b7a\u00b7bend", "aus", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VVFIN", "NN", "PTKVZ", "$("], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mit ihrem Freund? Na, so blau!", "tokens": ["Mit", "ih\u00b7rem", "Freund", "?", "Na", ",", "so", "blau", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ITJ", "$,", "ADV", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Die nehm ich glatt mit mir nach Haus \u2013", "tokens": ["Die", "nehm", "ich", "glatt", "mit", "mir", "nach", "Haus", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "APPR", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Augen hat die Frau \u2013!", "tokens": ["Au\u00b7gen", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.7": {"line.1": {"text": "Die Wechsel sind . . . na, wie finden Sie das?", "tokens": ["Die", "Wech\u00b7sel", "sind", ".", ".", ".", "na", ",", "wie", "fin\u00b7den", "Sie", "das", "?"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$.", "$.", "$.", "ITJ", "$,", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die klopfen ans Fenster, weil ich", "tokens": ["Die", "klop\u00b7fen", "ans", "Fens\u00b7ter", ",", "weil", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "APPRART", "NN", "$,", "KOUS", "PPER"], "meter": "-+--+-++", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "hier spreche \u2013 ich erz\u00e4hl Ihnen pers\u00f6nlich noch was,", "tokens": ["hier", "spre\u00b7che", "\u2013", "ich", "er\u00b7z\u00e4hl", "Ih\u00b7nen", "per\u00b7s\u00f6n\u00b7lich", "noch", "was", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "ADV", "PIS", "$,"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "ich bin n\u00e4mlich furchtbar eilig.", "tokens": ["ich", "bin", "n\u00e4m\u00b7lich", "furcht\u00b7bar", "ei\u00b7lig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Was ich sagen wollte . . . ich bin derartig scharf . . .", "tokens": ["Was", "ich", "sa\u00b7gen", "woll\u00b7te", ".", ".", ".", "ich", "bin", "der\u00b7ar\u00b7tig", "scharf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "PPER", "VVINF", "VMFIN", "$.", "$.", "$.", "PPER", "VAFIN", "ADJD", "VVFIN", "$.", "$.", "$."], "meter": "--+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Nat\u00fcrlich! Wei\u00df ich genau,", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "!", "Wei\u00df", "ich", "ge\u00b7nau", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "was ein Schentelm\u00e4n sich erlauben darf . . .", "tokens": ["was", "ein", "Schen\u00b7tel\u00b7m\u00e4n", "sich", "er\u00b7lau\u00b7ben", "darf", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PWS", "ART", "NN", "PRF", "VVINF", "VMFIN", "$.", "$.", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.8": {"text": "Einen R\u00fccken hat die Frau \u2013!", "tokens": ["Ei\u00b7nen", "R\u00fc\u00b7cken", "hat", "die", "Frau", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.9": {"text": "Fabelhaft.", "tokens": ["Fa\u00b7bel\u00b7haft", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.8": {"line.1": {"text": "Wir legen die Schecks . . . hallo? . . . unterbrochen . . .", "tokens": ["Wir", "le\u00b7gen", "die", "Schecks", ".", ".", ".", "hal\u00b7lo", "?", ".", ".", ".", "un\u00b7ter\u00b7bro\u00b7chen", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "$.", "$.", "FM.la", "$.", "$.", "$.", "$.", "VVPP", "$.", "$.", "$."], "meter": "-+--++-+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Ich habe doch noch gar nicht gesprochen . . . !", "tokens": ["Ich", "ha\u00b7be", "doch", "noch", "gar", "nicht", "ge\u00b7spro\u00b7chen", ".", ".", ".", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADV", "PTKNEG", "VVPP", "$.", "$.", "$.", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Na, denn nicht.", "tokens": ["Na", ",", "denn", "nicht", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "PTKNEG", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Nur keine falsche Hast!", "tokens": ["Nur", "kei\u00b7ne", "fal\u00b7sche", "Hast", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Ich spreche hier, solange 's mir pa\u00dft!", "tokens": ["Ich", "spre\u00b7che", "hier", ",", "so\u00b7lan\u00b7ge", "'s", "mir", "pa\u00dft", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "L\u00fcmmel.", "tokens": ["L\u00fcm\u00b7mel", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Ja \u2013! Nein \u2013!", "tokens": ["Ja", "\u2013", "!", "Nein", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["PTKANT", "$(", "$.", "PTKANT", "$(", "$."], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Na, da gehn Sie doch rein!", "tokens": ["Na", ",", "da", "gehn", "Sie", "doch", "rein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "Eine Luft wie in einem Schwitzkastenbad . . .", "tokens": ["Ei\u00b7ne", "Luft", "wie", "in", "ei\u00b7nem", "Schwitz\u00b7kas\u00b7ten\u00b7bad", ".", ".", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "KOKOM", "APPR", "ART", "NN", "$.", "$.", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.10": {"text": "Was der schon zu telefonieren hat \u2013", "tokens": ["Was", "der", "schon", "zu", "te\u00b7le\u00b7fo\u00b7nie\u00b7ren", "hat", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "ADV", "PTKZU", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "L\u00fcmmel.\u00ab", "tokens": ["L\u00fcm\u00b7mel", ".", "\u00ab"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$.", "$("], "meter": "+-", "measure": "trochaic.single"}}}}}