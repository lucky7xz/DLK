{"textgrid.poem.53555": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Preu\u00dfische Professoren", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eigentlich solltet ihr Pallas dienen.", "tokens": ["Ei\u00b7gent\u00b7lich", "soll\u00b7tet", "ihr", "Pal\u00b7las", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Aber Pallas kippt aus den Pantinen", "tokens": ["A\u00b7ber", "Pal\u00b7las", "kippt", "aus", "den", "Pan\u00b7ti\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "und flieht,", "tokens": ["und", "flieht", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "wenn sie solche Magister sieht.", "tokens": ["wenn", "sie", "sol\u00b7che", "Ma\u00b7gis\u00b7ter", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Damals, Vierzehn, Kanonengebrumm.", "tokens": ["Da\u00b7mals", ",", "Vier\u00b7zehn", ",", "Ka\u00b7no\u00b7nen\u00b7ge\u00b7brumm", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "CARD", "$,", "NE", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und sie fielen alle, alle um.", "tokens": ["Und", "sie", "fie\u00b7len", "al\u00b7le", ",", "al\u00b7le", "um", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Es beteten zum Himmel die Theologen,", "tokens": ["Es", "be\u00b7te\u00b7ten", "zum", "Him\u00b7mel", "die", "Theo\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df sich die Kanzelverzierungen bogen.", "tokens": ["da\u00df", "sich", "die", "Kan\u00b7zel\u00b7ver\u00b7zie\u00b7run\u00b7gen", "bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es bewiesen klipp und klar die Juristen", "tokens": ["Es", "be\u00b7wie\u00b7sen", "klipp", "und", "klar", "die", "Ju\u00b7ris\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "ART", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "die englisch-franz\u00f6sisch-belgischen Listen.", "tokens": ["die", "eng\u00b7lischfran\u00b7z\u00f6\u00b7sischbel\u00b7gi\u00b7schen", "Lis\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Der Generalstab bringt sie auf den Trab:", "tokens": ["Der", "Ge\u00b7ne\u00b7rals\u00b7tab", "bringt", "sie", "auf", "den", "Trab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Philosophen schw\u00f6ren das Fremdl\u00e4ndische ab.", "tokens": ["Phi\u00b7lo\u00b7so\u00b7phen", "schw\u00f6\u00b7ren", "das", "Fremd\u00b7l\u00e4n\u00b7di\u00b7sche", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Und kraucht auch ein Deutscher noch so mau:", "tokens": ["Und", "kraucht", "auch", "ein", "Deut\u00b7scher", "noch", "so", "mau", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "die Mediziner riefen: \u00bbKv.!\u00ab", "tokens": ["die", "Me\u00b7di\u00b7zi\u00b7ner", "rie\u00b7fen", ":", "\u00bb", "Kv", ".", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NE", "$.", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So schreitet jede Fakult\u00e4t", "tokens": ["So", "schrei\u00b7tet", "je\u00b7de", "Fa\u00b7kul\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "den Weg, der zum preu\u00dfischen Himmel geht.", "tokens": ["den", "Weg", ",", "der", "zum", "preu\u00b7\u00dfi\u00b7schen", "Him\u00b7mel", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "Aber sie waren auch geistig am Werk,", "tokens": ["A\u00b7ber", "sie", "wa\u00b7ren", "auch", "geis\u00b7tig", "am", "Werk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Seis nun Berlin oder K\u00f6nigsberg,", "tokens": ["Seis", "nun", "Ber\u00b7lin", "o\u00b7der", "K\u00f6\u00b7nigs\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "KON", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "sei es Breslau oder Halle \u2013", "tokens": ["sei", "es", "Bres\u00b7lau", "o\u00b7der", "Hal\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "KON", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dieses n\u00e4mlich taten sie alle:", "tokens": ["die\u00b7ses", "n\u00e4m\u00b7lich", "ta\u00b7ten", "sie", "al\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADV", "VVFIN", "PPER", "PIS", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Sie verliehen den Doktor, den h\u00e4ufig bezahlten,", "tokens": ["Sie", "ver\u00b7lie\u00b7hen", "den", "Dok\u00b7tor", ",", "den", "h\u00e4u\u00b7fig", "be\u00b7zahl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "den silbern und golden und r\u00f6tlich bemalten", "tokens": ["den", "sil\u00b7bern", "und", "gol\u00b7den", "und", "r\u00f6t\u00b7lich", "be\u00b7mal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "KON", "ADJD", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Generalen \u2013!", "tokens": ["Ge\u00b7ne\u00b7ra\u00b7len", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$(", "$."], "meter": "--+-", "measure": "anapaest.init"}, "line.4": {"text": "Und die brauchten nichts daf\u00fcr zu bezahlen!", "tokens": ["Und", "die", "brauch\u00b7ten", "nichts", "da\u00b7f\u00fcr", "zu", "be\u00b7zah\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PIS", "PAV", "PTKZU", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "So wurde ohne alle Pr\u00e4missen", "tokens": ["So", "wur\u00b7de", "oh\u00b7ne", "al\u00b7le", "Pr\u00e4\u00b7mis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "der Doktor vor die Soldaten geschmissen.", "tokens": ["der", "Dok\u00b7tor", "vor", "die", "Sol\u00b7da\u00b7ten", "ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Armes Diplom, schwarz-wei\u00df umr\u00e4ndert,", "tokens": ["Ar\u00b7mes", "Dip\u00b7lom", ",", "schwa\u00b7rz\u00b7wei\u00df", "um\u00b7r\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "armes Diplom! hast du dich ver\u00e4ndert!", "tokens": ["ar\u00b7mes", "Dip\u00b7lom", "!", "hast", "du", "dich", "ver\u00b7\u00e4n\u00b7dert", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Und heute?", "tokens": ["Und", "heu\u00b7te", "?"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Heute, wie ehedem.", "tokens": ["Heu\u00b7te", ",", "wie", "e\u00b7he\u00b7dem", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Reden ist ja so bequem.", "tokens": ["Re\u00b7den", "ist", "ja", "so", "be\u00b7quem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ist Roethe, der maulfeste Rufer,", "tokens": ["Da", "ist", "Roe\u00b7the", ",", "der", "maul\u00b7fes\u00b7te", "Ru\u00b7fer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "ein Thersites im Bart vom Panke-Ufer,", "tokens": ["ein", "Ther\u00b7si\u00b7tes", "im", "Bart", "vom", "Pan\u00b7ke\u00b7U\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und jener Birnenbauch Wilhelm Kahl \u2013", "tokens": ["und", "je\u00b7ner", "Bir\u00b7nen\u00b7bauch", "Wil\u00b7helm", "Kahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "NE", "NE", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "und allen ist der Zusammenbruch egal.", "tokens": ["und", "al\u00b7len", "ist", "der", "Zu\u00b7sam\u00b7men\u00b7bruch", "e\u00b7gal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Sie sehen nur die alten Fahnen,", "tokens": ["Sie", "se\u00b7hen", "nur", "die", "al\u00b7ten", "Fah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die schlanken Leutnants von den Ulanen,", "tokens": ["die", "schlan\u00b7ken", "Leut\u00b7nants", "von", "den", "U\u00b7la\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "sie sehen die Prinzen und die Haubitzen,", "tokens": ["sie", "se\u00b7hen", "die", "Prin\u00b7zen", "und", "die", "Hau\u00b7bit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "sie sehen die preu\u00dfischen Orden blitzen,", "tokens": ["sie", "se\u00b7hen", "die", "preu\u00b7\u00dfi\u00b7schen", "Or\u00b7den", "blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "sie sehen die ganze schuldige Schicht \u2013", "tokens": ["sie", "se\u00b7hen", "die", "gan\u00b7ze", "schul\u00b7di\u00b7ge", "Schicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Die neue \u00c4ra sehen sie nicht.", "tokens": ["Die", "neu\u00b7e", "\u00c4\u00b7ra", "se\u00b7hen", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "Deutschland, sind das deine geistigen Spitzen?", "tokens": ["Deutschland", ",", "sind", "das", "dei\u00b7ne", "geis\u00b7ti\u00b7gen", "Spit\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "ART", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie haben einen Hintern zum Sitzen,", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7nen", "Hin\u00b7tern", "zum", "Sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "sie haben auch einen servilen R\u00fccken,", "tokens": ["sie", "ha\u00b7ben", "auch", "ei\u00b7nen", "ser\u00b7vi\u00b7len", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "um sich vor jeder Macht zu b\u00fccken \u2013", "tokens": ["um", "sich", "vor", "je\u00b7der", "Macht", "zu", "b\u00fc\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kopf hingegen ist nicht vorhanden.", "tokens": ["Kopf", "hin\u00b7ge\u00b7gen", "ist", "nicht", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.8": {"line.1": {"text": "Arme Jugend in deutschen Landen!", "tokens": ["Ar\u00b7me", "Ju\u00b7gend", "in", "deut\u00b7schen", "Lan\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Diese hochgelahrten Nauken", "tokens": ["Die\u00b7se", "hoch\u00b7ge\u00b7lahr\u00b7ten", "Nau\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sind gut genug zum Examenpauken.", "tokens": ["sind", "gut", "ge\u00b7nug", "zum", "E\u00b7xa\u00b7men\u00b7pau\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPRART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Brauchst du aber klaren Wein \u2013:", "tokens": ["Brauchst", "du", "a\u00b7ber", "kla\u00b7ren", "Wein", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Komm, den kaufen wir anderswo ein!", "tokens": ["Komm", ",", "den", "kau\u00b7fen", "wir", "an\u00b7ders\u00b7wo", "ein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Eigentlich solltet ihr Pallas dienen.", "tokens": ["Ei\u00b7gent\u00b7lich", "soll\u00b7tet", "ihr", "Pal\u00b7las", "die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Aber Pallas kippt aus den Pantinen", "tokens": ["A\u00b7ber", "Pal\u00b7las", "kippt", "aus", "den", "Pan\u00b7ti\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "NE", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+--+--", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "und flieht,", "tokens": ["und", "flieht", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "wenn sie solche Magister sieht.", "tokens": ["wenn", "sie", "sol\u00b7che", "Ma\u00b7gis\u00b7ter", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Damals, Vierzehn, Kanonengebrumm.", "tokens": ["Da\u00b7mals", ",", "Vier\u00b7zehn", ",", "Ka\u00b7no\u00b7nen\u00b7ge\u00b7brumm", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "CARD", "$,", "NE", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Und sie fielen alle, alle um.", "tokens": ["Und", "sie", "fie\u00b7len", "al\u00b7le", ",", "al\u00b7le", "um", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "$,", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Es beteten zum Himmel die Theologen,", "tokens": ["Es", "be\u00b7te\u00b7ten", "zum", "Him\u00b7mel", "die", "Theo\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df sich die Kanzelverzierungen bogen.", "tokens": ["da\u00df", "sich", "die", "Kan\u00b7zel\u00b7ver\u00b7zie\u00b7run\u00b7gen", "bo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es bewiesen klipp und klar die Juristen", "tokens": ["Es", "be\u00b7wie\u00b7sen", "klipp", "und", "klar", "die", "Ju\u00b7ris\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "ADJD", "ART", "NN"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "die englisch-franz\u00f6sisch-belgischen Listen.", "tokens": ["die", "eng\u00b7lischfran\u00b7z\u00f6\u00b7sischbel\u00b7gi\u00b7schen", "Lis\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.7": {"text": "Der Generalstab bringt sie auf den Trab:", "tokens": ["Der", "Ge\u00b7ne\u00b7rals\u00b7tab", "bringt", "sie", "auf", "den", "Trab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Philosophen schw\u00f6ren das Fremdl\u00e4ndische ab.", "tokens": ["Phi\u00b7lo\u00b7so\u00b7phen", "schw\u00f6\u00b7ren", "das", "Fremd\u00b7l\u00e4n\u00b7di\u00b7sche", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Und kraucht auch ein Deutscher noch so mau:", "tokens": ["Und", "kraucht", "auch", "ein", "Deut\u00b7scher", "noch", "so", "mau", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "die Mediziner riefen: \u00bbKv.!\u00ab", "tokens": ["die", "Me\u00b7di\u00b7zi\u00b7ner", "rie\u00b7fen", ":", "\u00bb", "Kv", ".", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NE", "$.", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "So schreitet jede Fakult\u00e4t", "tokens": ["So", "schrei\u00b7tet", "je\u00b7de", "Fa\u00b7kul\u00b7t\u00e4t"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "den Weg, der zum preu\u00dfischen Himmel geht.", "tokens": ["den", "Weg", ",", "der", "zum", "preu\u00b7\u00dfi\u00b7schen", "Him\u00b7mel", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.11": {"line.1": {"text": "Aber sie waren auch geistig am Werk,", "tokens": ["A\u00b7ber", "sie", "wa\u00b7ren", "auch", "geis\u00b7tig", "am", "Werk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADJD", "APPRART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Seis nun Berlin oder K\u00f6nigsberg,", "tokens": ["Seis", "nun", "Ber\u00b7lin", "o\u00b7der", "K\u00f6\u00b7nigs\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NE", "KON", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "sei es Breslau oder Halle \u2013", "tokens": ["sei", "es", "Bres\u00b7lau", "o\u00b7der", "Hal\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "NE", "KON", "NE", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "dieses n\u00e4mlich taten sie alle:", "tokens": ["die\u00b7ses", "n\u00e4m\u00b7lich", "ta\u00b7ten", "sie", "al\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADV", "VVFIN", "PPER", "PIS", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Sie verliehen den Doktor, den h\u00e4ufig bezahlten,", "tokens": ["Sie", "ver\u00b7lie\u00b7hen", "den", "Dok\u00b7tor", ",", "den", "h\u00e4u\u00b7fig", "be\u00b7zahl\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "--+--+--+--+-", "measure": "anapaest.tetra.plus"}, "line.2": {"text": "den silbern und golden und r\u00f6tlich bemalten", "tokens": ["den", "sil\u00b7bern", "und", "gol\u00b7den", "und", "r\u00f6t\u00b7lich", "be\u00b7mal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ADJA", "KON", "ADJD", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Generalen \u2013!", "tokens": ["Ge\u00b7ne\u00b7ra\u00b7len", "\u2013", "!"], "token_info": ["word", "punct", "punct"], "pos": ["NN", "$(", "$."], "meter": "--+-", "measure": "anapaest.init"}, "line.4": {"text": "Und die brauchten nichts daf\u00fcr zu bezahlen!", "tokens": ["Und", "die", "brauch\u00b7ten", "nichts", "da\u00b7f\u00fcr", "zu", "be\u00b7zah\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "PIS", "PAV", "PTKZU", "VVINF", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "So wurde ohne alle Pr\u00e4missen", "tokens": ["So", "wur\u00b7de", "oh\u00b7ne", "al\u00b7le", "Pr\u00e4\u00b7mis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "der Doktor vor die Soldaten geschmissen.", "tokens": ["der", "Dok\u00b7tor", "vor", "die", "Sol\u00b7da\u00b7ten", "ge\u00b7schmis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Armes Diplom, schwarz-wei\u00df umr\u00e4ndert,", "tokens": ["Ar\u00b7mes", "Dip\u00b7lom", ",", "schwa\u00b7rz\u00b7wei\u00df", "um\u00b7r\u00e4n\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "armes Diplom! hast du dich ver\u00e4ndert!", "tokens": ["ar\u00b7mes", "Dip\u00b7lom", "!", "hast", "du", "dich", "ver\u00b7\u00e4n\u00b7dert", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.13": {"line.1": {"text": "Und heute?", "tokens": ["Und", "heu\u00b7te", "?"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Heute, wie ehedem.", "tokens": ["Heu\u00b7te", ",", "wie", "e\u00b7he\u00b7dem", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADV", "$."], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.3": {"text": "Reden ist ja so bequem.", "tokens": ["Re\u00b7den", "ist", "ja", "so", "be\u00b7quem", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Da ist Roethe, der maulfeste Rufer,", "tokens": ["Da", "ist", "Roe\u00b7the", ",", "der", "maul\u00b7fes\u00b7te", "Ru\u00b7fer", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "ein Thersites im Bart vom Panke-Ufer,", "tokens": ["ein", "Ther\u00b7si\u00b7tes", "im", "Bart", "vom", "Pan\u00b7ke\u00b7U\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und jener Birnenbauch Wilhelm Kahl \u2013", "tokens": ["und", "je\u00b7ner", "Bir\u00b7nen\u00b7bauch", "Wil\u00b7helm", "Kahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "NE", "NE", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "und allen ist der Zusammenbruch egal.", "tokens": ["und", "al\u00b7len", "ist", "der", "Zu\u00b7sam\u00b7men\u00b7bruch", "e\u00b7gal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Sie sehen nur die alten Fahnen,", "tokens": ["Sie", "se\u00b7hen", "nur", "die", "al\u00b7ten", "Fah\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die schlanken Leutnants von den Ulanen,", "tokens": ["die", "schlan\u00b7ken", "Leut\u00b7nants", "von", "den", "U\u00b7la\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "sie sehen die Prinzen und die Haubitzen,", "tokens": ["sie", "se\u00b7hen", "die", "Prin\u00b7zen", "und", "die", "Hau\u00b7bit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.11": {"text": "sie sehen die preu\u00dfischen Orden blitzen,", "tokens": ["sie", "se\u00b7hen", "die", "preu\u00b7\u00dfi\u00b7schen", "Or\u00b7den", "blit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "sie sehen die ganze schuldige Schicht \u2013", "tokens": ["sie", "se\u00b7hen", "die", "gan\u00b7ze", "schul\u00b7di\u00b7ge", "Schicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Die neue \u00c4ra sehen sie nicht.", "tokens": ["Die", "neu\u00b7e", "\u00c4\u00b7ra", "se\u00b7hen", "sie", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.15": {"line.1": {"text": "Deutschland, sind das deine geistigen Spitzen?", "tokens": ["Deutschland", ",", "sind", "das", "dei\u00b7ne", "geis\u00b7ti\u00b7gen", "Spit\u00b7zen", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VAFIN", "ART", "PPOSAT", "ADJA", "NN", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie haben einen Hintern zum Sitzen,", "tokens": ["Sie", "ha\u00b7ben", "ei\u00b7nen", "Hin\u00b7tern", "zum", "Sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "sie haben auch einen servilen R\u00fccken,", "tokens": ["sie", "ha\u00b7ben", "auch", "ei\u00b7nen", "ser\u00b7vi\u00b7len", "R\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "um sich vor jeder Macht zu b\u00fccken \u2013", "tokens": ["um", "sich", "vor", "je\u00b7der", "Macht", "zu", "b\u00fc\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PRF", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kopf hingegen ist nicht vorhanden.", "tokens": ["Kopf", "hin\u00b7ge\u00b7gen", "ist", "nicht", "vor\u00b7han\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.16": {"line.1": {"text": "Arme Jugend in deutschen Landen!", "tokens": ["Ar\u00b7me", "Ju\u00b7gend", "in", "deut\u00b7schen", "Lan\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Diese hochgelahrten Nauken", "tokens": ["Die\u00b7se", "hoch\u00b7ge\u00b7lahr\u00b7ten", "Nau\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sind gut genug zum Examenpauken.", "tokens": ["sind", "gut", "ge\u00b7nug", "zum", "E\u00b7xa\u00b7men\u00b7pau\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPRART", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Brauchst du aber klaren Wein \u2013:", "tokens": ["Brauchst", "du", "a\u00b7ber", "kla\u00b7ren", "Wein", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "$(", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Komm, den kaufen wir anderswo ein!", "tokens": ["Komm", ",", "den", "kau\u00b7fen", "wir", "an\u00b7ders\u00b7wo", "ein", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "VVFIN", "PPER", "ADV", "PTKVZ", "$."], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}}}}}