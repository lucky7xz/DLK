{"dta.poem.21844": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Momus/ der der Wei\u00dfheit Grund/ wie", "tokens": ["Mo\u00b7mus", "/", "der", "der", "Wei\u00df\u00b7heit", "Grund", "/", "wie"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NE", "$(", "ART", "ART", "NN", "NN", "$(", "KOKOM"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "aus dem Gestirne siehet/", "tokens": ["aus", "dem", "Ge\u00b7stir\u00b7ne", "sie\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "der au\u00df der Geschikkligkeit das gef\u00fcnffte", "tokens": ["der", "au\u00df", "der", "Ge\u00b7schikk\u00b7lig\u00b7keit", "das", "ge\u00b7f\u00fcnff\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ART", "ADJA"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Wesen ziehet/", "tokens": ["We\u00b7sen", "zie\u00b7het", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "welcher durch ein Perspektiv aller Men-", "tokens": ["wel\u00b7cher", "durch", "ein", "Pers\u00b7pek\u00b7tiv", "al\u00b7ler", "Men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "APPR", "ART", "NN", "PIAT", "TRUNC"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "schen Tuhn betrachtt", "tokens": ["schen", "Tuhn", "be\u00b7trachtt"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "ja auff Ammons Tohrheit selbst hat mit", "tokens": ["ja", "auff", "Am\u00b7mons", "Tohr\u00b7heit", "selbst", "hat", "mit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NE", "NN", "ADV", "VAFIN", "APPR"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "klugen Sinnen acht", "tokens": ["klu\u00b7gen", "Sin\u00b7nen", "acht"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "NN", "CARD"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.9": {"text": "Euer hoch-wizz zwinget mich diese Reden", "tokens": ["Eu\u00b7er", "hoch\u00b7wizz", "zwin\u00b7get", "mich", "die\u00b7se", "Re\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PDAT", "NN"], "meter": "+-+-+--+-+-", "measure": "sapphicusminor"}, "line.10": {"text": "Euch zugeben:", "tokens": ["Euch", "zu\u00b7ge\u00b7ben", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.11": {"text": "ein solch-hoch-erleuchter Sin\u0303 wird doch weit", "tokens": ["ein", "solch\u00b7hoch\u00b7er\u00b7leuch\u00b7ter", "Si\u00f1", "wird", "doch", "weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ADJD"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "und breit nicht leben", "tokens": ["und", "breit", "nicht", "le\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "PTKNEG", "VVINF"], "meter": "-+-+-", "measure": "iambic.di"}, "line.13": {"text": "der Euch/ Richter/ wage h\u00e4lt. Jhr nur", "tokens": ["der", "Euch", "/", "Rich\u00b7ter", "/", "wa\u00b7ge", "h\u00e4lt", ".", "Ihr", "nur"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$(", "NN", "$(", "VVFIN", "VVFIN", "$.", "PPER", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.14": {"text": "nehmt am ersten ein", "tokens": ["nehmt", "am", "ers\u00b7ten", "ein"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "ADJA", "ART"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.15": {"text": "was de\u00df/ so allhter verdekket/ wahre Mei-", "tokens": ["was", "de\u00df", "/", "so", "allh\u00b7ter", "ver\u00b7dek\u00b7ket", "/", "wah\u00b7re", "Mei"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ART", "$(", "ADV", "ADJD", "VVFIN", "$(", "ADJA", "TRUNC"], "meter": "+--+--+-+-+", "measure": "dactylic.di.plus"}, "line.16": {"text": "nung m\u00f6ge sein.", "tokens": ["nung", "m\u00f6\u00b7ge", "sein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Ein hart-ob sich stehend Haar/ da\u00df de\u00df Vogels", "tokens": ["Ein", "har\u00b7tob", "sich", "ste\u00b7hend", "Haar", "/", "da\u00df", "de\u00df", "Vo\u00b7gels"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "ADJD", "NN", "$(", "KOUS", "ART", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Federn gleichet", "tokens": ["Fe\u00b7dern", "glei\u00b7chet"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "den der Meleager scho\u00df und ihn Atalanten", "tokens": ["den", "der", "Me\u00b7le\u00b7a\u00b7ger", "scho\u00df", "und", "ihn", "A\u00b7tal\u00b7an\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN", "KON", "PPER", "NN"], "meter": "--+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "reichet'", "tokens": ["rei\u00b7chet'"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.21": {"text": "eine traur-bewuste Stirn/ die nur eine Run-", "tokens": ["ei\u00b7ne", "traur\u00b7be\u00b7wus\u00b7te", "Stirn", "/", "die", "nur", "ei\u00b7ne", "Run"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "ADV", "ART", "TRUNC"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.22": {"text": "zel hegt", "tokens": ["zel", "hegt"], "token_info": ["word", "word"], "pos": ["NE", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.23": {"text": "so sich umb das K\u00fcnste-schlo\u00df zehnfach ha", "tokens": ["so", "sich", "umb", "das", "K\u00fcns\u00b7te\u00b7schlo\u00df", "zehn\u00b7fach", "ha"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PRF", "APPR", "ART", "NN", "VVFIN", "NE"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.24": {"text": "herum gelegt", "tokens": ["he\u00b7rum", "ge\u00b7legt"], "token_info": ["word", "word"], "pos": ["APZR", "VVPP"], "meter": "-+-+", "measure": "iambic.di"}, "line.25": {"text": "ein ansehnlich-langer Gang/ wie Lykurgus", "tokens": ["ein", "an\u00b7sehn\u00b7lich\u00b7lan\u00b7ger", "Gang", "/", "wie", "Ly\u00b7kur\u00b7gus"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "KOKOM", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.26": {"text": "kahm getreten/", "tokens": ["kahm", "ge\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.27": {"text": "wenn er die Gesezze la\u00df so viel untergebnen", "tokens": ["wenn", "er", "die", "Ge\u00b7sez\u00b7ze", "la\u00df", "so", "viel", "un\u00b7ter\u00b7geb\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVIMP", "ADV", "ADV", "VVINF"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "St\u00e4ten/", "tokens": ["St\u00e4\u00b7ten", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.29": {"text": "Kleider als der Stoa trug/ wenn er die Be", "tokens": ["Klei\u00b7der", "als", "der", "Stoa", "trug", "/", "wenn", "er", "die", "Be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "KOKOM", "ART", "NN", "VVFIN", "$(", "KOUS", "PPER", "ART", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.30": {"text": "gierden zwang/", "tokens": ["gier\u00b7den", "zwang", "/"], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.31": {"text": "Sitten/ wie Fabrizius/ Reden hunde", "tokens": ["Sit\u00b7ten", "/", "wie", "Fab\u00b7ri\u00b7zius", "/", "Re\u00b7den", "hun\u00b7de"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$(", "KOKOM", "NE", "$(", "NN", "ADJA"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.32": {"text": "Ellen lang/", "tokens": ["El\u00b7len", "lang", "/"], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADJD", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.33": {"text": "Grobe Speisen/ hartes Lager/ schlechter Hau\u00df", "tokens": ["Gro\u00b7be", "Spei\u00b7sen", "/", "har\u00b7tes", "La\u00b7ger", "/", "schlech\u00b7ter", "Hau\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$(", "ADJA", "NN", "$(", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.34": {"text": "raht/ B\u00fccher! B\u00fccher!", "tokens": ["raht", "/", "B\u00fc\u00b7cher", "!", "B\u00fc\u00b7cher", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "$(", "NN", "$.", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.35": {"text": "B\u00fccher! B\u00fccher ohne Zahl/ und noch meh-", "tokens": ["B\u00fc\u00b7cher", "!", "B\u00fc\u00b7cher", "oh\u00b7ne", "Zahl", "/", "und", "noch", "meh"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "NN", "APPR", "NN", "$(", "KON", "ADV", "TRUNC"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.36": {"text": "res glaubet sicher", "tokens": ["res", "glau\u00b7bet", "si\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["ADJA", "VVFIN", "ADJD"], "meter": "-+-+-", "measure": "iambic.di"}, "line.37": {"text": "da\u00df di\u00df alles klar bezeugt ein verg\u00f6ttertes", "tokens": ["da\u00df", "di\u00df", "al\u00b7les", "klar", "be\u00b7zeugt", "ein", "ver\u00b7g\u00f6t\u00b7ter\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PDS", "PIS", "ADJD", "VVFIN", "ART", "ADJA"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.38": {"text": "Gem\u00fcht/", "tokens": ["Ge\u00b7m\u00fcht", "/"], "token_info": ["word", "punct"], "pos": ["VVPP", "$("], "meter": "-+", "measure": "iambic.single"}, "line.39": {"text": "so Minerven Heimligkeit durch viel tausend", "tokens": ["so", "Mi\u00b7ner\u00b7ven", "Heim\u00b7lig\u00b7keit", "durch", "viel", "tau\u00b7send"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "APPR", "PIAT", "CARD"], "meter": "-+--+-++-+-", "measure": "iambic.penta.relaxed"}, "line.40": {"text": "Brillen sieht.", "tokens": ["Bril\u00b7len", "sieht", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.41": {"text": "Weil ihr nu mit alle dehm/ Momus/ reichlich", "tokens": ["Weil", "ihr", "nu", "mit", "al\u00b7le", "dehm", "/", "Mo\u00b7mus", "/", "reich\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PIS", "ADJD", "$(", "NE", "$(", "ADJD"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.42": {"text": "seid begabet/", "tokens": ["seid", "be\u00b7ga\u00b7bet", "/"], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.43": {"text": "und sechs Unzen mehr Verstand/ als die G\u00f6t-", "tokens": ["und", "sechs", "Un\u00b7zen", "mehr", "Ver\u00b7stand", "/", "als", "die", "G\u00f6t"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "CARD", "NN", "PIAT", "NN", "$(", "KOUS", "ART", "TRUNC"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.44": {"text": "ter selber/ habet", "tokens": ["ter", "sel\u00b7ber", "/", "ha\u00b7bet"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJD", "ADV", "$(", "VAFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.45": {"text": "hab\u2019 ich di\u00df verbl\u00fcmte Spiel euerm Luch-", "tokens": ["hab'", "ich", "di\u00df", "ver\u00b7bl\u00fcm\u00b7te", "Spiel", "eu\u00b7erm", "Luch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PDS", "VVFIN", "NN", "PPOSAT", "TRUNC"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.46": {"text": "sen-scharffem Sinn'", "tokens": ["sen\u00b7scha\u00b7rf\u00b7fem", "Sinn'"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.47": {"text": "als zum Abschied\u2019 hergebracht. Nehmt es", "tokens": ["als", "zum", "Ab\u00b7schied'", "her\u00b7ge\u00b7bracht", ".", "Nehmt", "es"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "VVPP", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.48": {"text": "Pr\u00fcfer/ willigst hin.", "tokens": ["Pr\u00fc\u00b7fer", "/", "wil\u00b7ligst", "hin", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$(", "ADJD", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.49": {"text": "Andre handeln allzugrob. Dieser heist auch", "tokens": ["And\u00b7re", "han\u00b7deln", "all\u00b7zu\u00b7grob", ".", "Die\u00b7ser", "heist", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$.", "PDS", "VAFIN", "ADV"], "meter": "+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.50": {"text": "einen Narren/", "tokens": ["ei\u00b7nen", "Nar\u00b7ren", "/"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.51": {"text": "Jener schreibt auff euch Pa\u00dfqwill\u2019 und kan", "tokens": ["Je\u00b7ner", "schreibt", "auff", "euch", "Pa\u00df\u00b7qwill'", "und", "kan"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "VVFIN", "APPR", "PPER", "NN", "KON", "VMFIN"], "meter": "+-+--++-+", "measure": "trochaic.penta.relaxed"}, "line.52": {"text": "kaum so lange harren", "tokens": ["kaum", "so", "lan\u00b7ge", "har\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.53": {"text": "bi\u00df der Titul ist vorbey/ reizt er euch im er-", "tokens": ["bi\u00df", "der", "Ti\u00b7tul", "ist", "vor\u00b7bey", "/", "reizt", "er", "euch", "im", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "ADV", "$(", "VVFIN", "PPER", "PPER", "APPRART", "TRUNC"], "meter": "+--+-+-+-+--", "measure": "iambic.penta.invert"}, "line.54": {"text": "sten Blat/", "tokens": ["sten", "Blat", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "-+", "measure": "iambic.single"}, "line.55": {"text": "der tritt gar mit Drohen auff. Denn so", "tokens": ["der", "tritt", "gar", "mit", "Dro\u00b7hen", "auff", ".", "Denn", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$.", "KON", "ADV"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.56": {"text": "kommt der viert' und hat", "tokens": ["kommt", "der", "viert'", "und", "hat"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "KON", "VAFIN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.57": {"text": "allzuviel vor euch gelernt/ heist euch einen", "tokens": ["all\u00b7zu\u00b7viel", "vor", "euch", "ge\u00b7lernt", "/", "heist", "euch", "ei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "APPR", "PPER", "VVPP", "$(", "VVFIN", "PPER", "ART"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.58": {"text": "Jdioten/", "tokens": ["Jdio\u00b7ten", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.59": {"text": "heut euch einen Esels-drek/ und was mehr der", "tokens": ["heut", "euch", "ei\u00b7nen", "E\u00b7sels\u00b7drek", "/", "und", "was", "mehr", "der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ART", "NN", "$(", "KON", "PWS", "ADV", "ART"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.60": {"text": "groden Zoten", "tokens": ["gro\u00b7den", "Zo\u00b7ten"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.61": {"text": "die der Herr nicht leiden kan. Nein/ Herr/", "tokens": ["die", "der", "Herr", "nicht", "lei\u00b7den", "kan", ".", "Nein", "/", "Herr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$.", "PTKANT", "$(", "NN", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.62": {"text": "Momus! Nein/ Herr/ Nein!", "tokens": ["Mo\u00b7mus", "!", "Nein", "/", "Herr", "/", "Nein", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$.", "PTKANT", "$(", "NN", "$(", "PTKANT", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.63": {"text": "lasset uns fein Komplementisch/ lieber", "tokens": ["las\u00b7set", "uns", "fein", "Kom\u00b7ple\u00b7men\u00b7tisch", "/", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$(", "ADV"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.64": {"text": "Herr/ zusammen sein.", "tokens": ["Herr", "/", "zu\u00b7sam\u00b7men", "sein", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "VVPP", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.65": {"text": "Was ich hier hab\u2019 auffgesezzt/ g\u00f6nn\u2019 ich euch", "tokens": ["Was", "ich", "hier", "hab'", "auff\u00b7ge\u00b7sezzt", "/", "g\u00f6nn'", "ich", "euch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "VVPP", "$(", "VVFIN", "PPER", "PPER"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.66": {"text": "von ganzem Herzen.", "tokens": ["von", "gan\u00b7zem", "Her\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.67": {"text": "Meint Jhr/ da\u00df ich so mit Euch nu unh\u00f6ff-", "tokens": ["Meint", "Ihr", "/", "da\u00df", "ich", "so", "mit", "Euch", "nu", "un\u00b7h\u00f6ff"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$(", "KOUS", "PPER", "ADV", "APPR", "PPER", "ADV", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.68": {"text": "lich wolle scherzen?", "tokens": ["lich", "wol\u00b7le", "scher\u00b7zen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.69": {"text": "hier ist Ernst. Nein. wi\u00dft Jhr nu wie ihr", "tokens": ["hier", "ist", "Ernst", ".", "Nein", ".", "wi\u00dft", "Ihr", "nu", "wie", "ihr"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NE", "$.", "PTKANT", "$.", "VVFIN", "PPER", "ADV", "KOKOM", "PPOSAT"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.70": {"text": "di\u00df vergelten solt?", "tokens": ["di\u00df", "ver\u00b7gel\u00b7ten", "solt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VMFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.71": {"text": "da\u00df/ was ihr zutuhn sonst pflegt/ ihr hierin-", "tokens": ["da\u00df", "/", "was", "ihr", "zu\u00b7tuhn", "sonst", "pflegt", "/", "ihr", "hier\u00b7in"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "$(", "PWS", "PPER", "VVFIN", "ADV", "VVFIN", "$(", "PPOSAT", "TRUNC"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.72": {"text": "nen lassen wollt.", "tokens": ["nen", "las\u00b7sen", "wollt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVINF", "VVINF", "VMFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}