{"textgrid.poem.55894": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Von den Font\u00e4nen", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf einmal wei\u00df ich viel von den Font\u00e4nen,", "tokens": ["Auf", "ein\u00b7mal", "wei\u00df", "ich", "viel", "von", "den", "Fon\u00b7t\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "den unbegreiflichen B\u00e4umen aus Glas.", "tokens": ["den", "un\u00b7be\u00b7greif\u00b7li\u00b7chen", "B\u00e4u\u00b7men", "aus", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich k\u00f6nnte reden wie von eignen Tr\u00e4nen,", "tokens": ["Ich", "k\u00f6nn\u00b7te", "re\u00b7den", "wie", "von", "eig\u00b7nen", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "KOKOM", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die ich, ergriffen von sehr gro\u00dfen Tr\u00e4umen,", "tokens": ["die", "ich", ",", "er\u00b7grif\u00b7fen", "von", "sehr", "gro\u00b7\u00dfen", "Tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "$,", "VVPP", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "einmal vergeudete und dann verga\u00df.", "tokens": ["ein\u00b7mal", "ver\u00b7geu\u00b7de\u00b7te", "und", "dann", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Verga\u00df ich denn, da\u00df Himmel H\u00e4nde reichen", "tokens": ["Ver\u00b7ga\u00df", "ich", "denn", ",", "da\u00df", "Him\u00b7mel", "H\u00e4n\u00b7de", "rei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "zu vielen Dingen und in das Gedr\u00e4nge?", "tokens": ["zu", "vie\u00b7len", "Din\u00b7gen", "und", "in", "das", "Ge\u00b7dr\u00e4n\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sah ich nicht immer Gro\u00dfheit ohnegleichen", "tokens": ["Sah", "ich", "nicht", "im\u00b7mer", "Gro\u00df\u00b7heit", "oh\u00b7ne\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "im Aufstieg alter Parke, vor den weichen", "tokens": ["im", "Auf\u00b7stieg", "al\u00b7ter", "Par\u00b7ke", ",", "vor", "den", "wei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "erwartungsvollen Abenden, \u2013 in bleichen", "tokens": ["er\u00b7war\u00b7tungs\u00b7vol\u00b7len", "A\u00b7ben\u00b7den", ",", "\u2013", "in", "blei\u00b7chen"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "$(", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "aus fremden M\u00e4dchen steigenden Ges\u00e4ngen,", "tokens": ["aus", "frem\u00b7den", "M\u00e4d\u00b7chen", "stei\u00b7gen\u00b7den", "Ge\u00b7s\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "die \u00fcberflie\u00dfen aus der Melodie", "tokens": ["die", "\u00fc\u00b7berf\u00b7lie\u00b7\u00dfen", "aus", "der", "Me\u00b7lo\u00b7die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und wirklich werden und als m\u00fc\u00dften sie", "tokens": ["und", "wirk\u00b7lich", "wer\u00b7den", "und", "als", "m\u00fc\u00df\u00b7ten", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAINF", "KON", "KOUS", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sich spiegeln in den aufgetanen Teichen?", "tokens": ["sich", "spie\u00b7geln", "in", "den", "auf\u00b7ge\u00b7ta\u00b7nen", "Tei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich mu\u00df mich nur erinnern an das Alles,", "tokens": ["Ich", "mu\u00df", "mich", "nur", "e\u00b7rin\u00b7nern", "an", "das", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "APPR", "ART", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "was an Font\u00e4nen und an mir geschah, \u2013", "tokens": ["was", "an", "Fon\u00b7t\u00e4\u00b7nen", "und", "an", "mir", "ge\u00b7schah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "APPR", "NN", "KON", "APPR", "PPER", "VVFIN", "$,", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "dann f\u00fchl ich auch die Last des Niederfalles,", "tokens": ["dann", "f\u00fchl", "ich", "auch", "die", "Last", "des", "Nie\u00b7der\u00b7fal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in welcher ich die Wasser wiedersah:", "tokens": ["in", "wel\u00b7cher", "ich", "die", "Was\u00b7ser", "wie\u00b7der\u00b7sah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und wei\u00df von Zweigen, die sich abw\u00e4rts wandten,", "tokens": ["Und", "wei\u00df", "von", "Zwei\u00b7gen", ",", "die", "sich", "ab\u00b7w\u00e4rts", "wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "von Stimmen, die mit kleiner Flamme brannten,", "tokens": ["von", "Stim\u00b7men", ",", "die", "mit", "klei\u00b7ner", "Flam\u00b7me", "brann\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "von Teichen, welche nur die Uferkanten", "tokens": ["von", "Tei\u00b7chen", ",", "wel\u00b7che", "nur", "die", "U\u00b7fer\u00b7kan\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "schwachsinnig und verschoben wiederholten,", "tokens": ["schwach\u00b7sin\u00b7nig", "und", "ver\u00b7scho\u00b7ben", "wie\u00b7der\u00b7hol\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "von Abendhimmeln, welche von verkohlten", "tokens": ["von", "A\u00b7bend\u00b7him\u00b7meln", ",", "wel\u00b7che", "von", "ver\u00b7kohl\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "westlichen W\u00e4ldern ganz entfremdet traten", "tokens": ["west\u00b7li\u00b7chen", "W\u00e4l\u00b7dern", "ganz", "ent\u00b7frem\u00b7det", "tra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "VVPP", "VVFIN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "sich anders w\u00f6lbten, dunkelten und taten", "tokens": ["sich", "an\u00b7ders", "w\u00f6lb\u00b7ten", ",", "dun\u00b7kel\u00b7ten", "und", "ta\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADV", "VVFIN", "$,", "ADJA", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "als w\u00e4r das nicht die Welt, die sie gemeint...", "tokens": ["als", "w\u00e4r", "das", "nicht", "die", "Welt", ",", "die", "sie", "ge\u00b7meint", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PDS", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Verga\u00df ich denn, da\u00df Stern bei Stern versteint", "tokens": ["Ver\u00b7ga\u00df", "ich", "denn", ",", "da\u00df", "Stern", "bei", "Stern", "ver\u00b7steint"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und sich verschlie\u00dft gegen die Nachbargloben?", "tokens": ["und", "sich", "ver\u00b7schlie\u00dft", "ge\u00b7gen", "die", "Nach\u00b7bar\u00b7glo\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df sich die Welten nur noch wie verweint", "tokens": ["Da\u00df", "sich", "die", "Wel\u00b7ten", "nur", "noch", "wie", "ver\u00b7weint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "ADV", "KOKOM", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "im Raum erkennen? \u2013 Vielleicht sind wir ", "tokens": ["im", "Raum", "er\u00b7ken\u00b7nen", "?", "\u2013", "Viel\u00b7leicht", "sind", "wir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVINF", "$.", "$(", "ADV", "VAFIN", "PPER"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "in Himmel andrer Wesen eingewoben,", "tokens": ["in", "Him\u00b7mel", "an\u00b7drer", "We\u00b7sen", "ein\u00b7ge\u00b7wo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die zu uns aufschaun abends. Vielleicht loben", "tokens": ["die", "zu", "uns", "auf\u00b7schaun", "a\u00b7bends", ".", "Viel\u00b7leicht", "lo\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "PPER", "VVFIN", "ADV", "$.", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "uns ihre Dichter. Vielleicht beten viele", "tokens": ["uns", "ih\u00b7re", "Dich\u00b7ter.", "Viel\u00b7leicht", "be\u00b7ten", "vie\u00b7le"], "token_info": ["word", "word", "abbreviation", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVFIN", "PIS"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "zu uns empor. Vielleicht sind wir die Ziele", "tokens": ["zu", "uns", "em\u00b7por", ".", "Viel\u00b7leicht", "sind", "wir", "die", "Zie\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "von fremden Fl\u00fcchen, die uns nie erreichen,", "tokens": ["von", "frem\u00b7den", "Fl\u00fc\u00b7chen", ",", "die", "uns", "nie", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nachbaren eines Gottes, den sie meinen", "tokens": ["Nach\u00b7ba\u00b7ren", "ei\u00b7nes", "Got\u00b7tes", ",", "den", "sie", "mei\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "in unsrer H\u00f6he, wenn sie einsam weinen,", "tokens": ["in", "uns\u00b7rer", "H\u00f6\u00b7he", ",", "wenn", "sie", "ein\u00b7sam", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "an den sie glauben und den sie verlieren,", "tokens": ["an", "den", "sie", "glau\u00b7ben", "und", "den", "sie", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVINF", "KON", "ART", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "und dessen Bildnis, wie ein Schein aus ihren", "tokens": ["und", "des\u00b7sen", "Bild\u00b7nis", ",", "wie", "ein", "Schein", "aus", "ih\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PRELAT", "NN", "$,", "PWAV", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "suchenden Lampen, fl\u00fcchtig und verweht,", "tokens": ["su\u00b7chen\u00b7den", "Lam\u00b7pen", ",", "fl\u00fcch\u00b7tig", "und", "ver\u00b7weht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.15": {"text": "\u00fcber unsere zerstreuten Gesichter geht....", "tokens": ["\u00fc\u00b7ber", "un\u00b7se\u00b7re", "zer\u00b7streu\u00b7ten", "Ge\u00b7sich\u00b7ter", "geht", "...."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Auf einmal wei\u00df ich viel von den Font\u00e4nen,", "tokens": ["Auf", "ein\u00b7mal", "wei\u00df", "ich", "viel", "von", "den", "Fon\u00b7t\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "den unbegreiflichen B\u00e4umen aus Glas.", "tokens": ["den", "un\u00b7be\u00b7greif\u00b7li\u00b7chen", "B\u00e4u\u00b7men", "aus", "Glas", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ich k\u00f6nnte reden wie von eignen Tr\u00e4nen,", "tokens": ["Ich", "k\u00f6nn\u00b7te", "re\u00b7den", "wie", "von", "eig\u00b7nen", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "KOKOM", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die ich, ergriffen von sehr gro\u00dfen Tr\u00e4umen,", "tokens": ["die", "ich", ",", "er\u00b7grif\u00b7fen", "von", "sehr", "gro\u00b7\u00dfen", "Tr\u00e4u\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "$,", "VVPP", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "einmal vergeudete und dann verga\u00df.", "tokens": ["ein\u00b7mal", "ver\u00b7geu\u00b7de\u00b7te", "und", "dann", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Verga\u00df ich denn, da\u00df Himmel H\u00e4nde reichen", "tokens": ["Ver\u00b7ga\u00df", "ich", "denn", ",", "da\u00df", "Him\u00b7mel", "H\u00e4n\u00b7de", "rei\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "zu vielen Dingen und in das Gedr\u00e4nge?", "tokens": ["zu", "vie\u00b7len", "Din\u00b7gen", "und", "in", "das", "Ge\u00b7dr\u00e4n\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sah ich nicht immer Gro\u00dfheit ohnegleichen", "tokens": ["Sah", "ich", "nicht", "im\u00b7mer", "Gro\u00df\u00b7heit", "oh\u00b7ne\u00b7glei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "im Aufstieg alter Parke, vor den weichen", "tokens": ["im", "Auf\u00b7stieg", "al\u00b7ter", "Par\u00b7ke", ",", "vor", "den", "wei\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "NN", "$,", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "erwartungsvollen Abenden, \u2013 in bleichen", "tokens": ["er\u00b7war\u00b7tungs\u00b7vol\u00b7len", "A\u00b7ben\u00b7den", ",", "\u2013", "in", "blei\u00b7chen"], "token_info": ["word", "word", "punct", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "$(", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "aus fremden M\u00e4dchen steigenden Ges\u00e4ngen,", "tokens": ["aus", "frem\u00b7den", "M\u00e4d\u00b7chen", "stei\u00b7gen\u00b7den", "Ge\u00b7s\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "die \u00fcberflie\u00dfen aus der Melodie", "tokens": ["die", "\u00fc\u00b7berf\u00b7lie\u00b7\u00dfen", "aus", "der", "Me\u00b7lo\u00b7die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und wirklich werden und als m\u00fc\u00dften sie", "tokens": ["und", "wirk\u00b7lich", "wer\u00b7den", "und", "als", "m\u00fc\u00df\u00b7ten", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAINF", "KON", "KOUS", "VMFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sich spiegeln in den aufgetanen Teichen?", "tokens": ["sich", "spie\u00b7geln", "in", "den", "auf\u00b7ge\u00b7ta\u00b7nen", "Tei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich mu\u00df mich nur erinnern an das Alles,", "tokens": ["Ich", "mu\u00df", "mich", "nur", "e\u00b7rin\u00b7nern", "an", "das", "Al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "APPR", "ART", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "was an Font\u00e4nen und an mir geschah, \u2013", "tokens": ["was", "an", "Fon\u00b7t\u00e4\u00b7nen", "und", "an", "mir", "ge\u00b7schah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "APPR", "NN", "KON", "APPR", "PPER", "VVFIN", "$,", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "dann f\u00fchl ich auch die Last des Niederfalles,", "tokens": ["dann", "f\u00fchl", "ich", "auch", "die", "Last", "des", "Nie\u00b7der\u00b7fal\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in welcher ich die Wasser wiedersah:", "tokens": ["in", "wel\u00b7cher", "ich", "die", "Was\u00b7ser", "wie\u00b7der\u00b7sah", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und wei\u00df von Zweigen, die sich abw\u00e4rts wandten,", "tokens": ["Und", "wei\u00df", "von", "Zwei\u00b7gen", ",", "die", "sich", "ab\u00b7w\u00e4rts", "wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "von Stimmen, die mit kleiner Flamme brannten,", "tokens": ["von", "Stim\u00b7men", ",", "die", "mit", "klei\u00b7ner", "Flam\u00b7me", "brann\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "von Teichen, welche nur die Uferkanten", "tokens": ["von", "Tei\u00b7chen", ",", "wel\u00b7che", "nur", "die", "U\u00b7fer\u00b7kan\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "schwachsinnig und verschoben wiederholten,", "tokens": ["schwach\u00b7sin\u00b7nig", "und", "ver\u00b7scho\u00b7ben", "wie\u00b7der\u00b7hol\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "von Abendhimmeln, welche von verkohlten", "tokens": ["von", "A\u00b7bend\u00b7him\u00b7meln", ",", "wel\u00b7che", "von", "ver\u00b7kohl\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "westlichen W\u00e4ldern ganz entfremdet traten", "tokens": ["west\u00b7li\u00b7chen", "W\u00e4l\u00b7dern", "ganz", "ent\u00b7frem\u00b7det", "tra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "ADV", "VVPP", "VVFIN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.11": {"text": "sich anders w\u00f6lbten, dunkelten und taten", "tokens": ["sich", "an\u00b7ders", "w\u00f6lb\u00b7ten", ",", "dun\u00b7kel\u00b7ten", "und", "ta\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRF", "ADV", "VVFIN", "$,", "ADJA", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "als w\u00e4r das nicht die Welt, die sie gemeint...", "tokens": ["als", "w\u00e4r", "das", "nicht", "die", "Welt", ",", "die", "sie", "ge\u00b7meint", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PDS", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Verga\u00df ich denn, da\u00df Stern bei Stern versteint", "tokens": ["Ver\u00b7ga\u00df", "ich", "denn", ",", "da\u00df", "Stern", "bei", "Stern", "ver\u00b7steint"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und sich verschlie\u00dft gegen die Nachbargloben?", "tokens": ["und", "sich", "ver\u00b7schlie\u00dft", "ge\u00b7gen", "die", "Nach\u00b7bar\u00b7glo\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df sich die Welten nur noch wie verweint", "tokens": ["Da\u00df", "sich", "die", "Wel\u00b7ten", "nur", "noch", "wie", "ver\u00b7weint"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRF", "ART", "NN", "ADV", "ADV", "KOKOM", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "im Raum erkennen? \u2013 Vielleicht sind wir ", "tokens": ["im", "Raum", "er\u00b7ken\u00b7nen", "?", "\u2013", "Viel\u00b7leicht", "sind", "wir"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVINF", "$.", "$(", "ADV", "VAFIN", "PPER"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "in Himmel andrer Wesen eingewoben,", "tokens": ["in", "Him\u00b7mel", "an\u00b7drer", "We\u00b7sen", "ein\u00b7ge\u00b7wo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die zu uns aufschaun abends. Vielleicht loben", "tokens": ["die", "zu", "uns", "auf\u00b7schaun", "a\u00b7bends", ".", "Viel\u00b7leicht", "lo\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "APPR", "PPER", "VVFIN", "ADV", "$.", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "uns ihre Dichter. Vielleicht beten viele", "tokens": ["uns", "ih\u00b7re", "Dich\u00b7ter.", "Viel\u00b7leicht", "be\u00b7ten", "vie\u00b7le"], "token_info": ["word", "word", "abbreviation", "word", "word", "word"], "pos": ["PPER", "PPOSAT", "NN", "ADV", "VVFIN", "PIS"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.8": {"text": "zu uns empor. Vielleicht sind wir die Ziele", "tokens": ["zu", "uns", "em\u00b7por", ".", "Viel\u00b7leicht", "sind", "wir", "die", "Zie\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "PTKVZ", "$.", "ADV", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "von fremden Fl\u00fcchen, die uns nie erreichen,", "tokens": ["von", "frem\u00b7den", "Fl\u00fc\u00b7chen", ",", "die", "uns", "nie", "er\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nachbaren eines Gottes, den sie meinen", "tokens": ["Nach\u00b7ba\u00b7ren", "ei\u00b7nes", "Got\u00b7tes", ",", "den", "sie", "mei\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "in unsrer H\u00f6he, wenn sie einsam weinen,", "tokens": ["in", "uns\u00b7rer", "H\u00f6\u00b7he", ",", "wenn", "sie", "ein\u00b7sam", "wei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KOUS", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "an den sie glauben und den sie verlieren,", "tokens": ["an", "den", "sie", "glau\u00b7ben", "und", "den", "sie", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVINF", "KON", "ART", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "und dessen Bildnis, wie ein Schein aus ihren", "tokens": ["und", "des\u00b7sen", "Bild\u00b7nis", ",", "wie", "ein", "Schein", "aus", "ih\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PRELAT", "NN", "$,", "PWAV", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "suchenden Lampen, fl\u00fcchtig und verweht,", "tokens": ["su\u00b7chen\u00b7den", "Lam\u00b7pen", ",", "fl\u00fcch\u00b7tig", "und", "ver\u00b7weht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.15": {"text": "\u00fcber unsere zerstreuten Gesichter geht....", "tokens": ["\u00fc\u00b7ber", "un\u00b7se\u00b7re", "zer\u00b7streu\u00b7ten", "Ge\u00b7sich\u00b7ter", "geht", "...."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}}}}}