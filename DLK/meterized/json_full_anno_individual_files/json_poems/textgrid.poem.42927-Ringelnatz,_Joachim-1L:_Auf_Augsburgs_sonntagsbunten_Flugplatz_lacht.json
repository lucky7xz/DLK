{"textgrid.poem.42927": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf Augsburgs sonntagsbunten Flugplatz lacht", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf Augsburgs sonntagsbunten Flugplatz lacht", "tokens": ["Auf", "Augs\u00b7burgs", "sonn\u00b7tags\u00b7bun\u00b7ten", "Flug\u00b7platz", "lacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Sonne. Doch vergeblich br\u00fctet", "tokens": ["Die", "Son\u00b7ne", ".", "Doch", "ver\u00b7geb\u00b7lich", "br\u00fc\u00b7tet"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$.", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie auf gigantische Dickh\u00e4uteriche,", "tokens": ["Sie", "auf", "gi\u00b7gan\u00b7ti\u00b7sche", "Dick\u00b7h\u00e4u\u00b7te\u00b7ri\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die von Miliz und Polizei bewacht", "tokens": ["Die", "von", "Mi\u00b7liz", "und", "Po\u00b7li\u00b7zei", "be\u00b7wacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und liebevoll von Feuerwehr beh\u00fctet,", "tokens": ["Und", "lie\u00b7be\u00b7voll", "von", "Feu\u00b7er\u00b7wehr", "be\u00b7h\u00fc\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dick aufgeblasen \u00fcberm Boden schweben,", "tokens": ["Dick", "auf\u00b7ge\u00b7bla\u00b7sen", "\u00fc\u00b7berm", "Bo\u00b7den", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Von Photographen, Pressevolk umgeben.", "tokens": ["Von", "Pho\u00b7to\u00b7gra\u00b7phen", ",", "Pres\u00b7se\u00b7volk", "um\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch nicht nur diese wichtigen Leuteriche,", "tokens": ["Doch", "nicht", "nur", "die\u00b7se", "wich\u00b7ti\u00b7gen", "Leu\u00b7te\u00b7ri\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sondern vor allem: viele Autos warten", "tokens": ["Son\u00b7dern", "vor", "al\u00b7lem", ":", "vie\u00b7le", "Au\u00b7tos", "war\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "$.", "PIAT", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Darauf, da\u00df jene gasgef\u00fcllten Tiere \u2013", "tokens": ["Da\u00b7rauf", ",", "da\u00df", "je\u00b7ne", "gas\u00b7ge\u00b7f\u00fcll\u00b7ten", "Tie\u00b7re", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihrer sind viere \u2013 p\u00fcnktlich drei Uhr starten.", "tokens": ["Ih\u00b7rer", "sind", "vie\u00b7re", "\u2013", "p\u00fcnkt\u00b7lich", "drei", "Uhr", "star\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PIS", "$(", "ADJD", "CARD", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.3": {"line.1": {"text": "Denn es sind Ehrenpreise ausgesetzt", "tokens": ["Denn", "es", "sind", "Eh\u00b7ren\u00b7prei\u00b7se", "aus\u00b7ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr alle Wagenf\u00fchrer, die", "tokens": ["F\u00fcr", "al\u00b7le", "Wa\u00b7gen\u00b7f\u00fch\u00b7rer", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als erste die Ballons, wenn sie", "tokens": ["Als", "ers\u00b7te", "die", "Bal\u00b7lons", ",", "wenn", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADJA", "ART", "NN", "$,", "KOUS", "PPER"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Gelandet sind, erwischen.", "tokens": ["Ge\u00b7lan\u00b7det", "sind", ",", "er\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Jetzt", "tokens": ["Jetzt"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Erhebt ein Wind sich. Unsre Riesen zerren", "tokens": ["Er\u00b7hebt", "ein", "Wind", "sich", ".", "Uns\u00b7re", "Rie\u00b7sen", "zer\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PRF", "$.", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "An ihren Fesseln wild. Wir, ihre Herren,", "tokens": ["An", "ih\u00b7ren", "Fes\u00b7seln", "wild", ".", "Wir", ",", "ih\u00b7re", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$.", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Klettern in ihre K\u00f6rbe. \u2013 Es schl\u00e4gt drei. \u2013", "tokens": ["Klet\u00b7tern", "in", "ih\u00b7re", "K\u00f6r\u00b7be", ".", "\u2013", "Es", "schl\u00e4gt", "drei", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$.", "$(", "PPER", "VVFIN", "CARD", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Gewichte l\u00f6sen sich. Man l\u00e4\u00dft uns frei.", "tokens": ["Ge\u00b7wich\u00b7te", "l\u00f6\u00b7sen", "sich", ".", "Man", "l\u00e4\u00dft", "uns", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$.", "PIS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Menge winkt. Wir steigen munter.", "tokens": ["Die", "Men\u00b7ge", "winkt", ".", "Wir", "stei\u00b7gen", "mun\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als Blick nicht ausreicht mehr noch Winkehand,", "tokens": ["Als", "Blick", "nicht", "aus\u00b7reicht", "mehr", "noch", "Win\u00b7ke\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Schwing ich mich auf der Gondel Rand", "tokens": ["Schwing", "ich", "mich", "auf", "der", "Gon\u00b7del", "Rand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und schleudre meinen Hut hinunter,", "tokens": ["Und", "schleud\u00b7re", "mei\u00b7nen", "Hut", "hin\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Der Frau zum Gru\u00df, dem Publikum", "tokens": ["Der", "Frau", "zum", "Gru\u00df", ",", "dem", "Pub\u00b7li\u00b7kum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Zum dankbar lauten Gaudium.", "tokens": ["Zum", "dank\u00b7bar", "lau\u00b7ten", "Gau\u00b7di\u00b7um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Mich k\u00fcmmert's anfangs nicht, wohin", "tokens": ["Mich", "k\u00fcm\u00b7mert's", "an\u00b7fangs", "nicht", ",", "wo\u00b7hin"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Luft uns f\u00fchrt. Im Korbe bin", "tokens": ["Die", "Luft", "uns", "f\u00fchrt", ".", "Im", "Kor\u00b7be", "bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$.", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich nur geladener Passagier.", "tokens": ["Ich", "nur", "ge\u00b7la\u00b7de\u00b7ner", "Pas\u00b7sa\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch Dr. Weltz, der F\u00fchrer, neben mir", "tokens": ["Doch", "Dr.", "Weltz", ",", "der", "F\u00fch\u00b7rer", ",", "ne\u00b7ben", "mir"], "token_info": ["word", "abbreviation", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "NN", "$,", "ART", "NN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Unparteiischer E. Scheuermann,", "tokens": ["Und", "Un\u00b7par\u00b7tei\u00b7i\u00b7scher", "E.", "Scheu\u00b7er\u00b7mann", ","], "token_info": ["word", "word", "abbreviation", "word", "punct"], "pos": ["KON", "NN", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Zwei altbew\u00e4hrte Meisterflieger, sehn", "tokens": ["Zwei", "alt\u00b7be\u00b7w\u00e4hr\u00b7te", "Meis\u00b7ter\u00b7flie\u00b7ger", ",", "sehn"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["CARD", "ADJA", "NN", "$,", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sich kundig um und zeigen l\u00e4chelnd dann", "tokens": ["Sich", "kun\u00b7dig", "um", "und", "zei\u00b7gen", "l\u00e4\u00b7chelnd", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "PTKVZ", "KON", "VVFIN", "ADJD", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mir in der Tiefe winzige Chausseen,", "tokens": ["Mir", "in", "der", "Tie\u00b7fe", "win\u00b7zi\u00b7ge", "Chaus\u00b7seen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Auf denen unserer Verfolger Wagen", "tokens": ["Auf", "de\u00b7nen", "un\u00b7se\u00b7rer", "Ver\u00b7fol\u00b7ger", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Bald lauernd halten, bald wild weiterjagen.", "tokens": ["Bald", "lau\u00b7ernd", "hal\u00b7ten", ",", "bald", "wild", "wei\u00b7ter\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Wir m\u00fcssen vor zwei Stunden niedergehn,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "vor", "zwei", "Stun\u00b7den", "nie\u00b7der\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch d\u00fcrfen erst nach einer Stunde landen.", "tokens": ["Doch", "d\u00fcr\u00b7fen", "erst", "nach", "ei\u00b7ner", "Stun\u00b7de", "lan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Acht S\u00e4cke Ballast sind vorhanden,", "tokens": ["Acht", "S\u00e4\u00b7cke", "Bal\u00b7last", "sind", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Me\u00dfapparate, hundert Meter Tau.", "tokens": ["Me\u00b7\u00df\u00b7ap\u00b7pa\u00b7ra\u00b7te", ",", "hun\u00b7dert", "Me\u00b7ter", "Tau", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die beiden Sachverst\u00e4ndigen zeigen,", "tokens": ["Die", "bei\u00b7den", "Sach\u00b7ver\u00b7st\u00e4n\u00b7di\u00b7gen", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Erkl\u00e4ren alles mir genau.", "tokens": ["Er\u00b7kl\u00e4\u00b7ren", "al\u00b7les", "mir", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und unterdessen steigen wir und steigen.", "tokens": ["Und", "un\u00b7ter\u00b7des\u00b7sen", "stei\u00b7gen", "wir", "und", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Eintausend Meter, zweitausend vierhundert,", "tokens": ["Ein\u00b7tau\u00b7send", "Me\u00b7ter", ",", "zweit\u00b7au\u00b7send", "vier\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "CARD", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "F\u00fcnfhundert \u2013 \u2013. Herrlich! Uns umwundert", "tokens": ["F\u00fcnf\u00b7hun\u00b7dert", "\u2013", "\u2013", ".", "Herr\u00b7lich", "!", "Uns", "um\u00b7wun\u00b7dert"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$(", "$(", "$.", "NE", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Adlerwelt der \u00dcberlegenheit.", "tokens": ["Die", "Ad\u00b7ler\u00b7welt", "der", "\u00dc\u00b7berl\u00b7e\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Herr Scheuermann notiert Ort, Stand und Zeit.", "tokens": ["Herr", "Scheu\u00b7er\u00b7mann", "no\u00b7tiert", "Ort", ",", "Stand", "und", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}}, "stanza.9": {"line.1": {"text": "\u00bbschaut! Jener Wald\u00ab, sagt unser F\u00fchrer, \u00bbw\u00e4r", "tokens": ["\u00bb", "schaut", "!", "Je\u00b7ner", "Wald", "\u00ab", ",", "sagt", "un\u00b7ser", "F\u00fch\u00b7rer", ",", "\u00bb", "w\u00e4r"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "VVFIN", "$.", "PDAT", "NN", "$(", "$,", "VVFIN", "PPOSAT", "NN", "$,", "$(", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der rechte Platz, sich zu verstecken.", "tokens": ["Der", "rech\u00b7te", "Platz", ",", "sich", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch leider schiebt die Str\u00f6mung uns kontr\u00e4r.", "tokens": ["Doch", "lei\u00b7der", "schiebt", "die", "Str\u00f6\u00b7mung", "uns", "kont\u00b7r\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir m\u00fcssen tiefer!\u00ab \u2013 Als ich voller Schrecken", "tokens": ["Wir", "m\u00fcs\u00b7sen", "tie\u00b7fer", "!", "\u00ab", "\u2013", "Als", "ich", "vol\u00b7ler", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "$.", "$(", "$(", "KOUS", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auf ein Gewitter \u00fcberm Wald weise,", "tokens": ["Auf", "ein", "Ge\u00b7wit\u00b7ter", "\u00fc\u00b7berm", "Wald", "wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Sagt Weltz: \u00bbDas st\u00f6rt nicht unsre Reise.\u00ab", "tokens": ["Sagt", "Weltz", ":", "\u00bb", "Das", "st\u00f6rt", "nicht", "uns\u00b7re", "Rei\u00b7se", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "$.", "$(", "PDS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und h\u00e4ngt sich wuchtig an das Gasventil.", "tokens": ["Und", "h\u00e4ngt", "sich", "wuch\u00b7tig", "an", "das", "Gas\u00b7ven\u00b7til", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Wir sinken rasch, wie wir an Buntpapieren,", "tokens": ["Wir", "sin\u00b7ken", "rasch", ",", "wie", "wir", "an", "Bunt\u00b7pa\u00b7pie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PWAV", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wir auswerfen, deutlich konstatieren.", "tokens": ["Die", "wir", "aus\u00b7wer\u00b7fen", ",", "deut\u00b7lich", "kons\u00b7ta\u00b7tie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Str\u00f6mung \u00e4ndert sich; der Wald wird Ziel.", "tokens": ["Die", "Str\u00f6\u00b7mung", "\u00e4n\u00b7dert", "sich", ";", "der", "Wald", "wird", "Ziel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$.", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Der Himmel hat sich drohend \u00fcberzogen.", "tokens": ["Der", "Him\u00b7mel", "hat", "sich", "dro\u00b7hend", "\u00fc\u00b7berz\u00b7o\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von den Ballons, die mit uns aufgeflogen,", "tokens": ["Von", "den", "Bal\u00b7lons", ",", "die", "mit", "uns", "auf\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Ist nurmehr einer fern zu sehn.", "tokens": ["Ist", "nur\u00b7mehr", "ei\u00b7ner", "fern", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wir, mit Gas und Spannung angef\u00fcllt,", "tokens": ["Und", "wir", ",", "mit", "Gas", "und", "Span\u00b7nung", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sind pl\u00f6tzlich ganz in Nebel eingeh\u00fcllt.", "tokens": ["Sind", "pl\u00f6tz\u00b7lich", "ganz", "in", "Ne\u00b7bel", "ein\u00b7ge\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Drei M\u00e4nner, die lautlos im Schweigen stehn.", "tokens": ["Drei", "M\u00e4n\u00b7ner", ",", "die", "laut\u00b7los", "im", "Schwei\u00b7gen", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "PRELS", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "O zauberhaftes Indenwolkenschweben!", "tokens": ["O", "zau\u00b7ber\u00b7haf\u00b7tes", "In\u00b7den\u00b7wol\u00b7ken\u00b7schwe\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So wie die M\u00e4rchenengel f\u00fcr die Kinder leben.", "tokens": ["So", "wie", "die", "M\u00e4r\u00b7che\u00b7nen\u00b7gel", "f\u00fcr", "die", "Kin\u00b7der", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wir lauschen, warten, fallen, \u2013 \u2013 \u00bbDa!\u00ab", "tokens": ["Wir", "lau\u00b7schen", ",", "war\u00b7ten", ",", "fal\u00b7len", ",", "\u2013", "\u2013", "\u00bb", "Da", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,", "$(", "$(", "$(", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da schimmert etwas unter uns und nah,", "tokens": ["Da", "schim\u00b7mert", "et\u00b7was", "un\u00b7ter", "uns", "und", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wird klar und klarer \u2013 \u2013 Gr\u00fcne Waldesmassen.", "tokens": ["Wird", "klar", "und", "kla\u00b7rer", "\u2013", "\u2013", "Gr\u00fc\u00b7ne", "Wal\u00b7des\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJA", "$(", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbdort in die Tannen!\u00ab \u2013 Gas entlassen,", "tokens": ["\u00bb", "dort", "in", "die", "Tan\u00b7nen", "!", "\u00ab", "\u2013", "Gas", "ent\u00b7las\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "$.", "$(", "$(", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Eh der Gewitterwind uns fa\u00dft und treibt!", "tokens": ["Eh", "der", "Ge\u00b7wit\u00b7ter\u00b7wind", "uns", "fa\u00dft", "und", "treibt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.13": {"line.1": {"text": "Die Gondel schl\u00e4gt in Tannenwipfel, bleibt", "tokens": ["Die", "Gon\u00b7del", "schl\u00e4gt", "in", "Tan\u00b7nen\u00b7wip\u00b7fel", ",", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dort h\u00e4ngen wie ein Riesenvogelnest.", "tokens": ["Dort", "h\u00e4n\u00b7gen", "wie", "ein", "Rie\u00b7sen\u00b7vo\u00b7gel\u00b7nest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sechs H\u00e4nde krallen im Gezweig sich fest.", "tokens": ["Sechs", "H\u00e4n\u00b7de", "kral\u00b7len", "im", "Ge\u00b7zweig", "sich", "fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPRART", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich mu\u00df die Wipfel um Verzeihung bitten.", "tokens": ["Ich", "mu\u00df", "die", "Wip\u00b7fel", "um", "Ver\u00b7zei\u00b7hung", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie haben sicherlich dabei gelitten.", "tokens": ["Sie", "ha\u00b7ben", "si\u00b7cher\u00b7lich", "da\u00b7bei", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "So schweben wir in h\u00f6chsten Nadelzweigen,", "tokens": ["So", "schwe\u00b7ben", "wir", "in", "h\u00f6chs\u00b7ten", "Na\u00b7del\u00b7zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schaun auf die Uhr und lauschen, lauschen, schweigen.", "tokens": ["Schaun", "auf", "die", "Uhr", "und", "lau\u00b7schen", ",", "lau\u00b7schen", ",", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "KON", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schon f\u00fcnf Minuten sind verronnen.", "tokens": ["Schon", "f\u00fcnf", "Mi\u00b7nu\u00b7ten", "sind", "ver\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcnf weitre unentdeckt, dann ist's gewonnen.", "tokens": ["F\u00fcnf", "weit\u00b7re", "un\u00b7ent\u00b7deckt", ",", "dann", "ist's", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "VVFIN", "ADJD", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Doch: T\u00f6ff t\u00f6ff t\u00f6ff \u2013 \u2013 Dann: Eine Stimme schreit", "tokens": ["Doch", ":", "T\u00f6ff", "t\u00f6ff", "t\u00f6ff", "\u2013", "\u2013", "Dann", ":", "Ei\u00b7ne", "Stim\u00b7me", "schreit"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$.", "FM.la", "FM.la", "FM.la", "$(", "$(", "ADV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Von unten auf: \u00bbHallo! Ergebt euch g\u00fctig!\u00ab", "tokens": ["Von", "un\u00b7ten", "auf", ":", "\u00bb", "Hal\u00b7lo", "!", "Er\u00b7gebt", "euch", "g\u00fc\u00b7tig", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$.", "$(", "NE", "$.", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.16": {"line.1": {"text": "Wir sind gefa\u00dft. Ich rufe \u00fcberm\u00fctig:", "tokens": ["Wir", "sind", "ge\u00b7fa\u00dft", ".", "Ich", "ru\u00b7fe", "\u00fc\u00b7berm\u00b7\u00fc\u00b7tig", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbbedaure sehr, wir sind noch nicht so weit!\u00ab", "tokens": ["\u00bb", "be\u00b7dau\u00b7re", "sehr", ",", "wir", "sind", "noch", "nicht", "so", "weit", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dabei versuchen wir, wie vorgenommen,", "tokens": ["Da\u00b7bei", "ver\u00b7su\u00b7chen", "wir", ",", "wie", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu einem Weiterfluge freizukommen.", "tokens": ["Zu", "ei\u00b7nem", "Wei\u00b7ter\u00b7flu\u00b7ge", "frei\u00b7zu\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Aus kleinen S\u00e4cken sch\u00fctten wir in Hast", "tokens": ["Aus", "klei\u00b7nen", "S\u00e4\u00b7cken", "sch\u00fct\u00b7ten", "wir", "in", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Auf die Verfolger all unsren Ballast", "tokens": ["Auf", "die", "Ver\u00b7fol\u00b7ger", "all", "un\u00b7sren", "Bal\u00b7last"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "ADJA", "NN"], "meter": "+--+--+---", "measure": "dactylic.tri.plus"}, "line.7": {"text": "Und ziehn uns luvw\u00e4rts gegen Sturm. \u2013 \u2013", "tokens": ["Und", "ziehn", "uns", "luv\u00b7w\u00e4rts", "ge\u00b7gen", "Sturm", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Zu sp\u00e4t!", "tokens": ["Zu", "sp\u00e4t", "!"], "token_info": ["word", "word", "punct"], "pos": ["PTKA", "ADJD", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Gewitter und ein Wolkenbruch entl\u00e4dt", "tokens": ["Ge\u00b7wit\u00b7ter", "und", "ein", "Wol\u00b7ken\u00b7bruch", "ent\u00b7l\u00e4dt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sich. Blitz und Gu\u00df und Donner. \u2013 Toll! \u2013", "tokens": ["Sich", ".", "Blitz", "und", "Gu\u00df", "und", "Don\u00b7ner", ".", "\u2013", "Toll", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["PRF", "$.", "NN", "KON", "NN", "KON", "NN", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und Weltz und Scheuermann, gleich einsichtsvoll,", "tokens": ["Und", "Weltz", "und", "Scheu\u00b7er\u00b7mann", ",", "gleich", "ein\u00b7sichts\u00b7voll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Ergeben sich an die, die uns gefunden.", "tokens": ["Er\u00b7ge\u00b7ben", "sich", "an", "die", ",", "die", "uns", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Weltz rei\u00dft die H\u00fclle auf. Wir sausen. \u2013 F\u00fcr Sekunden", "tokens": ["Weltz", "rei\u00dft", "die", "H\u00fcl\u00b7le", "auf", ".", "Wir", "sau\u00b7sen", ".", "\u2013", "F\u00fcr", "Se\u00b7kun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "$.", "$(", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hakt unser Korb in Zweigen fest. Und dann \u2013", "tokens": ["Hakt", "un\u00b7ser", "Korb", "in", "Zwei\u00b7gen", "fest", ".", "Und", "dann", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$.", "KON", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zehn Meter \u00fcberm Boden mag es sein \u2013", "tokens": ["Zehn", "Me\u00b7ter", "\u00fc\u00b7berm", "Bo\u00b7den", "mag", "es", "sein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "VMFIN", "PPER", "VAINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Plumpst er hinunter wie ein harter Stein.", "tokens": ["Plumpst", "er", "hin\u00b7un\u00b7ter", "wie", "ein", "har\u00b7ter", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "\u00bbseid ihr gesund?\u00ab \u2013 \u00bbJa!\u00ab Ich, Weltz, Scheuermann.", "tokens": ["\u00bb", "seid", "ihr", "ge\u00b7sund", "?", "\u00ab", "\u2013", "\u00bb", "Ja", "!", "\u00ab", "Ich", ",", "Weltz", ",", "Scheu\u00b7er\u00b7mann", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "VVPP", "$.", "$(", "$(", "$(", "PTKANT", "$.", "$(", "PPER", "$,", "NN", "$,", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.20": {"line.1": {"text": "Auf Augsburgs sonntagsbunten Flugplatz lacht", "tokens": ["Auf", "Augs\u00b7burgs", "sonn\u00b7tags\u00b7bun\u00b7ten", "Flug\u00b7platz", "lacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Sonne. Doch vergeblich br\u00fctet", "tokens": ["Die", "Son\u00b7ne", ".", "Doch", "ver\u00b7geb\u00b7lich", "br\u00fc\u00b7tet"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$.", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie auf gigantische Dickh\u00e4uteriche,", "tokens": ["Sie", "auf", "gi\u00b7gan\u00b7ti\u00b7sche", "Dick\u00b7h\u00e4u\u00b7te\u00b7ri\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die von Miliz und Polizei bewacht", "tokens": ["Die", "von", "Mi\u00b7liz", "und", "Po\u00b7li\u00b7zei", "be\u00b7wacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und liebevoll von Feuerwehr beh\u00fctet,", "tokens": ["Und", "lie\u00b7be\u00b7voll", "von", "Feu\u00b7er\u00b7wehr", "be\u00b7h\u00fc\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Dick aufgeblasen \u00fcberm Boden schweben,", "tokens": ["Dick", "auf\u00b7ge\u00b7bla\u00b7sen", "\u00fc\u00b7berm", "Bo\u00b7den", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Von Photographen, Pressevolk umgeben.", "tokens": ["Von", "Pho\u00b7to\u00b7gra\u00b7phen", ",", "Pres\u00b7se\u00b7volk", "um\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Doch nicht nur diese wichtigen Leuteriche,", "tokens": ["Doch", "nicht", "nur", "die\u00b7se", "wich\u00b7ti\u00b7gen", "Leu\u00b7te\u00b7ri\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sondern vor allem: viele Autos warten", "tokens": ["Son\u00b7dern", "vor", "al\u00b7lem", ":", "vie\u00b7le", "Au\u00b7tos", "war\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PIS", "$.", "PIAT", "NN", "VVINF"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Darauf, da\u00df jene gasgef\u00fcllten Tiere \u2013", "tokens": ["Da\u00b7rauf", ",", "da\u00df", "je\u00b7ne", "gas\u00b7ge\u00b7f\u00fcll\u00b7ten", "Tie\u00b7re", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "PDAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ihrer sind viere \u2013 p\u00fcnktlich drei Uhr starten.", "tokens": ["Ih\u00b7rer", "sind", "vie\u00b7re", "\u2013", "p\u00fcnkt\u00b7lich", "drei", "Uhr", "star\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "VAFIN", "PIS", "$(", "ADJD", "CARD", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}}, "stanza.22": {"line.1": {"text": "Denn es sind Ehrenpreise ausgesetzt", "tokens": ["Denn", "es", "sind", "Eh\u00b7ren\u00b7prei\u00b7se", "aus\u00b7ge\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr alle Wagenf\u00fchrer, die", "tokens": ["F\u00fcr", "al\u00b7le", "Wa\u00b7gen\u00b7f\u00fch\u00b7rer", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als erste die Ballons, wenn sie", "tokens": ["Als", "ers\u00b7te", "die", "Bal\u00b7lons", ",", "wenn", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADJA", "ART", "NN", "$,", "KOUS", "PPER"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Gelandet sind, erwischen.", "tokens": ["Ge\u00b7lan\u00b7det", "sind", ",", "er\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Jetzt", "tokens": ["Jetzt"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Erhebt ein Wind sich. Unsre Riesen zerren", "tokens": ["Er\u00b7hebt", "ein", "Wind", "sich", ".", "Uns\u00b7re", "Rie\u00b7sen", "zer\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PRF", "$.", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "An ihren Fesseln wild. Wir, ihre Herren,", "tokens": ["An", "ih\u00b7ren", "Fes\u00b7seln", "wild", ".", "Wir", ",", "ih\u00b7re", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "$.", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Klettern in ihre K\u00f6rbe. \u2013 Es schl\u00e4gt drei. \u2013", "tokens": ["Klet\u00b7tern", "in", "ih\u00b7re", "K\u00f6r\u00b7be", ".", "\u2013", "Es", "schl\u00e4gt", "drei", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$.", "$(", "PPER", "VVFIN", "CARD", "$.", "$("], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Gewichte l\u00f6sen sich. Man l\u00e4\u00dft uns frei.", "tokens": ["Ge\u00b7wich\u00b7te", "l\u00f6\u00b7sen", "sich", ".", "Man", "l\u00e4\u00dft", "uns", "frei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PRF", "$.", "PIS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Die Menge winkt. Wir steigen munter.", "tokens": ["Die", "Men\u00b7ge", "winkt", ".", "Wir", "stei\u00b7gen", "mun\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Als Blick nicht ausreicht mehr noch Winkehand,", "tokens": ["Als", "Blick", "nicht", "aus\u00b7reicht", "mehr", "noch", "Win\u00b7ke\u00b7hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PTKNEG", "VVFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Schwing ich mich auf der Gondel Rand", "tokens": ["Schwing", "ich", "mich", "auf", "der", "Gon\u00b7del", "Rand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und schleudre meinen Hut hinunter,", "tokens": ["Und", "schleud\u00b7re", "mei\u00b7nen", "Hut", "hin\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Der Frau zum Gru\u00df, dem Publikum", "tokens": ["Der", "Frau", "zum", "Gru\u00df", ",", "dem", "Pub\u00b7li\u00b7kum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Zum dankbar lauten Gaudium.", "tokens": ["Zum", "dank\u00b7bar", "lau\u00b7ten", "Gau\u00b7di\u00b7um", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Mich k\u00fcmmert's anfangs nicht, wohin", "tokens": ["Mich", "k\u00fcm\u00b7mert's", "an\u00b7fangs", "nicht", ",", "wo\u00b7hin"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Luft uns f\u00fchrt. Im Korbe bin", "tokens": ["Die", "Luft", "uns", "f\u00fchrt", ".", "Im", "Kor\u00b7be", "bin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$.", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich nur geladener Passagier.", "tokens": ["Ich", "nur", "ge\u00b7la\u00b7de\u00b7ner", "Pas\u00b7sa\u00b7gier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch Dr. Weltz, der F\u00fchrer, neben mir", "tokens": ["Doch", "Dr.", "Weltz", ",", "der", "F\u00fch\u00b7rer", ",", "ne\u00b7ben", "mir"], "token_info": ["word", "abbreviation", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "NN", "$,", "ART", "NN", "$,", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Unparteiischer E. Scheuermann,", "tokens": ["Und", "Un\u00b7par\u00b7tei\u00b7i\u00b7scher", "E.", "Scheu\u00b7er\u00b7mann", ","], "token_info": ["word", "word", "abbreviation", "word", "punct"], "pos": ["KON", "NN", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Zwei altbew\u00e4hrte Meisterflieger, sehn", "tokens": ["Zwei", "alt\u00b7be\u00b7w\u00e4hr\u00b7te", "Meis\u00b7ter\u00b7flie\u00b7ger", ",", "sehn"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["CARD", "ADJA", "NN", "$,", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Sich kundig um und zeigen l\u00e4chelnd dann", "tokens": ["Sich", "kun\u00b7dig", "um", "und", "zei\u00b7gen", "l\u00e4\u00b7chelnd", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "ADJD", "PTKVZ", "KON", "VVFIN", "ADJD", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Mir in der Tiefe winzige Chausseen,", "tokens": ["Mir", "in", "der", "Tie\u00b7fe", "win\u00b7zi\u00b7ge", "Chaus\u00b7seen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "Auf denen unserer Verfolger Wagen", "tokens": ["Auf", "de\u00b7nen", "un\u00b7se\u00b7rer", "Ver\u00b7fol\u00b7ger", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Bald lauernd halten, bald wild weiterjagen.", "tokens": ["Bald", "lau\u00b7ernd", "hal\u00b7ten", ",", "bald", "wild", "wei\u00b7ter\u00b7ja\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$,", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Wir m\u00fcssen vor zwei Stunden niedergehn,", "tokens": ["Wir", "m\u00fcs\u00b7sen", "vor", "zwei", "Stun\u00b7den", "nie\u00b7der\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Doch d\u00fcrfen erst nach einer Stunde landen.", "tokens": ["Doch", "d\u00fcr\u00b7fen", "erst", "nach", "ei\u00b7ner", "Stun\u00b7de", "lan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Acht S\u00e4cke Ballast sind vorhanden,", "tokens": ["Acht", "S\u00e4\u00b7cke", "Bal\u00b7last", "sind", "vor\u00b7han\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Me\u00dfapparate, hundert Meter Tau.", "tokens": ["Me\u00b7\u00df\u00b7ap\u00b7pa\u00b7ra\u00b7te", ",", "hun\u00b7dert", "Me\u00b7ter", "Tau", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "CARD", "NN", "NN", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "Die beiden Sachverst\u00e4ndigen zeigen,", "tokens": ["Die", "bei\u00b7den", "Sach\u00b7ver\u00b7st\u00e4n\u00b7di\u00b7gen", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Erkl\u00e4ren alles mir genau.", "tokens": ["Er\u00b7kl\u00e4\u00b7ren", "al\u00b7les", "mir", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Und unterdessen steigen wir und steigen.", "tokens": ["Und", "un\u00b7ter\u00b7des\u00b7sen", "stei\u00b7gen", "wir", "und", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Eintausend Meter, zweitausend vierhundert,", "tokens": ["Ein\u00b7tau\u00b7send", "Me\u00b7ter", ",", "zweit\u00b7au\u00b7send", "vier\u00b7hun\u00b7dert", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "CARD", "CARD", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "F\u00fcnfhundert \u2013 \u2013. Herrlich! Uns umwundert", "tokens": ["F\u00fcnf\u00b7hun\u00b7dert", "\u2013", "\u2013", ".", "Herr\u00b7lich", "!", "Uns", "um\u00b7wun\u00b7dert"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$(", "$(", "$.", "NE", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Adlerwelt der \u00dcberlegenheit.", "tokens": ["Die", "Ad\u00b7ler\u00b7welt", "der", "\u00dc\u00b7berl\u00b7e\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Herr Scheuermann notiert Ort, Stand und Zeit.", "tokens": ["Herr", "Scheu\u00b7er\u00b7mann", "no\u00b7tiert", "Ort", ",", "Stand", "und", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}}, "stanza.28": {"line.1": {"text": "\u00bbschaut! Jener Wald\u00ab, sagt unser F\u00fchrer, \u00bbw\u00e4r", "tokens": ["\u00bb", "schaut", "!", "Je\u00b7ner", "Wald", "\u00ab", ",", "sagt", "un\u00b7ser", "F\u00fch\u00b7rer", ",", "\u00bb", "w\u00e4r"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "VVFIN", "$.", "PDAT", "NN", "$(", "$,", "VVFIN", "PPOSAT", "NN", "$,", "$(", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der rechte Platz, sich zu verstecken.", "tokens": ["Der", "rech\u00b7te", "Platz", ",", "sich", "zu", "ver\u00b7ste\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch leider schiebt die Str\u00f6mung uns kontr\u00e4r.", "tokens": ["Doch", "lei\u00b7der", "schiebt", "die", "Str\u00f6\u00b7mung", "uns", "kont\u00b7r\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "PPER", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wir m\u00fcssen tiefer!\u00ab \u2013 Als ich voller Schrecken", "tokens": ["Wir", "m\u00fcs\u00b7sen", "tie\u00b7fer", "!", "\u00ab", "\u2013", "Als", "ich", "vol\u00b7ler", "Schre\u00b7cken"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADJD", "$.", "$(", "$(", "KOUS", "PPER", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Auf ein Gewitter \u00fcberm Wald weise,", "tokens": ["Auf", "ein", "Ge\u00b7wit\u00b7ter", "\u00fc\u00b7berm", "Wald", "wei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}, "line.6": {"text": "Sagt Weltz: \u00bbDas st\u00f6rt nicht unsre Reise.\u00ab", "tokens": ["Sagt", "Weltz", ":", "\u00bb", "Das", "st\u00f6rt", "nicht", "uns\u00b7re", "Rei\u00b7se", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "$.", "$(", "PDS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und h\u00e4ngt sich wuchtig an das Gasventil.", "tokens": ["Und", "h\u00e4ngt", "sich", "wuch\u00b7tig", "an", "das", "Gas\u00b7ven\u00b7til", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Wir sinken rasch, wie wir an Buntpapieren,", "tokens": ["Wir", "sin\u00b7ken", "rasch", ",", "wie", "wir", "an", "Bunt\u00b7pa\u00b7pie\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PWAV", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die wir auswerfen, deutlich konstatieren.", "tokens": ["Die", "wir", "aus\u00b7wer\u00b7fen", ",", "deut\u00b7lich", "kons\u00b7ta\u00b7tie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Str\u00f6mung \u00e4ndert sich; der Wald wird Ziel.", "tokens": ["Die", "Str\u00f6\u00b7mung", "\u00e4n\u00b7dert", "sich", ";", "der", "Wald", "wird", "Ziel", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$.", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Der Himmel hat sich drohend \u00fcberzogen.", "tokens": ["Der", "Him\u00b7mel", "hat", "sich", "dro\u00b7hend", "\u00fc\u00b7berz\u00b7o\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von den Ballons, die mit uns aufgeflogen,", "tokens": ["Von", "den", "Bal\u00b7lons", ",", "die", "mit", "uns", "auf\u00b7ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+++-+-+-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Ist nurmehr einer fern zu sehn.", "tokens": ["Ist", "nur\u00b7mehr", "ei\u00b7ner", "fern", "zu", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und wir, mit Gas und Spannung angef\u00fcllt,", "tokens": ["Und", "wir", ",", "mit", "Gas", "und", "Span\u00b7nung", "an\u00b7ge\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sind pl\u00f6tzlich ganz in Nebel eingeh\u00fcllt.", "tokens": ["Sind", "pl\u00f6tz\u00b7lich", "ganz", "in", "Ne\u00b7bel", "ein\u00b7ge\u00b7h\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Drei M\u00e4nner, die lautlos im Schweigen stehn.", "tokens": ["Drei", "M\u00e4n\u00b7ner", ",", "die", "laut\u00b7los", "im", "Schwei\u00b7gen", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "PRELS", "ADJD", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "O zauberhaftes Indenwolkenschweben!", "tokens": ["O", "zau\u00b7ber\u00b7haf\u00b7tes", "In\u00b7den\u00b7wol\u00b7ken\u00b7schwe\u00b7ben", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "So wie die M\u00e4rchenengel f\u00fcr die Kinder leben.", "tokens": ["So", "wie", "die", "M\u00e4r\u00b7che\u00b7nen\u00b7gel", "f\u00fcr", "die", "Kin\u00b7der", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Wir lauschen, warten, fallen, \u2013 \u2013 \u00bbDa!\u00ab", "tokens": ["Wir", "lau\u00b7schen", ",", "war\u00b7ten", ",", "fal\u00b7len", ",", "\u2013", "\u2013", "\u00bb", "Da", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "$,", "VVINF", "$,", "$(", "$(", "$(", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da schimmert etwas unter uns und nah,", "tokens": ["Da", "schim\u00b7mert", "et\u00b7was", "un\u00b7ter", "uns", "und", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PPER", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wird klar und klarer \u2013 \u2013 Gr\u00fcne Waldesmassen.", "tokens": ["Wird", "klar", "und", "kla\u00b7rer", "\u2013", "\u2013", "Gr\u00fc\u00b7ne", "Wal\u00b7des\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJA", "$(", "$(", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbdort in die Tannen!\u00ab \u2013 Gas entlassen,", "tokens": ["\u00bb", "dort", "in", "die", "Tan\u00b7nen", "!", "\u00ab", "\u2013", "Gas", "ent\u00b7las\u00b7sen", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "$.", "$(", "$(", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Eh der Gewitterwind uns fa\u00dft und treibt!", "tokens": ["Eh", "der", "Ge\u00b7wit\u00b7ter\u00b7wind", "uns", "fa\u00dft", "und", "treibt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.32": {"line.1": {"text": "Die Gondel schl\u00e4gt in Tannenwipfel, bleibt", "tokens": ["Die", "Gon\u00b7del", "schl\u00e4gt", "in", "Tan\u00b7nen\u00b7wip\u00b7fel", ",", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dort h\u00e4ngen wie ein Riesenvogelnest.", "tokens": ["Dort", "h\u00e4n\u00b7gen", "wie", "ein", "Rie\u00b7sen\u00b7vo\u00b7gel\u00b7nest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sechs H\u00e4nde krallen im Gezweig sich fest.", "tokens": ["Sechs", "H\u00e4n\u00b7de", "kral\u00b7len", "im", "Ge\u00b7zweig", "sich", "fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "APPRART", "NN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich mu\u00df die Wipfel um Verzeihung bitten.", "tokens": ["Ich", "mu\u00df", "die", "Wip\u00b7fel", "um", "Ver\u00b7zei\u00b7hung", "bit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Sie haben sicherlich dabei gelitten.", "tokens": ["Sie", "ha\u00b7ben", "si\u00b7cher\u00b7lich", "da\u00b7bei", "ge\u00b7lit\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "So schweben wir in h\u00f6chsten Nadelzweigen,", "tokens": ["So", "schwe\u00b7ben", "wir", "in", "h\u00f6chs\u00b7ten", "Na\u00b7del\u00b7zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Schaun auf die Uhr und lauschen, lauschen, schweigen.", "tokens": ["Schaun", "auf", "die", "Uhr", "und", "lau\u00b7schen", ",", "lau\u00b7schen", ",", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "KON", "VVINF", "$,", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schon f\u00fcnf Minuten sind verronnen.", "tokens": ["Schon", "f\u00fcnf", "Mi\u00b7nu\u00b7ten", "sind", "ver\u00b7ron\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcnf weitre unentdeckt, dann ist's gewonnen.", "tokens": ["F\u00fcnf", "weit\u00b7re", "un\u00b7ent\u00b7deckt", ",", "dann", "ist's", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "VVFIN", "ADJD", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Doch: T\u00f6ff t\u00f6ff t\u00f6ff \u2013 \u2013 Dann: Eine Stimme schreit", "tokens": ["Doch", ":", "T\u00f6ff", "t\u00f6ff", "t\u00f6ff", "\u2013", "\u2013", "Dann", ":", "Ei\u00b7ne", "Stim\u00b7me", "schreit"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$.", "FM.la", "FM.la", "FM.la", "$(", "$(", "ADV", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Von unten auf: \u00bbHallo! Ergebt euch g\u00fctig!\u00ab", "tokens": ["Von", "un\u00b7ten", "auf", ":", "\u00bb", "Hal\u00b7lo", "!", "Er\u00b7gebt", "euch", "g\u00fc\u00b7tig", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "PTKVZ", "$.", "$(", "NE", "$.", "VVFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.35": {"line.1": {"text": "Wir sind gefa\u00dft. Ich rufe \u00fcberm\u00fctig:", "tokens": ["Wir", "sind", "ge\u00b7fa\u00dft", ".", "Ich", "ru\u00b7fe", "\u00fc\u00b7berm\u00b7\u00fc\u00b7tig", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbbedaure sehr, wir sind noch nicht so weit!\u00ab", "tokens": ["\u00bb", "be\u00b7dau\u00b7re", "sehr", ",", "wir", "sind", "noch", "nicht", "so", "weit", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "ADV", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dabei versuchen wir, wie vorgenommen,", "tokens": ["Da\u00b7bei", "ver\u00b7su\u00b7chen", "wir", ",", "wie", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu einem Weiterfluge freizukommen.", "tokens": ["Zu", "ei\u00b7nem", "Wei\u00b7ter\u00b7flu\u00b7ge", "frei\u00b7zu\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Aus kleinen S\u00e4cken sch\u00fctten wir in Hast", "tokens": ["Aus", "klei\u00b7nen", "S\u00e4\u00b7cken", "sch\u00fct\u00b7ten", "wir", "in", "Hast"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Auf die Verfolger all unsren Ballast", "tokens": ["Auf", "die", "Ver\u00b7fol\u00b7ger", "all", "un\u00b7sren", "Bal\u00b7last"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PIAT", "ADJA", "NN"], "meter": "+--+--+---", "measure": "dactylic.tri.plus"}, "line.7": {"text": "Und ziehn uns luvw\u00e4rts gegen Sturm. \u2013 \u2013", "tokens": ["Und", "ziehn", "uns", "luv\u00b7w\u00e4rts", "ge\u00b7gen", "Sturm", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Zu sp\u00e4t!", "tokens": ["Zu", "sp\u00e4t", "!"], "token_info": ["word", "word", "punct"], "pos": ["PTKA", "ADJD", "$."], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Gewitter und ein Wolkenbruch entl\u00e4dt", "tokens": ["Ge\u00b7wit\u00b7ter", "und", "ein", "Wol\u00b7ken\u00b7bruch", "ent\u00b7l\u00e4dt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sich. Blitz und Gu\u00df und Donner. \u2013 Toll! \u2013", "tokens": ["Sich", ".", "Blitz", "und", "Gu\u00df", "und", "Don\u00b7ner", ".", "\u2013", "Toll", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["PRF", "$.", "NN", "KON", "NN", "KON", "NN", "$.", "$(", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Und Weltz und Scheuermann, gleich einsichtsvoll,", "tokens": ["Und", "Weltz", "und", "Scheu\u00b7er\u00b7mann", ",", "gleich", "ein\u00b7sichts\u00b7voll", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Ergeben sich an die, die uns gefunden.", "tokens": ["Er\u00b7ge\u00b7ben", "sich", "an", "die", ",", "die", "uns", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ART", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Weltz rei\u00dft die H\u00fclle auf. Wir sausen. \u2013 F\u00fcr Sekunden", "tokens": ["Weltz", "rei\u00dft", "die", "H\u00fcl\u00b7le", "auf", ".", "Wir", "sau\u00b7sen", ".", "\u2013", "F\u00fcr", "Se\u00b7kun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "$.", "$(", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hakt unser Korb in Zweigen fest. Und dann \u2013", "tokens": ["Hakt", "un\u00b7ser", "Korb", "in", "Zwei\u00b7gen", "fest", ".", "Und", "dann", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "NN", "PTKVZ", "$.", "KON", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zehn Meter \u00fcberm Boden mag es sein \u2013", "tokens": ["Zehn", "Me\u00b7ter", "\u00fc\u00b7berm", "Bo\u00b7den", "mag", "es", "sein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "VMFIN", "PPER", "VAINF", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Plumpst er hinunter wie ein harter Stein.", "tokens": ["Plumpst", "er", "hin\u00b7un\u00b7ter", "wie", "ein", "har\u00b7ter", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "\u00bbseid ihr gesund?\u00ab \u2013 \u00bbJa!\u00ab Ich, Weltz, Scheuermann.", "tokens": ["\u00bb", "seid", "ihr", "ge\u00b7sund", "?", "\u00ab", "\u2013", "\u00bb", "Ja", "!", "\u00ab", "Ich", ",", "Weltz", ",", "Scheu\u00b7er\u00b7mann", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "punct", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "VAFIN", "PPER", "VVPP", "$.", "$(", "$(", "$(", "PTKANT", "$.", "$(", "PPER", "$,", "NN", "$,", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}}}}