{"textgrid.poem.44504": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Die Muse beklagt sich", "genre": "verse", "period": "N.A.", "pub_year": 1840, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was kommt ihr mit Spie\u00dfen und Stangen,", "tokens": ["Was", "kommt", "ihr", "mit", "Spie\u00b7\u00dfen", "und", "Stan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Mich zu fangen?", "tokens": ["Mich", "zu", "fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dem Himmel sei es geklagt,", "tokens": ["Dem", "Him\u00b7mel", "sei", "es", "ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Bin doch nur eine arme Magd!", "tokens": ["Bin", "doch", "nur", "ei\u00b7ne", "ar\u00b7me", "Magd", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Wollt mit Schlingen und Netzen", "tokens": ["Wollt", "mit", "Schlin\u00b7gen", "und", "Net\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "KON", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mich rings umsetzen!", "tokens": ["Mich", "rings", "um\u00b7set\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ich aber, schlanker als ein Aal,", "tokens": ["Ich", "a\u00b7ber", ",", "schlan\u00b7ker", "als", "ein", "Aal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entschl\u00fcpf euch allzumal.", "tokens": ["Ent\u00b7schl\u00fcpf", "euch", "all\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Etwa mein Schwesterlein,", "tokens": ["Et\u00b7wa", "mein", "Schwes\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Prosa hei\u00dft sie gemein,", "tokens": ["Pro\u00b7sa", "hei\u00dft", "sie", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Tr\u00e4gt oft mein Gewand,", "tokens": ["Tr\u00e4gt", "oft", "mein", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Die f\u00e4ngt man mit der Hand,", "tokens": ["Die", "f\u00e4ngt", "man", "mit", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich selber, auf Klippen und H\u00f6hn,", "tokens": ["Ich", "sel\u00b7ber", ",", "auf", "Klip\u00b7pen", "und", "H\u00f6hn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Lieb es, allein zu gehn,", "tokens": ["Lieb", "es", ",", "al\u00b7lein", "zu", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wer nicht klettert und springt,", "tokens": ["Wer", "nicht", "klet\u00b7tert", "und", "springt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Selbst nicht mein Anschaun erringt;", "tokens": ["Selbst", "nicht", "mein", "An\u00b7schaun", "er\u00b7ringt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Und ein Kamel nicht so schwer", "tokens": ["Und", "ein", "Ka\u00b7mel", "nicht", "so", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKNEG", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geht durch ein Nadel\u00f6hr,", "tokens": ["Geht", "durch", "ein", "Na\u00b7de\u00b7l\u00f6hr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als, mit Zitaten bepackt,", "tokens": ["Als", ",", "mit", "Zi\u00b7ta\u00b7ten", "be\u00b7packt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Einer die Muse erjagt.", "tokens": ["Ei\u00b7ner", "die", "Mu\u00b7se", "er\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.6": {"line.1": {"text": "Erst warens die Philosophen,", "tokens": ["Erst", "wa\u00b7rens", "die", "Phi\u00b7lo\u00b7so\u00b7phen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fuhren hervor hinterm Ofen,", "tokens": ["Fuh\u00b7ren", "her\u00b7vor", "hin\u00b7term", "O\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meinten mit cur und mit quare", "tokens": ["Mein\u00b7ten", "mit", "cur", "und", "mit", "qua\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Mich zu lehren das Wahre.", "tokens": ["Mich", "zu", "leh\u00b7ren", "das", "Wah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.7": {"line.1": {"text": "Drauf die Dichter, die halben,", "tokens": ["Drauf", "die", "Dich\u00b7ter", ",", "die", "hal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Prosa beduftet mit Salben,", "tokens": ["Pro\u00b7sa", "be\u00b7duf\u00b7tet", "mit", "Sal\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Ludwig Tieck und Geno\u00df,", "tokens": ["Lud\u00b7wig", "Tieck", "und", "Ge\u00b7no\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "All der Novellentro\u00df,", "tokens": ["All", "der", "No\u00b7vel\u00b7len\u00b7tro\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Endlich gar die Historiker,", "tokens": ["End\u00b7lich", "gar", "die", "His\u00b7to\u00b7ri\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4ppisch wie kein Voriger:", "tokens": ["T\u00e4p\u00b7pisch", "wie", "kein", "Vo\u00b7ri\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "PIAT", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Friedrich Raumer, der Schalk,", "tokens": ["Fried\u00b7rich", "Rau\u00b7mer", ",", "der", "Schalk", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Pa\u00dft in jeden Balg.", "tokens": ["Pa\u00dft", "in", "je\u00b7den", "Balg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "W\u00e4r doch der Letzte Gervinus,", "tokens": ["W\u00e4r", "doch", "der", "Letz\u00b7te", "Ger\u00b7vi\u00b7nus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt sein historisches Minus", "tokens": ["H\u00e4lt", "sein", "his\u00b7to\u00b7ri\u00b7sches", "Mi\u00b7nus"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "F\u00fcr ein poetisches Plus,", "tokens": ["F\u00fcr", "ein", "po\u00b7e\u00b7ti\u00b7sches", "Plus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "O Asinus!", "tokens": ["O", "A\u00b7si\u00b7nus", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Was kommt ihr mit Spie\u00dfen und Stangen,", "tokens": ["Was", "kommt", "ihr", "mit", "Spie\u00b7\u00dfen", "und", "Stan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Mich zu fangen?", "tokens": ["Mich", "zu", "fan\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Dem Himmel sei es geklagt,", "tokens": ["Dem", "Him\u00b7mel", "sei", "es", "ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Bin doch nur eine arme Magd!", "tokens": ["Bin", "doch", "nur", "ei\u00b7ne", "ar\u00b7me", "Magd", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Wollt mit Schlingen und Netzen", "tokens": ["Wollt", "mit", "Schlin\u00b7gen", "und", "Net\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "KON", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mich rings umsetzen!", "tokens": ["Mich", "rings", "um\u00b7set\u00b7zen", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Ich aber, schlanker als ein Aal,", "tokens": ["Ich", "a\u00b7ber", ",", "schlan\u00b7ker", "als", "ein", "Aal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entschl\u00fcpf euch allzumal.", "tokens": ["Ent\u00b7schl\u00fcpf", "euch", "all\u00b7zu\u00b7mal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Etwa mein Schwesterlein,", "tokens": ["Et\u00b7wa", "mein", "Schwes\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Prosa hei\u00dft sie gemein,", "tokens": ["Pro\u00b7sa", "hei\u00dft", "sie", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Tr\u00e4gt oft mein Gewand,", "tokens": ["Tr\u00e4gt", "oft", "mein", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Die f\u00e4ngt man mit der Hand,", "tokens": ["Die", "f\u00e4ngt", "man", "mit", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ich selber, auf Klippen und H\u00f6hn,", "tokens": ["Ich", "sel\u00b7ber", ",", "auf", "Klip\u00b7pen", "und", "H\u00f6hn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Lieb es, allein zu gehn,", "tokens": ["Lieb", "es", ",", "al\u00b7lein", "zu", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Wer nicht klettert und springt,", "tokens": ["Wer", "nicht", "klet\u00b7tert", "und", "springt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Selbst nicht mein Anschaun erringt;", "tokens": ["Selbst", "nicht", "mein", "An\u00b7schaun", "er\u00b7ringt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.14": {"line.1": {"text": "Und ein Kamel nicht so schwer", "tokens": ["Und", "ein", "Ka\u00b7mel", "nicht", "so", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "PTKNEG", "ADV", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Geht durch ein Nadel\u00f6hr,", "tokens": ["Geht", "durch", "ein", "Na\u00b7de\u00b7l\u00f6hr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als, mit Zitaten bepackt,", "tokens": ["Als", ",", "mit", "Zi\u00b7ta\u00b7ten", "be\u00b7packt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.4": {"text": "Einer die Muse erjagt.", "tokens": ["Ei\u00b7ner", "die", "Mu\u00b7se", "er\u00b7jagt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "ART", "NN", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.15": {"line.1": {"text": "Erst warens die Philosophen,", "tokens": ["Erst", "wa\u00b7rens", "die", "Phi\u00b7lo\u00b7so\u00b7phen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fuhren hervor hinterm Ofen,", "tokens": ["Fuh\u00b7ren", "her\u00b7vor", "hin\u00b7term", "O\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Meinten mit cur und mit quare", "tokens": ["Mein\u00b7ten", "mit", "cur", "und", "mit", "qua\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Mich zu lehren das Wahre.", "tokens": ["Mich", "zu", "leh\u00b7ren", "das", "Wah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.16": {"line.1": {"text": "Drauf die Dichter, die halben,", "tokens": ["Drauf", "die", "Dich\u00b7ter", ",", "die", "hal\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Prosa beduftet mit Salben,", "tokens": ["Pro\u00b7sa", "be\u00b7duf\u00b7tet", "mit", "Sal\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Ludwig Tieck und Geno\u00df,", "tokens": ["Lud\u00b7wig", "Tieck", "und", "Ge\u00b7no\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "All der Novellentro\u00df,", "tokens": ["All", "der", "No\u00b7vel\u00b7len\u00b7tro\u00df", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.17": {"line.1": {"text": "Endlich gar die Historiker,", "tokens": ["End\u00b7lich", "gar", "die", "His\u00b7to\u00b7ri\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4ppisch wie kein Voriger:", "tokens": ["T\u00e4p\u00b7pisch", "wie", "kein", "Vo\u00b7ri\u00b7ger", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "PIAT", "NN", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.3": {"text": "Friedrich Raumer, der Schalk,", "tokens": ["Fried\u00b7rich", "Rau\u00b7mer", ",", "der", "Schalk", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Pa\u00dft in jeden Balg.", "tokens": ["Pa\u00dft", "in", "je\u00b7den", "Balg", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "W\u00e4r doch der Letzte Gervinus,", "tokens": ["W\u00e4r", "doch", "der", "Letz\u00b7te", "Ger\u00b7vi\u00b7nus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "H\u00e4lt sein historisches Minus", "tokens": ["H\u00e4lt", "sein", "his\u00b7to\u00b7ri\u00b7sches", "Mi\u00b7nus"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "F\u00fcr ein poetisches Plus,", "tokens": ["F\u00fcr", "ein", "po\u00b7e\u00b7ti\u00b7sches", "Plus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "O Asinus!", "tokens": ["O", "A\u00b7si\u00b7nus", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}