{"textgrid.poem.41200": {"metadata": {"author": {"name": "Denis, Michael", "birth": "N.A.", "death": "N.A."}, "title": "1L: Das Grau der Vorzeit hellt sich dem Barden auf.", "genre": "verse", "period": "N.A.", "pub_year": 1764, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das Grau der Vorzeit hellt sich dem Barden auf.", "tokens": ["Das", "Grau", "der", "Vor\u00b7zeit", "hellt", "sich", "dem", "Bar\u00b7den", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er sieht. Ein Spr\u00f6\u00dfling laubt sich vor ihm empor,", "tokens": ["Er", "sieht", ".", "Ein", "Spr\u00f6\u00df\u00b7ling", "laubt", "sich", "vor", "ihm", "em\u00b7por", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "PRF", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Un\u00fcberpflanzt, in eig'nem Grunde,", "tokens": ["Un\u00b7\u00fc\u00b7ber\u00b7pflanzt", ",", "in", "eig'\u00b7nem", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Strecket er Wipfel und Nebenzweige,", "tokens": ["Stre\u00b7cket", "er", "Wip\u00b7fel", "und", "Ne\u00b7ben\u00b7zwei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.2": {"line.1": {"text": "Wird Baum, erzeuget Aeste. Sein waldig Haupt", "tokens": ["Wird", "Baum", ",", "er\u00b7zeu\u00b7get", "A\u00b7es\u00b7te", ".", "Sein", "wal\u00b7dig", "Haupt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NE", "$,", "VVFIN", "NN", "$.", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erraget Wolken, schattet Gebirgen selbst.", "tokens": ["Er\u00b7ra\u00b7get", "Wol\u00b7ken", ",", "schat\u00b7tet", "Ge\u00b7bir\u00b7gen", "selbst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "VVFIN", "NN", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Rhein, Weser, Elbe, Weichsel, Donau", "tokens": ["Rhein", ",", "We\u00b7ser", ",", "El\u00b7be", ",", "Weich\u00b7sel", ",", "Do\u00b7nau"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,", "NN", "$,", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Tr\u00e4nken die Tausende seiner Wurzeln.", "tokens": ["Tr\u00e4n\u00b7ken", "die", "Tau\u00b7sen\u00b7de", "sei\u00b7ner", "Wur\u00b7zeln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "Er bl\u00fch't, und reifet Samen. Der Winde Zug", "tokens": ["Er", "bl\u00fch't", ",", "und", "rei\u00b7fet", "Sa\u00b7men", ".", "Der", "Win\u00b7de", "Zug"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "NN", "$.", "ART", "NN", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vertr\u00e4gt die reifen K\u00f6rner in Ost und West", "tokens": ["Ver\u00b7tr\u00e4gt", "die", "rei\u00b7fen", "K\u00f6r\u00b7ner", "in", "Ost", "und", "West"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und S\u00fcd und Nord. Vom Mutterstamme", "tokens": ["Und", "S\u00fcd", "und", "Nord", ".", "Vom", "Mut\u00b7ter\u00b7stam\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NE", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fallen sie ferne, gewinnen Erde.", "tokens": ["Fal\u00b7len", "sie", "fer\u00b7ne", ",", "ge\u00b7win\u00b7nen", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.4": {"line.1": {"text": "Ein Korn (verge\u00dft, o S\u00f6hne von Teut, es nicht!", "tokens": ["Ein", "Korn", "(", "ver\u00b7ge\u00dft", ",", "o", "S\u00f6h\u00b7ne", "von", "Teut", ",", "es", "nicht", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "$,", "FM", "NN", "APPR", "NE", "$,", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sind schon dazwischen lange Jahrhunderte)", "tokens": ["Sind", "schon", "da\u00b7zwi\u00b7schen", "lan\u00b7ge", "Jahr\u00b7hun\u00b7der\u00b7te", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Flog einst den Rhein hin\u00fcber, grub sich", "tokens": ["Flog", "einst", "den", "Rhein", "hin\u00b7\u00fc\u00b7ber", ",", "grub", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NE", "ADV", "$,", "VVFIN", "PRF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Keimend in sonnenerhitzte Schollen,", "tokens": ["Kei\u00b7mend", "in", "son\u00b7ne\u00b7ner\u00b7hitz\u00b7te", "Schol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Und trieb Gescho\u00df und Wipfel, und eiferte", "tokens": ["Und", "trieb", "Ge\u00b7scho\u00df", "und", "Wip\u00b7fel", ",", "und", "ei\u00b7fer\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit seinem Mutterstamme. Gar oft erscholl:", "tokens": ["Mit", "sei\u00b7nem", "Mut\u00b7ter\u00b7stam\u00b7me", ".", "Gar", "oft", "er\u00b7scholl", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "\u00bbund wer, wer ist denn meine Mutter?\u00ab", "tokens": ["\u00bb", "und", "wer", ",", "wer", "ist", "denn", "mei\u00b7ne", "Mut\u00b7ter", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "$,", "PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus des erregteren Wipfel's H\u00f6hen.", "tokens": ["Aus", "des", "er\u00b7reg\u00b7te\u00b7ren", "Wip\u00b7fel's", "H\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Da st\u00fcrzten Felsenklumpen, dem Wanderer", "tokens": ["Da", "st\u00fcrz\u00b7ten", "Fel\u00b7sen\u00b7klum\u00b7pen", ",", "dem", "Wan\u00b7de\u00b7rer"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Un\u00fcbersteigbar, gr\u00e4\u00dflich an's Ufer her,", "tokens": ["Un\u00b7\u00fc\u00b7bers\u00b7teig\u00b7bar", ",", "gr\u00e4\u00df\u00b7lich", "an's", "U\u00b7fer", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und jeder Uebergang des Rheines", "tokens": ["Und", "je\u00b7der", "Ue\u00b7ber\u00b7gang", "des", "Rhei\u00b7nes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ART", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Barg sich in feindliche Dorngeb\u00fcsche.", "tokens": ["Barg", "sich", "in", "feind\u00b7li\u00b7che", "Dorn\u00b7ge\u00b7b\u00fc\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.7": {"line.1": {"text": "Therese kam. \u00bbWie lange schreckt es noch", "tokens": ["The\u00b7re\u00b7se", "kam", ".", "\u00bb", "Wie", "lan\u00b7ge", "schreckt", "es", "noch"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$.", "$(", "PWAV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Am Rheine?\u00ab war ihr Wort, dem Mann' ein Wink,", "tokens": ["Am", "Rhei\u00b7ne", "?", "\u00ab", "war", "ihr", "Wort", ",", "dem", "Mann'", "ein", "Wink", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "$.", "$(", "VAFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der ihre gro\u00dfe Seele ganz versteht", "tokens": ["Der", "ih\u00b7re", "gro\u00b7\u00dfe", "See\u00b7le", "ganz", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er sah' der Felsenklumpen wilden Sturz,", "tokens": ["Er", "sah'", "der", "Fel\u00b7sen\u00b7klum\u00b7pen", "wil\u00b7den", "Sturz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Dorngeb\u00fcsche feindliches Gewirr'", "tokens": ["Der", "Dorn\u00b7ge\u00b7b\u00fc\u00b7sche", "feind\u00b7li\u00b7ches", "Ge\u00b7wirr'"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mit jener stillen Geisteshoheit an,", "tokens": ["Mit", "je\u00b7ner", "stil\u00b7len", "Geis\u00b7tes\u00b7ho\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die seiner Herrscher ihn so w\u00fcrdig macht.", "tokens": ["Die", "sei\u00b7ner", "Herr\u00b7scher", "ihn", "so", "w\u00fcr\u00b7dig", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sie schwanden weg.", "tokens": ["Sie", "schwan\u00b7den", "weg", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Wie sollten sie nicht schwinden?", "tokens": ["Wie", "soll\u00b7ten", "sie", "nicht", "schwin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Denn mu\u00dfte nicht Antonia,", "tokens": ["Denn", "mu\u00df\u00b7te", "nicht", "An\u00b7to\u00b7nia", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In welcher sich verj\u00fcngt die G\u00f6ttermutter sah,", "tokens": ["In", "wel\u00b7cher", "sich", "ver\u00b7j\u00fcngt", "die", "G\u00f6t\u00b7ter\u00b7mut\u00b7ter", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Weg gebahnet finden,", "tokens": ["Den", "Weg", "ge\u00b7bah\u00b7net", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Um an des Frankenk\u00f6nig's Hand", "tokens": ["Um", "an", "des", "Fran\u00b7ken\u00b7k\u00f6\u00b7nig's", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zwei V\u00f6lker durch ein ewig Band", "tokens": ["Zwei", "V\u00f6l\u00b7ker", "durch", "ein", "e\u00b7wig", "Band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der holden Eintracht einzuweih'n,", "tokens": ["Der", "hol\u00b7den", "Ein\u00b7tracht", "ein\u00b7zu\u00b7weih'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und Deutschland's Ehre, Frankreich's Lust zu seyn?", "tokens": ["Und", "Deut\u00b7schlan\u00b7d's", "Eh\u00b7re", ",", "Frank\u00b7reich's", "Lust", "zu", "seyn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,", "NE", "NN", "PTKZU", "VAINF", "$."], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}}, "stanza.9": {"line.1": {"text": "Holder Sonnebot!", "tokens": ["Hol\u00b7der", "Son\u00b7ne\u00b7bot", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Letzter aller Sterne,", "tokens": ["Letz\u00b7ter", "al\u00b7ler", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schweb' hinan! Der Tagesgott", "tokens": ["Schweb'", "hi\u00b7nan", "!", "Der", "Ta\u00b7ges\u00b7gott"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$.", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Folget dir aus heller Ferne.", "tokens": ["Fol\u00b7get", "dir", "aus", "hel\u00b7ler", "Fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Er k\u00f6mmt! Zwar will er seine Stralen decken,", "tokens": ["Er", "k\u00f6mmt", "!", "Zwar", "will", "er", "sei\u00b7ne", "Stra\u00b7len", "de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sucht Dunkel um sich her zu streu'n.", "tokens": ["Sucht", "Dun\u00b7kel", "um", "sich", "her", "zu", "streu'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "NN", "APPR", "PRF", "APZR", "PTKZU", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, wie kann des Lichtes Urquell Schatten wecken,", "tokens": ["Al\u00b7lein", ",", "wie", "kann", "des", "Lich\u00b7tes", "Ur\u00b7quell", "Schat\u00b7ten", "we\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VMFIN", "ART", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er, was er ist, nicht seyn?", "tokens": ["Er", ",", "was", "er", "ist", ",", "nicht", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PWS", "PPER", "VAFIN", "$,", "PTKNEG", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Sein klein Gefolg \u2013 ja klein, wenn Arbeitsliebe,", "tokens": ["Sein", "klein", "Ge\u00b7folg", "\u2013", "ja", "klein", ",", "wenn", "Ar\u00b7beits\u00b7lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$(", "ADV", "ADJD", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn Einsicht, Klugheit, M\u00e4\u00dfigkeit,", "tokens": ["Wenn", "Ein\u00b7sicht", ",", "Klug\u00b7heit", ",", "M\u00e4\u00b7\u00dfig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Wi\u00dfbegier und Menschenhuld zur\u00fcckebliebe,", "tokens": ["Wenn", "Wi\u00df\u00b7be\u00b7gier", "und", "Men\u00b7schen\u00b7huld", "zu\u00b7r\u00fc\u00b7cke\u00b7blie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das herrlichste Geleit,", "tokens": ["Das", "herr\u00b7lichs\u00b7te", "Ge\u00b7leit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Das schon heran vom nachbarlichen Rheine", "tokens": ["Das", "schon", "he\u00b7ran", "vom", "nach\u00b7bar\u00b7li\u00b7chen", "Rhei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PTKVZ", "APPRART", "ADJA", "NE"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den niegeseh'nen Fremdling schm\u00fcckt,", "tokens": ["Den", "nie\u00b7ge\u00b7seh'\u00b7nen", "Fremd\u00b7ling", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mehr, als Purpur, Silber, Gold und Edelsteine", "tokens": ["Und", "mehr", ",", "als", "Pur\u00b7pur", ",", "Sil\u00b7ber", ",", "Gold", "und", "E\u00b7del\u00b7stei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Franken Aug' entz\u00fcckt.", "tokens": ["Der", "Fran\u00b7ken", "Aug'", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Sie steh'n geblendet, rufen: \u00bbDieser w\u00e4re,", "tokens": ["Sie", "steh'n", "ge\u00b7blen\u00b7det", ",", "ru\u00b7fen", ":", "\u00bb", "Die\u00b7ser", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "VVFIN", "$.", "$(", "PDS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Deutschlands hohen Machtstab h\u00e4lt!", "tokens": ["Der", "Deutschlands", "ho\u00b7hen", "Machts\u00b7tab", "h\u00e4lt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Herr ungez\u00e4hlter V\u00f6lker, ungez\u00e4hlter Heere,", "tokens": ["Herr", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "V\u00f6l\u00b7ker", ",", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der erste dieser Welt?", "tokens": ["Der", "ers\u00b7te", "die\u00b7ser", "Welt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Er w\u00e4r' es, den wir ruhig wandeln schauen", "tokens": ["Er", "w\u00e4r'", "es", ",", "den", "wir", "ru\u00b7hig", "wan\u00b7deln", "schau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von Menschenfluthen weit umringt,", "tokens": ["Von", "Men\u00b7schen\u00b7flu\u00b7then", "weit", "um\u00b7ringt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ging' er, fernes Wien! in deinen Fr\u00fchlingsauen,", "tokens": ["Als", "ging'", "er", ",", "fer\u00b7nes", "Wi\u00b7en", "!", "in", "dei\u00b7nen", "Fr\u00fch\u00b7lin\u00b7gsau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wo jede Kehl' ihn singt?", "tokens": ["Wo", "je\u00b7de", "Kehl'", "ihn", "singt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Er w\u00e4r's, auf dessen heit'rem Angesichte", "tokens": ["Er", "w\u00e4r's", ",", "auf", "des\u00b7sen", "heit'\u00b7rem", "An\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die G\u00fcte seelefassend wohnt,", "tokens": ["Die", "G\u00fc\u00b7te", "see\u00b7le\u00b7fas\u00b7send", "wohnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Gru\u00df zur\u00fccke gibt, dem mindesten Berichte", "tokens": ["Den", "Gru\u00df", "zu\u00b7r\u00fc\u00b7cke", "gibt", ",", "dem", "min\u00b7des\u00b7ten", "Be\u00b7rich\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Mit holdem Danke lohnt?", "tokens": ["Mit", "hol\u00b7dem", "Dan\u00b7ke", "lohnt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Er, der in Ludwig's Burg mit gleichem Fu\u00dfe,", "tokens": ["Er", ",", "der", "in", "Lud\u00b7wig's", "Burg", "mit", "glei\u00b7chem", "Fu\u00b7\u00dfe", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "NE", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So, wie in Pfl\u00fcgerh\u00fctten, steht,", "tokens": ["So", ",", "wie", "in", "Pfl\u00fc\u00b7ger\u00b7h\u00fct\u00b7ten", ",", "steht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und von der zartgeliebten Schwester Herzenskusse", "tokens": ["Und", "von", "der", "zart\u00b7ge\u00b7lieb\u00b7ten", "Schwes\u00b7ter", "Her\u00b7zens\u00b7kus\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu siechen Armen geht?", "tokens": ["Zu", "sie\u00b7chen", "Ar\u00b7men", "geht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Nun zusieht, wie gereizt von Waffenruhme", "tokens": ["Nun", "zu\u00b7sieht", ",", "wie", "ge\u00b7reizt", "von", "Waf\u00b7fen\u00b7ruh\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ADJD", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Das Feld im Lustgefechte blitzt,", "tokens": ["Das", "Feld", "im", "Lust\u00b7ge\u00b7fech\u00b7te", "blitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun in der Kunst und Weisheit stillem Heiligthume", "tokens": ["Nun", "in", "der", "Kunst", "und", "Weis\u00b7heit", "stil\u00b7lem", "Hei\u00b7lig\u00b7thu\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Lehrlingsblicke sitzt,", "tokens": ["Mit", "Lehr\u00b7lings\u00b7bli\u00b7cke", "sitzt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Und nun von Jedem, was er sieht und h\u00f6ret,", "tokens": ["Und", "nun", "von", "Je\u00b7dem", ",", "was", "er", "sieht", "und", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit solcher Meistereinsicht spricht,", "tokens": ["Mit", "sol\u00b7cher", "Meis\u00b7ter\u00b7ein\u00b7sicht", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wer den Einzigen nicht kennen sollte, schw\u00f6ret:", "tokens": ["Da\u00df", ",", "wer", "den", "Ein\u00b7zi\u00b7gen", "nicht", "ken\u00b7nen", "soll\u00b7te", ",", "schw\u00f6\u00b7ret", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er hat nur diese Pflicht! \u2013", "tokens": ["Er", "hat", "nur", "die\u00b7se", "Pflicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Ha Franz und Heinrich, und ihr Ludewige!", "tokens": ["Ha", "Franz", "und", "Hein\u00b7rich", ",", "und", "ihr", "Lu\u00b7de\u00b7wi\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NE", "$,", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Werth bleibt ihr ewig uns und gro\u00df;", "tokens": ["Werth", "bleibt", "ihr", "e\u00b7wig", "uns", "und", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "PPER", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch g\u00f6nnt der Sonne, die nun stralet, ihre Siege!", "tokens": ["Doch", "g\u00f6nnt", "der", "Son\u00b7ne", ",", "die", "nun", "stra\u00b7let", ",", "ih\u00b7re", "Sie\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie stralet mackellos.\u00ab", "tokens": ["Sie", "stra\u00b7let", "ma\u00b7ckel\u00b7los", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "So schallt es von den Th\u00fcrmen an der Seine", "tokens": ["So", "schallt", "es", "von", "den", "Th\u00fcr\u00b7men", "an", "der", "Sei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den fernen Pyren\u00e4en zu,", "tokens": ["Den", "fer\u00b7nen", "Py\u00b7re\u00b7n\u00e4\u00b7en", "zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kreis't an zweien Meeren, kehret zu dem Rheine.", "tokens": ["Und", "kreis't", "an", "zwei\u00b7en", "Mee\u00b7ren", ",", "keh\u00b7ret", "zu", "dem", "Rhei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "CARD", "NN", "$,", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Deutschland! horchest du?", "tokens": ["Mein", "Deutschland", "!", "hor\u00b7chest", "du", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Beim Zeugnisse so vieler fremden Zungen", "tokens": ["Beim", "Zeug\u00b7nis\u00b7se", "so", "vie\u00b7ler", "frem\u00b7den", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie hoch mu\u00df dein Entz\u00fccken seyn!", "tokens": ["Wie", "hoch", "mu\u00df", "dein", "Ent\u00b7z\u00fc\u00b7cken", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch einmal sei's empfunden, einmal noch gesungen:", "tokens": ["Noch", "ein\u00b7mal", "sei's", "emp\u00b7fun\u00b7den", ",", "ein\u00b7mal", "noch", "ge\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "VVPP", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O F\u00fcrst! so gro\u00df \u2013 und mein!", "tokens": ["O", "F\u00fcrst", "!", "so", "gro\u00df", "\u2013", "und", "mein", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "ADJD", "$(", "KON", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Heil allen Herrschern, die in seinen Tagen", "tokens": ["Heil", "al\u00b7len", "Herr\u00b7schern", ",", "die", "in", "sei\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Allvaters Hand der Erde lieh!", "tokens": ["All\u00b7va\u00b7ters", "Hand", "der", "Er\u00b7de", "lieh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch seinen Aufschwung wird ihr Stand emporgetragen.", "tokens": ["Durch", "sei\u00b7nen", "Auf\u00b7schwung", "wird", "ihr", "Stand", "em\u00b7por\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Joseph gl\u00e4nzen sie.", "tokens": ["In", "Jo\u00b7se\u00b7ph", "gl\u00e4n\u00b7zen", "sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Und Heil uns allen deutschen Biederleuten!", "tokens": ["Und", "Heil", "uns", "al\u00b7len", "deut\u00b7schen", "Bie\u00b7der\u00b7leu\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der f\u00fchl' ihn mit, der f\u00fchlen kann,", "tokens": ["Der", "f\u00fchl'", "ihn", "mit", ",", "der", "f\u00fch\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gro\u00df ist der Stolz und sch\u00f6n: Ich lebe Joseph's Zeiten,", "tokens": ["Gro\u00df", "ist", "der", "Stolz", "und", "sch\u00f6n", ":", "Ich", "le\u00b7be", "Jo\u00b7se\u00b7ph's", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "KON", "ADJD", "$.", "PPER", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bin selbst sein Unterthan!", "tokens": ["Bin", "selbst", "sein", "Un\u00b7ter\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "O F\u00fcrst und Mensch! \u2013 O Tugendfreund und Weiser,", "tokens": ["O", "F\u00fcrst", "und", "Mensch", "!", "\u2013", "O", "Tu\u00b7gend\u00b7freund", "und", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$.", "$(", "NE", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der gr\u00f6\u00dften Mutter gr\u00f6\u00dfter Sohn!", "tokens": ["Der", "gr\u00f6\u00df\u00b7ten", "Mut\u00b7ter", "gr\u00f6\u00df\u00b7ter", "Sohn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es lohnet Harfe \u2013 nein, f\u00fcr einen solchen Kaiser", "tokens": ["Es", "loh\u00b7net", "Har\u00b7fe", "\u2013", "nein", ",", "f\u00fcr", "ei\u00b7nen", "sol\u00b7chen", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$(", "PTKANT", "$,", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat Harfe keinen Lohn!", "tokens": ["Hat", "Har\u00b7fe", "kei\u00b7nen", "Lohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "So sang ich seine sechste Reise. Doch", "tokens": ["So", "sang", "ich", "sei\u00b7ne", "sechs\u00b7te", "Rei\u00b7se", ".", "Doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$.", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich f\u00fchle, da\u00df mit jeder Reise sich", "tokens": ["Ich", "f\u00fch\u00b7le", ",", "da\u00df", "mit", "je\u00b7der", "Rei\u00b7se", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Adler immer mehr dem Blick' entschwingt.", "tokens": ["Mein", "Ad\u00b7ler", "im\u00b7mer", "mehr", "dem", "Blick'", "ent\u00b7schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mein Spiel erschlafft, und meine Stimme bricht.", "tokens": ["Mein", "Spiel", "er\u00b7schlafft", ",", "und", "mei\u00b7ne", "Stim\u00b7me", "bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer hielt's auch mit dem Unerreichlichen?", "tokens": ["Wer", "hielt's", "auch", "mit", "dem", "Un\u00b7er\u00b7reich\u00b7li\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich m\u00fc\u00dfte Joseph unter Barden seyn,", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "Jo\u00b7se\u00b7ph", "un\u00b7ter", "Bar\u00b7den", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So wie er Joseph unter F\u00fcrsten ist.", "tokens": ["So", "wie", "er", "Jo\u00b7se\u00b7ph", "un\u00b7ter", "F\u00fcrs\u00b7ten", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "NE", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.26": {"line.1": {"text": "Das Grau der Vorzeit hellt sich dem Barden auf.", "tokens": ["Das", "Grau", "der", "Vor\u00b7zeit", "hellt", "sich", "dem", "Bar\u00b7den", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Er sieht. Ein Spr\u00f6\u00dfling laubt sich vor ihm empor,", "tokens": ["Er", "sieht", ".", "Ein", "Spr\u00f6\u00df\u00b7ling", "laubt", "sich", "vor", "ihm", "em\u00b7por", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "VVFIN", "PRF", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Un\u00fcberpflanzt, in eig'nem Grunde,", "tokens": ["Un\u00b7\u00fc\u00b7ber\u00b7pflanzt", ",", "in", "eig'\u00b7nem", "Grun\u00b7de", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Strecket er Wipfel und Nebenzweige,", "tokens": ["Stre\u00b7cket", "er", "Wip\u00b7fel", "und", "Ne\u00b7ben\u00b7zwei\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.27": {"line.1": {"text": "Wird Baum, erzeuget Aeste. Sein waldig Haupt", "tokens": ["Wird", "Baum", ",", "er\u00b7zeu\u00b7get", "A\u00b7es\u00b7te", ".", "Sein", "wal\u00b7dig", "Haupt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NE", "$,", "VVFIN", "NN", "$.", "PPOSAT", "ADJD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erraget Wolken, schattet Gebirgen selbst.", "tokens": ["Er\u00b7ra\u00b7get", "Wol\u00b7ken", ",", "schat\u00b7tet", "Ge\u00b7bir\u00b7gen", "selbst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "$,", "VVFIN", "NN", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Rhein, Weser, Elbe, Weichsel, Donau", "tokens": ["Rhein", ",", "We\u00b7ser", ",", "El\u00b7be", ",", "Weich\u00b7sel", ",", "Do\u00b7nau"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$,", "NN", "$,", "NE"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Tr\u00e4nken die Tausende seiner Wurzeln.", "tokens": ["Tr\u00e4n\u00b7ken", "die", "Tau\u00b7sen\u00b7de", "sei\u00b7ner", "Wur\u00b7zeln", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.28": {"line.1": {"text": "Er bl\u00fch't, und reifet Samen. Der Winde Zug", "tokens": ["Er", "bl\u00fch't", ",", "und", "rei\u00b7fet", "Sa\u00b7men", ".", "Der", "Win\u00b7de", "Zug"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KON", "VVFIN", "NN", "$.", "ART", "NN", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Vertr\u00e4gt die reifen K\u00f6rner in Ost und West", "tokens": ["Ver\u00b7tr\u00e4gt", "die", "rei\u00b7fen", "K\u00f6r\u00b7ner", "in", "Ost", "und", "West"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und S\u00fcd und Nord. Vom Mutterstamme", "tokens": ["Und", "S\u00fcd", "und", "Nord", ".", "Vom", "Mut\u00b7ter\u00b7stam\u00b7me"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NE", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Fallen sie ferne, gewinnen Erde.", "tokens": ["Fal\u00b7len", "sie", "fer\u00b7ne", ",", "ge\u00b7win\u00b7nen", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.29": {"line.1": {"text": "Ein Korn (verge\u00dft, o S\u00f6hne von Teut, es nicht!", "tokens": ["Ein", "Korn", "(", "ver\u00b7ge\u00dft", ",", "o", "S\u00f6h\u00b7ne", "von", "Teut", ",", "es", "nicht", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "VVFIN", "$,", "FM", "NN", "APPR", "NE", "$,", "PPER", "PTKNEG", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sind schon dazwischen lange Jahrhunderte)", "tokens": ["Sind", "schon", "da\u00b7zwi\u00b7schen", "lan\u00b7ge", "Jahr\u00b7hun\u00b7der\u00b7te", ")"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PAV", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Flog einst den Rhein hin\u00fcber, grub sich", "tokens": ["Flog", "einst", "den", "Rhein", "hin\u00b7\u00fc\u00b7ber", ",", "grub", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ADV", "ART", "NE", "ADV", "$,", "VVFIN", "PRF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Keimend in sonnenerhitzte Schollen,", "tokens": ["Kei\u00b7mend", "in", "son\u00b7ne\u00b7ner\u00b7hitz\u00b7te", "Schol\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.30": {"line.1": {"text": "Und trieb Gescho\u00df und Wipfel, und eiferte", "tokens": ["Und", "trieb", "Ge\u00b7scho\u00df", "und", "Wip\u00b7fel", ",", "und", "ei\u00b7fer\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "NN", "KON", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit seinem Mutterstamme. Gar oft erscholl:", "tokens": ["Mit", "sei\u00b7nem", "Mut\u00b7ter\u00b7stam\u00b7me", ".", "Gar", "oft", "er\u00b7scholl", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "\u00bbund wer, wer ist denn meine Mutter?\u00ab", "tokens": ["\u00bb", "und", "wer", ",", "wer", "ist", "denn", "mei\u00b7ne", "Mut\u00b7ter", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "$,", "PWS", "VAFIN", "ADV", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus des erregteren Wipfel's H\u00f6hen.", "tokens": ["Aus", "des", "er\u00b7reg\u00b7te\u00b7ren", "Wip\u00b7fel's", "H\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.31": {"line.1": {"text": "Da st\u00fcrzten Felsenklumpen, dem Wanderer", "tokens": ["Da", "st\u00fcrz\u00b7ten", "Fel\u00b7sen\u00b7klum\u00b7pen", ",", "dem", "Wan\u00b7de\u00b7rer"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Un\u00fcbersteigbar, gr\u00e4\u00dflich an's Ufer her,", "tokens": ["Un\u00b7\u00fc\u00b7bers\u00b7teig\u00b7bar", ",", "gr\u00e4\u00df\u00b7lich", "an's", "U\u00b7fer", "her", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Und jeder Uebergang des Rheines", "tokens": ["Und", "je\u00b7der", "Ue\u00b7ber\u00b7gang", "des", "Rhei\u00b7nes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "ART", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Barg sich in feindliche Dorngeb\u00fcsche.", "tokens": ["Barg", "sich", "in", "feind\u00b7li\u00b7che", "Dorn\u00b7ge\u00b7b\u00fc\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.32": {"line.1": {"text": "Therese kam. \u00bbWie lange schreckt es noch", "tokens": ["The\u00b7re\u00b7se", "kam", ".", "\u00bb", "Wie", "lan\u00b7ge", "schreckt", "es", "noch"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "$.", "$(", "PWAV", "ADV", "VVFIN", "PPER", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Am Rheine?\u00ab war ihr Wort, dem Mann' ein Wink,", "tokens": ["Am", "Rhei\u00b7ne", "?", "\u00ab", "war", "ihr", "Wort", ",", "dem", "Mann'", "ein", "Wink", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "$.", "$(", "VAFIN", "PPOSAT", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der ihre gro\u00dfe Seele ganz versteht", "tokens": ["Der", "ih\u00b7re", "gro\u00b7\u00dfe", "See\u00b7le", "ganz", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Er sah' der Felsenklumpen wilden Sturz,", "tokens": ["Er", "sah'", "der", "Fel\u00b7sen\u00b7klum\u00b7pen", "wil\u00b7den", "Sturz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der Dorngeb\u00fcsche feindliches Gewirr'", "tokens": ["Der", "Dorn\u00b7ge\u00b7b\u00fc\u00b7sche", "feind\u00b7li\u00b7ches", "Ge\u00b7wirr'"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mit jener stillen Geisteshoheit an,", "tokens": ["Mit", "je\u00b7ner", "stil\u00b7len", "Geis\u00b7tes\u00b7ho\u00b7heit", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Die seiner Herrscher ihn so w\u00fcrdig macht.", "tokens": ["Die", "sei\u00b7ner", "Herr\u00b7scher", "ihn", "so", "w\u00fcr\u00b7dig", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sie schwanden weg.", "tokens": ["Sie", "schwan\u00b7den", "weg", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.33": {"line.1": {"text": "Wie sollten sie nicht schwinden?", "tokens": ["Wie", "soll\u00b7ten", "sie", "nicht", "schwin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Denn mu\u00dfte nicht Antonia,", "tokens": ["Denn", "mu\u00df\u00b7te", "nicht", "An\u00b7to\u00b7nia", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "NE", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "In welcher sich verj\u00fcngt die G\u00f6ttermutter sah,", "tokens": ["In", "wel\u00b7cher", "sich", "ver\u00b7j\u00fcngt", "die", "G\u00f6t\u00b7ter\u00b7mut\u00b7ter", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Den Weg gebahnet finden,", "tokens": ["Den", "Weg", "ge\u00b7bah\u00b7net", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Um an des Frankenk\u00f6nig's Hand", "tokens": ["Um", "an", "des", "Fran\u00b7ken\u00b7k\u00f6\u00b7nig's", "Hand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zwei V\u00f6lker durch ein ewig Band", "tokens": ["Zwei", "V\u00f6l\u00b7ker", "durch", "ein", "e\u00b7wig", "Band"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der holden Eintracht einzuweih'n,", "tokens": ["Der", "hol\u00b7den", "Ein\u00b7tracht", "ein\u00b7zu\u00b7weih'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und Deutschland's Ehre, Frankreich's Lust zu seyn?", "tokens": ["Und", "Deut\u00b7schlan\u00b7d's", "Eh\u00b7re", ",", "Frank\u00b7reich's", "Lust", "zu", "seyn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NN", "$,", "NE", "NN", "PTKZU", "VAINF", "$."], "meter": "--+-+-+-+-+", "measure": "anapaest.init"}}, "stanza.34": {"line.1": {"text": "Holder Sonnebot!", "tokens": ["Hol\u00b7der", "Son\u00b7ne\u00b7bot", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Letzter aller Sterne,", "tokens": ["Letz\u00b7ter", "al\u00b7ler", "Ster\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schweb' hinan! Der Tagesgott", "tokens": ["Schweb'", "hi\u00b7nan", "!", "Der", "Ta\u00b7ges\u00b7gott"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$.", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Folget dir aus heller Ferne.", "tokens": ["Fol\u00b7get", "dir", "aus", "hel\u00b7ler", "Fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Er k\u00f6mmt! Zwar will er seine Stralen decken,", "tokens": ["Er", "k\u00f6mmt", "!", "Zwar", "will", "er", "sei\u00b7ne", "Stra\u00b7len", "de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sucht Dunkel um sich her zu streu'n.", "tokens": ["Sucht", "Dun\u00b7kel", "um", "sich", "her", "zu", "streu'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["VVFIN", "NN", "APPR", "PRF", "APZR", "PTKZU", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, wie kann des Lichtes Urquell Schatten wecken,", "tokens": ["Al\u00b7lein", ",", "wie", "kann", "des", "Lich\u00b7tes", "Ur\u00b7quell", "Schat\u00b7ten", "we\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VMFIN", "ART", "ADJA", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er, was er ist, nicht seyn?", "tokens": ["Er", ",", "was", "er", "ist", ",", "nicht", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "PWS", "PPER", "VAFIN", "$,", "PTKNEG", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Sein klein Gefolg \u2013 ja klein, wenn Arbeitsliebe,", "tokens": ["Sein", "klein", "Ge\u00b7folg", "\u2013", "ja", "klein", ",", "wenn", "Ar\u00b7beits\u00b7lie\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "$(", "ADV", "ADJD", "$,", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn Einsicht, Klugheit, M\u00e4\u00dfigkeit,", "tokens": ["Wenn", "Ein\u00b7sicht", ",", "Klug\u00b7heit", ",", "M\u00e4\u00b7\u00dfig\u00b7keit", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn Wi\u00dfbegier und Menschenhuld zur\u00fcckebliebe,", "tokens": ["Wenn", "Wi\u00df\u00b7be\u00b7gier", "und", "Men\u00b7schen\u00b7huld", "zu\u00b7r\u00fc\u00b7cke\u00b7blie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Das herrlichste Geleit,", "tokens": ["Das", "herr\u00b7lichs\u00b7te", "Ge\u00b7leit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Das schon heran vom nachbarlichen Rheine", "tokens": ["Das", "schon", "he\u00b7ran", "vom", "nach\u00b7bar\u00b7li\u00b7chen", "Rhei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "PTKVZ", "APPRART", "ADJA", "NE"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Den niegeseh'nen Fremdling schm\u00fcckt,", "tokens": ["Den", "nie\u00b7ge\u00b7seh'\u00b7nen", "Fremd\u00b7ling", "schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mehr, als Purpur, Silber, Gold und Edelsteine", "tokens": ["Und", "mehr", ",", "als", "Pur\u00b7pur", ",", "Sil\u00b7ber", ",", "Gold", "und", "E\u00b7del\u00b7stei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Franken Aug' entz\u00fcckt.", "tokens": ["Der", "Fran\u00b7ken", "Aug'", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Sie steh'n geblendet, rufen: \u00bbDieser w\u00e4re,", "tokens": ["Sie", "steh'n", "ge\u00b7blen\u00b7det", ",", "ru\u00b7fen", ":", "\u00bb", "Die\u00b7ser", "w\u00e4\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "$,", "VVFIN", "$.", "$(", "PDS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Deutschlands hohen Machtstab h\u00e4lt!", "tokens": ["Der", "Deutschlands", "ho\u00b7hen", "Machts\u00b7tab", "h\u00e4lt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Herr ungez\u00e4hlter V\u00f6lker, ungez\u00e4hlter Heere,", "tokens": ["Herr", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "V\u00f6l\u00b7ker", ",", "un\u00b7ge\u00b7z\u00e4hl\u00b7ter", "Hee\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der erste dieser Welt?", "tokens": ["Der", "ers\u00b7te", "die\u00b7ser", "Welt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PDAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Er w\u00e4r' es, den wir ruhig wandeln schauen", "tokens": ["Er", "w\u00e4r'", "es", ",", "den", "wir", "ru\u00b7hig", "wan\u00b7deln", "schau\u00b7en"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Von Menschenfluthen weit umringt,", "tokens": ["Von", "Men\u00b7schen\u00b7flu\u00b7then", "weit", "um\u00b7ringt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als ging' er, fernes Wien! in deinen Fr\u00fchlingsauen,", "tokens": ["Als", "ging'", "er", ",", "fer\u00b7nes", "Wi\u00b7en", "!", "in", "dei\u00b7nen", "Fr\u00fch\u00b7lin\u00b7gsau\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "$,", "ADJA", "NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Wo jede Kehl' ihn singt?", "tokens": ["Wo", "je\u00b7de", "Kehl'", "ihn", "singt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Er w\u00e4r's, auf dessen heit'rem Angesichte", "tokens": ["Er", "w\u00e4r's", ",", "auf", "des\u00b7sen", "heit'\u00b7rem", "An\u00b7ge\u00b7sich\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "APPR", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die G\u00fcte seelefassend wohnt,", "tokens": ["Die", "G\u00fc\u00b7te", "see\u00b7le\u00b7fas\u00b7send", "wohnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Gru\u00df zur\u00fccke gibt, dem mindesten Berichte", "tokens": ["Den", "Gru\u00df", "zu\u00b7r\u00fc\u00b7cke", "gibt", ",", "dem", "min\u00b7des\u00b7ten", "Be\u00b7rich\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Mit holdem Danke lohnt?", "tokens": ["Mit", "hol\u00b7dem", "Dan\u00b7ke", "lohnt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Er, der in Ludwig's Burg mit gleichem Fu\u00dfe,", "tokens": ["Er", ",", "der", "in", "Lud\u00b7wig's", "Burg", "mit", "glei\u00b7chem", "Fu\u00b7\u00dfe", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "APPR", "NE", "NE", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "So, wie in Pfl\u00fcgerh\u00fctten, steht,", "tokens": ["So", ",", "wie", "in", "Pfl\u00fc\u00b7ger\u00b7h\u00fct\u00b7ten", ",", "steht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "APPR", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und von der zartgeliebten Schwester Herzenskusse", "tokens": ["Und", "von", "der", "zart\u00b7ge\u00b7lieb\u00b7ten", "Schwes\u00b7ter", "Her\u00b7zens\u00b7kus\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zu siechen Armen geht?", "tokens": ["Zu", "sie\u00b7chen", "Ar\u00b7men", "geht", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Nun zusieht, wie gereizt von Waffenruhme", "tokens": ["Nun", "zu\u00b7sieht", ",", "wie", "ge\u00b7reizt", "von", "Waf\u00b7fen\u00b7ruh\u00b7me"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PWAV", "ADJD", "APPR", "NN"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Das Feld im Lustgefechte blitzt,", "tokens": ["Das", "Feld", "im", "Lust\u00b7ge\u00b7fech\u00b7te", "blitzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nun in der Kunst und Weisheit stillem Heiligthume", "tokens": ["Nun", "in", "der", "Kunst", "und", "Weis\u00b7heit", "stil\u00b7lem", "Hei\u00b7lig\u00b7thu\u00b7me"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "KON", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit Lehrlingsblicke sitzt,", "tokens": ["Mit", "Lehr\u00b7lings\u00b7bli\u00b7cke", "sitzt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Und nun von Jedem, was er sieht und h\u00f6ret,", "tokens": ["Und", "nun", "von", "Je\u00b7dem", ",", "was", "er", "sieht", "und", "h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PIAT", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit solcher Meistereinsicht spricht,", "tokens": ["Mit", "sol\u00b7cher", "Meis\u00b7ter\u00b7ein\u00b7sicht", "spricht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df, wer den Einzigen nicht kennen sollte, schw\u00f6ret:", "tokens": ["Da\u00df", ",", "wer", "den", "Ein\u00b7zi\u00b7gen", "nicht", "ken\u00b7nen", "soll\u00b7te", ",", "schw\u00f6\u00b7ret", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Er hat nur diese Pflicht! \u2013", "tokens": ["Er", "hat", "nur", "die\u00b7se", "Pflicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Ha Franz und Heinrich, und ihr Ludewige!", "tokens": ["Ha", "Franz", "und", "Hein\u00b7rich", ",", "und", "ihr", "Lu\u00b7de\u00b7wi\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "KON", "NE", "$,", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Werth bleibt ihr ewig uns und gro\u00df;", "tokens": ["Werth", "bleibt", "ihr", "e\u00b7wig", "uns", "und", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "PPER", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch g\u00f6nnt der Sonne, die nun stralet, ihre Siege!", "tokens": ["Doch", "g\u00f6nnt", "der", "Son\u00b7ne", ",", "die", "nun", "stra\u00b7let", ",", "ih\u00b7re", "Sie\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie stralet mackellos.\u00ab", "tokens": ["Sie", "stra\u00b7let", "ma\u00b7ckel\u00b7los", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "So schallt es von den Th\u00fcrmen an der Seine", "tokens": ["So", "schallt", "es", "von", "den", "Th\u00fcr\u00b7men", "an", "der", "Sei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den fernen Pyren\u00e4en zu,", "tokens": ["Den", "fer\u00b7nen", "Py\u00b7re\u00b7n\u00e4\u00b7en", "zu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und kreis't an zweien Meeren, kehret zu dem Rheine.", "tokens": ["Und", "kreis't", "an", "zwei\u00b7en", "Mee\u00b7ren", ",", "keh\u00b7ret", "zu", "dem", "Rhei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "CARD", "NN", "$,", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mein Deutschland! horchest du?", "tokens": ["Mein", "Deutschland", "!", "hor\u00b7chest", "du", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VVFIN", "PPER", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Beim Zeugnisse so vieler fremden Zungen", "tokens": ["Beim", "Zeug\u00b7nis\u00b7se", "so", "vie\u00b7ler", "frem\u00b7den", "Zun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ADV", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wie hoch mu\u00df dein Entz\u00fccken seyn!", "tokens": ["Wie", "hoch", "mu\u00df", "dein", "Ent\u00b7z\u00fc\u00b7cken", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VMFIN", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Noch einmal sei's empfunden, einmal noch gesungen:", "tokens": ["Noch", "ein\u00b7mal", "sei's", "emp\u00b7fun\u00b7den", ",", "ein\u00b7mal", "noch", "ge\u00b7sun\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "VVPP", "$,", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "O F\u00fcrst! so gro\u00df \u2013 und mein!", "tokens": ["O", "F\u00fcrst", "!", "so", "gro\u00df", "\u2013", "und", "mein", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "ADJD", "$(", "KON", "PPOSAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Heil allen Herrschern, die in seinen Tagen", "tokens": ["Heil", "al\u00b7len", "Herr\u00b7schern", ",", "die", "in", "sei\u00b7nen", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "NN", "$,", "PRELS", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Allvaters Hand der Erde lieh!", "tokens": ["All\u00b7va\u00b7ters", "Hand", "der", "Er\u00b7de", "lieh", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch seinen Aufschwung wird ihr Stand emporgetragen.", "tokens": ["Durch", "sei\u00b7nen", "Auf\u00b7schwung", "wird", "ihr", "Stand", "em\u00b7por\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In Joseph gl\u00e4nzen sie.", "tokens": ["In", "Jo\u00b7se\u00b7ph", "gl\u00e4n\u00b7zen", "sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.48": {"line.1": {"text": "Und Heil uns allen deutschen Biederleuten!", "tokens": ["Und", "Heil", "uns", "al\u00b7len", "deut\u00b7schen", "Bie\u00b7der\u00b7leu\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der f\u00fchl' ihn mit, der f\u00fchlen kann,", "tokens": ["Der", "f\u00fchl'", "ihn", "mit", ",", "der", "f\u00fch\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "PRELS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gro\u00df ist der Stolz und sch\u00f6n: Ich lebe Joseph's Zeiten,", "tokens": ["Gro\u00df", "ist", "der", "Stolz", "und", "sch\u00f6n", ":", "Ich", "le\u00b7be", "Jo\u00b7se\u00b7ph's", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "KON", "ADJD", "$.", "PPER", "VVFIN", "NE", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Bin selbst sein Unterthan!", "tokens": ["Bin", "selbst", "sein", "Un\u00b7ter\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "O F\u00fcrst und Mensch! \u2013 O Tugendfreund und Weiser,", "tokens": ["O", "F\u00fcrst", "und", "Mensch", "!", "\u2013", "O", "Tu\u00b7gend\u00b7freund", "und", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "$.", "$(", "NE", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der gr\u00f6\u00dften Mutter gr\u00f6\u00dfter Sohn!", "tokens": ["Der", "gr\u00f6\u00df\u00b7ten", "Mut\u00b7ter", "gr\u00f6\u00df\u00b7ter", "Sohn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es lohnet Harfe \u2013 nein, f\u00fcr einen solchen Kaiser", "tokens": ["Es", "loh\u00b7net", "Har\u00b7fe", "\u2013", "nein", ",", "f\u00fcr", "ei\u00b7nen", "sol\u00b7chen", "Kai\u00b7ser"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$(", "PTKANT", "$,", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hat Harfe keinen Lohn!", "tokens": ["Hat", "Har\u00b7fe", "kei\u00b7nen", "Lohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "So sang ich seine sechste Reise. Doch", "tokens": ["So", "sang", "ich", "sei\u00b7ne", "sechs\u00b7te", "Rei\u00b7se", ".", "Doch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$.", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich f\u00fchle, da\u00df mit jeder Reise sich", "tokens": ["Ich", "f\u00fch\u00b7le", ",", "da\u00df", "mit", "je\u00b7der", "Rei\u00b7se", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mein Adler immer mehr dem Blick' entschwingt.", "tokens": ["Mein", "Ad\u00b7ler", "im\u00b7mer", "mehr", "dem", "Blick'", "ent\u00b7schwingt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Mein Spiel erschlafft, und meine Stimme bricht.", "tokens": ["Mein", "Spiel", "er\u00b7schlafft", ",", "und", "mei\u00b7ne", "Stim\u00b7me", "bricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVPP", "$,", "KON", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Wer hielt's auch mit dem Unerreichlichen?", "tokens": ["Wer", "hielt's", "auch", "mit", "dem", "Un\u00b7er\u00b7reich\u00b7li\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich m\u00fc\u00dfte Joseph unter Barden seyn,", "tokens": ["Ich", "m\u00fc\u00df\u00b7te", "Jo\u00b7se\u00b7ph", "un\u00b7ter", "Bar\u00b7den", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NE", "APPR", "NN", "VAINF", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "So wie er Joseph unter F\u00fcrsten ist.", "tokens": ["So", "wie", "er", "Jo\u00b7se\u00b7ph", "un\u00b7ter", "F\u00fcrs\u00b7ten", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PPER", "NE", "APPR", "NN", "VAFIN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}}}}