{"textgrid.poem.60731": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es w\u00e4hlte eine Truthahnherde,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es w\u00e4hlte eine Truthahnherde,", "tokens": ["Es", "w\u00e4hl\u00b7te", "ei\u00b7ne", "Trut\u00b7hahn\u00b7her\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die ein begieriger Fuchs begehrte,", "tokens": ["Die", "ein", "be\u00b7gie\u00b7ri\u00b7ger", "Fuchs", "be\u00b7gehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NE", "ADJA", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zur Nachtrast eines Baumes \u00c4ste.", "tokens": ["Zur", "Nach\u00b7trast", "ei\u00b7nes", "Bau\u00b7mes", "\u00c4s\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst beschlich der Fuchs die Feste;", "tokens": ["Um\u00b7sonst", "be\u00b7schlich", "der", "Fuchs", "die", "Fes\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und lie\u00df er sich's auch viele G\u00e4nge kosten,", "tokens": ["Und", "lie\u00df", "er", "sich's", "auch", "vie\u00b7le", "G\u00e4n\u00b7ge", "kos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Fand er doch wachsam stets das Federvolk auf Posten.", "tokens": ["Fand", "er", "doch", "wach\u00b7sam", "stets", "das", "Fe\u00b7der\u00b7volk", "auf", "Pos\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er z\u00fcrnte: \u00bbWie? Man lacht mich aus! Man spottet mein!", "tokens": ["Er", "z\u00fcrn\u00b7te", ":", "\u00bb", "Wie", "?", "Man", "lacht", "mich", "aus", "!", "Man", "spot\u00b7tet", "mein", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWAV", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$.", "PIS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Sollten wahrhaftig einzig diese mir entgehen?", "tokens": ["Soll\u00b7ten", "wahr\u00b7haf\u00b7tig", "ein\u00b7zig", "die\u00b7se", "mir", "ent\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "ADJD", "PDAT", "PPER", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ich sage: nein! Bei allen G\u00f6ttern, nein!\u00ab", "tokens": ["Ich", "sa\u00b7ge", ":", "nein", "!", "Bei", "al\u00b7len", "G\u00f6t\u00b7tern", ",", "nein", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "PTKANT", "$.", "APPR", "PIAT", "NN", "$,", "PTKANT", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wie er's schwur, so ist's geschehen.", "tokens": ["Und", "wie", "er's", "schwur", ",", "so", "ist's", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenngleich das helle Mondenlicht", "tokens": ["Wenn\u00b7gleich", "das", "hel\u00b7le", "Mon\u00b7den\u00b7licht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch g\u00fcnstig schien der H\u00fchnerschar", "tokens": ["Auch", "g\u00fcns\u00b7tig", "schien", "der", "H\u00fch\u00b7ner\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und klar ihr zeigte die Gefahr \u2013", "tokens": ["Und", "klar", "ihr", "zeig\u00b7te", "die", "Ge\u00b7fahr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der kundige Fuchs verzagte nicht,", "tokens": ["Der", "kun\u00b7di\u00b7ge", "Fuchs", "ver\u00b7zag\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Er hatte seinen Sack voll List und Lug.", "tokens": ["Er", "hat\u00b7te", "sei\u00b7nen", "Sack", "voll", "List", "und", "Lug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADJD", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er tat zun\u00e4chst, als wolle er den Baum ersteigen,", "tokens": ["Er", "tat", "zu\u00b7n\u00e4chst", ",", "als", "wol\u00b7le", "er", "den", "Baum", "er\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "VMFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indem er seine Pfoten um die Rinde schlug;", "tokens": ["In\u00b7dem", "er", "sei\u00b7ne", "Pfo\u00b7ten", "um", "die", "Rin\u00b7de", "schlug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dann sank er hin, um sich als toten Mann zu zeigen,", "tokens": ["Dann", "sank", "er", "hin", ",", "um", "sich", "als", "to\u00b7ten", "Mann", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KOUI", "PRF", "KOUS", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und wieder auferstanden trieb er neuen Trug:", "tokens": ["Und", "wie\u00b7der", "auf\u00b7er\u00b7stan\u00b7den", "trieb", "er", "neu\u00b7en", "Trug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVIZU", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Verwandelte sich wie ein Harlekin", "tokens": ["Ver\u00b7wan\u00b7del\u00b7te", "sich", "wie", "ein", "Har\u00b7le\u00b7kin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "In immer andere Gestalten,", "tokens": ["In", "im\u00b7mer", "an\u00b7de\u00b7re", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Hob seinen Schwanz und schwenkte ihn,", "tokens": ["Hob", "sei\u00b7nen", "Schwanz", "und", "schwenk\u00b7te", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Hat unentwegt die indischen H\u00fchner wach gehalten.", "tokens": ["Hat", "un\u00b7ent\u00b7wegt", "die", "in\u00b7di\u00b7schen", "H\u00fch\u00b7ner", "wach", "ge\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Von diesen, die den Feind nicht aus den Augen lie\u00dfen,", "tokens": ["Von", "die\u00b7sen", ",", "die", "den", "Feind", "nicht", "aus", "den", "Au\u00b7gen", "lie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wagte nat\u00fcrlich keins, zum Schlaf das Lid zu schlie\u00dfen.", "tokens": ["Wag\u00b7te", "na\u00b7t\u00fcr\u00b7lich", "keins", ",", "zum", "Schlaf", "das", "Lid", "zu", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "$,", "APPRART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.5": {"line.1": {"text": "Scharf sp\u00e4hten sie und wurden endlich m\u00fcd und matt,", "tokens": ["Scharf", "sp\u00e4h\u00b7ten", "sie", "und", "wur\u00b7den", "end\u00b7lich", "m\u00fcd", "und", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "KON", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und manches taumelte ersch\u00f6pft vom Baum", "tokens": ["Und", "man\u00b7ches", "tau\u00b7mel\u00b7te", "er\u00b7sch\u00f6pft", "vom", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "VVPP", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und fand alsbald die letzte Ruhestatt,", "tokens": ["Und", "fand", "als\u00b7bald", "die", "letz\u00b7te", "Ru\u00b7he\u00b7statt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die ersten in des roten M\u00f6rders Magen,", "tokens": ["Die", "ers\u00b7ten", "in", "des", "ro\u00b7ten", "M\u00f6r\u00b7ders", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die n\u00e4chsten trug er schnell in seinen Vorratsraum", "tokens": ["Die", "n\u00e4chs\u00b7ten", "trug", "er", "schnell", "in", "sei\u00b7nen", "Vor\u00b7rats\u00b7raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach Malepartus ein.", "tokens": ["Nach", "Ma\u00b7le\u00b7par\u00b7tus", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Was meine Fabel euch erz\u00e4hlt?", "tokens": ["Was", "mei\u00b7ne", "Fa\u00b7bel", "euch", "er\u00b7z\u00e4hlt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 Wer nichts als immer die Gefahr im Auge h\u00e4lt,", "tokens": ["\u2013", "Wer", "nichts", "als", "im\u00b7mer", "die", "Ge\u00b7fahr", "im", "Au\u00b7ge", "h\u00e4lt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PIS", "KOKOM", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00e4llt schlie\u00dflich ganz gewi\u00df hinein.", "tokens": ["F\u00e4llt", "schlie\u00df\u00b7lich", "ganz", "ge\u00b7wi\u00df", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es w\u00e4hlte eine Truthahnherde,", "tokens": ["Es", "w\u00e4hl\u00b7te", "ei\u00b7ne", "Trut\u00b7hahn\u00b7her\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die ein begieriger Fuchs begehrte,", "tokens": ["Die", "ein", "be\u00b7gie\u00b7ri\u00b7ger", "Fuchs", "be\u00b7gehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NE", "ADJA", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zur Nachtrast eines Baumes \u00c4ste.", "tokens": ["Zur", "Nach\u00b7trast", "ei\u00b7nes", "Bau\u00b7mes", "\u00c4s\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Umsonst beschlich der Fuchs die Feste;", "tokens": ["Um\u00b7sonst", "be\u00b7schlich", "der", "Fuchs", "die", "Fes\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NE", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und lie\u00df er sich's auch viele G\u00e4nge kosten,", "tokens": ["Und", "lie\u00df", "er", "sich's", "auch", "vie\u00b7le", "G\u00e4n\u00b7ge", "kos\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Fand er doch wachsam stets das Federvolk auf Posten.", "tokens": ["Fand", "er", "doch", "wach\u00b7sam", "stets", "das", "Fe\u00b7der\u00b7volk", "auf", "Pos\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "ADV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Er z\u00fcrnte: \u00bbWie? Man lacht mich aus! Man spottet mein!", "tokens": ["Er", "z\u00fcrn\u00b7te", ":", "\u00bb", "Wie", "?", "Man", "lacht", "mich", "aus", "!", "Man", "spot\u00b7tet", "mein", "!"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PWAV", "$.", "PIS", "VVFIN", "PPER", "PTKVZ", "$.", "PIS", "VVFIN", "PPOSAT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Sollten wahrhaftig einzig diese mir entgehen?", "tokens": ["Soll\u00b7ten", "wahr\u00b7haf\u00b7tig", "ein\u00b7zig", "die\u00b7se", "mir", "ent\u00b7ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "ADJD", "PDAT", "PPER", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Ich sage: nein! Bei allen G\u00f6ttern, nein!\u00ab", "tokens": ["Ich", "sa\u00b7ge", ":", "nein", "!", "Bei", "al\u00b7len", "G\u00f6t\u00b7tern", ",", "nein", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "PTKANT", "$.", "APPR", "PIAT", "NN", "$,", "PTKANT", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und wie er's schwur, so ist's geschehen.", "tokens": ["Und", "wie", "er's", "schwur", ",", "so", "ist's", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "VVFIN", "$,", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wenngleich das helle Mondenlicht", "tokens": ["Wenn\u00b7gleich", "das", "hel\u00b7le", "Mon\u00b7den\u00b7licht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Auch g\u00fcnstig schien der H\u00fchnerschar", "tokens": ["Auch", "g\u00fcns\u00b7tig", "schien", "der", "H\u00fch\u00b7ner\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und klar ihr zeigte die Gefahr \u2013", "tokens": ["Und", "klar", "ihr", "zeig\u00b7te", "die", "Ge\u00b7fahr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der kundige Fuchs verzagte nicht,", "tokens": ["Der", "kun\u00b7di\u00b7ge", "Fuchs", "ver\u00b7zag\u00b7te", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "PTKNEG", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Er hatte seinen Sack voll List und Lug.", "tokens": ["Er", "hat\u00b7te", "sei\u00b7nen", "Sack", "voll", "List", "und", "Lug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "ADJD", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er tat zun\u00e4chst, als wolle er den Baum ersteigen,", "tokens": ["Er", "tat", "zu\u00b7n\u00e4chst", ",", "als", "wol\u00b7le", "er", "den", "Baum", "er\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KOUS", "VMFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indem er seine Pfoten um die Rinde schlug;", "tokens": ["In\u00b7dem", "er", "sei\u00b7ne", "Pfo\u00b7ten", "um", "die", "Rin\u00b7de", "schlug", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dann sank er hin, um sich als toten Mann zu zeigen,", "tokens": ["Dann", "sank", "er", "hin", ",", "um", "sich", "als", "to\u00b7ten", "Mann", "zu", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KOUI", "PRF", "KOUS", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und wieder auferstanden trieb er neuen Trug:", "tokens": ["Und", "wie\u00b7der", "auf\u00b7er\u00b7stan\u00b7den", "trieb", "er", "neu\u00b7en", "Trug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVIZU", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Verwandelte sich wie ein Harlekin", "tokens": ["Ver\u00b7wan\u00b7del\u00b7te", "sich", "wie", "ein", "Har\u00b7le\u00b7kin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "In immer andere Gestalten,", "tokens": ["In", "im\u00b7mer", "an\u00b7de\u00b7re", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Hob seinen Schwanz und schwenkte ihn,", "tokens": ["Hob", "sei\u00b7nen", "Schwanz", "und", "schwenk\u00b7te", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Hat unentwegt die indischen H\u00fchner wach gehalten.", "tokens": ["Hat", "un\u00b7ent\u00b7wegt", "die", "in\u00b7di\u00b7schen", "H\u00fch\u00b7ner", "wach", "ge\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ART", "ADJA", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "Von diesen, die den Feind nicht aus den Augen lie\u00dfen,", "tokens": ["Von", "die\u00b7sen", ",", "die", "den", "Feind", "nicht", "aus", "den", "Au\u00b7gen", "lie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "$,", "PRELS", "ART", "NN", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wagte nat\u00fcrlich keins, zum Schlaf das Lid zu schlie\u00dfen.", "tokens": ["Wag\u00b7te", "na\u00b7t\u00fcr\u00b7lich", "keins", ",", "zum", "Schlaf", "das", "Lid", "zu", "schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "$,", "APPRART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.11": {"line.1": {"text": "Scharf sp\u00e4hten sie und wurden endlich m\u00fcd und matt,", "tokens": ["Scharf", "sp\u00e4h\u00b7ten", "sie", "und", "wur\u00b7den", "end\u00b7lich", "m\u00fcd", "und", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "KON", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und manches taumelte ersch\u00f6pft vom Baum", "tokens": ["Und", "man\u00b7ches", "tau\u00b7mel\u00b7te", "er\u00b7sch\u00f6pft", "vom", "Baum"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "VVPP", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und fand alsbald die letzte Ruhestatt,", "tokens": ["Und", "fand", "als\u00b7bald", "die", "letz\u00b7te", "Ru\u00b7he\u00b7statt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die ersten in des roten M\u00f6rders Magen,", "tokens": ["Die", "ers\u00b7ten", "in", "des", "ro\u00b7ten", "M\u00f6r\u00b7ders", "Ma\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die n\u00e4chsten trug er schnell in seinen Vorratsraum", "tokens": ["Die", "n\u00e4chs\u00b7ten", "trug", "er", "schnell", "in", "sei\u00b7nen", "Vor\u00b7rats\u00b7raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nach Malepartus ein.", "tokens": ["Nach", "Ma\u00b7le\u00b7par\u00b7tus", "ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Was meine Fabel euch erz\u00e4hlt?", "tokens": ["Was", "mei\u00b7ne", "Fa\u00b7bel", "euch", "er\u00b7z\u00e4hlt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2013 Wer nichts als immer die Gefahr im Auge h\u00e4lt,", "tokens": ["\u2013", "Wer", "nichts", "als", "im\u00b7mer", "die", "Ge\u00b7fahr", "im", "Au\u00b7ge", "h\u00e4lt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "PIS", "KOKOM", "ADV", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00e4llt schlie\u00dflich ganz gewi\u00df hinein.", "tokens": ["F\u00e4llt", "schlie\u00df\u00b7lich", "ganz", "ge\u00b7wi\u00df", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}