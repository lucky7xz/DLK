{"textgrid.poem.49608": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "D' Marie", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Maria Seibold war nun schon", "tokens": ["Ma\u00b7ria", "Sei\u00b7bold", "war", "nun", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VAFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Drei Jahre in der Kondition", "tokens": ["Drei", "Jah\u00b7re", "in", "der", "Kon\u00b7di\u00b7ti\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Als Kellnerin beim Hackerbr\u00e4u.", "tokens": ["Als", "Kell\u00b7ne\u00b7rin", "beim", "Ha\u00b7cker\u00b7br\u00e4u", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch war sie flei\u00dfig, ehrlich, treu.", "tokens": ["Auch", "war", "sie", "flei\u00b7\u00dfig", ",", "ehr\u00b7lich", ",", "treu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das Leben einer Kellnerin", "tokens": ["Das", "Le\u00b7ben", "ei\u00b7ner", "Kell\u00b7ne\u00b7rin"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flie\u00dft nicht in lauter Unschuld hin.", "tokens": ["Flie\u00dft", "nicht", "in", "lau\u00b7ter", "Un\u00b7schuld", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die G\u00e4ste werden leicht frivol,", "tokens": ["Die", "G\u00e4s\u00b7te", "wer\u00b7den", "leicht", "fri\u00b7vol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beeinflu\u00dft durch den Alkohol.", "tokens": ["Be\u00b7ein\u00b7flu\u00dft", "durch", "den", "Al\u00b7ko\u00b7hol", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Sehr h\u00e4ufig zeigt ein alter Mann", "tokens": ["Sehr", "h\u00e4u\u00b7fig", "zeigt", "ein", "al\u00b7ter", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gef\u00fchle, die er nicht mehr kann;", "tokens": ["Ge\u00b7f\u00fch\u00b7le", ",", "die", "er", "nicht", "mehr", "kann", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Zote ist der letzte Trieb,", "tokens": ["Die", "Zo\u00b7te", "ist", "der", "letz\u00b7te", "Trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der ihm von allem \u00fcbrigblieb.", "tokens": ["Der", "ihm", "von", "al\u00b7lem", "\u00fcb\u00b7rig\u00b7blieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Kellnerin ist das Objekt", "tokens": ["Die", "Kell\u00b7ne\u00b7rin", "ist", "das", "Ob\u00b7jekt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Witze, die man sonst versteckt,", "tokens": ["F\u00fcr", "Wit\u00b7ze", ",", "die", "man", "sonst", "ver\u00b7steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie meckert so ein alter Greis,", "tokens": ["Wie", "me\u00b7ckert", "so", "ein", "al\u00b7ter", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wenn er was Ordin\u00e4res wei\u00df!", "tokens": ["Wenn", "er", "was", "Or\u00b7di\u00b7n\u00e4\u00b7res", "wei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wie herzlich lacht der Gro\u00dfpapa,", "tokens": ["Wie", "herz\u00b7lich", "lacht", "der", "Gro\u00df\u00b7pa\u00b7pa", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und tut hihi und tut haha!", "tokens": ["Und", "tut", "hi\u00b7hi", "und", "tut", "ha\u00b7ha", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "KON", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denkt sich, eine Kellnerin", "tokens": ["Und", "denkt", "sich", ",", "ei\u00b7ne", "Kell\u00b7ne\u00b7rin"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nimmt jeden Unflat gerne hin.", "tokens": ["Nimmt", "je\u00b7den", "Un\u00b7flat", "ger\u00b7ne", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "In dieser Welt der Sinnenlust", "tokens": ["In", "die\u00b7ser", "Welt", "der", "Sin\u00b7nen\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blieb Marie immer selbstbewu\u00dft,", "tokens": ["Blieb", "Ma\u00b7rie", "im\u00b7mer", "selbst\u00b7be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was sie vernahm, war oft gemein,", "tokens": ["Was", "sie", "ver\u00b7nahm", ",", "war", "oft", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch ihr Herz blieb sittenrein.", "tokens": ["Je\u00b7doch", "ihr", "Herz", "blieb", "sit\u00b7ten\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Kein F\u00e4hnrich und kein Korpsstudent", "tokens": ["Kein", "F\u00e4hn\u00b7rich", "und", "kein", "Korps\u00b7stu\u00b7dent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ersch\u00fctterte ihr Fundament.", "tokens": ["Er\u00b7sch\u00fct\u00b7ter\u00b7te", "ihr", "Fun\u00b7da\u00b7ment", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja selbst der sch\u00f6nste Offizier", "tokens": ["Ja", "selbst", "der", "sch\u00f6ns\u00b7te", "Of\u00b7fi\u00b7zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erreichte niemals nichts bei ihr.", "tokens": ["Er\u00b7reich\u00b7te", "nie\u00b7mals", "nichts", "bei", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "In ihrem Busen war kein Platz", "tokens": ["In", "ih\u00b7rem", "Bu\u00b7sen", "war", "kein", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Liebe oder einen Schatz.", "tokens": ["F\u00fcr", "Lie\u00b7be", "o\u00b7der", "ei\u00b7nen", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie blieb das ganze Jahr allein", "tokens": ["Sie", "blieb", "das", "gan\u00b7ze", "Jahr", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mochte nicht und sagte \u00bbnein\u00ab.", "tokens": ["Und", "moch\u00b7te", "nicht", "und", "sag\u00b7te", "\u00bb", "nein", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KON", "VVFIN", "$(", "PTKANT", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Indessen, wer es recht versteht,", "tokens": ["In\u00b7des\u00b7sen", ",", "wer", "es", "recht", "ver\u00b7steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wei\u00df ja selber, wie das geht,", "tokens": ["Der", "wei\u00df", "ja", "sel\u00b7ber", ",", "wie", "das", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "$,", "PWAV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tugend ist ein Zwangssystem", "tokens": ["Die", "Tu\u00b7gend", "ist", "ein", "Zwangs\u00b7sys\u00b7tem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und insofern nicht angenehm.", "tokens": ["Und", "in\u00b7so\u00b7fern", "nicht", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ihr Gegenteil ist ein Genu\u00df;", "tokens": ["Ihr", "Ge\u00b7gen\u00b7teil", "ist", "ein", "Ge\u00b7nu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man hat sie blo\u00df, weil man sie mu\u00df,", "tokens": ["Man", "hat", "sie", "blo\u00df", ",", "weil", "man", "sie", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man gibt sie weg, sobald man kann,", "tokens": ["Man", "gibt", "sie", "weg", ",", "so\u00b7bald", "man", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es fragt sich nur: mit wem und wann.", "tokens": ["Es", "fragt", "sich", "nur", ":", "mit", "wem", "und", "wann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$.", "APPR", "PWS", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Er hie\u00df mit Namen Konstantin", "tokens": ["Er", "hie\u00df", "mit", "Na\u00b7men", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und kam durch einen Zufall hin.", "tokens": ["Und", "kam", "durch", "ei\u00b7nen", "Zu\u00b7fall", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Maler brauchte er Kredit", "tokens": ["Als", "Ma\u00b7ler", "brauch\u00b7te", "er", "Kre\u00b7dit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und teilte es dem M\u00e4dchen mit.", "tokens": ["Und", "teil\u00b7te", "es", "dem", "M\u00e4d\u00b7chen", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Sie pumpte ihm. Man wei\u00df es ja:", "tokens": ["Sie", "pump\u00b7te", "ihm", ".", "Man", "wei\u00df", "es", "ja", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vertrauen bringt die Herzen nah,", "tokens": ["Ver\u00b7trau\u00b7en", "bringt", "die", "Her\u00b7zen", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und so erwachte auch f\u00fcr sie", "tokens": ["Und", "so", "er\u00b7wach\u00b7te", "auch", "f\u00fcr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der erste Keim der Sympathie.", "tokens": ["Der", "ers\u00b7te", "Keim", "der", "Sym\u00b7pa\u00b7thie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ein Weib f\u00fchlt stets f\u00fcr einen Mann,", "tokens": ["Ein", "Weib", "f\u00fchlt", "stets", "f\u00fcr", "ei\u00b7nen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem es mit etwas helfen kann,", "tokens": ["Dem", "es", "mit", "et\u00b7was", "hel\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die Regung sch\u00f6ner Z\u00e4rtlichkeit,", "tokens": ["Die", "Re\u00b7gung", "sch\u00f6\u00b7ner", "Z\u00e4rt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die dann naturgem\u00e4\u00df gedeiht.", "tokens": ["Die", "dann", "na\u00b7tur\u00b7ge\u00b7m\u00e4\u00df", "ge\u00b7deiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Das Wohlgefallen w\u00e4chst an Kraft,", "tokens": ["Das", "Wohl\u00b7ge\u00b7fal\u00b7len", "w\u00e4chst", "an", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Neigung wird zur Leidenschaft,", "tokens": ["Die", "Nei\u00b7gung", "wird", "zur", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn das Schicksal sie nicht trennt", "tokens": ["Und", "wenn", "das", "Schick\u00b7sal", "sie", "nicht", "trennt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt das geschlechtliche Moment.", "tokens": ["Kommt", "das", "ge\u00b7schlecht\u00b7li\u00b7che", "Mo\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Auch hier in dem besondern Fall", "tokens": ["Auch", "hier", "in", "dem", "be\u00b7son\u00b7dern", "Fall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging es wie stets und \u00fcberall.", "tokens": ["Ging", "es", "wie", "stets", "und", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am dritten Tag war Konstantin", "tokens": ["Am", "drit\u00b7ten", "Tag", "war", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "NE"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Das Ideal der Kellnerin.", "tokens": ["Das", "I\u00b7deal", "der", "Kell\u00b7ne\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Er selber nahm es mehr als Scherz,", "tokens": ["Er", "sel\u00b7ber", "nahm", "es", "mehr", "als", "Scherz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn ein erprobtes M\u00e4nnerherz", "tokens": ["Denn", "ein", "er\u00b7prob\u00b7tes", "M\u00e4n\u00b7ner\u00b7herz"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gibt mancherlei Gef\u00fchlen Raum", "tokens": ["Gibt", "man\u00b7cher\u00b7lei", "Ge\u00b7f\u00fch\u00b7len", "Raum"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und t\u00e4ndelt blo\u00df und merkt sie kaum.", "tokens": ["Und", "t\u00e4n\u00b7delt", "blo\u00df", "und", "merkt", "sie", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Indessen auch im leichten Spiel", "tokens": ["In\u00b7des\u00b7sen", "auch", "im", "leich\u00b7ten", "Spiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verfolgt man das bewu\u00dfte Ziel,", "tokens": ["Ver\u00b7folgt", "man", "das", "be\u00b7wu\u00df\u00b7te", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das jenseits von der Tugend liegt,", "tokens": ["Das", "jen\u00b7seits", "von", "der", "Tu\u00b7gend", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die selten k\u00e4mpft und niemals siegt.", "tokens": ["Die", "sel\u00b7ten", "k\u00e4mpft", "und", "nie\u00b7mals", "siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Nat\u00fcrlich nahm es Konstantin", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "nahm", "es", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als ziemlich selbstverst\u00e4ndlich hin,", "tokens": ["Als", "ziem\u00b7lich", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie ihm gern und liebevoll", "tokens": ["Da\u00df", "sie", "ihm", "gern", "und", "lie\u00b7be\u00b7voll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Allerbeste opfern soll.", "tokens": ["Das", "Al\u00b7ler\u00b7bes\u00b7te", "op\u00b7fern", "soll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Sie str\u00e4ubte sich; doch war der Ton", "tokens": ["Sie", "str\u00e4ub\u00b7te", "sich", ";", "doch", "war", "der", "Ton"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "$.", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit dem sie's tat, Gew\u00e4hrung schon.", "tokens": ["Mit", "dem", "sie's", "tat", ",", "Ge\u00b7w\u00e4h\u00b7rung", "schon", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es klang in das versch\u00e4mte \u00bbNein\u00ab", "tokens": ["Es", "klang", "in", "das", "ver\u00b7sch\u00e4m\u00b7te", "\u00bb", "Nein", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "$(", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz leise h\u00f6rbar \u00bbja\u00ab hinein.", "tokens": ["Ganz", "lei\u00b7se", "h\u00f6r\u00b7bar", "\u00bb", "ja", "\u00ab", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "$(", "PTKANT", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbo Marie, tu nur zimperlich:", "tokens": ["\u00bb", "o", "Ma\u00b7rie", ",", "tu", "nur", "zim\u00b7per\u00b7lich", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "$,", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was wetten wir, ich kriege dich.\u00ab", "tokens": ["Was", "wet\u00b7ten", "wir", ",", "ich", "krie\u00b7ge", "dich", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sprach sehr oft der Konstantin,", "tokens": ["So", "sprach", "sehr", "oft", "der", "Kons\u00b7tan\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Indem er heimging, vor sich hin.", "tokens": ["In\u00b7dem", "er", "heim\u00b7ging", ",", "vor", "sich", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Die Zeit f\u00fcr einen S\u00fcndenfall", "tokens": ["Die", "Zeit", "f\u00fcr", "ei\u00b7nen", "S\u00fcn\u00b7den\u00b7fall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist sicherlich der Karneval,", "tokens": ["Ist", "si\u00b7cher\u00b7lich", "der", "Kar\u00b7ne\u00b7val", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man hat den Ort, man hat die Zeit,", "tokens": ["Man", "hat", "den", "Ort", ",", "man", "hat", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "$,", "PIS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verf\u00fchrung und Gelegenheit.", "tokens": ["Ver\u00b7f\u00fch\u00b7rung", "und", "Ge\u00b7le\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Man sagt ganz harmlos: \u00bbAch herje,", "tokens": ["Man", "sagt", "ganz", "harm\u00b7los", ":", "\u00bb", "Ach", "her\u00b7je", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "$.", "$(", "ITJ", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie w\u00e4r's mit einem bal par\u00e9.\u00ab", "tokens": ["Wie", "w\u00e4r's", "mit", "ei\u00b7nem", "bal", "pa\u00b7r\u00e9", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "APPR", "ART", "ADV", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man bietet sich zum Schutze an,", "tokens": ["Man", "bie\u00b7tet", "sich", "zum", "Schut\u00b7ze", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit das M\u00e4dchen gehen kann.", "tokens": ["Da\u00b7mit", "das", "M\u00e4d\u00b7chen", "ge\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Das arme Ding, das gar nicht ahnt,", "tokens": ["Das", "ar\u00b7me", "Ding", ",", "das", "gar", "nicht", "ahnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was man so nebenbei noch plant,", "tokens": ["Was", "man", "so", "ne\u00b7ben\u00b7bei", "noch", "plant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sagt h\u00f6flich: \u00bbJa, da gehen wir.\u00ab", "tokens": ["Sagt", "h\u00f6f\u00b7lich", ":", "\u00bb", "Ja", ",", "da", "ge\u00b7hen", "wir", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "$.", "$(", "PTKANT", "$,", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es denkt nur an das Tanzpl\u00e4sier.", "tokens": ["Es", "denkt", "nur", "an", "das", "Tanz\u00b7pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Das Lamm, das auf der Wiese springt,", "tokens": ["Das", "Lamm", ",", "das", "auf", "der", "Wie\u00b7se", "springt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Folgt seinem Metzger unbedingt", "tokens": ["Folgt", "sei\u00b7nem", "Metz\u00b7ger", "un\u00b7be\u00b7dingt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denkt an keine arge List,", "tokens": ["Und", "denkt", "an", "kei\u00b7ne", "ar\u00b7ge", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis da\u00df es dann geschlachtet ist.", "tokens": ["Bis", "da\u00df", "es", "dann", "ge\u00b7schlach\u00b7tet", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Der Schmetterling fliegt in das Licht", "tokens": ["Der", "Schmet\u00b7ter\u00b7ling", "fliegt", "in", "das", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und denkt an keine Folgen nicht;", "tokens": ["Und", "denkt", "an", "kei\u00b7ne", "Fol\u00b7gen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Vogel merkt den Leim erst dann,", "tokens": ["Der", "Vo\u00b7gel", "merkt", "den", "Leim", "erst", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn er nicht mehr von hinnen kann.", "tokens": ["Wenn", "er", "nicht", "mehr", "von", "hin\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Und kurz und gut, manch sch\u00f6nes Kind", "tokens": ["Und", "kurz", "und", "gut", ",", "manch", "sch\u00f6\u00b7nes", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist harmlos, wie die Tierchen sind.", "tokens": ["Ist", "harm\u00b7los", ",", "wie", "die", "Tier\u00b7chen", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So fiel auch Marie ohne Arg", "tokens": ["So", "fiel", "auch", "Ma\u00b7rie", "oh\u00b7ne", "Arg"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "NE", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Ahnung in den Tugendberg.", "tokens": ["Und", "Ah\u00b7nung", "in", "den", "Tu\u00b7gend\u00b7berg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Die Geige klingt, die Fl\u00f6te pfeift,", "tokens": ["Die", "Gei\u00b7ge", "klingt", ",", "die", "Fl\u00f6\u00b7te", "pfeift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie so ein Walzer uns ergreift!", "tokens": ["Wie", "so", "ein", "Wal\u00b7zer", "uns", "er\u00b7greift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Herz des M\u00e4dchens quillt empor,", "tokens": ["Das", "Herz", "des", "M\u00e4d\u00b7chens", "quillt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es kommt ihm alles g\u00f6ttlich vor.", "tokens": ["Es", "kommt", "ihm", "al\u00b7les", "g\u00f6tt\u00b7lich", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Tira \u2013 la \u2013 lala \u2013 ach wie gut.", "tokens": ["Ti\u00b7ra", "\u2013", "la", "\u2013", "la\u00b7la", "\u2013", "ach", "wie", "gut", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "FM", "$(", "XY", "$(", "XY", "KOKOM", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Es klopft der Puls, es wallt das Blut.", "tokens": ["Es", "klopft", "der", "Puls", ",", "es", "wallt", "das", "Blut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er tanzt auch links mit viel Geschick,", "tokens": ["Er", "tanzt", "auch", "links", "mit", "viel", "Ge\u00b7schick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und immer feuchter wird der Blick.", "tokens": ["Und", "im\u00b7mer", "feuch\u00b7ter", "wird", "der", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "\u00bbmein Herr, Sie tanzen gar zu eng.\u00ab", "tokens": ["\u00bb", "mein", "Herr", ",", "Sie", "tan\u00b7zen", "gar", "zu", "eng", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdas kommt von selber im Gedr\u00e4ng'.", "tokens": ["\u00bb", "das", "kommt", "von", "sel\u00b7ber", "im", "Ge\u00b7dr\u00e4ng'", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "APPR", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entschuldigung, das war mein Knie.", "tokens": ["Ent\u00b7schul\u00b7di\u00b7gung", ",", "das", "war", "mein", "Knie", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich h\u00f6re auf.\u00ab \u00bbNein, bleiben Sie.\u00ab", "tokens": ["Ich", "h\u00f6\u00b7re", "auf", ".", "\u00ab", "\u00bb", "Nein", ",", "blei\u00b7ben", "Sie", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$(", "$(", "PTKANT", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Wie sich das Arm im Arme wiegt!", "tokens": ["Wie", "sich", "das", "Arm", "im", "Ar\u00b7me", "wiegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sich das Herz am Herzen liegt!", "tokens": ["Wie", "sich", "das", "Herz", "am", "Her\u00b7zen", "liegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbbist du mir gut?\u00ab \u00bbSo sei doch still.\u00ab", "tokens": ["\u00bb", "bist", "du", "mir", "gut", "?", "\u00ab", "\u00bb", "So", "sei", "doch", "still", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "ADJD", "$.", "$(", "$(", "ADV", "VAFIN", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbnein, sag mir, was ich wissen will!\u00ab", "tokens": ["\u00bb", "nein", ",", "sag", "mir", ",", "was", "ich", "wis\u00b7sen", "will", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Es r\u00f6tet sich das Angesicht.", "tokens": ["Es", "r\u00f6\u00b7tet", "sich", "das", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach, Konstantin, ich sag' es nicht,", "tokens": ["\u00bb", "ach", ",", "Kons\u00b7tan\u00b7tin", ",", "ich", "sag'", "es", "nicht", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ach, Konstantin, du wei\u00dft es schon!\u00ab", "tokens": ["Ach", ",", "Kons\u00b7tan\u00b7tin", ",", "du", "wei\u00dft", "es", "schon", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da schweigt der s\u00fc\u00dfe Geigenton.", "tokens": ["Da", "schweigt", "der", "s\u00fc\u00b7\u00dfe", "Gei\u00b7gen\u00b7ton", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Sie ist ersch\u00f6pft. Ein Gl\u00e4schen Sekt", "tokens": ["Sie", "ist", "er\u00b7sch\u00f6pft", ".", "Ein", "Gl\u00e4s\u00b7chen", "Sekt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erleichtert ihm, was er bezweckt,", "tokens": ["Er\u00b7leich\u00b7tert", "ihm", ",", "was", "er", "be\u00b7zweckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kommt nun, wie es kommen mu\u00df,", "tokens": ["Es", "kommt", "nun", ",", "wie", "es", "kom\u00b7men", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein langer Ku\u00df, und noch ein Ku\u00df.", "tokens": ["Ein", "lan\u00b7ger", "Ku\u00df", ",", "und", "noch", "ein", "Ku\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "\u00bbum Gottes willen, Konstantin!", "tokens": ["\u00bb", "um", "Got\u00b7tes", "wil\u00b7len", ",", "Kons\u00b7tan\u00b7tin", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "APPR", "NN", "NN", "$,", "NE", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo denken Sie denn wirklich hin?\u00ab", "tokens": ["Wo", "den\u00b7ken", "Sie", "denn", "wirk\u00b7lich", "hin", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbund str\u00e4ube dich nicht immerzu,", "tokens": ["\u00bb", "und", "str\u00e4u\u00b7be", "dich", "nicht", "im\u00b7mer\u00b7zu", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es gibt kein \u203aSie\u2039, wir sagen \u203adu\u2039.\u00ab", "tokens": ["Es", "gibt", "kein", "\u203a", "Sie", "\u2039", ",", "wir", "sa\u00b7gen", "\u203a", "du", "\u2039", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PPER", "$(", "$,", "PPER", "VVINF", "$(", "PPER", "$(", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Im Palmengarten wird es schw\u00fcl,", "tokens": ["Im", "Pal\u00b7men\u00b7gar\u00b7ten", "wird", "es", "schw\u00fcl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es steigert sich das Lustgef\u00fchl;", "tokens": ["Es", "stei\u00b7gert", "sich", "das", "Lust\u00b7ge\u00b7f\u00fchl", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie sich ihr Busen hebt und senkt!", "tokens": ["Wie", "sich", "ihr", "Bu\u00b7sen", "hebt", "und", "senkt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Auge sagt, was sie sich denkt.", "tokens": ["Ihr", "Au\u00b7ge", "sagt", ",", "was", "sie", "sich", "denkt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PRELS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "O Marie, du bist auf der Bahn,", "tokens": ["O", "Ma\u00b7rie", ",", "du", "bist", "auf", "der", "Bahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die abw\u00e4rts f\u00fchrt. So geht es an.", "tokens": ["Die", "ab\u00b7w\u00e4rts", "f\u00fchrt", ".", "So", "geht", "es", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Ku\u00df ist so gef\u00e4hrlich nicht,", "tokens": ["Ein", "Ku\u00df", "ist", "so", "ge\u00b7f\u00e4hr\u00b7lich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch schlimm ist das, was er verspricht.", "tokens": ["Doch", "schlimm", "ist", "das", ",", "was", "er", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PDS", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Sie schmatzen wieder. T\u00e4tere\u2013t\u00e4!", "tokens": ["Sie", "schmat\u00b7zen", "wie\u00b7der", ".", "T\u00e4\u00b7te\u00b7re", "\u2013", "t\u00e4", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "NN", "$(", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man bl\u00e4st das Zeichen zum Fra\u00df\u00e4", "tokens": ["Man", "bl\u00e4st", "das", "Zei\u00b7chen", "zum", "Fra\u00b7\u00df\u00e4"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Autsch M\u00e4dchentugend! Autsch Marie!", "tokens": ["Autsch", "M\u00e4d\u00b7chen\u00b7tu\u00b7gend", "!", "Autsch", "Ma\u00b7rie", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O kehre um! Jetzt oder nie!", "tokens": ["O", "keh\u00b7re", "um", "!", "Jetzt", "o\u00b7der", "nie", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$.", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Sie bleibt und spricht der Sitte Hohn.", "tokens": ["Sie", "bleibt", "und", "spricht", "der", "Sit\u00b7te", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr guter Engel ist entflohn,", "tokens": ["Ihr", "gu\u00b7ter", "En\u00b7gel", "ist", "ent\u00b7flohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nun entwickelt sich im Saal", "tokens": ["Und", "nun", "ent\u00b7wi\u00b7ckelt", "sich", "im", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das wohlbekannte Bacchanal.", "tokens": ["Das", "wohl\u00b7be\u00b7kann\u00b7te", "Bac\u00b7cha\u00b7nal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Es steigern sich bei jeder Tour", "tokens": ["Es", "stei\u00b7gern", "sich", "bei", "je\u00b7der", "Tour"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wilden Triebe der Natur;", "tokens": ["Die", "wil\u00b7den", "Trie\u00b7be", "der", "Na\u00b7tur", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es fliegt das Bein, es fliegt der Rock,", "tokens": ["Es", "fliegt", "das", "Bein", ",", "es", "fliegt", "der", "Rock", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jeder J\u00fcngling wird ein Bock.", "tokens": ["Ein", "je\u00b7der", "J\u00fcng\u00b7ling", "wird", "ein", "Bock", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Beim Tanze, da gilt keine Kunst.", "tokens": ["Beim", "Tan\u00b7ze", ",", "da", "gilt", "kei\u00b7ne", "Kunst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man dreht sich nur in toller Brunst,", "tokens": ["Man", "dreht", "sich", "nur", "in", "tol\u00b7ler", "Brunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man jauchzt besessen, schreit und stampft,", "tokens": ["Man", "jauchzt", "be\u00b7ses\u00b7sen", ",", "schreit", "und", "stampft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVPP", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man lacht und br\u00fcllt und schwitzt und dampft.", "tokens": ["Man", "lacht", "und", "br\u00fcllt", "und", "schwitzt", "und", "dampft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Du s\u00fc\u00dfe Unschuld, lebe wohl!", "tokens": ["Du", "s\u00fc\u00b7\u00dfe", "Un\u00b7schuld", ",", "le\u00b7be", "wohl", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das andre macht der Alkohol.", "tokens": ["Das", "and\u00b7re", "macht", "der", "Al\u00b7ko\u00b7hol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du hast's erreicht, mein Konstantin!", "tokens": ["Du", "hast's", "er\u00b7reicht", ",", "mein", "Kons\u00b7tan\u00b7tin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie ist verloren. Nimm sie hin!", "tokens": ["Sie", "ist", "ver\u00b7lo\u00b7ren", ".", "Nimm", "sie", "hin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "NE", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Und bei dem letzten Fl\u00f6tenpfiff", "tokens": ["Und", "bei", "dem", "letz\u00b7ten", "Fl\u00f6\u00b7ten\u00b7pfiff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erlosch ihr letzter Schambegriff,", "tokens": ["Er\u00b7losch", "ihr", "letz\u00b7ter", "Scham\u00b7be\u00b7griff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie duldet jeden H\u00e4ndedruck,", "tokens": ["Sie", "dul\u00b7det", "je\u00b7den", "H\u00e4n\u00b7de\u00b7druck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verzichtet auf den Tugendschmuck.", "tokens": ["Ver\u00b7zich\u00b7tet", "auf", "den", "Tu\u00b7gend\u00b7schmuck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Und das Programm entwickelt sich,", "tokens": ["Und", "das", "Pro\u00b7gramm", "ent\u00b7wi\u00b7ckelt", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Verliebt, begehrlich, liederlich,", "tokens": ["Ver\u00b7liebt", ",", "be\u00b7gehr\u00b7lich", ",", "lie\u00b7der\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie i\u00dft noch Wei\u00dfw\u00fcrscht, geht zu ihm.", "tokens": ["Sie", "i\u00dft", "noch", "Wei\u00df\u00b7w\u00fcrscht", ",", "geht", "zu", "ihm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun sind ja wieder zwei intim.", "tokens": ["Nun", "sind", "ja", "wie\u00b7der", "zwei", "in\u00b7tim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "CARD", "APPRART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Maria ist nach dieser Nacht", "tokens": ["Ma\u00b7ria", "ist", "nach", "die\u00b7ser", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In seinem Atelier erwacht,", "tokens": ["In", "sei\u00b7nem", "A\u00b7te\u00b7lier", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und von derselben Stunde an", "tokens": ["Und", "von", "der\u00b7sel\u00b7ben", "Stun\u00b7de", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geriet sie auf die schiefe Bahn.", "tokens": ["Ge\u00b7riet", "sie", "auf", "die", "schie\u00b7fe", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Sie sch\u00e4kert jetzt mit jedem Gast", "tokens": ["Sie", "sch\u00e4\u00b7kert", "jetzt", "mit", "je\u00b7dem", "Gast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und freut sich mehr als jede fast,", "tokens": ["Und", "freut", "sich", "mehr", "als", "je\u00b7de", "fast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PIAT", "KOKOM", "PIAT", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn so ein ordin\u00e4rer Greis", "tokens": ["Wenn", "so", "ein", "or\u00b7di\u00b7n\u00e4\u00b7rer", "Greis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Stammtisch was Gemeines wei\u00df.", "tokens": ["Am", "Stamm\u00b7tisch", "was", "Ge\u00b7mei\u00b7nes", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Maria Seibold war nun schon", "tokens": ["Ma\u00b7ria", "Sei\u00b7bold", "war", "nun", "schon"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VAFIN", "ADV", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Drei Jahre in der Kondition", "tokens": ["Drei", "Jah\u00b7re", "in", "der", "Kon\u00b7di\u00b7ti\u00b7on"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "APPR", "ART", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Als Kellnerin beim Hackerbr\u00e4u.", "tokens": ["Als", "Kell\u00b7ne\u00b7rin", "beim", "Ha\u00b7cker\u00b7br\u00e4u", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPRART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch war sie flei\u00dfig, ehrlich, treu.", "tokens": ["Auch", "war", "sie", "flei\u00b7\u00dfig", ",", "ehr\u00b7lich", ",", "treu", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "ADJD", "$,", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Das Leben einer Kellnerin", "tokens": ["Das", "Le\u00b7ben", "ei\u00b7ner", "Kell\u00b7ne\u00b7rin"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Flie\u00dft nicht in lauter Unschuld hin.", "tokens": ["Flie\u00dft", "nicht", "in", "lau\u00b7ter", "Un\u00b7schuld", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die G\u00e4ste werden leicht frivol,", "tokens": ["Die", "G\u00e4s\u00b7te", "wer\u00b7den", "leicht", "fri\u00b7vol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beeinflu\u00dft durch den Alkohol.", "tokens": ["Be\u00b7ein\u00b7flu\u00dft", "durch", "den", "Al\u00b7ko\u00b7hol", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Sehr h\u00e4ufig zeigt ein alter Mann", "tokens": ["Sehr", "h\u00e4u\u00b7fig", "zeigt", "ein", "al\u00b7ter", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gef\u00fchle, die er nicht mehr kann;", "tokens": ["Ge\u00b7f\u00fch\u00b7le", ",", "die", "er", "nicht", "mehr", "kann", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PPER", "PTKNEG", "ADV", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Zote ist der letzte Trieb,", "tokens": ["Die", "Zo\u00b7te", "ist", "der", "letz\u00b7te", "Trieb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der ihm von allem \u00fcbrigblieb.", "tokens": ["Der", "ihm", "von", "al\u00b7lem", "\u00fcb\u00b7rig\u00b7blieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Die Kellnerin ist das Objekt", "tokens": ["Die", "Kell\u00b7ne\u00b7rin", "ist", "das", "Ob\u00b7jekt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Witze, die man sonst versteckt,", "tokens": ["F\u00fcr", "Wit\u00b7ze", ",", "die", "man", "sonst", "ver\u00b7steckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie meckert so ein alter Greis,", "tokens": ["Wie", "me\u00b7ckert", "so", "ein", "al\u00b7ter", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Wenn er was Ordin\u00e4res wei\u00df!", "tokens": ["Wenn", "er", "was", "Or\u00b7di\u00b7n\u00e4\u00b7res", "wei\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Wie herzlich lacht der Gro\u00dfpapa,", "tokens": ["Wie", "herz\u00b7lich", "lacht", "der", "Gro\u00df\u00b7pa\u00b7pa", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und tut hihi und tut haha!", "tokens": ["Und", "tut", "hi\u00b7hi", "und", "tut", "ha\u00b7ha", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM", "FM", "KON", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denkt sich, eine Kellnerin", "tokens": ["Und", "denkt", "sich", ",", "ei\u00b7ne", "Kell\u00b7ne\u00b7rin"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nimmt jeden Unflat gerne hin.", "tokens": ["Nimmt", "je\u00b7den", "Un\u00b7flat", "ger\u00b7ne", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "In dieser Welt der Sinnenlust", "tokens": ["In", "die\u00b7ser", "Welt", "der", "Sin\u00b7nen\u00b7lust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Blieb Marie immer selbstbewu\u00dft,", "tokens": ["Blieb", "Ma\u00b7rie", "im\u00b7mer", "selbst\u00b7be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Was sie vernahm, war oft gemein,", "tokens": ["Was", "sie", "ver\u00b7nahm", ",", "war", "oft", "ge\u00b7mein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jedoch ihr Herz blieb sittenrein.", "tokens": ["Je\u00b7doch", "ihr", "Herz", "blieb", "sit\u00b7ten\u00b7rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Kein F\u00e4hnrich und kein Korpsstudent", "tokens": ["Kein", "F\u00e4hn\u00b7rich", "und", "kein", "Korps\u00b7stu\u00b7dent"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ersch\u00fctterte ihr Fundament.", "tokens": ["Er\u00b7sch\u00fct\u00b7ter\u00b7te", "ihr", "Fun\u00b7da\u00b7ment", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja selbst der sch\u00f6nste Offizier", "tokens": ["Ja", "selbst", "der", "sch\u00f6ns\u00b7te", "Of\u00b7fi\u00b7zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erreichte niemals nichts bei ihr.", "tokens": ["Er\u00b7reich\u00b7te", "nie\u00b7mals", "nichts", "bei", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIS", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "In ihrem Busen war kein Platz", "tokens": ["In", "ih\u00b7rem", "Bu\u00b7sen", "war", "kein", "Platz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr Liebe oder einen Schatz.", "tokens": ["F\u00fcr", "Lie\u00b7be", "o\u00b7der", "ei\u00b7nen", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie blieb das ganze Jahr allein", "tokens": ["Sie", "blieb", "das", "gan\u00b7ze", "Jahr", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und mochte nicht und sagte \u00bbnein\u00ab.", "tokens": ["Und", "moch\u00b7te", "nicht", "und", "sag\u00b7te", "\u00bb", "nein", "\u00ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "KON", "VVFIN", "$(", "PTKANT", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Indessen, wer es recht versteht,", "tokens": ["In\u00b7des\u00b7sen", ",", "wer", "es", "recht", "ver\u00b7steht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWS", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der wei\u00df ja selber, wie das geht,", "tokens": ["Der", "wei\u00df", "ja", "sel\u00b7ber", ",", "wie", "das", "geht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "$,", "PWAV", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tugend ist ein Zwangssystem", "tokens": ["Die", "Tu\u00b7gend", "ist", "ein", "Zwangs\u00b7sys\u00b7tem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Und insofern nicht angenehm.", "tokens": ["Und", "in\u00b7so\u00b7fern", "nicht", "an\u00b7ge\u00b7nehm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Ihr Gegenteil ist ein Genu\u00df;", "tokens": ["Ihr", "Ge\u00b7gen\u00b7teil", "ist", "ein", "Ge\u00b7nu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man hat sie blo\u00df, weil man sie mu\u00df,", "tokens": ["Man", "hat", "sie", "blo\u00df", ",", "weil", "man", "sie", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man gibt sie weg, sobald man kann,", "tokens": ["Man", "gibt", "sie", "weg", ",", "so\u00b7bald", "man", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PIS", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es fragt sich nur: mit wem und wann.", "tokens": ["Es", "fragt", "sich", "nur", ":", "mit", "wem", "und", "wann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$.", "APPR", "PWS", "KON", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Er hie\u00df mit Namen Konstantin", "tokens": ["Er", "hie\u00df", "mit", "Na\u00b7men", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "NE"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und kam durch einen Zufall hin.", "tokens": ["Und", "kam", "durch", "ei\u00b7nen", "Zu\u00b7fall", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Als Maler brauchte er Kredit", "tokens": ["Als", "Ma\u00b7ler", "brauch\u00b7te", "er", "Kre\u00b7dit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und teilte es dem M\u00e4dchen mit.", "tokens": ["Und", "teil\u00b7te", "es", "dem", "M\u00e4d\u00b7chen", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Sie pumpte ihm. Man wei\u00df es ja:", "tokens": ["Sie", "pump\u00b7te", "ihm", ".", "Man", "wei\u00df", "es", "ja", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vertrauen bringt die Herzen nah,", "tokens": ["Ver\u00b7trau\u00b7en", "bringt", "die", "Her\u00b7zen", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und so erwachte auch f\u00fcr sie", "tokens": ["Und", "so", "er\u00b7wach\u00b7te", "auch", "f\u00fcr", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der erste Keim der Sympathie.", "tokens": ["Der", "ers\u00b7te", "Keim", "der", "Sym\u00b7pa\u00b7thie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Ein Weib f\u00fchlt stets f\u00fcr einen Mann,", "tokens": ["Ein", "Weib", "f\u00fchlt", "stets", "f\u00fcr", "ei\u00b7nen", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem es mit etwas helfen kann,", "tokens": ["Dem", "es", "mit", "et\u00b7was", "hel\u00b7fen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "PIS", "VVINF", "VMFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Die Regung sch\u00f6ner Z\u00e4rtlichkeit,", "tokens": ["Die", "Re\u00b7gung", "sch\u00f6\u00b7ner", "Z\u00e4rt\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die dann naturgem\u00e4\u00df gedeiht.", "tokens": ["Die", "dann", "na\u00b7tur\u00b7ge\u00b7m\u00e4\u00df", "ge\u00b7deiht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.58": {"line.1": {"text": "Das Wohlgefallen w\u00e4chst an Kraft,", "tokens": ["Das", "Wohl\u00b7ge\u00b7fal\u00b7len", "w\u00e4chst", "an", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Neigung wird zur Leidenschaft,", "tokens": ["Die", "Nei\u00b7gung", "wird", "zur", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und wenn das Schicksal sie nicht trennt", "tokens": ["Und", "wenn", "das", "Schick\u00b7sal", "sie", "nicht", "trennt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "PPER", "PTKNEG", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt das geschlechtliche Moment.", "tokens": ["Kommt", "das", "ge\u00b7schlecht\u00b7li\u00b7che", "Mo\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Auch hier in dem besondern Fall", "tokens": ["Auch", "hier", "in", "dem", "be\u00b7son\u00b7dern", "Fall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging es wie stets und \u00fcberall.", "tokens": ["Ging", "es", "wie", "stets", "und", "\u00fc\u00b7be\u00b7rall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Am dritten Tag war Konstantin", "tokens": ["Am", "drit\u00b7ten", "Tag", "war", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VAFIN", "NE"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Das Ideal der Kellnerin.", "tokens": ["Das", "I\u00b7deal", "der", "Kell\u00b7ne\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.60": {"line.1": {"text": "Er selber nahm es mehr als Scherz,", "tokens": ["Er", "sel\u00b7ber", "nahm", "es", "mehr", "als", "Scherz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Denn ein erprobtes M\u00e4nnerherz", "tokens": ["Denn", "ein", "er\u00b7prob\u00b7tes", "M\u00e4n\u00b7ner\u00b7herz"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gibt mancherlei Gef\u00fchlen Raum", "tokens": ["Gibt", "man\u00b7cher\u00b7lei", "Ge\u00b7f\u00fch\u00b7len", "Raum"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und t\u00e4ndelt blo\u00df und merkt sie kaum.", "tokens": ["Und", "t\u00e4n\u00b7delt", "blo\u00df", "und", "merkt", "sie", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Indessen auch im leichten Spiel", "tokens": ["In\u00b7des\u00b7sen", "auch", "im", "leich\u00b7ten", "Spiel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verfolgt man das bewu\u00dfte Ziel,", "tokens": ["Ver\u00b7folgt", "man", "das", "be\u00b7wu\u00df\u00b7te", "Ziel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das jenseits von der Tugend liegt,", "tokens": ["Das", "jen\u00b7seits", "von", "der", "Tu\u00b7gend", "liegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die selten k\u00e4mpft und niemals siegt.", "tokens": ["Die", "sel\u00b7ten", "k\u00e4mpft", "und", "nie\u00b7mals", "siegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "KON", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Nat\u00fcrlich nahm es Konstantin", "tokens": ["Na\u00b7t\u00fcr\u00b7lich", "nahm", "es", "Kons\u00b7tan\u00b7tin"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Als ziemlich selbstverst\u00e4ndlich hin,", "tokens": ["Als", "ziem\u00b7lich", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", "hin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df sie ihm gern und liebevoll", "tokens": ["Da\u00df", "sie", "ihm", "gern", "und", "lie\u00b7be\u00b7voll"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "ADV", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das Allerbeste opfern soll.", "tokens": ["Das", "Al\u00b7ler\u00b7bes\u00b7te", "op\u00b7fern", "soll", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Sie str\u00e4ubte sich; doch war der Ton", "tokens": ["Sie", "str\u00e4ub\u00b7te", "sich", ";", "doch", "war", "der", "Ton"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "$.", "ADV", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit dem sie's tat, Gew\u00e4hrung schon.", "tokens": ["Mit", "dem", "sie's", "tat", ",", "Ge\u00b7w\u00e4h\u00b7rung", "schon", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es klang in das versch\u00e4mte \u00bbNein\u00ab", "tokens": ["Es", "klang", "in", "das", "ver\u00b7sch\u00e4m\u00b7te", "\u00bb", "Nein", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "ADJA", "$(", "PTKANT", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ganz leise h\u00f6rbar \u00bbja\u00ab hinein.", "tokens": ["Ganz", "lei\u00b7se", "h\u00f6r\u00b7bar", "\u00bb", "ja", "\u00ab", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "$(", "PTKANT", "$(", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "\u00bbo Marie, tu nur zimperlich:", "tokens": ["\u00bb", "o", "Ma\u00b7rie", ",", "tu", "nur", "zim\u00b7per\u00b7lich", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NE", "$,", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was wetten wir, ich kriege dich.\u00ab", "tokens": ["Was", "wet\u00b7ten", "wir", ",", "ich", "krie\u00b7ge", "dich", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sprach sehr oft der Konstantin,", "tokens": ["So", "sprach", "sehr", "oft", "der", "Kons\u00b7tan\u00b7tin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Indem er heimging, vor sich hin.", "tokens": ["In\u00b7dem", "er", "heim\u00b7ging", ",", "vor", "sich", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "APPR", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Die Zeit f\u00fcr einen S\u00fcndenfall", "tokens": ["Die", "Zeit", "f\u00fcr", "ei\u00b7nen", "S\u00fcn\u00b7den\u00b7fall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist sicherlich der Karneval,", "tokens": ["Ist", "si\u00b7cher\u00b7lich", "der", "Kar\u00b7ne\u00b7val", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man hat den Ort, man hat die Zeit,", "tokens": ["Man", "hat", "den", "Ort", ",", "man", "hat", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "NN", "$,", "PIS", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verf\u00fchrung und Gelegenheit.", "tokens": ["Ver\u00b7f\u00fch\u00b7rung", "und", "Ge\u00b7le\u00b7gen\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Man sagt ganz harmlos: \u00bbAch herje,", "tokens": ["Man", "sagt", "ganz", "harm\u00b7los", ":", "\u00bb", "Ach", "her\u00b7je", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ADJD", "$.", "$(", "ITJ", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie w\u00e4r's mit einem bal par\u00e9.\u00ab", "tokens": ["Wie", "w\u00e4r's", "mit", "ei\u00b7nem", "bal", "pa\u00b7r\u00e9", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "APPR", "ART", "ADV", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man bietet sich zum Schutze an,", "tokens": ["Man", "bie\u00b7tet", "sich", "zum", "Schut\u00b7ze", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Damit das M\u00e4dchen gehen kann.", "tokens": ["Da\u00b7mit", "das", "M\u00e4d\u00b7chen", "ge\u00b7hen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Das arme Ding, das gar nicht ahnt,", "tokens": ["Das", "ar\u00b7me", "Ding", ",", "das", "gar", "nicht", "ahnt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was man so nebenbei noch plant,", "tokens": ["Was", "man", "so", "ne\u00b7ben\u00b7bei", "noch", "plant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "ADV", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sagt h\u00f6flich: \u00bbJa, da gehen wir.\u00ab", "tokens": ["Sagt", "h\u00f6f\u00b7lich", ":", "\u00bb", "Ja", ",", "da", "ge\u00b7hen", "wir", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ADJD", "$.", "$(", "PTKANT", "$,", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es denkt nur an das Tanzpl\u00e4sier.", "tokens": ["Es", "denkt", "nur", "an", "das", "Tanz\u00b7pl\u00e4\u00b7sier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Das Lamm, das auf der Wiese springt,", "tokens": ["Das", "Lamm", ",", "das", "auf", "der", "Wie\u00b7se", "springt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Folgt seinem Metzger unbedingt", "tokens": ["Folgt", "sei\u00b7nem", "Metz\u00b7ger", "un\u00b7be\u00b7dingt"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denkt an keine arge List,", "tokens": ["Und", "denkt", "an", "kei\u00b7ne", "ar\u00b7ge", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis da\u00df es dann geschlachtet ist.", "tokens": ["Bis", "da\u00df", "es", "dann", "ge\u00b7schlach\u00b7tet", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Der Schmetterling fliegt in das Licht", "tokens": ["Der", "Schmet\u00b7ter\u00b7ling", "fliegt", "in", "das", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Und denkt an keine Folgen nicht;", "tokens": ["Und", "denkt", "an", "kei\u00b7ne", "Fol\u00b7gen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Vogel merkt den Leim erst dann,", "tokens": ["Der", "Vo\u00b7gel", "merkt", "den", "Leim", "erst", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn er nicht mehr von hinnen kann.", "tokens": ["Wenn", "er", "nicht", "mehr", "von", "hin\u00b7nen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "APPR", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Und kurz und gut, manch sch\u00f6nes Kind", "tokens": ["Und", "kurz", "und", "gut", ",", "manch", "sch\u00f6\u00b7nes", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "ADJD", "$,", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist harmlos, wie die Tierchen sind.", "tokens": ["Ist", "harm\u00b7los", ",", "wie", "die", "Tier\u00b7chen", "sind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So fiel auch Marie ohne Arg", "tokens": ["So", "fiel", "auch", "Ma\u00b7rie", "oh\u00b7ne", "Arg"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "NE", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Ahnung in den Tugendberg.", "tokens": ["Und", "Ah\u00b7nung", "in", "den", "Tu\u00b7gend\u00b7berg", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Die Geige klingt, die Fl\u00f6te pfeift,", "tokens": ["Die", "Gei\u00b7ge", "klingt", ",", "die", "Fl\u00f6\u00b7te", "pfeift", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie so ein Walzer uns ergreift!", "tokens": ["Wie", "so", "ein", "Wal\u00b7zer", "uns", "er\u00b7greift", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Herz des M\u00e4dchens quillt empor,", "tokens": ["Das", "Herz", "des", "M\u00e4d\u00b7chens", "quillt", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es kommt ihm alles g\u00f6ttlich vor.", "tokens": ["Es", "kommt", "ihm", "al\u00b7les", "g\u00f6tt\u00b7lich", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Tira \u2013 la \u2013 lala \u2013 ach wie gut.", "tokens": ["Ti\u00b7ra", "\u2013", "la", "\u2013", "la\u00b7la", "\u2013", "ach", "wie", "gut", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "FM", "$(", "XY", "$(", "XY", "KOKOM", "ADJD", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Es klopft der Puls, es wallt das Blut.", "tokens": ["Es", "klopft", "der", "Puls", ",", "es", "wallt", "das", "Blut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er tanzt auch links mit viel Geschick,", "tokens": ["Er", "tanzt", "auch", "links", "mit", "viel", "Ge\u00b7schick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und immer feuchter wird der Blick.", "tokens": ["Und", "im\u00b7mer", "feuch\u00b7ter", "wird", "der", "Blick", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "\u00bbmein Herr, Sie tanzen gar zu eng.\u00ab", "tokens": ["\u00bb", "mein", "Herr", ",", "Sie", "tan\u00b7zen", "gar", "zu", "eng", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PPER", "VVFIN", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdas kommt von selber im Gedr\u00e4ng'.", "tokens": ["\u00bb", "das", "kommt", "von", "sel\u00b7ber", "im", "Ge\u00b7dr\u00e4ng'", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VVFIN", "APPR", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entschuldigung, das war mein Knie.", "tokens": ["Ent\u00b7schul\u00b7di\u00b7gung", ",", "das", "war", "mein", "Knie", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich h\u00f6re auf.\u00ab \u00bbNein, bleiben Sie.\u00ab", "tokens": ["Ich", "h\u00f6\u00b7re", "auf", ".", "\u00ab", "\u00bb", "Nein", ",", "blei\u00b7ben", "Sie", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$.", "$(", "$(", "PTKANT", "$,", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Wie sich das Arm im Arme wiegt!", "tokens": ["Wie", "sich", "das", "Arm", "im", "Ar\u00b7me", "wiegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie sich das Herz am Herzen liegt!", "tokens": ["Wie", "sich", "das", "Herz", "am", "Her\u00b7zen", "liegt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbbist du mir gut?\u00ab \u00bbSo sei doch still.\u00ab", "tokens": ["\u00bb", "bist", "du", "mir", "gut", "?", "\u00ab", "\u00bb", "So", "sei", "doch", "still", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "PPER", "PPER", "ADJD", "$.", "$(", "$(", "ADV", "VAFIN", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbnein, sag mir, was ich wissen will!\u00ab", "tokens": ["\u00bb", "nein", ",", "sag", "mir", ",", "was", "ich", "wis\u00b7sen", "will", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PTKANT", "$,", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Es r\u00f6tet sich das Angesicht.", "tokens": ["Es", "r\u00f6\u00b7tet", "sich", "das", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbach, Konstantin, ich sag' es nicht,", "tokens": ["\u00bb", "ach", ",", "Kons\u00b7tan\u00b7tin", ",", "ich", "sag'", "es", "nicht", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ach, Konstantin, du wei\u00dft es schon!\u00ab", "tokens": ["Ach", ",", "Kons\u00b7tan\u00b7tin", ",", "du", "wei\u00dft", "es", "schon", "!", "\u00ab"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da schweigt der s\u00fc\u00dfe Geigenton.", "tokens": ["Da", "schweigt", "der", "s\u00fc\u00b7\u00dfe", "Gei\u00b7gen\u00b7ton", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Sie ist ersch\u00f6pft. Ein Gl\u00e4schen Sekt", "tokens": ["Sie", "ist", "er\u00b7sch\u00f6pft", ".", "Ein", "Gl\u00e4s\u00b7chen", "Sekt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erleichtert ihm, was er bezweckt,", "tokens": ["Er\u00b7leich\u00b7tert", "ihm", ",", "was", "er", "be\u00b7zweckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es kommt nun, wie es kommen mu\u00df,", "tokens": ["Es", "kommt", "nun", ",", "wie", "es", "kom\u00b7men", "mu\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein langer Ku\u00df, und noch ein Ku\u00df.", "tokens": ["Ein", "lan\u00b7ger", "Ku\u00df", ",", "und", "noch", "ein", "Ku\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "\u00bbum Gottes willen, Konstantin!", "tokens": ["\u00bb", "um", "Got\u00b7tes", "wil\u00b7len", ",", "Kons\u00b7tan\u00b7tin", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "APPR", "NN", "NN", "$,", "NE", "$."], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo denken Sie denn wirklich hin?\u00ab", "tokens": ["Wo", "den\u00b7ken", "Sie", "denn", "wirk\u00b7lich", "hin", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00bbund str\u00e4ube dich nicht immerzu,", "tokens": ["\u00bb", "und", "str\u00e4u\u00b7be", "dich", "nicht", "im\u00b7mer\u00b7zu", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es gibt kein \u203aSie\u2039, wir sagen \u203adu\u2039.\u00ab", "tokens": ["Es", "gibt", "kein", "\u203a", "Sie", "\u2039", ",", "wir", "sa\u00b7gen", "\u203a", "du", "\u2039", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PPER", "$(", "$,", "PPER", "VVINF", "$(", "PPER", "$(", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Im Palmengarten wird es schw\u00fcl,", "tokens": ["Im", "Pal\u00b7men\u00b7gar\u00b7ten", "wird", "es", "schw\u00fcl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es steigert sich das Lustgef\u00fchl;", "tokens": ["Es", "stei\u00b7gert", "sich", "das", "Lust\u00b7ge\u00b7f\u00fchl", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie sich ihr Busen hebt und senkt!", "tokens": ["Wie", "sich", "ihr", "Bu\u00b7sen", "hebt", "und", "senkt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "PPOSAT", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ihr Auge sagt, was sie sich denkt.", "tokens": ["Ihr", "Au\u00b7ge", "sagt", ",", "was", "sie", "sich", "denkt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PRELS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "O Marie, du bist auf der Bahn,", "tokens": ["O", "Ma\u00b7rie", ",", "du", "bist", "auf", "der", "Bahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die abw\u00e4rts f\u00fchrt. So geht es an.", "tokens": ["Die", "ab\u00b7w\u00e4rts", "f\u00fchrt", ".", "So", "geht", "es", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Ku\u00df ist so gef\u00e4hrlich nicht,", "tokens": ["Ein", "Ku\u00df", "ist", "so", "ge\u00b7f\u00e4hr\u00b7lich", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch schlimm ist das, was er verspricht.", "tokens": ["Doch", "schlimm", "ist", "das", ",", "was", "er", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PDS", "$,", "PWS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.80": {"line.1": {"text": "Sie schmatzen wieder. T\u00e4tere\u2013t\u00e4!", "tokens": ["Sie", "schmat\u00b7zen", "wie\u00b7der", ".", "T\u00e4\u00b7te\u00b7re", "\u2013", "t\u00e4", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "NN", "$(", "NE", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man bl\u00e4st das Zeichen zum Fra\u00df\u00e4", "tokens": ["Man", "bl\u00e4st", "das", "Zei\u00b7chen", "zum", "Fra\u00b7\u00df\u00e4"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Autsch M\u00e4dchentugend! Autsch Marie!", "tokens": ["Autsch", "M\u00e4d\u00b7chen\u00b7tu\u00b7gend", "!", "Autsch", "Ma\u00b7rie", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "O kehre um! Jetzt oder nie!", "tokens": ["O", "keh\u00b7re", "um", "!", "Jetzt", "o\u00b7der", "nie", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKVZ", "$.", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "Sie bleibt und spricht der Sitte Hohn.", "tokens": ["Sie", "bleibt", "und", "spricht", "der", "Sit\u00b7te", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr guter Engel ist entflohn,", "tokens": ["Ihr", "gu\u00b7ter", "En\u00b7gel", "ist", "ent\u00b7flohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nun entwickelt sich im Saal", "tokens": ["Und", "nun", "ent\u00b7wi\u00b7ckelt", "sich", "im", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das wohlbekannte Bacchanal.", "tokens": ["Das", "wohl\u00b7be\u00b7kann\u00b7te", "Bac\u00b7cha\u00b7nal", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Es steigern sich bei jeder Tour", "tokens": ["Es", "stei\u00b7gern", "sich", "bei", "je\u00b7der", "Tour"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die wilden Triebe der Natur;", "tokens": ["Die", "wil\u00b7den", "Trie\u00b7be", "der", "Na\u00b7tur", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es fliegt das Bein, es fliegt der Rock,", "tokens": ["Es", "fliegt", "das", "Bein", ",", "es", "fliegt", "der", "Rock", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein jeder J\u00fcngling wird ein Bock.", "tokens": ["Ein", "je\u00b7der", "J\u00fcng\u00b7ling", "wird", "ein", "Bock", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VAFIN", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Beim Tanze, da gilt keine Kunst.", "tokens": ["Beim", "Tan\u00b7ze", ",", "da", "gilt", "kei\u00b7ne", "Kunst", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADV", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Man dreht sich nur in toller Brunst,", "tokens": ["Man", "dreht", "sich", "nur", "in", "tol\u00b7ler", "Brunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PRF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man jauchzt besessen, schreit und stampft,", "tokens": ["Man", "jauchzt", "be\u00b7ses\u00b7sen", ",", "schreit", "und", "stampft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "VVPP", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Man lacht und br\u00fcllt und schwitzt und dampft.", "tokens": ["Man", "lacht", "und", "br\u00fcllt", "und", "schwitzt", "und", "dampft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Du s\u00fc\u00dfe Unschuld, lebe wohl!", "tokens": ["Du", "s\u00fc\u00b7\u00dfe", "Un\u00b7schuld", ",", "le\u00b7be", "wohl", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das andre macht der Alkohol.", "tokens": ["Das", "and\u00b7re", "macht", "der", "Al\u00b7ko\u00b7hol", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du hast's erreicht, mein Konstantin!", "tokens": ["Du", "hast's", "er\u00b7reicht", ",", "mein", "Kons\u00b7tan\u00b7tin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie ist verloren. Nimm sie hin!", "tokens": ["Sie", "ist", "ver\u00b7lo\u00b7ren", ".", "Nimm", "sie", "hin", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "NE", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "Und bei dem letzten Fl\u00f6tenpfiff", "tokens": ["Und", "bei", "dem", "letz\u00b7ten", "Fl\u00f6\u00b7ten\u00b7pfiff"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erlosch ihr letzter Schambegriff,", "tokens": ["Er\u00b7losch", "ihr", "letz\u00b7ter", "Scham\u00b7be\u00b7griff", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie duldet jeden H\u00e4ndedruck,", "tokens": ["Sie", "dul\u00b7det", "je\u00b7den", "H\u00e4n\u00b7de\u00b7druck", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verzichtet auf den Tugendschmuck.", "tokens": ["Ver\u00b7zich\u00b7tet", "auf", "den", "Tu\u00b7gend\u00b7schmuck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "Und das Programm entwickelt sich,", "tokens": ["Und", "das", "Pro\u00b7gramm", "ent\u00b7wi\u00b7ckelt", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Verliebt, begehrlich, liederlich,", "tokens": ["Ver\u00b7liebt", ",", "be\u00b7gehr\u00b7lich", ",", "lie\u00b7der\u00b7lich", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie i\u00dft noch Wei\u00dfw\u00fcrscht, geht zu ihm.", "tokens": ["Sie", "i\u00dft", "noch", "Wei\u00df\u00b7w\u00fcrscht", ",", "geht", "zu", "ihm", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun sind ja wieder zwei intim.", "tokens": ["Nun", "sind", "ja", "wie\u00b7der", "zwei", "in\u00b7tim", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "CARD", "APPRART", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Maria ist nach dieser Nacht", "tokens": ["Ma\u00b7ria", "ist", "nach", "die\u00b7ser", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In seinem Atelier erwacht,", "tokens": ["In", "sei\u00b7nem", "A\u00b7te\u00b7lier", "er\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und von derselben Stunde an", "tokens": ["Und", "von", "der\u00b7sel\u00b7ben", "Stun\u00b7de", "an"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geriet sie auf die schiefe Bahn.", "tokens": ["Ge\u00b7riet", "sie", "auf", "die", "schie\u00b7fe", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Sie sch\u00e4kert jetzt mit jedem Gast", "tokens": ["Sie", "sch\u00e4\u00b7kert", "jetzt", "mit", "je\u00b7dem", "Gast"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und freut sich mehr als jede fast,", "tokens": ["Und", "freut", "sich", "mehr", "als", "je\u00b7de", "fast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PIAT", "KOKOM", "PIAT", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn so ein ordin\u00e4rer Greis", "tokens": ["Wenn", "so", "ein", "or\u00b7di\u00b7n\u00e4\u00b7rer", "Greis"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Am Stammtisch was Gemeines wei\u00df.", "tokens": ["Am", "Stamm\u00b7tisch", "was", "Ge\u00b7mei\u00b7nes", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PWS", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}