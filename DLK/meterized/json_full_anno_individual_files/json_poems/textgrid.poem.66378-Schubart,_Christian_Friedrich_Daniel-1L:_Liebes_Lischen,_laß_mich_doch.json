{"textgrid.poem.66378": {"metadata": {"author": {"name": "Schubart, Christian Friedrich Daniel", "birth": "N.A.", "death": "N.A."}, "title": "1L: Liebes Lischen, la\u00df mich doch", "genre": "verse", "period": "N.A.", "pub_year": 1774, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Liebes Lischen, la\u00df mich doch", "tokens": ["Lie\u00b7bes", "Li\u00b7schen", ",", "la\u00df", "mich", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur ein wenig klagen!", "tokens": ["Nur", "ein", "we\u00b7nig", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eile nicht, ich habe noch", "tokens": ["Ei\u00b7le", "nicht", ",", "ich", "ha\u00b7be", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vieles dir zu sagen.", "tokens": ["Vie\u00b7les", "dir", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Seit der Ernte bin ich dir", "tokens": ["Seit", "der", "Ern\u00b7te", "bin", "ich", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4glich nachgeschlichen;", "tokens": ["T\u00e4g\u00b7lich", "nach\u00b7ge\u00b7schli\u00b7chen", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber listig bist du mir", "tokens": ["A\u00b7ber", "lis\u00b7tig", "bist", "du", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer ausgewichen.", "tokens": ["Im\u00b7mer", "aus\u00b7ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Sieh, ich bin dir gut, und du", "tokens": ["Sieh", ",", "ich", "bin", "dir", "gut", ",", "und", "du"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$,", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4ltst mich immer schlechter;", "tokens": ["H\u00e4ltst", "mich", "im\u00b7mer", "schlech\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ja, ich werde noch darzu", "tokens": ["Ja", ",", "ich", "wer\u00b7de", "noch", "dar\u00b7zu"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Allen zum Gel\u00e4chter.", "tokens": ["Al\u00b7len", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Wei\u00dft du noch? Am Erntetanz", "tokens": ["Wei\u00dft", "du", "noch", "?", "Am", "Ern\u00b7te\u00b7tanz"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprangest du so munter;", "tokens": ["Spran\u00b7gest", "du", "so", "mun\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und da fiel der Blumenkranz", "tokens": ["Und", "da", "fiel", "der", "Blu\u00b7men\u00b7kranz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Dir vom Kopf herunter.", "tokens": ["Dir", "vom", "Kopf", "her\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Husch! da griff ich eilend zu,", "tokens": ["Husch", "!", "da", "griff", "ich", "ei\u00b7lend", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dachte voll Entz\u00fccken,", "tokens": ["Dach\u00b7te", "voll", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fcr die M\u00fche w\u00fcrdest du", "tokens": ["F\u00fcr", "die", "M\u00fc\u00b7he", "w\u00fcr\u00b7dest", "du"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dankbarlich mir nicken.", "tokens": ["Dank\u00b7bar\u00b7lich", "mir", "ni\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.6": {"line.1": {"text": "Losgegangen war ein Band;", "tokens": ["Los\u00b7ge\u00b7gan\u00b7gen", "war", "ein", "Band", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ergriff ich sachte,", "tokens": ["Das", "er\u00b7griff", "ich", "sach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Bis ich's langsam mit der Hand", "tokens": ["Bis", "ich's", "lang\u00b7sam", "mit", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die Seite brachte.", "tokens": ["Auf", "die", "Sei\u00b7te", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Holla! dacht' ich, meinem Hut", "tokens": ["Hol\u00b7la", "!", "dacht'", "ich", ",", "mei\u00b7nem", "Hut"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Soll es trefflich stehen;", "tokens": ["Soll", "es", "treff\u00b7lich", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch du hattest gar zu gut,", "tokens": ["Doch", "du", "hat\u00b7test", "gar", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich that, gesehen.", "tokens": ["Was", "ich", "that", ",", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Das ist sch\u00f6n! so fingst du an,", "tokens": ["Das", "ist", "sch\u00f6n", "!", "so", "fingst", "du", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Willst du mich bestehlen?", "tokens": ["Willst", "du", "mich", "be\u00b7steh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seht den feinen Dieb! Er kann", "tokens": ["Seht", "den", "fei\u00b7nen", "Dieb", "!", "Er", "kann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seinen Raub nicht hehlen.", "tokens": ["Sei\u00b7nen", "Raub", "nicht", "heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Feuerroth ward mein Gesicht;", "tokens": ["Feu\u00b7er\u00b7roth", "ward", "mein", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie vom Blitz geschlagen", "tokens": ["Wie", "vom", "Blitz", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stand ich da, und konnte nicht", "tokens": ["Stand", "ich", "da", ",", "und", "konn\u00b7te", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KON", "VMFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Silbe sagen.", "tokens": ["Ei\u00b7ne", "Sil\u00b7be", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Alle Bauern stellten sich", "tokens": ["Al\u00b7le", "Bau\u00b7ern", "stell\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Um mich her, und machten", "tokens": ["Um", "mich", "her", ",", "und", "mach\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUI", "PRF", "APZR", "$,", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mich zu Schanden; nannten mich", "tokens": ["Mich", "zu", "Schan\u00b7den", ";", "nann\u00b7ten", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "APPR", "NN", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Dieb \u2013 und lachten.", "tokens": ["Ei\u00b7nen", "Dieb", "\u2013", "und", "lach\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Lischen, sieh, das war nicht fein,", "tokens": ["Li\u00b7schen", ",", "sieh", ",", "das", "war", "nicht", "fein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner so zu lachen,", "tokens": ["Mei\u00b7ner", "so", "zu", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mich vor dem ganzen Reih'n", "tokens": ["Und", "mich", "vor", "dem", "gan\u00b7zen", "Reih'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zum Gesp\u00f6tt zu machen.", "tokens": ["Zum", "Ge\u00b7sp\u00f6tt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Sage, hast du denn bei dir", "tokens": ["Sa\u00b7ge", ",", "hast", "du", "denn", "bei", "dir"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Solche Lust empfunden,", "tokens": ["Sol\u00b7che", "Lust", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als die hellen Z\u00e4hren mir", "tokens": ["Als", "die", "hel\u00b7len", "Z\u00e4h\u00b7ren", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Augen stunden?", "tokens": ["In", "den", "Au\u00b7gen", "stun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Sieh, ich bin dir doch so gut,", "tokens": ["Sieh", ",", "ich", "bin", "dir", "doch", "so", "gut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sei mir's auch ein bischen!", "tokens": ["Sei", "mir's", "auch", "ein", "bi\u00b7schen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mehr noch, als mein eigen Blut,", "tokens": ["Mehr", "noch", ",", "als", "mein", "ei\u00b7gen", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lieb' ich dich, mein Lischen.", "tokens": ["Lieb'", "ich", "dich", ",", "mein", "Li\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Liebes Lischen, la\u00df mich doch", "tokens": ["Lie\u00b7bes", "Li\u00b7schen", ",", "la\u00df", "mich", "doch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur ein wenig klagen!", "tokens": ["Nur", "ein", "we\u00b7nig", "kla\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "PIS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eile nicht, ich habe noch", "tokens": ["Ei\u00b7le", "nicht", ",", "ich", "ha\u00b7be", "noch"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PTKNEG", "$,", "PPER", "VAFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Vieles dir zu sagen.", "tokens": ["Vie\u00b7les", "dir", "zu", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.15": {"line.1": {"text": "Seit der Ernte bin ich dir", "tokens": ["Seit", "der", "Ern\u00b7te", "bin", "ich", "dir"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "T\u00e4glich nachgeschlichen;", "tokens": ["T\u00e4g\u00b7lich", "nach\u00b7ge\u00b7schli\u00b7chen", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVIZU", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Aber listig bist du mir", "tokens": ["A\u00b7ber", "lis\u00b7tig", "bist", "du", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Immer ausgewichen.", "tokens": ["Im\u00b7mer", "aus\u00b7ge\u00b7wi\u00b7chen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Sieh, ich bin dir gut, und du", "tokens": ["Sieh", ",", "ich", "bin", "dir", "gut", ",", "und", "du"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADJD", "$,", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4ltst mich immer schlechter;", "tokens": ["H\u00e4ltst", "mich", "im\u00b7mer", "schlech\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ja, ich werde noch darzu", "tokens": ["Ja", ",", "ich", "wer\u00b7de", "noch", "dar\u00b7zu"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Allen zum Gel\u00e4chter.", "tokens": ["Al\u00b7len", "zum", "Ge\u00b7l\u00e4ch\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Wei\u00dft du noch? Am Erntetanz", "tokens": ["Wei\u00dft", "du", "noch", "?", "Am", "Ern\u00b7te\u00b7tanz"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$.", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sprangest du so munter;", "tokens": ["Spran\u00b7gest", "du", "so", "mun\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und da fiel der Blumenkranz", "tokens": ["Und", "da", "fiel", "der", "Blu\u00b7men\u00b7kranz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "Dir vom Kopf herunter.", "tokens": ["Dir", "vom", "Kopf", "her\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPRART", "NN", "PTKVZ", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Husch! da griff ich eilend zu,", "tokens": ["Husch", "!", "da", "griff", "ich", "ei\u00b7lend", "zu", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Dachte voll Entz\u00fccken,", "tokens": ["Dach\u00b7te", "voll", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "F\u00fcr die M\u00fche w\u00fcrdest du", "tokens": ["F\u00fcr", "die", "M\u00fc\u00b7he", "w\u00fcr\u00b7dest", "du"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Dankbarlich mir nicken.", "tokens": ["Dank\u00b7bar\u00b7lich", "mir", "ni\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.19": {"line.1": {"text": "Losgegangen war ein Band;", "tokens": ["Los\u00b7ge\u00b7gan\u00b7gen", "war", "ein", "Band", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Das ergriff ich sachte,", "tokens": ["Das", "er\u00b7griff", "ich", "sach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Bis ich's langsam mit der Hand", "tokens": ["Bis", "ich's", "lang\u00b7sam", "mit", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "ADJD", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auf die Seite brachte.", "tokens": ["Auf", "die", "Sei\u00b7te", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Holla! dacht' ich, meinem Hut", "tokens": ["Hol\u00b7la", "!", "dacht'", "ich", ",", "mei\u00b7nem", "Hut"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Soll es trefflich stehen;", "tokens": ["Soll", "es", "treff\u00b7lich", "ste\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Doch du hattest gar zu gut,", "tokens": ["Doch", "du", "hat\u00b7test", "gar", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was ich that, gesehen.", "tokens": ["Was", "ich", "that", ",", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Das ist sch\u00f6n! so fingst du an,", "tokens": ["Das", "ist", "sch\u00f6n", "!", "so", "fingst", "du", "an", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Willst du mich bestehlen?", "tokens": ["Willst", "du", "mich", "be\u00b7steh\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seht den feinen Dieb! Er kann", "tokens": ["Seht", "den", "fei\u00b7nen", "Dieb", "!", "Er", "kann"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VMFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Seinen Raub nicht hehlen.", "tokens": ["Sei\u00b7nen", "Raub", "nicht", "heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Feuerroth ward mein Gesicht;", "tokens": ["Feu\u00b7er\u00b7roth", "ward", "mein", "Ge\u00b7sicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie vom Blitz geschlagen", "tokens": ["Wie", "vom", "Blitz", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Stand ich da, und konnte nicht", "tokens": ["Stand", "ich", "da", ",", "und", "konn\u00b7te", "nicht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KON", "VMFIN", "PTKNEG"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine Silbe sagen.", "tokens": ["Ei\u00b7ne", "Sil\u00b7be", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Alle Bauern stellten sich", "tokens": ["Al\u00b7le", "Bau\u00b7ern", "stell\u00b7ten", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PRF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Um mich her, und machten", "tokens": ["Um", "mich", "her", ",", "und", "mach\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KOUI", "PRF", "APZR", "$,", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mich zu Schanden; nannten mich", "tokens": ["Mich", "zu", "Schan\u00b7den", ";", "nann\u00b7ten", "mich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "APPR", "NN", "$.", "VVFIN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Dieb \u2013 und lachten.", "tokens": ["Ei\u00b7nen", "Dieb", "\u2013", "und", "lach\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "KON", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Lischen, sieh, das war nicht fein,", "tokens": ["Li\u00b7schen", ",", "sieh", ",", "das", "war", "nicht", "fein", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Meiner so zu lachen,", "tokens": ["Mei\u00b7ner", "so", "zu", "la\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und mich vor dem ganzen Reih'n", "tokens": ["Und", "mich", "vor", "dem", "gan\u00b7zen", "Reih'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Zum Gesp\u00f6tt zu machen.", "tokens": ["Zum", "Ge\u00b7sp\u00f6tt", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Sage, hast du denn bei dir", "tokens": ["Sa\u00b7ge", ",", "hast", "du", "denn", "bei", "dir"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "VAFIN", "PPER", "ADV", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Solche Lust empfunden,", "tokens": ["Sol\u00b7che", "Lust", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Als die hellen Z\u00e4hren mir", "tokens": ["Als", "die", "hel\u00b7len", "Z\u00e4h\u00b7ren", "mir"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "In den Augen stunden?", "tokens": ["In", "den", "Au\u00b7gen", "stun\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "Sieh, ich bin dir doch so gut,", "tokens": ["Sieh", ",", "ich", "bin", "dir", "doch", "so", "gut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Sei mir's auch ein bischen!", "tokens": ["Sei", "mir's", "auch", "ein", "bi\u00b7schen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "ADV", "ART", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Mehr noch, als mein eigen Blut,", "tokens": ["Mehr", "noch", ",", "als", "mein", "ei\u00b7gen", "Blut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Lieb' ich dich, mein Lischen.", "tokens": ["Lieb'", "ich", "dich", ",", "mein", "Li\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}