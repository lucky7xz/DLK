{"textgrid.poem.67024": {"metadata": {"author": {"name": "Henckell, Karl", "birth": "N.A.", "death": "N.A."}, "title": "L\u00e4uterung", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Manches war ein gro\u00dfer Wahn \u2013", "tokens": ["Man\u00b7ches", "war", "ein", "gro\u00b7\u00dfer", "Wahn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist die Glut darum vertan?", "tokens": ["Ist", "die", "Glut", "da\u00b7rum", "ver\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PAV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat es dich nur selbst gereinigt,", "tokens": ["Hat", "es", "dich", "nur", "selbst", "ge\u00b7rei\u00b7nigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sei das Opfer nicht gesteinigt!", "tokens": ["Sei", "das", "Op\u00b7fer", "nicht", "ge\u00b7stei\u00b7nigt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Manches war ein gro\u00dfer Wahn \u2013", "tokens": ["Man\u00b7ches", "war", "ein", "gro\u00b7\u00dfer", "Wahn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist die Glut darum vertan?", "tokens": ["Ist", "die", "Glut", "da\u00b7rum", "ver\u00b7tan", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PAV", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hat es dich nur selbst gereinigt,", "tokens": ["Hat", "es", "dich", "nur", "selbst", "ge\u00b7rei\u00b7nigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "ADV", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sei das Opfer nicht gesteinigt!", "tokens": ["Sei", "das", "Op\u00b7fer", "nicht", "ge\u00b7stei\u00b7nigt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}