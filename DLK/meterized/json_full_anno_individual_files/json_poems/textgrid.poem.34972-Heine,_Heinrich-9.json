{"textgrid.poem.34972": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "9", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Gestalt der wahren Sphinx", "tokens": ["Die", "Ge\u00b7stalt", "der", "wah\u00b7ren", "Sphinx"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weicht nicht ab von der des Weibes;", "tokens": ["Weicht", "nicht", "ab", "von", "der", "des", "Wei\u00b7bes", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKVZ", "APPR", "ART", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Faselei ist jener Zusatz", "tokens": ["Fa\u00b7se\u00b7lei", "ist", "je\u00b7ner", "Zu\u00b7satz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des betatzten L\u00f6wenleibes.", "tokens": ["Des", "be\u00b7tatz\u00b7ten", "L\u00f6\u00b7wen\u00b7lei\u00b7bes", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Todesdunkel ist das R\u00e4tsel", "tokens": ["To\u00b7des\u00b7dun\u00b7kel", "ist", "das", "R\u00e4t\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser wahren Sphinx. Es hatte", "tokens": ["Die\u00b7ser", "wah\u00b7ren", "Sphinx", ".", "Es", "hat\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "$.", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kein so schweres zu erraten", "tokens": ["Kein", "so", "schwe\u00b7res", "zu", "er\u00b7ra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADV", "ADJA", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Frau Jokastens Sohn und Gatte.", "tokens": ["Frau", "Jo\u00b7kas\u00b7tens", "Sohn", "und", "Gat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch zum Gl\u00fccke kennt sein eignes", "tokens": ["Doch", "zum", "Gl\u00fc\u00b7cke", "kennt", "sein", "eig\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "R\u00e4tsel nicht das Frauenzimmer;", "tokens": ["R\u00e4t\u00b7sel", "nicht", "das", "Frau\u00b7en\u00b7zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spr\u00e4ch es aus das L\u00f6sungswort,", "tokens": ["Spr\u00e4ch", "es", "aus", "das", "L\u00f6\u00b7sungs\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fiele diese Welt in Tr\u00fcmmer.", "tokens": ["Fie\u00b7le", "die\u00b7se", "Welt", "in", "Tr\u00fcm\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Gestalt der wahren Sphinx", "tokens": ["Die", "Ge\u00b7stalt", "der", "wah\u00b7ren", "Sphinx"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weicht nicht ab von der des Weibes;", "tokens": ["Weicht", "nicht", "ab", "von", "der", "des", "Wei\u00b7bes", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKVZ", "APPR", "ART", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Faselei ist jener Zusatz", "tokens": ["Fa\u00b7se\u00b7lei", "ist", "je\u00b7ner", "Zu\u00b7satz"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des betatzten L\u00f6wenleibes.", "tokens": ["Des", "be\u00b7tatz\u00b7ten", "L\u00f6\u00b7wen\u00b7lei\u00b7bes", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Todesdunkel ist das R\u00e4tsel", "tokens": ["To\u00b7des\u00b7dun\u00b7kel", "ist", "das", "R\u00e4t\u00b7sel"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dieser wahren Sphinx. Es hatte", "tokens": ["Die\u00b7ser", "wah\u00b7ren", "Sphinx", ".", "Es", "hat\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "$.", "PPER", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Kein so schweres zu erraten", "tokens": ["Kein", "so", "schwe\u00b7res", "zu", "er\u00b7ra\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADV", "ADJA", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Frau Jokastens Sohn und Gatte.", "tokens": ["Frau", "Jo\u00b7kas\u00b7tens", "Sohn", "und", "Gat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch zum Gl\u00fccke kennt sein eignes", "tokens": ["Doch", "zum", "Gl\u00fc\u00b7cke", "kennt", "sein", "eig\u00b7nes"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPOSAT", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "R\u00e4tsel nicht das Frauenzimmer;", "tokens": ["R\u00e4t\u00b7sel", "nicht", "das", "Frau\u00b7en\u00b7zim\u00b7mer", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Spr\u00e4ch es aus das L\u00f6sungswort,", "tokens": ["Spr\u00e4ch", "es", "aus", "das", "L\u00f6\u00b7sungs\u00b7wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fiele diese Welt in Tr\u00fcmmer.", "tokens": ["Fie\u00b7le", "die\u00b7se", "Welt", "in", "Tr\u00fcm\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}