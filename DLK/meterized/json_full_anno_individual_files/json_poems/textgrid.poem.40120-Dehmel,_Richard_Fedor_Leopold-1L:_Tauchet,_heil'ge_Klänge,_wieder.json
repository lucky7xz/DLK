{"textgrid.poem.40120": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "1L: Tauchet, heil'ge Kl\u00e4nge, wieder", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tauchet, heil'ge Kl\u00e4nge, wieder", "tokens": ["Tau\u00b7chet", ",", "heil'\u00b7ge", "Kl\u00e4n\u00b7ge", ",", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ganz in meinen Glauben mich!", "tokens": ["ganz", "in", "mei\u00b7nen", "Glau\u00b7ben", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Quellet, quellt, ihr alten Lieder:", "tokens": ["Quel\u00b7let", ",", "quellt", ",", "ihr", "al\u00b7ten", "Lie\u00b7der", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fcllet ganz mit Reinheit mich!", "tokens": ["f\u00fcl\u00b7let", "ganz", "mit", "Rein\u00b7heit", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "da\u00df ich in die Kniee fallen,", "tokens": ["da\u00df", "ich", "in", "die", "Kni\u00b7ee", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Mal wieder beten kann,", "tokens": ["Ein", "Mal", "wie\u00b7der", "be\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein Mal wie ein Kind noch lallen", "tokens": ["Ein", "Mal", "wie", "ein", "Kind", "noch", "lal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und die H\u00e4nde falten kann!", "tokens": ["und", "die", "H\u00e4n\u00b7de", "fal\u00b7ten", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Denn ich f\u00fchl's: die Liebe ", "tokens": ["Denn", "ich", "f\u00fchl's", ":", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "die in Ihm geboren worden,", "tokens": ["die", "in", "Ihm", "ge\u00b7bo\u00b7ren", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVPP", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ob sie gleich in R\u00e4tseln schwebet,", "tokens": ["ob", "sie", "gleich", "in", "R\u00e4t\u00b7seln", "schwe\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ob gleich Er gekreuzigt worden;", "tokens": ["ob", "gleich", "Er", "ge\u00b7kreu\u00b7zigt", "wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVPP", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "denn ich sehe fromm sie werden \u2013", "tokens": ["denn", "ich", "se\u00b7he", "fromm", "sie", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PPER", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "heute, Ewig fromm \u2013 die Menschen,", "tokens": ["heu\u00b7te", ",", "E\u00b7wig", "fromm", "\u2013", "die", "Men\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "$(", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn es klinget: Fried' auf Erden", "tokens": ["wenn", "es", "klin\u00b7get", ":", "Fried'", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ein ", "tokens": ["und", "ein"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "-+", "measure": "iambic.single"}}, "stanza.5": {"line.1": {"text": "Tauchet, heil'ge Kl\u00e4nge, wieder", "tokens": ["Tau\u00b7chet", ",", "heil'\u00b7ge", "Kl\u00e4n\u00b7ge", ",", "wie\u00b7der"], "token_info": ["word", "punct", "word", "word", "punct", "word"], "pos": ["VVFIN", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ganz in meinen Glauben mich!", "tokens": ["ganz", "in", "mei\u00b7nen", "Glau\u00b7ben", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Quellet, quellt, ihr alten Lieder:", "tokens": ["Quel\u00b7let", ",", "quellt", ",", "ihr", "al\u00b7ten", "Lie\u00b7der", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "f\u00fcllet ganz mit Reinheit mich!", "tokens": ["f\u00fcl\u00b7let", "ganz", "mit", "Rein\u00b7heit", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "da\u00df ich in die Kniee fallen,", "tokens": ["da\u00df", "ich", "in", "die", "Kni\u00b7ee", "fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ein Mal wieder beten kann,", "tokens": ["Ein", "Mal", "wie\u00b7der", "be\u00b7ten", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ein Mal wie ein Kind noch lallen", "tokens": ["Ein", "Mal", "wie", "ein", "Kind", "noch", "lal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "und die H\u00e4nde falten kann!", "tokens": ["und", "die", "H\u00e4n\u00b7de", "fal\u00b7ten", "kann", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Denn ich f\u00fchl's: die Liebe ", "tokens": ["Denn", "ich", "f\u00fchl's", ":", "die", "Lie\u00b7be"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$.", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "die in Ihm geboren worden,", "tokens": ["die", "in", "Ihm", "ge\u00b7bo\u00b7ren", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VVPP", "VAPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ob sie gleich in R\u00e4tseln schwebet,", "tokens": ["ob", "sie", "gleich", "in", "R\u00e4t\u00b7seln", "schwe\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "ob gleich Er gekreuzigt worden;", "tokens": ["ob", "gleich", "Er", "ge\u00b7kreu\u00b7zigt", "wor\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "VVPP", "VAPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "denn ich sehe fromm sie werden \u2013", "tokens": ["denn", "ich", "se\u00b7he", "fromm", "sie", "wer\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PPER", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "heute, Ewig fromm \u2013 die Menschen,", "tokens": ["heu\u00b7te", ",", "E\u00b7wig", "fromm", "\u2013", "die", "Men\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "ADJD", "$(", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wenn es klinget: Fried' auf Erden", "tokens": ["wenn", "es", "klin\u00b7get", ":", "Fried'", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$.", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ein ", "tokens": ["und", "ein"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "-+", "measure": "iambic.single"}}}}}