{"textgrid.poem.41471": {"metadata": {"author": {"name": "Hagedorn, Friedrich von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du b\u00fc\u00dfest, unverdient, der V\u00e4ter Missethaten.", "genre": "verse", "period": "N.A.", "pub_year": 1731, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du b\u00fc\u00dfest, unverdient, der V\u00e4ter Missethaten.", "tokens": ["Du", "b\u00fc\u00b7\u00dfest", ",", "un\u00b7ver\u00b7di\u00b7ent", ",", "der", "V\u00e4\u00b7ter", "Mis\u00b7se\u00b7tha\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bis du, o sichres Rom, die Tempel wieder baust,", "tokens": ["Bis", "du", ",", "o", "sich\u00b7res", "Rom", ",", "die", "Tem\u00b7pel", "wie\u00b7der", "baust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "FM", "NE", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der G\u00f6tter Wohnungen, die in Verfall gerathen,", "tokens": ["Der", "G\u00f6t\u00b7ter", "Woh\u00b7nun\u00b7gen", ",", "die", "in", "Ver\u00b7fall", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf deren Bildern du noch Rauch und Moder schaust.", "tokens": ["Auf", "de\u00b7ren", "Bil\u00b7dern", "du", "noch", "Rauch", "und", "Mo\u00b7der", "schaust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Durch Ehrfurcht gegen sie hast du das Heft erhalten.", "tokens": ["Durch", "Ehr\u00b7furcht", "ge\u00b7gen", "sie", "hast", "du", "das", "Heft", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie gr\u00fcndete den Flor, der dir den Vorzug gibt;", "tokens": ["Sie", "gr\u00fcn\u00b7de\u00b7te", "den", "Flor", ",", "der", "dir", "den", "Vor\u00b7zug", "gibt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch sahn die G\u00f6tter kaum den ersten Dank erkalten,", "tokens": ["Doch", "sahn", "die", "G\u00f6t\u00b7ter", "kaum", "den", "ers\u00b7ten", "Dank", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ward Hesperien durch \u00f6ftre Noth betr\u00fcbt.", "tokens": ["So", "ward", "Hes\u00b7pe\u00b7ri\u00b7en", "durch", "\u00f6ft\u00b7re", "Noth", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Wir kriegten ohne sie, uneingedenk der Zeichen:", "tokens": ["Wir", "krieg\u00b7ten", "oh\u00b7ne", "sie", ",", "un\u00b7ein\u00b7ge\u00b7denk", "der", "Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schon zweimal b\u00e4ndigt uns Monaeses und Pacor.", "tokens": ["Schon", "zwei\u00b7mal", "b\u00e4n\u00b7digt", "uns", "Mo\u00b7nae\u00b7ses", "und", "Pa\u00b7cor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch gr\u00f6\u00dfrer Ketten Gold, den Raub von unsern Leichen,", "tokens": ["Durch", "gr\u00f6\u00df\u00b7rer", "Ket\u00b7ten", "Gold", ",", "den", "Raub", "von", "un\u00b7sern", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hebt sich der Parther Hals weit stolzer, als zuvor.", "tokens": ["Hebt", "sich", "der", "Par\u00b7ther", "Hals", "weit", "stol\u00b7zer", ",", "als", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "ADJD", "ADJA", "$,", "KOUS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Bald h\u00e4tt' Aegyptens Volk, das mit der Seemacht schreckte,", "tokens": ["Bald", "h\u00e4tt'", "A\u00b7e\u00b7gyp\u00b7tens", "Volk", ",", "das", "mit", "der", "See\u00b7macht", "schreck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Und bald der Dacier, der frech den Wurfpfeil schwenkt,", "tokens": ["Und", "bald", "der", "Da\u00b7cier", ",", "der", "frech", "den", "Wurf\u00b7pfeil", "schwenkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als alles schw\u00fcrig war und voller Aufruhr steckte,", "tokens": ["Als", "al\u00b7les", "schw\u00fc\u00b7rig", "war", "und", "vol\u00b7ler", "Auf\u00b7ruhr", "steck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Mauern unsrer Stadt in \u00f6den Staub versenkt.", "tokens": ["Die", "Mau\u00b7ern", "uns\u00b7rer", "Stadt", "in", "\u00f6\u00b7den", "Staub", "ver\u00b7senkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Der Zeiten \u00f6ftre Brut, der Frevel und die Schande,", "tokens": ["Der", "Zei\u00b7ten", "\u00f6ft\u00b7re", "Brut", ",", "der", "Fre\u00b7vel", "und", "die", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beschmitzten anfangs bald die Ehen, Haus und Stamm;", "tokens": ["Be\u00b7schmitz\u00b7ten", "an\u00b7fangs", "bald", "die", "E\u00b7hen", ",", "Haus", "und", "Stamm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und diese Quelle war's, aus der dem Vaterlande,", "tokens": ["Und", "die\u00b7se", "Quel\u00b7le", "wa\u00b7r's", ",", "aus", "der", "dem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "$,", "APPR", "ART", "ART", "NN", "$,"], "meter": "---+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dem Volke des Quirins, der Strom der Strafen kam.", "tokens": ["Dem", "Vol\u00b7ke", "des", "Qui\u00b7rins", ",", "der", "Strom", "der", "Stra\u00b7fen", "kam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.6": {"line.1": {"text": "Ein reifes M\u00e4dchen lernt der geilsten Griechen T\u00e4nze,", "tokens": ["Ein", "rei\u00b7fes", "M\u00e4d\u00b7chen", "lernt", "der", "geils\u00b7ten", "Grie\u00b7chen", "T\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Stellung Wissenschaft, der Glieder Fertigkeit,", "tokens": ["Der", "Stel\u00b7lung", "Wis\u00b7sen\u00b7schaft", ",", "der", "Glie\u00b7der", "Fer\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sinnt, voll Ungeduld, in ihrem ersten Lenze,", "tokens": ["Und", "sinnt", ",", "voll", "Un\u00b7ge\u00b7duld", ",", "in", "ih\u00b7rem", "ers\u00b7ten", "Len\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADJD", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schon auf ein Meisterst\u00fcck der fr\u00fchen L\u00fcsternheit.", "tokens": ["Schon", "auf", "ein", "Meis\u00b7ter\u00b7st\u00fcck", "der", "fr\u00fc\u00b7hen", "L\u00fcs\u00b7tern\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Sie freit und wagt beim Schmaus vom Mann sich wegzustehlen.", "tokens": ["Sie", "freit", "und", "wagt", "beim", "Schmaus", "vom", "Mann", "sich", "weg\u00b7zu\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "VVFIN", "APPRART", "NN", "APPRART", "NN", "PRF", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sucht j\u00fcngre Buhler auf, mit denen sie entschleicht,", "tokens": ["Sucht", "j\u00fcng\u00b7re", "Buh\u00b7ler", "auf", ",", "mit", "de\u00b7nen", "sie", "ent\u00b7schleicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ihnen, schnell und frech und ohne langes W\u00e4hlen,", "tokens": ["Und", "ih\u00b7nen", ",", "schnell", "und", "frech", "und", "oh\u00b7ne", "lan\u00b7ges", "W\u00e4h\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJD", "KON", "ADJD", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann sie das Licht entfernt, verbotne K\u00fcsse reicht.", "tokens": ["Wann", "sie", "das", "Licht", "ent\u00b7fernt", ",", "ver\u00b7bot\u00b7ne", "K\u00fcs\u00b7se", "reicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVPP", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Doch nein! Sie hei\u00dft den Mann, der Schande Hehler, trinken,", "tokens": ["Doch", "nein", "!", "Sie", "hei\u00dft", "den", "Mann", ",", "der", "Schan\u00b7de", "Heh\u00b7ler", ",", "trin\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Steht auf und schmieget sich an eines Fremden Brust;", "tokens": ["Steht", "auf", "und", "schmie\u00b7get", "sich", "an", "ei\u00b7nes", "Frem\u00b7den", "Brust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es mag ein M\u00e4kler ihr, es mag ein Schiffherr winken,", "tokens": ["Es", "mag", "ein", "M\u00e4k\u00b7ler", "ihr", ",", "es", "mag", "ein", "Schiff\u00b7herr", "win\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Meistbietenden f\u00fcr manche schn\u00f6de Lust.", "tokens": ["Als", "die", "Meist\u00b7bie\u00b7ten\u00b7den", "f\u00fcr", "man\u00b7che", "schn\u00f6\u00b7de", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Roms tapfre Jugend ist von solchen nicht entsprungen;", "tokens": ["Roms", "tapf\u00b7re", "Ju\u00b7gend", "ist", "von", "sol\u00b7chen", "nicht", "ent\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAFIN", "APPR", "PIAT", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nie f\u00e4rbt' ein Meer durch sie der Poener Blut und Fall.", "tokens": ["Nie", "f\u00e4rbt'", "ein", "Meer", "durch", "sie", "der", "Poe\u00b7ner", "Blut", "und", "Fall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch S\u00f6hne bess'rer Art ward Pyrrhus Heer bezwungen,", "tokens": ["Durch", "S\u00f6h\u00b7ne", "bess'\u00b7rer", "Art", "ward", "Pyrr\u00b7hus", "Heer", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "VAFIN", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Held Antiochus, der grimme Hannibal.", "tokens": ["Der", "Held", "An\u00b7tio\u00b7chus", ",", "der", "grim\u00b7me", "Han\u00b7ni\u00b7bal", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Durch r\u00fcstig Bauernvolk, durch manchen Held im Kittel,", "tokens": ["Durch", "r\u00fcs\u00b7tig", "Bau\u00b7ern\u00b7volk", ",", "durch", "man\u00b7chen", "Held", "im", "Kit\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "$,", "APPR", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Der, durch den Feldbau stark, geh\u00e4rtet durch den Pflug,", "tokens": ["Der", ",", "durch", "den", "Feld\u00b7bau", "stark", ",", "ge\u00b7h\u00e4r\u00b7tet", "durch", "den", "Pflug", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "ADJD", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nach scharfer M\u00fctter Sinn, noch emsig Scheit und Kn\u00fcttel", "tokens": ["Nach", "schar\u00b7fer", "M\u00fct\u00b7ter", "Sinn", ",", "noch", "em\u00b7sig", "Scheit", "und", "Kn\u00fct\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ADV", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Schlu\u00df der Arbeit hieb und in die H\u00fctte trug:", "tokens": ["Zum", "Schlu\u00df", "der", "Ar\u00b7beit", "hieb", "und", "in", "die", "H\u00fct\u00b7te", "trug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Bis, wann die Sonne nun den Wagen tiefer lenkte", "tokens": ["Bis", ",", "wann", "die", "Son\u00b7ne", "nun", "den", "Wa\u00b7gen", "tie\u00b7fer", "lenk\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "$,", "PWAV", "ART", "NN", "ADV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und an den Bergen sich der sp\u00e4tste Schatten wies,", "tokens": ["Und", "an", "den", "Ber\u00b7gen", "sich", "der", "sp\u00e4ts\u00b7te", "Schat\u00b7ten", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die s\u00fc\u00dfe Stunde kam, die ihm die Ruhe schenkte", "tokens": ["Die", "s\u00fc\u00b7\u00dfe", "Stun\u00b7de", "kam", ",", "die", "ihm", "die", "Ru\u00b7he", "schenk\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und aus dem schweren Joch die m\u00fcden Rinder lie\u00df.", "tokens": ["Und", "aus", "dem", "schwe\u00b7ren", "Joch", "die", "m\u00fc\u00b7den", "Rin\u00b7der", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Was mindert nicht die Zeit? Verarten wir nicht immer?", "tokens": ["Was", "min\u00b7dert", "nicht", "die", "Zeit", "?", "Ver\u00b7ar\u00b7ten", "wir", "nicht", "im\u00b7mer", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die R\u00f6mer sind nicht mehr was sie gewesen sind:", "tokens": ["Die", "R\u00f6\u00b7mer", "sind", "nicht", "mehr", "was", "sie", "ge\u00b7we\u00b7sen", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "PWS", "PPER", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ahnen waren arg, die V\u00e4ter wurden schlimmer,", "tokens": ["Die", "Ah\u00b7nen", "wa\u00b7ren", "arg", ",", "die", "V\u00e4\u00b7ter", "wur\u00b7den", "schlim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00e4rger, als wir selbst, wird Kind und Kindeskind.", "tokens": ["Und", "\u00e4r\u00b7ger", ",", "als", "wir", "selbst", ",", "wird", "Kind", "und", "Kin\u00b7des\u00b7kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "PPER", "ADV", "$,", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Du b\u00fc\u00dfest, unverdient, der V\u00e4ter Missethaten.", "tokens": ["Du", "b\u00fc\u00b7\u00dfest", ",", "un\u00b7ver\u00b7di\u00b7ent", ",", "der", "V\u00e4\u00b7ter", "Mis\u00b7se\u00b7tha\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Bis du, o sichres Rom, die Tempel wieder baust,", "tokens": ["Bis", "du", ",", "o", "sich\u00b7res", "Rom", ",", "die", "Tem\u00b7pel", "wie\u00b7der", "baust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "FM", "FM", "NE", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der G\u00f6tter Wohnungen, die in Verfall gerathen,", "tokens": ["Der", "G\u00f6t\u00b7ter", "Woh\u00b7nun\u00b7gen", ",", "die", "in", "Ver\u00b7fall", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PRELS", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf deren Bildern du noch Rauch und Moder schaust.", "tokens": ["Auf", "de\u00b7ren", "Bil\u00b7dern", "du", "noch", "Rauch", "und", "Mo\u00b7der", "schaust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ADV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Durch Ehrfurcht gegen sie hast du das Heft erhalten.", "tokens": ["Durch", "Ehr\u00b7furcht", "ge\u00b7gen", "sie", "hast", "du", "das", "Heft", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VAFIN", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sie gr\u00fcndete den Flor, der dir den Vorzug gibt;", "tokens": ["Sie", "gr\u00fcn\u00b7de\u00b7te", "den", "Flor", ",", "der", "dir", "den", "Vor\u00b7zug", "gibt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch sahn die G\u00f6tter kaum den ersten Dank erkalten,", "tokens": ["Doch", "sahn", "die", "G\u00f6t\u00b7ter", "kaum", "den", "ers\u00b7ten", "Dank", "er\u00b7kal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ward Hesperien durch \u00f6ftre Noth betr\u00fcbt.", "tokens": ["So", "ward", "Hes\u00b7pe\u00b7ri\u00b7en", "durch", "\u00f6ft\u00b7re", "Noth", "be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Wir kriegten ohne sie, uneingedenk der Zeichen:", "tokens": ["Wir", "krieg\u00b7ten", "oh\u00b7ne", "sie", ",", "un\u00b7ein\u00b7ge\u00b7denk", "der", "Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$,", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schon zweimal b\u00e4ndigt uns Monaeses und Pacor.", "tokens": ["Schon", "zwei\u00b7mal", "b\u00e4n\u00b7digt", "uns", "Mo\u00b7nae\u00b7ses", "und", "Pa\u00b7cor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch gr\u00f6\u00dfrer Ketten Gold, den Raub von unsern Leichen,", "tokens": ["Durch", "gr\u00f6\u00df\u00b7rer", "Ket\u00b7ten", "Gold", ",", "den", "Raub", "von", "un\u00b7sern", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hebt sich der Parther Hals weit stolzer, als zuvor.", "tokens": ["Hebt", "sich", "der", "Par\u00b7ther", "Hals", "weit", "stol\u00b7zer", ",", "als", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NN", "ADJD", "ADJA", "$,", "KOUS", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Bald h\u00e4tt' Aegyptens Volk, das mit der Seemacht schreckte,", "tokens": ["Bald", "h\u00e4tt'", "A\u00b7e\u00b7gyp\u00b7tens", "Volk", ",", "das", "mit", "der", "See\u00b7macht", "schreck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "--+-+-+-+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Und bald der Dacier, der frech den Wurfpfeil schwenkt,", "tokens": ["Und", "bald", "der", "Da\u00b7cier", ",", "der", "frech", "den", "Wurf\u00b7pfeil", "schwenkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$,", "PRELS", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Als alles schw\u00fcrig war und voller Aufruhr steckte,", "tokens": ["Als", "al\u00b7les", "schw\u00fc\u00b7rig", "war", "und", "vol\u00b7ler", "Auf\u00b7ruhr", "steck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADJD", "VAFIN", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Mauern unsrer Stadt in \u00f6den Staub versenkt.", "tokens": ["Die", "Mau\u00b7ern", "uns\u00b7rer", "Stadt", "in", "\u00f6\u00b7den", "Staub", "ver\u00b7senkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Der Zeiten \u00f6ftre Brut, der Frevel und die Schande,", "tokens": ["Der", "Zei\u00b7ten", "\u00f6ft\u00b7re", "Brut", ",", "der", "Fre\u00b7vel", "und", "die", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beschmitzten anfangs bald die Ehen, Haus und Stamm;", "tokens": ["Be\u00b7schmitz\u00b7ten", "an\u00b7fangs", "bald", "die", "E\u00b7hen", ",", "Haus", "und", "Stamm", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und diese Quelle war's, aus der dem Vaterlande,", "tokens": ["Und", "die\u00b7se", "Quel\u00b7le", "wa\u00b7r's", ",", "aus", "der", "dem", "Va\u00b7ter\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "$,", "APPR", "ART", "ART", "NN", "$,"], "meter": "---+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Dem Volke des Quirins, der Strom der Strafen kam.", "tokens": ["Dem", "Vol\u00b7ke", "des", "Qui\u00b7rins", ",", "der", "Strom", "der", "Stra\u00b7fen", "kam", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--++-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.18": {"line.1": {"text": "Ein reifes M\u00e4dchen lernt der geilsten Griechen T\u00e4nze,", "tokens": ["Ein", "rei\u00b7fes", "M\u00e4d\u00b7chen", "lernt", "der", "geils\u00b7ten", "Grie\u00b7chen", "T\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Stellung Wissenschaft, der Glieder Fertigkeit,", "tokens": ["Der", "Stel\u00b7lung", "Wis\u00b7sen\u00b7schaft", ",", "der", "Glie\u00b7der", "Fer\u00b7tig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und sinnt, voll Ungeduld, in ihrem ersten Lenze,", "tokens": ["Und", "sinnt", ",", "voll", "Un\u00b7ge\u00b7duld", ",", "in", "ih\u00b7rem", "ers\u00b7ten", "Len\u00b7ze", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "ADJD", "NN", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Schon auf ein Meisterst\u00fcck der fr\u00fchen L\u00fcsternheit.", "tokens": ["Schon", "auf", "ein", "Meis\u00b7ter\u00b7st\u00fcck", "der", "fr\u00fc\u00b7hen", "L\u00fcs\u00b7tern\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Sie freit und wagt beim Schmaus vom Mann sich wegzustehlen.", "tokens": ["Sie", "freit", "und", "wagt", "beim", "Schmaus", "vom", "Mann", "sich", "weg\u00b7zu\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "VVFIN", "APPRART", "NN", "APPRART", "NN", "PRF", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sucht j\u00fcngre Buhler auf, mit denen sie entschleicht,", "tokens": ["Sucht", "j\u00fcng\u00b7re", "Buh\u00b7ler", "auf", ",", "mit", "de\u00b7nen", "sie", "ent\u00b7schleicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "PTKVZ", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ihnen, schnell und frech und ohne langes W\u00e4hlen,", "tokens": ["Und", "ih\u00b7nen", ",", "schnell", "und", "frech", "und", "oh\u00b7ne", "lan\u00b7ges", "W\u00e4h\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJD", "KON", "ADJD", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wann sie das Licht entfernt, verbotne K\u00fcsse reicht.", "tokens": ["Wann", "sie", "das", "Licht", "ent\u00b7fernt", ",", "ver\u00b7bot\u00b7ne", "K\u00fcs\u00b7se", "reicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVPP", "$,", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Doch nein! Sie hei\u00dft den Mann, der Schande Hehler, trinken,", "tokens": ["Doch", "nein", "!", "Sie", "hei\u00dft", "den", "Mann", ",", "der", "Schan\u00b7de", "Heh\u00b7ler", ",", "trin\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "NE", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Steht auf und schmieget sich an eines Fremden Brust;", "tokens": ["Steht", "auf", "und", "schmie\u00b7get", "sich", "an", "ei\u00b7nes", "Frem\u00b7den", "Brust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VVFIN", "PRF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Es mag ein M\u00e4kler ihr, es mag ein Schiffherr winken,", "tokens": ["Es", "mag", "ein", "M\u00e4k\u00b7ler", "ihr", ",", "es", "mag", "ein", "Schiff\u00b7herr", "win\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "PPER", "$,", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als die Meistbietenden f\u00fcr manche schn\u00f6de Lust.", "tokens": ["Als", "die", "Meist\u00b7bie\u00b7ten\u00b7den", "f\u00fcr", "man\u00b7che", "schn\u00f6\u00b7de", "Lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Roms tapfre Jugend ist von solchen nicht entsprungen;", "tokens": ["Roms", "tapf\u00b7re", "Ju\u00b7gend", "ist", "von", "sol\u00b7chen", "nicht", "ent\u00b7sprun\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VAFIN", "APPR", "PIAT", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nie f\u00e4rbt' ein Meer durch sie der Poener Blut und Fall.", "tokens": ["Nie", "f\u00e4rbt'", "ein", "Meer", "durch", "sie", "der", "Poe\u00b7ner", "Blut", "und", "Fall", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "ART", "NN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch S\u00f6hne bess'rer Art ward Pyrrhus Heer bezwungen,", "tokens": ["Durch", "S\u00f6h\u00b7ne", "bess'\u00b7rer", "Art", "ward", "Pyrr\u00b7hus", "Heer", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJA", "NN", "VAFIN", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der Held Antiochus, der grimme Hannibal.", "tokens": ["Der", "Held", "An\u00b7tio\u00b7chus", ",", "der", "grim\u00b7me", "Han\u00b7ni\u00b7bal", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.22": {"line.1": {"text": "Durch r\u00fcstig Bauernvolk, durch manchen Held im Kittel,", "tokens": ["Durch", "r\u00fcs\u00b7tig", "Bau\u00b7ern\u00b7volk", ",", "durch", "man\u00b7chen", "Held", "im", "Kit\u00b7tel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "NN", "$,", "APPR", "PIAT", "NN", "APPRART", "NN", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Der, durch den Feldbau stark, geh\u00e4rtet durch den Pflug,", "tokens": ["Der", ",", "durch", "den", "Feld\u00b7bau", "stark", ",", "ge\u00b7h\u00e4r\u00b7tet", "durch", "den", "Pflug", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "APPR", "ART", "NN", "ADJD", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Nach scharfer M\u00fctter Sinn, noch emsig Scheit und Kn\u00fcttel", "tokens": ["Nach", "schar\u00b7fer", "M\u00fct\u00b7ter", "Sinn", ",", "noch", "em\u00b7sig", "Scheit", "und", "Kn\u00fct\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "NN", "$,", "ADV", "ADJD", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zum Schlu\u00df der Arbeit hieb und in die H\u00fctte trug:", "tokens": ["Zum", "Schlu\u00df", "der", "Ar\u00b7beit", "hieb", "und", "in", "die", "H\u00fct\u00b7te", "trug", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Bis, wann die Sonne nun den Wagen tiefer lenkte", "tokens": ["Bis", ",", "wann", "die", "Son\u00b7ne", "nun", "den", "Wa\u00b7gen", "tie\u00b7fer", "lenk\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "$,", "PWAV", "ART", "NN", "ADV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und an den Bergen sich der sp\u00e4tste Schatten wies,", "tokens": ["Und", "an", "den", "Ber\u00b7gen", "sich", "der", "sp\u00e4ts\u00b7te", "Schat\u00b7ten", "wies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die s\u00fc\u00dfe Stunde kam, die ihm die Ruhe schenkte", "tokens": ["Die", "s\u00fc\u00b7\u00dfe", "Stun\u00b7de", "kam", ",", "die", "ihm", "die", "Ru\u00b7he", "schenk\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und aus dem schweren Joch die m\u00fcden Rinder lie\u00df.", "tokens": ["Und", "aus", "dem", "schwe\u00b7ren", "Joch", "die", "m\u00fc\u00b7den", "Rin\u00b7der", "lie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Was mindert nicht die Zeit? Verarten wir nicht immer?", "tokens": ["Was", "min\u00b7dert", "nicht", "die", "Zeit", "?", "Ver\u00b7ar\u00b7ten", "wir", "nicht", "im\u00b7mer", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "NN", "$.", "VVFIN", "PPER", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die R\u00f6mer sind nicht mehr was sie gewesen sind:", "tokens": ["Die", "R\u00f6\u00b7mer", "sind", "nicht", "mehr", "was", "sie", "ge\u00b7we\u00b7sen", "sind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ADV", "PWS", "PPER", "VAPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ahnen waren arg, die V\u00e4ter wurden schlimmer,", "tokens": ["Die", "Ah\u00b7nen", "wa\u00b7ren", "arg", ",", "die", "V\u00e4\u00b7ter", "wur\u00b7den", "schlim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und \u00e4rger, als wir selbst, wird Kind und Kindeskind.", "tokens": ["Und", "\u00e4r\u00b7ger", ",", "als", "wir", "selbst", ",", "wird", "Kind", "und", "Kin\u00b7des\u00b7kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "PPER", "ADV", "$,", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}