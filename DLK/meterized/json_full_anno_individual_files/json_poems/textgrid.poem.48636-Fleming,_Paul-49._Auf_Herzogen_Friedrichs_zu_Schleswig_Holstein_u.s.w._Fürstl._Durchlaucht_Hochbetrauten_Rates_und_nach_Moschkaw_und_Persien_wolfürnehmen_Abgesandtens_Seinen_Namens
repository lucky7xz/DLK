{"textgrid.poem.48636": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "49. Auf Herzogen Friedrichs zu Schleswig Holstein u.s.w. F\u00fcrstl. Durchlaucht Hochbetrauten Rates und nach Moschkaw und Persien wolf\u00fcrnehmen Abgesandtens Seinen Namenstag, welcher den 4. Wintermonatstag des 1638. Jahres vor Deutuscha an der Wolgen auf der R\u00fcckreise aus Persien gef\u00e4llig gewesen", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sechsmal, z\u00e4hl' ich anders recht,", "tokens": ["Sechs\u00b7mal", ",", "z\u00e4hl'", "ich", "an\u00b7ders", "recht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "haben die verreiften Saaten", "tokens": ["ha\u00b7ben", "die", "ver\u00b7reif\u00b7ten", "Saa\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "an des Hundssterns Glut gebraten;", "tokens": ["an", "des", "Hunds\u00b7sterns", "Glut", "ge\u00b7bra\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sechsmal geu\u00dft der Wasserknecht", "tokens": ["sechs\u00b7mal", "geu\u00dft", "der", "Was\u00b7ser\u00b7knecht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVPP", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "seinen Krug nun auf die Erden", "tokens": ["sei\u00b7nen", "Krug", "nun", "auf", "die", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und l\u00e4\u00dft Alles Winter werden,", "tokens": ["und", "l\u00e4\u00dft", "Al\u00b7les", "Win\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "seit wir meisten dieser Schaar", "tokens": ["seit", "wir", "meis\u00b7ten", "die\u00b7ser", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "euch, Herr, hin und her nun folgen", "tokens": ["euch", ",", "Herr", ",", "hin", "und", "her", "nun", "fol\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "ADV", "KON", "ADV", "ADV", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "und itzt von der sichern ", "tokens": ["und", "itzt", "von", "der", "si\u00b7chern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00fcberschauen die Gefahr,", "tokens": ["\u00fc\u00b7bersc\u00b7hau\u00b7en", "die", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die uns neulich und vor l\u00e4ngsten", "tokens": ["die", "uns", "neu\u00b7lich", "und", "vor", "l\u00e4ngs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "oft besucht' mit tausent \u00c4ngsten.", "tokens": ["oft", "be\u00b7sucht'", "mit", "tau\u00b7sent", "\u00c4ngs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch was n\u00fctzt es um und an", "tokens": ["Doch", "was", "n\u00fctzt", "es", "um", "und", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "PPER", "APPR", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sich mit toten Sorgen qu\u00e4len", "tokens": ["sich", "mit", "to\u00b7ten", "Sor\u00b7gen", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und ihm seinen Ha\u00df erz\u00e4hlen?", "tokens": ["und", "ihm", "sei\u00b7nen", "Ha\u00df", "er\u00b7z\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott sei Dank, es ist getan!", "tokens": ["Gott", "sei", "Dank", ",", "es", "ist", "ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00dft uns itzt mit neuen Freuden", "tokens": ["La\u00dft", "uns", "itzt", "mit", "neu\u00b7en", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die befreiten Geister weiden!", "tokens": ["die", "be\u00b7frei\u00b7ten", "Geis\u00b7ter", "wei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auch so bin ich nicht bedacht", "tokens": ["Auch", "so", "bin", "ich", "nicht", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "euren Ruhm hier zu vermelden,", "tokens": ["eu\u00b7ren", "Ruhm", "hier", "zu", "ver\u00b7mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "der von wegen eines Helden", "tokens": ["der", "von", "we\u00b7gen", "ei\u00b7nes", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "euch so weit so wert gemacht,", "tokens": ["euch", "so", "weit", "so", "wert", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df euch ehret nach dem Besten", "tokens": ["da\u00df", "euch", "eh\u00b7ret", "nach", "dem", "Bes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nord und Ost und S\u00fcd und Westen.", "tokens": ["Nord", "und", "Ost", "und", "S\u00fcd", "und", "Wes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Solches nichts treibt itzt mein Sin.", "tokens": ["Sol\u00b7ches", "nichts", "treibt", "itzt", "mein", "Sin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ihr Treflichs habt erwiesen,", "tokens": ["Was", "ihr", "Tref\u00b7lichs", "habt", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "will nicht auf der Flucht gepriesen,", "tokens": ["will", "nicht", "auf", "der", "Flucht", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht erw\u00e4hnt sein obenhin.", "tokens": ["nicht", "er\u00b7w\u00e4hnt", "sein", "o\u00b7ben\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "VAINF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrdigs Lob in hohen Sachen,", "tokens": ["W\u00fcr\u00b7digs", "Lob", "in", "ho\u00b7hen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "l\u00e4\u00dft sich nicht im Reisen machen.", "tokens": ["l\u00e4\u00dft", "sich", "nicht", "im", "Rei\u00b7sen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Uns soll die gehoffte Zeit", "tokens": ["Uns", "soll", "die", "ge\u00b7hoff\u00b7te", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "zwischen Scherz und Lust verflie\u00dfen.", "tokens": ["zwi\u00b7schen", "Scherz", "und", "Lust", "ver\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den Tag wollen wir beschlie\u00dfen", "tokens": ["Den", "Tag", "wol\u00b7len", "wir", "be\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "in vertrauter Einigkeit", "tokens": ["in", "ver\u00b7trau\u00b7ter", "Ei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und bei euren reichen Giften", "tokens": ["und", "bei", "eu\u00b7ren", "rei\u00b7chen", "Gif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eine neue Freundschaft stiften.", "tokens": ["ei\u00b7ne", "neu\u00b7e", "Freund\u00b7schaft", "stif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Komus hat den Preis der Kraft,", "tokens": ["Ko\u00b7mus", "hat", "den", "Preis", "der", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df er auch den Zorn der G\u00f6tter", "tokens": ["da\u00df", "er", "auch", "den", "Zorn", "der", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "stilt und sterbt und freundlich Wetter", "tokens": ["stilt", "und", "sterbt", "und", "freund\u00b7lich", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "KON", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der Menschen Herzen schafft,", "tokens": ["in", "der", "Men\u00b7schen", "Her\u00b7zen", "schafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die sich oft um etwas hassen", "tokens": ["die", "sich", "oft", "um", "et\u00b7was", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PRF", "ADV", "APPR", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und bald bessre Sinnen fassen.", "tokens": ["und", "bald", "bess\u00b7re", "Sin\u00b7nen", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Pfui! wie \u00fcbel sieht sichs drein,", "tokens": ["Pfui", "!", "wie", "\u00fc\u00b7bel", "sieht", "sichs", "drein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ADJD", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wo die ungemenschten ", "tokens": ["wo", "die", "un\u00b7ge\u00b7menschten"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "ADJA"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "sich mit Zank und Schl\u00e4gen martern", "tokens": ["sich", "mit", "Zank", "und", "Schl\u00e4\u00b7gen", "mar\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und bei Unlust lustig sein,", "tokens": ["und", "bei", "Un\u00b7lust", "lus\u00b7tig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn sie in des Libers Gaben", "tokens": ["wenn", "sie", "in", "des", "Li\u00b7bers", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sin und Witz ers\u00e4ufet haben!", "tokens": ["Sin", "und", "Witz", "er\u00b7s\u00e4u\u00b7fet", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Jupiter, wie stets ihm auch", "tokens": ["Ju\u00b7pi\u00b7ter", ",", "wie", "stets", "ihm", "auch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ADV", "PPER", "ADV"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "die verdamte Welt macht Kummer,", "tokens": ["die", "ver\u00b7dam\u00b7te", "Welt", "macht", "Kum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "doch so blitzt er nur im Sommer,", "tokens": ["doch", "so", "blitzt", "er", "nur", "im", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und der L\u00f6we hat den Brauch,", "tokens": ["und", "der", "L\u00f6\u00b7we", "hat", "den", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df er leichtlich wird beweget", "tokens": ["da\u00df", "er", "leicht\u00b7lich", "wird", "be\u00b7we\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und nur starke Feinde schl\u00e4get.", "tokens": ["und", "nur", "star\u00b7ke", "Fein\u00b7de", "schl\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "F\u00f6rdert Gott, so hindert nichts.", "tokens": ["F\u00f6r\u00b7dert", "Gott", ",", "so", "hin\u00b7dert", "nichts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "VVFIN", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gro\u00dfe Zier hat gro\u00dfe Feinde.", "tokens": ["Gro\u00b7\u00dfe", "Zier", "hat", "gro\u00b7\u00dfe", "Fein\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch wer Gott nur hat zu Freunde,", "tokens": ["Doch", "wer", "Gott", "nur", "hat", "zu", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der ist sicher des Gerichts,", "tokens": ["der", "ist", "si\u00b7cher", "des", "Ge\u00b7richts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ADJD", "ART", "NN", "$,"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.5": {"text": "das der Rat der leichten Seelen", "tokens": ["das", "der", "Rat", "der", "leich\u00b7ten", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auf ihn pfleget zu erw\u00e4hlen.", "tokens": ["auf", "ihn", "pfle\u00b7get", "zu", "er\u00b7w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Tugend ist das h\u00f6chste Gut.", "tokens": ["Tu\u00b7gend", "ist", "das", "h\u00f6chs\u00b7te", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mi\u00dfgunst, deine tausent Rachen", "tokens": ["Mi\u00df\u00b7gunst", ",", "dei\u00b7ne", "tau\u00b7sent", "Ra\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sollen Niemand irre machen,", "tokens": ["sol\u00b7len", "Nie\u00b7mand", "ir\u00b7re", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der was Redlichs denkt und tut!", "tokens": ["der", "was", "Red\u00b7lichs", "denkt", "und", "tut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PWS", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nichts steht ehrlicher auf Erden", "tokens": ["Nichts", "steht", "ehr\u00b7li\u00b7cher", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "als umsonst getadelt werden.", "tokens": ["als", "um\u00b7sonst", "ge\u00b7ta\u00b7delt", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Blut, das regt und legt sich bald,", "tokens": ["Blut", ",", "das", "regt", "und", "legt", "sich", "bald", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "welches wohnt in edlen Adern.", "tokens": ["wel\u00b7ches", "wohnt", "in", "ed\u00b7len", "A\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlechtes Volk hat Lust zu hadern,", "tokens": ["Schlech\u00b7tes", "Volk", "hat", "Lust", "zu", "ha\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "P\u00f6fel mi\u00dfbraucht der Gewalt.", "tokens": ["P\u00f6\u00b7fel", "mi\u00df\u00b7braucht", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "F\u00fcrsten nur und gro\u00dfen Sinnen", "tokens": ["F\u00fcrs\u00b7ten", "nur", "und", "gro\u00b7\u00dfen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "kommt es zu verzeihenk\u00f6nnen.", "tokens": ["kommt", "es", "zu", "ver\u00b7zei\u00b7hen\u00b7k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Bacchus zwar, der F\u00fcrst der Kost", "tokens": ["Bac\u00b7chus", "zwar", ",", "der", "F\u00fcrst", "der", "Kost"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "$,", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "auf ber\u00fchmten Gastereien,", "tokens": ["auf", "be\u00b7r\u00fchm\u00b7ten", "Gas\u00b7te\u00b7rei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wird sich hier mit uns nicht freuen,", "tokens": ["wird", "sich", "hier", "mit", "uns", "nicht", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "APPR", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "weil er scheut des Nordens Frost;", "tokens": ["weil", "er", "scheut", "des", "Nor\u00b7dens", "Frost", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sein Fu\u00df hat in diesen Landen", "tokens": ["sein", "Fu\u00df", "hat", "in", "die\u00b7sen", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "nie als auf der Post gestanden.", "tokens": ["nie", "als", "auf", "der", "Post", "ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch stellt Ceres sich uns ein,", "tokens": ["Doch", "stellt", "Ce\u00b7res", "sich", "uns", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "PRF", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die noch hat des Grolles Zeichen,", "tokens": ["die", "noch", "hat", "des", "Grol\u00b7les", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df sie muste Bacchus weichen", "tokens": ["da\u00df", "sie", "mus\u00b7te", "Bac\u00b7chus", "wei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ihn lassen Meister sein.", "tokens": ["und", "ihn", "las\u00b7sen", "Meis\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dein Rat, Achelous, machet,", "tokens": ["Dein", "Rat", ",", "A\u00b7che\u00b7lous", ",", "ma\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "da\u00df man ihn hier fast verlachet.", "tokens": ["da\u00df", "man", "ihn", "hier", "fast", "ver\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "und brennt eine Kraft aus K\u00f6rnern,", "tokens": ["und", "brennt", "ei\u00b7ne", "Kraft", "aus", "K\u00f6r\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "die, Osiris, deinen H\u00f6rnern", "tokens": ["die", ",", "O\u00b7si\u00b7ris", ",", "dei\u00b7nen", "H\u00f6r\u00b7nern"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "$,", "NE", "$,", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Trutz beut und die Wage h\u00e4lt.", "tokens": ["Trutz", "beut", "und", "die", "Wa\u00b7ge", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Trauben haben gro\u00dfe Kr\u00e4fte,", "tokens": ["Trau\u00b7ben", "ha\u00b7ben", "gro\u00b7\u00dfe", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so doch die \u00c4hren st\u00e4rkre S\u00e4fte.", "tokens": ["so", "doch", "die", "\u00c4h\u00b7ren", "st\u00e4r\u00b7kre", "S\u00e4f\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00dcber di\u00df steht Hybla hier,", "tokens": ["\u00dc\u00b7ber", "di\u00df", "steht", "Hy\u00b7bla", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "NE", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die der Blumen g\u00f6ttlichs Wesen", "tokens": ["die", "der", "Blu\u00b7men", "g\u00f6tt\u00b7lichs", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "durch die Bienen ein l\u00e4\u00dft lesen", "tokens": ["durch", "die", "Bie\u00b7nen", "ein", "l\u00e4\u00dft", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und uns vorsetzt eine Zier,", "tokens": ["und", "uns", "vor\u00b7setzt", "ei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "die f\u00fcr Jupiters Getr\u00e4nken", "tokens": ["die", "f\u00fcr", "Ju\u00b7pi\u00b7ters", "Ge\u00b7tr\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.6": {"text": "Ganymed pflegt einzuschenken.", "tokens": ["Ga\u00b7ny\u00b7med", "pflegt", "ein\u00b7zu\u00b7schen\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn der Eurische Nordost", "tokens": ["Wenn", "der", "Eu\u00b7ri\u00b7sche", "Nord\u00b7ost"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "in die holen D\u00e4cher pfeifet,", "tokens": ["in", "die", "ho\u00b7len", "D\u00e4\u00b7cher", "pfei\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und es um die T\u00fcren reifet,", "tokens": ["und", "es", "um", "die", "T\u00fc\u00b7ren", "rei\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn es dreht und Flocken schlo\u00dft,", "tokens": ["wenn", "es", "dreht", "und", "Flo\u00b7cken", "schlo\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir fast nicht ohne Grauen", "tokens": ["da\u00df", "wir", "fast", "nicht", "oh\u00b7ne", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "f\u00fcr das kalte Fenster schauen:", "tokens": ["f\u00fcr", "das", "kal\u00b7te", "Fens\u00b7ter", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "denn so ist es mehr als recht,", "tokens": ["denn", "so", "ist", "es", "mehr", "als", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df man sich zusammen setzet", "tokens": ["da\u00df", "man", "sich", "zu\u00b7sam\u00b7men", "set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und bei warmer Lust ergetzet,", "tokens": ["und", "bei", "war\u00b7mer", "Lust", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df man singet, tanzt und zecht", "tokens": ["da\u00df", "man", "sin\u00b7get", ",", "tanzt", "und", "zecht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und mehr, wenn wir uns zu laben,", "tokens": ["und", "mehr", ",", "wenn", "wir", "uns", "zu", "la\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie anitzo, Ursach' haben.", "tokens": ["wie", "a\u00b7nit\u00b7zo", ",", "Ur\u00b7sach'", "ha\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Itzt zumal, da kein Gott fast", "tokens": ["Itzt", "zu\u00b7mal", ",", "da", "kein", "Gott", "fast"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PIAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "au\u00dfer \u00c4oln auf der Erden", "tokens": ["au\u00b7\u00dfer", "\u00c4\u00b7oln", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "leichtlich kan gesp\u00fcret werden.", "tokens": ["leicht\u00b7lich", "kan", "ge\u00b7sp\u00fc\u00b7ret", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle lieben ihre Rast.", "tokens": ["Al\u00b7le", "lie\u00b7ben", "ih\u00b7re", "Rast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Selbst der F\u00fcrst des Tagelichtes", "tokens": ["Selbst", "der", "F\u00fcrst", "des", "Ta\u00b7ge\u00b7lich\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "w\u00fcrdigt uns kaum des Gesichtes.", "tokens": ["w\u00fcr\u00b7digt", "uns", "kaum", "des", "Ge\u00b7sich\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.20": {"line.1": {"text": "Mars hat ihm Quartier gesucht,", "tokens": ["Mars", "hat", "ihm", "Quar\u00b7tier", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Delie l\u00e4st P\u00fcsch' und H\u00f6hen,", "tokens": ["De\u00b7lie", "l\u00e4st", "P\u00fcsch'", "und", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mulciber den Ambos stehen,", "tokens": ["Mul\u00b7ci\u00b7ber", "den", "Am\u00b7bos", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ceres zehrt von ihrer Frucht.", "tokens": ["Ce\u00b7res", "zehrt", "von", "ih\u00b7rer", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie sind Tag f\u00fcr Tag zu Gaste", "tokens": ["Sie", "sind", "Tag", "f\u00fcr", "Tag", "zu", "Gas\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "in Diespiters Palaste.", "tokens": ["in", "Dies\u00b7pi\u00b7ters", "Pa\u00b7las\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.21": {"line.1": {"text": "Venus und ihr kleiner Sohn", "tokens": ["Ve\u00b7nus", "und", "ihr", "klei\u00b7ner", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "sind auf Erden eingefroren,", "tokens": ["sind", "auf", "Er\u00b7den", "ein\u00b7ge\u00b7fro\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "haben Zeit und Weg verloren", "tokens": ["ha\u00b7ben", "Zeit", "und", "Weg", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "zu der Sternen ihrem Thron", "tokens": ["zu", "der", "Ster\u00b7nen", "ih\u00b7rem", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und stehn hier uns anzusinnen,", "tokens": ["und", "stehn", "hier", "uns", "an\u00b7zu\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "VVIZU", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "wo sie mit uns wintern k\u00f6nnen.", "tokens": ["wo", "sie", "mit", "uns", "win\u00b7tern", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Fangt denn an, Herr, aufzustehn", "tokens": ["Fangt", "denn", "an", ",", "Herr", ",", "auf\u00b7zu\u00b7stehn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "NN", "$,", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und la\u00dft Schalen, Schiff' und Trauben", "tokens": ["und", "la\u00dft", "Scha\u00b7len", ",", "Schiff'", "und", "Trau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "recht auf ", "tokens": ["recht", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "rund um unser' Tafel gehn,", "tokens": ["rund", "um", "un\u00b7ser'", "Ta\u00b7fel", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis nicht Einen mehr wird d\u00fcrsten!", "tokens": ["bis", "nicht", "Ei\u00b7nen", "mehr", "wird", "d\u00fcrs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "ADV", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auf Gesundheit unsers F\u00fcrsten!", "tokens": ["Auf", "Ge\u00b7sund\u00b7heit", "un\u00b7sers", "F\u00fcrs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Sechsmal, z\u00e4hl' ich anders recht,", "tokens": ["Sechs\u00b7mal", ",", "z\u00e4hl'", "ich", "an\u00b7ders", "recht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "haben die verreiften Saaten", "tokens": ["ha\u00b7ben", "die", "ver\u00b7reif\u00b7ten", "Saa\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "an des Hundssterns Glut gebraten;", "tokens": ["an", "des", "Hunds\u00b7sterns", "Glut", "ge\u00b7bra\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "sechsmal geu\u00dft der Wasserknecht", "tokens": ["sechs\u00b7mal", "geu\u00dft", "der", "Was\u00b7ser\u00b7knecht"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVPP", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "seinen Krug nun auf die Erden", "tokens": ["sei\u00b7nen", "Krug", "nun", "auf", "die", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und l\u00e4\u00dft Alles Winter werden,", "tokens": ["und", "l\u00e4\u00dft", "Al\u00b7les", "Win\u00b7ter", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "VAINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.24": {"line.1": {"text": "seit wir meisten dieser Schaar", "tokens": ["seit", "wir", "meis\u00b7ten", "die\u00b7ser", "Schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "euch, Herr, hin und her nun folgen", "tokens": ["euch", ",", "Herr", ",", "hin", "und", "her", "nun", "fol\u00b7gen"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "$,", "NN", "$,", "ADV", "KON", "ADV", "ADV", "VVINF"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "und itzt von der sichern ", "tokens": ["und", "itzt", "von", "der", "si\u00b7chern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "\u00fcberschauen die Gefahr,", "tokens": ["\u00fc\u00b7bersc\u00b7hau\u00b7en", "die", "Ge\u00b7fahr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die uns neulich und vor l\u00e4ngsten", "tokens": ["die", "uns", "neu\u00b7lich", "und", "vor", "l\u00e4ngs\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADV", "KON", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "oft besucht' mit tausent \u00c4ngsten.", "tokens": ["oft", "be\u00b7sucht'", "mit", "tau\u00b7sent", "\u00c4ngs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "CARD", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Doch was n\u00fctzt es um und an", "tokens": ["Doch", "was", "n\u00fctzt", "es", "um", "und", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "VVFIN", "PPER", "APPR", "KON", "APPR"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sich mit toten Sorgen qu\u00e4len", "tokens": ["sich", "mit", "to\u00b7ten", "Sor\u00b7gen", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ADJA", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und ihm seinen Ha\u00df erz\u00e4hlen?", "tokens": ["und", "ihm", "sei\u00b7nen", "Ha\u00df", "er\u00b7z\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Gott sei Dank, es ist getan!", "tokens": ["Gott", "sei", "Dank", ",", "es", "ist", "ge\u00b7tan", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "NN", "$,", "PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "La\u00dft uns itzt mit neuen Freuden", "tokens": ["La\u00dft", "uns", "itzt", "mit", "neu\u00b7en", "Freu\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "die befreiten Geister weiden!", "tokens": ["die", "be\u00b7frei\u00b7ten", "Geis\u00b7ter", "wei\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Auch so bin ich nicht bedacht", "tokens": ["Auch", "so", "bin", "ich", "nicht", "be\u00b7dacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PTKNEG", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "euren Ruhm hier zu vermelden,", "tokens": ["eu\u00b7ren", "Ruhm", "hier", "zu", "ver\u00b7mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "der von wegen eines Helden", "tokens": ["der", "von", "we\u00b7gen", "ei\u00b7nes", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "euch so weit so wert gemacht,", "tokens": ["euch", "so", "weit", "so", "wert", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "ADV", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df euch ehret nach dem Besten", "tokens": ["da\u00df", "euch", "eh\u00b7ret", "nach", "dem", "Bes\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nord und Ost und S\u00fcd und Westen.", "tokens": ["Nord", "und", "Ost", "und", "S\u00fcd", "und", "Wes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "KON", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Solches nichts treibt itzt mein Sin.", "tokens": ["Sol\u00b7ches", "nichts", "treibt", "itzt", "mein", "Sin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Was ihr Treflichs habt erwiesen,", "tokens": ["Was", "ihr", "Tref\u00b7lichs", "habt", "er\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "will nicht auf der Flucht gepriesen,", "tokens": ["will", "nicht", "auf", "der", "Flucht", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nicht erw\u00e4hnt sein obenhin.", "tokens": ["nicht", "er\u00b7w\u00e4hnt", "sein", "o\u00b7ben\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVPP", "VAINF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrdigs Lob in hohen Sachen,", "tokens": ["W\u00fcr\u00b7digs", "Lob", "in", "ho\u00b7hen", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "l\u00e4\u00dft sich nicht im Reisen machen.", "tokens": ["l\u00e4\u00dft", "sich", "nicht", "im", "Rei\u00b7sen", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "PTKNEG", "APPRART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Uns soll die gehoffte Zeit", "tokens": ["Uns", "soll", "die", "ge\u00b7hoff\u00b7te", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "zwischen Scherz und Lust verflie\u00dfen.", "tokens": ["zwi\u00b7schen", "Scherz", "und", "Lust", "ver\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den Tag wollen wir beschlie\u00dfen", "tokens": ["Den", "Tag", "wol\u00b7len", "wir", "be\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "in vertrauter Einigkeit", "tokens": ["in", "ver\u00b7trau\u00b7ter", "Ei\u00b7nig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und bei euren reichen Giften", "tokens": ["und", "bei", "eu\u00b7ren", "rei\u00b7chen", "Gif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "eine neue Freundschaft stiften.", "tokens": ["ei\u00b7ne", "neu\u00b7e", "Freund\u00b7schaft", "stif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Komus hat den Preis der Kraft,", "tokens": ["Ko\u00b7mus", "hat", "den", "Preis", "der", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df er auch den Zorn der G\u00f6tter", "tokens": ["da\u00df", "er", "auch", "den", "Zorn", "der", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "stilt und sterbt und freundlich Wetter", "tokens": ["stilt", "und", "sterbt", "und", "freund\u00b7lich", "Wet\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVFIN", "KON", "ADJD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "in der Menschen Herzen schafft,", "tokens": ["in", "der", "Men\u00b7schen", "Her\u00b7zen", "schafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "die sich oft um etwas hassen", "tokens": ["die", "sich", "oft", "um", "et\u00b7was", "has\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PRF", "ADV", "APPR", "PIS", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und bald bessre Sinnen fassen.", "tokens": ["und", "bald", "bess\u00b7re", "Sin\u00b7nen", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Pfui! wie \u00fcbel sieht sichs drein,", "tokens": ["Pfui", "!", "wie", "\u00fc\u00b7bel", "sieht", "sichs", "drein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "PWAV", "ADJD", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wo die ungemenschten ", "tokens": ["wo", "die", "un\u00b7ge\u00b7menschten"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "ART", "ADJA"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "sich mit Zank und Schl\u00e4gen martern", "tokens": ["sich", "mit", "Zank", "und", "Schl\u00e4\u00b7gen", "mar\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und bei Unlust lustig sein,", "tokens": ["und", "bei", "Un\u00b7lust", "lus\u00b7tig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADJD", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wenn sie in des Libers Gaben", "tokens": ["wenn", "sie", "in", "des", "Li\u00b7bers", "Ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Sin und Witz ers\u00e4ufet haben!", "tokens": ["Sin", "und", "Witz", "er\u00b7s\u00e4u\u00b7fet", "ha\u00b7ben", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Jupiter, wie stets ihm auch", "tokens": ["Ju\u00b7pi\u00b7ter", ",", "wie", "stets", "ihm", "auch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWAV", "ADV", "PPER", "ADV"], "meter": "+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "die verdamte Welt macht Kummer,", "tokens": ["die", "ver\u00b7dam\u00b7te", "Welt", "macht", "Kum\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "doch so blitzt er nur im Sommer,", "tokens": ["doch", "so", "blitzt", "er", "nur", "im", "Som\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und der L\u00f6we hat den Brauch,", "tokens": ["und", "der", "L\u00f6\u00b7we", "hat", "den", "Brauch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df er leichtlich wird beweget", "tokens": ["da\u00df", "er", "leicht\u00b7lich", "wird", "be\u00b7we\u00b7get"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "und nur starke Feinde schl\u00e4get.", "tokens": ["und", "nur", "star\u00b7ke", "Fein\u00b7de", "schl\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.32": {"line.1": {"text": "F\u00f6rdert Gott, so hindert nichts.", "tokens": ["F\u00f6r\u00b7dert", "Gott", ",", "so", "hin\u00b7dert", "nichts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "ADV", "VVFIN", "PIS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Gro\u00dfe Zier hat gro\u00dfe Feinde.", "tokens": ["Gro\u00b7\u00dfe", "Zier", "hat", "gro\u00b7\u00dfe", "Fein\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch wer Gott nur hat zu Freunde,", "tokens": ["Doch", "wer", "Gott", "nur", "hat", "zu", "Freun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der ist sicher des Gerichts,", "tokens": ["der", "ist", "si\u00b7cher", "des", "Ge\u00b7richts", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "ADJD", "ART", "NN", "$,"], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.5": {"text": "das der Rat der leichten Seelen", "tokens": ["das", "der", "Rat", "der", "leich\u00b7ten", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ART", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "auf ihn pfleget zu erw\u00e4hlen.", "tokens": ["auf", "ihn", "pfle\u00b7get", "zu", "er\u00b7w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.33": {"line.1": {"text": "Tugend ist das h\u00f6chste Gut.", "tokens": ["Tu\u00b7gend", "ist", "das", "h\u00f6chs\u00b7te", "Gut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mi\u00dfgunst, deine tausent Rachen", "tokens": ["Mi\u00df\u00b7gunst", ",", "dei\u00b7ne", "tau\u00b7sent", "Ra\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PPOSAT", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sollen Niemand irre machen,", "tokens": ["sol\u00b7len", "Nie\u00b7mand", "ir\u00b7re", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "VVFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "der was Redlichs denkt und tut!", "tokens": ["der", "was", "Red\u00b7lichs", "denkt", "und", "tut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PWS", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nichts steht ehrlicher auf Erden", "tokens": ["Nichts", "steht", "ehr\u00b7li\u00b7cher", "auf", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "als umsonst getadelt werden.", "tokens": ["als", "um\u00b7sonst", "ge\u00b7ta\u00b7delt", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Blut, das regt und legt sich bald,", "tokens": ["Blut", ",", "das", "regt", "und", "legt", "sich", "bald", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "KON", "VVFIN", "PRF", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "welches wohnt in edlen Adern.", "tokens": ["wel\u00b7ches", "wohnt", "in", "ed\u00b7len", "A\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Schlechtes Volk hat Lust zu hadern,", "tokens": ["Schlech\u00b7tes", "Volk", "hat", "Lust", "zu", "ha\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "P\u00f6fel mi\u00dfbraucht der Gewalt.", "tokens": ["P\u00f6\u00b7fel", "mi\u00df\u00b7braucht", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.5": {"text": "F\u00fcrsten nur und gro\u00dfen Sinnen", "tokens": ["F\u00fcrs\u00b7ten", "nur", "und", "gro\u00b7\u00dfen", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KON", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "kommt es zu verzeihenk\u00f6nnen.", "tokens": ["kommt", "es", "zu", "ver\u00b7zei\u00b7hen\u00b7k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Bacchus zwar, der F\u00fcrst der Kost", "tokens": ["Bac\u00b7chus", "zwar", ",", "der", "F\u00fcrst", "der", "Kost"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "$,", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "auf ber\u00fchmten Gastereien,", "tokens": ["auf", "be\u00b7r\u00fchm\u00b7ten", "Gas\u00b7te\u00b7rei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wird sich hier mit uns nicht freuen,", "tokens": ["wird", "sich", "hier", "mit", "uns", "nicht", "freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "APPR", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "weil er scheut des Nordens Frost;", "tokens": ["weil", "er", "scheut", "des", "Nor\u00b7dens", "Frost", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "sein Fu\u00df hat in diesen Landen", "tokens": ["sein", "Fu\u00df", "hat", "in", "die\u00b7sen", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "PDAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "nie als auf der Post gestanden.", "tokens": ["nie", "als", "auf", "der", "Post", "ge\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Doch stellt Ceres sich uns ein,", "tokens": ["Doch", "stellt", "Ce\u00b7res", "sich", "uns", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "PRF", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die noch hat des Grolles Zeichen,", "tokens": ["die", "noch", "hat", "des", "Grol\u00b7les", "Zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "da\u00df sie muste Bacchus weichen", "tokens": ["da\u00df", "sie", "mus\u00b7te", "Bac\u00b7chus", "wei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VMFIN", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und ihn lassen Meister sein.", "tokens": ["und", "ihn", "las\u00b7sen", "Meis\u00b7ter", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVINF", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dein Rat, Achelous, machet,", "tokens": ["Dein", "Rat", ",", "A\u00b7che\u00b7lous", ",", "ma\u00b7chet", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NE", "$,", "VVFIN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "da\u00df man ihn hier fast verlachet.", "tokens": ["da\u00df", "man", "ihn", "hier", "fast", "ver\u00b7la\u00b7chet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.37": {"line.1": {"text": "und brennt eine Kraft aus K\u00f6rnern,", "tokens": ["und", "brennt", "ei\u00b7ne", "Kraft", "aus", "K\u00f6r\u00b7nern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "die, Osiris, deinen H\u00f6rnern", "tokens": ["die", ",", "O\u00b7si\u00b7ris", ",", "dei\u00b7nen", "H\u00f6r\u00b7nern"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "$,", "NE", "$,", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Trutz beut und die Wage h\u00e4lt.", "tokens": ["Trutz", "beut", "und", "die", "Wa\u00b7ge", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Trauben haben gro\u00dfe Kr\u00e4fte,", "tokens": ["Trau\u00b7ben", "ha\u00b7ben", "gro\u00b7\u00dfe", "Kr\u00e4f\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "so doch die \u00c4hren st\u00e4rkre S\u00e4fte.", "tokens": ["so", "doch", "die", "\u00c4h\u00b7ren", "st\u00e4r\u00b7kre", "S\u00e4f\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "\u00dcber di\u00df steht Hybla hier,", "tokens": ["\u00dc\u00b7ber", "di\u00df", "steht", "Hy\u00b7bla", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VVFIN", "NE", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "die der Blumen g\u00f6ttlichs Wesen", "tokens": ["die", "der", "Blu\u00b7men", "g\u00f6tt\u00b7lichs", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "durch die Bienen ein l\u00e4\u00dft lesen", "tokens": ["durch", "die", "Bie\u00b7nen", "ein", "l\u00e4\u00dft", "le\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ART", "VVFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "und uns vorsetzt eine Zier,", "tokens": ["und", "uns", "vor\u00b7setzt", "ei\u00b7ne", "Zier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "die f\u00fcr Jupiters Getr\u00e4nken", "tokens": ["die", "f\u00fcr", "Ju\u00b7pi\u00b7ters", "Ge\u00b7tr\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ADJA", "NN"], "meter": "---+--+-", "measure": "iambic.di.relaxed"}, "line.6": {"text": "Ganymed pflegt einzuschenken.", "tokens": ["Ga\u00b7ny\u00b7med", "pflegt", "ein\u00b7zu\u00b7schen\u00b7ken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.39": {"line.1": {"text": "Wenn der Eurische Nordost", "tokens": ["Wenn", "der", "Eu\u00b7ri\u00b7sche", "Nord\u00b7ost"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "in die holen D\u00e4cher pfeifet,", "tokens": ["in", "die", "ho\u00b7len", "D\u00e4\u00b7cher", "pfei\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und es um die T\u00fcren reifet,", "tokens": ["und", "es", "um", "die", "T\u00fc\u00b7ren", "rei\u00b7fet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "wenn es dreht und Flocken schlo\u00dft,", "tokens": ["wenn", "es", "dreht", "und", "Flo\u00b7cken", "schlo\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "da\u00df wir fast nicht ohne Grauen", "tokens": ["da\u00df", "wir", "fast", "nicht", "oh\u00b7ne", "Grau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PTKNEG", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "f\u00fcr das kalte Fenster schauen:", "tokens": ["f\u00fcr", "das", "kal\u00b7te", "Fens\u00b7ter", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "denn so ist es mehr als recht,", "tokens": ["denn", "so", "ist", "es", "mehr", "als", "recht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PIAT", "KOKOM", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "da\u00df man sich zusammen setzet", "tokens": ["da\u00df", "man", "sich", "zu\u00b7sam\u00b7men", "set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "und bei warmer Lust ergetzet,", "tokens": ["und", "bei", "war\u00b7mer", "Lust", "er\u00b7get\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "da\u00df man singet, tanzt und zecht", "tokens": ["da\u00df", "man", "sin\u00b7get", ",", "tanzt", "und", "zecht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "$,", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und mehr, wenn wir uns zu laben,", "tokens": ["und", "mehr", ",", "wenn", "wir", "uns", "zu", "la\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "wie anitzo, Ursach' haben.", "tokens": ["wie", "a\u00b7nit\u00b7zo", ",", "Ur\u00b7sach'", "ha\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADV", "$,", "NN", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Itzt zumal, da kein Gott fast", "tokens": ["Itzt", "zu\u00b7mal", ",", "da", "kein", "Gott", "fast"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PIAT", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "au\u00dfer \u00c4oln auf der Erden", "tokens": ["au\u00b7\u00dfer", "\u00c4\u00b7oln", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "leichtlich kan gesp\u00fcret werden.", "tokens": ["leicht\u00b7lich", "kan", "ge\u00b7sp\u00fc\u00b7ret", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle lieben ihre Rast.", "tokens": ["Al\u00b7le", "lie\u00b7ben", "ih\u00b7re", "Rast", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Selbst der F\u00fcrst des Tagelichtes", "tokens": ["Selbst", "der", "F\u00fcrst", "des", "Ta\u00b7ge\u00b7lich\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "w\u00fcrdigt uns kaum des Gesichtes.", "tokens": ["w\u00fcr\u00b7digt", "uns", "kaum", "des", "Ge\u00b7sich\u00b7tes", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}}, "stanza.42": {"line.1": {"text": "Mars hat ihm Quartier gesucht,", "tokens": ["Mars", "hat", "ihm", "Quar\u00b7tier", "ge\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "NN", "VVPP", "$,"], "meter": "-+-++-+", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Delie l\u00e4st P\u00fcsch' und H\u00f6hen,", "tokens": ["De\u00b7lie", "l\u00e4st", "P\u00fcsch'", "und", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mulciber den Ambos stehen,", "tokens": ["Mul\u00b7ci\u00b7ber", "den", "Am\u00b7bos", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ceres zehrt von ihrer Frucht.", "tokens": ["Ce\u00b7res", "zehrt", "von", "ih\u00b7rer", "Frucht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sie sind Tag f\u00fcr Tag zu Gaste", "tokens": ["Sie", "sind", "Tag", "f\u00fcr", "Tag", "zu", "Gas\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "APPR", "NN", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "in Diespiters Palaste.", "tokens": ["in", "Dies\u00b7pi\u00b7ters", "Pa\u00b7las\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.43": {"line.1": {"text": "Venus und ihr kleiner Sohn", "tokens": ["Ve\u00b7nus", "und", "ihr", "klei\u00b7ner", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "sind auf Erden eingefroren,", "tokens": ["sind", "auf", "Er\u00b7den", "ein\u00b7ge\u00b7fro\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "haben Zeit und Weg verloren", "tokens": ["ha\u00b7ben", "Zeit", "und", "Weg", "ver\u00b7lo\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "zu der Sternen ihrem Thron", "tokens": ["zu", "der", "Ster\u00b7nen", "ih\u00b7rem", "Thron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und stehn hier uns anzusinnen,", "tokens": ["und", "stehn", "hier", "uns", "an\u00b7zu\u00b7sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PPER", "VVIZU", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "wo sie mit uns wintern k\u00f6nnen.", "tokens": ["wo", "sie", "mit", "uns", "win\u00b7tern", "k\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.44": {"line.1": {"text": "Fangt denn an, Herr, aufzustehn", "tokens": ["Fangt", "denn", "an", ",", "Herr", ",", "auf\u00b7zu\u00b7stehn"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "NN", "$,", "VVINF"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "und la\u00dft Schalen, Schiff' und Trauben", "tokens": ["und", "la\u00dft", "Scha\u00b7len", ",", "Schiff'", "und", "Trau\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "recht auf ", "tokens": ["recht", "auf"], "token_info": ["word", "word"], "pos": ["ADV", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "rund um unser' Tafel gehn,", "tokens": ["rund", "um", "un\u00b7ser'", "Ta\u00b7fel", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "bis nicht Einen mehr wird d\u00fcrsten!", "tokens": ["bis", "nicht", "Ei\u00b7nen", "mehr", "wird", "d\u00fcrs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "ADV", "VAFIN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auf Gesundheit unsers F\u00fcrsten!", "tokens": ["Auf", "Ge\u00b7sund\u00b7heit", "un\u00b7sers", "F\u00fcrs\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}