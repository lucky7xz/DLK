{"textgrid.poem.40020": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als meine Kinder einst, vor wenig Tagen,", "genre": "verse", "period": "N.A.", "pub_year": 1713, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als meine Kinder einst, vor wenig Tagen,", "tokens": ["Als", "mei\u00b7ne", "Kin\u00b7der", "einst", ",", "vor", "we\u00b7nig", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da es noch ziemlich fr\u00fch, in sanfter Ruhe lagen,", "tokens": ["Da", "es", "noch", "ziem\u00b7lich", "fr\u00fch", ",", "in", "sanf\u00b7ter", "Ru\u00b7he", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ich, um sie vom Schlafe zu erwecken,", "tokens": ["Und", "ich", ",", "um", "sie", "vom", "Schla\u00b7fe", "zu", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUI", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Selbst in die Kammer trat; sah ich sie, voll Vergn\u00fcgen,", "tokens": ["Selbst", "in", "die", "Kam\u00b7mer", "trat", ";", "sah", "ich", "sie", ",", "voll", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$.", "VVFIN", "PPER", "PPER", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Von lauem Schwei\u00df gef\u00e4rbt, in s\u00fcsser R\u00f6the liegen,", "tokens": ["Von", "lau\u00b7em", "Schwei\u00df", "ge\u00b7f\u00e4rbt", ",", "in", "s\u00fcs\u00b7ser", "R\u00f6\u00b7the", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, wie die Rosen, bl\u00fchn. Theils hatten sie die Decken", "tokens": ["Und", ",", "wie", "die", "Ro\u00b7sen", ",", "bl\u00fchn", ".", "Theils", "hat\u00b7ten", "sie", "die", "De\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "VVFIN", "$.", "NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Im Schlafe von sich weggeschoben,", "tokens": ["Im", "Schla\u00b7fe", "von", "sich", "weg\u00b7ge\u00b7scho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier hatt' ein kleiner Arm sich um sein Haupt gelenckt,", "tokens": ["Hier", "hatt'", "ein", "klei\u00b7ner", "Arm", "sich", "um", "sein", "Haupt", "ge\u00b7lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein andrer lag auf seinem Pf\u00fcl erhoben,", "tokens": ["Ein", "an\u00b7drer", "lag", "auf", "sei\u00b7nem", "Pf\u00fcl", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Dort waren zwey mit Hand und Bein verschr\u00e4nckt,", "tokens": ["Dort", "wa\u00b7ren", "zwey", "mit", "Hand", "und", "Bein", "ver\u00b7schr\u00e4nckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "CARD", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ein Aermchen ruh'te dort auf seines Bruders Brust,", "tokens": ["Ein", "A\u00b7erm\u00b7chen", "ruh'\u00b7te", "dort", "auf", "sei\u00b7nes", "Bru\u00b7ders", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.12": {"text": "Wie es der Zufall gab. Ich sahe sie mit Lust,", "tokens": ["Wie", "es", "der", "Zu\u00b7fall", "gab", ".", "Ich", "sa\u00b7he", "sie", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich danckte Gott, da\u00df er sie so gesund geschaffen,", "tokens": ["Ich", "danck\u00b7te", "Gott", ",", "da\u00df", "er", "sie", "so", "ge\u00b7sund", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auch da\u00df sie, durch desselben Macht,", "tokens": ["Auch", "da\u00df", "sie", ",", "durch", "des\u00b7sel\u00b7ben", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So wohl, als ich, die gantze Nacht", "tokens": ["So", "wohl", ",", "als", "ich", ",", "die", "gant\u00b7ze", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So sanft, so ruhig k\u00f6nnen schlafen.", "tokens": ["So", "sanft", ",", "so", "ru\u00b7hig", "k\u00f6n\u00b7nen", "schla\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Kaum rief ich ihnen zu: Auf! als ich sie", "tokens": ["Kaum", "rief", "ich", "ih\u00b7nen", "zu", ":", "Auf", "!", "als", "ich", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$.", "APPR", "$.", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So bald, den Schlummer zu vertreiben,", "tokens": ["So", "bald", ",", "den", "Schlum\u00b7mer", "zu", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zugleich besch\u00e4fftigt sah. Doch wollte, sonder M\u00fch',", "tokens": ["Zu\u00b7gleich", "be\u00b7sch\u00e4ff\u00b7tigt", "sah", ".", "Doch", "woll\u00b7te", ",", "son\u00b7der", "M\u00fch'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVFIN", "$.", "KON", "VMFIN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der tr\u00e4ge Schlaf nicht fort; ein sanftes Augen-Reiben", "tokens": ["Der", "tr\u00e4\u00b7ge", "Schlaf", "nicht", "fort", ";", "ein", "sanf\u00b7tes", "Au\u00b7gen\u00b7Rei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erhub sich \u00fcberall. Hier streckt' ein Aermchen sich,", "tokens": ["Er\u00b7hub", "sich", "\u00fc\u00b7be\u00b7rall", ".", "Hier", "streckt'", "ein", "A\u00b7erm\u00b7chen", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Und dort ein kleines Bein.", "tokens": ["Und", "dort", "ein", "klei\u00b7nes", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Hier sahe mich", "tokens": ["Hier", "sa\u00b7he", "mich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Von dieser kleinen Schaar", "tokens": ["Von", "die\u00b7ser", "klei\u00b7nen", "Schaar"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ein halb ge\u00f6ffnet Aug', indem des Tages Schein", "tokens": ["Ein", "halb", "ge\u00b7\u00f6ff\u00b7net", "Aug'", ",", "in\u00b7dem", "des", "Ta\u00b7ges", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVPP", "NN", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihn anfangs blendete, mit holdem L\u00e4cheln zwar,", "tokens": ["Ihn", "an\u00b7fangs", "blen\u00b7de\u00b7te", ",", "mit", "hol\u00b7dem", "L\u00e4\u00b7cheln", "zwar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch kurtzen Blicken an. Ich h\u00f6rete von allen", "tokens": ["Doch", "kurt\u00b7zen", "Bli\u00b7cken", "an", ".", "Ich", "h\u00f6\u00b7re\u00b7te", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein froh verwirrt Papa! Papa! erschallen.", "tokens": ["Ein", "froh", "ver\u00b7wirrt", "Pa\u00b7pa", "!", "Pa\u00b7pa", "!", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$.", "NN", "$.", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Auf! rief ich, lasst mich sehn, wer von euch kann", "tokens": ["Auf", "!", "rief", "ich", ",", "lasst", "mich", "sehn", ",", "wer", "von", "euch", "kann"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "VVINF", "$,", "PWS", "APPR", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Am ersten angethan,", "tokens": ["Am", "ers\u00b7ten", "an\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am schnellsten fertig werden.", "tokens": ["Am", "schnells\u00b7ten", "fer\u00b7tig", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJD", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich war der Schlummer fort, ein \u00e4msiges Gew\u00fchl,", "tokens": ["Gleich", "war", "der", "Schlum\u00b7mer", "fort", ",", "ein", "\u00e4m\u00b7si\u00b7ges", "Ge\u00b7w\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das jedem, der es sah, gefiel,", "tokens": ["Das", "je\u00b7dem", ",", "der", "es", "sah", ",", "ge\u00b7fiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erhub sich \u00fcberall; sie sprungen von der Erden,", "tokens": ["Er\u00b7hub", "sich", "\u00fc\u00b7be\u00b7rall", ";", "sie", "sprun\u00b7gen", "von", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, eh' ich's mich versah,", "tokens": ["Und", ",", "eh'", "ich's", "mich", "ver\u00b7sah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Stund alles fertig da.", "tokens": ["Stund", "al\u00b7les", "fer\u00b7tig", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mir fiel hier\u00fcber folgends ein:", "tokens": ["Mir", "fiel", "hier\u00b7\u00fc\u00b7ber", "fol\u00b7gends", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wie n\u00fctzlich und wie gut in unserm Leben", "tokens": ["Wie", "n\u00fctz\u00b7lich", "und", "wie", "gut", "in", "un\u00b7serm", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KON", "PWAV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Leidenschaften seyn;", "tokens": ["Die", "Lei\u00b7den\u00b7schaf\u00b7ten", "seyn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Davon kann dieses Kinder-Spiel", "tokens": ["Da\u00b7von", "kann", "die\u00b7ses", "Kin\u00b7der\u00b7Spiel"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir eine gute Nachricht geben.", "tokens": ["Mir", "ei\u00b7ne", "gu\u00b7te", "Nach\u00b7richt", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Welch eine Schl\u00e4frigkeit w\u00fcrd' an dem Menschen kleben,", "tokens": ["Welch", "ei\u00b7ne", "Schl\u00e4f\u00b7rig\u00b7keit", "w\u00fcrd'", "an", "dem", "Men\u00b7schen", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie tr\u00e4g' und ungeschickt w\u00fcrd' er zu allem seyn,", "tokens": ["Wie", "tr\u00e4g'", "und", "un\u00b7ge\u00b7schickt", "w\u00fcrd'", "er", "zu", "al\u00b7lem", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "KON", "ADJD", "VAFIN", "PPER", "APPR", "PIS", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn eine Leidenschaft, zumahl der Trieb zur Ehre,", "tokens": ["Wenn", "ei\u00b7ne", "Lei\u00b7den\u00b7schaft", ",", "zu\u00b7mahl", "der", "Trieb", "zur", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht bey uns Menschen w\u00e4re.", "tokens": ["Nicht", "bey", "uns", "Men\u00b7schen", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es fliesst hieraus noch eine Lehre:", "tokens": ["Es", "fliesst", "hier\u00b7aus", "noch", "ei\u00b7ne", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ob gleich wir Menschen schwach und unverm\u00f6gend heissen;", "tokens": ["Ob", "gleich", "wir", "Men\u00b7schen", "schwach", "und", "un\u00b7ver\u00b7m\u00f6\u00b7gend", "heis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So sind wir doch geschickter, als man denckt,", "tokens": ["So", "sind", "wir", "doch", "ge\u00b7schick\u00b7ter", ",", "als", "man", "denckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Uns dem Gewohnheits-Schlaf und Schlummer zu entreissen,", "tokens": ["Uns", "dem", "Ge\u00b7wohn\u00b7heits\u00b7Schlaf", "und", "Schlum\u00b7mer", "zu", "en\u00b7treis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn man die Sinne nur auf einen Vorwurf lenckt,", "tokens": ["Wenn", "man", "die", "Sin\u00b7ne", "nur", "auf", "ei\u00b7nen", "Vor\u00b7wurf", "lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der uns gef\u00e4llig ist: Man wird viel Unvergn\u00fcgen", "tokens": ["Der", "uns", "ge\u00b7f\u00e4l\u00b7lig", "ist", ":", "Man", "wird", "viel", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VAFIN", "$.", "PIS", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Hinderni\u00df geschickt seyn zu besiegen,", "tokens": ["Und", "Hin\u00b7der\u00b7ni\u00df", "ge\u00b7schickt", "seyn", "zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "VAINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Mehr als man selbst geglaubt.", "tokens": ["Mehr", "als", "man", "selbst", "ge\u00b7glaubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sprich nicht: Die\u00df Gleichni\u00df hier vom Schlafe geht nicht an,", "tokens": ["Sprich", "nicht", ":", "Die\u00df", "Gleich\u00b7ni\u00df", "hier", "vom", "Schla\u00b7fe", "geht", "nicht", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKNEG", "$.", "PDS", "NN", "ADV", "APPRART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil man denselbigen, des Morgens, leicht bekriegen,", "tokens": ["Weil", "man", "den\u00b7sel\u00b7bi\u00b7gen", ",", "des", "Mor\u00b7gens", ",", "leicht", "be\u00b7krie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDS", "$,", "ART", "ADV", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und, durch geringen Zwang, vertreiben kann,", "tokens": ["Und", ",", "durch", "ge\u00b7rin\u00b7gen", "Zwang", ",", "ver\u00b7trei\u00b7ben", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ADJA", "NN", "$,", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Da er sich ohnedem hinweg pflegt zu verf\u00fcgen;", "tokens": ["Da", "er", "sich", "oh\u00b7ne\u00b7dem", "hin\u00b7weg", "pflegt", "zu", "ver\u00b7f\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "APZR", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn der Gewohnheits-Schlaf hingegen", "tokens": ["Wenn", "der", "Ge\u00b7wohn\u00b7heits\u00b7Schlaf", "hin\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Best\u00e4ndig an uns klebt, und immer z\u00e4her wird.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "an", "uns", "klebt", ",", "und", "im\u00b7mer", "z\u00e4\u00b7her", "wird", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "$,", "KON", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df scheint zwar wahr zu seyn; Doch, wenn wir's recht erwegen,", "tokens": ["Die\u00df", "scheint", "zwar", "wahr", "zu", "seyn", ";", "Doch", ",", "wenn", "wir's", "recht", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "PTKZU", "VAINF", "$.", "KON", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So hast du dich dennoch geirrt.", "tokens": ["So", "hast", "du", "dich", "den\u00b7noch", "ge\u00b7irrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ob durch Gewohnheit gleich die Leidenschaft", "tokens": ["Ob", "durch", "Ge\u00b7wohn\u00b7heit", "gleich", "die", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Noch immer st\u00e4rcker wird; kann gleichwohl ihre Kraft", "tokens": ["Noch", "im\u00b7mer", "st\u00e4r\u00b7cker", "wird", ";", "kann", "gleich\u00b7wohl", "ih\u00b7re", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "$.", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die gegenseitige Gewohnheit wieder d\u00e4mpfen.", "tokens": ["Die", "ge\u00b7gen\u00b7sei\u00b7ti\u00b7ge", "Ge\u00b7wohn\u00b7heit", "wie\u00b7der", "d\u00e4mp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es liegt, in diesem Fall, am festen Vorsatz viel.", "tokens": ["Es", "liegt", ",", "in", "die\u00b7sem", "Fall", ",", "am", "fes\u00b7ten", "Vor\u00b7satz", "viel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PDAT", "NN", "$,", "APPRART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Fang' du nur tapfer an, und fahre fort zu k\u00e4mpfen!", "tokens": ["Fang'", "du", "nur", "tap\u00b7fer", "an", ",", "und", "fah\u00b7re", "fort", "zu", "k\u00e4mp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du kommst zuletzt gewi\u00df zum vorgesteckten Ziel.", "tokens": ["Du", "kommst", "zu\u00b7letzt", "ge\u00b7wi\u00df", "zum", "vor\u00b7ge\u00b7steck\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Als meine Kinder einst, vor wenig Tagen,", "tokens": ["Als", "mei\u00b7ne", "Kin\u00b7der", "einst", ",", "vor", "we\u00b7nig", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da es noch ziemlich fr\u00fch, in sanfter Ruhe lagen,", "tokens": ["Da", "es", "noch", "ziem\u00b7lich", "fr\u00fch", ",", "in", "sanf\u00b7ter", "Ru\u00b7he", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ich, um sie vom Schlafe zu erwecken,", "tokens": ["Und", "ich", ",", "um", "sie", "vom", "Schla\u00b7fe", "zu", "er\u00b7we\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "KOUI", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Selbst in die Kammer trat; sah ich sie, voll Vergn\u00fcgen,", "tokens": ["Selbst", "in", "die", "Kam\u00b7mer", "trat", ";", "sah", "ich", "sie", ",", "voll", "Ver\u00b7gn\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$.", "VVFIN", "PPER", "PPER", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+---+-+-", "measure": "unknown.measure.penta"}, "line.5": {"text": "Von lauem Schwei\u00df gef\u00e4rbt, in s\u00fcsser R\u00f6the liegen,", "tokens": ["Von", "lau\u00b7em", "Schwei\u00df", "ge\u00b7f\u00e4rbt", ",", "in", "s\u00fcs\u00b7ser", "R\u00f6\u00b7the", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und, wie die Rosen, bl\u00fchn. Theils hatten sie die Decken", "tokens": ["Und", ",", "wie", "die", "Ro\u00b7sen", ",", "bl\u00fchn", ".", "Theils", "hat\u00b7ten", "sie", "die", "De\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "VVFIN", "$.", "NN", "VAFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Im Schlafe von sich weggeschoben,", "tokens": ["Im", "Schla\u00b7fe", "von", "sich", "weg\u00b7ge\u00b7scho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier hatt' ein kleiner Arm sich um sein Haupt gelenckt,", "tokens": ["Hier", "hatt'", "ein", "klei\u00b7ner", "Arm", "sich", "um", "sein", "Haupt", "ge\u00b7lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PRF", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein andrer lag auf seinem Pf\u00fcl erhoben,", "tokens": ["Ein", "an\u00b7drer", "lag", "auf", "sei\u00b7nem", "Pf\u00fcl", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Dort waren zwey mit Hand und Bein verschr\u00e4nckt,", "tokens": ["Dort", "wa\u00b7ren", "zwey", "mit", "Hand", "und", "Bein", "ver\u00b7schr\u00e4nckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "CARD", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Ein Aermchen ruh'te dort auf seines Bruders Brust,", "tokens": ["Ein", "A\u00b7erm\u00b7chen", "ruh'\u00b7te", "dort", "auf", "sei\u00b7nes", "Bru\u00b7ders", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.12": {"text": "Wie es der Zufall gab. Ich sahe sie mit Lust,", "tokens": ["Wie", "es", "der", "Zu\u00b7fall", "gab", ".", "Ich", "sa\u00b7he", "sie", "mit", "Lust", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ich danckte Gott, da\u00df er sie so gesund geschaffen,", "tokens": ["Ich", "danck\u00b7te", "Gott", ",", "da\u00df", "er", "sie", "so", "ge\u00b7sund", "ge\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Auch da\u00df sie, durch desselben Macht,", "tokens": ["Auch", "da\u00df", "sie", ",", "durch", "des\u00b7sel\u00b7ben", "Macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So wohl, als ich, die gantze Nacht", "tokens": ["So", "wohl", ",", "als", "ich", ",", "die", "gant\u00b7ze", "Nacht"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "So sanft, so ruhig k\u00f6nnen schlafen.", "tokens": ["So", "sanft", ",", "so", "ru\u00b7hig", "k\u00f6n\u00b7nen", "schla\u00b7fen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Kaum rief ich ihnen zu: Auf! als ich sie", "tokens": ["Kaum", "rief", "ich", "ih\u00b7nen", "zu", ":", "Auf", "!", "als", "ich", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$.", "APPR", "$.", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So bald, den Schlummer zu vertreiben,", "tokens": ["So", "bald", ",", "den", "Schlum\u00b7mer", "zu", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zugleich besch\u00e4fftigt sah. Doch wollte, sonder M\u00fch',", "tokens": ["Zu\u00b7gleich", "be\u00b7sch\u00e4ff\u00b7tigt", "sah", ".", "Doch", "woll\u00b7te", ",", "son\u00b7der", "M\u00fch'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VVFIN", "$.", "KON", "VMFIN", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der tr\u00e4ge Schlaf nicht fort; ein sanftes Augen-Reiben", "tokens": ["Der", "tr\u00e4\u00b7ge", "Schlaf", "nicht", "fort", ";", "ein", "sanf\u00b7tes", "Au\u00b7gen\u00b7Rei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Erhub sich \u00fcberall. Hier streckt' ein Aermchen sich,", "tokens": ["Er\u00b7hub", "sich", "\u00fc\u00b7be\u00b7rall", ".", "Hier", "streckt'", "ein", "A\u00b7erm\u00b7chen", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$.", "ADV", "VVFIN", "ART", "NN", "PRF", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Und dort ein kleines Bein.", "tokens": ["Und", "dort", "ein", "klei\u00b7nes", "Bein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Hier sahe mich", "tokens": ["Hier", "sa\u00b7he", "mich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Von dieser kleinen Schaar", "tokens": ["Von", "die\u00b7ser", "klei\u00b7nen", "Schaar"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Ein halb ge\u00f6ffnet Aug', indem des Tages Schein", "tokens": ["Ein", "halb", "ge\u00b7\u00f6ff\u00b7net", "Aug'", ",", "in\u00b7dem", "des", "Ta\u00b7ges", "Schein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVPP", "NN", "$,", "KOUS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Ihn anfangs blendete, mit holdem L\u00e4cheln zwar,", "tokens": ["Ihn", "an\u00b7fangs", "blen\u00b7de\u00b7te", ",", "mit", "hol\u00b7dem", "L\u00e4\u00b7cheln", "zwar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "APPR", "ADJA", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Doch kurtzen Blicken an. Ich h\u00f6rete von allen", "tokens": ["Doch", "kurt\u00b7zen", "Bli\u00b7cken", "an", ".", "Ich", "h\u00f6\u00b7re\u00b7te", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Ein froh verwirrt Papa! Papa! erschallen.", "tokens": ["Ein", "froh", "ver\u00b7wirrt", "Pa\u00b7pa", "!", "Pa\u00b7pa", "!", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "$.", "NN", "$.", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Auf! rief ich, lasst mich sehn, wer von euch kann", "tokens": ["Auf", "!", "rief", "ich", ",", "lasst", "mich", "sehn", ",", "wer", "von", "euch", "kann"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "$.", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "VVINF", "$,", "PWS", "APPR", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Am ersten angethan,", "tokens": ["Am", "ers\u00b7ten", "an\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Am schnellsten fertig werden.", "tokens": ["Am", "schnells\u00b7ten", "fer\u00b7tig", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ADJD", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich war der Schlummer fort, ein \u00e4msiges Gew\u00fchl,", "tokens": ["Gleich", "war", "der", "Schlum\u00b7mer", "fort", ",", "ein", "\u00e4m\u00b7si\u00b7ges", "Ge\u00b7w\u00fchl", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das jedem, der es sah, gefiel,", "tokens": ["Das", "je\u00b7dem", ",", "der", "es", "sah", ",", "ge\u00b7fiel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erhub sich \u00fcberall; sie sprungen von der Erden,", "tokens": ["Er\u00b7hub", "sich", "\u00fc\u00b7be\u00b7rall", ";", "sie", "sprun\u00b7gen", "von", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, eh' ich's mich versah,", "tokens": ["Und", ",", "eh'", "ich's", "mich", "ver\u00b7sah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Stund alles fertig da.", "tokens": ["Stund", "al\u00b7les", "fer\u00b7tig", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Mir fiel hier\u00fcber folgends ein:", "tokens": ["Mir", "fiel", "hier\u00b7\u00fc\u00b7ber", "fol\u00b7gends", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Wie n\u00fctzlich und wie gut in unserm Leben", "tokens": ["Wie", "n\u00fctz\u00b7lich", "und", "wie", "gut", "in", "un\u00b7serm", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KON", "PWAV", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Leidenschaften seyn;", "tokens": ["Die", "Lei\u00b7den\u00b7schaf\u00b7ten", "seyn", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Davon kann dieses Kinder-Spiel", "tokens": ["Da\u00b7von", "kann", "die\u00b7ses", "Kin\u00b7der\u00b7Spiel"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mir eine gute Nachricht geben.", "tokens": ["Mir", "ei\u00b7ne", "gu\u00b7te", "Nach\u00b7richt", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Welch eine Schl\u00e4frigkeit w\u00fcrd' an dem Menschen kleben,", "tokens": ["Welch", "ei\u00b7ne", "Schl\u00e4f\u00b7rig\u00b7keit", "w\u00fcrd'", "an", "dem", "Men\u00b7schen", "kle\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie tr\u00e4g' und ungeschickt w\u00fcrd' er zu allem seyn,", "tokens": ["Wie", "tr\u00e4g'", "und", "un\u00b7ge\u00b7schickt", "w\u00fcrd'", "er", "zu", "al\u00b7lem", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "KON", "ADJD", "VAFIN", "PPER", "APPR", "PIS", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn eine Leidenschaft, zumahl der Trieb zur Ehre,", "tokens": ["Wenn", "ei\u00b7ne", "Lei\u00b7den\u00b7schaft", ",", "zu\u00b7mahl", "der", "Trieb", "zur", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "KOUS", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Nicht bey uns Menschen w\u00e4re.", "tokens": ["Nicht", "bey", "uns", "Men\u00b7schen", "w\u00e4\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Es fliesst hieraus noch eine Lehre:", "tokens": ["Es", "fliesst", "hier\u00b7aus", "noch", "ei\u00b7ne", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ob gleich wir Menschen schwach und unverm\u00f6gend heissen;", "tokens": ["Ob", "gleich", "wir", "Men\u00b7schen", "schwach", "und", "un\u00b7ver\u00b7m\u00f6\u00b7gend", "heis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "NN", "ADJD", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So sind wir doch geschickter, als man denckt,", "tokens": ["So", "sind", "wir", "doch", "ge\u00b7schick\u00b7ter", ",", "als", "man", "denckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Uns dem Gewohnheits-Schlaf und Schlummer zu entreissen,", "tokens": ["Uns", "dem", "Ge\u00b7wohn\u00b7heits\u00b7Schlaf", "und", "Schlum\u00b7mer", "zu", "en\u00b7treis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn man die Sinne nur auf einen Vorwurf lenckt,", "tokens": ["Wenn", "man", "die", "Sin\u00b7ne", "nur", "auf", "ei\u00b7nen", "Vor\u00b7wurf", "lenckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der uns gef\u00e4llig ist: Man wird viel Unvergn\u00fcgen", "tokens": ["Der", "uns", "ge\u00b7f\u00e4l\u00b7lig", "ist", ":", "Man", "wird", "viel", "Un\u00b7ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VAFIN", "$.", "PIS", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und Hinderni\u00df geschickt seyn zu besiegen,", "tokens": ["Und", "Hin\u00b7der\u00b7ni\u00df", "ge\u00b7schickt", "seyn", "zu", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "VAINF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Mehr als man selbst geglaubt.", "tokens": ["Mehr", "als", "man", "selbst", "ge\u00b7glaubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "KOKOM", "PIS", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Sprich nicht: Die\u00df Gleichni\u00df hier vom Schlafe geht nicht an,", "tokens": ["Sprich", "nicht", ":", "Die\u00df", "Gleich\u00b7ni\u00df", "hier", "vom", "Schla\u00b7fe", "geht", "nicht", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKNEG", "$.", "PDS", "NN", "ADV", "APPRART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil man denselbigen, des Morgens, leicht bekriegen,", "tokens": ["Weil", "man", "den\u00b7sel\u00b7bi\u00b7gen", ",", "des", "Mor\u00b7gens", ",", "leicht", "be\u00b7krie\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PDS", "$,", "ART", "ADV", "$,", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und, durch geringen Zwang, vertreiben kann,", "tokens": ["Und", ",", "durch", "ge\u00b7rin\u00b7gen", "Zwang", ",", "ver\u00b7trei\u00b7ben", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ADJA", "NN", "$,", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Da er sich ohnedem hinweg pflegt zu verf\u00fcgen;", "tokens": ["Da", "er", "sich", "oh\u00b7ne\u00b7dem", "hin\u00b7weg", "pflegt", "zu", "ver\u00b7f\u00fc\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "APZR", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wenn der Gewohnheits-Schlaf hingegen", "tokens": ["Wenn", "der", "Ge\u00b7wohn\u00b7heits\u00b7Schlaf", "hin\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Best\u00e4ndig an uns klebt, und immer z\u00e4her wird.", "tokens": ["Be\u00b7st\u00e4n\u00b7dig", "an", "uns", "klebt", ",", "und", "im\u00b7mer", "z\u00e4\u00b7her", "wird", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPER", "VVFIN", "$,", "KON", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df scheint zwar wahr zu seyn; Doch, wenn wir's recht erwegen,", "tokens": ["Die\u00df", "scheint", "zwar", "wahr", "zu", "seyn", ";", "Doch", ",", "wenn", "wir's", "recht", "er\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "PTKZU", "VAINF", "$.", "KON", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So hast du dich dennoch geirrt.", "tokens": ["So", "hast", "du", "dich", "den\u00b7noch", "ge\u00b7irrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ob durch Gewohnheit gleich die Leidenschaft", "tokens": ["Ob", "durch", "Ge\u00b7wohn\u00b7heit", "gleich", "die", "Lei\u00b7den\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "NN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Noch immer st\u00e4rcker wird; kann gleichwohl ihre Kraft", "tokens": ["Noch", "im\u00b7mer", "st\u00e4r\u00b7cker", "wird", ";", "kann", "gleich\u00b7wohl", "ih\u00b7re", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADJD", "VAFIN", "$.", "VMFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die gegenseitige Gewohnheit wieder d\u00e4mpfen.", "tokens": ["Die", "ge\u00b7gen\u00b7sei\u00b7ti\u00b7ge", "Ge\u00b7wohn\u00b7heit", "wie\u00b7der", "d\u00e4mp\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es liegt, in diesem Fall, am festen Vorsatz viel.", "tokens": ["Es", "liegt", ",", "in", "die\u00b7sem", "Fall", ",", "am", "fes\u00b7ten", "Vor\u00b7satz", "viel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPR", "PDAT", "NN", "$,", "APPRART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Fang' du nur tapfer an, und fahre fort zu k\u00e4mpfen!", "tokens": ["Fang'", "du", "nur", "tap\u00b7fer", "an", ",", "und", "fah\u00b7re", "fort", "zu", "k\u00e4mp\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du kommst zuletzt gewi\u00df zum vorgesteckten Ziel.", "tokens": ["Du", "kommst", "zu\u00b7letzt", "ge\u00b7wi\u00df", "zum", "vor\u00b7ge\u00b7steck\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}