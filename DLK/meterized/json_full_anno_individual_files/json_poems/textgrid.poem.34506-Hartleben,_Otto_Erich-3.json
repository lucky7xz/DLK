{"textgrid.poem.34506": {"metadata": {"author": {"name": "Hartleben, Otto Erich", "birth": "N.A.", "death": "N.A."}, "title": "3", "genre": "verse", "period": "N.A.", "pub_year": 1884, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und am andern Morgen in der Fr\u00fche", "tokens": ["Und", "am", "an\u00b7dern", "Mor\u00b7gen", "in", "der", "Fr\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "stand der K\u00f6nig auf und ging mit Daniel", "tokens": ["stand", "der", "K\u00f6\u00b7nig", "auf", "und", "ging", "mit", "Da\u00b7ni\u00b7el"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "vor den Tempel. Und der K\u00f6nig fragte:", "tokens": ["vor", "den", "Tem\u00b7pel", ".", "Und", "der", "K\u00f6\u00b7nig", "frag\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "KON", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ist das Siegel unversehrt?", "tokens": ["Ist", "das", "Sie\u00b7gel", "un\u00b7ver\u00b7sehrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das Siegel", "tokens": ["Das", "Sie\u00b7gel"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "hat kein Mensch ber\u00fchrt, versetzte Daniel.", "tokens": ["hat", "kein", "Mensch", "be\u00b7r\u00fchrt", ",", "ver\u00b7setz\u00b7te", "Da\u00b7ni\u00b7el", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$,", "VVFIN", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.2": {"line.1": {"text": "Und die Th\u00fcr sprang auf. Leer war der Altar.", "tokens": ["Und", "die", "Th\u00fcr", "sprang", "auf", ".", "Leer", "war", "der", "Al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$.", "NE", "VAFIN", "ART", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Cyrus aber rief mit lauter Stimme:", "tokens": ["Cy\u00b7rus", "a\u00b7ber", "rief", "mit", "lau\u00b7ter", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Baal, du bist ein grosser Gott! Bei dir ist", "tokens": ["Baal", ",", "du", "bist", "ein", "gros\u00b7ser", "Gott", "!", "Bei", "dir", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "APPR", "PPER", "VAFIN"], "meter": "+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.4": {"text": "kein Betrug! Verzeih mir! Und er wollte", "tokens": ["kein", "Be\u00b7trug", "!", "Ver\u00b7zeih", "mir", "!", "Und", "er", "woll\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$.", "VVIMP", "PPER", "$.", "KON", "PPER", "VMFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "vorw\u00e4rts eilen.", "tokens": ["vor\u00b7w\u00e4rts", "ei\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Halt!, rief Daniel lachend:", "tokens": ["Halt", "!", ",", "rief", "Da\u00b7ni\u00b7el", "la\u00b7chend", ":"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "$,", "VVFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Halt, mein K\u00f6nig, warte nur ein wenig.", "tokens": ["Halt", ",", "mein", "K\u00f6\u00b7nig", ",", "war\u00b7te", "nur", "ein", "we\u00b7nig", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "ART", "PIS", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Siehe dort! Was siehst du auf dem Boden?", "tokens": ["Sie\u00b7he", "dort", "!", "Was", "siehst", "du", "auf", "dem", "Bo\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Wes sind diese Stapfen?", "tokens": ["Wes", "sind", "die\u00b7se", "Stap\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PDAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Und der K\u00f6nig", "tokens": ["Und", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.2": {"text": "sah und sprach: Ich sehe wohl die Tritte.", "tokens": ["sah", "und", "sprach", ":", "Ich", "se\u00b7he", "wohl", "die", "Trit\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "M\u00e4nner gingen aus und ein und Weiber,", "tokens": ["M\u00e4n\u00b7ner", "gin\u00b7gen", "aus", "und", "ein", "und", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "ART", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Kinder auch ...", "tokens": ["Kin\u00b7der", "auch", "..."], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Und siehst du auch, woher sie", "tokens": ["Und", "siehst", "du", "auch", ",", "wo\u00b7her", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "alle kamen und wohin sie laufen?", "tokens": ["al\u00b7le", "ka\u00b7men", "und", "wo\u00b7hin", "sie", "lau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "PWAV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "In den grossen Bauch des grossen Baal! Dort", "tokens": ["In", "den", "gros\u00b7sen", "Bauch", "des", "gros\u00b7sen", "Baal", "!", "Dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$.", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "m\u00fcndet ein geheimer Gang ... Ja, K\u00f6nig:", "tokens": ["m\u00fcn\u00b7det", "ein", "ge\u00b7hei\u00b7mer", "Gang", "...", "Ja", ",", "K\u00f6\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "PTKANT", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "was der G\u00f6tze frisst, verdaut der Priester!", "tokens": ["was", "der", "G\u00f6t\u00b7ze", "frisst", ",", "ver\u00b7daut", "der", "Pries\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Da ergrimmte Cyrus! Alle Priester", "tokens": ["Da", "er\u00b7grimm\u00b7te", "Cy\u00b7rus", "!", "Al\u00b7le", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$.", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "liess er fangen. Und noch einmal mussten", "tokens": ["liess", "er", "fan\u00b7gen", ".", "Und", "noch", "ein\u00b7mal", "muss\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN", "$.", "KON", "ADV", "ADV", "VMFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "sie mit Weib und Kindern durch die H\u00f6hle", "tokens": ["sie", "mit", "Weib", "und", "Kin\u00b7dern", "durch", "die", "H\u00f6h\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "in den Tempel kriechen \u2013 statt der vierzig", "tokens": ["in", "den", "Tem\u00b7pel", "krie\u00b7chen", "\u2013", "statt", "der", "vier\u00b7zig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF", "$(", "APPR", "ART", "CARD"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Schafe wurden siebzig Priester festlich", "tokens": ["Scha\u00b7fe", "wur\u00b7den", "sieb\u00b7zig", "Pries\u00b7ter", "fest\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "CARD", "NN", "ADJD"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Baal geschlachtet, der ges\u00e4ttigt grinste.", "tokens": ["Baal", "ge\u00b7schlach\u00b7tet", ",", "der", "ge\u00b7s\u00e4t\u00b7tigt", "grins\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "PRELS", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Aber dann zerschlug das Bild des G\u00f6tzen", "tokens": ["A\u00b7ber", "dann", "zer\u00b7schlug", "das", "Bild", "des", "G\u00f6t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Daniel und zerbrach des Tempels S\u00e4ulen", "tokens": ["Da\u00b7ni\u00b7el", "und", "zer\u00b7brach", "des", "Tem\u00b7pels", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und zerst\u00f6rte seine festen Hallen.", "tokens": ["und", "zer\u00b7st\u00f6r\u00b7te", "sei\u00b7ne", "fes\u00b7ten", "Hal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Und am andern Morgen in der Fr\u00fche", "tokens": ["Und", "am", "an\u00b7dern", "Mor\u00b7gen", "in", "der", "Fr\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "stand der K\u00f6nig auf und ging mit Daniel", "tokens": ["stand", "der", "K\u00f6\u00b7nig", "auf", "und", "ging", "mit", "Da\u00b7ni\u00b7el"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "NE"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "vor den Tempel. Und der K\u00f6nig fragte:", "tokens": ["vor", "den", "Tem\u00b7pel", ".", "Und", "der", "K\u00f6\u00b7nig", "frag\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "KON", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Ist das Siegel unversehrt?", "tokens": ["Ist", "das", "Sie\u00b7gel", "un\u00b7ver\u00b7sehrt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das Siegel", "tokens": ["Das", "Sie\u00b7gel"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "hat kein Mensch ber\u00fchrt, versetzte Daniel.", "tokens": ["hat", "kein", "Mensch", "be\u00b7r\u00fchrt", ",", "ver\u00b7setz\u00b7te", "Da\u00b7ni\u00b7el", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "VVPP", "$,", "VVFIN", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}}, "stanza.7": {"line.1": {"text": "Und die Th\u00fcr sprang auf. Leer war der Altar.", "tokens": ["Und", "die", "Th\u00fcr", "sprang", "auf", ".", "Leer", "war", "der", "Al\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$.", "NE", "VAFIN", "ART", "NN", "$."], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Cyrus aber rief mit lauter Stimme:", "tokens": ["Cy\u00b7rus", "a\u00b7ber", "rief", "mit", "lau\u00b7ter", "Stim\u00b7me", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "Baal, du bist ein grosser Gott! Bei dir ist", "tokens": ["Baal", ",", "du", "bist", "ein", "gros\u00b7ser", "Gott", "!", "Bei", "dir", "ist"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$.", "APPR", "PPER", "VAFIN"], "meter": "+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.4": {"text": "kein Betrug! Verzeih mir! Und er wollte", "tokens": ["kein", "Be\u00b7trug", "!", "Ver\u00b7zeih", "mir", "!", "Und", "er", "woll\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "NN", "$.", "VVIMP", "PPER", "$.", "KON", "PPER", "VMFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "vorw\u00e4rts eilen.", "tokens": ["vor\u00b7w\u00e4rts", "ei\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.6": {"text": "Halt!, rief Daniel lachend:", "tokens": ["Halt", "!", ",", "rief", "Da\u00b7ni\u00b7el", "la\u00b7chend", ":"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "$,", "VVFIN", "NE", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Halt, mein K\u00f6nig, warte nur ein wenig.", "tokens": ["Halt", ",", "mein", "K\u00f6\u00b7nig", ",", "war\u00b7te", "nur", "ein", "we\u00b7nig", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "VVFIN", "ADV", "ART", "PIS", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.8": {"text": "Siehe dort! Was siehst du auf dem Boden?", "tokens": ["Sie\u00b7he", "dort", "!", "Was", "siehst", "du", "auf", "dem", "Bo\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "Wes sind diese Stapfen?", "tokens": ["Wes", "sind", "die\u00b7se", "Stap\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PDAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Und der K\u00f6nig", "tokens": ["Und", "der", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "--+-", "measure": "anapaest.init"}, "line.2": {"text": "sah und sprach: Ich sehe wohl die Tritte.", "tokens": ["sah", "und", "sprach", ":", "Ich", "se\u00b7he", "wohl", "die", "Trit\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "M\u00e4nner gingen aus und ein und Weiber,", "tokens": ["M\u00e4n\u00b7ner", "gin\u00b7gen", "aus", "und", "ein", "und", "Wei\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "KON", "ART", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Kinder auch ...", "tokens": ["Kin\u00b7der", "auch", "..."], "token_info": ["word", "word", "punct"], "pos": ["NN", "ADV", "$("], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Und siehst du auch, woher sie", "tokens": ["Und", "siehst", "du", "auch", ",", "wo\u00b7her", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$,", "PWAV", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "alle kamen und wohin sie laufen?", "tokens": ["al\u00b7le", "ka\u00b7men", "und", "wo\u00b7hin", "sie", "lau\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "PWAV", "PPER", "VVINF", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.7": {"text": "In den grossen Bauch des grossen Baal! Dort", "tokens": ["In", "den", "gros\u00b7sen", "Bauch", "des", "gros\u00b7sen", "Baal", "!", "Dort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$.", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "m\u00fcndet ein geheimer Gang ... Ja, K\u00f6nig:", "tokens": ["m\u00fcn\u00b7det", "ein", "ge\u00b7hei\u00b7mer", "Gang", "...", "Ja", ",", "K\u00f6\u00b7nig", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$(", "PTKANT", "$,", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "was der G\u00f6tze frisst, verdaut der Priester!", "tokens": ["was", "der", "G\u00f6t\u00b7ze", "frisst", ",", "ver\u00b7daut", "der", "Pries\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Da ergrimmte Cyrus! Alle Priester", "tokens": ["Da", "er\u00b7grimm\u00b7te", "Cy\u00b7rus", "!", "Al\u00b7le", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "$.", "PIAT", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "liess er fangen. Und noch einmal mussten", "tokens": ["liess", "er", "fan\u00b7gen", ".", "Und", "noch", "ein\u00b7mal", "muss\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVFIN", "$.", "KON", "ADV", "ADV", "VMFIN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.3": {"text": "sie mit Weib und Kindern durch die H\u00f6hle", "tokens": ["sie", "mit", "Weib", "und", "Kin\u00b7dern", "durch", "die", "H\u00f6h\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "in den Tempel kriechen \u2013 statt der vierzig", "tokens": ["in", "den", "Tem\u00b7pel", "krie\u00b7chen", "\u2013", "statt", "der", "vier\u00b7zig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF", "$(", "APPR", "ART", "CARD"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Schafe wurden siebzig Priester festlich", "tokens": ["Scha\u00b7fe", "wur\u00b7den", "sieb\u00b7zig", "Pries\u00b7ter", "fest\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "CARD", "NN", "ADJD"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Baal geschlachtet, der ges\u00e4ttigt grinste.", "tokens": ["Baal", "ge\u00b7schlach\u00b7tet", ",", "der", "ge\u00b7s\u00e4t\u00b7tigt", "grins\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVPP", "$,", "PRELS", "VVPP", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.10": {"line.1": {"text": "Aber dann zerschlug das Bild des G\u00f6tzen", "tokens": ["A\u00b7ber", "dann", "zer\u00b7schlug", "das", "Bild", "des", "G\u00f6t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Daniel und zerbrach des Tempels S\u00e4ulen", "tokens": ["Da\u00b7ni\u00b7el", "und", "zer\u00b7brach", "des", "Tem\u00b7pels", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und zerst\u00f6rte seine festen Hallen.", "tokens": ["und", "zer\u00b7st\u00f6r\u00b7te", "sei\u00b7ne", "fes\u00b7ten", "Hal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}}}}