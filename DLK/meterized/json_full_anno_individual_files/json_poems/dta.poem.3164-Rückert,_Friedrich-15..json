{"dta.poem.3164": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "15.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1838", "urn": "urn:nbn:de:kobv:b4-200905195108", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Soviel hab' ich gelernt: ich darf auf gar nichts z\u00e4hlen;", "tokens": ["So\u00b7viel", "hab'", "ich", "ge\u00b7lernt", ":", "ich", "darf", "auf", "gar", "nichts", "z\u00e4h\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$.", "PPER", "VMFIN", "APPR", "ADV", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Worauf ich z\u00e4hlte, das gerade wird mir fehlen.", "tokens": ["Wo\u00b7rauf", "ich", "z\u00e4hl\u00b7te", ",", "das", "ge\u00b7ra\u00b7de", "wird", "mir", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVFIN", "$,", "PRELS", "ADV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Gez\u00e4hltes wird nicht mehr, gez\u00e4hltes Gut wird minder;", "tokens": ["Ge\u00b7z\u00e4hl\u00b7tes", "wird", "nicht", "mehr", ",", "ge\u00b7z\u00e4hl\u00b7tes", "Gut", "wird", "min\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PTKNEG", "ADV", "$,", "ADJA", "NN", "VAFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ja Wolf und L\u00f6we fri\u00dft gez\u00e4hlte Schaf' und Rinder.", "tokens": ["Ja", "Wolf", "und", "L\u00f6\u00b7we", "fri\u00dft", "ge\u00b7z\u00e4hl\u00b7te", "Schaf'", "und", "Rin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "NE", "KON", "NE", "VVFIN", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Gez\u00e4hltes wird nicht mehr; je mehr der Geiz'ge z\u00e4hlt", "tokens": ["Ge\u00b7z\u00e4hl\u00b7tes", "wird", "nicht", "mehr", ";", "je", "mehr", "der", "Gei\u00b7z'\u00b7ge", "z\u00e4hlt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PTKNEG", "ADV", "$.", "ADV", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+--+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Wie viel er hat, je mehr meint er, da\u00df ihm noch fehlt.", "tokens": ["Wie", "viel", "er", "hat", ",", "je", "mehr", "meint", "er", ",", "da\u00df", "ihm", "noch", "fehlt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "VAFIN", "$,", "ADV", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+--+-++-+", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Drum z\u00e4hle nicht, die Gott gez\u00e4hlet hat, die Zahl", "tokens": ["Drum", "z\u00e4h\u00b7le", "nicht", ",", "die", "Gott", "ge\u00b7z\u00e4h\u00b7let", "hat", ",", "die", "Zahl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVFIN", "PTKNEG", "$,", "ART", "NN", "VVPP", "VAFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Haare deines Haupts; wer sie erst z\u00e4hlt, wird kahl.", "tokens": ["Der", "Haa\u00b7re", "dei\u00b7nes", "Haupts", ";", "wer", "sie", "erst", "z\u00e4hlt", ",", "wird", "kahl", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$.", "PWS", "PPER", "ADV", "VVFIN", "$,", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Z\u00e4hl' deine Freuden nicht! es m\u00f6chte dir hienieden", "tokens": ["Z\u00e4hl'", "dei\u00b7ne", "Freu\u00b7den", "nicht", "!", "es", "m\u00f6ch\u00b7te", "dir", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "PTKNEG", "$.", "PPER", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Bed\u00fcnken, wenige nur seien dir beschieden.", "tokens": ["Be\u00b7d\u00fcn\u00b7ken", ",", "we\u00b7ni\u00b7ge", "nur", "sei\u00b7en", "dir", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PIS", "ADV", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Doch deine Leiden, wenn du sie willst zahllos meinen,", "tokens": ["Doch", "dei\u00b7ne", "Lei\u00b7den", ",", "wenn", "du", "sie", "willst", "zahl\u00b7los", "mei\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "VMFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Z\u00e4hle sie nur, damit sie dir gering erscheinen.", "tokens": ["Z\u00e4h\u00b7le", "sie", "nur", ",", "da\u00b7mit", "sie", "dir", "ge\u00b7ring", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "PPER", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}}, "stanza.7": {"line.1": {"text": "Wie manchmal mit Bedacht die Rechnung wird gemacht,", "tokens": ["Wie", "manch\u00b7mal", "mit", "Be\u00b7dacht", "die", "Rech\u00b7nung", "wird", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NN", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Rechnung ist am End' ohne den Wirth gemacht.", "tokens": ["Die", "Rech\u00b7nung", "ist", "am", "End'", "oh\u00b7ne", "den", "Wirth", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}}, "stanza.8": {"line.1": {"text": "Die Summe willst du ziehn, und machst schon deinen Strich,", "tokens": ["Die", "Sum\u00b7me", "willst", "du", "ziehn", ",", "und", "machst", "schon", "dei\u00b7nen", "Strich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,", "KON", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da macht das Schicksal durch die Rechnung einen Strich.", "tokens": ["Da", "macht", "das", "Schick\u00b7sal", "durch", "die", "Rech\u00b7nung", "ei\u00b7nen", "Strich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Mit goldnen G\u00fclden glaubst du dich bezahlt, die blechnen", "tokens": ["Mit", "gold\u00b7nen", "G\u00fcl\u00b7den", "glaubst", "du", "dich", "be\u00b7zahlt", ",", "die", "blech\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PRF", "VVPP", "$,", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Erkennest du zu sp\u00e4t, die Pfennige bei'm Rechnen.", "tokens": ["Er\u00b7ken\u00b7nest", "du", "zu", "sp\u00e4t", ",", "die", "Pfen\u00b7ni\u00b7ge", "bei'm", "Rech\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKA", "ADJD", "$,", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}