{"textgrid.poem.48661": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "24. Basilene", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Eine hab' ich mir erw\u00e4let", "tokens": ["Ei\u00b7ne", "hab'", "ich", "mir", "er\u00b7w\u00e4\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PPER", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und die solls alleine sein,", "tokens": ["und", "die", "solls", "al\u00b7lei\u00b7ne", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die mich fr\u00f6lich macht und qu\u00e4let", "tokens": ["die", "mich", "fr\u00f6\u00b7lich", "macht", "und", "qu\u00e4\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "doch mit einer s\u00fc\u00dfen Pein.", "tokens": ["doch", "mit", "ei\u00b7ner", "s\u00fc\u00b7\u00dfen", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihrer Tugend reine Pracht", "tokens": ["Ih\u00b7rer", "Tu\u00b7gend", "rei\u00b7ne", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hat mir ihre Gunst gemacht.", "tokens": ["hat", "mir", "ih\u00b7re", "Gunst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Lobt der Seine von der Jugend,", "tokens": ["Lobt", "der", "Sei\u00b7ne", "von", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "jener Seine von der Zier", "tokens": ["je\u00b7ner", "Sei\u00b7ne", "von", "der", "Zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mich erg\u00f6tzet ihre Tugend,", "tokens": ["mich", "er\u00b7g\u00f6t\u00b7zet", "ih\u00b7re", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die vor andern gl\u00e4nzt an ihr,", "tokens": ["die", "vor", "an\u00b7dern", "gl\u00e4nzt", "an", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie des Monden voller Schein", "tokens": ["wie", "des", "Mon\u00b7den", "vol\u00b7ler", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "unter tausent Sternelein.", "tokens": ["un\u00b7ter", "tau\u00b7sent", "Ster\u00b7ne\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "So erstreckt sich mein Begehren", "tokens": ["So", "er\u00b7streckt", "sich", "mein", "Be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weiter als auf Treue nicht.", "tokens": ["wei\u00b7ter", "als", "auf", "Treu\u00b7e", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre Warheit kan gew\u00e4ren,", "tokens": ["Ih\u00b7re", "War\u00b7heit", "kan", "ge\u00b7w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was mir ihre Gunst verspricht.", "tokens": ["was", "mir", "ih\u00b7re", "Gunst", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hab' ich sie, so hab' ich mir", "tokens": ["Hab'", "ich", "sie", ",", "so", "hab'", "ich", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "$,", "ADV", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "aller Sch\u00e4tze Sch\u00e4tz' an ihr.", "tokens": ["al\u00b7ler", "Sch\u00e4t\u00b7ze", "Sch\u00e4tz'", "an", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf sie bin ich ausgesch\u00fcttet.", "tokens": ["Auf", "sie", "bin", "ich", "aus\u00b7ge\u00b7sch\u00fct\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mein Licht borgt von ihr den Schein.", "tokens": ["Mein", "Licht", "borgt", "von", "ihr", "den", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was mein Mund, der nichts mehr bittet,", "tokens": ["Was", "mein", "Mund", ",", "der", "nichts", "mehr", "bit\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "als von ihr gek\u00fc\u00dft zu sein,", "tokens": ["als", "von", "ihr", "ge\u00b7k\u00fc\u00dft", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nachts und Tages, spat und fr\u00fch", "tokens": ["Nachts", "und", "Ta\u00b7ges", ",", "spat", "und", "fr\u00fch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KON", "NN", "$,", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "redt und singet, das ist sie.", "tokens": ["redt", "und", "sin\u00b7get", ",", "das", "ist", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PDS", "VAFIN", "PPER", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.5": {"line.1": {"text": "dein gewisser, fester Sinn,", "tokens": ["dein", "ge\u00b7wis\u00b7ser", ",", "fes\u00b7ter", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "der mich dir zu lieben triebe,", "tokens": ["der", "mich", "dir", "zu", "lie\u00b7ben", "trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wird ger\u00fchmt sein, weil ich bin.", "tokens": ["wird", "ge\u00b7r\u00fchmt", "sein", ",", "weil", "ich", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "VAINF", "$,", "KOUS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner treuen Redlichkeit", "tokens": ["Dei\u00b7ner", "treu\u00b7en", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wird vergessen keine Zeit.", "tokens": ["wird", "ver\u00b7ges\u00b7sen", "kei\u00b7ne", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Ein Ged\u00e4chtn\u00fc\u00df will ich stiften", "tokens": ["Ein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "will", "ich", "stif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und von Jaspis f\u00fchren auf,", "tokens": ["und", "von", "Jas\u00b7pis", "f\u00fch\u00b7ren", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Amor soll mit g\u00fcldnen Schriften", "tokens": ["A\u00b7mor", "soll", "mit", "g\u00fcld\u00b7nen", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "diese Worte stechen drauf:", "tokens": ["die\u00b7se", "Wor\u00b7te", "ste\u00b7chen", "drauf", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und sonst keine soll es sein!", "tokens": ["und", "sonst", "kei\u00b7ne", "soll", "es", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Eine hab' ich mir erw\u00e4let", "tokens": ["Ei\u00b7ne", "hab'", "ich", "mir", "er\u00b7w\u00e4\u00b7let"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VAFIN", "PPER", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und die solls alleine sein,", "tokens": ["und", "die", "solls", "al\u00b7lei\u00b7ne", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "die mich fr\u00f6lich macht und qu\u00e4let", "tokens": ["die", "mich", "fr\u00f6\u00b7lich", "macht", "und", "qu\u00e4\u00b7let"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "doch mit einer s\u00fc\u00dfen Pein.", "tokens": ["doch", "mit", "ei\u00b7ner", "s\u00fc\u00b7\u00dfen", "Pein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ihrer Tugend reine Pracht", "tokens": ["Ih\u00b7rer", "Tu\u00b7gend", "rei\u00b7ne", "Pracht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "hat mir ihre Gunst gemacht.", "tokens": ["hat", "mir", "ih\u00b7re", "Gunst", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Lobt der Seine von der Jugend,", "tokens": ["Lobt", "der", "Sei\u00b7ne", "von", "der", "Ju\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "jener Seine von der Zier", "tokens": ["je\u00b7ner", "Sei\u00b7ne", "von", "der", "Zier"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "mich erg\u00f6tzet ihre Tugend,", "tokens": ["mich", "er\u00b7g\u00f6t\u00b7zet", "ih\u00b7re", "Tu\u00b7gend", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "die vor andern gl\u00e4nzt an ihr,", "tokens": ["die", "vor", "an\u00b7dern", "gl\u00e4nzt", "an", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIS", "VVFIN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wie des Monden voller Schein", "tokens": ["wie", "des", "Mon\u00b7den", "vol\u00b7ler", "Schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "unter tausent Sternelein.", "tokens": ["un\u00b7ter", "tau\u00b7sent", "Ster\u00b7ne\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "So erstreckt sich mein Begehren", "tokens": ["So", "er\u00b7streckt", "sich", "mein", "Be\u00b7geh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "weiter als auf Treue nicht.", "tokens": ["wei\u00b7ter", "als", "auf", "Treu\u00b7e", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "APPR", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihre Warheit kan gew\u00e4ren,", "tokens": ["Ih\u00b7re", "War\u00b7heit", "kan", "ge\u00b7w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "was mir ihre Gunst verspricht.", "tokens": ["was", "mir", "ih\u00b7re", "Gunst", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Hab' ich sie, so hab' ich mir", "tokens": ["Hab'", "ich", "sie", ",", "so", "hab'", "ich", "mir"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "$,", "ADV", "VAFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "aller Sch\u00e4tze Sch\u00e4tz' an ihr.", "tokens": ["al\u00b7ler", "Sch\u00e4t\u00b7ze", "Sch\u00e4tz'", "an", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Auf sie bin ich ausgesch\u00fcttet.", "tokens": ["Auf", "sie", "bin", "ich", "aus\u00b7ge\u00b7sch\u00fct\u00b7tet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mein Licht borgt von ihr den Schein.", "tokens": ["Mein", "Licht", "borgt", "von", "ihr", "den", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Was mein Mund, der nichts mehr bittet,", "tokens": ["Was", "mein", "Mund", ",", "der", "nichts", "mehr", "bit\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "$,", "PRELS", "PIS", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "als von ihr gek\u00fc\u00dft zu sein,", "tokens": ["als", "von", "ihr", "ge\u00b7k\u00fc\u00dft", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nachts und Tages, spat und fr\u00fch", "tokens": ["Nachts", "und", "Ta\u00b7ges", ",", "spat", "und", "fr\u00fch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KON", "NN", "$,", "VVFIN", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "redt und singet, das ist sie.", "tokens": ["redt", "und", "sin\u00b7get", ",", "das", "ist", "sie", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$,", "PDS", "VAFIN", "PPER", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.11": {"line.1": {"text": "dein gewisser, fester Sinn,", "tokens": ["dein", "ge\u00b7wis\u00b7ser", ",", "fes\u00b7ter", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "der mich dir zu lieben triebe,", "tokens": ["der", "mich", "dir", "zu", "lie\u00b7ben", "trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "wird ger\u00fchmt sein, weil ich bin.", "tokens": ["wird", "ge\u00b7r\u00fchmt", "sein", ",", "weil", "ich", "bin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "VAINF", "$,", "KOUS", "PPER", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Deiner treuen Redlichkeit", "tokens": ["Dei\u00b7ner", "treu\u00b7en", "Red\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "wird vergessen keine Zeit.", "tokens": ["wird", "ver\u00b7ges\u00b7sen", "kei\u00b7ne", "Zeit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Ein Ged\u00e4chtn\u00fc\u00df will ich stiften", "tokens": ["Ein", "Ge\u00b7d\u00e4cht\u00b7n\u00fc\u00df", "will", "ich", "stif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "und von Jaspis f\u00fchren auf,", "tokens": ["und", "von", "Jas\u00b7pis", "f\u00fch\u00b7ren", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Amor soll mit g\u00fcldnen Schriften", "tokens": ["A\u00b7mor", "soll", "mit", "g\u00fcld\u00b7nen", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "diese Worte stechen drauf:", "tokens": ["die\u00b7se", "Wor\u00b7te", "ste\u00b7chen", "drauf", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "und sonst keine soll es sein!", "tokens": ["und", "sonst", "kei\u00b7ne", "soll", "es", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "VMFIN", "PPER", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}