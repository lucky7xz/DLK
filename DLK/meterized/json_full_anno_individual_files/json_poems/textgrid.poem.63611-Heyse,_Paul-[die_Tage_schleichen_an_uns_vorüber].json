{"textgrid.poem.63611": {"metadata": {"author": {"name": "Heyse, Paul", "birth": "N.A.", "death": "N.A."}, "title": "[die Tage schleichen an uns vor\u00fcber]", "genre": "verse", "period": "N.A.", "pub_year": 1872, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Tage schleichen an uns vor\u00fcber,", "tokens": ["Die", "Ta\u00b7ge", "schlei\u00b7chen", "an", "uns", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie eine dunkle Geschwisterschar,", "tokens": ["Wie", "ei\u00b7ne", "dunk\u00b7le", "Ge\u00b7schwis\u00b7ter\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die einen sanfter, die andern tr\u00fcber,", "tokens": ["Die", "ei\u00b7nen", "sanf\u00b7ter", ",", "die", "an\u00b7dern", "tr\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch keiner lachend und freudenklar.", "tokens": ["Doch", "kei\u00b7ner", "la\u00b7chend", "und", "freu\u00b7den\u00b7klar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Sie tragen Gaben in bleichen H\u00e4nden,", "tokens": ["Sie", "tra\u00b7gen", "Ga\u00b7ben", "in", "blei\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der edeln G\u00fcter gar mancherlei,", "tokens": ["Der", "e\u00b7deln", "G\u00fc\u00b7ter", "gar", "man\u00b7cher\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PIS", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch florumwunden sind ihre Spenden,", "tokens": ["Doch", "flo\u00b7rum\u00b7wun\u00b7den", "sind", "ih\u00b7re", "Spen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und unbewillkommt ziehn sie vorbei.", "tokens": ["Und", "un\u00b7be\u00b7will\u00b7kommt", "ziehn", "sie", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Voran geht einer mit harten Mienen", "tokens": ["Vo\u00b7ran", "geht", "ei\u00b7ner", "mit", "har\u00b7ten", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und scheuem Trutzblick, gesenkt das Haupt;", "tokens": ["Und", "scheu\u00b7em", "Trutz\u00b7blick", ",", "ge\u00b7senkt", "das", "Haupt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVPP", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er ist von gleichem Geschlecht mit ihnen,", "tokens": ["Er", "ist", "von", "glei\u00b7chem", "Ge\u00b7schlecht", "mit", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch statt zu schenken, hat er geraubt.", "tokens": ["Doch", "statt", "zu", "schen\u00b7ken", ",", "hat", "er", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VVINF", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.4": {"line.1": {"text": "Seitdem mi\u00dftraun wir den andern allen,", "tokens": ["Seit\u00b7dem", "mi\u00df\u00b7traun", "wir", "den", "an\u00b7dern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "ADJA", "PIAT", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die sonst wir arglos ans Herz gedr\u00fcckt.", "tokens": ["Die", "sonst", "wir", "arg\u00b7los", "ans", "Herz", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ADJD", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auch mit den Schwestern sind wir zerfallen,", "tokens": ["Auch", "mit", "den", "Schwes\u00b7tern", "sind", "wir", "zer\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Den sch\u00f6nen N\u00e4chten, so reichgeschm\u00fcckt.", "tokens": ["Den", "sch\u00f6\u00b7nen", "N\u00e4ch\u00b7ten", ",", "so", "reich\u00b7ge\u00b7schm\u00fcckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Ein Tag wird kommen, der wird uns retten,", "tokens": ["Ein", "Tag", "wird", "kom\u00b7men", ",", "der", "wird", "uns", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,", "PRELS", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Weltvers\u00f6hner, aus allem Harm;", "tokens": ["Ein", "Welt\u00b7ver\u00b7s\u00f6h\u00b7ner", ",", "aus", "al\u00b7lem", "Harm", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PIS", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mitleidig f\u00fchrt er zu ew'gen St\u00e4tten", "tokens": ["Mit\u00b7lei\u00b7dig", "f\u00fchrt", "er", "zu", "ew'\u00b7gen", "St\u00e4t\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der stillsten Schwester uns in den Arm.", "tokens": ["Der", "stills\u00b7ten", "Schwes\u00b7ter", "uns", "in", "den", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.6": {"line.1": {"text": "Die Tage schleichen an uns vor\u00fcber,", "tokens": ["Die", "Ta\u00b7ge", "schlei\u00b7chen", "an", "uns", "vor\u00b7\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie eine dunkle Geschwisterschar,", "tokens": ["Wie", "ei\u00b7ne", "dunk\u00b7le", "Ge\u00b7schwis\u00b7ter\u00b7schar", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die einen sanfter, die andern tr\u00fcber,", "tokens": ["Die", "ei\u00b7nen", "sanf\u00b7ter", ",", "die", "an\u00b7dern", "tr\u00fc\u00b7ber", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "$,", "PRELS", "PIS", "ADJD", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch keiner lachend und freudenklar.", "tokens": ["Doch", "kei\u00b7ner", "la\u00b7chend", "und", "freu\u00b7den\u00b7klar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie tragen Gaben in bleichen H\u00e4nden,", "tokens": ["Sie", "tra\u00b7gen", "Ga\u00b7ben", "in", "blei\u00b7chen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der edeln G\u00fcter gar mancherlei,", "tokens": ["Der", "e\u00b7deln", "G\u00fc\u00b7ter", "gar", "man\u00b7cher\u00b7lei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PIS", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch florumwunden sind ihre Spenden,", "tokens": ["Doch", "flo\u00b7rum\u00b7wun\u00b7den", "sind", "ih\u00b7re", "Spen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Und unbewillkommt ziehn sie vorbei.", "tokens": ["Und", "un\u00b7be\u00b7will\u00b7kommt", "ziehn", "sie", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+---+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Voran geht einer mit harten Mienen", "tokens": ["Vo\u00b7ran", "geht", "ei\u00b7ner", "mit", "har\u00b7ten", "Mie\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und scheuem Trutzblick, gesenkt das Haupt;", "tokens": ["Und", "scheu\u00b7em", "Trutz\u00b7blick", ",", "ge\u00b7senkt", "das", "Haupt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVPP", "ART", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er ist von gleichem Geschlecht mit ihnen,", "tokens": ["Er", "ist", "von", "glei\u00b7chem", "Ge\u00b7schlecht", "mit", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch statt zu schenken, hat er geraubt.", "tokens": ["Doch", "statt", "zu", "schen\u00b7ken", ",", "hat", "er", "ge\u00b7raubt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VVINF", "$,", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Seitdem mi\u00dftraun wir den andern allen,", "tokens": ["Seit\u00b7dem", "mi\u00df\u00b7traun", "wir", "den", "an\u00b7dern", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ART", "ADJA", "PIAT", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Die sonst wir arglos ans Herz gedr\u00fcckt.", "tokens": ["Die", "sonst", "wir", "arg\u00b7los", "ans", "Herz", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPER", "ADJD", "APPRART", "NN", "VVPP", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Auch mit den Schwestern sind wir zerfallen,", "tokens": ["Auch", "mit", "den", "Schwes\u00b7tern", "sind", "wir", "zer\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Den sch\u00f6nen N\u00e4chten, so reichgeschm\u00fcckt.", "tokens": ["Den", "sch\u00f6\u00b7nen", "N\u00e4ch\u00b7ten", ",", "so", "reich\u00b7ge\u00b7schm\u00fcckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Ein Tag wird kommen, der wird uns retten,", "tokens": ["Ein", "Tag", "wird", "kom\u00b7men", ",", "der", "wird", "uns", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$,", "PRELS", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Weltvers\u00f6hner, aus allem Harm;", "tokens": ["Ein", "Welt\u00b7ver\u00b7s\u00f6h\u00b7ner", ",", "aus", "al\u00b7lem", "Harm", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "PIS", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mitleidig f\u00fchrt er zu ew'gen St\u00e4tten", "tokens": ["Mit\u00b7lei\u00b7dig", "f\u00fchrt", "er", "zu", "ew'\u00b7gen", "St\u00e4t\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der stillsten Schwester uns in den Arm.", "tokens": ["Der", "stills\u00b7ten", "Schwes\u00b7ter", "uns", "in", "den", "Arm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}}}}}