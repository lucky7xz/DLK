{"dta.poem.4249": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das Th\u00fcrmchen zu Ritzeb\u00fcttel.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Der Sitz, wodurch ich, abgesondert von Menschen,", "tokens": ["Der", "Sitz", ",", "wo\u00b7durch", "ich", ",", "ab\u00b7ge\u00b7son\u00b7dert", "von", "Men\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "PPER", "$,", "VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "einsam und allein", "tokens": ["ein\u00b7sam", "und", "al\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["ADJD", "KON", "ADV"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "In ungest\u00f6rter Ruhe sitze, wo mich des falschen Neides", "tokens": ["In", "un\u00b7ge\u00b7st\u00f6r\u00b7ter", "Ru\u00b7he", "sit\u00b7ze", ",", "wo", "mich", "des", "fal\u00b7schen", "Nei\u00b7des"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Stein,", "tokens": ["Stein", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Da ich so weit von ihm entfernt, und ihm nicht sichtbar bin,", "tokens": ["Da", "ich", "so", "weit", "von", "ihm", "ent\u00b7fernt", ",", "und", "ihm", "nicht", "sicht\u00b7bar", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$,", "KON", "PPER", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "nicht trifft,", "tokens": ["nicht", "trifft", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Wo weder bittrer Ha\u00df noch Zank, noch der Verleumdung", "tokens": ["Wo", "we\u00b7der", "bit\u00b7trer", "Ha\u00df", "noch", "Zank", ",", "noch", "der", "Ver\u00b7leum\u00b7dung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "KON", "ADJA", "NN", "ADV", "NN", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "falsches Gift", "tokens": ["fal\u00b7sches", "Gift"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Mich, weil man mein vergi\u00dft, nicht qu\u00e4let. Mein Th\u00fcrm-", "tokens": ["Mich", ",", "weil", "man", "mein", "ver\u00b7gi\u00dft", ",", "nicht", "qu\u00e4\u00b7let", ".", "Mein", "Th\u00fcr\u00b7m"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "$,", "KOUS", "PIS", "PPOSAT", "VVFIN", "$,", "PTKNEG", "VVFIN", "$.", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "chen, wo ich, ungest\u00f6rt,", "tokens": ["chen", ",", "wo", "ich", ",", "un\u00b7ge\u00b7st\u00f6rt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "$,", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Die sch\u00f6ne Welt, als GOttes Werk, und als des grossen", "tokens": ["Die", "sch\u00f6\u00b7ne", "Welt", ",", "als", "Got\u00b7tes", "Werk", ",", "und", "als", "des", "gros\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KOUS", "NN", "NN", "$,", "KON", "KOUS", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sch\u00f6pfers Bau,", "tokens": ["Sch\u00f6p\u00b7fers", "Bau", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Von Erde, Luft und Fluht verbunden, und wunderbar", "tokens": ["Von", "Er\u00b7de", ",", "Luft", "und", "Fluht", "ver\u00b7bun\u00b7den", ",", "und", "wun\u00b7der\u00b7bar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVPP", "$,", "KON", "ADJD"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "gef\u00fcgt, beschau,", "tokens": ["ge\u00b7f\u00fcgt", ",", "be\u00b7schau", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Ist einer eigenen Beschreibung, zur stetigen Erinn\u2019rung,", "tokens": ["Ist", "ei\u00b7ner", "ei\u00b7ge\u00b7nen", "Be\u00b7schrei\u00b7bung", ",", "zur", "ste\u00b7ti\u00b7gen", "Er\u00b7inn'\u00b7rung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+---+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "wehrt.", "tokens": ["wehrt", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+", "measure": "single.up"}}, "stanza.2": {"line.1": {"text": "Wie ich zuerst herunter kam, um die Gelegenheit zu", "tokens": ["Wie", "ich", "zu\u00b7erst", "her\u00b7un\u00b7ter", "kam", ",", "um", "die", "Ge\u00b7le\u00b7gen\u00b7heit", "zu"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$,", "KOUI", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.2": {"text": "seh'n", "tokens": ["seh'n"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Des Amts und Schlosses ", "tokens": ["Des", "Amts", "und", "Schlos\u00b7ses"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Th\u00fcrmchen sah,", "tokens": ["Th\u00fcrm\u00b7chen", "sah", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Das damahls ungebrauchet stand, so wu\u00dft\u2019 ich kaum, wie", "tokens": ["Das", "da\u00b7mahls", "un\u00b7ge\u00b7brau\u00b7chet", "stand", ",", "so", "wu\u00dft'", "ich", "kaum", ",", "wie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "ADV", "ADJD", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,", "PWAV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "mir geschah.", "tokens": ["mir", "ge\u00b7schah", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.3": {"line.1": {"text": "Mir war, als wenn er zu mir spr\u00e4ch\u2019: Komm, la\u00df mich", "tokens": ["Mir", "war", ",", "als", "wenn", "er", "zu", "mir", "spr\u00e4ch'", ":", "Komm", ",", "la\u00df", "mich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "KOKOM", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "VVFIN", "$,", "VVIMP", "PPER"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "dir zu Dienste steh'n,", "tokens": ["dir", "zu", "Diens\u00b7te", "steh'n", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Du kannst an keinem andern Ort, wie Erde, Luft und", "tokens": ["Du", "kannst", "an", "kei\u00b7nem", "an\u00b7dern", "Ort", ",", "wie", "Er\u00b7de", ",", "Luft", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PIAT", "ADJA", "NN", "$,", "PWAV", "NN", "$,", "NN", "KON"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Fluht so sch\u00f6n,", "tokens": ["Fluht", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Mit gr\u00f6\u00dfrer Deutlichkeit betrachten. Hier kannst du", "tokens": ["Mit", "gr\u00f6\u00df\u00b7rer", "Deut\u00b7lich\u00b7keit", "be\u00b7trach\u00b7ten", ".", "Hier", "kannst", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$.", "ADV", "VMFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ruhig ganz allein,", "tokens": ["ru\u00b7hig", "ganz", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Von aller Hinderni\u00df befreyt, vom Welt-Ger\u00e4usch", "tokens": ["Von", "al\u00b7ler", "Hin\u00b7der\u00b7ni\u00df", "be\u00b7freyt", ",", "vom", "Welt\u00b7Ge\u00b7r\u00e4usch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$,", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "entfernet seyn.", "tokens": ["ent\u00b7fer\u00b7net", "seyn", "."], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Die Rede dr\u00fcckte sich so gleich so tief in meine Sin-", "tokens": ["Die", "Re\u00b7de", "dr\u00fcck\u00b7te", "sich", "so", "gleich", "so", "tief", "in", "mei\u00b7ne", "Sin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "ADV", "ADV", "ADV", "ADJD", "APPR", "PPOSAT", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "nen ein,", "tokens": ["nen", "ein", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Da\u00df ich, nur bald her ab zu kommen, den Zug in mir verst\u00e4rket", "tokens": ["Da\u00df", "ich", ",", "nur", "bald", "her", "ab", "zu", "kom\u00b7men", ",", "den", "Zug", "in", "mir", "ver\u00b7st\u00e4r\u00b7ket"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "$,", "ADV", "ADV", "ADV", "PTKVZ", "PTKZU", "VVINF", "$,", "ART", "NN", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "f\u00fchlte,", "tokens": ["f\u00fchl\u00b7te", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Und von der Zeit mit meinem Denken auf nichts, als Ritze", "tokens": ["Und", "von", "der", "Zeit", "mit", "mei\u00b7nem", "Den\u00b7ken", "auf", "nichts", ",", "als", "Rit\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "APPR", "PIS", "$,", "KOUS", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "b\u00fcttel, zielte.", "tokens": ["b\u00fct\u00b7tel", ",", "ziel\u00b7te", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Jtzt, da ich, nach verschiednen F\u00e4llen, GOtt Lob! nunmehro", "tokens": ["Jtzt", ",", "da", "ich", ",", "nach", "ver\u00b7schied\u00b7nen", "F\u00e4l\u00b7len", ",", "Gott", "Lob", "!", "nun\u00b7meh\u00b7ro"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "NN", "NN", "$.", "ADV"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "hergekommen,", "tokens": ["her\u00b7ge\u00b7kom\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Und die so lang\u2019 erseufzte Stelle bereits schon in Besitz", "tokens": ["Und", "die", "so", "lang'", "er\u00b7seufz\u00b7te", "Stel\u00b7le", "be\u00b7reits", "schon", "in", "Be\u00b7sitz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADV", "ADV", "ADJA", "NN", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "genommen,", "tokens": ["ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Hab\u2019 ich zuv\u00f6rderst GOtt gedankt, und dank\u2019 Jhm noch, nebst", "tokens": ["Hab'", "ich", "zu\u00b7v\u00f6r\u00b7derst", "Gott", "ge\u00b7dankt", ",", "und", "dank'", "Jhm", "noch", ",", "nebst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["NN", "PPER", "ADV", "NN", "VVPP", "$,", "KON", "VVFIN", "PPER", "ADV", "$,", "APPR"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.12": {"text": "innerm Fleh'n,", "tokens": ["in\u00b7nerm", "Fleh'n", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Da\u00df die Gewohnheit, wie gew\u00f6hnlich, mir H\u00f6ren, Riechen,", "tokens": ["Da\u00df", "die", "Ge\u00b7wohn\u00b7heit", ",", "wie", "ge\u00b7w\u00f6hn\u00b7lich", ",", "mir", "H\u00f6\u00b7ren", ",", "Rie\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "PWAV", "ADJD", "$,", "PPER", "VVFIN", "$,", "NN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "F\u00fchlen, Seh'n,", "tokens": ["F\u00fch\u00b7len", ",", "Seh'n", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.15": {"text": "Und, in den Sinnen, Lust und Dank nicht rauben m\u00f6ge!", "tokens": ["Und", ",", "in", "den", "Sin\u00b7nen", ",", "Lust", "und", "Dank", "nicht", "rau\u00b7ben", "m\u00f6\u00b7ge", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "NN", "$,", "NN", "KON", "NN", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Da\u00df ich nimmer,", "tokens": ["Da\u00df", "ich", "nim\u00b7mer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.17": {"text": "Ohn\u2019 innre Freud\u2019 an GOttes Werken, und mir geschenktem", "tokens": ["Ohn'", "inn\u00b7re", "Freud'", "an", "Got\u00b7tes", "Wer\u00b7ken", ",", "und", "mir", "ge\u00b7schenk\u00b7tem"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "NN", "$,", "KON", "PPER", "ADJA"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Guht, die\u00df Zimmer", "tokens": ["Guht", ",", "die\u00df", "Zim\u00b7mer"], "token_info": ["word", "punct", "word", "word"], "pos": ["ADJD", "$,", "PDS", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.19": {"text": "Betreten noch gebrauchen m\u00f6ge! Um meine Lust oft zu", "tokens": ["Be\u00b7tre\u00b7ten", "noch", "ge\u00b7brau\u00b7chen", "m\u00f6\u00b7ge", "!", "Um", "mei\u00b7ne", "Lust", "oft", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "VVINF", "VMFIN", "$.", "KOUI", "PPOSAT", "NN", "ADV", "PTKZU"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.20": {"text": "ermessen,", "tokens": ["er\u00b7mes\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.21": {"text": "Und dieses Th\u00fcrmchens Lage, Reiz und Anmuht nimmer zu", "tokens": ["Und", "die\u00b7ses", "Th\u00fcrm\u00b7chens", "La\u00b7ge", ",", "Reiz", "und", "An\u00b7muht", "nim\u00b7mer", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "NN", "$,", "NN", "KON", "NN", "ADV", "APPR"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.22": {"text": "vergessen,", "tokens": ["ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.5": {"line.1": {"text": "Soll itzt, so deutlich als ich kann, dasselbe, nebst dem Theil", "tokens": ["Soll", "itzt", ",", "so", "deut\u00b7lich", "als", "ich", "kann", ",", "das\u00b7sel\u00b7be", ",", "nebst", "dem", "Theil"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "ADV", "$,", "ADV", "ADJD", "KOKOM", "PPER", "VMFIN", "$,", "PDAT", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "der Erden,", "tokens": ["der", "Er\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "So man aus ihm mit Anmuht sieht, betrachtet und beschrie-", "tokens": ["So", "man", "aus", "ihm", "mit", "An\u00b7muht", "sieht", ",", "be\u00b7trach\u00b7tet", "und", "be\u00b7schrie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIS", "APPR", "PPER", "APPR", "NN", "VVFIN", "$,", "VVPP", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "ben werden:", "tokens": ["ben", "wer\u00b7den", ":"], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VAINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.6": {"line.1": {"text": "Ein Regel- rechtes Acht-Eck theilt des Th\u00fcrmchens", "tokens": ["Ein", "Re\u00b7gel", "rech\u00b7tes", "Acht\u00b7Eck", "theilt", "des", "Th\u00fcrm\u00b7chens"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "ADJA", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "R\u00fcnde richtig ein,", "tokens": ["R\u00fcn\u00b7de", "rich\u00b7tig", "ein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Wovon f\u00fcnf F\u00e4cher nichts als Fenster, aus welchen, wegen", "tokens": ["Wo\u00b7von", "f\u00fcnf", "F\u00e4\u00b7cher", "nichts", "als", "Fens\u00b7ter", ",", "aus", "wel\u00b7chen", ",", "we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PWAV", "CARD", "NN", "PIS", "KOKOM", "NN", "$,", "APPR", "PWAT", "$,", "APPR"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "seiner H\u00f6he,", "tokens": ["sei\u00b7ner", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Ich, \u00fcber alle H\u00e4us- und Felder, das Grenzen- lose Wasser", "tokens": ["Ich", ",", "\u00fc\u00b7ber", "al\u00b7le", "H\u00e4us", "und", "Fel\u00b7der", ",", "das", "Gren\u00b7zen", "lo\u00b7se", "Was\u00b7ser"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "$,", "APPR", "PIAT", "TRUNC", "KON", "NN", "$,", "ART", "TRUNC", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.6": {"text": "sehe,", "tokens": ["se\u00b7he", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "So allesammt die sch\u00f6nsten Vorw\u00fcrf\u2019, in einer sch\u00f6nen Land-", "tokens": ["So", "al\u00b7le\u00b7sammt", "die", "sch\u00f6ns\u00b7ten", "Vor\u00b7w\u00fcr\u00b7f'", ",", "in", "ei\u00b7ner", "sch\u00f6\u00b7nen", "Lan\u00b7d"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,", "APPR", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.8": {"text": "schaft, seyn.", "tokens": ["schaft", ",", "seyn", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["ADJD", "$,", "VAINF", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.7": {"line.1": {"text": "Weil nun die Lage dieses Th\u00fcrmchens Nord-Ost-werts;", "tokens": ["Weil", "nun", "die", "La\u00b7ge", "die\u00b7ses", "Th\u00fcrm\u00b7chens", "Nord\u00b7Ost\u00b7werts", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PDAT", "NN", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "trifft der Sonnen-Schein,", "tokens": ["trifft", "der", "Son\u00b7nen\u00b7Schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Nur blo\u00df des Morgens, meinen Sitz, und bin ich, wenn der", "tokens": ["Nur", "blo\u00df", "des", "Mor\u00b7gens", ",", "mei\u00b7nen", "Sitz", ",", "und", "bin", "ich", ",", "wenn", "der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADV", "$,", "PPOSAT", "NN", "$,", "KON", "VAFIN", "PPER", "$,", "KOUS", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mittag blitzet,", "tokens": ["Mit\u00b7tag", "blit\u00b7zet", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Durch des erhabnen Schlosses Mauer, die S\u00fcd-werts", "tokens": ["Durch", "des", "er\u00b7hab\u00b7nen", "Schlos\u00b7ses", "Mau\u00b7er", ",", "die", "S\u00fcd\u00b7werts"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "lieget, so besch\u00fctzet,", "tokens": ["lie\u00b7get", ",", "so", "be\u00b7sch\u00fct\u00b7zet", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Da\u00df ich, in einem k\u00fchlen Schatten, an diesem Ort, den ganzen", "tokens": ["Da\u00df", "ich", ",", "in", "ei\u00b7nem", "k\u00fch\u00b7len", "Schat\u00b7ten", ",", "an", "die\u00b7sem", "Ort", ",", "den", "gan\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "$,", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "PDAT", "NN", "$,", "ART", "ADJA"], "meter": "-+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Tag,", "tokens": ["Tag", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Die \u00fcberall bestrahlte Vorw\u00fcrf\u2019, auf Land und Fluht,", "tokens": ["Die", "\u00fc\u00b7be\u00b7rall", "be\u00b7strahl\u00b7te", "Vor\u00b7w\u00fcr\u00b7f'", ",", "auf", "Land", "und", "Fluht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.10": {"text": "zu seh'n vermag.", "tokens": ["zu", "seh'n", "ver\u00b7mag", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Von dem von hier zu sehenden, so weiten Kreise des Ge-", "tokens": ["Von", "dem", "von", "hier", "zu", "se\u00b7hen\u00b7den", ",", "so", "wei\u00b7ten", "Krei\u00b7se", "des", "Ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "APPR", "ADV", "PTKZU", "VVINF", "$,", "ADV", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "sichts,", "tokens": ["sichts", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Von den so vielen Gegenw\u00fcrfen von Wiesen, Feldern, auf", "tokens": ["Von", "den", "so", "vie\u00b7len", "Ge\u00b7gen\u00b7w\u00fcr\u00b7fen", "von", "Wie\u00b7sen", ",", "Fel\u00b7dern", ",", "auf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["APPR", "ART", "ADV", "PIAT", "NN", "APPR", "NN", "$,", "NN", "$,", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "dem Lande,", "tokens": ["dem", "Lan\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Von den nicht wenigern im Wasser, auf dem Betrachtens-", "tokens": ["Von", "den", "nicht", "we\u00b7ni\u00b7gern", "im", "Was\u00b7ser", ",", "auf", "dem", "Be\u00b7trach\u00b7tens"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "PTKNEG", "ADV", "APPRART", "NN", "$,", "APPR", "ART", "TRUNC"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "wehrten Strande,", "tokens": ["wehr\u00b7ten", "Stran\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Und \u00fcberall uns, durch den Glanz des all\u2019s erhell\u2019nden Son-", "tokens": ["Und", "\u00fc\u00b7be\u00b7rall", "uns", ",", "durch", "den", "Glanz", "des", "all's", "er\u00b7hell'n\u00b7den", "Son"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PPER", "$,", "APPR", "ART", "NN", "ART", "ADJA", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "nen-Lichts,", "tokens": ["nen\u00b7Lichts", ","], "token_info": ["word", "punct"], "pos": ["PTKANT", "$,"], "meter": "-+", "measure": "iambic.single"}}, "stanza.9": {"line.1": {"text": "So hell- gezeigten Gegenw\u00fcrfen, hab\u2019 ich, zwar im Zusam-", "tokens": ["So", "hell", "ge\u00b7zeig\u00b7ten", "Ge\u00b7gen\u00b7w\u00fcr\u00b7fen", ",", "hab'", "ich", ",", "zwar", "im", "Zu\u00b7sam"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "TRUNC", "ADJA", "NN", "$,", "VAFIN", "PPER", "$,", "ADV", "APPRART", "TRUNC"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.2": {"text": "menhange,", "tokens": ["men\u00b7han\u00b7ge", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Bereits vorhin schon was geschrieben; doch war dasselbe", "tokens": ["Be\u00b7reits", "vor\u00b7hin", "schon", "was", "ge\u00b7schrie\u00b7ben", ";", "doch", "war", "das\u00b7sel\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PIS", "VVPP", "$.", "ADV", "VAFIN", "PDAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "lange, lange", "tokens": ["lan\u00b7ge", ",", "lan\u00b7ge"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$,", "ADV"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Nicht alles, wie auch dieses hier, nicht alle Vorw\u00fcrf\u2019 unsren", "tokens": ["Nicht", "al\u00b7les", ",", "wie", "auch", "die\u00b7ses", "hier", ",", "nicht", "al\u00b7le", "Vor\u00b7w\u00fcr\u00b7f'", "un\u00b7sren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKNEG", "PIS", "$,", "PWAV", "ADV", "PDAT", "ADV", "$,", "PTKNEG", "PIAT", "NN", "PPOSAT"], "meter": "-+-+-+-+-+-+-++-", "measure": "unknown.measure.octa.plus"}, "line.6": {"text": "Augen,", "tokens": ["Au\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Die hier mein hoher Sitz uns zeiget, nach W\u00fcrden zu", "tokens": ["Die", "hier", "mein", "ho\u00b7her", "Sitz", "uns", "zei\u00b7get", ",", "nach", "W\u00fcr\u00b7den", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "PPOSAT", "ADJA", "NN", "PPER", "VVFIN", "$,", "APPR", "NN", "PTKZU"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "ersch\u00f6pfen taugen,", "tokens": ["er\u00b7sch\u00f6p\u00b7fen", "tau\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["VVPP", "VVFIN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Weil Meng\u2019 und Sch\u00f6nheit gar zu gro\u00df. Damit der Vor-", "tokens": ["Weil", "Meng'", "und", "Sch\u00f6n\u00b7heit", "gar", "zu", "gro\u00df", ".", "Da\u00b7mit", "der", "Vor"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NE", "KON", "NN", "ADV", "PTKA", "ADJD", "$.", "PAV", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "w\u00fcrf' Ueberflu\u00df", "tokens": ["w\u00fcr\u00b7f'", "Ue\u00b7berf\u00b7lu\u00df"], "token_info": ["word", "word"], "pos": ["VAFIN", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "Nun durch die Vielheit uns nicht blenden, und am betrach-", "tokens": ["Nun", "durch", "die", "Viel\u00b7heit", "uns", "nicht", "blen\u00b7den", ",", "und", "am", "be\u00b7trach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "PPER", "PTKNEG", "VVFIN", "$,", "KON", "APPRART", "TRUNC"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "tenden Genu\u00df", "tokens": ["ten\u00b7den", "Ge\u00b7nu\u00df"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "Uns nicht mehr hindern m\u00f6g\u2019, als n\u00fctzen; so theil\u2019 ich alles,", "tokens": ["Uns", "nicht", "mehr", "hin\u00b7dern", "m\u00f6g'", ",", "als", "n\u00fct\u00b7zen", ";", "so", "theil'", "ich", "al\u00b7les", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "VVINF", "VMFIN", "$,", "KOUS", "VVINF", "$.", "ADV", "VVFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "was ich sehe", "tokens": ["was", "ich", "se\u00b7he"], "token_info": ["word", "word", "word"], "pos": ["PWS", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.15": {"text": "In der nicht abzuseh\u2019nden Landschaft, so in der Weit\u2019, als in", "tokens": ["In", "der", "nicht", "ab\u00b7zu\u00b7seh'n\u00b7den", "Land\u00b7schaft", ",", "so", "in", "der", "Weit'", ",", "als", "in"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "PTKNEG", "ADJA", "NN", "$,", "ADV", "APPR", "ART", "NN", "$,", "KOUS", "APPR"], "meter": "-+-+-+-+--+-+-+", "measure": "iambic.septa.relaxed"}, "line.16": {"text": "der N\u00e4he,", "tokens": ["der", "N\u00e4\u00b7he", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.17": {"text": "Durch der f\u00fcnf Fenster Oeffnungen, in f\u00fcnf gevierte F\u00e4cher", "tokens": ["Durch", "der", "f\u00fcnf", "Fens\u00b7ter", "Oeff\u00b7nun\u00b7gen", ",", "in", "f\u00fcnf", "ge\u00b7vier\u00b7te", "F\u00e4\u00b7cher"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "CARD", "NN", "NN", "$,", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+---+-+-+-", "measure": "unknown.measure.hexa"}, "line.18": {"text": "ein,", "tokens": ["ein", ","], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$,"], "meter": "-", "measure": "single.down"}, "line.19": {"text": "Die denn f\u00fcnf pr\u00e4cht\u2019gen Schildereyen, durch solche Thei-", "tokens": ["Die", "denn", "f\u00fcnf", "pr\u00e4cht'\u00b7gen", "Schil\u00b7de\u00b7re\u00b7yen", ",", "durch", "sol\u00b7che", "Thei"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "CARD", "ADJA", "NN", "$,", "APPR", "PIAT", "TRUNC"], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.20": {"text": "lung, \u00e4hnlich seyn.", "tokens": ["lung", ",", "\u00e4hn\u00b7lich", "seyn", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "VAINF", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.21": {"text": "Ach, m\u00f6cht\u2019 hierinn des Urbilds Sch\u00f6nheit, die\u00df sch\u00f6ne Theil", "tokens": ["Ach", ",", "m\u00f6cht'", "hie\u00b7rinn", "des", "Ur\u00b7bilds", "Sch\u00f6n\u00b7heit", ",", "die\u00df", "sch\u00f6\u00b7ne", "Theil"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VMFIN", "ADV", "ART", "NN", "NN", "$,", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "von unsrer Erden,", "tokens": ["von", "uns\u00b7rer", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.23": {"text": "In meiner m\u00fchsamen Copie, nicht gar zu sehr verstellet", "tokens": ["In", "mei\u00b7ner", "m\u00fch\u00b7sa\u00b7men", "Co\u00b7pie", ",", "nicht", "gar", "zu", "sehr", "ver\u00b7stel\u00b7let"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PTKNEG", "ADV", "PTKA", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.24": {"text": "werden!", "tokens": ["wer\u00b7den", "!"], "token_info": ["word", "punct"], "pos": ["VAINF", "$."], "meter": "+-", "measure": "trochaic.single"}}}}}