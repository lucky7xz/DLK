{"textgrid.poem.54899": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "Anderes Straff-Gedichte", "genre": "verse", "period": "N.A.", "pub_year": 1640, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Man fragt ", "tokens": ["Man", "fragt"], "token_info": ["word", "word"], "pos": ["PIS", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Da\u00df ich so einsam mir zu leben vorgenommen/", "tokens": ["Da\u00df", "ich", "so", "ein\u00b7sam", "mir", "zu", "le\u00b7ben", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PPER", "PTKZU", "VVINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df mich ein todtes Buch/ ein rauher Wald ergetzt/", "tokens": ["Da\u00df", "mich", "ein", "tod\u00b7tes", "Buch", "/", "ein", "rau\u00b7her", "Wald", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ", "tokens": ["Da"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Die mit gebeugtem Knie ihm schier die F\u00fcsse k\u00fcssen/", "tokens": ["Die", "mit", "ge\u00b7beug\u00b7tem", "Knie", "ihm", "schier", "die", "F\u00fcs\u00b7se", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "PPER", "ADJD", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und bi\u00df nach Mitternacht vom Morgen ihn begr\u00fcssen.", "tokens": ["Und", "bi\u00df", "nach", "Mit\u00b7ter\u00b7nacht", "vom", "Mor\u00b7gen", "ihn", "be\u00b7gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die/ wenn er \u00fcber Feld und \u00fcber See wil gehn/", "tokens": ["Die", "/", "wenn", "er", "\u00fc\u00b7ber", "Feld", "und", "\u00fc\u00b7ber", "See", "wil", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "APPR", "NN", "KON", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als Sclaven/ auf ein Wort/ ihm zu Gebote stehn.", "tokens": ["Als", "Scla\u00b7ven", "/", "auf", "ein", "Wort", "/", "ihm", "zu", "Ge\u00b7bo\u00b7te", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "APPR", "ART", "NN", "$(", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was mag die Ursach seyn? man hat ja offt versp\u00fchret/", "tokens": ["Was", "mag", "die", "Ur\u00b7sach", "seyn", "?", "man", "hat", "ja", "offt", "ver\u00b7sp\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VAINF", "$.", "PIS", "VAFIN", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das mich mein D\u00fcnckel nicht in mich allein verf\u00fchret/", "tokens": ["Das", "mich", "mein", "D\u00fcn\u00b7ckel", "nicht", "in", "mich", "al\u00b7lein", "ver\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "PTKNEG", "APPR", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mein niemals falsches Hertz mit grosser Freundligkeit.", "tokens": ["Mein", "nie\u00b7mals", "fal\u00b7sches", "Hertz", "mit", "gros\u00b7ser", "Freund\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sein \u00fcber-pr\u00e4chtig Haus was \u00f6ffter zu betreten/", "tokens": ["Sein", "\u00fc\u00b7ber\u00b7pr\u00e4ch\u00b7tig", "Haus", "was", "\u00f6ff\u00b7ter", "zu", "be\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "PWS", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die grosse ", "tokens": ["Die", "gros\u00b7se"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Man zeucht mich hier und dar nicht wenig andern vor.", "tokens": ["Man", "zeucht", "mich", "hier", "und", "dar", "nicht", "we\u00b7nig", "an\u00b7dern", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "PTKVZ", "PTKNEG", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man kennt und ehrt mich dort/ wo ich noch nie hinkommen/", "tokens": ["Man", "kennt", "und", "ehrt", "mich", "dort", "/", "wo", "ich", "noch", "nie", "hin\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$(", "PWAV", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Viel Seelen haben mich in ihren Bund genommen.", "tokens": ["Viel", "See\u00b7len", "ha\u00b7ben", "mich", "in", "ih\u00b7ren", "Bund", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Viel lieb' ich mehr denn mich und bin nicht selber mein/", "tokens": ["Viel", "lieb'", "ich", "mehr", "denn", "mich", "und", "bin", "nicht", "sel\u00b7ber", "mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PPER", "KON", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dafern zu ihrem Nutz ich kan beh\u00fclfflich seyn.", "tokens": ["Da\u00b7fern", "zu", "ih\u00b7rem", "Nutz", "ich", "kan", "be\u00b7h\u00fclf\u00b7flich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df ich mich aber nicht mach' iedermann gemeine/", "tokens": ["Da\u00df", "ich", "mich", "a\u00b7ber", "nicht", "mach'", "ie\u00b7der\u00b7mann", "ge\u00b7mei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VVFIN", "ADV", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ist di\u00df wol fragens werth? Viel besser gantz alleine/", "tokens": ["Ist", "di\u00df", "wol", "fra\u00b7gens", "werth", "?", "Viel", "bes\u00b7ser", "gantz", "al\u00b7lei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADV", "ADJD", "$.", "ADV", "ADJD", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als unter fremden Volck/ das untreu in der That/", "tokens": ["Als", "un\u00b7ter", "frem\u00b7den", "Volck", "/", "das", "un\u00b7treu", "in", "der", "That", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "$(", "ART", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.22": {"text": "Und nichts denn lauter Treu auf falscher Zungen hat.", "tokens": ["Und", "nichts", "denn", "lau\u00b7ter", "Treu", "auf", "fal\u00b7scher", "Zun\u00b7gen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mit allen geh ich um. Ich werde nichts versagen/", "tokens": ["Mit", "al\u00b7len", "geh", "ich", "um", ".", "Ich", "wer\u00b7de", "nichts", "ver\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VAFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dafern es m\u00f6glich ist. Man mag mich sicher fragen/", "tokens": ["Da\u00b7fern", "es", "m\u00f6g\u00b7lich", "ist", ".", "Man", "mag", "mich", "si\u00b7cher", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$.", "PIS", "VMFIN", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ich wil mir lieber selbst als andern sch\u00e4dlich seyn.", "tokens": ["Ich", "wil", "mir", "lie\u00b7ber", "selbst", "als", "an\u00b7dern", "sch\u00e4d\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "KOUS", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Doch da\u00df ich allen stracks mein Hertze solt entdecken/", "tokens": ["Doch", "da\u00df", "ich", "al\u00b7len", "stracks", "mein", "Hert\u00b7ze", "solt", "ent\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "PPOSAT", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "D\u00fcnckt mich so rathsam nicht. Ehr wolt ich mich verstecken/", "tokens": ["D\u00fcnckt", "mich", "so", "rath\u00b7sam", "nicht", ".", "Ehr", "wolt", "ich", "mich", "ver\u00b7ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKNEG", "$.", "NN", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "In ein verw\u00fcstet Land/ in ein verlassen Feld.", "tokens": ["In", "ein", "ver\u00b7w\u00fcs\u00b7tet", "Land", "/", "in", "ein", "ver\u00b7las\u00b7sen", "Feld", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVPP", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wo ein verdorrter Baum sich an die Felsen h\u00e4lt/", "tokens": ["Wo", "ein", "ver\u00b7dorr\u00b7ter", "Baum", "sich", "an", "die", "Fel\u00b7sen", "h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der nun mit Fallen dr\u00e4ut. Dieweil in wenig Jahren/", "tokens": ["Der", "nun", "mit", "Fal\u00b7len", "dr\u00e4ut", ".", "Die\u00b7weil", "in", "we\u00b7nig", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$.", "NN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Ich/ was ein falscher Freund vor eine Last erfahren/", "tokens": ["Ich", "/", "was", "ein", "fal\u00b7scher", "Freund", "vor", "ei\u00b7ne", "Last", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PWS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dieweil (wo denck ich hin?) dieweil ich offt erkannt/", "tokens": ["Die\u00b7weil", "(", "wo", "denck", "ich", "hin", "?", ")", "die\u00b7weil", "ich", "offt", "er\u00b7kannt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWAV", "VVIMP", "PPER", "PTKVZ", "$.", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie man mit Eyden schertzt/ und mit dem Mund und Hand.", "tokens": ["Wie", "man", "mit", "Ey\u00b7den", "schertzt", "/", "und", "mit", "dem", "Mund", "und", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "VVFIN", "$(", "KON", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mit Aug' und Lippen lieg'/ ich wil euch nicht erzehlen/", "tokens": ["Mit", "Aug'", "und", "Lip\u00b7pen", "lieg'", "/", "ich", "wil", "euch", "nicht", "er\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$(", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.36": {"text": "Wie treflich da\u00df er schwur/ als der auf frischer Fahrt", "tokens": ["Wie", "tref\u00b7lich", "da\u00df", "er", "schwur", "/", "als", "der", "auf", "fri\u00b7scher", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Mit dem gefasten Raub von mir ergriffen ward.", "tokens": ["Mit", "dem", "ge\u00b7fas\u00b7ten", "Raub", "von", "mir", "er\u00b7grif\u00b7fen", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und hat n\u00e4chst meiner Th\u00fcr ein St\u00fccklein vorgenommen/", "tokens": ["Und", "hat", "n\u00e4chst", "mei\u00b7ner", "Th\u00fcr", "ein", "St\u00fcck\u00b7lein", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Das auch den Feind verdro\u00df/ um das ich in der Noth/", "tokens": ["Das", "auch", "den", "Feind", "ver\u00b7dro\u00df", "/", "um", "das", "ich", "in", "der", "Noth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "$(", "APPR", "PRELS", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "In die er sich vert\u00e4ufft ihm treuen Beystand both.", "tokens": ["In", "die", "er", "sich", "ver\u00b7t\u00e4ufft", "ihm", "treu\u00b7en", "Beys\u00b7tand", "both", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVFIN", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Um da\u00df ich Ursach bin da\u00df man noch heut' ihn ehret/", "tokens": ["Um", "da\u00df", "ich", "Ur\u00b7sach", "bin", "da\u00df", "man", "noch", "heut'", "ihn", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KOUS", "PPER", "NN", "VAFIN", "KOUS", "PIS", "ADV", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Doch di\u00df ist Kinderwerck: Der/ der mich angeh\u00f6ret/", "tokens": ["Doch", "di\u00df", "ist", "Kin\u00b7der\u00b7werck", ":", "Der", "/", "der", "mich", "an\u00b7ge\u00b7h\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$.", "ART", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und mir durch Blut verkn\u00fcpft; Was hat er nicht erdacht?", "tokens": ["Und", "mir", "durch", "Blut", "ver\u00b7kn\u00fcpft", ";", "Was", "hat", "er", "nicht", "er\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVPP", "$.", "PWS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Hat er nicht f\u00fcr und f\u00fcr auf meinen Fall gewacht?", "tokens": ["Hat", "er", "nicht", "f\u00fcr", "und", "f\u00fcr", "auf", "mei\u00b7nen", "Fall", "ge\u00b7wacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "KON", "APPR", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wem hab' ichs/ da\u00df ich steh' und ihm entgieng zu dancken?", "tokens": ["Wem", "hab'", "ichs", "/", "da\u00df", "ich", "steh'", "und", "ihm", "ent\u00b7gieng", "zu", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PIS", "$(", "KOUS", "PPER", "VVFIN", "KON", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "O Schande! ", "tokens": ["O", "Schan\u00b7de", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.47": {"text": "Uns schlug mir Beystand ab; Er zog' und rie\u00df zu sich", "tokens": ["Uns", "schlug", "mir", "Beys\u00b7tand", "ab", ";", "Er", "zo\u00b7g'", "und", "rie\u00df", "zu", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "PRF"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.48": {"text": "Was doch mein eigen war. ", "tokens": ["Was", "doch", "mein", "ei\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.49": {"text": "Umsonst/ eh' als sie schied/ zu Erben eingesetzet/", "tokens": ["Um\u00b7sonst", "/", "eh'", "als", "sie", "schied", "/", "zu", "Er\u00b7ben", "ein\u00b7ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "KOUS", "PPER", "VVFIN", "$(", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Das sch\u00f6ne Gold/ das ihr/ als sie der Todt verletzet/", "tokens": ["Das", "sch\u00f6\u00b7ne", "Gold", "/", "das", "ihr", "/", "als", "sie", "der", "Todt", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PPER", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Noch um den zarten Hal\u00df und beyde Br\u00fcste hing/", "tokens": ["Noch", "um", "den", "zar\u00b7ten", "Hal\u00df", "und", "bey\u00b7de", "Br\u00fcs\u00b7te", "hing", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "KON", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Der beyden Ohren Pracht/ und der so theure Ring", "tokens": ["Der", "bey\u00b7den", "Oh\u00b7ren", "Pracht", "/", "und", "der", "so", "theu\u00b7re", "Ring"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "$(", "KON", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ward/ als sie noch nicht kalt/ in einem nun verr\u00fccket!", "tokens": ["Ward", "/", "als", "sie", "noch", "nicht", "kalt", "/", "in", "ei\u00b7nem", "nun", "ver\u00b7r\u00fc\u00b7cket", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "$(", "APPR", "ART", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Jetzt hat der Mann sein Weib und Kind damit geschm\u00fccket!", "tokens": ["Jetzt", "hat", "der", "Mann", "sein", "Weib", "und", "Kind", "da\u00b7mit", "ge\u00b7schm\u00fc\u00b7cket", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "KON", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Schaut seine Kammern an: Was hier und dar zu sehn/", "tokens": ["Schaut", "sei\u00b7ne", "Kam\u00b7mern", "an", ":", "Was", "hier", "und", "dar", "zu", "sehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "PWS", "ADV", "KON", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Steht meines Vatern Geld. Ruffin der alle schm\u00e4hn/", "tokens": ["Steht", "mei\u00b7nes", "Va\u00b7tern", "Geld", ".", "Ruf\u00b7fin", "der", "al\u00b7le", "schm\u00e4hn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$.", "NN", "ART", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und keinen loben kan/ wird sich so sch\u00f6ne machen/", "tokens": ["Und", "kei\u00b7nen", "lo\u00b7ben", "kan", "/", "wird", "sich", "so", "sch\u00f6\u00b7ne", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVINF", "VMFIN", "$(", "VAFIN", "PRF", "ADV", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Dafern er zu mir kommt: Bald wird er h\u00f6nisch lachen/", "tokens": ["Da\u00b7fern", "er", "zu", "mir", "kommt", ":", "Bald", "wird", "er", "h\u00f6\u00b7nisch", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und l\u00e4stern was ich schrieb: Weil sein verfluchter Mund", "tokens": ["Und", "l\u00e4s\u00b7tern", "was", "ich", "schrieb", ":", "Weil", "sein", "ver\u00b7fluch\u00b7ter", "Mund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VVFIN", "$.", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "(trotzt diesem/ den es schmertzt) von mir mit gutem Grund", "tokens": ["(", "trotzt", "die\u00b7sem", "/", "den", "es", "schmertzt", ")", "von", "mir", "mit", "gu\u00b7tem", "Grund"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PDAT", "$(", "ART", "PPER", "VVFIN", "$(", "APPR", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Nichts sch\u00e4ndlichs sagen kan. Kein Tag' ist vor erblichen/", "tokens": ["Nichts", "sch\u00e4nd\u00b7lichs", "sa\u00b7gen", "kan", ".", "Kein", "Tag'", "ist", "vor", "er\u00b7bli\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVINF", "VMFIN", "$.", "PIAT", "NN", "VAFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "In welchem nicht Levin schier st\u00fcndlich kam geschlichen/", "tokens": ["In", "wel\u00b7chem", "nicht", "Le\u00b7vin", "schier", "st\u00fcnd\u00b7lich", "kam", "ge\u00b7schli\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PTKNEG", "NN", "ADJD", "ADJD", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und seine Dienst' anboth. Bi\u00df er von mir erlangt", "tokens": ["Und", "sei\u00b7ne", "Dienst'", "an\u00b7both", ".", "Bi\u00df", "er", "von", "mir", "er\u00b7langt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$.", "KOUS", "PPER", "APPR", "PPER", "VVPP"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.64": {"text": "(den er nunmehr nicht kennt) womit er pocht' und prangt.", "tokens": ["(", "den", "er", "nun\u00b7mehr", "nicht", "kennt", ")", "wo\u00b7mit", "er", "pocht'", "und", "prangt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PPER", "ADV", "PTKNEG", "VVFIN", "$(", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Da auch was mehr denn sonst/ die Taffel wird besetzet/", "tokens": ["Da", "auch", "was", "mehr", "denn", "sonst", "/", "die", "Taf\u00b7fel", "wird", "be\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PWS", "ADV", "ADV", "ADV", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Kommt ", "tokens": ["Kommt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.67": {"text": "Und Speise fr\u00f6lich macht. Schleust man die K\u00fcchen zu/", "tokens": ["Und", "Spei\u00b7se", "fr\u00f6\u00b7lich", "macht", ".", "Schleust", "man", "die", "K\u00fc\u00b7chen", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVFIN", "$.", "NN", "PIS", "ART", "NN", "PTKZU", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.68": {"text": "Denn hat mein Diener wohl f\u00fcr seinem klopffen Ruh.", "tokens": ["Denn", "hat", "mein", "Die\u00b7ner", "wohl", "f\u00fcr", "sei\u00b7nem", "klopf\u00b7fen", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Sucht ", "tokens": ["Sucht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.70": {"text": "Darff ", "tokens": ["Darff"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.71": {"text": "Den fragt man auf der Burg/ den fragt man in der Stadt/", "tokens": ["Den", "fragt", "man", "auf", "der", "Burg", "/", "den", "fragt", "man", "in", "der", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "APPR", "ART", "NN", "$(", "ART", "VVFIN", "PIS", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Bi\u00df dieser oder der mich angetroffen hat.", "tokens": ["Bi\u00df", "die\u00b7ser", "o\u00b7der", "der", "mich", "an\u00b7ge\u00b7trof\u00b7fen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "KON", "ART", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Denn hei\u00df ich Herr und Freund/ denn wil ", "tokens": ["Denn", "hei\u00df", "ich", "Herr", "und", "Freund", "/", "denn", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "PPER", "NN", "KON", "NN", "$(", "KON", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.75": {"text": "So bald man ohne mich den Wagen f\u00fchren kan/", "tokens": ["So", "bald", "man", "oh\u00b7ne", "mich", "den", "Wa\u00b7gen", "f\u00fch\u00b7ren", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "PPER", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Denn sieht mich ", "tokens": ["Denn", "sieht", "mich"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.77": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.78": {"text": "Wo meine Wohnung war/ und wo ich angesessen/", "tokens": ["Wo", "mei\u00b7ne", "Woh\u00b7nung", "war", "/", "und", "wo", "ich", "an\u00b7ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VAFIN", "$(", "KON", "PWAV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Was red' ich? Ist ein Mensch/ dem ", "tokens": ["Was", "red'", "ich", "?", "Ist", "ein", "Mensch", "/", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VAFIN", "ART", "NN", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.80": {"text": "Und dem verborgen ist/ wie ich mit Hertz und Hand", "tokens": ["Und", "dem", "ver\u00b7bor\u00b7gen", "ist", "/", "wie", "ich", "mit", "Hertz", "und", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVPP", "VAFIN", "$(", "PWAV", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Ihm beygesprungen bin. Was hab' ich nicht erlitten?", "tokens": ["Ihm", "bey\u00b7ge\u00b7sprun\u00b7gen", "bin", ".", "Was", "hab'", "ich", "nicht", "er\u00b7lit\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAFIN", "$.", "PWS", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Als er von so viel Angst und grimmer Noth bestritten", "tokens": ["Als", "er", "von", "so", "viel", "Angst", "und", "grim\u00b7mer", "Noth", "be\u00b7strit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADV", "PIAT", "NN", "KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Wir in die Armen fiel/ und sein Anliegen klagt", "tokens": ["Wir", "in", "die", "Ar\u00b7men", "fiel", "/", "und", "sein", "An\u00b7lie\u00b7gen", "klagt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Da ich mein Leben selbst f\u00fcr seines hingewagt.", "tokens": ["Da", "ich", "mein", "Le\u00b7ben", "selbst", "f\u00fcr", "sei\u00b7nes", "hin\u00b7ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Was hat er vor und ietzt? Das er mir nicht zu dancken?", "tokens": ["Was", "hat", "er", "vor", "und", "ietzt", "?", "Das", "er", "mir", "nicht", "zu", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKVZ", "KON", "ADV", "$.", "PDS", "PPER", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Jetzt schm\u00e4ht mich ", "tokens": ["Jetzt", "schm\u00e4ht", "mich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.87": {"text": "Ein rasend tolles Pferd ohn Zaum und Ziegel rennt/", "tokens": ["Ein", "ra\u00b7send", "tol\u00b7les", "Pferd", "ohn", "Zaum", "und", "Zie\u00b7gel", "rennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Das weder rechte Bahn noch Menschen-Stimm' erkennt/", "tokens": ["Das", "we\u00b7der", "rech\u00b7te", "Bahn", "noch", "Men\u00b7schen\u00b7Stimm'", "er\u00b7kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "ADJA", "NN", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Und seinen Meister Tritt/ und durch den Sand umreisset/", "tokens": ["Und", "sei\u00b7nen", "Meis\u00b7ter", "Tritt", "/", "und", "durch", "den", "Sand", "um\u00b7reis\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$(", "KON", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Und was entgegen kommt voll Grimm zu boden schmeisset.", "tokens": ["Und", "was", "ent\u00b7ge\u00b7gen", "kommt", "voll", "Grimm", "zu", "bo\u00b7den", "schmeis\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKVZ", "VVFIN", "ADJD", "NE", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Nicht wenig die es schmertzt/ beklagen meine Treu/", "tokens": ["Nicht", "we\u00b7nig", "die", "es", "schmertzt", "/", "be\u00b7kla\u00b7gen", "mei\u00b7ne", "Treu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "PPER", "VVFIN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Umsonst ihr Liebsten! Ach! es ist nicht heute neu;", "tokens": ["Um\u00b7sonst", "ihr", "Liebs\u00b7ten", "!", "Ach", "!", "es", "ist", "nicht", "heu\u00b7te", "neu", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$.", "ITJ", "$.", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Da\u00df Undanck auf den Danck und Schimpff auf Wolthat folge/", "tokens": ["Da\u00df", "Un\u00b7danck", "auf", "den", "Danck", "und", "Schimpff", "auf", "Wolt\u00b7hat", "fol\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Drum m\u00f6gen immerhin die Scythen an der Wolge", "tokens": ["Drum", "m\u00f6\u00b7gen", "im\u00b7mer\u00b7hin", "die", "Scyt\u00b7hen", "an", "der", "Wol\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und dort bey Astracan auf recht und redlich seyn.", "tokens": ["Und", "dort", "bey", "A\u00b7stra\u00b7can", "auf", "recht", "und", "red\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "APPR", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.96": {"text": "Der \u00fcberklugen Welt geht nur die Falschheit ein.", "tokens": ["Der", "\u00fc\u00b7berk\u00b7lu\u00b7gen", "Welt", "geht", "nur", "die", "Falschheit", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Man fragt ", "tokens": ["Man", "fragt"], "token_info": ["word", "word"], "pos": ["PIS", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "Da\u00df ich so einsam mir zu leben vorgenommen/", "tokens": ["Da\u00df", "ich", "so", "ein\u00b7sam", "mir", "zu", "le\u00b7ben", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "PPER", "PTKZU", "VVINF", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df mich ein todtes Buch/ ein rauher Wald ergetzt/", "tokens": ["Da\u00df", "mich", "ein", "tod\u00b7tes", "Buch", "/", "ein", "rau\u00b7her", "Wald", "er\u00b7getzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$(", "ART", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da ", "tokens": ["Da"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Die mit gebeugtem Knie ihm schier die F\u00fcsse k\u00fcssen/", "tokens": ["Die", "mit", "ge\u00b7beug\u00b7tem", "Knie", "ihm", "schier", "die", "F\u00fcs\u00b7se", "k\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "PPER", "ADJD", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und bi\u00df nach Mitternacht vom Morgen ihn begr\u00fcssen.", "tokens": ["Und", "bi\u00df", "nach", "Mit\u00b7ter\u00b7nacht", "vom", "Mor\u00b7gen", "ihn", "be\u00b7gr\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die/ wenn er \u00fcber Feld und \u00fcber See wil gehn/", "tokens": ["Die", "/", "wenn", "er", "\u00fc\u00b7ber", "Feld", "und", "\u00fc\u00b7ber", "See", "wil", "gehn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$(", "KOUS", "PPER", "APPR", "NN", "KON", "APPR", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als Sclaven/ auf ein Wort/ ihm zu Gebote stehn.", "tokens": ["Als", "Scla\u00b7ven", "/", "auf", "ein", "Wort", "/", "ihm", "zu", "Ge\u00b7bo\u00b7te", "stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$(", "APPR", "ART", "NN", "$(", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was mag die Ursach seyn? man hat ja offt versp\u00fchret/", "tokens": ["Was", "mag", "die", "Ur\u00b7sach", "seyn", "?", "man", "hat", "ja", "offt", "ver\u00b7sp\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "VAINF", "$.", "PIS", "VAFIN", "ADV", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das mich mein D\u00fcnckel nicht in mich allein verf\u00fchret/", "tokens": ["Das", "mich", "mein", "D\u00fcn\u00b7ckel", "nicht", "in", "mich", "al\u00b7lein", "ver\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "PPOSAT", "NN", "PTKNEG", "APPR", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mein niemals falsches Hertz mit grosser Freundligkeit.", "tokens": ["Mein", "nie\u00b7mals", "fal\u00b7sches", "Hertz", "mit", "gros\u00b7ser", "Freund\u00b7lig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sein \u00fcber-pr\u00e4chtig Haus was \u00f6ffter zu betreten/", "tokens": ["Sein", "\u00fc\u00b7ber\u00b7pr\u00e4ch\u00b7tig", "Haus", "was", "\u00f6ff\u00b7ter", "zu", "be\u00b7tre\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJD", "NN", "PWS", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die grosse ", "tokens": ["Die", "gros\u00b7se"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Man zeucht mich hier und dar nicht wenig andern vor.", "tokens": ["Man", "zeucht", "mich", "hier", "und", "dar", "nicht", "we\u00b7nig", "an\u00b7dern", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "KON", "PTKVZ", "PTKNEG", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man kennt und ehrt mich dort/ wo ich noch nie hinkommen/", "tokens": ["Man", "kennt", "und", "ehrt", "mich", "dort", "/", "wo", "ich", "noch", "nie", "hin\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$(", "PWAV", "PPER", "ADV", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Viel Seelen haben mich in ihren Bund genommen.", "tokens": ["Viel", "See\u00b7len", "ha\u00b7ben", "mich", "in", "ih\u00b7ren", "Bund", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Viel lieb' ich mehr denn mich und bin nicht selber mein/", "tokens": ["Viel", "lieb'", "ich", "mehr", "denn", "mich", "und", "bin", "nicht", "sel\u00b7ber", "mein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "PPER", "KON", "VAFIN", "PTKNEG", "ADV", "PPOSAT", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Dafern zu ihrem Nutz ich kan beh\u00fclfflich seyn.", "tokens": ["Da\u00b7fern", "zu", "ih\u00b7rem", "Nutz", "ich", "kan", "be\u00b7h\u00fclf\u00b7flich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Da\u00df ich mich aber nicht mach' iedermann gemeine/", "tokens": ["Da\u00df", "ich", "mich", "a\u00b7ber", "nicht", "mach'", "ie\u00b7der\u00b7mann", "ge\u00b7mei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKNEG", "VVFIN", "ADV", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ist di\u00df wol fragens werth? Viel besser gantz alleine/", "tokens": ["Ist", "di\u00df", "wol", "fra\u00b7gens", "werth", "?", "Viel", "bes\u00b7ser", "gantz", "al\u00b7lei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ADV", "ADV", "ADJD", "$.", "ADV", "ADJD", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Als unter fremden Volck/ das untreu in der That/", "tokens": ["Als", "un\u00b7ter", "frem\u00b7den", "Volck", "/", "das", "un\u00b7treu", "in", "der", "That", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "$(", "ART", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-++--+", "measure": "iambic.hexa.chol"}, "line.22": {"text": "Und nichts denn lauter Treu auf falscher Zungen hat.", "tokens": ["Und", "nichts", "denn", "lau\u00b7ter", "Treu", "auf", "fal\u00b7scher", "Zun\u00b7gen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Mit allen geh ich um. Ich werde nichts versagen/", "tokens": ["Mit", "al\u00b7len", "geh", "ich", "um", ".", "Ich", "wer\u00b7de", "nichts", "ver\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVFIN", "PPER", "PTKVZ", "$.", "PPER", "VAFIN", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Dafern es m\u00f6glich ist. Man mag mich sicher fragen/", "tokens": ["Da\u00b7fern", "es", "m\u00f6g\u00b7lich", "ist", ".", "Man", "mag", "mich", "si\u00b7cher", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VAFIN", "$.", "PIS", "VMFIN", "PRF", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Ich wil mir lieber selbst als andern sch\u00e4dlich seyn.", "tokens": ["Ich", "wil", "mir", "lie\u00b7ber", "selbst", "als", "an\u00b7dern", "sch\u00e4d\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "KOUS", "PIS", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Doch da\u00df ich allen stracks mein Hertze solt entdecken/", "tokens": ["Doch", "da\u00df", "ich", "al\u00b7len", "stracks", "mein", "Hert\u00b7ze", "solt", "ent\u00b7de\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PIAT", "NN", "PPOSAT", "VVFIN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "D\u00fcnckt mich so rathsam nicht. Ehr wolt ich mich verstecken/", "tokens": ["D\u00fcnckt", "mich", "so", "rath\u00b7sam", "nicht", ".", "Ehr", "wolt", "ich", "mich", "ver\u00b7ste\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKNEG", "$.", "NN", "VMFIN", "PPER", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "In ein verw\u00fcstet Land/ in ein verlassen Feld.", "tokens": ["In", "ein", "ver\u00b7w\u00fcs\u00b7tet", "Land", "/", "in", "ein", "ver\u00b7las\u00b7sen", "Feld", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "VVPP", "NN", "$(", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Wo ein verdorrter Baum sich an die Felsen h\u00e4lt/", "tokens": ["Wo", "ein", "ver\u00b7dorr\u00b7ter", "Baum", "sich", "an", "die", "Fel\u00b7sen", "h\u00e4lt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Der nun mit Fallen dr\u00e4ut. Dieweil in wenig Jahren/", "tokens": ["Der", "nun", "mit", "Fal\u00b7len", "dr\u00e4ut", ".", "Die\u00b7weil", "in", "we\u00b7nig", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$.", "NN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Ich/ was ein falscher Freund vor eine Last erfahren/", "tokens": ["Ich", "/", "was", "ein", "fal\u00b7scher", "Freund", "vor", "ei\u00b7ne", "Last", "er\u00b7fah\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PWS", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Dieweil (wo denck ich hin?) dieweil ich offt erkannt/", "tokens": ["Die\u00b7weil", "(", "wo", "denck", "ich", "hin", "?", ")", "die\u00b7weil", "ich", "offt", "er\u00b7kannt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$(", "PWAV", "VVIMP", "PPER", "PTKVZ", "$.", "$(", "KOUS", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wie man mit Eyden schertzt/ und mit dem Mund und Hand.", "tokens": ["Wie", "man", "mit", "Ey\u00b7den", "schertzt", "/", "und", "mit", "dem", "Mund", "und", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "NN", "VVFIN", "$(", "KON", "APPR", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Mit Aug' und Lippen lieg'/ ich wil euch nicht erzehlen/", "tokens": ["Mit", "Aug'", "und", "Lip\u00b7pen", "lieg'", "/", "ich", "wil", "euch", "nicht", "er\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$(", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.36": {"text": "Wie treflich da\u00df er schwur/ als der auf frischer Fahrt", "tokens": ["Wie", "tref\u00b7lich", "da\u00df", "er", "schwur", "/", "als", "der", "auf", "fri\u00b7scher", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "ART", "APPR", "ADJA", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Mit dem gefasten Raub von mir ergriffen ward.", "tokens": ["Mit", "dem", "ge\u00b7fas\u00b7ten", "Raub", "von", "mir", "er\u00b7grif\u00b7fen", "ward", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Und hat n\u00e4chst meiner Th\u00fcr ein St\u00fccklein vorgenommen/", "tokens": ["Und", "hat", "n\u00e4chst", "mei\u00b7ner", "Th\u00fcr", "ein", "St\u00fcck\u00b7lein", "vor\u00b7ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Das auch den Feind verdro\u00df/ um das ich in der Noth/", "tokens": ["Das", "auch", "den", "Feind", "ver\u00b7dro\u00df", "/", "um", "das", "ich", "in", "der", "Noth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "NN", "VVFIN", "$(", "APPR", "PRELS", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "In die er sich vert\u00e4ufft ihm treuen Beystand both.", "tokens": ["In", "die", "er", "sich", "ver\u00b7t\u00e4ufft", "ihm", "treu\u00b7en", "Beys\u00b7tand", "both", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVFIN", "PPER", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Um da\u00df ich Ursach bin da\u00df man noch heut' ihn ehret/", "tokens": ["Um", "da\u00df", "ich", "Ur\u00b7sach", "bin", "da\u00df", "man", "noch", "heut'", "ihn", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "KOUS", "PPER", "NN", "VAFIN", "KOUS", "PIS", "ADV", "ADV", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Doch di\u00df ist Kinderwerck: Der/ der mich angeh\u00f6ret/", "tokens": ["Doch", "di\u00df", "ist", "Kin\u00b7der\u00b7werck", ":", "Der", "/", "der", "mich", "an\u00b7ge\u00b7h\u00f6\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "NN", "$.", "ART", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Und mir durch Blut verkn\u00fcpft; Was hat er nicht erdacht?", "tokens": ["Und", "mir", "durch", "Blut", "ver\u00b7kn\u00fcpft", ";", "Was", "hat", "er", "nicht", "er\u00b7dacht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVPP", "$.", "PWS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Hat er nicht f\u00fcr und f\u00fcr auf meinen Fall gewacht?", "tokens": ["Hat", "er", "nicht", "f\u00fcr", "und", "f\u00fcr", "auf", "mei\u00b7nen", "Fall", "ge\u00b7wacht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "APPR", "KON", "APPR", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wem hab' ichs/ da\u00df ich steh' und ihm entgieng zu dancken?", "tokens": ["Wem", "hab'", "ichs", "/", "da\u00df", "ich", "steh'", "und", "ihm", "ent\u00b7gieng", "zu", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PIS", "$(", "KOUS", "PPER", "VVFIN", "KON", "PPER", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "O Schande! ", "tokens": ["O", "Schan\u00b7de", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.47": {"text": "Uns schlug mir Beystand ab; Er zog' und rie\u00df zu sich", "tokens": ["Uns", "schlug", "mir", "Beys\u00b7tand", "ab", ";", "Er", "zo\u00b7g'", "und", "rie\u00df", "zu", "sich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "PRF"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.48": {"text": "Was doch mein eigen war. ", "tokens": ["Was", "doch", "mein", "ei\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.49": {"text": "Umsonst/ eh' als sie schied/ zu Erben eingesetzet/", "tokens": ["Um\u00b7sonst", "/", "eh'", "als", "sie", "schied", "/", "zu", "Er\u00b7ben", "ein\u00b7ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "KOUS", "KOUS", "PPER", "VVFIN", "$(", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Das sch\u00f6ne Gold/ das ihr/ als sie der Todt verletzet/", "tokens": ["Das", "sch\u00f6\u00b7ne", "Gold", "/", "das", "ihr", "/", "als", "sie", "der", "Todt", "ver\u00b7let\u00b7zet", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$(", "PRELS", "PPER", "$(", "KOUS", "PPER", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Noch um den zarten Hal\u00df und beyde Br\u00fcste hing/", "tokens": ["Noch", "um", "den", "zar\u00b7ten", "Hal\u00df", "und", "bey\u00b7de", "Br\u00fcs\u00b7te", "hing", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "KON", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Der beyden Ohren Pracht/ und der so theure Ring", "tokens": ["Der", "bey\u00b7den", "Oh\u00b7ren", "Pracht", "/", "und", "der", "so", "theu\u00b7re", "Ring"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "NN", "$(", "KON", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Ward/ als sie noch nicht kalt/ in einem nun verr\u00fccket!", "tokens": ["Ward", "/", "als", "sie", "noch", "nicht", "kalt", "/", "in", "ei\u00b7nem", "nun", "ver\u00b7r\u00fc\u00b7cket", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$(", "KOUS", "PPER", "ADV", "PTKNEG", "ADJD", "$(", "APPR", "ART", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Jetzt hat der Mann sein Weib und Kind damit geschm\u00fccket!", "tokens": ["Jetzt", "hat", "der", "Mann", "sein", "Weib", "und", "Kind", "da\u00b7mit", "ge\u00b7schm\u00fc\u00b7cket", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PPOSAT", "NN", "KON", "NN", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Schaut seine Kammern an: Was hier und dar zu sehn/", "tokens": ["Schaut", "sei\u00b7ne", "Kam\u00b7mern", "an", ":", "Was", "hier", "und", "dar", "zu", "sehn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$.", "PWS", "ADV", "KON", "PTKVZ", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Steht meines Vatern Geld. Ruffin der alle schm\u00e4hn/", "tokens": ["Steht", "mei\u00b7nes", "Va\u00b7tern", "Geld", ".", "Ruf\u00b7fin", "der", "al\u00b7le", "schm\u00e4hn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$.", "NN", "ART", "PIS", "VVINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Und keinen loben kan/ wird sich so sch\u00f6ne machen/", "tokens": ["Und", "kei\u00b7nen", "lo\u00b7ben", "kan", "/", "wird", "sich", "so", "sch\u00f6\u00b7ne", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVINF", "VMFIN", "$(", "VAFIN", "PRF", "ADV", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Dafern er zu mir kommt: Bald wird er h\u00f6nisch lachen/", "tokens": ["Da\u00b7fern", "er", "zu", "mir", "kommt", ":", "Bald", "wird", "er", "h\u00f6\u00b7nisch", "la\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Und l\u00e4stern was ich schrieb: Weil sein verfluchter Mund", "tokens": ["Und", "l\u00e4s\u00b7tern", "was", "ich", "schrieb", ":", "Weil", "sein", "ver\u00b7fluch\u00b7ter", "Mund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PWS", "PPER", "VVFIN", "$.", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "(trotzt diesem/ den es schmertzt) von mir mit gutem Grund", "tokens": ["(", "trotzt", "die\u00b7sem", "/", "den", "es", "schmertzt", ")", "von", "mir", "mit", "gu\u00b7tem", "Grund"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "VVFIN", "PDAT", "$(", "ART", "PPER", "VVFIN", "$(", "APPR", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Nichts sch\u00e4ndlichs sagen kan. Kein Tag' ist vor erblichen/", "tokens": ["Nichts", "sch\u00e4nd\u00b7lichs", "sa\u00b7gen", "kan", ".", "Kein", "Tag'", "ist", "vor", "er\u00b7bli\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PIS", "VVINF", "VMFIN", "$.", "PIAT", "NN", "VAFIN", "APPR", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "In welchem nicht Levin schier st\u00fcndlich kam geschlichen/", "tokens": ["In", "wel\u00b7chem", "nicht", "Le\u00b7vin", "schier", "st\u00fcnd\u00b7lich", "kam", "ge\u00b7schli\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PTKNEG", "NN", "ADJD", "ADJD", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Und seine Dienst' anboth. Bi\u00df er von mir erlangt", "tokens": ["Und", "sei\u00b7ne", "Dienst'", "an\u00b7both", ".", "Bi\u00df", "er", "von", "mir", "er\u00b7langt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "$.", "KOUS", "PPER", "APPR", "PPER", "VVPP"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.64": {"text": "(den er nunmehr nicht kennt) womit er pocht' und prangt.", "tokens": ["(", "den", "er", "nun\u00b7mehr", "nicht", "kennt", ")", "wo\u00b7mit", "er", "pocht'", "und", "prangt", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "PPER", "ADV", "PTKNEG", "VVFIN", "$(", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Da auch was mehr denn sonst/ die Taffel wird besetzet/", "tokens": ["Da", "auch", "was", "mehr", "denn", "sonst", "/", "die", "Taf\u00b7fel", "wird", "be\u00b7set\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PWS", "ADV", "ADV", "ADV", "$(", "ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Kommt ", "tokens": ["Kommt"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "-", "measure": "single.down"}, "line.67": {"text": "Und Speise fr\u00f6lich macht. Schleust man die K\u00fcchen zu/", "tokens": ["Und", "Spei\u00b7se", "fr\u00f6\u00b7lich", "macht", ".", "Schleust", "man", "die", "K\u00fc\u00b7chen", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "VVFIN", "$.", "NN", "PIS", "ART", "NN", "PTKZU", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.68": {"text": "Denn hat mein Diener wohl f\u00fcr seinem klopffen Ruh.", "tokens": ["Denn", "hat", "mein", "Die\u00b7ner", "wohl", "f\u00fcr", "sei\u00b7nem", "klopf\u00b7fen", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Sucht ", "tokens": ["Sucht"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.70": {"text": "Darff ", "tokens": ["Darff"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.71": {"text": "Den fragt man auf der Burg/ den fragt man in der Stadt/", "tokens": ["Den", "fragt", "man", "auf", "der", "Burg", "/", "den", "fragt", "man", "in", "der", "Stadt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIS", "APPR", "ART", "NN", "$(", "ART", "VVFIN", "PIS", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.72": {"text": "Bi\u00df dieser oder der mich angetroffen hat.", "tokens": ["Bi\u00df", "die\u00b7ser", "o\u00b7der", "der", "mich", "an\u00b7ge\u00b7trof\u00b7fen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "KON", "ART", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.73": {"text": "Denn hei\u00df ich Herr und Freund/ denn wil ", "tokens": ["Denn", "hei\u00df", "ich", "Herr", "und", "Freund", "/", "denn", "wil"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "PPER", "NN", "KON", "NN", "$(", "KON", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.75": {"text": "So bald man ohne mich den Wagen f\u00fchren kan/", "tokens": ["So", "bald", "man", "oh\u00b7ne", "mich", "den", "Wa\u00b7gen", "f\u00fch\u00b7ren", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "APPR", "PPER", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Denn sieht mich ", "tokens": ["Denn", "sieht", "mich"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.77": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.78": {"text": "Wo meine Wohnung war/ und wo ich angesessen/", "tokens": ["Wo", "mei\u00b7ne", "Woh\u00b7nung", "war", "/", "und", "wo", "ich", "an\u00b7ge\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VAFIN", "$(", "KON", "PWAV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Was red' ich? Ist ein Mensch/ dem ", "tokens": ["Was", "red'", "ich", "?", "Ist", "ein", "Mensch", "/", "dem"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VAFIN", "ART", "NN", "$(", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.80": {"text": "Und dem verborgen ist/ wie ich mit Hertz und Hand", "tokens": ["Und", "dem", "ver\u00b7bor\u00b7gen", "ist", "/", "wie", "ich", "mit", "Hertz", "und", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "VVPP", "VAFIN", "$(", "PWAV", "PPER", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Ihm beygesprungen bin. Was hab' ich nicht erlitten?", "tokens": ["Ihm", "bey\u00b7ge\u00b7sprun\u00b7gen", "bin", ".", "Was", "hab'", "ich", "nicht", "er\u00b7lit\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAFIN", "$.", "PWS", "VAFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Als er von so viel Angst und grimmer Noth bestritten", "tokens": ["Als", "er", "von", "so", "viel", "Angst", "und", "grim\u00b7mer", "Noth", "be\u00b7strit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADV", "PIAT", "NN", "KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Wir in die Armen fiel/ und sein Anliegen klagt", "tokens": ["Wir", "in", "die", "Ar\u00b7men", "fiel", "/", "und", "sein", "An\u00b7lie\u00b7gen", "klagt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$(", "KON", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Da ich mein Leben selbst f\u00fcr seines hingewagt.", "tokens": ["Da", "ich", "mein", "Le\u00b7ben", "selbst", "f\u00fcr", "sei\u00b7nes", "hin\u00b7ge\u00b7wagt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "APPR", "PPOSAT", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Was hat er vor und ietzt? Das er mir nicht zu dancken?", "tokens": ["Was", "hat", "er", "vor", "und", "ietzt", "?", "Das", "er", "mir", "nicht", "zu", "dan\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "PTKVZ", "KON", "ADV", "$.", "PDS", "PPER", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Jetzt schm\u00e4ht mich ", "tokens": ["Jetzt", "schm\u00e4ht", "mich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.87": {"text": "Ein rasend tolles Pferd ohn Zaum und Ziegel rennt/", "tokens": ["Ein", "ra\u00b7send", "tol\u00b7les", "Pferd", "ohn", "Zaum", "und", "Zie\u00b7gel", "rennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Das weder rechte Bahn noch Menschen-Stimm' erkennt/", "tokens": ["Das", "we\u00b7der", "rech\u00b7te", "Bahn", "noch", "Men\u00b7schen\u00b7Stimm'", "er\u00b7kennt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "ADJA", "NN", "ADV", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Und seinen Meister Tritt/ und durch den Sand umreisset/", "tokens": ["Und", "sei\u00b7nen", "Meis\u00b7ter", "Tritt", "/", "und", "durch", "den", "Sand", "um\u00b7reis\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$(", "KON", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Und was entgegen kommt voll Grimm zu boden schmeisset.", "tokens": ["Und", "was", "ent\u00b7ge\u00b7gen", "kommt", "voll", "Grimm", "zu", "bo\u00b7den", "schmeis\u00b7set", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKVZ", "VVFIN", "ADJD", "NE", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Nicht wenig die es schmertzt/ beklagen meine Treu/", "tokens": ["Nicht", "we\u00b7nig", "die", "es", "schmertzt", "/", "be\u00b7kla\u00b7gen", "mei\u00b7ne", "Treu", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "PPER", "VVFIN", "$(", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Umsonst ihr Liebsten! Ach! es ist nicht heute neu;", "tokens": ["Um\u00b7sonst", "ihr", "Liebs\u00b7ten", "!", "Ach", "!", "es", "ist", "nicht", "heu\u00b7te", "neu", ";"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "$.", "ITJ", "$.", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Da\u00df Undanck auf den Danck und Schimpff auf Wolthat folge/", "tokens": ["Da\u00df", "Un\u00b7danck", "auf", "den", "Danck", "und", "Schimpff", "auf", "Wolt\u00b7hat", "fol\u00b7ge", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "ART", "NN", "KON", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Drum m\u00f6gen immerhin die Scythen an der Wolge", "tokens": ["Drum", "m\u00f6\u00b7gen", "im\u00b7mer\u00b7hin", "die", "Scyt\u00b7hen", "an", "der", "Wol\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "ADV", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Und dort bey Astracan auf recht und redlich seyn.", "tokens": ["Und", "dort", "bey", "A\u00b7stra\u00b7can", "auf", "recht", "und", "red\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NE", "APPR", "ADJD", "KON", "ADJD", "VAINF", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.96": {"text": "Der \u00fcberklugen Welt geht nur die Falschheit ein.", "tokens": ["Der", "\u00fc\u00b7berk\u00b7lu\u00b7gen", "Welt", "geht", "nur", "die", "Falschheit", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}