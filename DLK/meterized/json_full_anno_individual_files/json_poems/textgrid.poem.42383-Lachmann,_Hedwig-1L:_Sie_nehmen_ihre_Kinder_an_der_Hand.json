{"textgrid.poem.42383": {"metadata": {"author": {"name": "Lachmann, Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sie nehmen ihre Kinder an der Hand", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sie nehmen ihre Kinder an der Hand", "tokens": ["Sie", "neh\u00b7men", "ih\u00b7re", "Kin\u00b7der", "an", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ziehen fort; es duldet sie kein Land.", "tokens": ["Und", "zie\u00b7hen", "fort", ";", "es", "dul\u00b7det", "sie", "kein", "Land", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Grenzw\u00e4chter sind auf ihren Weg gestellt,", "tokens": ["Grenz\u00b7w\u00e4ch\u00b7ter", "sind", "auf", "ih\u00b7ren", "Weg", "ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie wenn ein Hund am Tor die Wache h\u00e4lt.", "tokens": ["Wie", "wenn", "ein", "Hund", "am", "Tor", "die", "Wa\u00b7che", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Sind \u00fcberm Meer noch ein paar Ackerbreit,", "tokens": ["Sind", "\u00fc\u00b7berm", "Meer", "noch", "ein", "paar", "A\u00b7cker\u00b7breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ADV", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Worauf nicht Gras noch Futterkorn gedeiht?", "tokens": ["Wo\u00b7rauf", "nicht", "Gras", "noch", "Fut\u00b7ter\u00b7korn", "ge\u00b7deiht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "NN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Sandd\u00fcnen, die kein S\u00e4mann noch bewarf,", "tokens": ["Sand\u00b7d\u00fc\u00b7nen", ",", "die", "kein", "S\u00e4\u00b7mann", "noch", "be\u00b7warf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PIAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dass dort ein Bettelvolk verhungern darf?", "tokens": ["Dass", "dort", "ein", "Bet\u00b7tel\u00b7volk", "ver\u00b7hun\u00b7gern", "darf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der Bauch der Schiffe nimmt sie endlich auf,", "tokens": ["Der", "Bauch", "der", "Schif\u00b7fe", "nimmt", "sie", "end\u00b7lich", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zum Ballast hingeworfen, Hauf um Hauf.", "tokens": ["Zum", "Bal\u00b7last", "hin\u00b7ge\u00b7wor\u00b7fen", ",", "Hauf", "um", "Hauf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und setzt sie an den fernen K\u00fcsten aus", "tokens": ["Und", "setzt", "sie", "an", "den", "fer\u00b7nen", "K\u00fcs\u00b7ten", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Findlingskinder vor ein fremdes Haus.", "tokens": ["Wie", "Find\u00b7lings\u00b7kin\u00b7der", "vor", "ein", "frem\u00b7des", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Sie nehmen ihre Kinder an der Hand", "tokens": ["Sie", "neh\u00b7men", "ih\u00b7re", "Kin\u00b7der", "an", "der", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ziehen fort; es duldet sie kein Land.", "tokens": ["Und", "zie\u00b7hen", "fort", ";", "es", "dul\u00b7det", "sie", "kein", "Land", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Grenzw\u00e4chter sind auf ihren Weg gestellt,", "tokens": ["Grenz\u00b7w\u00e4ch\u00b7ter", "sind", "auf", "ih\u00b7ren", "Weg", "ge\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie wenn ein Hund am Tor die Wache h\u00e4lt.", "tokens": ["Wie", "wenn", "ein", "Hund", "am", "Tor", "die", "Wa\u00b7che", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Sind \u00fcberm Meer noch ein paar Ackerbreit,", "tokens": ["Sind", "\u00fc\u00b7berm", "Meer", "noch", "ein", "paar", "A\u00b7cker\u00b7breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ADV", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Worauf nicht Gras noch Futterkorn gedeiht?", "tokens": ["Wo\u00b7rauf", "nicht", "Gras", "noch", "Fut\u00b7ter\u00b7korn", "ge\u00b7deiht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PTKNEG", "NN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Sandd\u00fcnen, die kein S\u00e4mann noch bewarf,", "tokens": ["Sand\u00b7d\u00fc\u00b7nen", ",", "die", "kein", "S\u00e4\u00b7mann", "noch", "be\u00b7warf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PIAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dass dort ein Bettelvolk verhungern darf?", "tokens": ["Dass", "dort", "ein", "Bet\u00b7tel\u00b7volk", "ver\u00b7hun\u00b7gern", "darf", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Der Bauch der Schiffe nimmt sie endlich auf,", "tokens": ["Der", "Bauch", "der", "Schif\u00b7fe", "nimmt", "sie", "end\u00b7lich", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Zum Ballast hingeworfen, Hauf um Hauf.", "tokens": ["Zum", "Bal\u00b7last", "hin\u00b7ge\u00b7wor\u00b7fen", ",", "Hauf", "um", "Hauf", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Und setzt sie an den fernen K\u00fcsten aus", "tokens": ["Und", "setzt", "sie", "an", "den", "fer\u00b7nen", "K\u00fcs\u00b7ten", "aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie Findlingskinder vor ein fremdes Haus.", "tokens": ["Wie", "Find\u00b7lings\u00b7kin\u00b7der", "vor", "ein", "frem\u00b7des", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}