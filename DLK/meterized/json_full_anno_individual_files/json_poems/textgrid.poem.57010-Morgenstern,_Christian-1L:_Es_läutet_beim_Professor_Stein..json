{"textgrid.poem.57010": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Es l\u00e4utet beim Professor Stein.", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es l\u00e4utet beim Professor Stein.", "tokens": ["Es", "l\u00e4u\u00b7tet", "beim", "Pro\u00b7fes\u00b7sor", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die K\u00f6chin rupft die H\u00fchner.", "tokens": ["Die", "K\u00f6\u00b7chin", "rupft", "die", "H\u00fch\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Minna geht: Wer kann das sein? \u2013", "tokens": ["Die", "Min\u00b7na", "geht", ":", "Wer", "kann", "das", "sein", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "VMFIN", "PDS", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Gaul steht vor der T\u00fcre.", "tokens": ["Ein", "Gaul", "steht", "vor", "der", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Minna wirft die T\u00fcre zu.", "tokens": ["Die", "Min\u00b7na", "wirft", "die", "T\u00fc\u00b7re", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die K\u00f6chin kommt: Was gibt's denn?", "tokens": ["Die", "K\u00f6\u00b7chin", "kommt", ":", "Was", "gibt's", "denn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das Fr\u00e4ulein kommt im Morgenschuh.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "kommt", "im", "Mor\u00b7gen\u00b7schuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es kommt die ganze Familie.", "tokens": ["Es", "kommt", "die", "gan\u00b7ze", "Fa\u00b7mi\u00b7lie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "\u00bbich bin, verzeihn Sie\u00ab, spricht der Gaul,", "tokens": ["\u00bb", "ich", "bin", ",", "ver\u00b7zeihn", "Sie", "\u00ab", ",", "spricht", "der", "Gaul", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "$(", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbder Gaul vom Tischler Bartels.", "tokens": ["\u00bb", "der", "Gaul", "vom", "Tischler", "Bar\u00b7tels", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich brachte Ihnen dazumaul", "tokens": ["Ich", "brach\u00b7te", "Ih\u00b7nen", "da\u00b7zu\u00b7maul"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die T\u00fcr- und Fensterrahmen!\u00ab", "tokens": ["die", "T\u00fcr", "und", "Fens\u00b7ter\u00b7rah\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die vierzehn Leute samt dem Mops,", "tokens": ["Die", "vier\u00b7zehn", "Leu\u00b7te", "samt", "dem", "Mops", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stehn, als ob sie tr\u00e4umten.", "tokens": ["sie", "stehn", ",", "als", "ob", "sie", "tr\u00e4um\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das kleinste Kind tut einen Hops,", "tokens": ["Das", "kleins\u00b7te", "Kind", "tut", "ei\u00b7nen", "Hops", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die andern stehn wie B\u00e4ume.", "tokens": ["die", "an\u00b7dern", "stehn", "wie", "B\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Der Gaul, da keiner ihn versteht,", "tokens": ["Der", "Gaul", ",", "da", "kei\u00b7ner", "ihn", "ver\u00b7steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "schnalzt blo\u00df mal mit der Zunge,", "tokens": ["schnalzt", "blo\u00df", "mal", "mit", "der", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "dann kehrt er still sich ab und geht", "tokens": ["dann", "kehrt", "er", "still", "sich", "ab", "und", "geht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VMFIN", "PRF", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die Treppe wieder hinunter.", "tokens": ["die", "Trep\u00b7pe", "wie\u00b7der", "hin\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Die dreizehn schaun auf ihren Herrn,", "tokens": ["Die", "drei\u00b7zehn", "schaun", "auf", "ih\u00b7ren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ob er nicht sprechen m\u00f6chte", "tokens": ["ob", "er", "nicht", "spre\u00b7chen", "m\u00f6ch\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdas war\u00ab, spricht der Professor Stein,", "tokens": ["\u00bb", "das", "war", "\u00ab", ",", "spricht", "der", "Pro\u00b7fes\u00b7sor", "Stein", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$(", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "\u00bbein unerh\u00f6rtes Erlebnis! ...\u00ab", "tokens": ["\u00bb", "ein", "un\u00b7er\u00b7h\u00f6r\u00b7tes", "Er\u00b7leb\u00b7nis", "!", "...", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Es l\u00e4utet beim Professor Stein.", "tokens": ["Es", "l\u00e4u\u00b7tet", "beim", "Pro\u00b7fes\u00b7sor", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die K\u00f6chin rupft die H\u00fchner.", "tokens": ["Die", "K\u00f6\u00b7chin", "rupft", "die", "H\u00fch\u00b7ner", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die Minna geht: Wer kann das sein? \u2013", "tokens": ["Die", "Min\u00b7na", "geht", ":", "Wer", "kann", "das", "sein", "?", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "VMFIN", "PDS", "VAINF", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Gaul steht vor der T\u00fcre.", "tokens": ["Ein", "Gaul", "steht", "vor", "der", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die Minna wirft die T\u00fcre zu.", "tokens": ["Die", "Min\u00b7na", "wirft", "die", "T\u00fc\u00b7re", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die K\u00f6chin kommt: Was gibt's denn?", "tokens": ["Die", "K\u00f6\u00b7chin", "kommt", ":", "Was", "gibt's", "denn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PWS", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das Fr\u00e4ulein kommt im Morgenschuh.", "tokens": ["Das", "Fr\u00e4u\u00b7lein", "kommt", "im", "Mor\u00b7gen\u00b7schuh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es kommt die ganze Familie.", "tokens": ["Es", "kommt", "die", "gan\u00b7ze", "Fa\u00b7mi\u00b7lie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbich bin, verzeihn Sie\u00ab, spricht der Gaul,", "tokens": ["\u00bb", "ich", "bin", ",", "ver\u00b7zeihn", "Sie", "\u00ab", ",", "spricht", "der", "Gaul", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "VVFIN", "PPER", "$(", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbder Gaul vom Tischler Bartels.", "tokens": ["\u00bb", "der", "Gaul", "vom", "Tischler", "Bar\u00b7tels", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich brachte Ihnen dazumaul", "tokens": ["Ich", "brach\u00b7te", "Ih\u00b7nen", "da\u00b7zu\u00b7maul"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die T\u00fcr- und Fensterrahmen!\u00ab", "tokens": ["die", "T\u00fcr", "und", "Fens\u00b7ter\u00b7rah\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "TRUNC", "KON", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Die vierzehn Leute samt dem Mops,", "tokens": ["Die", "vier\u00b7zehn", "Leu\u00b7te", "samt", "dem", "Mops", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sie stehn, als ob sie tr\u00e4umten.", "tokens": ["sie", "stehn", ",", "als", "ob", "sie", "tr\u00e4um\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Das kleinste Kind tut einen Hops,", "tokens": ["Das", "kleins\u00b7te", "Kind", "tut", "ei\u00b7nen", "Hops", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die andern stehn wie B\u00e4ume.", "tokens": ["die", "an\u00b7dern", "stehn", "wie", "B\u00e4u\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "KOKOM", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Gaul, da keiner ihn versteht,", "tokens": ["Der", "Gaul", ",", "da", "kei\u00b7ner", "ihn", "ver\u00b7steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "schnalzt blo\u00df mal mit der Zunge,", "tokens": ["schnalzt", "blo\u00df", "mal", "mit", "der", "Zun\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "dann kehrt er still sich ab und geht", "tokens": ["dann", "kehrt", "er", "still", "sich", "ab", "und", "geht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "VMFIN", "PRF", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "die Treppe wieder hinunter.", "tokens": ["die", "Trep\u00b7pe", "wie\u00b7der", "hin\u00b7un\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Die dreizehn schaun auf ihren Herrn,", "tokens": ["Die", "drei\u00b7zehn", "schaun", "auf", "ih\u00b7ren", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "CARD", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ob er nicht sprechen m\u00f6chte", "tokens": ["ob", "er", "nicht", "spre\u00b7chen", "m\u00f6ch\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdas war\u00ab, spricht der Professor Stein,", "tokens": ["\u00bb", "das", "war", "\u00ab", ",", "spricht", "der", "Pro\u00b7fes\u00b7sor", "Stein", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PDS", "VAFIN", "$(", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "\u00bbein unerh\u00f6rtes Erlebnis! ...\u00ab", "tokens": ["\u00bb", "ein", "un\u00b7er\u00b7h\u00f6r\u00b7tes", "Er\u00b7leb\u00b7nis", "!", "...", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "$(", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}