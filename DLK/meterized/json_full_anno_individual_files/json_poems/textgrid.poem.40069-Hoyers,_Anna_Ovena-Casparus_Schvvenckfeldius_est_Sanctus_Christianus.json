{"textgrid.poem.40069": {"metadata": {"author": {"name": "Hoyers, Anna Ovena", "birth": "N.A.", "death": "N.A."}, "title": "Casparus Schvvenckfeldius est Sanctus Christianus", "genre": "verse", "period": "N.A.", "pub_year": 1619, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Caspar Schwenckfeld Ein Seeliger Christ", "tokens": ["Cas\u00b7par", "Schwen\u00b7ck\u00b7feld", "Ein", "See\u00b7li\u00b7ger", "Christ"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Vnd Zeug der reinen Warheit ist/", "tokens": ["Vnd", "Zeug", "der", "rei\u00b7nen", "War\u00b7heit", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein gedechtn\u00fc\u00df bleibt jederfrist/", "tokens": ["Sein", "ge\u00b7decht\u00b7n\u00fc\u00df", "bleibt", "je\u00b7der\u00b7frist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wird nicht gedempfft durch Satans list.", "tokens": ["Wird", "nicht", "ge\u00b7dem\u00b7pfft", "durch", "Sa\u00b7tans", "list", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVPP", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Der Frommen Lob breittet au\u00df mit reden und schreiben/", "tokens": ["Der", "From\u00b7men", "Lob", "breit\u00b7tet", "au\u00df", "mit", "re\u00b7den", "und", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "APPR", "VVINF", "KON", "VVINF", "$("], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Gerechten gedechtn\u00fc\u00df wird im Segen bleiben,", "tokens": ["Der", "Ge\u00b7rech\u00b7ten", "ge\u00b7decht\u00b7n\u00fc\u00df", "wird", "im", "Se\u00b7gen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Kein Teuffel oder b\u00f6ser Mensch wird sie vertreiben.", "tokens": ["Kein", "Teuf\u00b7fel", "o\u00b7der", "b\u00f6\u00b7ser", "Mensch", "wird", "sie", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Der Warheit zeug, ein Frommer Christ;", "tokens": ["Der", "War\u00b7heit", "zeug", ",", "ein", "From\u00b7mer", "Christ", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Gottes Wort bey seiner zeit", "tokens": ["Hat", "Got\u00b7tes", "Wort", "bey", "sei\u00b7ner", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch red und schreiben au\u00dfgebreitt/", "tokens": ["Durch", "red", "und", "schrei\u00b7ben", "au\u00df\u00b7ge\u00b7breitt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd umb de\u00dfwillen viel gelitten/", "tokens": ["Vnd", "umb", "de\u00df\u00b7wil\u00b7len", "viel", "ge\u00b7lit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil Satan wieder ihn gestritten/", "tokens": ["Weil", "Sa\u00b7tan", "wie\u00b7der", "ihn", "ge\u00b7strit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd seine Hund' an ihn gehetzt/", "tokens": ["Vnd", "sei\u00b7ne", "Hund'", "an", "ihn", "ge\u00b7hetzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ihm starck haben zugesetzt/", "tokens": ["Die", "ihm", "starck", "ha\u00b7ben", "zu\u00b7ge\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vnd h\u00e4tten ihn zerrissen gern:", "tokens": ["Vnd", "h\u00e4t\u00b7ten", "ihn", "zer\u00b7ris\u00b7sen", "gern", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Aber er war im schutz des Herrn/", "tokens": ["A\u00b7ber", "er", "war", "im", "schutz", "des", "Herrn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Sie musten ihn passieren lassen", "tokens": ["Sie", "mus\u00b7ten", "ihn", "pas\u00b7sie\u00b7ren", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Frey unbesch\u00e4digt seine strassen.", "tokens": ["Frey", "un\u00b7be\u00b7sch\u00e4\u00b7digt", "sei\u00b7ne", "stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Er hat gelebet Gott zum prei\u00df/", "tokens": ["Er", "hat", "ge\u00b7le\u00b7bet", "Gott", "zum", "prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Vnd ruhet itzt im Paradeys:", "tokens": ["Vnd", "ru\u00b7het", "itzt", "im", "Pa\u00b7ra\u00b7deys", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Sein B\u00fccher gehn/ Satan zum trotz/", "tokens": ["Sein", "B\u00fc\u00b7cher", "gehn", "/", "Sa\u00b7tan", "zum", "trotz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$(", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Durch St\u00e4t und Land/ sind vielen n\u00fctz/", "tokens": ["Durch", "St\u00e4t", "und", "Land", "/", "sind", "vie\u00b7len", "n\u00fctz", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Auch kommen Gott sey lob zu mir/", "tokens": ["Auch", "kom\u00b7men", "Gott", "sey", "lob", "zu", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "VAFIN", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Viel gutes ich darinnen sp\u00fchr/", "tokens": ["Viel", "gu\u00b7tes", "ich", "da\u00b7rin\u00b7nen", "sp\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Des waren Wortes Eigenschafft/", "tokens": ["Des", "wa\u00b7ren", "Wor\u00b7tes", "Ei\u00b7gen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sein lebendige w\u00fcrcklich krafft/", "tokens": ["Sein", "le\u00b7ben\u00b7di\u00b7ge", "w\u00fcrck\u00b7lich", "krafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJD", "NN", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.20": {"text": "Sein wesen her von Ewigkeit/", "tokens": ["Sein", "we\u00b7sen", "her", "von", "E\u00b7wig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wird uns hirin klar angedeut.", "tokens": ["Wird", "uns", "hi\u00b7rin", "klar", "an\u00b7ge\u00b7deut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Auch vom Buchstab der Heilig'n Schrifft/", "tokens": ["Auch", "vom", "Buch\u00b7stab", "der", "Hei\u00b7lig'n", "Schrifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.23": {"text": "Was sein W\u00fcrckung und art betrifft/", "tokens": ["Was", "sein", "W\u00fcr\u00b7ckung", "und", "art", "be\u00b7tr\u00b7ifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$("], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Vnd da\u00df er nur sey ein Figur/", "tokens": ["Vnd", "da\u00df", "er", "nur", "sey", "ein", "Fi\u00b7gur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VAFIN", "ART", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.25": {"text": "Des Waren Worts ", "tokens": ["Des", "Wa\u00b7ren", "Worts"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.26": {"text": "So f\u00fcr den eussern Menschen ist;", "tokens": ["So", "f\u00fcr", "den", "eus\u00b7sern", "Men\u00b7schen", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Aber Gottes Wort Jesus Christ/", "tokens": ["A\u00b7ber", "Got\u00b7tes", "Wort", "Je\u00b7sus", "Christ", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "NE", "NE", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Ist Geist und Leben/ redt inwendig/", "tokens": ["Ist", "Geist", "und", "Le\u00b7ben", "/", "redt", "in\u00b7wen\u00b7dig", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "$(", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Machet allein das hertz verst\u00e4ndig/", "tokens": ["Ma\u00b7chet", "al\u00b7lein", "das", "hertz", "ver\u00b7st\u00e4n\u00b7dig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Endert der Menschen sinn und muth/", "tokens": ["En\u00b7dert", "der", "Men\u00b7schen", "sinn", "und", "muth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.31": {"text": "Reicht weiter dann der Buchstab thut.", "tokens": ["Reicht", "wei\u00b7ter", "dann", "der", "Buch\u00b7stab", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Das Eu\u00dfer nur die Ohren r\u00fchrt/", "tokens": ["Das", "Eu\u00b7\u00dfer", "nur", "die", "Oh\u00b7ren", "r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Das Inner wort zum Geist einf\u00fchrt;", "tokens": ["Das", "In\u00b7ner", "wort", "zum", "Geist", "ein\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Bringt mit ihm lebens krafft und safft/", "tokens": ["Bringt", "mit", "ihm", "le\u00b7bens", "krafft", "und", "safft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADJA", "NN", "KON", "VVFIN", "$("], "meter": "+----+-+", "measure": "dactylic.init"}, "line.35": {"text": "Ohn di\u00df das Eu\u00dfer weinig schafft/", "tokens": ["Ohn", "di\u00df", "das", "Eu\u00b7\u00dfer", "wei\u00b7nig", "schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Drumb soll man nach dem Innern trachten/", "tokens": ["Drumb", "soll", "man", "nach", "dem", "In\u00b7nern", "trach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Das Eu\u00dfer aber nicht verachten;", "tokens": ["Das", "Eu\u00b7\u00dfer", "a\u00b7ber", "nicht", "ver\u00b7ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Sondern zum zeugnu\u00df nemen an/", "tokens": ["Son\u00b7dern", "zum", "zeug\u00b7nu\u00df", "ne\u00b7men", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.39": {"text": "Weil es uns dazu dienen kan/", "tokens": ["Weil", "es", "uns", "da\u00b7zu", "die\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Vnd ist darumb gebracht ans Liecht/", "tokens": ["Vnd", "ist", "da\u00b7rumb", "ge\u00b7bracht", "ans", "Liecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "VVPP", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Da\u00df es uns sey zum unterricht/", "tokens": ["Da\u00df", "es", "uns", "sey", "zum", "un\u00b7ter\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Vns tr\u00f6st/ lehr und vermahn mit flei\u00df", "tokens": ["Vns", "tr\u00f6st", "/", "lehr", "und", "ver\u00b7mahn", "mit", "flei\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "VVIMP", "KON", "VVFIN", "APPR", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.43": {"text": "Zuf\u00fchr/ und auff das Inner wei\u00df:", "tokens": ["Zu\u00b7f\u00fchr", "/", "und", "auff", "das", "In\u00b7ner", "wei\u00df", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Kan sonst nichts mehr/ ist viel zu schlecht;", "tokens": ["Kan", "sonst", "nichts", "mehr", "/", "ist", "viel", "zu", "schlecht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "ADV", "$(", "VAFIN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Der Geist ist Herr/ der Buchstab knecht.", "tokens": ["Der", "Geist", "ist", "Herr", "/", "der", "Buch\u00b7stab", "knecht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$(", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "So ich des Worts krafft soll geniessen", "tokens": ["So", "ich", "des", "Worts", "krafft", "soll", "ge\u00b7nies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ART", "NN", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Mu\u00df der Herr selbst mein hertz auffschliessen.", "tokens": ["Mu\u00df", "der", "Herr", "selbst", "mein", "hertz", "auff\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Gleich wie der Purpur Kr\u00e4merinnen/", "tokens": ["Gleich", "wie", "der", "Pur\u00b7pur", "Kr\u00e4\u00b7me\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Al\u00df wir in ", "tokens": ["Al\u00df", "wir", "in"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.50": {"text": "Vmbsonst ist was man h\u00f6rt und list/", "tokens": ["Vmbsonst", "ist", "was", "man", "h\u00f6rt", "und", "list", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PWS", "PIS", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.51": {"text": "So nicht das Wort inwendig ist.", "tokens": ["So", "nicht", "das", "Wort", "in\u00b7wen\u00b7dig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Vom Herren das gedeyen fleust,", "tokens": ["Vom", "Her\u00b7ren", "das", "ge\u00b7de\u00b7yen", "fleust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.53": {"text": "Das inner kan sein wirckung haben/", "tokens": ["Das", "in\u00b7ner", "kan", "sein", "wir\u00b7ckung", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "Ohn eu\u00dfer mittel und Buchstaben:", "tokens": ["Ohn", "eu\u00b7\u00dfer", "mit\u00b7tel", "und", "Buch\u00b7sta\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.55": {"text": "Aber ohn krafft des innern liechts/", "tokens": ["A\u00b7ber", "ohn", "krafft", "des", "in\u00b7nern", "liechts", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "ADJA", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.56": {"text": "Wircken die eu\u00dfern mittel nichts.", "tokens": ["Wir\u00b7cken", "die", "eu\u00b7\u00dfern", "mit\u00b7tel", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PIS", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.57": {"text": "So uns soll nutz seyn h\u00f6rn und lesen/", "tokens": ["So", "uns", "soll", "nutz", "seyn", "h\u00f6rn", "und", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "NN", "PPOSAT", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.58": {"text": "Mu\u00df wircken di\u00df das ware wesen.", "tokens": ["Mu\u00df", "wir\u00b7cken", "di\u00df", "das", "wa\u00b7re", "we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PDS", "PDS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Das Wort das uns die Schrifft erklert/", "tokens": ["Das", "Wort", "das", "uns", "die", "Schrifft", "er\u00b7klert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Die Salbung die uns alles lehrt/", "tokens": ["Die", "Sal\u00b7bung", "die", "uns", "al\u00b7les", "lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Ist die warheit die niemand treugt/", "tokens": ["Ist", "die", "war\u00b7heit", "die", "nie\u00b7mand", "treugt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "PIS", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.62": {"text": "Ein Mund ohn falschheit/ der nicht leugt/", "tokens": ["Ein", "Mund", "ohn", "falschheit", "/", "der", "nicht", "leugt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "ART", "PTKNEG", "VVFIN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.63": {"text": "Der Schl\u00fcssel Davids der auffschleust/", "tokens": ["Der", "Schl\u00fcs\u00b7sel", "Da\u00b7vids", "der", "auff\u00b7schleust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Der Brunn darau\u00df die Wei\u00dfheit fleust/", "tokens": ["Der", "Brunn", "dar\u00b7au\u00df", "die", "Wei\u00df\u00b7heit", "fleust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Ein Liecht so das hertz ", "tokens": ["Ein", "Liecht", "so", "das", "hertz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.66": {"text": "Der Weg so uns zum Vater f\u00fchrt.", "tokens": ["Der", "Weg", "so", "uns", "zum", "Va\u00b7ter", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Im Anfang war die\u00df Lebens Wort/", "tokens": ["Im", "An\u00b7fang", "war", "die\u00df", "Le\u00b7bens", "Wort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PDS", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "War bey Gott/ war Gott/ bleibt hinfort/", "tokens": ["War", "bey", "Gott", "/", "war", "Gott", "/", "bleibt", "hin\u00b7fort", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$(", "VAFIN", "NN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Bey Gott und Gott in Ewigkeit.", "tokens": ["Bey", "Gott", "und", "Gott", "in", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Vnd di\u00df Wort ward Fleisch in der zeit/", "tokens": ["Vnd", "di\u00df", "Wort", "ward", "Fleisch", "in", "der", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "VAFIN", "NN", "APPR", "ART", "NN", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.71": {"text": "Ist zu uns in die Welt gekommen/", "tokens": ["Ist", "zu", "uns", "in", "die", "Welt", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.72": {"text": "Ward von der Welt nicht angenommen:", "tokens": ["Ward", "von", "der", "Welt", "nicht", "an\u00b7ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "In der finsternu\u00df scheint di\u00df liecht/", "tokens": ["In", "der", "fins\u00b7ter\u00b7nu\u00df", "scheint", "di\u00df", "liecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PDS", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.74": {"text": "Die finsternu\u00df begreifft es nicht.", "tokens": ["Die", "fins\u00b7ter\u00b7nu\u00df", "be\u00b7greifft", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Druch di\u00df Wort ist die Welt gemacht/", "tokens": ["Druch", "di\u00df", "Wort", "ist", "die", "Welt", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.76": {"text": "Vnd/ was man sicht/ ans liecht gebracht:", "tokens": ["Vnd", "/", "was", "man", "sicht", "/", "ans", "liecht", "ge\u00b7bracht", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWS", "PIS", "VVFIN", "$(", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "All' wachsende ding kommen fort", "tokens": ["All'", "wach\u00b7sen\u00b7de", "ding", "kom\u00b7men", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Noch t\u00e4glich/ durch di\u00df kr\u00e4fftig Wort.", "tokens": ["Noch", "t\u00e4g\u00b7lich", "/", "durch", "di\u00df", "kr\u00e4ff\u00b7tig", "Wort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "APPR", "PDS", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "Di\u00df Wort ist der Balsam in allen/", "tokens": ["Di\u00df", "Wort", "ist", "der", "Bal\u00b7sam", "in", "al\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "ART", "NN", "APPR", "PIAT", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.80": {"text": "In Thieren/ Kr\u00e4utern und Metallen.", "tokens": ["In", "Thie\u00b7ren", "/", "Kr\u00e4u\u00b7tern", "und", "Me\u00b7tal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.81": {"text": "Alles wird durch di\u00df Wort bewegt/", "tokens": ["Al\u00b7les", "wird", "durch", "di\u00df", "Wort", "be\u00b7wegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PDS", "NN", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.82": {"text": "In diesem Wort sich alles regt.", "tokens": ["In", "die\u00b7sem", "Wort", "sich", "al\u00b7les", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "PDAT", "NN", "PRF", "PIS", "XY"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.83": {"text": "O blinder Menschen unverstandt/", "tokens": ["O", "blin\u00b7der", "Men\u00b7schen", "un\u00b7ver\u00b7standt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "M\u00f6cht euch di\u00df Wort seyn recht bekant!", "tokens": ["M\u00f6cht", "euch", "di\u00df", "Wort", "seyn", "recht", "be\u00b7kant", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "NN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "Ihr w\u00fcrdet ander sachen sp\u00fchren/", "tokens": ["Ihr", "w\u00fcr\u00b7det", "an\u00b7der", "sa\u00b7chen", "sp\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.86": {"text": "Vnd viel ein bessers leben f\u00fchren/", "tokens": ["Vnd", "viel", "ein", "bes\u00b7sers", "le\u00b7ben", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.87": {"text": "Aber wer ist der darnach fraget?", "tokens": ["A\u00b7ber", "wer", "ist", "der", "dar\u00b7nach", "fra\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "PAV", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.88": {"text": "Man schreyt und schreibt/ man singt und saget/", "tokens": ["Man", "schreyt", "und", "schreibt", "/", "man", "singt", "und", "sa\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$(", "PIS", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "Ist alles umbsonst und verlohren/", "tokens": ["Ist", "al\u00b7les", "um\u00b7bsonst", "und", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "KON", "VVPP", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.90": {"text": "Verstockt und verstopfft sind die ohren.", "tokens": ["Ver\u00b7stockt", "und", "ver\u00b7stopfft", "sind", "die", "oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.91": {"text": "Das mach't der b\u00f6se will allein/", "tokens": ["Das", "mach't", "der", "b\u00f6\u00b7se", "will", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "VMFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Keiner begehrt recht wei\u00df zu seyn;", "tokens": ["Kei\u00b7ner", "be\u00b7gehrt", "recht", "wei\u00df", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "ADJD", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.93": {"text": "Jedermann meynet er sey klug/", "tokens": ["Je\u00b7der\u00b7mann", "mey\u00b7net", "er", "sey", "klug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "Der Buchstab geb' ihm liechts genug.", "tokens": ["Der", "Buch\u00b7stab", "geb'", "ihm", "liechts", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.95": {"text": "Kompt einer her und sagt vom Geist/", "tokens": ["Kompt", "ei\u00b7ner", "her", "und", "sagt", "vom", "Geist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "Der wird sehr \u00fcbel abgeweist/", "tokens": ["Der", "wird", "sehr", "\u00fc\u00b7bel", "ab\u00b7ge\u00b7weist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.97": {"text": "Vnd al\u00df ein Ketzer hart verklaget/", "tokens": ["Vnd", "al\u00df", "ein", "Ket\u00b7zer", "hart", "ver\u00b7kla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Genant Schwenckfelder und Phantast/", "tokens": ["Ge\u00b7nant", "Schwen\u00b7ck\u00b7fel\u00b7der", "und", "Phan\u00b7tast", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.99": {"text": "Rosencreutzer/ Enthusiast/", "tokens": ["Ro\u00b7sen\u00b7creut\u00b7zer", "/", "En\u00b7thu\u00b7si\u00b7ast", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.100": {"text": "Chiliast/ Weigelianist/", "tokens": ["Chi\u00b7li\u00b7ast", "/", "Wei\u00b7ge\u00b7li\u00b7a\u00b7nist", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.101": {"text": "Davidianer/ Neutralist.", "tokens": ["Da\u00b7vi\u00b7di\u00b7a\u00b7ner", "/", "Neut\u00b7ra\u00b7list", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Welche nicht mit dem gr\u00f6sten hauffen", "tokens": ["Wel\u00b7che", "nicht", "mit", "dem", "gr\u00f6s\u00b7ten", "hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.103": {"text": "Den breiten Welt-weg wollen lauffen:", "tokens": ["Den", "brei\u00b7ten", "Welt\u00b7weg", "wol\u00b7len", "lauf\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.104": {"text": "Sondern nach Christi Lehr sich halten/", "tokens": ["Son\u00b7dern", "nach", "Chris\u00b7ti", "Lehr", "sich", "hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "PRF", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.105": {"text": "Die sind verhasst bey Jung'n und Alten.", "tokens": ["Die", "sind", "ver\u00b7hasst", "bey", "Jung'n", "und", "Al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "Ja, alle die den innern grund/", "tokens": ["Ja", ",", "al\u00b7le", "die", "den", "in\u00b7nern", "grund", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PIS", "ART", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.107": {"text": "Mit hand und mund recht machen kund/", "tokens": ["Mit", "hand", "und", "mund", "recht", "ma\u00b7chen", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Vnd vom Geist sagen oder schreiben/", "tokens": ["Vnd", "vom", "Geist", "sa\u00b7gen", "o\u00b7der", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVINF", "KON", "VVINF", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.109": {"text": "K\u00f6nnen nirgend mit frieden bleiben.", "tokens": ["K\u00f6n\u00b7nen", "nir\u00b7gend", "mit", "frie\u00b7den", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.110": {"text": "Der Dreyk\u00f6pffige Hund der Hellen/", "tokens": ["Der", "Drey\u00b7k\u00f6pf\u00b7fi\u00b7ge", "Hund", "der", "Hel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "Kan's lassen nicht/ mu\u00df sie anbellen:", "tokens": ["Kan's", "las\u00b7sen", "nicht", "/", "mu\u00df", "sie", "an\u00b7bel\u00b7len", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "$(", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.112": {"text": "Ihr keiner vom Geist h\u00f6ren will.", "tokens": ["Ihr", "kei\u00b7ner", "vom", "Geist", "h\u00f6\u00b7ren", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.113": {"text": "Wilt haben fried/ schweig davon still;", "tokens": ["Wilt", "ha\u00b7ben", "fried", "/", "schweig", "da\u00b7von", "still", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAFIN", "NN", "$(", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "Das inner wort redt viel zu hart/", "tokens": ["Das", "in\u00b7ner", "wort", "redt", "viel", "zu", "hart", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "Wieder des alten Adams art.", "tokens": ["Wie\u00b7der", "des", "al\u00b7ten", "A\u00b7dams", "art", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.116": {"text": "Es ist dem fleisch ein schweres Creutz/", "tokens": ["Es", "ist", "dem", "fleisch", "ein", "schwe\u00b7res", "Creutz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Keiner von den Welt-kindern leidts/", "tokens": ["Kei\u00b7ner", "von", "den", "Welt\u00b7kin\u00b7dern", "leidts", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.118": {"text": "Weil sie zu weit sind au\u00dfgefallen;", "tokens": ["Weil", "sie", "zu", "weit", "sind", "au\u00df\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKA", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.119": {"text": "Der alte Wahn ist starck in allen.", "tokens": ["Der", "al\u00b7te", "Wahn", "ist", "starck", "in", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.120": {"text": "Die breite Bahn ist leicht zu lauffen/", "tokens": ["Die", "brei\u00b7te", "Bahn", "ist", "leicht", "zu", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.121": {"text": "Man helt es mit dem gr\u00f6sten hauffen.", "tokens": ["Man", "helt", "es", "mit", "dem", "gr\u00f6s\u00b7ten", "hauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.122": {"text": "Welt gunst und freundtschafft hindert viel/", "tokens": ["Welt", "gunst", "und", "freundt\u00b7schafft", "hin\u00b7dert", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.123": {"text": "Da\u00df man nicht kompt zum rechten Ziel.", "tokens": ["Da\u00df", "man", "nicht", "kompt", "zum", "rech\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.124": {"text": "Der Gelerten ", "tokens": ["Der", "Ge\u00b7ler\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.125": {"text": "Vielen frommen im liecht auch steht/", "tokens": ["Vie\u00b7len", "from\u00b7men", "im", "liecht", "auch", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "APPRART", "VVFIN", "ADV", "VVFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.126": {"text": "Da\u00df sie nicht wieder kehren ein/", "tokens": ["Da\u00df", "sie", "nicht", "wie\u00b7der", "keh\u00b7ren", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.127": {"text": "Zu dem darau\u00df sie kommen seyn.", "tokens": ["Zu", "dem", "dar\u00b7au\u00df", "sie", "kom\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PAV", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Der Ketzer Name manchen schreckt/", "tokens": ["Der", "Ket\u00b7zer", "Na\u00b7me", "man\u00b7chen", "schreckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.129": {"text": "Da\u00df er den kern der Schrifft nicht schmeckt.", "tokens": ["Da\u00df", "er", "den", "kern", "der", "Schrifft", "nicht", "schmeckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.130": {"text": "Keiner will sich gern schelten lassen/", "tokens": ["Kei\u00b7ner", "will", "sich", "gern", "schel\u00b7ten", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "VVINF", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.131": {"text": "Vnd sehn da\u00df ihn die Freunde hassen.", "tokens": ["Vnd", "sehn", "da\u00df", "ihn", "die", "Freun\u00b7de", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.132": {"text": "Man liebet mehr Welt-freund' und Ehr/", "tokens": ["Man", "lie\u00b7bet", "mehr", "Welt\u00b7freund'", "und", "Ehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.133": {"text": "Al\u00df Gottes Wort und reine Lehr.", "tokens": ["Al\u00df", "Got\u00b7tes", "Wort", "und", "rei\u00b7ne", "Lehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Darumb bleiben auch viel dahinden/", "tokens": ["Da\u00b7rumb", "blei\u00b7ben", "auch", "viel", "da\u00b7hin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "PAV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.135": {"text": "Werden die Wei\u00dfheit nimmer finden.", "tokens": ["Wer\u00b7den", "die", "Wei\u00df\u00b7heit", "nim\u00b7mer", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.136": {"text": "Aber all' die sich hertzlich gern", "tokens": ["A\u00b7ber", "all'", "die", "sich", "hertz\u00b7lich", "gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ART", "PRF", "ADJD", "ADV"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.137": {"text": "Woll'n lassen lehrn vom Geist des Herrn/", "tokens": ["Woll'n", "las\u00b7sen", "lehrn", "vom", "Geist", "des", "Herrn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "VVFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.138": {"text": "Vnd nach dem schatz im Acker trachten/", "tokens": ["Vnd", "nach", "dem", "schatz", "im", "A\u00b7cker", "trach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.139": {"text": "Welt-kunst/ gunst und freundtschafft verachten/", "tokens": ["Welt\u00b7kunst", "/", "gunst", "und", "freundt\u00b7schafft", "ver\u00b7ach\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "KON", "NN", "VVFIN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.140": {"text": "Schmach/ schelt- und L\u00e4ster-wort vertragen/", "tokens": ["Schmach", "/", "schel\u00b7t", "und", "L\u00e4s\u00b7ter\u00b7wort", "ver\u00b7tra\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "TRUNC", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.141": {"text": "Nach Ehr und Ansehn nicht mehr fragen/", "tokens": ["Nach", "Ehr", "und", "An\u00b7sehn", "nicht", "mehr", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.142": {"text": "Die Welt und alle ding verlassen/", "tokens": ["Die", "Welt", "und", "al\u00b7le", "ding", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.143": {"text": "Ja, auch ihr eigen leben hassen/", "tokens": ["Ja", ",", "auch", "ihr", "ei\u00b7gen", "le\u00b7ben", "has\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "PPER", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.144": {"text": "Die sind durch Gottes gnad geschm\u00fcckt/", "tokens": ["Die", "sind", "durch", "Got\u00b7tes", "gnad", "ge\u00b7schm\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.145": {"text": "W\u00fcrdig gemacht und wolgeschickt/", "tokens": ["W\u00fcr\u00b7dig", "ge\u00b7macht", "und", "wol\u00b7ge\u00b7schickt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "ADJD", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.146": {"text": "Im innern Tempel einzugehn/", "tokens": ["Im", "in\u00b7nern", "Tem\u00b7pel", "ein\u00b7zu\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVIZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.147": {"text": "Des Herren Herrlicheit zusehn.", "tokens": ["Des", "Her\u00b7ren", "Herr\u00b7li\u00b7cheit", "zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Caspar Schwenckfeld Ein Seeliger Christ", "tokens": ["Cas\u00b7par", "Schwen\u00b7ck\u00b7feld", "Ein", "See\u00b7li\u00b7ger", "Christ"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "ADJA", "NN"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Vnd Zeug der reinen Warheit ist/", "tokens": ["Vnd", "Zeug", "der", "rei\u00b7nen", "War\u00b7heit", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ART", "ADJA", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sein gedechtn\u00fc\u00df bleibt jederfrist/", "tokens": ["Sein", "ge\u00b7decht\u00b7n\u00fc\u00df", "bleibt", "je\u00b7der\u00b7frist", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Wird nicht gedempfft durch Satans list.", "tokens": ["Wird", "nicht", "ge\u00b7dem\u00b7pfft", "durch", "Sa\u00b7tans", "list", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVPP", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.5": {"line.1": {"text": "Der Frommen Lob breittet au\u00df mit reden und schreiben/", "tokens": ["Der", "From\u00b7men", "Lob", "breit\u00b7tet", "au\u00df", "mit", "re\u00b7den", "und", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "APPR", "VVINF", "KON", "VVINF", "$("], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der Gerechten gedechtn\u00fc\u00df wird im Segen bleiben,", "tokens": ["Der", "Ge\u00b7rech\u00b7ten", "ge\u00b7decht\u00b7n\u00fc\u00df", "wird", "im", "Se\u00b7gen", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VAFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Kein Teuffel oder b\u00f6ser Mensch wird sie vertreiben.", "tokens": ["Kein", "Teuf\u00b7fel", "o\u00b7der", "b\u00f6\u00b7ser", "Mensch", "wird", "sie", "ver\u00b7trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "ADJA", "NN", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der Warheit zeug, ein Frommer Christ;", "tokens": ["Der", "War\u00b7heit", "zeug", ",", "ein", "From\u00b7mer", "Christ", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Gottes Wort bey seiner zeit", "tokens": ["Hat", "Got\u00b7tes", "Wort", "bey", "sei\u00b7ner", "zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch red und schreiben au\u00dfgebreitt/", "tokens": ["Durch", "red", "und", "schrei\u00b7ben", "au\u00df\u00b7ge\u00b7breitt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vnd umb de\u00dfwillen viel gelitten/", "tokens": ["Vnd", "umb", "de\u00df\u00b7wil\u00b7len", "viel", "ge\u00b7lit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil Satan wieder ihn gestritten/", "tokens": ["Weil", "Sa\u00b7tan", "wie\u00b7der", "ihn", "ge\u00b7strit\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Vnd seine Hund' an ihn gehetzt/", "tokens": ["Vnd", "sei\u00b7ne", "Hund'", "an", "ihn", "ge\u00b7hetzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die ihm starck haben zugesetzt/", "tokens": ["Die", "ihm", "starck", "ha\u00b7ben", "zu\u00b7ge\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Vnd h\u00e4tten ihn zerrissen gern:", "tokens": ["Vnd", "h\u00e4t\u00b7ten", "ihn", "zer\u00b7ris\u00b7sen", "gern", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Aber er war im schutz des Herrn/", "tokens": ["A\u00b7ber", "er", "war", "im", "schutz", "des", "Herrn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Sie musten ihn passieren lassen", "tokens": ["Sie", "mus\u00b7ten", "ihn", "pas\u00b7sie\u00b7ren", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Frey unbesch\u00e4digt seine strassen.", "tokens": ["Frey", "un\u00b7be\u00b7sch\u00e4\u00b7digt", "sei\u00b7ne", "stras\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Er hat gelebet Gott zum prei\u00df/", "tokens": ["Er", "hat", "ge\u00b7le\u00b7bet", "Gott", "zum", "prei\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Vnd ruhet itzt im Paradeys:", "tokens": ["Vnd", "ru\u00b7het", "itzt", "im", "Pa\u00b7ra\u00b7deys", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Sein B\u00fccher gehn/ Satan zum trotz/", "tokens": ["Sein", "B\u00fc\u00b7cher", "gehn", "/", "Sa\u00b7tan", "zum", "trotz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "$(", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Durch St\u00e4t und Land/ sind vielen n\u00fctz/", "tokens": ["Durch", "St\u00e4t", "und", "Land", "/", "sind", "vie\u00b7len", "n\u00fctz", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Auch kommen Gott sey lob zu mir/", "tokens": ["Auch", "kom\u00b7men", "Gott", "sey", "lob", "zu", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "VAFIN", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Viel gutes ich darinnen sp\u00fchr/", "tokens": ["Viel", "gu\u00b7tes", "ich", "da\u00b7rin\u00b7nen", "sp\u00fchr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "PPER", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Des waren Wortes Eigenschafft/", "tokens": ["Des", "wa\u00b7ren", "Wor\u00b7tes", "Ei\u00b7gen\u00b7schafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Sein lebendige w\u00fcrcklich krafft/", "tokens": ["Sein", "le\u00b7ben\u00b7di\u00b7ge", "w\u00fcrck\u00b7lich", "krafft", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "ADJD", "NN", "$("], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.20": {"text": "Sein wesen her von Ewigkeit/", "tokens": ["Sein", "we\u00b7sen", "her", "von", "E\u00b7wig\u00b7keit", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Wird uns hirin klar angedeut.", "tokens": ["Wird", "uns", "hi\u00b7rin", "klar", "an\u00b7ge\u00b7deut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Auch vom Buchstab der Heilig'n Schrifft/", "tokens": ["Auch", "vom", "Buch\u00b7stab", "der", "Hei\u00b7lig'n", "Schrifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "ADJA", "NN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.23": {"text": "Was sein W\u00fcrckung und art betrifft/", "tokens": ["Was", "sein", "W\u00fcr\u00b7ckung", "und", "art", "be\u00b7tr\u00b7ifft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "KON", "NN", "VVFIN", "$("], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Vnd da\u00df er nur sey ein Figur/", "tokens": ["Vnd", "da\u00df", "er", "nur", "sey", "ein", "Fi\u00b7gur", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VAFIN", "ART", "NN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.25": {"text": "Des Waren Worts ", "tokens": ["Des", "Wa\u00b7ren", "Worts"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.26": {"text": "So f\u00fcr den eussern Menschen ist;", "tokens": ["So", "f\u00fcr", "den", "eus\u00b7sern", "Men\u00b7schen", "ist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Aber Gottes Wort Jesus Christ/", "tokens": ["A\u00b7ber", "Got\u00b7tes", "Wort", "Je\u00b7sus", "Christ", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "NE", "NE", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Ist Geist und Leben/ redt inwendig/", "tokens": ["Ist", "Geist", "und", "Le\u00b7ben", "/", "redt", "in\u00b7wen\u00b7dig", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "$(", "VVFIN", "ADJD", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Machet allein das hertz verst\u00e4ndig/", "tokens": ["Ma\u00b7chet", "al\u00b7lein", "das", "hertz", "ver\u00b7st\u00e4n\u00b7dig", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJD", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.30": {"text": "Endert der Menschen sinn und muth/", "tokens": ["En\u00b7dert", "der", "Men\u00b7schen", "sinn", "und", "muth", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "KON", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.31": {"text": "Reicht weiter dann der Buchstab thut.", "tokens": ["Reicht", "wei\u00b7ter", "dann", "der", "Buch\u00b7stab", "thut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.32": {"text": "Das Eu\u00dfer nur die Ohren r\u00fchrt/", "tokens": ["Das", "Eu\u00b7\u00dfer", "nur", "die", "Oh\u00b7ren", "r\u00fchrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Das Inner wort zum Geist einf\u00fchrt;", "tokens": ["Das", "In\u00b7ner", "wort", "zum", "Geist", "ein\u00b7f\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Bringt mit ihm lebens krafft und safft/", "tokens": ["Bringt", "mit", "ihm", "le\u00b7bens", "krafft", "und", "safft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADJA", "NN", "KON", "VVFIN", "$("], "meter": "+----+-+", "measure": "dactylic.init"}, "line.35": {"text": "Ohn di\u00df das Eu\u00dfer weinig schafft/", "tokens": ["Ohn", "di\u00df", "das", "Eu\u00b7\u00dfer", "wei\u00b7nig", "schafft", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Drumb soll man nach dem Innern trachten/", "tokens": ["Drumb", "soll", "man", "nach", "dem", "In\u00b7nern", "trach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VMFIN", "PIS", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.37": {"text": "Das Eu\u00dfer aber nicht verachten;", "tokens": ["Das", "Eu\u00b7\u00dfer", "a\u00b7ber", "nicht", "ver\u00b7ach\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.38": {"text": "Sondern zum zeugnu\u00df nemen an/", "tokens": ["Son\u00b7dern", "zum", "zeug\u00b7nu\u00df", "ne\u00b7men", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "+--++--+", "measure": "iambic.tetra.chol"}, "line.39": {"text": "Weil es uns dazu dienen kan/", "tokens": ["Weil", "es", "uns", "da\u00b7zu", "die\u00b7nen", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Vnd ist darumb gebracht ans Liecht/", "tokens": ["Vnd", "ist", "da\u00b7rumb", "ge\u00b7bracht", "ans", "Liecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "VVPP", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "Da\u00df es uns sey zum unterricht/", "tokens": ["Da\u00df", "es", "uns", "sey", "zum", "un\u00b7ter\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Vns tr\u00f6st/ lehr und vermahn mit flei\u00df", "tokens": ["Vns", "tr\u00f6st", "/", "lehr", "und", "ver\u00b7mahn", "mit", "flei\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "VVIMP", "KON", "VVFIN", "APPR", "NN"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.43": {"text": "Zuf\u00fchr/ und auff das Inner wei\u00df:", "tokens": ["Zu\u00b7f\u00fchr", "/", "und", "auff", "das", "In\u00b7ner", "wei\u00df", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Kan sonst nichts mehr/ ist viel zu schlecht;", "tokens": ["Kan", "sonst", "nichts", "mehr", "/", "ist", "viel", "zu", "schlecht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PIS", "ADV", "$(", "VAFIN", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.45": {"text": "Der Geist ist Herr/ der Buchstab knecht.", "tokens": ["Der", "Geist", "ist", "Herr", "/", "der", "Buch\u00b7stab", "knecht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$(", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "So ich des Worts krafft soll geniessen", "tokens": ["So", "ich", "des", "Worts", "krafft", "soll", "ge\u00b7nies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "ART", "NN", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Mu\u00df der Herr selbst mein hertz auffschliessen.", "tokens": ["Mu\u00df", "der", "Herr", "selbst", "mein", "hertz", "auff\u00b7schlies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.48": {"text": "Gleich wie der Purpur Kr\u00e4merinnen/", "tokens": ["Gleich", "wie", "der", "Pur\u00b7pur", "Kr\u00e4\u00b7me\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Al\u00df wir in ", "tokens": ["Al\u00df", "wir", "in"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.50": {"text": "Vmbsonst ist was man h\u00f6rt und list/", "tokens": ["Vmbsonst", "ist", "was", "man", "h\u00f6rt", "und", "list", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PWS", "PIS", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.51": {"text": "So nicht das Wort inwendig ist.", "tokens": ["So", "nicht", "das", "Wort", "in\u00b7wen\u00b7dig", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Vom Herren das gedeyen fleust,", "tokens": ["Vom", "Her\u00b7ren", "das", "ge\u00b7de\u00b7yen", "fleust", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.53": {"text": "Das inner kan sein wirckung haben/", "tokens": ["Das", "in\u00b7ner", "kan", "sein", "wir\u00b7ckung", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "PPOSAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.54": {"text": "Ohn eu\u00dfer mittel und Buchstaben:", "tokens": ["Ohn", "eu\u00b7\u00dfer", "mit\u00b7tel", "und", "Buch\u00b7sta\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "$."], "meter": "-+-+--++-", "measure": "iambic.tetra.relaxed"}, "line.55": {"text": "Aber ohn krafft des innern liechts/", "tokens": ["A\u00b7ber", "ohn", "krafft", "des", "in\u00b7nern", "liechts", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ART", "ADJA", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.56": {"text": "Wircken die eu\u00dfern mittel nichts.", "tokens": ["Wir\u00b7cken", "die", "eu\u00b7\u00dfern", "mit\u00b7tel", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "PIS", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.57": {"text": "So uns soll nutz seyn h\u00f6rn und lesen/", "tokens": ["So", "uns", "soll", "nutz", "seyn", "h\u00f6rn", "und", "le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VMFIN", "NN", "PPOSAT", "NN", "KON", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.58": {"text": "Mu\u00df wircken di\u00df das ware wesen.", "tokens": ["Mu\u00df", "wir\u00b7cken", "di\u00df", "das", "wa\u00b7re", "we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "PDS", "PDS", "VAFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.59": {"text": "Das Wort das uns die Schrifft erklert/", "tokens": ["Das", "Wort", "das", "uns", "die", "Schrifft", "er\u00b7klert", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.60": {"text": "Die Salbung die uns alles lehrt/", "tokens": ["Die", "Sal\u00b7bung", "die", "uns", "al\u00b7les", "lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "PPER", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Ist die warheit die niemand treugt/", "tokens": ["Ist", "die", "war\u00b7heit", "die", "nie\u00b7mand", "treugt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "PIS", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.62": {"text": "Ein Mund ohn falschheit/ der nicht leugt/", "tokens": ["Ein", "Mund", "ohn", "falschheit", "/", "der", "nicht", "leugt", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$(", "ART", "PTKNEG", "VVFIN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.63": {"text": "Der Schl\u00fcssel Davids der auffschleust/", "tokens": ["Der", "Schl\u00fcs\u00b7sel", "Da\u00b7vids", "der", "auff\u00b7schleust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Der Brunn darau\u00df die Wei\u00dfheit fleust/", "tokens": ["Der", "Brunn", "dar\u00b7au\u00df", "die", "Wei\u00df\u00b7heit", "fleust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.65": {"text": "Ein Liecht so das hertz ", "tokens": ["Ein", "Liecht", "so", "das", "hertz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.66": {"text": "Der Weg so uns zum Vater f\u00fchrt.", "tokens": ["Der", "Weg", "so", "uns", "zum", "Va\u00b7ter", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Im Anfang war die\u00df Lebens Wort/", "tokens": ["Im", "An\u00b7fang", "war", "die\u00df", "Le\u00b7bens", "Wort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "PDS", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.68": {"text": "War bey Gott/ war Gott/ bleibt hinfort/", "tokens": ["War", "bey", "Gott", "/", "war", "Gott", "/", "bleibt", "hin\u00b7fort", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "NN", "$(", "VAFIN", "NN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Bey Gott und Gott in Ewigkeit.", "tokens": ["Bey", "Gott", "und", "Gott", "in", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Vnd di\u00df Wort ward Fleisch in der zeit/", "tokens": ["Vnd", "di\u00df", "Wort", "ward", "Fleisch", "in", "der", "zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "NN", "VAFIN", "NN", "APPR", "ART", "NN", "$("], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.71": {"text": "Ist zu uns in die Welt gekommen/", "tokens": ["Ist", "zu", "uns", "in", "die", "Welt", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.72": {"text": "Ward von der Welt nicht angenommen:", "tokens": ["Ward", "von", "der", "Welt", "nicht", "an\u00b7ge\u00b7nom\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.73": {"text": "In der finsternu\u00df scheint di\u00df liecht/", "tokens": ["In", "der", "fins\u00b7ter\u00b7nu\u00df", "scheint", "di\u00df", "liecht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PDS", "VVFIN", "$("], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.74": {"text": "Die finsternu\u00df begreifft es nicht.", "tokens": ["Die", "fins\u00b7ter\u00b7nu\u00df", "be\u00b7greifft", "es", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Druch di\u00df Wort ist die Welt gemacht/", "tokens": ["Druch", "di\u00df", "Wort", "ist", "die", "Welt", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PDS", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.76": {"text": "Vnd/ was man sicht/ ans liecht gebracht:", "tokens": ["Vnd", "/", "was", "man", "sicht", "/", "ans", "liecht", "ge\u00b7bracht", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$(", "PWS", "PIS", "VVFIN", "$(", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "All' wachsende ding kommen fort", "tokens": ["All'", "wach\u00b7sen\u00b7de", "ding", "kom\u00b7men", "fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.78": {"text": "Noch t\u00e4glich/ durch di\u00df kr\u00e4fftig Wort.", "tokens": ["Noch", "t\u00e4g\u00b7lich", "/", "durch", "di\u00df", "kr\u00e4ff\u00b7tig", "Wort", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "APPR", "PDS", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "Di\u00df Wort ist der Balsam in allen/", "tokens": ["Di\u00df", "Wort", "ist", "der", "Bal\u00b7sam", "in", "al\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "ART", "NN", "APPR", "PIAT", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.80": {"text": "In Thieren/ Kr\u00e4utern und Metallen.", "tokens": ["In", "Thie\u00b7ren", "/", "Kr\u00e4u\u00b7tern", "und", "Me\u00b7tal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.81": {"text": "Alles wird durch di\u00df Wort bewegt/", "tokens": ["Al\u00b7les", "wird", "durch", "di\u00df", "Wort", "be\u00b7wegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PDS", "NN", "VVFIN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.82": {"text": "In diesem Wort sich alles regt.", "tokens": ["In", "die\u00b7sem", "Wort", "sich", "al\u00b7les", "reg\u00b7t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPR", "PDAT", "NN", "PRF", "PIS", "XY"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.83": {"text": "O blinder Menschen unverstandt/", "tokens": ["O", "blin\u00b7der", "Men\u00b7schen", "un\u00b7ver\u00b7standt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.84": {"text": "M\u00f6cht euch di\u00df Wort seyn recht bekant!", "tokens": ["M\u00f6cht", "euch", "di\u00df", "Wort", "seyn", "recht", "be\u00b7kant", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PDS", "NN", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.85": {"text": "Ihr w\u00fcrdet ander sachen sp\u00fchren/", "tokens": ["Ihr", "w\u00fcr\u00b7det", "an\u00b7der", "sa\u00b7chen", "sp\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.86": {"text": "Vnd viel ein bessers leben f\u00fchren/", "tokens": ["Vnd", "viel", "ein", "bes\u00b7sers", "le\u00b7ben", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.87": {"text": "Aber wer ist der darnach fraget?", "tokens": ["A\u00b7ber", "wer", "ist", "der", "dar\u00b7nach", "fra\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "PAV", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.88": {"text": "Man schreyt und schreibt/ man singt und saget/", "tokens": ["Man", "schreyt", "und", "schreibt", "/", "man", "singt", "und", "sa\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "KON", "VVFIN", "$(", "PIS", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.89": {"text": "Ist alles umbsonst und verlohren/", "tokens": ["Ist", "al\u00b7les", "um\u00b7bsonst", "und", "ver\u00b7loh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "KON", "VVPP", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.90": {"text": "Verstockt und verstopfft sind die ohren.", "tokens": ["Ver\u00b7stockt", "und", "ver\u00b7stopfft", "sind", "die", "oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVPP", "VAFIN", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.91": {"text": "Das mach't der b\u00f6se will allein/", "tokens": ["Das", "mach't", "der", "b\u00f6\u00b7se", "will", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "ADJA", "VMFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.92": {"text": "Keiner begehrt recht wei\u00df zu seyn;", "tokens": ["Kei\u00b7ner", "be\u00b7gehrt", "recht", "wei\u00df", "zu", "seyn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVPP", "ADJD", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.93": {"text": "Jedermann meynet er sey klug/", "tokens": ["Je\u00b7der\u00b7mann", "mey\u00b7net", "er", "sey", "klug", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.94": {"text": "Der Buchstab geb' ihm liechts genug.", "tokens": ["Der", "Buch\u00b7stab", "geb'", "ihm", "liechts", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.95": {"text": "Kompt einer her und sagt vom Geist/", "tokens": ["Kompt", "ei\u00b7ner", "her", "und", "sagt", "vom", "Geist", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PTKVZ", "KON", "VVFIN", "APPRART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.96": {"text": "Der wird sehr \u00fcbel abgeweist/", "tokens": ["Der", "wird", "sehr", "\u00fc\u00b7bel", "ab\u00b7ge\u00b7weist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.97": {"text": "Vnd al\u00df ein Ketzer hart verklaget/", "tokens": ["Vnd", "al\u00df", "ein", "Ket\u00b7zer", "hart", "ver\u00b7kla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Genant Schwenckfelder und Phantast/", "tokens": ["Ge\u00b7nant", "Schwen\u00b7ck\u00b7fel\u00b7der", "und", "Phan\u00b7tast", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.99": {"text": "Rosencreutzer/ Enthusiast/", "tokens": ["Ro\u00b7sen\u00b7creut\u00b7zer", "/", "En\u00b7thu\u00b7si\u00b7ast", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.100": {"text": "Chiliast/ Weigelianist/", "tokens": ["Chi\u00b7li\u00b7ast", "/", "Wei\u00b7ge\u00b7li\u00b7a\u00b7nist", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.101": {"text": "Davidianer/ Neutralist.", "tokens": ["Da\u00b7vi\u00b7di\u00b7a\u00b7ner", "/", "Neut\u00b7ra\u00b7list", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.102": {"text": "Welche nicht mit dem gr\u00f6sten hauffen", "tokens": ["Wel\u00b7che", "nicht", "mit", "dem", "gr\u00f6s\u00b7ten", "hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PTKNEG", "APPR", "ART", "ADJA", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.103": {"text": "Den breiten Welt-weg wollen lauffen:", "tokens": ["Den", "brei\u00b7ten", "Welt\u00b7weg", "wol\u00b7len", "lauf\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.104": {"text": "Sondern nach Christi Lehr sich halten/", "tokens": ["Son\u00b7dern", "nach", "Chris\u00b7ti", "Lehr", "sich", "hal\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "PRF", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.105": {"text": "Die sind verhasst bey Jung'n und Alten.", "tokens": ["Die", "sind", "ver\u00b7hasst", "bey", "Jung'n", "und", "Al\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "Ja, alle die den innern grund/", "tokens": ["Ja", ",", "al\u00b7le", "die", "den", "in\u00b7nern", "grund", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PIS", "ART", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.107": {"text": "Mit hand und mund recht machen kund/", "tokens": ["Mit", "hand", "und", "mund", "recht", "ma\u00b7chen", "kund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "ADJD", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.108": {"text": "Vnd vom Geist sagen oder schreiben/", "tokens": ["Vnd", "vom", "Geist", "sa\u00b7gen", "o\u00b7der", "schrei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "VVINF", "KON", "VVINF", "$("], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.109": {"text": "K\u00f6nnen nirgend mit frieden bleiben.", "tokens": ["K\u00f6n\u00b7nen", "nir\u00b7gend", "mit", "frie\u00b7den", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.110": {"text": "Der Dreyk\u00f6pffige Hund der Hellen/", "tokens": ["Der", "Drey\u00b7k\u00f6pf\u00b7fi\u00b7ge", "Hund", "der", "Hel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.111": {"text": "Kan's lassen nicht/ mu\u00df sie anbellen:", "tokens": ["Kan's", "las\u00b7sen", "nicht", "/", "mu\u00df", "sie", "an\u00b7bel\u00b7len", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PTKNEG", "$(", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.112": {"text": "Ihr keiner vom Geist h\u00f6ren will.", "tokens": ["Ihr", "kei\u00b7ner", "vom", "Geist", "h\u00f6\u00b7ren", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.113": {"text": "Wilt haben fried/ schweig davon still;", "tokens": ["Wilt", "ha\u00b7ben", "fried", "/", "schweig", "da\u00b7von", "still", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAFIN", "NN", "$(", "VVFIN", "PAV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.114": {"text": "Das inner wort redt viel zu hart/", "tokens": ["Das", "in\u00b7ner", "wort", "redt", "viel", "zu", "hart", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "PTKA", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "Wieder des alten Adams art.", "tokens": ["Wie\u00b7der", "des", "al\u00b7ten", "A\u00b7dams", "art", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.116": {"text": "Es ist dem fleisch ein schweres Creutz/", "tokens": ["Es", "ist", "dem", "fleisch", "ein", "schwe\u00b7res", "Creutz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Keiner von den Welt-kindern leidts/", "tokens": ["Kei\u00b7ner", "von", "den", "Welt\u00b7kin\u00b7dern", "leidts", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.118": {"text": "Weil sie zu weit sind au\u00dfgefallen;", "tokens": ["Weil", "sie", "zu", "weit", "sind", "au\u00df\u00b7ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKA", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.119": {"text": "Der alte Wahn ist starck in allen.", "tokens": ["Der", "al\u00b7te", "Wahn", "ist", "starck", "in", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "APPR", "PIAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.120": {"text": "Die breite Bahn ist leicht zu lauffen/", "tokens": ["Die", "brei\u00b7te", "Bahn", "ist", "leicht", "zu", "lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.121": {"text": "Man helt es mit dem gr\u00f6sten hauffen.", "tokens": ["Man", "helt", "es", "mit", "dem", "gr\u00f6s\u00b7ten", "hauf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.122": {"text": "Welt gunst und freundtschafft hindert viel/", "tokens": ["Welt", "gunst", "und", "freundt\u00b7schafft", "hin\u00b7dert", "viel", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "KON", "NN", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.123": {"text": "Da\u00df man nicht kompt zum rechten Ziel.", "tokens": ["Da\u00df", "man", "nicht", "kompt", "zum", "rech\u00b7ten", "Ziel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PTKNEG", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.124": {"text": "Der Gelerten ", "tokens": ["Der", "Ge\u00b7ler\u00b7ten"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.125": {"text": "Vielen frommen im liecht auch steht/", "tokens": ["Vie\u00b7len", "from\u00b7men", "im", "liecht", "auch", "steht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "APPRART", "VVFIN", "ADV", "VVFIN", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.126": {"text": "Da\u00df sie nicht wieder kehren ein/", "tokens": ["Da\u00df", "sie", "nicht", "wie\u00b7der", "keh\u00b7ren", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "ADV", "VVFIN", "ART", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.127": {"text": "Zu dem darau\u00df sie kommen seyn.", "tokens": ["Zu", "dem", "dar\u00b7au\u00df", "sie", "kom\u00b7men", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PAV", "PPER", "VVFIN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Der Ketzer Name manchen schreckt/", "tokens": ["Der", "Ket\u00b7zer", "Na\u00b7me", "man\u00b7chen", "schreckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.129": {"text": "Da\u00df er den kern der Schrifft nicht schmeckt.", "tokens": ["Da\u00df", "er", "den", "kern", "der", "Schrifft", "nicht", "schmeckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.130": {"text": "Keiner will sich gern schelten lassen/", "tokens": ["Kei\u00b7ner", "will", "sich", "gern", "schel\u00b7ten", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "ADV", "VVINF", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.131": {"text": "Vnd sehn da\u00df ihn die Freunde hassen.", "tokens": ["Vnd", "sehn", "da\u00df", "ihn", "die", "Freun\u00b7de", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KOUS", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.132": {"text": "Man liebet mehr Welt-freund' und Ehr/", "tokens": ["Man", "lie\u00b7bet", "mehr", "Welt\u00b7freund'", "und", "Ehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.133": {"text": "Al\u00df Gottes Wort und reine Lehr.", "tokens": ["Al\u00df", "Got\u00b7tes", "Wort", "und", "rei\u00b7ne", "Lehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.134": {"text": "Darumb bleiben auch viel dahinden/", "tokens": ["Da\u00b7rumb", "blei\u00b7ben", "auch", "viel", "da\u00b7hin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ADV", "ADV", "PAV", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.135": {"text": "Werden die Wei\u00dfheit nimmer finden.", "tokens": ["Wer\u00b7den", "die", "Wei\u00df\u00b7heit", "nim\u00b7mer", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.136": {"text": "Aber all' die sich hertzlich gern", "tokens": ["A\u00b7ber", "all'", "die", "sich", "hertz\u00b7lich", "gern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "ART", "PRF", "ADJD", "ADV"], "meter": "+----+-+", "measure": "dactylic.init"}, "line.137": {"text": "Woll'n lassen lehrn vom Geist des Herrn/", "tokens": ["Woll'n", "las\u00b7sen", "lehrn", "vom", "Geist", "des", "Herrn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVINF", "VVFIN", "APPRART", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.138": {"text": "Vnd nach dem schatz im Acker trachten/", "tokens": ["Vnd", "nach", "dem", "schatz", "im", "A\u00b7cker", "trach\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.139": {"text": "Welt-kunst/ gunst und freundtschafft verachten/", "tokens": ["Welt\u00b7kunst", "/", "gunst", "und", "freundt\u00b7schafft", "ver\u00b7ach\u00b7ten", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "KON", "NN", "VVFIN", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.140": {"text": "Schmach/ schelt- und L\u00e4ster-wort vertragen/", "tokens": ["Schmach", "/", "schel\u00b7t", "und", "L\u00e4s\u00b7ter\u00b7wort", "ver\u00b7tra\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "TRUNC", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.141": {"text": "Nach Ehr und Ansehn nicht mehr fragen/", "tokens": ["Nach", "Ehr", "und", "An\u00b7sehn", "nicht", "mehr", "fra\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKNEG", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.142": {"text": "Die Welt und alle ding verlassen/", "tokens": ["Die", "Welt", "und", "al\u00b7le", "ding", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.143": {"text": "Ja, auch ihr eigen leben hassen/", "tokens": ["Ja", ",", "auch", "ihr", "ei\u00b7gen", "le\u00b7ben", "has\u00b7sen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "PPER", "ADJD", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.144": {"text": "Die sind durch Gottes gnad geschm\u00fcckt/", "tokens": ["Die", "sind", "durch", "Got\u00b7tes", "gnad", "ge\u00b7schm\u00fcckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.145": {"text": "W\u00fcrdig gemacht und wolgeschickt/", "tokens": ["W\u00fcr\u00b7dig", "ge\u00b7macht", "und", "wol\u00b7ge\u00b7schickt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "KON", "ADJD", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.146": {"text": "Im innern Tempel einzugehn/", "tokens": ["Im", "in\u00b7nern", "Tem\u00b7pel", "ein\u00b7zu\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVIZU", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.147": {"text": "Des Herren Herrlicheit zusehn.", "tokens": ["Des", "Her\u00b7ren", "Herr\u00b7li\u00b7cheit", "zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}