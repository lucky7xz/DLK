{"textgrid.poem.54129": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Der Mitesser", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Er wohnt am Rand der reichen Leute,", "tokens": ["Er", "wohnt", "am", "Rand", "der", "rei\u00b7chen", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "verkehrt mit Adel und hei\u00dft Schmidt.", "tokens": ["ver\u00b7kehrt", "mit", "A\u00b7del", "und", "hei\u00dft", "Schmidt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Schlips von morgen tr\u00e4gt er heute", "tokens": ["Den", "Schlips", "von", "mor\u00b7gen", "tr\u00e4gt", "er", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und f\u00e4hrt in fremden Autos mit.", "tokens": ["und", "f\u00e4hrt", "in", "frem\u00b7den", "Au\u00b7tos", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt in einem ihm fremden Stile \u2013", "tokens": ["Er", "lebt", "in", "ei\u00b7nem", "ihm", "frem\u00b7den", "Sti\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "PPER", "ADJA", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Fauler Kopp!", "tokens": ["Fau\u00b7ler", "Kopp", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Fauler Snob!", "tokens": ["Fau\u00b7ler", "Snob", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Aber davon gibts viele.", "tokens": ["A\u00b7ber", "da\u00b7von", "gibts", "vie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.2": {"line.1": {"text": "Er selbst hat nur ein kleines Zimmer,", "tokens": ["Er", "selbst", "hat", "nur", "ein", "klei\u00b7nes", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als Untermieter bei Frau Schay.", "tokens": ["als", "Un\u00b7ter\u00b7mie\u00b7ter", "bei", "Frau", "Schay", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch geht er aus, dann tut er immer,", "tokens": ["Doch", "geht", "er", "aus", ",", "dann", "tut", "er", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.4": {"text": "als w\u00e4r er aufgewachsen bei.", "tokens": ["als", "w\u00e4r", "er", "auf\u00b7ge\u00b7wach\u00b7sen", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von der Socke bis zum gescheitelten Haar:", "tokens": ["Von", "der", "So\u00b7cke", "bis", "zum", "ge\u00b7schei\u00b7tel\u00b7ten", "Haar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "es ist alles nicht wahr \u2013 es ist alles nicht wahr!", "tokens": ["es", "ist", "al\u00b7les", "nicht", "wahr", "\u2013", "es", "ist", "al\u00b7les", "nicht", "wahr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PTKNEG", "ADJD", "$(", "PPER", "VAFIN", "PIS", "PTKNEG", "ADJD", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.3": {"line.1": {"text": "Er ist so gerne eingeladen:", "tokens": ["Er", "ist", "so", "ger\u00b7ne", "ein\u00b7ge\u00b7la\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "er zeckt an Kaufmann und Bankier.", "tokens": ["er", "zeckt", "an", "Kauf\u00b7mann", "und", "Ban\u00b7kier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er wei\u00df, am Lido mu\u00df man baden,", "tokens": ["Er", "wei\u00df", ",", "am", "Li\u00b7do", "mu\u00df", "man", "ba\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPRART", "NE", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "er gr\u00fc\u00dft im Ritz den Herrn Portier.", "tokens": ["er", "gr\u00fc\u00dft", "im", "Ritz", "den", "Herrn", "Por\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er nassauert elegant und beflissen", "tokens": ["Er", "nas\u00b7sau\u00b7ert", "e\u00b7le\u00b7gant", "und", "be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVINF"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "vor fremden Kulissen.", "tokens": ["vor", "frem\u00b7den", "Ku\u00b7lis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Was er auch hat, das hat er gratis.", "tokens": ["Was", "er", "auch", "hat", ",", "das", "hat", "er", "gra\u00b7tis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$,", "PDS", "VAFIN", "PPER", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er l\u00e4uft mit der Society.", "tokens": ["Er", "l\u00e4uft", "mit", "der", "So\u00b7cie\u00b7ty", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er kennt die feinsten Cocktail-Parties.", "tokens": ["Er", "kennt", "die", "feins\u00b7ten", "Cock\u00b7tail\u00b7Par\u00b7ties", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Nur seine Lage kennt er nie.", "tokens": ["Nur", "sei\u00b7ne", "La\u00b7ge", "kennt", "er", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald kunstgewerblicher Friseur,", "tokens": ["Bald", "kunst\u00b7ge\u00b7werb\u00b7li\u00b7cher", "Fri\u00b7seur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bald Redakteur . . .", "tokens": ["bald", "Re\u00b7dak\u00b7teur", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "$.", "$.", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "so sehn wir ihn gestern, morgen und heute:", "tokens": ["so", "sehn", "wir", "ihn", "ge\u00b7stern", ",", "mor\u00b7gen", "und", "heu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "ein Affe.", "tokens": ["ein", "Af\u00b7fe", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ein Affe der reichen Leute.", "tokens": ["Ein", "Af\u00b7fe", "der", "rei\u00b7chen", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Er wohnt am Rand der reichen Leute,", "tokens": ["Er", "wohnt", "am", "Rand", "der", "rei\u00b7chen", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "verkehrt mit Adel und hei\u00dft Schmidt.", "tokens": ["ver\u00b7kehrt", "mit", "A\u00b7del", "und", "hei\u00dft", "Schmidt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Schlips von morgen tr\u00e4gt er heute", "tokens": ["Den", "Schlips", "von", "mor\u00b7gen", "tr\u00e4gt", "er", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und f\u00e4hrt in fremden Autos mit.", "tokens": ["und", "f\u00e4hrt", "in", "frem\u00b7den", "Au\u00b7tos", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt in einem ihm fremden Stile \u2013", "tokens": ["Er", "lebt", "in", "ei\u00b7nem", "ihm", "frem\u00b7den", "Sti\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "PPER", "ADJA", "NN", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Fauler Kopp!", "tokens": ["Fau\u00b7ler", "Kopp", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Fauler Snob!", "tokens": ["Fau\u00b7ler", "Snob", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Aber davon gibts viele.", "tokens": ["A\u00b7ber", "da\u00b7von", "gibts", "vie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "PIS", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.6": {"line.1": {"text": "Er selbst hat nur ein kleines Zimmer,", "tokens": ["Er", "selbst", "hat", "nur", "ein", "klei\u00b7nes", "Zim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "als Untermieter bei Frau Schay.", "tokens": ["als", "Un\u00b7ter\u00b7mie\u00b7ter", "bei", "Frau", "Schay", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch geht er aus, dann tut er immer,", "tokens": ["Doch", "geht", "er", "aus", ",", "dann", "tut", "er", "im\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.4": {"text": "als w\u00e4r er aufgewachsen bei.", "tokens": ["als", "w\u00e4r", "er", "auf\u00b7ge\u00b7wach\u00b7sen", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von der Socke bis zum gescheitelten Haar:", "tokens": ["Von", "der", "So\u00b7cke", "bis", "zum", "ge\u00b7schei\u00b7tel\u00b7ten", "Haar", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "APPRART", "ADJA", "NN", "$."], "meter": "--+--+-+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "es ist alles nicht wahr \u2013 es ist alles nicht wahr!", "tokens": ["es", "ist", "al\u00b7les", "nicht", "wahr", "\u2013", "es", "ist", "al\u00b7les", "nicht", "wahr", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PTKNEG", "ADJD", "$(", "PPER", "VAFIN", "PIS", "PTKNEG", "ADJD", "$."], "meter": "--+--+--+--+", "measure": "anapaest.tetra.plus"}}, "stanza.7": {"line.1": {"text": "Er ist so gerne eingeladen:", "tokens": ["Er", "ist", "so", "ger\u00b7ne", "ein\u00b7ge\u00b7la\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "er zeckt an Kaufmann und Bankier.", "tokens": ["er", "zeckt", "an", "Kauf\u00b7mann", "und", "Ban\u00b7kier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Er wei\u00df, am Lido mu\u00df man baden,", "tokens": ["Er", "wei\u00df", ",", "am", "Li\u00b7do", "mu\u00df", "man", "ba\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPRART", "NE", "VMFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "er gr\u00fc\u00dft im Ritz den Herrn Portier.", "tokens": ["er", "gr\u00fc\u00dft", "im", "Ritz", "den", "Herrn", "Por\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er nassauert elegant und beflissen", "tokens": ["Er", "nas\u00b7sau\u00b7ert", "e\u00b7le\u00b7gant", "und", "be\u00b7flis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "KON", "VVINF"], "meter": "+-+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "vor fremden Kulissen.", "tokens": ["vor", "frem\u00b7den", "Ku\u00b7lis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.8": {"line.1": {"text": "Was er auch hat, das hat er gratis.", "tokens": ["Was", "er", "auch", "hat", ",", "das", "hat", "er", "gra\u00b7tis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VAFIN", "$,", "PDS", "VAFIN", "PPER", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er l\u00e4uft mit der Society.", "tokens": ["Er", "l\u00e4uft", "mit", "der", "So\u00b7cie\u00b7ty", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Er kennt die feinsten Cocktail-Parties.", "tokens": ["Er", "kennt", "die", "feins\u00b7ten", "Cock\u00b7tail\u00b7Par\u00b7ties", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Nur seine Lage kennt er nie.", "tokens": ["Nur", "sei\u00b7ne", "La\u00b7ge", "kennt", "er", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald kunstgewerblicher Friseur,", "tokens": ["Bald", "kunst\u00b7ge\u00b7werb\u00b7li\u00b7cher", "Fri\u00b7seur", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "bald Redakteur . . .", "tokens": ["bald", "Re\u00b7dak\u00b7teur", ".", ".", "."], "token_info": ["word", "word", "punct", "punct", "punct"], "pos": ["ADV", "NN", "$.", "$.", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "so sehn wir ihn gestern, morgen und heute:", "tokens": ["so", "sehn", "wir", "ihn", "ge\u00b7stern", ",", "mor\u00b7gen", "und", "heu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "$,", "ADV", "KON", "ADV", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "ein Affe.", "tokens": ["ein", "Af\u00b7fe", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ein Affe der reichen Leute.", "tokens": ["Ein", "Af\u00b7fe", "der", "rei\u00b7chen", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}