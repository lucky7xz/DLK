{"textgrid.poem.57732": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Und als das Kind geboren ward,", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und als das Kind geboren ward,", "tokens": ["Und", "als", "das", "Kind", "ge\u00b7bo\u00b7ren", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wehmutter sprach: \u00bbEi seht!", "tokens": ["Die", "Weh\u00b7mut\u00b7ter", "sprach", ":", "\u00bb", "Ei", "seht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "VVFIN", "$."], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Es tr\u00e4gt ja ein Gl\u00fccksh\u00e4ubelein,", "tokens": ["Es", "tr\u00e4gt", "ja", "ein", "Gl\u00fccks\u00b7h\u00e4u\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Wie Sammet weich, wie Seide fein,", "tokens": ["Wie", "Sam\u00b7met", "weich", ",", "wie", "Sei\u00b7de", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "PWAV", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es wird einst vor dem Volk erh\u00f6ht.\u00ab", "tokens": ["Es", "wird", "einst", "vor", "dem", "Volk", "er\u00b7h\u00f6ht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und Vater List und Mutter List,", "tokens": ["Und", "Va\u00b7ter", "List", "und", "Mut\u00b7ter", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die schauen gl\u00e4ubig drein;", "tokens": ["Die", "schau\u00b7en", "gl\u00e4u\u00b7big", "drein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbgriete Tetzlaff spricht nicht ungefragt,", "tokens": ["\u00bb", "grie\u00b7te", "Tetz\u00b7laff", "spricht", "nicht", "un\u00b7ge\u00b7fragt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn Griete Tetzlaff etwas sagt,", "tokens": ["Wenn", "Grie\u00b7te", "Tetz\u00b7laff", "et\u00b7was", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dann trifft es immer richtig ein.\u00ab", "tokens": ["Dann", "trifft", "es", "im\u00b7mer", "rich\u00b7tig", "ein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und Vater List und Mutter List,", "tokens": ["Und", "Va\u00b7ter", "List", "und", "Mut\u00b7ter", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die stellen sich an, o Gott!", "tokens": ["Die", "stel\u00b7len", "sich", "an", ",", "o", "Gott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$,", "FM", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nichts ist f\u00fcr Nickelchen zu fein,", "tokens": ["Nichts", "ist", "f\u00fcr", "Ni\u00b7ckel\u00b7chen", "zu", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PIS", "PTKA", "ADJD", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Sie schauen in ihr Kind hinein,", "tokens": ["Sie", "schau\u00b7en", "in", "ihr", "Kind", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als w\u00e4r' es ein goldner Pott.", "tokens": ["Als", "w\u00e4r'", "es", "ein", "gold\u00b7ner", "Pott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Wer ist der reiche Kavalier?", "tokens": ["Wer", "ist", "der", "rei\u00b7che", "Ka\u00b7va\u00b7lier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Baron de la Mosel er hei\u00dft!", "tokens": ["Ba\u00b7ron", "de", "la", "Mo\u00b7sel", "er", "hei\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "FM", "FM", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Sammet ist er angetan,", "tokens": ["Mit", "Sam\u00b7met", "ist", "er", "an\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Gold er nur so w\u00fchlen kann,", "tokens": ["Im", "Gold", "er", "nur", "so", "w\u00fch\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit gro\u00dfem Tro\u00df im Land er reist.", "tokens": ["Mit", "gro\u00b7\u00dfem", "Tro\u00df", "im", "Land", "er", "reist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Und sein Gemahl ist ebenfalls", "tokens": ["Und", "sein", "Ge\u00b7mahl", "ist", "e\u00b7ben\u00b7falls"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus hochgebornem Haus;", "tokens": ["Aus", "hoch\u00b7ge\u00b7bor\u00b7nem", "Haus", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Selbst unsre B\u00fcrgermeisterfrau", "tokens": ["Selbst", "uns\u00b7re", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter\u00b7frau"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Tr\u00e4gt solche Perlen nicht zur Schau,", "tokens": ["Tr\u00e4gt", "sol\u00b7che", "Per\u00b7len", "nicht", "zur", "Schau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sieht dagegen \u00e4rmlich aus.", "tokens": ["Sie", "sieht", "da\u00b7ge\u00b7gen", "\u00e4rm\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "So spricht man, wo er geht und steht,", "tokens": ["So", "spricht", "man", ",", "wo", "er", "geht", "und", "steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es lacht der Herr Baron", "tokens": ["Es", "lacht", "der", "Herr", "Ba\u00b7ron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und denkt: Es sieht mir niemand an,", "tokens": ["Und", "denkt", ":", "Es", "sieht", "mir", "nie\u00b7mand", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df jedes Schlo\u00df ich sprengen kann", "tokens": ["Da\u00df", "je\u00b7des", "Schlo\u00df", "ich", "spren\u00b7gen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df ich bin ein H\u00e4uslingssohn.", "tokens": ["Und", "da\u00df", "ich", "bin", "ein", "H\u00e4us\u00b7lings\u00b7sohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "In Hamburg seufzt man: \u00bbDomine!", "tokens": ["In", "Ham\u00b7burg", "seufzt", "man", ":", "\u00bb", "Do\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "$.", "$(", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O welches Skandalum!", "tokens": ["O", "wel\u00b7ches", "Skan\u00b7da\u00b7lum", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bestohlen ist Sankt Nikolaus,", "tokens": ["Be\u00b7stoh\u00b7len", "ist", "Sankt", "Ni\u00b7ko\u00b7laus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geraubt der Schatz dem Gotteshaus!\u00ab", "tokens": ["Ge\u00b7raubt", "der", "Schatz", "dem", "Got\u00b7tes\u00b7haus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Ratsherrn schleichen tr\u00fcb herum.", "tokens": ["Die", "Rats\u00b7herrn", "schlei\u00b7chen", "tr\u00fcb", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "In Braunschweig st\u00f6hnt man: \u00bbJemine!", "tokens": ["In", "Braun\u00b7schweig", "st\u00f6hnt", "man", ":", "\u00bb", "Je\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "$.", "$(", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O Sakrilegium!", "tokens": ["O", "Sak\u00b7ri\u00b7le\u00b7gi\u00b7um", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geschehn ist, was man nie geglaubt,", "tokens": ["Ge\u00b7schehn", "ist", ",", "was", "man", "nie", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sankt Katharina ist beraubt.\u00ab", "tokens": ["Sankt", "Ka\u00b7tha\u00b7ri\u00b7na", "ist", "be\u00b7raubt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Die Ratsherrn sind vor Grausen stumm.", "tokens": ["Die", "Rats\u00b7herrn", "sind", "vor", "Grau\u00b7sen", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "In L\u00fcneburg ist Ach und Weh,", "tokens": ["In", "L\u00fc\u00b7ne\u00b7burg", "ist", "Ach", "und", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbsankt Michel ist entweiht!", "tokens": ["\u00bb", "sankt", "Mi\u00b7chel", "ist", "ent\u00b7weiht", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es hat ein Dieb in letzter Nacht", "tokens": ["Es", "hat", "ein", "Dieb", "in", "letz\u00b7ter", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die g\u00fcldne Tafel fortgebracht,", "tokens": ["Die", "g\u00fcld\u00b7ne", "Ta\u00b7fel", "fort\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Himmel auf die Untat schreit.\u00ab", "tokens": ["Zum", "Him\u00b7mel", "auf", "die", "Un\u00b7tat", "schreit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Zu Celle auf dem Galgenplatz", "tokens": ["Zu", "Cel\u00b7le", "auf", "dem", "Gal\u00b7gen\u00b7platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Volk steht dicht an dicht;", "tokens": ["Das", "Volk", "steht", "dicht", "an", "dicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Gl\u00f6cklein gibt so schnellen Klang,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "gibt", "so", "schnel\u00b7len", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Nickel tut den letzten Gang,", "tokens": ["Der", "Ni\u00b7ckel", "tut", "den", "letz\u00b7ten", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es wird ihm endlich das Gericht.", "tokens": ["Es", "wird", "ihm", "end\u00b7lich", "das", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Henker st\u00f6\u00dft ihm mit dem Rad", "tokens": ["Der", "Hen\u00b7ker", "st\u00f6\u00dft", "ihm", "mit", "dem", "Rad"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So Arm wie Bein entzwei;", "tokens": ["So", "Arm", "wie", "Bein", "ent\u00b7zwei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die hochgeborne Lebensart", "tokens": ["Die", "hoch\u00b7ge\u00b7bor\u00b7ne", "Le\u00b7ben\u00b7sart"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich Nickel bis ans Letzte wahrt,", "tokens": ["Sich", "Ni\u00b7ckel", "bis", "ans", "Letz\u00b7te", "wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er tut auch nicht den kleinsten Schrei.", "tokens": ["Er", "tut", "auch", "nicht", "den", "kleins\u00b7ten", "Schrei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und als es nun zu Ende war,", "tokens": ["Und", "als", "es", "nun", "zu", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Henker sprach: \u00bbEi seht!", "tokens": ["Der", "Hen\u00b7ker", "sprach", ":", "\u00bb", "Ei", "seht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er trug ja ein Gl\u00fccksh\u00e4ubelein,", "tokens": ["Er", "trug", "ja", "ein", "Gl\u00fccks\u00b7h\u00e4u\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Wie Sammet weich, wie Seide fein,", "tokens": ["Wie", "Sam\u00b7met", "weich", ",", "wie", "Sei\u00b7de", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "PWAV", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum ward er vor dem Volk erh\u00f6ht!\u00ab", "tokens": ["Drum", "ward", "er", "vor", "dem", "Volk", "er\u00b7h\u00f6ht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Und als das Kind geboren ward,", "tokens": ["Und", "als", "das", "Kind", "ge\u00b7bo\u00b7ren", "ward", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wehmutter sprach: \u00bbEi seht!", "tokens": ["Die", "Weh\u00b7mut\u00b7ter", "sprach", ":", "\u00bb", "Ei", "seht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "VVFIN", "$."], "meter": "-++-+-+", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Es tr\u00e4gt ja ein Gl\u00fccksh\u00e4ubelein,", "tokens": ["Es", "tr\u00e4gt", "ja", "ein", "Gl\u00fccks\u00b7h\u00e4u\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Wie Sammet weich, wie Seide fein,", "tokens": ["Wie", "Sam\u00b7met", "weich", ",", "wie", "Sei\u00b7de", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "PWAV", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es wird einst vor dem Volk erh\u00f6ht.\u00ab", "tokens": ["Es", "wird", "einst", "vor", "dem", "Volk", "er\u00b7h\u00f6ht", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Und Vater List und Mutter List,", "tokens": ["Und", "Va\u00b7ter", "List", "und", "Mut\u00b7ter", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die schauen gl\u00e4ubig drein;", "tokens": ["Die", "schau\u00b7en", "gl\u00e4u\u00b7big", "drein", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbgriete Tetzlaff spricht nicht ungefragt,", "tokens": ["\u00bb", "grie\u00b7te", "Tetz\u00b7laff", "spricht", "nicht", "un\u00b7ge\u00b7fragt", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn Griete Tetzlaff etwas sagt,", "tokens": ["Wenn", "Grie\u00b7te", "Tetz\u00b7laff", "et\u00b7was", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dann trifft es immer richtig ein.\u00ab", "tokens": ["Dann", "trifft", "es", "im\u00b7mer", "rich\u00b7tig", "ein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und Vater List und Mutter List,", "tokens": ["Und", "Va\u00b7ter", "List", "und", "Mut\u00b7ter", "List", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NE", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die stellen sich an, o Gott!", "tokens": ["Die", "stel\u00b7len", "sich", "an", ",", "o", "Gott", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "PTKVZ", "$,", "FM", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Nichts ist f\u00fcr Nickelchen zu fein,", "tokens": ["Nichts", "ist", "f\u00fcr", "Ni\u00b7ckel\u00b7chen", "zu", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PIS", "PTKA", "ADJD", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.4": {"text": "Sie schauen in ihr Kind hinein,", "tokens": ["Sie", "schau\u00b7en", "in", "ihr", "Kind", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als w\u00e4r' es ein goldner Pott.", "tokens": ["Als", "w\u00e4r'", "es", "ein", "gold\u00b7ner", "Pott", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.16": {"line.1": {"text": "Wer ist der reiche Kavalier?", "tokens": ["Wer", "ist", "der", "rei\u00b7che", "Ka\u00b7va\u00b7lier", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Baron de la Mosel er hei\u00dft!", "tokens": ["Ba\u00b7ron", "de", "la", "Mo\u00b7sel", "er", "hei\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "FM", "FM", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Sammet ist er angetan,", "tokens": ["Mit", "Sam\u00b7met", "ist", "er", "an\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Im Gold er nur so w\u00fchlen kann,", "tokens": ["Im", "Gold", "er", "nur", "so", "w\u00fch\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit gro\u00dfem Tro\u00df im Land er reist.", "tokens": ["Mit", "gro\u00b7\u00dfem", "Tro\u00df", "im", "Land", "er", "reist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPRART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Und sein Gemahl ist ebenfalls", "tokens": ["Und", "sein", "Ge\u00b7mahl", "ist", "e\u00b7ben\u00b7falls"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus hochgebornem Haus;", "tokens": ["Aus", "hoch\u00b7ge\u00b7bor\u00b7nem", "Haus", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Selbst unsre B\u00fcrgermeisterfrau", "tokens": ["Selbst", "uns\u00b7re", "B\u00fcr\u00b7ger\u00b7meis\u00b7ter\u00b7frau"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Tr\u00e4gt solche Perlen nicht zur Schau,", "tokens": ["Tr\u00e4gt", "sol\u00b7che", "Per\u00b7len", "nicht", "zur", "Schau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKNEG", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sie sieht dagegen \u00e4rmlich aus.", "tokens": ["Sie", "sieht", "da\u00b7ge\u00b7gen", "\u00e4rm\u00b7lich", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "So spricht man, wo er geht und steht,", "tokens": ["So", "spricht", "man", ",", "wo", "er", "geht", "und", "steht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es lacht der Herr Baron", "tokens": ["Es", "lacht", "der", "Herr", "Ba\u00b7ron"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und denkt: Es sieht mir niemand an,", "tokens": ["Und", "denkt", ":", "Es", "sieht", "mir", "nie\u00b7mand", "an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df jedes Schlo\u00df ich sprengen kann", "tokens": ["Da\u00df", "je\u00b7des", "Schlo\u00df", "ich", "spren\u00b7gen", "kann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und da\u00df ich bin ein H\u00e4uslingssohn.", "tokens": ["Und", "da\u00df", "ich", "bin", "ein", "H\u00e4us\u00b7lings\u00b7sohn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "In Hamburg seufzt man: \u00bbDomine!", "tokens": ["In", "Ham\u00b7burg", "seufzt", "man", ":", "\u00bb", "Do\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "$.", "$(", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O welches Skandalum!", "tokens": ["O", "wel\u00b7ches", "Skan\u00b7da\u00b7lum", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ITJ", "PWS", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bestohlen ist Sankt Nikolaus,", "tokens": ["Be\u00b7stoh\u00b7len", "ist", "Sankt", "Ni\u00b7ko\u00b7laus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geraubt der Schatz dem Gotteshaus!\u00ab", "tokens": ["Ge\u00b7raubt", "der", "Schatz", "dem", "Got\u00b7tes\u00b7haus", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Ratsherrn schleichen tr\u00fcb herum.", "tokens": ["Die", "Rats\u00b7herrn", "schlei\u00b7chen", "tr\u00fcb", "he\u00b7rum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "In Braunschweig st\u00f6hnt man: \u00bbJemine!", "tokens": ["In", "Braun\u00b7schweig", "st\u00f6hnt", "man", ":", "\u00bb", "Je\u00b7mi\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PIS", "$.", "$(", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "O Sakrilegium!", "tokens": ["O", "Sak\u00b7ri\u00b7le\u00b7gi\u00b7um", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Geschehn ist, was man nie geglaubt,", "tokens": ["Ge\u00b7schehn", "ist", ",", "was", "man", "nie", "ge\u00b7glaubt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "PRELS", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sankt Katharina ist beraubt.\u00ab", "tokens": ["Sankt", "Ka\u00b7tha\u00b7ri\u00b7na", "ist", "be\u00b7raubt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NE", "VAFIN", "VVPP", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Die Ratsherrn sind vor Grausen stumm.", "tokens": ["Die", "Rats\u00b7herrn", "sind", "vor", "Grau\u00b7sen", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "In L\u00fcneburg ist Ach und Weh,", "tokens": ["In", "L\u00fc\u00b7ne\u00b7burg", "ist", "Ach", "und", "Weh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbsankt Michel ist entweiht!", "tokens": ["\u00bb", "sankt", "Mi\u00b7chel", "ist", "ent\u00b7weiht", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "NE", "VAFIN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es hat ein Dieb in letzter Nacht", "tokens": ["Es", "hat", "ein", "Dieb", "in", "letz\u00b7ter", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die g\u00fcldne Tafel fortgebracht,", "tokens": ["Die", "g\u00fcld\u00b7ne", "Ta\u00b7fel", "fort\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Himmel auf die Untat schreit.\u00ab", "tokens": ["Zum", "Him\u00b7mel", "auf", "die", "Un\u00b7tat", "schreit", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Zu Celle auf dem Galgenplatz", "tokens": ["Zu", "Cel\u00b7le", "auf", "dem", "Gal\u00b7gen\u00b7platz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Volk steht dicht an dicht;", "tokens": ["Das", "Volk", "steht", "dicht", "an", "dicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Gl\u00f6cklein gibt so schnellen Klang,", "tokens": ["Das", "Gl\u00f6c\u00b7klein", "gibt", "so", "schnel\u00b7len", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Nickel tut den letzten Gang,", "tokens": ["Der", "Ni\u00b7ckel", "tut", "den", "letz\u00b7ten", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es wird ihm endlich das Gericht.", "tokens": ["Es", "wird", "ihm", "end\u00b7lich", "das", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Der Henker st\u00f6\u00dft ihm mit dem Rad", "tokens": ["Der", "Hen\u00b7ker", "st\u00f6\u00dft", "ihm", "mit", "dem", "Rad"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So Arm wie Bein entzwei;", "tokens": ["So", "Arm", "wie", "Bein", "ent\u00b7zwei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die hochgeborne Lebensart", "tokens": ["Die", "hoch\u00b7ge\u00b7bor\u00b7ne", "Le\u00b7ben\u00b7sart"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich Nickel bis ans Letzte wahrt,", "tokens": ["Sich", "Ni\u00b7ckel", "bis", "ans", "Letz\u00b7te", "wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er tut auch nicht den kleinsten Schrei.", "tokens": ["Er", "tut", "auch", "nicht", "den", "kleins\u00b7ten", "Schrei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Und als es nun zu Ende war,", "tokens": ["Und", "als", "es", "nun", "zu", "En\u00b7de", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Henker sprach: \u00bbEi seht!", "tokens": ["Der", "Hen\u00b7ker", "sprach", ":", "\u00bb", "Ei", "seht", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er trug ja ein Gl\u00fccksh\u00e4ubelein,", "tokens": ["Er", "trug", "ja", "ein", "Gl\u00fccks\u00b7h\u00e4u\u00b7be\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Wie Sammet weich, wie Seide fein,", "tokens": ["Wie", "Sam\u00b7met", "weich", ",", "wie", "Sei\u00b7de", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ADJD", "$,", "PWAV", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Drum ward er vor dem Volk erh\u00f6ht!\u00ab", "tokens": ["Drum", "ward", "er", "vor", "dem", "Volk", "er\u00b7h\u00f6ht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "APPR", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}