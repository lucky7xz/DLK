{"textgrid.poem.53776": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "In Wei\u00dfensee", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.71", "af:0.28"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Da, wo Chamottefabriken stehn", "tokens": ["Da", ",", "wo", "Cha\u00b7mot\u00b7te\u00b7fab\u00b7ri\u00b7ken", "stehn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "NN", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u2013 Motorgebrumm \u2013", "tokens": ["\u2013", "Mo\u00b7tor\u00b7ge\u00b7brumm", "\u2013"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "da kannst du einen Friedhof sehn,", "tokens": ["da", "kannst", "du", "ei\u00b7nen", "Fried\u00b7hof", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Mauern drum.", "tokens": ["mit", "Mau\u00b7ern", "drum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Jedweder hat hier seine Welt:", "tokens": ["Jed\u00b7we\u00b7der", "hat", "hier", "sei\u00b7ne", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein Feld.", "tokens": ["ein", "Feld", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Und so ein Feld hei\u00dft irgendwie:", "tokens": ["Und", "so", "ein", "Feld", "hei\u00dft", "ir\u00b7gend\u00b7wie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O oder I . . .", "tokens": ["O", "o\u00b7der", "I", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "KON", "CARD", "$.", "$.", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Sie kamen hierher aus den Betten,", "tokens": ["Sie", "ka\u00b7men", "hier\u00b7her", "aus", "den", "Bet\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "ART", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "aus Kellern, Wagen und Toiletten,", "tokens": ["aus", "Kel\u00b7lern", ",", "Wa\u00b7gen", "und", "To\u00b7i\u00b7let\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "und manche aus der Charit\u00e9", "tokens": ["und", "man\u00b7che", "aus", "der", "Cha\u00b7rit\u00e9"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "nach Wei\u00dfensee,", "tokens": ["nach", "Wei\u00b7\u00dfen\u00b7see", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "nach Wei\u00dfensee.", "tokens": ["nach", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Wird einer frisch dort eingepflanzt", "tokens": ["Wird", "ei\u00b7ner", "frisch", "dort", "ein\u00b7ge\u00b7pflanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJD", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nach frommem Brauch,", "tokens": ["nach", "from\u00b7mem", "Brauch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "dann kommen viele angetanzt \u2013", "tokens": ["dann", "kom\u00b7men", "vie\u00b7le", "an\u00b7ge\u00b7tanzt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das mu\u00df man auch.", "tokens": ["das", "mu\u00df", "man", "auch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Harmonium singt Adagio", "tokens": ["Har\u00b7mo\u00b7ni\u00b7um", "singt", "A\u00b7da\u00b7gio"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "NE"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "\u2013 Feld O \u2013", "tokens": ["\u2013", "Feld", "O", "\u2013"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "das Auto wartet \u2013 Taxe drei \u2013", "tokens": ["das", "Au\u00b7to", "war\u00b7tet", "\u2013", "Ta\u00b7xe", "drei", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "NN", "CARD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u2013 Feld Ei \u2013", "tokens": ["\u2013", "Feld", "Ei", "\u2013"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$("], "meter": "++", "measure": "spondeus"}, "line.9": {"text": "Ein Geistlicher kann seins nicht lesen.", "tokens": ["Ein", "Geist\u00b7li\u00b7cher", "kann", "seins", "nicht", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und was er f\u00fcr ein Herz gewesen,", "tokens": ["Und", "was", "er", "f\u00fcr", "ein", "Herz", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "h\u00f6rt stolz im Sarge der Bankier", "tokens": ["h\u00f6rt", "stolz", "im", "Sar\u00b7ge", "der", "Ban\u00b7kier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "in Wei\u00dfensee,", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "in Wei\u00dfensee.", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Da, wo ich oft gewesen bin,", "tokens": ["Da", ",", "wo", "ich", "oft", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zwecks Trauerei,", "tokens": ["zwecks", "Trau\u00b7e\u00b7rei", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "da kommst du hin, da komm ich hin,", "tokens": ["da", "kommst", "du", "hin", ",", "da", "komm", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenns mal vorbei.", "tokens": ["wenns", "mal", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Du liebst. Du reist. Du freust dich, du \u2013", "tokens": ["Du", "liebst", ".", "Du", "reist", ".", "Du", "freust", "dich", ",", "du", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "$,", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Feld U \u2013", "tokens": ["Feld", "U", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "XY", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Es wartet in absentia", "tokens": ["Es", "war\u00b7tet", "in", "ab\u00b7sen\u00b7tia"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Feld A.", "tokens": ["Feld", "A."], "token_info": ["word", "abbreviation"], "pos": ["NN", "APPRART"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Es tickt die Uhr. Dein Grab hat Zeit,", "tokens": ["Es", "tickt", "die", "Uhr", ".", "Dein", "Grab", "hat", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "drei Meter lang, ein Meter breit.", "tokens": ["drei", "Me\u00b7ter", "lang", ",", "ein", "Me\u00b7ter", "breit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Du siehst noch drei, vier fremde St\u00e4dte,", "tokens": ["Du", "siehst", "noch", "drei", ",", "vier", "frem\u00b7de", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "$,", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "du siehst noch eine nackte Grete,", "tokens": ["du", "siehst", "noch", "ei\u00b7ne", "nack\u00b7te", "Gre\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "noch zwanzig\u2013, drei\u00dfigmal den Schnee \u2013", "tokens": ["noch", "zwan\u00b7zig", "\u2013", ",", "drei\u00b7\u00dfig\u00b7mal", "den", "Schnee", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "$(", "$,", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und dann:", "tokens": ["Und", "dann", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Feld P \u2013 in Wei\u00dfensee \u2013", "tokens": ["Feld", "P", "\u2013", "in", "Wei\u00b7\u00dfen\u00b7see", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "APPR", "NE", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.16": {"text": "in Wei\u00dfensee.", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Da, wo Chamottefabriken stehn", "tokens": ["Da", ",", "wo", "Cha\u00b7mot\u00b7te\u00b7fab\u00b7ri\u00b7ken", "stehn"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWAV", "NN", "VVINF"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u2013 Motorgebrumm \u2013", "tokens": ["\u2013", "Mo\u00b7tor\u00b7ge\u00b7brumm", "\u2013"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "NE", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "da kannst du einen Friedhof sehn,", "tokens": ["da", "kannst", "du", "ei\u00b7nen", "Fried\u00b7hof", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Mauern drum.", "tokens": ["mit", "Mau\u00b7ern", "drum", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Jedweder hat hier seine Welt:", "tokens": ["Jed\u00b7we\u00b7der", "hat", "hier", "sei\u00b7ne", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ein Feld.", "tokens": ["ein", "Feld", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+", "measure": "iambic.single"}, "line.7": {"text": "Und so ein Feld hei\u00dft irgendwie:", "tokens": ["Und", "so", "ein", "Feld", "hei\u00dft", "ir\u00b7gend\u00b7wie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "O oder I . . .", "tokens": ["O", "o\u00b7der", "I", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["NE", "KON", "CARD", "$.", "$.", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.9": {"text": "Sie kamen hierher aus den Betten,", "tokens": ["Sie", "ka\u00b7men", "hier\u00b7her", "aus", "den", "Bet\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "ART", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "aus Kellern, Wagen und Toiletten,", "tokens": ["aus", "Kel\u00b7lern", ",", "Wa\u00b7gen", "und", "To\u00b7i\u00b7let\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "und manche aus der Charit\u00e9", "tokens": ["und", "man\u00b7che", "aus", "der", "Cha\u00b7rit\u00e9"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "APPR", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.12": {"text": "nach Wei\u00dfensee,", "tokens": ["nach", "Wei\u00b7\u00dfen\u00b7see", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "nach Wei\u00dfensee.", "tokens": ["nach", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.5": {"line.1": {"text": "Wird einer frisch dort eingepflanzt", "tokens": ["Wird", "ei\u00b7ner", "frisch", "dort", "ein\u00b7ge\u00b7pflanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJD", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nach frommem Brauch,", "tokens": ["nach", "from\u00b7mem", "Brauch", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "dann kommen viele angetanzt \u2013", "tokens": ["dann", "kom\u00b7men", "vie\u00b7le", "an\u00b7ge\u00b7tanzt", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "das mu\u00df man auch.", "tokens": ["das", "mu\u00df", "man", "auch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PIS", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Harmonium singt Adagio", "tokens": ["Har\u00b7mo\u00b7ni\u00b7um", "singt", "A\u00b7da\u00b7gio"], "token_info": ["word", "word", "word"], "pos": ["NE", "VVFIN", "NE"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "\u2013 Feld O \u2013", "tokens": ["\u2013", "Feld", "O", "\u2013"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "NN", "NE", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "das Auto wartet \u2013 Taxe drei \u2013", "tokens": ["das", "Au\u00b7to", "war\u00b7tet", "\u2013", "Ta\u00b7xe", "drei", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$(", "NN", "CARD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u2013 Feld Ei \u2013", "tokens": ["\u2013", "Feld", "Ei", "\u2013"], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "NN", "NN", "$("], "meter": "++", "measure": "spondeus"}, "line.9": {"text": "Ein Geistlicher kann seins nicht lesen.", "tokens": ["Ein", "Geist\u00b7li\u00b7cher", "kann", "seins", "nicht", "le\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und was er f\u00fcr ein Herz gewesen,", "tokens": ["Und", "was", "er", "f\u00fcr", "ein", "Herz", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "APPR", "ART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "h\u00f6rt stolz im Sarge der Bankier", "tokens": ["h\u00f6rt", "stolz", "im", "Sar\u00b7ge", "der", "Ban\u00b7kier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "APPRART", "NN", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.12": {"text": "in Wei\u00dfensee,", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.13": {"text": "in Wei\u00dfensee.", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.6": {"line.1": {"text": "Da, wo ich oft gewesen bin,", "tokens": ["Da", ",", "wo", "ich", "oft", "ge\u00b7we\u00b7sen", "bin", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "PPER", "ADV", "VAPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zwecks Trauerei,", "tokens": ["zwecks", "Trau\u00b7e\u00b7rei", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "da kommst du hin, da komm ich hin,", "tokens": ["da", "kommst", "du", "hin", ",", "da", "komm", "ich", "hin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wenns mal vorbei.", "tokens": ["wenns", "mal", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PTKVZ", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Du liebst. Du reist. Du freust dich, du \u2013", "tokens": ["Du", "liebst", ".", "Du", "reist", ".", "Du", "freust", "dich", ",", "du", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "$,", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Feld U \u2013", "tokens": ["Feld", "U", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["NN", "XY", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Es wartet in absentia", "tokens": ["Es", "war\u00b7tet", "in", "ab\u00b7sen\u00b7tia"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Feld A.", "tokens": ["Feld", "A."], "token_info": ["word", "abbreviation"], "pos": ["NN", "APPRART"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Es tickt die Uhr. Dein Grab hat Zeit,", "tokens": ["Es", "tickt", "die", "Uhr", ".", "Dein", "Grab", "hat", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PPOSAT", "NN", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "drei Meter lang, ein Meter breit.", "tokens": ["drei", "Me\u00b7ter", "lang", ",", "ein", "Me\u00b7ter", "breit", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "$,", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Du siehst noch drei, vier fremde St\u00e4dte,", "tokens": ["Du", "siehst", "noch", "drei", ",", "vier", "frem\u00b7de", "St\u00e4d\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "CARD", "$,", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "du siehst noch eine nackte Grete,", "tokens": ["du", "siehst", "noch", "ei\u00b7ne", "nack\u00b7te", "Gre\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "noch zwanzig\u2013, drei\u00dfigmal den Schnee \u2013", "tokens": ["noch", "zwan\u00b7zig", "\u2013", ",", "drei\u00b7\u00dfig\u00b7mal", "den", "Schnee", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "$(", "$,", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und dann:", "tokens": ["Und", "dann", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$."], "meter": "-+", "measure": "iambic.single"}, "line.15": {"text": "Feld P \u2013 in Wei\u00dfensee \u2013", "tokens": ["Feld", "P", "\u2013", "in", "Wei\u00b7\u00dfen\u00b7see", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "APPR", "NE", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.16": {"text": "in Wei\u00dfensee.", "tokens": ["in", "Wei\u00b7\u00dfen\u00b7see", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}}}}}