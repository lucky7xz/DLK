{"dta.poem.19085": {"metadata": {"author": {"name": "Zinzendorf, Nicolaus Ludwig von", "birth": "N.A.", "death": "N.A."}, "title": "LxVII.  Auf des theuren Elers Entschlafen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20688-6", "language": ["de:0.99"], "booktitle": "Zinzendorf, Nicolaus Ludwig von: Teutscher Gedichte Erster Theil. Herrnhuth, 1735."}, "poem": {"stanza.1": {"line.1": {"text": "Mein K\u00f6nig, Priester und Prophet,", "tokens": ["Mein", "K\u00f6\u00b7nig", ",", "Pries\u00b7ter", "und", "Pro\u00b7phet", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du treuester von allen Zeugen,", "tokens": ["Du", "treu\u00b7es\u00b7ter", "von", "al\u00b7len", "Zeu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du allerkr\u00e4ftigster Magnet,", "tokens": ["Du", "al\u00b7ler\u00b7kr\u00e4f\u00b7tigs\u00b7ter", "Mag\u00b7net", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Du Held im Stehen und im Beugen,", "tokens": ["Du", "Held", "im", "Ste\u00b7hen", "und", "im", "Beu\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es hat dein sch\u00f6nes Ebenbild,", "tokens": ["Es", "hat", "dein", "sch\u00f6\u00b7nes", "E\u00b7ben\u00b7bild", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Seit du es uns mit Blut erworben,", "tokens": ["Seit", "du", "es", "uns", "mit", "Blut", "er\u00b7wor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PRF", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wol manches edles Hertz erf\u00fcllt,", "tokens": ["Wol", "man\u00b7ches", "ed\u00b7les", "Hertz", "er\u00b7f\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das schon auf deinen Tod gestorben:", "tokens": ["Das", "schon", "auf", "dei\u00b7nen", "Tod", "ge\u00b7stor\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Allein, was haben wir", "tokens": ["Al\u00b7lein", ",", "was", "ha\u00b7ben", "wir"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "PWS", "VAFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Vor eine Zions-Zier", "tokens": ["Vor", "ei\u00b7ne", "Zi\u00b7ons\u00b7Zier"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Seit wenig Tagen eingesarget?", "tokens": ["Seit", "we\u00b7nig", "Ta\u00b7gen", "ein\u00b7ge\u00b7sar\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Wer war dein ", "tokens": ["Wer", "war", "dein"], "token_info": ["word", "word", "word"], "pos": ["PWS", "VAFIN", "PPOSAT"], "meter": "+-+", "measure": "trochaic.di"}, "line.13": {"text": "Das brennend helle Licht,", "tokens": ["Das", "bren\u00b7nend", "hel\u00b7le", "Licht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Des Abgang man dir fast verarget?", "tokens": ["Des", "Ab\u00b7gang", "man", "dir", "fast", "ver\u00b7ar\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Er war ein K\u00f6nig \u00fcber sich,", "tokens": ["Er", "war", "ein", "K\u00f6\u00b7nig", "\u00fc\u00b7ber", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein K\u00f6nig, weil er von dir stammte,", "tokens": ["Ein", "K\u00f6\u00b7nig", ",", "weil", "er", "von", "dir", "stamm\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ein K\u00f6nig, weil er niemand wich,", "tokens": ["Ein", "K\u00f6\u00b7nig", ",", "weil", "er", "nie\u00b7mand", "wich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein K\u00f6nig im Beruf und Amte:", "tokens": ["Ein", "K\u00f6\u00b7nig", "im", "Be\u00b7ruf", "und", "Am\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Priester vor das Waysen-Hau\u00df,", "tokens": ["Ein", "Pries\u00b7ter", "vor", "das", "Way\u00b7sen\u00b7Hau\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Aus grossen Francken Bet-Altar:", "tokens": ["Aus", "gros\u00b7sen", "Fran\u00b7cken", "Bet\u00b7Al\u00b7tar", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Er gieng als Jungfrau ein und aus,", "tokens": ["Er", "gieng", "als", "Jung\u00b7frau", "ein", "und", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und webte dir fast funfzig Jahr.", "tokens": ["Und", "web\u00b7te", "dir", "fast", "funf\u00b7zig", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "CARD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Er war auch ein Prophet,", "tokens": ["Er", "war", "auch", "ein", "Pro\u00b7phet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Jm Handel, beym Pulpet,", "tokens": ["Jm", "Han\u00b7del", ",", "beym", "Pul\u00b7pet", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Daheim so wohl als auf den Messen,", "tokens": ["Da\u00b7heim", "so", "wohl", "als", "auf", "den", "Mes\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "ADV", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Manch Zeugni\u00df vor dem HErrn,", "tokens": ["Manch", "Zeug\u00b7ni\u00df", "vor", "dem", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Dem hellen Morgen-Stern", "tokens": ["Dem", "hel\u00b7len", "Mor\u00b7gen\u00b7S\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.14": {"text": "Gieng, oder flog\u2019 aus seinen Pressen.", "tokens": ["Gieng", ",", "o\u00b7der", "flo\u00b7g'", "aus", "sei\u00b7nen", "Pres\u00b7sen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Mir war er recht als ein Magnet.", "tokens": ["Mir", "war", "er", "recht", "als", "ein", "Mag\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ich h\u00f6rte von ihm an dem Orte,", "tokens": ["Ich", "h\u00f6r\u00b7te", "von", "ihm", "an", "dem", "Or\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wo seiner H\u00e4nde Werck noch steht,", "tokens": ["Wo", "sei\u00b7ner", "H\u00e4n\u00b7de", "Werck", "noch", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vor achtzehn Jahren grosse Worte,", "tokens": ["Vor", "acht\u00b7zehn", "Jah\u00b7ren", "gros\u00b7se", "Wor\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die griffen mir ins Hertz hinein,", "tokens": ["Die", "grif\u00b7fen", "mir", "ins", "Hertz", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die unterhielten JEsu Liebe,", "tokens": ["Die", "un\u00b7ter\u00b7hiel\u00b7ten", "Je\u00b7su", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Jtzt reitzte mich sein heller Schein,", "tokens": ["Jtzt", "reitz\u00b7te", "mich", "sein", "hel\u00b7ler", "Schein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Bald drang sein Eifer meine Triebe.", "tokens": ["Bald", "drang", "sein", "Ei\u00b7fer", "mei\u00b7ne", "Trie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mein Heyland! dich, ", "tokens": ["Mein", "Hey\u00b7land", "!", "dich", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.10": {"text": "Verehr ich ", "tokens": ["Ver\u00b7ehr", "ich"], "token_info": ["word", "word"], "pos": ["NN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.11": {"text": "Dich darf ich nur mein Leben nennen;", "tokens": ["Dich", "darf", "ich", "nur", "mein", "Le\u00b7ben", "nen\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Doch kan ich mancherley,", "tokens": ["Doch", "kan", "ich", "man\u00b7cher\u00b7ley", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Und grosse ", "tokens": ["Und", "gros\u00b7se"], "token_info": ["word", "word"], "pos": ["KON", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}}}}}