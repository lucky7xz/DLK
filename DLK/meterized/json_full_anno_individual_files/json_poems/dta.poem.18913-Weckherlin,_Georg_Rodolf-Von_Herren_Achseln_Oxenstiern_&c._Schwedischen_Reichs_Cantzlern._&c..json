{"dta.poem.18913": {"metadata": {"author": {"name": "Weckherlin, Georg Rodolf", "birth": "N.A.", "death": "N.A."}, "title": "Von Herren Achseln Oxenstiern   &c.  \n  Schwedischen Reichs Cantzlern.   &c.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1641", "urn": "urn:nbn:de:kobv:b4-200905198111", "language": ["de:0.85", "af:0.14"], "booktitle": "Weckherlin, Georg Rodolf: Gaistliche und Weltliche Gedichte. Amsterdam, 1641."}, "poem": {"stanza.1": {"line.1": {"text": "Man findet kein gestirn/ das mit so klarem brand", "tokens": ["Man", "fin\u00b7det", "kein", "ge\u00b7stirn", "/", "das", "mit", "so", "kla\u00b7rem", "brand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PIAT", "NN", "$(", "PDS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Vnd starckem gegenschein als diser Nord-", "tokens": ["Vnd", "star\u00b7ckem", "ge\u00b7gen\u00b7schein", "als", "di\u00b7ser", "Nord"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KOKOM", "PDS", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "stern scheinet/", "tokens": ["stern", "schei\u00b7net", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$("], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Stracks wider die zu weit vnd hart greiffende", "tokens": ["Stracks", "wi\u00b7der", "die", "zu", "weit", "vnd", "hart", "greif\u00b7fen\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "PTKA", "ADJD", "KON", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "hand/", "tokens": ["hand", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Darunder dz numehr gejochte Teutschla\u0303d weinet.", "tokens": ["Da\u00b7run\u00b7der", "dz", "nu\u00b7mehr", "ge\u00b7joch\u00b7te", "Teut\u00b7schl\u00e3d", "wei\u00b7net", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "KOUS", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Man findet keine ", "tokens": ["Man", "fin\u00b7det", "kei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VVFIN", "PIAT"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Erfahrung/ wei\u00dfheit/ kunst/ des Risen/ der ver-", "tokens": ["Er\u00b7fah\u00b7rung", "/", "wei\u00df\u00b7heit", "/", "kunst", "/", "des", "Ri\u00b7sen", "/", "der", "ver"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$(", "NN", "$(", "PTKVZ", "$(", "ART", "NN", "$(", "ART", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "meinet", "tokens": ["mei\u00b7net"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Da\u00df jhm gehorchen solt ein jedes Meer/ Volck/", "tokens": ["Da\u00df", "jhm", "ge\u00b7hor\u00b7chen", "solt", "ein", "je\u00b7des", "Meer", "/", "Volck", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "VMFIN", "ART", "PIAT", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Land/", "tokens": ["Land", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Zu weit-g\u00f6nenden munds welt-weitten lust ver-", "tokens": ["Zu", "weit\u00b7g\u00f6\u00b7nen\u00b7den", "munds", "welt\u00b7weit\u00b7ten", "lust", "ver"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVFIN", "TRUNC"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "neinet.", "tokens": ["nei\u00b7net", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.3": {"line.1": {"text": "Hat sch\u00f5 dein Hercules (Gustav der Gro\u00df) mit muht", "tokens": ["Hat", "sch\u00f5", "dein", "Her\u00b7cu\u00b7les", "(", "Gus\u00b7tav", "der", "Gro\u00df", ")", "mit", "muht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVFIN", "PPOSAT", "NN", "$(", "NE", "ART", "NE", "$(", "APPR", "VVFIN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Sich durch der Risen heer den G\u00f6ttern zuge-", "tokens": ["Sich", "durch", "der", "Ri\u00b7sen", "heer", "den", "G\u00f6t\u00b7tern", "zu\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "APPR", "ART", "NN", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "schlagen/", "tokens": ["schla\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["VVFIN", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "So f\u00f6rcht/ O frommer hauff/ du doch nicht jhre", "tokens": ["So", "f\u00f6rcht", "/", "O", "from\u00b7mer", "hauff", "/", "du", "doch", "nicht", "jhre"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$(", "NE", "ADJA", "NN", "$(", "PPER", "ADV", "PTKNEG", "PPOSAT"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "wuht.", "tokens": ["wuht", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-", "measure": "single.down"}}, "stanza.4": {"line.1": {"text": "Dan solt der himmel sich vil f\u00f6rchten oder klagen/", "tokens": ["Dan", "solt", "der", "him\u00b7mel", "sich", "vil", "f\u00f6rch\u00b7ten", "o\u00b7der", "kla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PRF", "ADV", "VVFIN", "KON", "VVINF", "$("], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Al\u00dflang des H\u00f6chsten hand/ Allm\u00e4chtig vnnd", "tokens": ["Al\u00df\u00b7lang", "des", "H\u00f6chs\u00b7ten", "hand", "/", "All\u00b7m\u00e4ch\u00b7tig", "vnnd"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "$(", "ADJD", "KON"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "allgut/", "tokens": ["all\u00b7gut", "/"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Bewahret dise seul vnd ", "tokens": ["Be\u00b7wah\u00b7ret", "di\u00b7se", "seul", "vnd"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "NN", "KON"], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}