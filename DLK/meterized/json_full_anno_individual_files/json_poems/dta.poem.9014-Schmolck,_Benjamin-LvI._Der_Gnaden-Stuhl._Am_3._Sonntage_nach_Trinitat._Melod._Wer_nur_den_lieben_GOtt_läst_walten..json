{"dta.poem.9014": {"metadata": {"author": {"name": "Schmolck, Benjamin", "birth": "N.A.", "death": "N.A."}, "title": "LvI.  \n  Der Gnaden-Stuhl.  \n Am 3. Sonntage nach Trinitat.  \n Melod. Wer nur den lieben GOtt l\u00e4st walten.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1712", "urn": "urn:nbn:de:kobv:b4-20543-0", "language": ["de:0.99"], "booktitle": "Schmolck, Benjamin: Der Lustige Sabbath. Jauer u. a., 1712."}, "poem": {"stanza.1": {"line.1": {"text": "1. (der/", "tokens": ["(", "der", "/"], "token_info": ["punct", "word", "punct"], "pos": ["$(", "ART", "$("], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Ach s\u00fcsses Wort f\u00fcr arme S\u00fcn-", "tokens": ["Ach", "s\u00fcs\u00b7ses", "Wort", "f\u00fcr", "ar\u00b7me", "S\u00fcn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "ADJA", "NN", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das man mir heut ins Hertze", "tokens": ["Das", "man", "mir", "heut", "ins", "Hert\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "PPER", "ADV", "APPRART", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "schreibt/ (der", "tokens": ["schreibt", "/", "(", "der"], "token_info": ["word", "punct", "punct", "word"], "pos": ["VVFIN", "$(", "$(", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Ob gleich der Mund der Satans kin-", "tokens": ["Ob", "gleich", "der", "Mund", "der", "Sa\u00b7tans", "kin"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nur sein Gesp\u00f6tte dr\u00fcber treibt.", "tokens": ["Nur", "sein", "Ge\u00b7sp\u00f6t\u00b7te", "dr\u00fc\u00b7ber", "treibt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "O Wort das mich erfreuen kan:", "tokens": ["O", "Wort", "das", "mich", "er\u00b7freu\u00b7en", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Mein JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "2.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Ich bin auch unter diesem Hauffen/", "tokens": ["Ich", "bin", "auch", "un\u00b7ter", "die\u00b7sem", "Hauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der JEsu von dir ferne stund.", "tokens": ["Der", "Je\u00b7su", "von", "dir", "fer\u00b7ne", "stund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch komm ich dir itzt nachgelauffen/", "tokens": ["Doch", "komm", "ich", "dir", "itzt", "nach\u00b7ge\u00b7lauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Es naht sich zu dir Hertz und Mund.", "tokens": ["Es", "naht", "sich", "zu", "dir", "Hertz", "und", "Mund", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach thue/ was du dort gethan.", "tokens": ["Ach", "thue", "/", "was", "du", "dort", "ge\u00b7than", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$(", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Mein JESU/ nihm den S&#252;nder an!", "tokens": ["Mein", "Je\u00b7SU", "/", "nihm", "den", "S", "&#252;", "nder", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$(", "VVIMP", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "3.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Ein Hirte suchet mit Verlangen/", "tokens": ["Ein", "Hir\u00b7te", "su\u00b7chet", "mit", "Ver\u00b7lan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wenn er ein Schaff verlohren hat.", "tokens": ["Wenn", "er", "ein", "Schaff", "ver\u00b7loh\u00b7ren", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ach eile doch mich zu umbfangen/", "tokens": ["Ach", "ei\u00b7le", "doch", "mich", "zu", "umb\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und bringe mich auff rechten Pfad.", "tokens": ["Und", "brin\u00b7ge", "mich", "auff", "rech\u00b7ten", "Pfad", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du bist der/ der mich finden kan.", "tokens": ["Du", "bist", "der", "/", "der", "mich", "fin\u00b7den", "kan", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "$(", "PRELS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ach JESU/ nihm dein Sch&#228;flein an!", "tokens": ["Ach", "Je\u00b7SU", "/", "nihm", "dein", "Sch", "&#228;", "flein", "an", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["NN", "NE", "$(", "VVIMP", "PPOSAT", "NN", "$(", "VVIMP", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "4.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Ich bin ja leider! sehr verirret/", "tokens": ["Ich", "bin", "ja", "lei\u00b7der", "!", "sehr", "ver\u00b7ir\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$.", "ADV", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Welt ist meine W\u00fcsteney/", "tokens": ["Die", "Welt", "ist", "mei\u00b7ne", "W\u00fcs\u00b7te\u00b7ney", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da hab ich meinen Fu\u00df verwirret/", "tokens": ["Da", "hab", "ich", "mei\u00b7nen", "Fu\u00df", "ver\u00b7wir\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ach mache mich in Gnaden frey/", "tokens": ["Ach", "ma\u00b7che", "mich", "in", "Gna\u00b7den", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "PRF", "APPR", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man von mir auch sagen kan:", "tokens": ["Da\u00df", "man", "von", "mir", "auch", "sa\u00b7gen", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mein JESUS nim\u0303t den S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "den", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "5.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Du hattest wohl zu deinem Bilde/", "tokens": ["Du", "hat\u00b7test", "wohl", "zu", "dei\u00b7nem", "Bil\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als einen Groschen mich gepr\u00e4gt.", "tokens": ["Als", "ei\u00b7nen", "Gro\u00b7schen", "mich", "ge\u00b7pr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Allein ich f\u00fchrte das im Schilde/", "tokens": ["Al\u00b7lein", "ich", "f\u00fchr\u00b7te", "das", "im", "Schil\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "APPRART", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was lauter S\u00fcnd und Greuel hegt.", "tokens": ["Was", "lau\u00b7ter", "S\u00fcnd", "und", "Greu\u00b7el", "hegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach wie so wenig dacht ich dran:", "tokens": ["Ach", "wie", "so", "we\u00b7nig", "dacht", "ich", "dran", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ADV", "PIS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "6.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Nun suche mich mit deinem Lichte", "tokens": ["Nun", "su\u00b7che", "mich", "mit", "dei\u00b7nem", "Lich\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Aus meinem S\u00fcnden-winckel auff.", "tokens": ["Aus", "mei\u00b7nem", "S\u00fcn\u00b7den\u00b7win\u00b7ckel", "auff", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gib mir ein anderes Gewichte/", "tokens": ["Gib", "mir", "ein", "an\u00b7de\u00b7res", "Ge\u00b7wich\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und dr\u00fcck ein neues Bildn\u00fc\u00df drauff.", "tokens": ["Und", "dr\u00fcck", "ein", "neu\u00b7es", "Bild\u00b7n\u00fc\u00df", "drauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df man dich ferner r\u00fchmen kan:", "tokens": ["Da\u00df", "man", "dich", "fer\u00b7ner", "r\u00fch\u00b7men", "kan", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "7.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Gib da\u00df ich dir mit meiner Busse", "tokens": ["Gib", "da\u00df", "ich", "dir", "mit", "mei\u00b7ner", "Bus\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "KOUS", "PPER", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Auch eine Freude machen mag/", "tokens": ["Auch", "ei\u00b7ne", "Freu\u00b7de", "ma\u00b7chen", "mag", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich fall in Demuth dir zu Fusse/", "tokens": ["Ich", "fall", "in", "De\u00b7muth", "dir", "zu", "Fus\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach stiffte selber den Vertrag.", "tokens": ["Ach", "stiff\u00b7te", "sel\u00b7ber", "den", "Ver\u00b7trag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Du hast genung f\u00fcr mich gethan.", "tokens": ["Du", "hast", "ge\u00b7nung", "f\u00fcr", "mich", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "8.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Und hast du einmahl mich gefunden/", "tokens": ["Und", "hast", "du", "ein\u00b7mahl", "mich", "ge\u00b7fun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So la\u00df mich nicht verlohren gehn.", "tokens": ["So", "la\u00df", "mich", "nicht", "ver\u00b7loh\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "PTKNEG", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erhalte mich in deinen Wunden/", "tokens": ["Er\u00b7hal\u00b7te", "mich", "in", "dei\u00b7nen", "Wun\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Tugend-Klang sey im\u0303er sch\u00f6n.", "tokens": ["Mein", "Tu\u00b7gen\u00b7dKlang", "sey", "i\u00b7m\u0303er", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mein Lauff sey stets auff dieser bahn/", "tokens": ["Mein", "Lauff", "sey", "stets", "auff", "die\u00b7ser", "bahn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Wo JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Wo", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PWAV", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "9.", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Trag endlich mich auff deinem R\u00fccke", "tokens": ["Trag", "end\u00b7lich", "mich", "auff", "dei\u00b7nem", "R\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In deinen Stall zur Welt hinaus/", "tokens": ["In", "dei\u00b7nen", "Stall", "zur", "Welt", "hin\u00b7aus", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "NN", "APZR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Und la\u00df mich dort im Schatze blicken/", "tokens": ["Und", "la\u00df", "mich", "dort", "im", "Schat\u00b7ze", "bli\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo dein geschm\u00fccktes Himelshau\u00df.", "tokens": ["Wo", "dein", "ge\u00b7schm\u00fcck\u00b7tes", "Hi\u00b7mels\u00b7hau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wei\u00df ich/ was dis Trostwort kan:", "tokens": ["So", "wei\u00df", "ich", "/", "was", "dis", "Trost\u00b7wort", "kan", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$(", "PWS", "PDS", "NN", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein JESUS nim\u0303t die S&#252;nder an.", "tokens": ["Mein", "Je\u00b7SUS", "nim\u0303t", "die", "S", "&#252;", "nder", "an", "."], "token_info": ["word", "word", "word", "word", "word", "XML_entity", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "ART", "XY", "$(", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}