{"textgrid.poem.53497": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Papiernot", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gewi\u00df \u2013 es ist nicht immer sch\u00f6n gewesen", "tokens": ["Ge\u00b7wi\u00df", "\u2013", "es", "ist", "nicht", "im\u00b7mer", "sch\u00f6n", "ge\u00b7we\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "das aberwitzige Echo unsrer Zeit:", "tokens": ["das", "a\u00b7berw\u00b7it\u00b7zi\u00b7ge", "E\u00b7cho", "uns\u00b7rer", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "man konnte rechtsrum, konnte linksrum lesen", "tokens": ["man", "konn\u00b7te", "rechts\u00b7rum", ",", "konn\u00b7te", "links\u00b7rum", "le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "$,", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und war zum Schlu\u00df meist ebenso gescheit.", "tokens": ["und", "war", "zum", "Schlu\u00df", "meist", "e\u00b7ben\u00b7so", "ge\u00b7scheit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Presse schm\u00fcckte stets mit neuen Funkelthesen", "tokens": ["Die", "Pres\u00b7se", "schm\u00fcck\u00b7te", "stets", "mit", "neu\u00b7en", "Fun\u00b7kelt\u00b7he\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ihr Morgen-, Mittags- und ihr Abendkleid . . .", "tokens": ["ihr", "Mor\u00b7gen", ",", "Mit\u00b7tags", "und", "ihr", "A\u00b7bend\u00b7kleid", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "TRUNC", "$,", "TRUNC", "KON", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und doch: ein Quentchen blieb \u2013 es war nicht viel,", "tokens": ["Und", "doch", ":", "ein", "Quent\u00b7chen", "blieb", "\u2013", "es", "war", "nicht", "viel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "ART", "NN", "VVFIN", "$(", "PPER", "VAFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "ein St\u00fcckchen B\u00fcrgerfreiheit \u2013 kurz: ein Dampfventil.", "tokens": ["ein", "St\u00fcck\u00b7chen", "B\u00fcr\u00b7ger\u00b7frei\u00b7heit", "\u2013", "kurz", ":", "ein", "Dampf\u00b7ven\u00b7til", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ADJD", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Doch jetzt, im Krieg, schwillt des Geheimrats Weste,", "tokens": ["Doch", "jetzt", ",", "im", "Krieg", ",", "schwillt", "des", "Ge\u00b7heim\u00b7rats", "Wes\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "er liebt die Einfachheit f\u00fcr die Nation,", "tokens": ["er", "liebt", "die", "Ein\u00b7fach\u00b7heit", "f\u00fcr", "die", "Na\u00b7tion", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hilflos spricht er: \u00bbEs ist wohl das beste:", "tokens": ["und", "hil\u00b7flos", "spricht", "er", ":", "\u00bb", "Es", "ist", "wohl", "das", "bes\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$.", "$(", "PPER", "VAFIN", "ADV", "ART", "ADJA", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Volk, Ein Heer, Ein F\u00f6lljetohn.", "tokens": ["Ein", "Volk", ",", "Ein", "Heer", ",", "Ein", "F\u00f6ll\u00b7je\u00b7tohn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Spart nur Papier!\u00ab Doch mit emp\u00f6rter Geste", "tokens": ["Spart", "nur", "Pa\u00b7pier", "!", "\u00ab", "Doch", "mit", "em\u00b7p\u00f6r\u00b7ter", "Ges\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "NN", "$.", "$(", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "erhebt sich br\u00fcsk die Zeitungskonfektion:", "tokens": ["er\u00b7hebt", "sich", "br\u00fcsk", "die", "Zei\u00b7tungs\u00b7kon\u00b7fek\u00b7ti\u00b7on", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "\u00bbder Fortschritt ist bedroht! das Volk! der Staat!\u00ab", "tokens": ["\u00bb", "der", "Fort\u00b7schritt", "ist", "be\u00b7droht", "!", "das", "Volk", "!", "der", "Staat", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dahinter, riesengro\u00df: das Inserat!", "tokens": ["Da\u00b7hin\u00b7ter", ",", "rie\u00b7sen\u00b7gro\u00df", ":", "das", "In\u00b7se\u00b7rat", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "VVFIN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Das ist der deutsche Zustand. Und du, Zeitung,", "tokens": ["Das", "ist", "der", "deut\u00b7sche", "Zu\u00b7stand", ".", "Und", "du", ",", "Zei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "KON", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "du kleener Freiheitshut, wie stehst du da?", "tokens": ["du", "klee\u00b7ner", "Frei\u00b7heits\u00b7hut", ",", "wie", "stehst", "du", "da", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Noch hast du Platz \u2013 zum Beispiel zur Verbreitung", "tokens": ["Noch", "hast", "du", "Platz", "\u2013", "zum", "Bei\u00b7spiel", "zur", "Ver\u00b7brei\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$(", "APPRART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "von Kintopschwatz f\u00fcr ganz Christiania.", "tokens": ["von", "Kin\u00b7top\u00b7schwatz", "f\u00fcr", "ganz", "Chris\u00b7ti\u00b7a\u00b7nia", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADV", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es str\u00f6mt bei Arras. Die Annoncen-Leitung", "tokens": ["Es", "str\u00f6mt", "bei", "Ar\u00b7ras", ".", "Die", "An\u00b7non\u00b7cen\u00b7Lei\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$.", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "pflegt eifrig Gasthaus-Personalia . . .", "tokens": ["pflegt", "eif\u00b7rig", "Gast\u00b7haus\u00b7Per\u00b7so\u00b7na\u00b7lia", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "ADJD", "NE", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ob ihr genug Papier habt oder keins:", "tokens": ["Ob", "ihr", "ge\u00b7nug", "Pa\u00b7pier", "habt", "o\u00b7der", "keins", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "KON", "PIAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ihr helft dem Land nicht!", "tokens": ["Ihr", "helft", "dem", "Land", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Es ist alles eins.", "tokens": ["Es", "ist", "al\u00b7les", "eins", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PIS", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Gewi\u00df \u2013 es ist nicht immer sch\u00f6n gewesen", "tokens": ["Ge\u00b7wi\u00df", "\u2013", "es", "ist", "nicht", "im\u00b7mer", "sch\u00f6n", "ge\u00b7we\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$(", "PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VAPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "das aberwitzige Echo unsrer Zeit:", "tokens": ["das", "a\u00b7berw\u00b7it\u00b7zi\u00b7ge", "E\u00b7cho", "uns\u00b7rer", "Zeit", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "man konnte rechtsrum, konnte linksrum lesen", "tokens": ["man", "konn\u00b7te", "rechts\u00b7rum", ",", "konn\u00b7te", "links\u00b7rum", "le\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VMFIN", "ADV", "$,", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und war zum Schlu\u00df meist ebenso gescheit.", "tokens": ["und", "war", "zum", "Schlu\u00df", "meist", "e\u00b7ben\u00b7so", "ge\u00b7scheit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPRART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Presse schm\u00fcckte stets mit neuen Funkelthesen", "tokens": ["Die", "Pres\u00b7se", "schm\u00fcck\u00b7te", "stets", "mit", "neu\u00b7en", "Fun\u00b7kelt\u00b7he\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ihr Morgen-, Mittags- und ihr Abendkleid . . .", "tokens": ["ihr", "Mor\u00b7gen", ",", "Mit\u00b7tags", "und", "ihr", "A\u00b7bend\u00b7kleid", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["PPOSAT", "TRUNC", "$,", "TRUNC", "KON", "PPOSAT", "NN", "$.", "$.", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und doch: ein Quentchen blieb \u2013 es war nicht viel,", "tokens": ["Und", "doch", ":", "ein", "Quent\u00b7chen", "blieb", "\u2013", "es", "war", "nicht", "viel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "ART", "NN", "VVFIN", "$(", "PPER", "VAFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "ein St\u00fcckchen B\u00fcrgerfreiheit \u2013 kurz: ein Dampfventil.", "tokens": ["ein", "St\u00fcck\u00b7chen", "B\u00fcr\u00b7ger\u00b7frei\u00b7heit", "\u2013", "kurz", ":", "ein", "Dampf\u00b7ven\u00b7til", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$(", "ADJD", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Doch jetzt, im Krieg, schwillt des Geheimrats Weste,", "tokens": ["Doch", "jetzt", ",", "im", "Krieg", ",", "schwillt", "des", "Ge\u00b7heim\u00b7rats", "Wes\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "er liebt die Einfachheit f\u00fcr die Nation,", "tokens": ["er", "liebt", "die", "Ein\u00b7fach\u00b7heit", "f\u00fcr", "die", "Na\u00b7tion", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hilflos spricht er: \u00bbEs ist wohl das beste:", "tokens": ["und", "hil\u00b7flos", "spricht", "er", ":", "\u00bb", "Es", "ist", "wohl", "das", "bes\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$.", "$(", "PPER", "VAFIN", "ADV", "ART", "ADJA", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Volk, Ein Heer, Ein F\u00f6lljetohn.", "tokens": ["Ein", "Volk", ",", "Ein", "Heer", ",", "Ein", "F\u00f6ll\u00b7je\u00b7tohn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Spart nur Papier!\u00ab Doch mit emp\u00f6rter Geste", "tokens": ["Spart", "nur", "Pa\u00b7pier", "!", "\u00ab", "Doch", "mit", "em\u00b7p\u00f6r\u00b7ter", "Ges\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "NN", "$.", "$(", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "erhebt sich br\u00fcsk die Zeitungskonfektion:", "tokens": ["er\u00b7hebt", "sich", "br\u00fcsk", "die", "Zei\u00b7tungs\u00b7kon\u00b7fek\u00b7ti\u00b7on", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "\u00bbder Fortschritt ist bedroht! das Volk! der Staat!\u00ab", "tokens": ["\u00bb", "der", "Fort\u00b7schritt", "ist", "be\u00b7droht", "!", "das", "Volk", "!", "der", "Staat", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "$.", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Dahinter, riesengro\u00df: das Inserat!", "tokens": ["Da\u00b7hin\u00b7ter", ",", "rie\u00b7sen\u00b7gro\u00df", ":", "das", "In\u00b7se\u00b7rat", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "$,", "VVFIN", "$.", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Das ist der deutsche Zustand. Und du, Zeitung,", "tokens": ["Das", "ist", "der", "deut\u00b7sche", "Zu\u00b7stand", ".", "Und", "du", ",", "Zei\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "KON", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "du kleener Freiheitshut, wie stehst du da?", "tokens": ["du", "klee\u00b7ner", "Frei\u00b7heits\u00b7hut", ",", "wie", "stehst", "du", "da", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,", "PWAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Noch hast du Platz \u2013 zum Beispiel zur Verbreitung", "tokens": ["Noch", "hast", "du", "Platz", "\u2013", "zum", "Bei\u00b7spiel", "zur", "Ver\u00b7brei\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$(", "APPRART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "von Kintopschwatz f\u00fcr ganz Christiania.", "tokens": ["von", "Kin\u00b7top\u00b7schwatz", "f\u00fcr", "ganz", "Chris\u00b7ti\u00b7a\u00b7nia", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADV", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es str\u00f6mt bei Arras. Die Annoncen-Leitung", "tokens": ["Es", "str\u00f6mt", "bei", "Ar\u00b7ras", ".", "Die", "An\u00b7non\u00b7cen\u00b7Lei\u00b7tung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "$.", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "pflegt eifrig Gasthaus-Personalia . . .", "tokens": ["pflegt", "eif\u00b7rig", "Gast\u00b7haus\u00b7Per\u00b7so\u00b7na\u00b7lia", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "punct", "punct"], "pos": ["VVFIN", "ADJD", "NE", "$.", "$.", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ob ihr genug Papier habt oder keins:", "tokens": ["Ob", "ihr", "ge\u00b7nug", "Pa\u00b7pier", "habt", "o\u00b7der", "keins", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NN", "VAFIN", "KON", "PIAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ihr helft dem Land nicht!", "tokens": ["Ihr", "helft", "dem", "Land", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.9": {"text": "Es ist alles eins.", "tokens": ["Es", "ist", "al\u00b7les", "eins", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "PIS", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}