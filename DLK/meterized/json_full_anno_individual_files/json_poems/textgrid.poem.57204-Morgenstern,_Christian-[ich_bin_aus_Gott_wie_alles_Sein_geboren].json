{"textgrid.poem.57204": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "[ich bin aus Gott wie alles Sein geboren]", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin aus Gott wie alles Sein geboren,", "tokens": ["Ich", "bin", "aus", "Gott", "wie", "al\u00b7les", "Sein", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KOKOM", "PIS", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich geh im Gott mit allem Mein zu sterben,", "tokens": ["ich", "geh", "im", "Gott", "mit", "al\u00b7lem", "Mein", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "PIS", "PPOSAT", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ich kehre heim, o Gott, als Dein zu leben.", "tokens": ["ich", "keh\u00b7re", "heim", ",", "o", "Gott", ",", "als", "Dein", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "FM", "NN", "$,", "KOUS", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Erst wurde ich aus Deinem Ich gegeben,", "tokens": ["Erst", "wur\u00b7de", "ich", "aus", "Dei\u00b7nem", "Ich", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dann galt es dies Gegebne zu erwerben,", "tokens": ["dann", "galt", "es", "dies", "Ge\u00b7geb\u00b7ne", "zu", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dir als ein Du es Brust an Brust zu heben.", "tokens": ["Dir", "als", "ein", "Du", "es", "Brust", "an", "Brust", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "PPER", "PPER", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Da wollte Stolz es mittendrin verderben,", "tokens": ["Da", "woll\u00b7te", "Stolz", "es", "mit\u00b7ten\u00b7drin", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und es ward Dir, und Du warst ihm verloren ...", "tokens": ["und", "es", "ward", "Dir", ",", "und", "Du", "warst", "ihm", "ver\u00b7lo\u00b7ren", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "$,", "KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bis da\u00df Du \u00fcberm\u00e4chtig mich beschworen!", "tokens": ["Bis", "da\u00df", "Du", "\u00fc\u00b7ber\u00b7m\u00e4ch\u00b7tig", "mich", "be\u00b7schwo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Da ward ich Dir zum andernmal geboren:", "tokens": ["Da", "ward", "ich", "Dir", "zum", "an\u00b7dern\u00b7mal", "ge\u00b7bo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "denn ich verstand zum erstenmal zu sterben,", "tokens": ["denn", "ich", "ver\u00b7stand", "zum", "ers\u00b7ten\u00b7mal", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "denn ich empfand zum erstenmal zu leben.", "tokens": ["denn", "ich", "emp\u00b7fand", "zum", "ers\u00b7ten\u00b7mal", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich bin aus Gott wie alles Sein geboren,", "tokens": ["Ich", "bin", "aus", "Gott", "wie", "al\u00b7les", "Sein", "ge\u00b7bo\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KOKOM", "PIS", "PPOSAT", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "ich geh im Gott mit allem Mein zu sterben,", "tokens": ["ich", "geh", "im", "Gott", "mit", "al\u00b7lem", "Mein", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "APPR", "PIS", "PPOSAT", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "ich kehre heim, o Gott, als Dein zu leben.", "tokens": ["ich", "keh\u00b7re", "heim", ",", "o", "Gott", ",", "als", "Dein", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "FM", "NN", "$,", "KOUS", "PPOSAT", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Erst wurde ich aus Deinem Ich gegeben,", "tokens": ["Erst", "wur\u00b7de", "ich", "aus", "Dei\u00b7nem", "Ich", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "PPOSAT", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "dann galt es dies Gegebne zu erwerben,", "tokens": ["dann", "galt", "es", "dies", "Ge\u00b7geb\u00b7ne", "zu", "er\u00b7wer\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PDS", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dir als ein Du es Brust an Brust zu heben.", "tokens": ["Dir", "als", "ein", "Du", "es", "Brust", "an", "Brust", "zu", "he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "PPER", "PPER", "NN", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Da wollte Stolz es mittendrin verderben,", "tokens": ["Da", "woll\u00b7te", "Stolz", "es", "mit\u00b7ten\u00b7drin", "ver\u00b7der\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und es ward Dir, und Du warst ihm verloren ...", "tokens": ["und", "es", "ward", "Dir", ",", "und", "Du", "warst", "ihm", "ver\u00b7lo\u00b7ren", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "$,", "KON", "PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Bis da\u00df Du \u00fcberm\u00e4chtig mich beschworen!", "tokens": ["Bis", "da\u00df", "Du", "\u00fc\u00b7ber\u00b7m\u00e4ch\u00b7tig", "mich", "be\u00b7schwo\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Da ward ich Dir zum andernmal geboren:", "tokens": ["Da", "ward", "ich", "Dir", "zum", "an\u00b7dern\u00b7mal", "ge\u00b7bo\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPER", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "denn ich verstand zum erstenmal zu sterben,", "tokens": ["denn", "ich", "ver\u00b7stand", "zum", "ers\u00b7ten\u00b7mal", "zu", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "denn ich empfand zum erstenmal zu leben.", "tokens": ["denn", "ich", "emp\u00b7fand", "zum", "ers\u00b7ten\u00b7mal", "zu", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "APPRART", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}