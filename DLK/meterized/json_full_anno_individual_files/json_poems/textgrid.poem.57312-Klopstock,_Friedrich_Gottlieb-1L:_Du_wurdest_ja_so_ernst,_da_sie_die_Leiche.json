{"textgrid.poem.57312": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Du wurdest ja so ernst, da sie die Leiche", "genre": "verse", "period": "N.A.", "pub_year": 1779, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Du wurdest ja so ernst, da sie die Leiche", "tokens": ["Du", "wur\u00b7dest", "ja", "so", "ernst", ",", "da", "sie", "die", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor\u00fcbertrugen;", "tokens": ["Vor\u00b7\u00fc\u00b7bert\u00b7ru\u00b7gen", ";"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "F\u00fcrchtest du den Tod? \u00bbIhn nicht!\u00ab", "tokens": ["F\u00fcrch\u00b7test", "du", "den", "Tod", "?", "\u00bb", "Ihn", "nicht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "$(", "PPER", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcrchtest du denn? \u00bbDas Sterben!\u00ab", "tokens": ["Was", "f\u00fcrch\u00b7test", "du", "denn", "?", "\u00bb", "Das", "Ster\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "$(", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich selbst dieses nicht. \u00bbDu f\u00fcrchtest also nichts?\u00ab", "tokens": ["Ich", "selbst", "die\u00b7ses", "nicht", ".", "\u00bb", "Du", "f\u00fcrch\u00b7test", "al\u00b7so", "nichts", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "PDS", "PTKNEG", "$.", "$(", "PPER", "VVFIN", "ADV", "PIS", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Weh mir, ich f\u00fcrcht', ich f\u00fcrchte. \u00bbBeym Himmel! was?\u00ab", "tokens": ["Weh", "mir", ",", "ich", "f\u00fcrcht'", ",", "ich", "f\u00fcrch\u00b7te", ".", "\u00bb", "Beym", "Him\u00b7mel", "!", "was", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$(", "APPRART", "NN", "$.", "PWS", "$.", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Den Abschied von den Freunden!", "tokens": ["Den", "Ab\u00b7schied", "von", "den", "Freun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und meinen nicht nur, ihren Abschied auch!", "tokens": ["Und", "mei\u00b7nen", "nicht", "nur", ",", "ih\u00b7ren", "Ab\u00b7schied", "auch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$,", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Das war's, dass ich noch ernster als du;", "tokens": ["Das", "wa\u00b7r's", ",", "dass", "ich", "noch", "erns\u00b7ter", "als", "du", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und tiefer in der Seel' es wurde,", "tokens": ["Und", "tie\u00b7fer", "in", "der", "Seel'", "es", "wur\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da sie die Leiche", "tokens": ["Da", "sie", "die", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vor\u00fcbertrugen.", "tokens": ["Vor\u00b7\u00fc\u00b7bert\u00b7ru\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Du wurdest ja so ernst, da sie die Leiche", "tokens": ["Du", "wur\u00b7dest", "ja", "so", "ernst", ",", "da", "sie", "die", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Vor\u00fcbertrugen;", "tokens": ["Vor\u00b7\u00fc\u00b7bert\u00b7ru\u00b7gen", ";"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "F\u00fcrchtest du den Tod? \u00bbIhn nicht!\u00ab", "tokens": ["F\u00fcrch\u00b7test", "du", "den", "Tod", "?", "\u00bb", "Ihn", "nicht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "$(", "PPER", "PTKNEG", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Was f\u00fcrchtest du denn? \u00bbDas Sterben!\u00ab", "tokens": ["Was", "f\u00fcrch\u00b7test", "du", "denn", "?", "\u00bb", "Das", "Ster\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "$(", "ART", "NN", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Ich selbst dieses nicht. \u00bbDu f\u00fcrchtest also nichts?\u00ab", "tokens": ["Ich", "selbst", "die\u00b7ses", "nicht", ".", "\u00bb", "Du", "f\u00fcrch\u00b7test", "al\u00b7so", "nichts", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "PDS", "PTKNEG", "$.", "$(", "PPER", "VVFIN", "ADV", "PIS", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Weh mir, ich f\u00fcrcht', ich f\u00fcrchte. \u00bbBeym Himmel! was?\u00ab", "tokens": ["Weh", "mir", ",", "ich", "f\u00fcrcht'", ",", "ich", "f\u00fcrch\u00b7te", ".", "\u00bb", "Beym", "Him\u00b7mel", "!", "was", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$(", "APPRART", "NN", "$.", "PWS", "$.", "$("], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Den Abschied von den Freunden!", "tokens": ["Den", "Ab\u00b7schied", "von", "den", "Freun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und meinen nicht nur, ihren Abschied auch!", "tokens": ["Und", "mei\u00b7nen", "nicht", "nur", ",", "ih\u00b7ren", "Ab\u00b7schied", "auch", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "$,", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Das war's, dass ich noch ernster als du;", "tokens": ["Das", "wa\u00b7r's", ",", "dass", "ich", "noch", "erns\u00b7ter", "als", "du", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "KOUS", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und tiefer in der Seel' es wurde,", "tokens": ["Und", "tie\u00b7fer", "in", "der", "Seel'", "es", "wur\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da sie die Leiche", "tokens": ["Da", "sie", "die", "Lei\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Vor\u00fcbertrugen.", "tokens": ["Vor\u00b7\u00fc\u00b7bert\u00b7ru\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}}}}