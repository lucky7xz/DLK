{"dta.poem.9268": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Das andere Gespr\u00e4ch.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Schwartzes m\u00e4dgen/ meine freude/", "tokens": ["Schwart\u00b7zes", "m\u00e4d\u00b7gen", "/", "mei\u00b7ne", "freu\u00b7de", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVINF", "$(", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Giebstu deinen willen drein/", "tokens": ["Giebs\u00b7tu", "dei\u00b7nen", "wil\u00b7len", "drein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df wir k\u00fcnfftig alle beyde", "tokens": ["Da\u00df", "wir", "k\u00fcnff\u00b7tig", "al\u00b7le", "bey\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "PIAT", "PIS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollen ohne sorgen seyn/", "tokens": ["Wol\u00b7len", "oh\u00b7ne", "sor\u00b7gen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Nun so la\u00df mich deine wangen", "tokens": ["Nun", "so", "la\u00df", "mich", "dei\u00b7ne", "wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVIMP", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "In der schwartzen zier umfangen.", "tokens": ["In", "der", "schwart\u00b7zen", "zier", "um\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "2. Zwar du trauest meinem hertzen", "tokens": ["Zwar", "du", "trau\u00b7est", "mei\u00b7nem", "hert\u00b7zen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Keine solche freundschafft zu/", "tokens": ["Kei\u00b7ne", "sol\u00b7che", "freund\u00b7schafft", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIAT", "NN", "PTKZU", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und es heist/ ich will nur schertzen/", "tokens": ["Und", "es", "heist", "/", "ich", "will", "nur", "schert\u00b7zen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$(", "PPER", "VMFIN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn ich noch so freundlich thu;", "tokens": ["Wenn", "ich", "noch", "so", "freund\u00b7lich", "thu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So hab ich mein gut gewissen", "tokens": ["So", "hab", "ich", "mein", "gut", "ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJD", "VAPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nur mit hoffnung speisen m\u00fcssen.", "tokens": ["Nur", "mit", "hoff\u00b7nung", "spei\u00b7sen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "3. Doch mein liebgen werde munter/", "tokens": ["Doch", "mein", "lieb\u00b7gen", "wer\u00b7de", "mun\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "VVINF", "VAFIN", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und erfreue meinen muth/", "tokens": ["Und", "er\u00b7freu\u00b7e", "mei\u00b7nen", "muth", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bistu gleich was schwartz mit unter:", "tokens": ["Bis\u00b7tu", "gleich", "was", "schwartz", "mit", "un\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PWS", "ADJD", "APPR", "APPR", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schwartze kirschen schmecken gut/", "tokens": ["Schwart\u00b7ze", "kir\u00b7schen", "schme\u00b7cken", "gut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VVFIN", "ADJD", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und nach ihren schwartzen zweigen", "tokens": ["Und", "nach", "ih\u00b7ren", "schwart\u00b7zen", "zwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Pflegt man treflich hoch zu steigen.", "tokens": ["Pflegt", "man", "tref\u00b7lich", "hoch", "zu", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "ADJD", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "4. Mir belieben die rosinen/", "tokens": ["Mir", "be\u00b7lie\u00b7ben", "die", "ro\u00b7si\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche schwartz und kleine sind/", "tokens": ["Wel\u00b7che", "schwartz", "und", "klei\u00b7ne", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "NN", "KON", "ADJA", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Heidelbeeren weil sie gr\u00fcnen/", "tokens": ["Hei\u00b7del\u00b7bee\u00b7ren", "weil", "sie", "gr\u00fc\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KOUS", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sucht und pfl\u00fcckt man nicht geschwind:", "tokens": ["Sucht", "und", "pfl\u00fcckt", "man", "nicht", "ge\u00b7schwind", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "PIS", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber wenn sie sich verf\u00e4rben/", "tokens": ["A\u00b7ber", "wenn", "sie", "sich", "ver\u00b7f\u00e4r\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hohlt man sie zu gantzen k\u00f6rben.", "tokens": ["Hohlt", "man", "sie", "zu", "gant\u00b7zen", "k\u00f6r\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKZU", "VVINF", "VMINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "5. Schwartze dinte schreibt am besten/", "tokens": ["Schwart\u00b7ze", "din\u00b7te", "schreibt", "am", "bes\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PTKA", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwartzes ehrt man allezeit/", "tokens": ["Schwart\u00b7zes", "ehrt", "man", "al\u00b7le\u00b7zeit", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "ADV", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "An den allerh\u00f6chsten Festen", "tokens": ["An", "den", "al\u00b7ler\u00b7h\u00f6chs\u00b7ten", "Fes\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Tr\u00e4gt man nur ein schwartzes kleid.", "tokens": ["Tr\u00e4gt", "man", "nur", "ein", "schwart\u00b7zes", "kleid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer auch will ein Raths-herr heissen/", "tokens": ["Wer", "auch", "will", "ein", "Raths\u00b7herr", "heis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VMFIN", "ART", "NN", "VVINF", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Mu\u00df sich nur auf schwartz befleissen.", "tokens": ["Mu\u00df", "sich", "nur", "auf", "schwartz", "be\u00b7fleis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ADV", "APPR", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "6. Schwartze farbe wird uns n\u00fctze/", "tokens": ["Schwart\u00b7ze", "far\u00b7be", "wird", "uns", "n\u00fct\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wo man leid und freude stifft:", "tokens": ["Wo", "man", "leid", "und", "freu\u00b7de", "stifft", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADJD", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das ist auch der beste sch\u00fctze/", "tokens": ["Das", "ist", "auch", "der", "bes\u00b7te", "sch\u00fct\u00b7ze", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "VVFIN", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Welcher in das schwartze trifft/", "tokens": ["Wel\u00b7cher", "in", "das", "schwart\u00b7ze", "trifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAT", "APPR", "ART", "ADJA", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und ich wei\u00df nicht was ich wolte/", "tokens": ["Und", "ich", "wei\u00df", "nicht", "was", "ich", "wol\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "PWS", "PPER", "VMFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn ichs hier auch treffen solte.", "tokens": ["Wenn", "ichs", "hier", "auch", "tref\u00b7fen", "sol\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "7. Nun mein angenehmes Schw\u00e4rtzgen/", "tokens": ["Nun", "mein", "an\u00b7ge\u00b7neh\u00b7mes", "Schw\u00e4rtz\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich verbleibe dir getreu.", "tokens": ["Ich", "ver\u00b7blei\u00b7be", "dir", "ge\u00b7treu", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bleib du nur mein liebstes hertzgen/", "tokens": ["Bleib", "du", "nur", "mein", "liebs\u00b7tes", "hertz\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und la\u00df mich hinfort dabey/", "tokens": ["Und", "la\u00df", "mich", "hin\u00b7fort", "da\u00b7bey", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "ADV", "PAV", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Da\u00df ich in der schwartzen erde", "tokens": ["Da\u00df", "ich", "in", "der", "schwart\u00b7zen", "er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Fortgepflantzt und fruchtbar werde.", "tokens": ["Fort\u00b7ge\u00b7pflantzt", "und", "frucht\u00b7bar", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}