{"dta.poem.4421": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  Der Geruch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1727", "urn": "urn:nbn:de:kobv:b4-200905198599", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Nach Erforschen, Sehn und Achten", "tokens": ["Nach", "Er\u00b7for\u00b7schen", ",", "Sehn", "und", "Ach\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "VVFIN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf der Augen Trefflichkeit,", "tokens": ["Auf", "der", "Au\u00b7gen", "Treff\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wollen wir nun auch betrachten", "tokens": ["Wol\u00b7len", "wir", "nun", "auch", "be\u00b7trach\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Geruchs Beschaffenheit;", "tokens": ["Des", "Ge\u00b7ruchs", "Be\u00b7schaf\u00b7fen\u00b7heit", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Worin, wenn wir ihn ergr\u00fcnden,", "tokens": ["Wo\u00b7rin", ",", "wenn", "wir", "ihn", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "KOUS", "PPER", "PPER", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wir nicht minder Wunder finden,", "tokens": ["Wir", "nicht", "min\u00b7der", "Wun\u00b7der", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Weil auch den kein Witz, kein Flei\u00df", "tokens": ["Weil", "auch", "den", "kein", "Witz", ",", "kein", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ADV", "ART", "PIAT", "NN", "$,", "PIAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Fasst und zu begreifen wei\u00df.", "tokens": ["Fasst", "und", "zu", "be\u00b7grei\u00b7fen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "An der Augen rege Spiegel", "tokens": ["An", "der", "Au\u00b7gen", "re\u00b7ge", "Spie\u00b7gel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Grenzt und teil\u2019t der Wangen Feld", "tokens": ["Grenzt", "und", "teil't", "der", "Wan\u00b7gen", "Feld"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "KON", "VVFIN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ein erhab\u2019ner kleiner H\u00fcgel.", "tokens": ["Ein", "er\u00b7hab'\u00b7ner", "klei\u00b7ner", "H\u00fc\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieser, wie ein Pfeiler, h\u00e4lt", "tokens": ["Die\u00b7ser", ",", "wie", "ein", "Pfei\u00b7ler", ",", "h\u00e4lt"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PDS", "$,", "PWAV", "ART", "NN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Die gew\u00f6lbten Augenbrauen:", "tokens": ["Die", "ge\u00b7w\u00f6lb\u00b7ten", "Au\u00b7gen\u00b7brau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hier kann man zween Wege schauen:", "tokens": ["Hier", "kann", "man", "zween", "We\u00b7ge", "schau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "VVFIN", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Dadurch drenget durch die Stirn", "tokens": ["Da\u00b7durch", "dren\u00b7get", "durch", "die", "Stirn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "APPR", "ART", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.8": {"text": "Der Geruch sich ins Gehirn.", "tokens": ["Der", "Ge\u00b7ruch", "sich", "ins", "Ge\u00b7hirn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Halb von Knorpel, halb von Knochen", "tokens": ["Halb", "von", "Knor\u00b7pel", ",", "halb", "von", "Kno\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "APPR", "NE", "$,", "ADJD", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist die Nase zugericht\u2019t,", "tokens": ["Ist", "die", "Na\u00b7se", "zu\u00b7ge\u00b7richt't", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df sie, w\u00e4r sie leicht gebrochen,", "tokens": ["Da\u00df", "sie", ",", "w\u00e4r", "sie", "leicht", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht verstellte das Gesicht.", "tokens": ["Nicht", "ver\u00b7stell\u00b7te", "das", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Doppelt sind die off\u2019nen Th\u00fcren,", "tokens": ["Dop\u00b7pelt", "sind", "die", "off'\u00b7nen", "Th\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Den Geruch nicht zu verlieren,", "tokens": ["Den", "Ge\u00b7ruch", "nicht", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn vom Schleim von ungefehr", "tokens": ["Wenn", "vom", "Schleim", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "APPR", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Eine wo verstopfet w\u00e4r.", "tokens": ["Ei\u00b7ne", "wo", "ver\u00b7stop\u00b7fet", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PWAV", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ferner dienen diese R\u00f6ren,", "tokens": ["Fer\u00b7ner", "die\u00b7nen", "die\u00b7se", "R\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die zu zarte Feuchtigkeit", "tokens": ["Die", "zu", "zar\u00b7te", "Feuch\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PTKZU", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Des Gehirnes auszuleeren;", "tokens": ["Des", "Ge\u00b7hir\u00b7nes", "aus\u00b7zu\u00b7lee\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ja noch gr\u00f6ss\u2019re Nutzbarkeit", "tokens": ["Ja", "noch", "gr\u00f6ss'\u00b7re", "Nutz\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sp\u00fcr\u2019t man von dem Athem-ziehen,", "tokens": ["Sp\u00fcr't", "man", "von", "dem", "A\u00b7them\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wenn durch der Natur Bem\u00fchen", "tokens": ["Wenn", "durch", "der", "Na\u00b7tur", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Luft durch ihre R\u00f6ren f\u00e4hrt,", "tokens": ["Luft", "durch", "ih\u00b7re", "R\u00f6\u00b7ren", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Und dadurch die Lunge n\u00e4hrt.", "tokens": ["Und", "da\u00b7durch", "die", "Lun\u00b7ge", "n\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}}, "stanza.5": {"line.1": {"text": "Wo nicht Luft ist, riecht man nimmer.", "tokens": ["Wo", "nicht", "Luft", "ist", ",", "riecht", "man", "nim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "NN", "VAFIN", "$,", "VVFIN", "PIS", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche Weisheit! darum steht", "tokens": ["Wel\u00b7che", "Weis\u00b7heit", "!", "da\u00b7rum", "steht"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAT", "NN", "$.", "PAV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Geruch da, wo fast immer", "tokens": ["Der", "Ge\u00b7ruch", "da", ",", "wo", "fast", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "PWAV", "ADV", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Luft im Athem in uns geht.", "tokens": ["Luft", "im", "A\u00b7them", "in", "uns", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Um die Eigenschaft der Speisen", "tokens": ["Um", "die", "Ei\u00b7gen\u00b7schaft", "der", "Spei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "ART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Auch zugleich mit anzuweisen,", "tokens": ["Auch", "zu\u00b7gleich", "mit", "an\u00b7zu\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Naht der Mund der Nase sich,", "tokens": ["Naht", "der", "Mund", "der", "Na\u00b7se", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "NN", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Welches recht verwunderlich.", "tokens": ["Wel\u00b7ches", "recht", "ver\u00b7wun\u00b7der\u00b7lich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn der Speise Lieblichkeiten", "tokens": ["Wenn", "der", "Spei\u00b7se", "Lieb\u00b7lich\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Uns\u2019re Zung\u2019 erst r\u00fchren mu\u00df,", "tokens": ["Un\u00b7s'\u00b7re", "Zung'", "erst", "r\u00fch\u00b7ren", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat man im Geruch von weiten", "tokens": ["Hat", "man", "im", "Ge\u00b7ruch", "von", "wei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "APPRART", "NN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Schon von C\u00f6rpern den Genu\u00df.", "tokens": ["Schon", "von", "C\u00f6r\u00b7pern", "den", "Ge\u00b7nu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Schicken in Provence Kr\u00e4uter", "tokens": ["Schi\u00b7cken", "in", "Pro\u00b7ven\u00b7ce", "Kr\u00e4u\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPR", "NE", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Zwanzig Meilen, ja noch weiter,", "tokens": ["Zwan\u00b7zig", "Mei\u00b7len", ",", "ja", "noch", "wei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$,", "ADV", "ADV", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Jhren Dufts-Geruch in\u2019s Meer", "tokens": ["Ih\u00b7ren", "Duft\u00b7sGe\u00b7ruch", "in's", "Meer"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nicht von ihren K\u00fcsten her?", "tokens": ["Nicht", "von", "ih\u00b7ren", "K\u00fcs\u00b7ten", "her", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie sich der Geschmack entdecket", "tokens": ["Wie", "sich", "der", "Ge\u00b7schmack", "ent\u00b7de\u00b7cket"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PRF", "ART", "NN", "VVFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Mehr, wenn man die C\u00f6rper teilt;", "tokens": ["Mehr", ",", "wenn", "man", "die", "C\u00f6r\u00b7per", "teilt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Also was in C\u00f6rpern stecket,", "tokens": ["Al\u00b7so", "was", "in", "C\u00f6r\u00b7pern", "ste\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "APPR", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches riecht, wird eh\u2019 ereilt", "tokens": ["Wel\u00b7ches", "riecht", ",", "wird", "eh'", "er\u00b7eilt"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "VAFIN", "ADJD", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und durch den Geruch empfunden,", "tokens": ["Und", "durch", "den", "Ge\u00b7ruch", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wenns durch Reiben ist entbunden,", "tokens": ["Wenns", "durch", "Rei\u00b7ben", "ist", "ent\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und beweget wird: den Brauch", "tokens": ["Und", "be\u00b7we\u00b7get", "wird", ":", "den", "Brauch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "VAFIN", "$.", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mehren W\u00e4rm\u2019 und Feuer auch.", "tokens": ["Meh\u00b7ren", "W\u00e4rm'", "und", "Feu\u00b7er", "auch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Ein zu heftiges Bewegen,", "tokens": ["Ein", "zu", "hef\u00b7ti\u00b7ges", "Be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auch die K\u00e4lt\u2019 und Feuchtigkeit", "tokens": ["Auch", "die", "K\u00e4lt'", "und", "Feuch\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Hindern den Geruch: hingegen", "tokens": ["Hin\u00b7dern", "den", "Ge\u00b7ruch", ":", "hin\u00b7ge\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "$.", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Macht der Bluhmen Lieblichkeit", "tokens": ["Macht", "der", "Bluh\u00b7men", "Lieb\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Uns bey aufgekl\u00e4r\u2019ten Tagen", "tokens": ["Uns", "bey", "auf\u00b7ge\u00b7kl\u00e4r'\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ein weit gr\u00f6sseres Behagen,", "tokens": ["Ein", "weit", "gr\u00f6s\u00b7se\u00b7res", "Be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "Als wenns Wetter kalt und feucht.", "tokens": ["Als", "wenns", "Wet\u00b7ter", "kalt", "und", "feucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "NN", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Man versp\u00fcr\u2019t sie dann nicht leicht.", "tokens": ["Man", "ver\u00b7sp\u00fcr't", "sie", "dann", "nicht", "leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Ueber alle diese Kr\u00e4fte", "tokens": ["Ue\u00b7ber", "al\u00b7le", "die\u00b7se", "Kr\u00e4f\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIS", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist in ihr die gr\u00f6ste Kraft,", "tokens": ["Ist", "in", "ihr", "die", "gr\u00f6s\u00b7te", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ihr n\u00fctzlichstes Gesch\u00e4ffte", "tokens": ["Und", "ihr", "n\u00fctz\u00b7lichs\u00b7tes", "Ge\u00b7sch\u00e4ff\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Geruches Eigenschaft;", "tokens": ["Des", "Ge\u00b7ru\u00b7ches", "Ei\u00b7gen\u00b7schaft", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wodurch sie aus allen Dingen", "tokens": ["Wo\u00b7durch", "sie", "aus", "al\u00b7len", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Wei\u00df den Geist heraus zu bringen,", "tokens": ["Wei\u00df", "den", "Geist", "he\u00b7raus", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Den, so bald sie ihn versp\u00fcr\u2019t,", "tokens": ["Den", ",", "so", "bald", "sie", "ihn", "ver\u00b7sp\u00fcr't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "ADV", "PPER", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sie nach dem Gehirne f\u00fchrt.", "tokens": ["Sie", "nach", "dem", "Ge\u00b7hir\u00b7ne", "f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Massen denn die innern Teile", "tokens": ["Mas\u00b7sen", "denn", "die", "in\u00b7nern", "Tei\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wunderbarlich zugericht\u2019t:", "tokens": ["Wun\u00b7der\u00b7bar\u00b7lich", "zu\u00b7ge\u00b7richt't", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df nicht in zuschneller Eile", "tokens": ["Da\u00df", "nicht", "in", "zu\u00b7schnel\u00b7ler", "Ei\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dampf und Luft das Hirn vernicht\u2019t;", "tokens": ["Dampf", "und", "Luft", "das", "Hirn", "ver\u00b7nicht't", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Mu\u00df, was ins Gehirn will dringen,", "tokens": ["Mu\u00df", ",", "was", "ins", "Ge\u00b7hirn", "will", "drin\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "PRELS", "APPRART", "NN", "VMFIN", "VVINF", "$,"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "Durch ein Sieb vorher sich zwingen,", "tokens": ["Durch", "ein", "Sieb", "vor\u00b7her", "sich", "zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Welches hier an diesem Ort", "tokens": ["Wel\u00b7ches", "hier", "an", "die\u00b7sem", "Ort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit viel L\u00f6chern durchgebohrt.", "tokens": ["Mit", "viel", "L\u00f6\u00b7chern", "durch\u00b7ge\u00b7bohrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ferner mu\u00df die Luft gebrochen", "tokens": ["Fer\u00b7ner", "mu\u00df", "die", "Luft", "ge\u00b7bro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "ART", "NN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch ein schwammigt Wesen gehn,", "tokens": ["Durch", "ein", "schwam\u00b7migt", "We\u00b7sen", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches denn an diesen Knochen", "tokens": ["Wel\u00b7ches", "denn", "an", "die\u00b7sen", "Kno\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "APPR", "PDAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit Verwund\u2019rung anzusehn.", "tokens": ["Mit", "Ver\u00b7wun\u00b7d'\u00b7rung", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVIZU", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.5": {"text": "Hier in diesen kleinen G\u00e4ngen", "tokens": ["Hier", "in", "die\u00b7sen", "klei\u00b7nen", "G\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da sich Geist und Luft durchdrengen,", "tokens": ["Da", "sich", "Geist", "und", "Luft", "durch\u00b7dren\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wird die Luft, die hier gebracht,", "tokens": ["Wird", "die", "Luft", ",", "die", "hier", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Zum Geruch geschickt gemacht.", "tokens": ["Zum", "Ge\u00b7ruch", "ge\u00b7schickt", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Welche drauf durch zweene Strassen,", "tokens": ["Wel\u00b7che", "drauf", "durch", "zwee\u00b7ne", "Stras\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PAV", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die vom z\u00e4rt\u2019sten Fleisch formir\u2019t,", "tokens": ["Die", "vom", "z\u00e4rt'\u00b7sten", "Fleisch", "for\u00b7mir't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und sich nimmer sp\u00e4rren lassen,", "tokens": ["Und", "sich", "nim\u00b7mer", "sp\u00e4r\u00b7ren", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "VVINF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ganz wird ins Gehirn gef\u00fchr\u2019t.", "tokens": ["Ganz", "wird", "ins", "Ge\u00b7hirn", "ge\u00b7f\u00fchr'", "t."], "token_info": ["word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "NE", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Hier nun wirk\u2019t die Kraft der Selen,", "tokens": ["Hier", "nun", "wirk't", "die", "Kraft", "der", "Se\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Abzusondern und zu w\u00e4len", "tokens": ["Ab\u00b7zu\u00b7son\u00b7dern", "und", "zu", "w\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "PTKZU", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Das, was sie f\u00fcr sch\u00e4dlich h\u00e4lt,", "tokens": ["Das", ",", "was", "sie", "f\u00fcr", "sch\u00e4d\u00b7lich", "h\u00e4lt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "PPER", "APPR", "ADJD", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Von dem, was ihr wol gef\u00e4llt.", "tokens": ["Von", "dem", ",", "was", "ihr", "wol", "ge\u00b7f\u00e4llt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PWS", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Wer kann unbewundert lassen,", "tokens": ["Wer", "kann", "un\u00b7be\u00b7wun\u00b7dert", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da die Nasen-L\u00f6cher sind", "tokens": ["Da", "die", "Na\u00b7sen\u00b7L\u00f6\u00b7cher", "sind"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VAFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unten weit, mehr Luft zu fassen,", "tokens": ["Un\u00b7ten", "weit", ",", "mehr", "Luft", "zu", "fas\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie man es bey allen find\u2019t,", "tokens": ["Wie", "man", "es", "bey", "al\u00b7len", "find't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "APPR", "PIS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oben aber schmal und enge,", "tokens": ["O\u00b7ben", "a\u00b7ber", "schmal", "und", "en\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KON", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df der Duft durch ein Gedrenge,", "tokens": ["Da\u00df", "der", "Duft", "durch", "ein", "Ge\u00b7dren\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Als durch einen sanften Schlag,", "tokens": ["Als", "durch", "ei\u00b7nen", "sanf\u00b7ten", "Schlag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Mehr das Nervgen r\u00fchren mag?", "tokens": ["Mehr", "das", "Nerv\u00b7gen", "r\u00fch\u00b7ren", "mag", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ferner ist noch zu erw\u00e4gen,", "tokens": ["Fer\u00b7ner", "ist", "noch", "zu", "er\u00b7w\u00e4\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welche Tugend, welche Kraft", "tokens": ["Wel\u00b7che", "Tu\u00b7gend", ",", "wel\u00b7che", "Kraft"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWAT", "NN", "$,", "PWAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Unterschied\u2019ne C\u00f6rper hegen,", "tokens": ["Un\u00b7ter\u00b7schie\u00b7d'\u00b7ne", "C\u00f6r\u00b7per", "he\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Deren selten\u2019 Eigenschaft", "tokens": ["De\u00b7ren", "sel\u00b7ten'", "Ei\u00b7gen\u00b7schaft"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Stets die Luft, die sie umh\u00fcllet,", "tokens": ["Stets", "die", "Luft", ",", "die", "sie", "um\u00b7h\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mit Geruch und D\u00fcnsten f\u00fcllet,", "tokens": ["Mit", "Ge\u00b7ruch", "und", "D\u00fcns\u00b7ten", "f\u00fcl\u00b7let", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die sie recht, als wenn es raucht,", "tokens": ["Die", "sie", "recht", ",", "als", "wenn", "es", "raucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Doch unsichtbar, von sich haucht.", "tokens": ["Doch", "un\u00b7sicht\u00b7bar", ",", "von", "sich", "haucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "PRF", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Da\u00df nun von verschied\u2019nen Dingen", "tokens": ["Da\u00df", "nun", "von", "ver\u00b7schie\u00b7d'\u00b7nen", "Din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.2": {"text": "Der Geruch sich nie verzehr\u2019t,", "tokens": ["Der", "Ge\u00b7ruch", "sich", "nie", "ver\u00b7zehr't", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADV", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern stetig D\u00fcnste dringen,", "tokens": ["Son\u00b7dern", "ste\u00b7tig", "D\u00fcns\u00b7te", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist wol recht Bewunderns wehrt.", "tokens": ["Ist", "wol", "recht", "Be\u00b7wun\u00b7derns", "wehrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sassafra\u00df kann nach viel Jahren", "tokens": ["Sas\u00b7sa\u00b7fra\u00df", "kann", "nach", "viel", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Diese Kr\u00e4fte noch bewahren,", "tokens": ["Die\u00b7se", "Kr\u00e4f\u00b7te", "noch", "be\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "ADV", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df, wenn man ihn gleich nicht r\u00fchr\u2019t,", "tokens": ["Da\u00df", ",", "wenn", "man", "ihn", "gleich", "nicht", "r\u00fchr't", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PIS", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "Man ihn doch von ferne sp\u00fcr\u2019t.", "tokens": ["Man", "ihn", "doch", "von", "fer\u00b7ne", "sp\u00fcr'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PIS", "PPER", "ADV", "APPR", "ADV", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Ein Beweistum l\u00e4sst sich h\u00f6ren,", "tokens": ["Ein", "Be\u00b7wei\u00b7stum", "l\u00e4sst", "sich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Warum nicht der Dunst verfleucht,", "tokens": ["Wa\u00b7rum", "nicht", "der", "Dunst", "ver\u00b7fleucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ob\u2019s vielleicht durch eig\u2019ne R\u00f6ren", "tokens": ["Ob's", "viel\u00b7leicht", "durch", "eig'\u00b7ne", "R\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stets Luft wieder an sich zeucht,", "tokens": ["Stets", "Luft", "wie\u00b7der", "an", "sich", "zeucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und durch and\u2019re von sich treibet,", "tokens": ["Und", "durch", "an\u00b7d'\u00b7re", "von", "sich", "trei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Weil dieselbe Schwere bleibet,", "tokens": ["Weil", "die\u00b7sel\u00b7be", "Schwe\u00b7re", "blei\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wenn, wie lang\u2019 es immer liegt,", "tokens": ["Wenn", ",", "wie", "lang'", "es", "im\u00b7mer", "liegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Man dasselbe wieder wiegt.", "tokens": ["Man", "das\u00b7sel\u00b7be", "wie\u00b7der", "wiegt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Oder, ob auf selbe Weise", "tokens": ["O\u00b7der", ",", "ob", "auf", "sel\u00b7be", "Wei\u00b7se"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUS", "APPR", "ADJA", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Dieser strenge Dunst vielleicht", "tokens": ["Die\u00b7ser", "stren\u00b7ge", "Dunst", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Allezeit in einem Kreise", "tokens": ["Al\u00b7le\u00b7zeit", "in", "ei\u00b7nem", "Krei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um den eig\u2019nen C\u00f6rper fleucht;", "tokens": ["Um", "den", "eig'\u00b7nen", "C\u00f6r\u00b7per", "fleucht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Oder ob man k\u00f6nn\u2019 erzwingen,", "tokens": ["O\u00b7der", "ob", "man", "k\u00f6nn'", "er\u00b7zwin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Da\u00df der Stoff von allen Dingen,", "tokens": ["Da\u00df", "der", "Stoff", "von", "al\u00b7len", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "PIAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Also auch der Specerey,", "tokens": ["Al\u00b7so", "auch", "der", "Spe\u00b7ce\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ganz unendlich teilbar sey.", "tokens": ["Ganz", "un\u00b7end\u00b7lich", "teil\u00b7bar", "sey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJD", "VAFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Da\u00df nun manches s\u00fc\u00df und sauer,", "tokens": ["Da\u00df", "nun", "man\u00b7ches", "s\u00fc\u00df", "und", "sau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Widrig, lieblich, stark und schwach,", "tokens": ["Wid\u00b7rig", ",", "lieb\u00b7lich", ",", "stark", "und", "schwach", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fl\u00fcchtig und von langer Dauer,", "tokens": ["Fl\u00fcch\u00b7tig", "und", "von", "lan\u00b7ger", "Dau\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Kommt, der meisten Meinung nach,", "tokens": ["Kommt", ",", "der", "meis\u00b7ten", "Mei\u00b7nung", "nach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "PIAT", "NN", "APPR", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Von der C\u00f6rperchen Figuren.", "tokens": ["Von", "der", "C\u00f6r\u00b7per\u00b7chen", "Fi\u00b7gu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Denn was rund, l\u00e4ss\u2019t and\u2019re Spuren", "tokens": ["Denn", "was", "rund", ",", "l\u00e4ss't", "an\u00b7d'\u00b7re", "Spu\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "ADJD", "$,", "VVFIN", "ADJA", "NN"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "In der schwach beweg\u2019ten Luft,", "tokens": ["In", "der", "schwach", "be\u00b7weg'\u00b7ten", "Luft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Als ein mehr gespitzter Duft.", "tokens": ["Als", "ein", "mehr", "ge\u00b7spitz\u00b7ter", "Duft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PIAT", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Alle Wunder zu entdecken,", "tokens": ["Al\u00b7le", "Wun\u00b7der", "zu", "ent\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle Kr\u00e4ft\u2019 und Seltenheit,", "tokens": ["Al\u00b7le", "Kr\u00e4ft'", "und", "Sel\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Die in diesem Sinne stecken,", "tokens": ["Die", "in", "die\u00b7sem", "Sin\u00b7ne", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PDAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist wol keine M\u00f6glichkeit.", "tokens": ["Ist", "wol", "kei\u00b7ne", "M\u00f6g\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wer kann doch die Kraft verstehen,", "tokens": ["Wer", "kann", "doch", "die", "Kraft", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "So wir an den Hunden sehen,", "tokens": ["So", "wir", "an", "den", "Hun\u00b7den", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Die uns durch die Nas\u2019 allein", "tokens": ["Die", "uns", "durch", "die", "Nas'", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wunderw\u00fcrdig n\u00fctzlich seyn?", "tokens": ["Wun\u00b7der\u00b7w\u00fcr\u00b7dig", "n\u00fctz\u00b7lich", "seyn", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Da\u00df wir riechen, doch mit Massen,", "tokens": ["Da\u00df", "wir", "rie\u00b7chen", ",", "doch", "mit", "Mas\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein Wunder. Sollte man", "tokens": ["Ist", "ein", "Wun\u00b7der", ".", "Soll\u00b7te", "man"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "ART", "NN", "$.", "VMFIN", "PIS"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Alle D\u00fcnste sch\u00e4rfer fassen,", "tokens": ["Al\u00b7le", "D\u00fcns\u00b7te", "sch\u00e4r\u00b7fer", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die man itzt nicht sp\u00fcren kann;", "tokens": ["Die", "man", "itzt", "nicht", "sp\u00fc\u00b7ren", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "W\u00fcrden so viel tausend Sachen", "tokens": ["W\u00fcr\u00b7den", "so", "viel", "tau\u00b7send", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "CARD", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Uns Verdru\u00df und Eckel machen,", "tokens": ["Uns", "Ver\u00b7dru\u00df", "und", "E\u00b7ckel", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Deren Dampf uns itzt nicht r\u00fchr\u2019t,", "tokens": ["De\u00b7ren", "Dampf", "uns", "itzt", "nicht", "r\u00fchr't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "PPER", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Weil man gar zu scharf nicht sp\u00fcr\u2019t.", "tokens": ["Weil", "man", "gar", "zu", "scharf", "nicht", "sp\u00fcr'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PIS", "ADV", "PTKA", "ADJD", "PTKNEG", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Welchen Nutzen in dem Leben", "tokens": ["Wel\u00b7chen", "Nut\u00b7zen", "in", "dem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bringet der Geruch uns nicht?", "tokens": ["Brin\u00b7get", "der", "Ge\u00b7ruch", "uns", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Will sich eine Brunst erheben;", "tokens": ["Will", "sich", "ei\u00b7ne", "Brunst", "er\u00b7he\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nutz\u2019t er mehr, als das Gesicht.", "tokens": ["Nutz't", "er", "mehr", ",", "als", "das", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Manche Gluht w\u00e4r\u2019 ausgebrochen,", "tokens": ["Man\u00b7che", "Gluht", "w\u00e4r'", "aus\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "H\u00e4tte man sie nicht gerochen,", "tokens": ["H\u00e4t\u00b7te", "man", "sie", "nicht", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Und zu recht dem Feu\u2019r gewehr\u2019t,", "tokens": ["Und", "zu", "recht", "dem", "Feu'r", "ge\u00b7wehr't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKA", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Das sonst Hab\u2019 und Gut verzehr\u2019t.", "tokens": ["Das", "sonst", "Hab'", "und", "Gut", "ver\u00b7zehr'", "t."], "token_info": ["word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PDS", "ADV", "NN", "KON", "ADJD", "VVFIN", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "So viel hundert tausend Bluhmen,", "tokens": ["So", "viel", "hun\u00b7dert", "tau\u00b7send", "Bluh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "CARD", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "So viel s\u00fcsse Specerey,", "tokens": ["So", "viel", "s\u00fcs\u00b7se", "Spe\u00b7ce\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Was in Indien, Jdumen", "tokens": ["Was", "in", "In\u00b7di\u00b7en", ",", "Jdu\u00b7men"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PWS", "APPR", "NE", "$,", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "W\u00e4chst und in der Barbarey,", "tokens": ["W\u00e4chst", "und", "in", "der", "Bar\u00b7ba\u00b7rey", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "K\u00f6nnte kein Gesch\u00f6pf gebrauchen,", "tokens": ["K\u00f6nn\u00b7te", "kein", "Ge\u00b7sch\u00f6pf", "ge\u00b7brau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und m\u00fcst\u2019, ohne Nutz, verrauchen,", "tokens": ["Und", "m\u00fcst'", ",", "oh\u00b7ne", "Nutz", ",", "ver\u00b7rau\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUI", "NN", "$,", "VVFIN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "W\u00e4r die Nase nicht geschickt,", "tokens": ["W\u00e4r", "die", "Na\u00b7se", "nicht", "ge\u00b7schickt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df sie sich dadurch erqvickt.", "tokens": ["Da\u00df", "sie", "sich", "da\u00b7durch", "er\u00b7qvickt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PAV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Sprich, verwildertes Gem\u00fcte,", "tokens": ["Sprich", ",", "ver\u00b7wil\u00b7der\u00b7tes", "Ge\u00b7m\u00fc\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Kommt die\u00df wol von ungefehr,", "tokens": ["Kommt", "die\u00df", "wol", "von", "un\u00b7ge\u00b7fehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "ADV", "APPR", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Oder aus der Macht und G\u00fcte", "tokens": ["O\u00b7der", "aus", "der", "Macht", "und", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines weisen Wesens her?", "tokens": ["Ei\u00b7nes", "wei\u00b7sen", "We\u00b7sens", "her", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sprich: verdienen solche Werke", "tokens": ["Sprich", ":", "ver\u00b7die\u00b7nen", "sol\u00b7che", "Wer\u00b7ke"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["VVIMP", "$.", "VVFIN", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nicht so viel, da\u00df man sie merke?", "tokens": ["Nicht", "so", "viel", ",", "da\u00df", "man", "sie", "mer\u00b7ke", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADV", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Wers Gesch\u00f6pfe nicht betracht\u2019t,", "tokens": ["Wers", "Ge\u00b7sch\u00f6p\u00b7fe", "nicht", "be\u00b7tracht't", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Sch\u00e4ndet seines Sch\u00f6pfers Macht.", "tokens": ["Sch\u00e4n\u00b7det", "sei\u00b7nes", "Sch\u00f6p\u00b7fers", "Macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}