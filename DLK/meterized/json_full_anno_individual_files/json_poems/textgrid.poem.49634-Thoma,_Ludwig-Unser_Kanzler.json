{"textgrid.poem.49634": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Unser Kanzler", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "D\u00fcrres Herz wie d\u00fcrre Beine,", "tokens": ["D\u00fcr\u00b7res", "Herz", "wie", "d\u00fcr\u00b7re", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lang, wie ein Gedankenstrich,", "tokens": ["Lang", ",", "wie", "ein", "Ge\u00b7dan\u00b7ken\u00b7strich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kommen wir mit uns ins reine:", "tokens": ["Kom\u00b7men", "wir", "mit", "uns", "ins", "rei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "APPRART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieser Mann ist f\u00fcrchterlich.", "tokens": ["Die\u00b7ser", "Mann", "ist", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Wie wir seine Art gefunden,", "tokens": ["Wie", "wir", "sei\u00b7ne", "Art", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gilt er uns als Aktenband,", "tokens": ["Gilt", "er", "uns", "als", "Ak\u00b7ten\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "KOUS", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zupetschiert und eingebunden", "tokens": ["Zu\u00b7pet\u00b7schiert", "und", "ein\u00b7ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In Papier und Leinenwand.", "tokens": ["In", "Pa\u00b7pier", "und", "Lei\u00b7nen\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Jedes Auge schwimmt in Tr\u00e4nen,", "tokens": ["Je\u00b7des", "Au\u00b7ge", "schwimmt", "in", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welches diesen Kanzler sieht,", "tokens": ["Wel\u00b7ches", "die\u00b7sen", "Kanz\u00b7ler", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ein ungeheures G\u00e4hnen", "tokens": ["Weil", "ein", "un\u00b7ge\u00b7heu\u00b7res", "G\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Backen aufw\u00e4rts zieht.", "tokens": ["Al\u00b7le", "Ba\u00b7cken", "auf\u00b7w\u00e4rts", "zieht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wenn am Tisch des Bundesrates", "tokens": ["Wenn", "am", "Tisch", "des", "Bun\u00b7des\u00b7ra\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich erhebt der Herr Major,", "tokens": ["Sich", "er\u00b7hebt", "der", "Herr", "Ma\u00b7jor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4lt man sich was Obligates", "tokens": ["H\u00e4lt", "man", "sich", "was", "Ob\u00b7li\u00b7ga\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "PWS", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aufgesperrten M\u00e4ulern vor.", "tokens": ["Auf\u00b7ge\u00b7sperr\u00b7ten", "M\u00e4u\u00b7lern", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Bethmann ist von selten tiefer", "tokens": ["Beth\u00b7mann", "ist", "von", "sel\u00b7ten", "tie\u00b7fer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirkung, wie es jeder sah,", "tokens": ["Wir\u00b7kung", ",", "wie", "es", "je\u00b7der", "sah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Auf des H\u00f6rers Unterkiefer", "tokens": ["Auf", "des", "H\u00f6\u00b7rers", "Un\u00b7ter\u00b7kie\u00b7fer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder auch mandibula.", "tokens": ["O\u00b7der", "auch", "man\u00b7di\u00b7bu\u00b7la", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "D\u00fcrres Herz wie d\u00fcrre Beine,", "tokens": ["D\u00fcr\u00b7res", "Herz", "wie", "d\u00fcr\u00b7re", "Bei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KOKOM", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Lang, wie ein Gedankenstrich,", "tokens": ["Lang", ",", "wie", "ein", "Ge\u00b7dan\u00b7ken\u00b7strich", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kommen wir mit uns ins reine:", "tokens": ["Kom\u00b7men", "wir", "mit", "uns", "ins", "rei\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPER", "APPRART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieser Mann ist f\u00fcrchterlich.", "tokens": ["Die\u00b7ser", "Mann", "ist", "f\u00fcrch\u00b7ter\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wie wir seine Art gefunden,", "tokens": ["Wie", "wir", "sei\u00b7ne", "Art", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gilt er uns als Aktenband,", "tokens": ["Gilt", "er", "uns", "als", "Ak\u00b7ten\u00b7band", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "KOUS", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Zupetschiert und eingebunden", "tokens": ["Zu\u00b7pet\u00b7schiert", "und", "ein\u00b7ge\u00b7bun\u00b7den"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In Papier und Leinenwand.", "tokens": ["In", "Pa\u00b7pier", "und", "Lei\u00b7nen\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Jedes Auge schwimmt in Tr\u00e4nen,", "tokens": ["Je\u00b7des", "Au\u00b7ge", "schwimmt", "in", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Welches diesen Kanzler sieht,", "tokens": ["Wel\u00b7ches", "die\u00b7sen", "Kanz\u00b7ler", "sieht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil ein ungeheures G\u00e4hnen", "tokens": ["Weil", "ein", "un\u00b7ge\u00b7heu\u00b7res", "G\u00e4h\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Alle Backen aufw\u00e4rts zieht.", "tokens": ["Al\u00b7le", "Ba\u00b7cken", "auf\u00b7w\u00e4rts", "zieht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Wenn am Tisch des Bundesrates", "tokens": ["Wenn", "am", "Tisch", "des", "Bun\u00b7des\u00b7ra\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich erhebt der Herr Major,", "tokens": ["Sich", "er\u00b7hebt", "der", "Herr", "Ma\u00b7jor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "H\u00e4lt man sich was Obligates", "tokens": ["H\u00e4lt", "man", "sich", "was", "Ob\u00b7li\u00b7ga\u00b7tes"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "PWS", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aufgesperrten M\u00e4ulern vor.", "tokens": ["Auf\u00b7ge\u00b7sperr\u00b7ten", "M\u00e4u\u00b7lern", "vor", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Bethmann ist von selten tiefer", "tokens": ["Beth\u00b7mann", "ist", "von", "sel\u00b7ten", "tie\u00b7fer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wirkung, wie es jeder sah,", "tokens": ["Wir\u00b7kung", ",", "wie", "es", "je\u00b7der", "sah", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Auf des H\u00f6rers Unterkiefer", "tokens": ["Auf", "des", "H\u00f6\u00b7rers", "Un\u00b7ter\u00b7kie\u00b7fer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Oder auch mandibula.", "tokens": ["O\u00b7der", "auch", "man\u00b7di\u00b7bu\u00b7la", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}