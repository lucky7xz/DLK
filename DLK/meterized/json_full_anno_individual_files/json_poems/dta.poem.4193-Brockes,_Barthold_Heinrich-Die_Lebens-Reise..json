{"dta.poem.4193": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Die Lebens-Reise.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1743", "urn": "urn:nbn:de:kobv:b4-20083-6", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Noch wandern sollen, \u00fcberlegen,", "tokens": ["Noch", "wan\u00b7dern", "sol\u00b7len", ",", "\u00fc\u00b7berl\u00b7e\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "VMFIN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df wir in stetigem Bewegen!", "tokens": ["Da\u00df", "wir", "in", "ste\u00b7ti\u00b7gem", "Be\u00b7we\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ach, la\u00df uns diese Wahrheit fassen,", "tokens": ["Ach", ",", "la\u00df", "uns", "die\u00b7se", "Wahr\u00b7heit", "fas\u00b7sen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVIMP", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Da\u00df wir, recht wie ein strenger Flu\u00df,", "tokens": ["Da\u00df", "wir", ",", "recht", "wie", "ein", "stren\u00b7ger", "Flu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.5": {"text": "Der immer vorwerts eilen mu\u00df,", "tokens": ["Der", "im\u00b7mer", "vor\u00b7werts", "ei\u00b7len", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVFIN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So Strand als Ufer r\u00fcckwerts lassen!", "tokens": ["So", "Strand", "als", "U\u00b7fer", "r\u00fcck\u00b7werts", "las\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Auch da\u00df uns nichts, von allen Seiten,", "tokens": ["Auch", "da\u00df", "uns", "nichts", ",", "von", "al\u00b7len", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PIS", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Begleitet, nein, da\u00df wir uns selber nur begleiten,", "tokens": ["Be\u00b7glei\u00b7tet", ",", "nein", ",", "da\u00df", "wir", "uns", "sel\u00b7ber", "nur", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PTKANT", "$,", "KOUS", "PPER", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, da\u00df wir endlich ganz allein,", "tokens": ["Ja", ",", "da\u00df", "wir", "end\u00b7lich", "ganz", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PPER", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nach unsrer Reis\u2019 auf dieser Erden,", "tokens": ["Nach", "uns\u00b7rer", "Reis'", "auf", "die\u00b7ser", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ohn\u2019 allen Vorwurf uns befinden werden!", "tokens": ["Ohn'", "al\u00b7len", "Vor\u00b7wurf", "uns", "be\u00b7fin\u00b7den", "wer\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ach, gieb, da\u00df, ohn\u2019 Gewissens-Pein,", "tokens": ["Ach", ",", "gieb", ",", "da\u00df", ",", "ohn'", "Ge\u00b7wis\u00b7sens\u00b7Pein", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVIMP", "$,", "KOUS", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Wir uns, sodann uns selbst nicht unertr\u00e4glich seyn!", "tokens": ["Wir", "uns", ",", "so\u00b7dann", "uns", "selbst", "nicht", "un\u00b7er\u00b7tr\u00e4g\u00b7lich", "seyn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "$,", "PWAV", "PPER", "ADV", "PTKNEG", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}