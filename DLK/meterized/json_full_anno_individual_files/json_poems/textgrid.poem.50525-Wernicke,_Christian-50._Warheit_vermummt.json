{"textgrid.poem.50525": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "50. Warheit vermummt", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die traff' ich an, als sie ", "tokens": ["Die", "traff'", "ich", "an", ",", "als", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich naht' herzu, und gleich als ob ich sie nicht kante,", "tokens": ["Ich", "naht'", "her\u00b7zu", ",", "und", "gleich", "als", "ob", "ich", "sie", "nicht", "kan\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KON", "ADV", "KOKOM", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ihr ", "tokens": ["Und", "ihr"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sagt' ich, als ich die Hand nach ihrer ", "tokens": ["Sagt'", "ich", ",", "als", "ich", "die", "Hand", "nach", "ih\u00b7rer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Glaubt ihr, versetzte sie, dass insgemein auch ", "tokens": ["Glaubt", "ihr", ",", "ver\u00b7setz\u00b7te", "sie", ",", "dass", "ins\u00b7ge\u00b7mein", "auch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ADV"], "meter": "++-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.6": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Erz\u00fcrnt durch dieses Wort, Ey ist euch nicht bekant,", "tokens": ["Er\u00b7z\u00fcrnt", "durch", "die\u00b7ses", "Wort", ",", "Ey", "ist", "euch", "nicht", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PDAT", "NN", "$,", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sprach ich, ein ", "tokens": ["Sprach", "ich", ",", "ein"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "PPER", "$,", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Sie liess', als sie noch lebt', auf ihren ", "tokens": ["Sie", "liess'", ",", "als", "sie", "noch", "lebt'", ",", "auf", "ih\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Frembdling fand sich drauf nach vielen Jahren ein;", "tokens": ["Ein", "Frembd\u00b7ling", "fand", "sich", "drauf", "nach", "vie\u00b7len", "Jah\u00b7ren", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PAV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er lahs, und dachte Geld verachten nur die Narren,", "tokens": ["Er", "lahs", ",", "und", "dach\u00b7te", "Geld", "ver\u00b7ach\u00b7ten", "nur", "die", "Nar\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "KON", "VVFIN", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und fing die Grufft an aufzuscharren.", "tokens": ["Und", "fing", "die", "Grufft", "an", "auf\u00b7zu\u00b7schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Es kostet' ihm viel M\u00fch', und offtmahls sch\u00f6pft' er Lufft,", "tokens": ["Es", "kos\u00b7tet'", "ihm", "viel", "M\u00fch'", ",", "und", "offt\u00b7mahls", "sch\u00f6pft'", "er", "Lufft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Eh' er den ", "tokens": ["Eh'", "er", "den"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Als aber er zuletzt den ", "tokens": ["Als", "a\u00b7ber", "er", "zu\u00b7letzt", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "So fand er nichts als ", "tokens": ["So", "fand", "er", "nichts", "als"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "KOKOM"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Ich schwieg: sie aber sprach, Freund ich versteh' euch nicht;", "tokens": ["Ich", "schwieg", ":", "sie", "a\u00b7ber", "sprach", ",", "Freund", "ich", "ver\u00b7steh'", "euch", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "ADV", "VVFIN", "$,", "NN", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nein, sagt' ich, ", "tokens": ["Nein", ",", "sagt'", "ich", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,"], "meter": "++-", "measure": "unknown.measure.di"}}, "stanza.2": {"line.1": {"text": "Die traff' ich an, als sie ", "tokens": ["Die", "traff'", "ich", "an", ",", "als", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ich naht' herzu, und gleich als ob ich sie nicht kante,", "tokens": ["Ich", "naht'", "her\u00b7zu", ",", "und", "gleich", "als", "ob", "ich", "sie", "nicht", "kan\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KON", "ADV", "KOKOM", "KOUS", "PPER", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und ihr ", "tokens": ["Und", "ihr"], "token_info": ["word", "word"], "pos": ["KON", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Sagt' ich, als ich die Hand nach ihrer ", "tokens": ["Sagt'", "ich", ",", "als", "ich", "die", "Hand", "nach", "ih\u00b7rer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Glaubt ihr, versetzte sie, dass insgemein auch ", "tokens": ["Glaubt", "ihr", ",", "ver\u00b7setz\u00b7te", "sie", ",", "dass", "ins\u00b7ge\u00b7mein", "auch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ADV"], "meter": "++-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.6": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Erz\u00fcrnt durch dieses Wort, Ey ist euch nicht bekant,", "tokens": ["Er\u00b7z\u00fcrnt", "durch", "die\u00b7ses", "Wort", ",", "Ey", "ist", "euch", "nicht", "be\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PDAT", "NN", "$,", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sprach ich, ein ", "tokens": ["Sprach", "ich", ",", "ein"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "PPER", "$,", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.9": {"text": "Sie liess', als sie noch lebt', auf ihren ", "tokens": ["Sie", "liess'", ",", "als", "sie", "noch", "lebt'", ",", "auf", "ih\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,", "APPR", "PPOSAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Frembdling fand sich drauf nach vielen Jahren ein;", "tokens": ["Ein", "Frembd\u00b7ling", "fand", "sich", "drauf", "nach", "vie\u00b7len", "Jah\u00b7ren", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PAV", "APPR", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er lahs, und dachte Geld verachten nur die Narren,", "tokens": ["Er", "lahs", ",", "und", "dach\u00b7te", "Geld", "ver\u00b7ach\u00b7ten", "nur", "die", "Nar\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "$,", "KON", "VVFIN", "NN", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und fing die Grufft an aufzuscharren.", "tokens": ["Und", "fing", "die", "Grufft", "an", "auf\u00b7zu\u00b7schar\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Es kostet' ihm viel M\u00fch', und offtmahls sch\u00f6pft' er Lufft,", "tokens": ["Es", "kos\u00b7tet'", "ihm", "viel", "M\u00fch'", ",", "und", "offt\u00b7mahls", "sch\u00f6pft'", "er", "Lufft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Eh' er den ", "tokens": ["Eh'", "er", "den"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Als aber er zuletzt den ", "tokens": ["Als", "a\u00b7ber", "er", "zu\u00b7letzt", "den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "ADV", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "So fand er nichts als ", "tokens": ["So", "fand", "er", "nichts", "als"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "KOKOM"], "meter": "-+-+-", "measure": "iambic.di"}, "line.17": {"text": "Ich schwieg: sie aber sprach, Freund ich versteh' euch nicht;", "tokens": ["Ich", "schwieg", ":", "sie", "a\u00b7ber", "sprach", ",", "Freund", "ich", "ver\u00b7steh'", "euch", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "ADV", "VVFIN", "$,", "NN", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Nein, sagt' ich, ", "tokens": ["Nein", ",", "sagt'", "ich", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "PPER", "$,"], "meter": "++-", "measure": "unknown.measure.di"}}}}}