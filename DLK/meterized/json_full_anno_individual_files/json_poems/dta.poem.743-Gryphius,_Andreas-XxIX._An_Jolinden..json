{"dta.poem.743": {"metadata": {"author": {"name": "Gryphius, Andreas", "birth": "N.A.", "death": "N.A."}, "title": "XxIX.  An  Jolinden.", "genre": "Lyrik, Drama", "period": "N.A.", "pub_year": "1650", "urn": "urn:nbn:de:kobv:b4-20218-7", "language": ["de:0.99"], "booktitle": "Gryphius, Andreas: Teutsche Reim-Gedichte. Frankfurt (Main), 1650."}, "poem": {"stanza.1": {"line.1": {"text": "Was habt jhr das jhr m\u00f6gt an euch ewr eigen nennen! ", "tokens": ["Was", "habt", "jhr", "das", "jhr", "m\u00f6gt", "an", "euch", "ewr", "ei\u00b7gen", "nen\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ART", "PPER", "VMFIN", "APPR", "PPER", "ADV", "ADJD", "VVINF", "$."], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die schminck ists die euch so bluttrotte Lippen macht:", "tokens": ["Die", "schminck", "ists", "die", "euch", "so", "blutt\u00b7rot\u00b7te", "Lip\u00b7pen", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "ART", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Z\u00e4hne sindt durch kunst in leeren ", "tokens": ["Die", "Z\u00e4h\u00b7ne", "sindt", "durch", "kunst", "in", "lee\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "APPR", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man weis das ", "tokens": ["Man", "weis", "das"], "token_info": ["word", "word", "word"], "pos": ["PIS", "PTKVZ", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Ewr eingekanftes Haar kan auch ein Kind\u2019 erkennen.", "tokens": ["Ewr", "ein\u00b7ge\u00b7kanf\u00b7tes", "Haar", "kan", "auch", "ein", "Kind'", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der schlimme ", "tokens": ["Der", "schlim\u00b7me"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Vnd die polirte Stirn wird billich au\u00dfgelacht", "tokens": ["Vnd", "die", "po\u00b7lir\u00b7te", "Stirn", "wird", "bil\u00b7lich", "au\u00df\u00b7ge\u00b7lacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VAFIN", "ADJD", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn sich der Salben Eys will bey den runtzeln trennen. ", "tokens": ["Wenn", "sich", "der", "Sal\u00b7ben", "Eys", "will", "bey", "den", "runt\u00b7zeln", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "NE", "VMFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Gemahlte/ sagt mir doch wer seidt jhr/ vnd wie alt? ", "tokens": ["Ge\u00b7mahl\u00b7te", "/", "sagt", "mir", "doch", "wer", "seidt", "jhr", "/", "vnd", "wie", "alt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "PPER", "ADV", "PWS", "VAFIN", "PPER", "$(", "KON", "PWAV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr meyn ich/ sechzehn jahr/ drey ", "tokens": ["Ihr", "meyn", "ich", "/", "sech\u00b7zehn", "jahr", "/", "drey"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["PPER", "PPOSAT", "PPER", "$(", "CARD", "NN", "$(", "CARD"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Jhr seidt von Haus\u2019 vnd sie ist vber See ankommen.", "tokens": ["Ihr", "seidt", "von", "Haus'", "vnd", "sie", "ist", "vber", "See", "an\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "KON", "PPER", "VAFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.4": {"line.1": {"text": "Jhr sch\u00e4tzt euch trefflich hoch/ vmbsonst! der Maler hat ", "tokens": ["Ihr", "sch\u00e4tzt", "euch", "treff\u00b7lich", "hoch", "/", "vmbsonst", "!", "der", "Ma\u00b7ler", "hat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "ADJD", "$(", "ADV", "$.", "ART", "NN", "VAFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Noch f\u00fcr ein sch\u00f6ner bild/ das feil war in der stadt", "tokens": ["Noch", "f\u00fcr", "ein", "sch\u00f6\u00b7ner", "bild", "/", "das", "feil", "war", "in", "der", "stadt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$(", "ART", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Vnd l\u00e4nger bleibt/ denn jhr/ drey Kronen nur genommen.", "tokens": ["Vnd", "l\u00e4n\u00b7ger", "bleibt", "/", "denn", "jhr", "/", "drey", "Kro\u00b7nen", "nur", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "$(", "KON", "PPER", "$(", "CARD", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}