{"textgrid.poem.34957": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bblechzend klebe mir die Zunge", "tokens": ["\u00bb", "lech\u00b7zend", "kle\u00b7be", "mir", "die", "Zun\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem Gaumen, und es welke", "tokens": ["An", "dem", "Gau\u00b7men", ",", "und", "es", "wel\u00b7ke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "PPER", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Meine rechte Hand, verg\u00e4\u00df ich", "tokens": ["Mei\u00b7ne", "rech\u00b7te", "Hand", ",", "ver\u00b7g\u00e4\u00df", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jemals dein, Jerusalem \u2013\u00ab", "tokens": ["Je\u00b7mals", "dein", ",", "Je\u00b7ru\u00b7sa\u00b7lem", "\u2013", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "$,", "NE", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Wort und Weise, unaufh\u00f6rlich", "tokens": ["Wort", "und", "Wei\u00b7se", ",", "un\u00b7auf\u00b7h\u00f6r\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "KON", "NN", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwirren sie mir heut im Kopfe,", "tokens": ["Schwir\u00b7ren", "sie", "mir", "heut", "im", "Kop\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mir ist, als h\u00f6rt ich Stimmen,", "tokens": ["Und", "mir", "ist", ",", "als", "h\u00f6rt", "ich", "Stim\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Psalmodierend, M\u00e4nnerstimmen \u2013", "tokens": ["Psal\u00b7mo\u00b7die\u00b7rend", ",", "M\u00e4n\u00b7ner\u00b7stim\u00b7men", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Manchmal kommen auch zum Vorschein", "tokens": ["Manch\u00b7mal", "kom\u00b7men", "auch", "zum", "Vor\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "B\u00e4rte, schattig lange B\u00e4rte \u2013", "tokens": ["B\u00e4r\u00b7te", ",", "schat\u00b7tig", "lan\u00b7ge", "B\u00e4r\u00b7te", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Traumgestalten, wer von euch", "tokens": ["Traum\u00b7ge\u00b7stal\u00b7ten", ",", "wer", "von", "euch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist Jehuda ben Halevy?", "tokens": ["Ist", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch sie huschen rasch vor\u00fcber;", "tokens": ["Doch", "sie", "hu\u00b7schen", "rasch", "vor\u00b7\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Gespenster scheuen furchtsam", "tokens": ["Die", "Ge\u00b7spens\u00b7ter", "scheu\u00b7en", "furcht\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Lebend'gen plumpen Zuspruch \u2013", "tokens": ["Der", "Le\u00b7ben\u00b7d'\u00b7gen", "plum\u00b7pen", "Zu\u00b7spruch", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aber ihn hab ich erkannt \u2013", "tokens": ["A\u00b7ber", "ihn", "hab", "ich", "er\u00b7kannt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "Ich erkannt ihn an der bleichen", "tokens": ["Ich", "er\u00b7kannt", "ihn", "an", "der", "blei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gedankenstolzen Stirne,", "tokens": ["Und", "ge\u00b7dan\u00b7ken\u00b7stol\u00b7zen", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An der Augen s\u00fc\u00dfer Starrheit \u2013", "tokens": ["An", "der", "Au\u00b7gen", "s\u00fc\u00b7\u00dfer", "Star\u00b7rheit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sahn mich an so schmerzlich forschend \u2013", "tokens": ["Sahn", "mich", "an", "so", "schmerz\u00b7lich", "for\u00b7schend", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch zumeist erkannt ich ihn", "tokens": ["Doch", "zu\u00b7meist", "er\u00b7kannt", "ich", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem r\u00e4tselhaften L\u00e4cheln", "tokens": ["An", "dem", "r\u00e4t\u00b7sel\u00b7haf\u00b7ten", "L\u00e4\u00b7cheln"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener sch\u00f6n gereimten Lippen,", "tokens": ["Je\u00b7ner", "sch\u00f6n", "ge\u00b7reim\u00b7ten", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die man nur bei Dichtern findet.", "tokens": ["Die", "man", "nur", "bei", "Dich\u00b7tern", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Jahre kommen und verflie\u00dfen.", "tokens": ["Jah\u00b7re", "kom\u00b7men", "und", "ver\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seit Jehuda ben Halevy", "tokens": ["Seit", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward geboren, sind verflossen", "tokens": ["Ward", "ge\u00b7bo\u00b7ren", ",", "sind", "ver\u00b7flos\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Siebenhundertfunfzig Jahre \u2013", "tokens": ["Sie\u00b7ben\u00b7hun\u00b7dert\u00b7funf\u00b7zig", "Jah\u00b7re", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Hat zuerst das Licht erblickt", "tokens": ["Hat", "zu\u00b7erst", "das", "Licht", "er\u00b7blickt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu Toledo in Kastilien,", "tokens": ["Zu", "To\u00b7le\u00b7do", "in", "Kas\u00b7ti\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und es hat der goldne Tajo", "tokens": ["Und", "es", "hat", "der", "gold\u00b7ne", "Ta\u00b7jo"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihm sein Wiegenlied gelullet.", "tokens": ["Ihm", "sein", "Wie\u00b7gen\u00b7lied", "ge\u00b7lul\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "F\u00fcr Entwicklung seines Geistes", "tokens": ["F\u00fcr", "Ent\u00b7wick\u00b7lung", "sei\u00b7nes", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sorgte fr\u00fch der strenge Vater,", "tokens": ["Sorg\u00b7te", "fr\u00fch", "der", "stren\u00b7ge", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der den Unterricht begann", "tokens": ["Der", "den", "Un\u00b7ter\u00b7richt", "be\u00b7gann"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit dem Gottesbuch, der Thora.", "tokens": ["Mit", "dem", "Got\u00b7tes\u00b7buch", ",", "der", "Tho\u00b7ra", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Diese las er mit dem Sohne", "tokens": ["Die\u00b7se", "las", "er", "mit", "dem", "Soh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In dem Urtext, dessen sch\u00f6ne,", "tokens": ["In", "dem", "Ur\u00b7text", ",", "des\u00b7sen", "sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hieroglyphisch pittoreske,", "tokens": ["Hie\u00b7ro\u00b7gly\u00b7phisch", "pit\u00b7to\u00b7res\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Altchald\u00e4ische Quadratschrift", "tokens": ["Alt\u00b7chal\u00b7d\u00e4i\u00b7sche", "Quad\u00b7rat\u00b7schrift"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Herstammt aus dem Kindesalter", "tokens": ["Her\u00b7stammt", "aus", "dem", "Kin\u00b7de\u00b7sal\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Unsrer Welt, und auch deswegen", "tokens": ["Uns\u00b7rer", "Welt", ",", "und", "auch", "des\u00b7we\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "ADV", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jedem kindlichen Gem\u00fcte", "tokens": ["Je\u00b7dem", "kind\u00b7li\u00b7chen", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So vertraut entgegenlacht.", "tokens": ["So", "ver\u00b7traut", "ent\u00b7ge\u00b7gen\u00b7lacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Diesen echten alten Text", "tokens": ["Die\u00b7sen", "ech\u00b7ten", "al\u00b7ten", "Text"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Rezitierte auch der Knabe", "tokens": ["Re\u00b7zi\u00b7tier\u00b7te", "auch", "der", "Kna\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der uralt hergebrachten", "tokens": ["In", "der", "ur\u00b7alt", "her\u00b7ge\u00b7brach\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Singsangweise, Tropp gehei\u00dfen \u2013", "tokens": ["Sings\u00b7ang\u00b7wei\u00b7se", ",", "Tropp", "ge\u00b7hei\u00b7\u00dfen", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Und er gurgelte gar lieblich", "tokens": ["Und", "er", "gur\u00b7gel\u00b7te", "gar", "lieb\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Jene fetten Gutturalen,", "tokens": ["Je\u00b7ne", "fet\u00b7ten", "Gut\u00b7tu\u00b7ra\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er schlug dabei den Triller,", "tokens": ["Und", "er", "schlug", "da\u00b7bei", "den", "Tril\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Den Schalscheleth, wie ein Vogel.", "tokens": ["Den", "Schal\u00b7sche\u00b7leth", ",", "wie", "ein", "Vo\u00b7gel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Auch den Targum Onkelos,", "tokens": ["Auch", "den", "Tar\u00b7gum", "On\u00b7ke\u00b7los", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der geschrieben ist in jenem", "tokens": ["Der", "ge\u00b7schrie\u00b7ben", "ist", "in", "je\u00b7nem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VVPP", "VAFIN", "APPR", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Plattjud\u00e4ischen Idiom,", "tokens": ["Platt\u00b7ju\u00b7d\u00e4\u00b7i\u00b7schen", "I\u00b7diom", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das wir Aram\u00e4isch nennen", "tokens": ["Das", "wir", "A\u00b7ra\u00b7m\u00e4isch", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVINF"], "meter": "--+-+--", "measure": "anapaest.init"}}, "stanza.15": {"line.1": {"text": "Und zur Sprache der Propheten", "tokens": ["Und", "zur", "Spra\u00b7che", "der", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich verhalten mag etwa", "tokens": ["Sich", "ver\u00b7hal\u00b7ten", "mag", "et\u00b7wa"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "VVINF", "VMFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie das Schw\u00e4bische zum Deutschen \u2013", "tokens": ["Wie", "das", "Schw\u00e4\u00b7bi\u00b7sche", "zum", "Deut\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieses Gelbveiglein-Hebr\u00e4isch", "tokens": ["Die\u00b7ses", "Gelb\u00b7veig\u00b7lein\u00b7He\u00b7br\u00e4\u00b7isch"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "Lernte gleichfalls fr\u00fch der Knabe,", "tokens": ["Lern\u00b7te", "gleich\u00b7falls", "fr\u00fch", "der", "Kna\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es kam ihm solche Kenntnis", "tokens": ["Und", "es", "kam", "ihm", "sol\u00b7che", "Kennt\u00b7nis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bald darauf sehr gut zustatten", "tokens": ["Bald", "da\u00b7rauf", "sehr", "gut", "zu\u00b7stat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "ADV", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bei dem Studium des Talmuds.", "tokens": ["Bei", "dem", "Stu\u00b7di\u00b7um", "des", "Tal\u00b7muds", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ja, fr\u00fchzeitig hat der Vater", "tokens": ["Ja", ",", "fr\u00fch\u00b7zei\u00b7tig", "hat", "der", "Va\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihn geleitet zu dem Talmud,", "tokens": ["ihn", "ge\u00b7lei\u00b7tet", "zu", "dem", "Tal\u00b7mud", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da hat er ihm erschlossen", "tokens": ["Und", "da", "hat", "er", "ihm", "er\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Halacha, diese gro\u00dfe", "tokens": ["Die", "Ha\u00b7lac\u00b7ha", ",", "die\u00b7se", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$,", "PDAT", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Fechterschule, wo die besten", "tokens": ["Fech\u00b7ter\u00b7schu\u00b7le", ",", "wo", "die", "bes\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dialektischen Athleten", "tokens": ["Di\u00b7a\u00b7lek\u00b7ti\u00b7schen", "Ath\u00b7le\u00b7ten"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Babylons und Pumpedithas", "tokens": ["Ba\u00b7by\u00b7lons", "und", "Pum\u00b7pe\u00b7di\u00b7thas"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ihre K\u00e4mpferspiele trieben.", "tokens": ["Ih\u00b7re", "K\u00e4mp\u00b7fer\u00b7spie\u00b7le", "trie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Lernen konnte hier der Knabe", "tokens": ["Ler\u00b7nen", "konn\u00b7te", "hier", "der", "Kna\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle K\u00fcnste der Polemik;", "tokens": ["Al\u00b7le", "K\u00fcns\u00b7te", "der", "Po\u00b7le\u00b7mik", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Seine Meisterschaft bezeugte", "tokens": ["Sei\u00b7ne", "Meis\u00b7ter\u00b7schaft", "be\u00b7zeug\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sp\u00e4terhin das Buch Cosari.", "tokens": ["Sp\u00e4\u00b7ter\u00b7hin", "das", "Buch", "Co\u00b7sa\u00b7ri", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Doch der Himmel gie\u00dft herunter", "tokens": ["Doch", "der", "Him\u00b7mel", "gie\u00dft", "her\u00b7un\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwei verschiedne Sorten Lichtes:", "tokens": ["Zwei", "ver\u00b7schied\u00b7ne", "Sor\u00b7ten", "Lich\u00b7tes", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Grelles Tageslicht der Sonne", "tokens": ["Grel\u00b7les", "Ta\u00b7ges\u00b7licht", "der", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das mildre Mondlicht \u2013 Also,", "tokens": ["Und", "das", "mild\u00b7re", "Mond\u00b7licht", "\u2013", "Al\u00b7so", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "PTKANT", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.21": {"line.1": {"text": "Also leuchtet auch der Talmud", "tokens": ["Al\u00b7so", "leuch\u00b7tet", "auch", "der", "Tal\u00b7mud"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwiefach, und man teilt ihn ein", "tokens": ["Zwie\u00b7fach", ",", "und", "man", "teilt", "ihn", "ein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PIS", "VVFIN", "PPER", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In Halacha und Hagada.", "tokens": ["In", "Ha\u00b7lac\u00b7ha", "und", "Ha\u00b7ga\u00b7da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstre nannt ich eine Fechtschul' \u2013", "tokens": ["Er\u00b7stre", "nannt", "ich", "ei\u00b7ne", "Fecht\u00b7schul'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.22": {"line.1": {"text": "Letztre aber, die Hagada,", "tokens": ["Letz\u00b7tre", "a\u00b7ber", ",", "die", "Ha\u00b7ga\u00b7da", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "PRELS", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Will ich einen Garten nennen,", "tokens": ["Will", "ich", "ei\u00b7nen", "Gar\u00b7ten", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Garten, hochphantastisch", "tokens": ["Ei\u00b7nen", "Gar\u00b7ten", ",", "hoch\u00b7phan\u00b7tas\u00b7tisch"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vergleichbar jenem andern,", "tokens": ["Und", "ver\u00b7gleich\u00b7bar", "je\u00b7nem", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Welcher ebenfalls dem Boden", "tokens": ["Wel\u00b7cher", "e\u00b7ben\u00b7falls", "dem", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Babylons entsprossen weiland \u2013", "tokens": ["Ba\u00b7by\u00b7lons", "ent\u00b7spros\u00b7sen", "wei\u00b7land", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Garten der Semiramis,", "tokens": ["Gar\u00b7ten", "der", "Se\u00b7mi\u00b7ra\u00b7mis", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Achtes Wunderwerk der Welt.", "tokens": ["Ach\u00b7tes", "Wun\u00b7der\u00b7werk", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.24": {"line.1": {"text": "K\u00f6nigin Semiramis,", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "Se\u00b7mi\u00b7ra\u00b7mis", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die als Kind erzogen worden", "tokens": ["Die", "als", "Kind", "er\u00b7zo\u00b7gen", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "NN", "VVPP", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von den V\u00f6geln, und gar manche", "tokens": ["Von", "den", "V\u00f6\u00b7geln", ",", "und", "gar", "man\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "ADV", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "V\u00f6gelt\u00fcmlichkeit bewahrte,", "tokens": ["V\u00f6\u00b7gel\u00b7t\u00fcm\u00b7lich\u00b7keit", "be\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Wollte nicht auf platter Erde", "tokens": ["Woll\u00b7te", "nicht", "auf", "plat\u00b7ter", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Promenieren wie wir andern", "tokens": ["Pro\u00b7me\u00b7nie\u00b7ren", "wie", "wir", "an\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "PPER", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4ugetiere, und sie pflanzte", "tokens": ["S\u00e4u\u00b7ge\u00b7tie\u00b7re", ",", "und", "sie", "pflanz\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Garten in der Luft \u2013", "tokens": ["Ei\u00b7nen", "Gar\u00b7ten", "in", "der", "Luft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Hoch auf kolossalen S\u00e4ulen", "tokens": ["Hoch", "auf", "ko\u00b7los\u00b7sa\u00b7len", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Prangten Palmen und Zypressen,", "tokens": ["Prang\u00b7ten", "Pal\u00b7men", "und", "Zyp\u00b7res\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NE", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Goldorangen, Blumenbeete,", "tokens": ["Gol\u00b7do\u00b7ran\u00b7gen", ",", "Blu\u00b7men\u00b7bee\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Marmorbilder, auch Springbrunnen,", "tokens": ["Mar\u00b7mor\u00b7bil\u00b7der", ",", "auch", "Spring\u00b7brun\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.27": {"line.1": {"text": "Alles klug und fest verbunden", "tokens": ["Al\u00b7les", "klug", "und", "fest", "ver\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "KON", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch unz\u00e4hl'ge H\u00e4ngebr\u00fccken,", "tokens": ["Durch", "un\u00b7z\u00e4hl'\u00b7ge", "H\u00e4n\u00b7ge\u00b7br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die wie Schlingepflanzen aussahn", "tokens": ["Die", "wie", "Schlin\u00b7ge\u00b7pflan\u00b7zen", "aus\u00b7sahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "KOKOM", "NN", "VVIZU"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und worauf sich V\u00f6gel wiegten \u2013", "tokens": ["Und", "wo\u00b7rauf", "sich", "V\u00f6\u00b7gel", "wieg\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "NN", "VVFIN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.28": {"line.1": {"text": "Gro\u00dfe, bunte, ernste V\u00f6gel,", "tokens": ["Gro\u00b7\u00dfe", ",", "bun\u00b7te", ",", "erns\u00b7te", "V\u00f6\u00b7gel", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tiefe Denker, die nicht singen,", "tokens": ["Tie\u00b7fe", "Den\u00b7ker", ",", "die", "nicht", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend sie umflattert kleines", "tokens": ["W\u00e4h\u00b7rend", "sie", "um\u00b7flat\u00b7tert", "klei\u00b7nes"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zeisigvolk, das lustig trillert \u2013", "tokens": ["Zei\u00b7sig\u00b7volk", ",", "das", "lus\u00b7tig", "tril\u00b7lert", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.29": {"line.1": {"text": "Alle atmen ein, beseligt,", "tokens": ["Al\u00b7le", "at\u00b7men", "ein", ",", "be\u00b7se\u00b7ligt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen reinen Balsamduft,", "tokens": ["Ei\u00b7nen", "rei\u00b7nen", "Bal\u00b7sam\u00b7duft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welcher unvermischt mit schn\u00f6dem", "tokens": ["Wel\u00b7cher", "un\u00b7ver\u00b7mischt", "mit", "schn\u00f6\u00b7dem"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "NN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Erdendunst und Mi\u00dfgeruche.", "tokens": ["Er\u00b7den\u00b7dunst", "und", "Mi\u00df\u00b7ge\u00b7ru\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Die Hagada ist ein Garten", "tokens": ["Die", "Ha\u00b7ga\u00b7da", "ist", "ein", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Solcher Luftkindgrillenart,", "tokens": ["Sol\u00b7cher", "Luft\u00b7kind\u00b7gril\u00b7len\u00b7art", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der junge Talmudsch\u00fcler,", "tokens": ["Und", "der", "jun\u00b7ge", "Tal\u00b7mud\u00b7sch\u00fc\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sein Herze war best\u00e4ubet", "tokens": ["Wenn", "sein", "Her\u00b7ze", "war", "be\u00b7st\u00e4u\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Und bet\u00e4ubet vom Gez\u00e4nke", "tokens": ["Und", "be\u00b7t\u00e4u\u00b7bet", "vom", "Ge\u00b7z\u00e4n\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Halacha, vom Dispute", "tokens": ["Der", "Ha\u00b7lac\u00b7ha", ",", "vom", "Dis\u00b7pu\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00dcber das fatale Ei,", "tokens": ["\u00dc\u00b7ber", "das", "fa\u00b7ta\u00b7le", "Ei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ein Huhn gelegt am Festtag,", "tokens": ["Das", "ein", "Huhn", "ge\u00b7legt", "am", "Fest\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "APPRART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.32": {"line.1": {"text": "Oder \u00fcber eine Frage", "tokens": ["O\u00b7der", "\u00fc\u00b7ber", "ei\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleicher Importanz \u2013 der Knabe", "tokens": ["Glei\u00b7cher", "Im\u00b7por\u00b7tanz", "\u2013", "der", "Kna\u00b7be"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$(", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Floh alsdann, sich zu erfrischen,", "tokens": ["Floh", "als\u00b7dann", ",", "sich", "zu", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In die bl\u00fchende Hagada,", "tokens": ["In", "die", "bl\u00fc\u00b7hen\u00b7de", "Ha\u00b7ga\u00b7da", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.33": {"line.1": {"text": "Wo die sch\u00f6nen alten Sagen,", "tokens": ["Wo", "die", "sch\u00f6\u00b7nen", "al\u00b7ten", "Sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Engelm\u00e4rchen und Legenden,", "tokens": ["En\u00b7gel\u00b7m\u00e4r\u00b7chen", "und", "Le\u00b7gen\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Stille M\u00e4rtyrerhistorien,", "tokens": ["Stil\u00b7le", "M\u00e4r\u00b7ty\u00b7rer\u00b7his\u00b7to\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+--+---", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Festges\u00e4nge, Weisheitspr\u00fcche,", "tokens": ["Fest\u00b7ge\u00b7s\u00e4n\u00b7ge", ",", "Weis\u00b7heits\u00b7pr\u00fc\u00b7che", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.34": {"line.1": {"text": "Auch Hyperbeln, gar possierlich,", "tokens": ["Auch", "Hy\u00b7per\u00b7beln", ",", "gar", "pos\u00b7sier\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Alles aber glaubenskr\u00e4ftig,", "tokens": ["Al\u00b7les", "a\u00b7ber", "glau\u00b7bens\u00b7kr\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Glaubensgl\u00fchend \u2013 Oh, das gl\u00e4nzte,", "tokens": ["Glau\u00b7bens\u00b7gl\u00fc\u00b7hend", "\u2013", "Oh", ",", "das", "gl\u00e4nz\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$(", "ITJ", "$,", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Quoll und spro\u00df so \u00fcberschwenglich \u2013", "tokens": ["Quoll", "und", "spro\u00df", "so", "\u00fc\u00b7bersc\u00b7hweng\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.35": {"line.1": {"text": "Und des Knaben edles Herze", "tokens": ["Und", "des", "Kna\u00b7ben", "ed\u00b7les", "Her\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward ergriffen von der wilden,", "tokens": ["Ward", "er\u00b7grif\u00b7fen", "von", "der", "wil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Abenteuerlichen S\u00fc\u00dfe,", "tokens": ["A\u00b7bent\u00b7eu\u00b7er\u00b7li\u00b7chen", "S\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Von der wundersamen Schmerzlust", "tokens": ["Von", "der", "wun\u00b7der\u00b7sa\u00b7men", "Schmerz\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Und den fabelhaften Schauern", "tokens": ["Und", "den", "fa\u00b7bel\u00b7haf\u00b7ten", "Schau\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jener seligen Geheimwelt,", "tokens": ["Je\u00b7ner", "se\u00b7li\u00b7gen", "Ge\u00b7heim\u00b7welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener gro\u00dfen Offenbarung,", "tokens": ["Je\u00b7ner", "gro\u00b7\u00dfen", "Of\u00b7fen\u00b7ba\u00b7rung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die wir nennen Poesie.", "tokens": ["Die", "wir", "nen\u00b7nen", "Poe\u00b7sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.37": {"line.1": {"text": "Auch die Kunst der Poesie,", "tokens": ["Auch", "die", "Kunst", "der", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heitres Wissen, holdes K\u00f6nnen,", "tokens": ["Heit\u00b7res", "Wis\u00b7sen", ",", "hol\u00b7des", "K\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches wir die Dichtkunst hei\u00dfen,", "tokens": ["Wel\u00b7ches", "wir", "die", "Dicht\u00b7kunst", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tat sich auf dem Sinn des Knaben.", "tokens": ["Tat", "sich", "auf", "dem", "Sinn", "des", "Kna\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Und Jehuda ben Halevy", "tokens": ["Und", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward nicht blo\u00df ein Schriftgelehrter,", "tokens": ["Ward", "nicht", "blo\u00df", "ein", "Schrift\u00b7ge\u00b7lehr\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern auch der Dichtkunst Meister,", "tokens": ["Son\u00b7dern", "auch", "der", "Dicht\u00b7kunst", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern auch ein gro\u00dfer Dichter.", "tokens": ["Son\u00b7dern", "auch", "ein", "gro\u00b7\u00dfer", "Dich\u00b7ter."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Ja, er ward ein gro\u00dfer Dichter,", "tokens": ["Ja", ",", "er", "ward", "ein", "gro\u00b7\u00dfer", "Dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stern und Fackel seiner Zeit,", "tokens": ["Stern", "und", "Fa\u00b7ckel", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seines Volkes Licht und Leuchte,", "tokens": ["Sei\u00b7nes", "Vol\u00b7kes", "Licht", "und", "Leuch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine wunderbare, gro\u00dfe", "tokens": ["Ei\u00b7ne", "wun\u00b7der\u00b7ba\u00b7re", ",", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.40": {"line.1": {"text": "Feuers\u00e4ule des Gesanges,", "tokens": ["Feu\u00b7er\u00b7s\u00e4u\u00b7le", "des", "Ge\u00b7san\u00b7ges", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die der Schmerzenskarawane", "tokens": ["Die", "der", "Schmer\u00b7zens\u00b7ka\u00b7ra\u00b7wa\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Israels vorangezogen", "tokens": ["Is\u00b7raels", "vor\u00b7an\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word"], "pos": ["NE", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In der W\u00fcste des Exils.", "tokens": ["In", "der", "W\u00fcs\u00b7te", "des", "E\u00b7xils", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.41": {"line.1": {"text": "Rein und wahrhaft, sonder Makel", "tokens": ["Rein", "und", "wahr\u00b7haft", ",", "son\u00b7der", "Ma\u00b7kel"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "ADV", "$,", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War sein Lied, wie seine Seele \u2013", "tokens": ["War", "sein", "Lied", ",", "wie", "sei\u00b7ne", "See\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PWAV", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als der Sch\u00f6pfer sie erschaffen,", "tokens": ["Als", "der", "Sch\u00f6p\u00b7fer", "sie", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diese Seele, selbstzufrieden", "tokens": ["Die\u00b7se", "See\u00b7le", ",", "selbst\u00b7zu\u00b7frie\u00b7den"], "token_info": ["word", "word", "punct", "word"], "pos": ["PDAT", "NN", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.42": {"line.1": {"text": "K\u00fc\u00dfte er die sch\u00f6ne Seele,", "tokens": ["K\u00fc\u00df\u00b7te", "er", "die", "sch\u00f6\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und des Kusses holder Nachklang", "tokens": ["Und", "des", "Kus\u00b7ses", "hol\u00b7der", "Nach\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bebt in jedem Lied des Dichters,", "tokens": ["Bebt", "in", "je\u00b7dem", "Lied", "des", "Dich\u00b7ters", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das geweiht durch diese Gnade.", "tokens": ["Das", "ge\u00b7weiht", "durch", "die\u00b7se", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.43": {"line.1": {"text": "Wie im Leben, so im Dichten", "tokens": ["Wie", "im", "Le\u00b7ben", ",", "so", "im", "Dich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Ist das h\u00f6chste Gut die Gnade \u2013", "tokens": ["Ist", "das", "h\u00f6chs\u00b7te", "Gut", "die", "Gna\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sie hat, der kann nicht s\u00fcnd'gen,", "tokens": ["Wer", "sie", "hat", ",", "der", "kann", "nicht", "s\u00fcn\u00b7d'\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PRELS", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "--+-++-+-", "measure": "anapaest.init"}, "line.4": {"text": "Nicht in Versen, noch in Prosa.", "tokens": ["Nicht", "in", "Ver\u00b7sen", ",", "noch", "in", "Pro\u00b7sa", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "ADV", "APPR", "NN", "$."], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.44": {"line.1": {"text": "Solchen Dichter von der Gnade", "tokens": ["Sol\u00b7chen", "Dich\u00b7ter", "von", "der", "Gna\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottes nennen wir Genie:", "tokens": ["Got\u00b7tes", "nen\u00b7nen", "wir", "Ge\u00b7nie", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Unverantwortlicher K\u00f6nig", "tokens": ["Un\u00b7ver\u00b7ant\u00b7wort\u00b7li\u00b7cher", "K\u00f6\u00b7nig"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Gedankenreiches ist er.", "tokens": ["Des", "Ge\u00b7dan\u00b7ken\u00b7rei\u00b7ches", "ist", "er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Nur dem Gotte steht er Rede,", "tokens": ["Nur", "dem", "Got\u00b7te", "steht", "er", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht dem Volke \u2013 In der Kunst,", "tokens": ["Nicht", "dem", "Vol\u00b7ke", "\u2013", "In", "der", "Kunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$(", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie im Leben, kann das Volk", "tokens": ["Wie", "im", "Le\u00b7ben", ",", "kann", "das", "Volk"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "$,", "VMFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6ten uns, doch niemals richten. \u2013", "tokens": ["T\u00f6\u00b7ten", "uns", ",", "doch", "nie\u00b7mals", "rich\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.46": {"line.1": {"text": "\u00bblechzend klebe mir die Zunge", "tokens": ["\u00bb", "lech\u00b7zend", "kle\u00b7be", "mir", "die", "Zun\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem Gaumen, und es welke", "tokens": ["An", "dem", "Gau\u00b7men", ",", "und", "es", "wel\u00b7ke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "PPER", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Meine rechte Hand, verg\u00e4\u00df ich", "tokens": ["Mei\u00b7ne", "rech\u00b7te", "Hand", ",", "ver\u00b7g\u00e4\u00df", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "VVFIN", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jemals dein, Jerusalem \u2013\u00ab", "tokens": ["Je\u00b7mals", "dein", ",", "Je\u00b7ru\u00b7sa\u00b7lem", "\u2013", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "$,", "NE", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.47": {"line.1": {"text": "Wort und Weise, unaufh\u00f6rlich", "tokens": ["Wort", "und", "Wei\u00b7se", ",", "un\u00b7auf\u00b7h\u00f6r\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "KON", "NN", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schwirren sie mir heut im Kopfe,", "tokens": ["Schwir\u00b7ren", "sie", "mir", "heut", "im", "Kop\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mir ist, als h\u00f6rt ich Stimmen,", "tokens": ["Und", "mir", "ist", ",", "als", "h\u00f6rt", "ich", "Stim\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "$,", "KOUS", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Psalmodierend, M\u00e4nnerstimmen \u2013", "tokens": ["Psal\u00b7mo\u00b7die\u00b7rend", ",", "M\u00e4n\u00b7ner\u00b7stim\u00b7men", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Manchmal kommen auch zum Vorschein", "tokens": ["Manch\u00b7mal", "kom\u00b7men", "auch", "zum", "Vor\u00b7schein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "B\u00e4rte, schattig lange B\u00e4rte \u2013", "tokens": ["B\u00e4r\u00b7te", ",", "schat\u00b7tig", "lan\u00b7ge", "B\u00e4r\u00b7te", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Traumgestalten, wer von euch", "tokens": ["Traum\u00b7ge\u00b7stal\u00b7ten", ",", "wer", "von", "euch"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWS", "APPR", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Ist Jehuda ben Halevy?", "tokens": ["Ist", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Doch sie huschen rasch vor\u00fcber;", "tokens": ["Doch", "sie", "hu\u00b7schen", "rasch", "vor\u00b7\u00fc\u00b7ber", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Gespenster scheuen furchtsam", "tokens": ["Die", "Ge\u00b7spens\u00b7ter", "scheu\u00b7en", "furcht\u00b7sam"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Lebend'gen plumpen Zuspruch \u2013", "tokens": ["Der", "Le\u00b7ben\u00b7d'\u00b7gen", "plum\u00b7pen", "Zu\u00b7spruch", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aber ihn hab ich erkannt \u2013", "tokens": ["A\u00b7ber", "ihn", "hab", "ich", "er\u00b7kannt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "VVPP", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.50": {"line.1": {"text": "Ich erkannt ihn an der bleichen", "tokens": ["Ich", "er\u00b7kannt", "ihn", "an", "der", "blei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und gedankenstolzen Stirne,", "tokens": ["Und", "ge\u00b7dan\u00b7ken\u00b7stol\u00b7zen", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "An der Augen s\u00fc\u00dfer Starrheit \u2013", "tokens": ["An", "der", "Au\u00b7gen", "s\u00fc\u00b7\u00dfer", "Star\u00b7rheit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sahn mich an so schmerzlich forschend \u2013", "tokens": ["Sahn", "mich", "an", "so", "schmerz\u00b7lich", "for\u00b7schend", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADV", "ADJD", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.51": {"line.1": {"text": "Doch zumeist erkannt ich ihn", "tokens": ["Doch", "zu\u00b7meist", "er\u00b7kannt", "ich", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "An dem r\u00e4tselhaften L\u00e4cheln", "tokens": ["An", "dem", "r\u00e4t\u00b7sel\u00b7haf\u00b7ten", "L\u00e4\u00b7cheln"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener sch\u00f6n gereimten Lippen,", "tokens": ["Je\u00b7ner", "sch\u00f6n", "ge\u00b7reim\u00b7ten", "Lip\u00b7pen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "ADJD", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die man nur bei Dichtern findet.", "tokens": ["Die", "man", "nur", "bei", "Dich\u00b7tern", "fin\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.52": {"line.1": {"text": "Jahre kommen und verflie\u00dfen.", "tokens": ["Jah\u00b7re", "kom\u00b7men", "und", "ver\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Seit Jehuda ben Halevy", "tokens": ["Seit", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward geboren, sind verflossen", "tokens": ["Ward", "ge\u00b7bo\u00b7ren", ",", "sind", "ver\u00b7flos\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Siebenhundertfunfzig Jahre \u2013", "tokens": ["Sie\u00b7ben\u00b7hun\u00b7dert\u00b7funf\u00b7zig", "Jah\u00b7re", "\u2013"], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.53": {"line.1": {"text": "Hat zuerst das Licht erblickt", "tokens": ["Hat", "zu\u00b7erst", "das", "Licht", "er\u00b7blickt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zu Toledo in Kastilien,", "tokens": ["Zu", "To\u00b7le\u00b7do", "in", "Kas\u00b7ti\u00b7li\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und es hat der goldne Tajo", "tokens": ["Und", "es", "hat", "der", "gold\u00b7ne", "Ta\u00b7jo"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihm sein Wiegenlied gelullet.", "tokens": ["Ihm", "sein", "Wie\u00b7gen\u00b7lied", "ge\u00b7lul\u00b7let", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.54": {"line.1": {"text": "F\u00fcr Entwicklung seines Geistes", "tokens": ["F\u00fcr", "Ent\u00b7wick\u00b7lung", "sei\u00b7nes", "Geis\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sorgte fr\u00fch der strenge Vater,", "tokens": ["Sorg\u00b7te", "fr\u00fch", "der", "stren\u00b7ge", "Va\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Der den Unterricht begann", "tokens": ["Der", "den", "Un\u00b7ter\u00b7richt", "be\u00b7gann"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit dem Gottesbuch, der Thora.", "tokens": ["Mit", "dem", "Got\u00b7tes\u00b7buch", ",", "der", "Tho\u00b7ra", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.55": {"line.1": {"text": "Diese las er mit dem Sohne", "tokens": ["Die\u00b7se", "las", "er", "mit", "dem", "Soh\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In dem Urtext, dessen sch\u00f6ne,", "tokens": ["In", "dem", "Ur\u00b7text", ",", "des\u00b7sen", "sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Hieroglyphisch pittoreske,", "tokens": ["Hie\u00b7ro\u00b7gly\u00b7phisch", "pit\u00b7to\u00b7res\u00b7ke", ","], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Altchald\u00e4ische Quadratschrift", "tokens": ["Alt\u00b7chal\u00b7d\u00e4i\u00b7sche", "Quad\u00b7rat\u00b7schrift"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.56": {"line.1": {"text": "Herstammt aus dem Kindesalter", "tokens": ["Her\u00b7stammt", "aus", "dem", "Kin\u00b7de\u00b7sal\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Unsrer Welt, und auch deswegen", "tokens": ["Uns\u00b7rer", "Welt", ",", "und", "auch", "des\u00b7we\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "ADV", "PAV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jedem kindlichen Gem\u00fcte", "tokens": ["Je\u00b7dem", "kind\u00b7li\u00b7chen", "Ge\u00b7m\u00fc\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "So vertraut entgegenlacht.", "tokens": ["So", "ver\u00b7traut", "ent\u00b7ge\u00b7gen\u00b7lacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.57": {"line.1": {"text": "Diesen echten alten Text", "tokens": ["Die\u00b7sen", "ech\u00b7ten", "al\u00b7ten", "Text"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Rezitierte auch der Knabe", "tokens": ["Re\u00b7zi\u00b7tier\u00b7te", "auch", "der", "Kna\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der uralt hergebrachten", "tokens": ["In", "der", "ur\u00b7alt", "her\u00b7ge\u00b7brach\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Singsangweise, Tropp gehei\u00dfen \u2013", "tokens": ["Sings\u00b7ang\u00b7wei\u00b7se", ",", "Tropp", "ge\u00b7hei\u00b7\u00dfen", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Und er gurgelte gar lieblich", "tokens": ["Und", "er", "gur\u00b7gel\u00b7te", "gar", "lieb\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "ADJD"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Jene fetten Gutturalen,", "tokens": ["Je\u00b7ne", "fet\u00b7ten", "Gut\u00b7tu\u00b7ra\u00b7len", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und er schlug dabei den Triller,", "tokens": ["Und", "er", "schlug", "da\u00b7bei", "den", "Tril\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PAV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Den Schalscheleth, wie ein Vogel.", "tokens": ["Den", "Schal\u00b7sche\u00b7leth", ",", "wie", "ein", "Vo\u00b7gel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.59": {"line.1": {"text": "Auch den Targum Onkelos,", "tokens": ["Auch", "den", "Tar\u00b7gum", "On\u00b7ke\u00b7los", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der geschrieben ist in jenem", "tokens": ["Der", "ge\u00b7schrie\u00b7ben", "ist", "in", "je\u00b7nem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "VVPP", "VAFIN", "APPR", "PDAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Plattjud\u00e4ischen Idiom,", "tokens": ["Platt\u00b7ju\u00b7d\u00e4\u00b7i\u00b7schen", "I\u00b7diom", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das wir Aram\u00e4isch nennen", "tokens": ["Das", "wir", "A\u00b7ra\u00b7m\u00e4isch", "nen\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PPER", "NN", "VVINF"], "meter": "--+-+--", "measure": "anapaest.init"}}, "stanza.60": {"line.1": {"text": "Und zur Sprache der Propheten", "tokens": ["Und", "zur", "Spra\u00b7che", "der", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sich verhalten mag etwa", "tokens": ["Sich", "ver\u00b7hal\u00b7ten", "mag", "et\u00b7wa"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "VVINF", "VMFIN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie das Schw\u00e4bische zum Deutschen \u2013", "tokens": ["Wie", "das", "Schw\u00e4\u00b7bi\u00b7sche", "zum", "Deut\u00b7schen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPRART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Dieses Gelbveiglein-Hebr\u00e4isch", "tokens": ["Die\u00b7ses", "Gelb\u00b7veig\u00b7lein\u00b7He\u00b7br\u00e4\u00b7isch"], "token_info": ["word", "word"], "pos": ["PDAT", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.61": {"line.1": {"text": "Lernte gleichfalls fr\u00fch der Knabe,", "tokens": ["Lern\u00b7te", "gleich\u00b7falls", "fr\u00fch", "der", "Kna\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und es kam ihm solche Kenntnis", "tokens": ["Und", "es", "kam", "ihm", "sol\u00b7che", "Kennt\u00b7nis"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PPER", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bald darauf sehr gut zustatten", "tokens": ["Bald", "da\u00b7rauf", "sehr", "gut", "zu\u00b7stat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PAV", "ADV", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bei dem Studium des Talmuds.", "tokens": ["Bei", "dem", "Stu\u00b7di\u00b7um", "des", "Tal\u00b7muds", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.62": {"line.1": {"text": "Ja, fr\u00fchzeitig hat der Vater", "tokens": ["Ja", ",", "fr\u00fch\u00b7zei\u00b7tig", "hat", "der", "Va\u00b7ter"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "VAFIN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "ihn geleitet zu dem Talmud,", "tokens": ["ihn", "ge\u00b7lei\u00b7tet", "zu", "dem", "Tal\u00b7mud", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und da hat er ihm erschlossen", "tokens": ["Und", "da", "hat", "er", "ihm", "er\u00b7schlos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die Halacha, diese gro\u00dfe", "tokens": ["Die", "Ha\u00b7lac\u00b7ha", ",", "die\u00b7se", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$,", "PDAT", "ADJA"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.63": {"line.1": {"text": "Fechterschule, wo die besten", "tokens": ["Fech\u00b7ter\u00b7schu\u00b7le", ",", "wo", "die", "bes\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dialektischen Athleten", "tokens": ["Di\u00b7a\u00b7lek\u00b7ti\u00b7schen", "Ath\u00b7le\u00b7ten"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Babylons und Pumpedithas", "tokens": ["Ba\u00b7by\u00b7lons", "und", "Pum\u00b7pe\u00b7di\u00b7thas"], "token_info": ["word", "word", "word"], "pos": ["NE", "KON", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ihre K\u00e4mpferspiele trieben.", "tokens": ["Ih\u00b7re", "K\u00e4mp\u00b7fer\u00b7spie\u00b7le", "trie\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.64": {"line.1": {"text": "Lernen konnte hier der Knabe", "tokens": ["Ler\u00b7nen", "konn\u00b7te", "hier", "der", "Kna\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Alle K\u00fcnste der Polemik;", "tokens": ["Al\u00b7le", "K\u00fcns\u00b7te", "der", "Po\u00b7le\u00b7mik", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Seine Meisterschaft bezeugte", "tokens": ["Sei\u00b7ne", "Meis\u00b7ter\u00b7schaft", "be\u00b7zeug\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sp\u00e4terhin das Buch Cosari.", "tokens": ["Sp\u00e4\u00b7ter\u00b7hin", "das", "Buch", "Co\u00b7sa\u00b7ri", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "NE", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.65": {"line.1": {"text": "Doch der Himmel gie\u00dft herunter", "tokens": ["Doch", "der", "Him\u00b7mel", "gie\u00dft", "her\u00b7un\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwei verschiedne Sorten Lichtes:", "tokens": ["Zwei", "ver\u00b7schied\u00b7ne", "Sor\u00b7ten", "Lich\u00b7tes", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Grelles Tageslicht der Sonne", "tokens": ["Grel\u00b7les", "Ta\u00b7ges\u00b7licht", "der", "Son\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das mildre Mondlicht \u2013 Also,", "tokens": ["Und", "das", "mild\u00b7re", "Mond\u00b7licht", "\u2013", "Al\u00b7so", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$(", "PTKANT", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.66": {"line.1": {"text": "Also leuchtet auch der Talmud", "tokens": ["Al\u00b7so", "leuch\u00b7tet", "auch", "der", "Tal\u00b7mud"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwiefach, und man teilt ihn ein", "tokens": ["Zwie\u00b7fach", ",", "und", "man", "teilt", "ihn", "ein"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PIS", "VVFIN", "PPER", "ART"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "In Halacha und Hagada.", "tokens": ["In", "Ha\u00b7lac\u00b7ha", "und", "Ha\u00b7ga\u00b7da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstre nannt ich eine Fechtschul' \u2013", "tokens": ["Er\u00b7stre", "nannt", "ich", "ei\u00b7ne", "Fecht\u00b7schul'", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.67": {"line.1": {"text": "Letztre aber, die Hagada,", "tokens": ["Letz\u00b7tre", "a\u00b7ber", ",", "die", "Ha\u00b7ga\u00b7da", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "ADV", "$,", "PRELS", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Will ich einen Garten nennen,", "tokens": ["Will", "ich", "ei\u00b7nen", "Gar\u00b7ten", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Garten, hochphantastisch", "tokens": ["Ei\u00b7nen", "Gar\u00b7ten", ",", "hoch\u00b7phan\u00b7tas\u00b7tisch"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "NN", "$,", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und vergleichbar jenem andern,", "tokens": ["Und", "ver\u00b7gleich\u00b7bar", "je\u00b7nem", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PDAT", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.68": {"line.1": {"text": "Welcher ebenfalls dem Boden", "tokens": ["Wel\u00b7cher", "e\u00b7ben\u00b7falls", "dem", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Babylons entsprossen weiland \u2013", "tokens": ["Ba\u00b7by\u00b7lons", "ent\u00b7spros\u00b7sen", "wei\u00b7land", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Garten der Semiramis,", "tokens": ["Gar\u00b7ten", "der", "Se\u00b7mi\u00b7ra\u00b7mis", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Achtes Wunderwerk der Welt.", "tokens": ["Ach\u00b7tes", "Wun\u00b7der\u00b7werk", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.69": {"line.1": {"text": "K\u00f6nigin Semiramis,", "tokens": ["K\u00f6\u00b7ni\u00b7gin", "Se\u00b7mi\u00b7ra\u00b7mis", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die als Kind erzogen worden", "tokens": ["Die", "als", "Kind", "er\u00b7zo\u00b7gen", "wor\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "NN", "VVPP", "VAPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Von den V\u00f6geln, und gar manche", "tokens": ["Von", "den", "V\u00f6\u00b7geln", ",", "und", "gar", "man\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "KON", "ADV", "PIAT"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "V\u00f6gelt\u00fcmlichkeit bewahrte,", "tokens": ["V\u00f6\u00b7gel\u00b7t\u00fcm\u00b7lich\u00b7keit", "be\u00b7wahr\u00b7te", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.70": {"line.1": {"text": "Wollte nicht auf platter Erde", "tokens": ["Woll\u00b7te", "nicht", "auf", "plat\u00b7ter", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PTKNEG", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Promenieren wie wir andern", "tokens": ["Pro\u00b7me\u00b7nie\u00b7ren", "wie", "wir", "an\u00b7dern"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KOKOM", "PPER", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "S\u00e4ugetiere, und sie pflanzte", "tokens": ["S\u00e4u\u00b7ge\u00b7tie\u00b7re", ",", "und", "sie", "pflanz\u00b7te"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "KON", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Einen Garten in der Luft \u2013", "tokens": ["Ei\u00b7nen", "Gar\u00b7ten", "in", "der", "Luft", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.71": {"line.1": {"text": "Hoch auf kolossalen S\u00e4ulen", "tokens": ["Hoch", "auf", "ko\u00b7los\u00b7sa\u00b7len", "S\u00e4u\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "APPR", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Prangten Palmen und Zypressen,", "tokens": ["Prang\u00b7ten", "Pal\u00b7men", "und", "Zyp\u00b7res\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NE", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Goldorangen, Blumenbeete,", "tokens": ["Gol\u00b7do\u00b7ran\u00b7gen", ",", "Blu\u00b7men\u00b7bee\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Marmorbilder, auch Springbrunnen,", "tokens": ["Mar\u00b7mor\u00b7bil\u00b7der", ",", "auch", "Spring\u00b7brun\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.72": {"line.1": {"text": "Alles klug und fest verbunden", "tokens": ["Al\u00b7les", "klug", "und", "fest", "ver\u00b7bun\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "ADJD", "KON", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Durch unz\u00e4hl'ge H\u00e4ngebr\u00fccken,", "tokens": ["Durch", "un\u00b7z\u00e4hl'\u00b7ge", "H\u00e4n\u00b7ge\u00b7br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Die wie Schlingepflanzen aussahn", "tokens": ["Die", "wie", "Schlin\u00b7ge\u00b7pflan\u00b7zen", "aus\u00b7sahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "KOKOM", "NN", "VVIZU"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Und worauf sich V\u00f6gel wiegten \u2013", "tokens": ["Und", "wo\u00b7rauf", "sich", "V\u00f6\u00b7gel", "wieg\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PRF", "NN", "VVFIN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.73": {"line.1": {"text": "Gro\u00dfe, bunte, ernste V\u00f6gel,", "tokens": ["Gro\u00b7\u00dfe", ",", "bun\u00b7te", ",", "erns\u00b7te", "V\u00f6\u00b7gel", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Tiefe Denker, die nicht singen,", "tokens": ["Tie\u00b7fe", "Den\u00b7ker", ",", "die", "nicht", "sin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4hrend sie umflattert kleines", "tokens": ["W\u00e4h\u00b7rend", "sie", "um\u00b7flat\u00b7tert", "klei\u00b7nes"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zeisigvolk, das lustig trillert \u2013", "tokens": ["Zei\u00b7sig\u00b7volk", ",", "das", "lus\u00b7tig", "tril\u00b7lert", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.74": {"line.1": {"text": "Alle atmen ein, beseligt,", "tokens": ["Al\u00b7le", "at\u00b7men", "ein", ",", "be\u00b7se\u00b7ligt", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PIAT", "NN", "PTKVZ", "$,", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Einen reinen Balsamduft,", "tokens": ["Ei\u00b7nen", "rei\u00b7nen", "Bal\u00b7sam\u00b7duft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Welcher unvermischt mit schn\u00f6dem", "tokens": ["Wel\u00b7cher", "un\u00b7ver\u00b7mischt", "mit", "schn\u00f6\u00b7dem"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAT", "NN", "APPR", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Erdendunst und Mi\u00dfgeruche.", "tokens": ["Er\u00b7den\u00b7dunst", "und", "Mi\u00df\u00b7ge\u00b7ru\u00b7che", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "Die Hagada ist ein Garten", "tokens": ["Die", "Ha\u00b7ga\u00b7da", "ist", "ein", "Gar\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NE", "VAFIN", "ART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Solcher Luftkindgrillenart,", "tokens": ["Sol\u00b7cher", "Luft\u00b7kind\u00b7gril\u00b7len\u00b7art", ","], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und der junge Talmudsch\u00fcler,", "tokens": ["Und", "der", "jun\u00b7ge", "Tal\u00b7mud\u00b7sch\u00fc\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn sein Herze war best\u00e4ubet", "tokens": ["Wenn", "sein", "Her\u00b7ze", "war", "be\u00b7st\u00e4u\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VAFIN", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Und bet\u00e4ubet vom Gez\u00e4nke", "tokens": ["Und", "be\u00b7t\u00e4u\u00b7bet", "vom", "Ge\u00b7z\u00e4n\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Der Halacha, vom Dispute", "tokens": ["Der", "Ha\u00b7lac\u00b7ha", ",", "vom", "Dis\u00b7pu\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NE", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "\u00dcber das fatale Ei,", "tokens": ["\u00dc\u00b7ber", "das", "fa\u00b7ta\u00b7le", "Ei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Das ein Huhn gelegt am Festtag,", "tokens": ["Das", "ein", "Huhn", "ge\u00b7legt", "am", "Fest\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "APPRART", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.77": {"line.1": {"text": "Oder \u00fcber eine Frage", "tokens": ["O\u00b7der", "\u00fc\u00b7ber", "ei\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gleicher Importanz \u2013 der Knabe", "tokens": ["Glei\u00b7cher", "Im\u00b7por\u00b7tanz", "\u2013", "der", "Kna\u00b7be"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$(", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.3": {"text": "Floh alsdann, sich zu erfrischen,", "tokens": ["Floh", "als\u00b7dann", ",", "sich", "zu", "er\u00b7fri\u00b7schen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In die bl\u00fchende Hagada,", "tokens": ["In", "die", "bl\u00fc\u00b7hen\u00b7de", "Ha\u00b7ga\u00b7da", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.78": {"line.1": {"text": "Wo die sch\u00f6nen alten Sagen,", "tokens": ["Wo", "die", "sch\u00f6\u00b7nen", "al\u00b7ten", "Sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Engelm\u00e4rchen und Legenden,", "tokens": ["En\u00b7gel\u00b7m\u00e4r\u00b7chen", "und", "Le\u00b7gen\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "+-+--+--", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Stille M\u00e4rtyrerhistorien,", "tokens": ["Stil\u00b7le", "M\u00e4r\u00b7ty\u00b7rer\u00b7his\u00b7to\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$,"], "meter": "+-+--+---", "measure": "trochaic.tri.relaxed"}, "line.4": {"text": "Festges\u00e4nge, Weisheitspr\u00fcche,", "tokens": ["Fest\u00b7ge\u00b7s\u00e4n\u00b7ge", ",", "Weis\u00b7heits\u00b7pr\u00fc\u00b7che", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "Auch Hyperbeln, gar possierlich,", "tokens": ["Auch", "Hy\u00b7per\u00b7beln", ",", "gar", "pos\u00b7sier\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Alles aber glaubenskr\u00e4ftig,", "tokens": ["Al\u00b7les", "a\u00b7ber", "glau\u00b7bens\u00b7kr\u00e4f\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Glaubensgl\u00fchend \u2013 Oh, das gl\u00e4nzte,", "tokens": ["Glau\u00b7bens\u00b7gl\u00fc\u00b7hend", "\u2013", "Oh", ",", "das", "gl\u00e4nz\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$(", "ITJ", "$,", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Quoll und spro\u00df so \u00fcberschwenglich \u2013", "tokens": ["Quoll", "und", "spro\u00df", "so", "\u00fc\u00b7bersc\u00b7hweng\u00b7lich", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Und des Knaben edles Herze", "tokens": ["Und", "des", "Kna\u00b7ben", "ed\u00b7les", "Her\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ward ergriffen von der wilden,", "tokens": ["Ward", "er\u00b7grif\u00b7fen", "von", "der", "wil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Abenteuerlichen S\u00fc\u00dfe,", "tokens": ["A\u00b7bent\u00b7eu\u00b7er\u00b7li\u00b7chen", "S\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "Von der wundersamen Schmerzlust", "tokens": ["Von", "der", "wun\u00b7der\u00b7sa\u00b7men", "Schmerz\u00b7lust"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "Und den fabelhaften Schauern", "tokens": ["Und", "den", "fa\u00b7bel\u00b7haf\u00b7ten", "Schau\u00b7ern"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Jener seligen Geheimwelt,", "tokens": ["Je\u00b7ner", "se\u00b7li\u00b7gen", "Ge\u00b7heim\u00b7welt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener gro\u00dfen Offenbarung,", "tokens": ["Je\u00b7ner", "gro\u00b7\u00dfen", "Of\u00b7fen\u00b7ba\u00b7rung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die wir nennen Poesie.", "tokens": ["Die", "wir", "nen\u00b7nen", "Poe\u00b7sie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "NN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.82": {"line.1": {"text": "Auch die Kunst der Poesie,", "tokens": ["Auch", "die", "Kunst", "der", "Poe\u00b7sie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heitres Wissen, holdes K\u00f6nnen,", "tokens": ["Heit\u00b7res", "Wis\u00b7sen", ",", "hol\u00b7des", "K\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welches wir die Dichtkunst hei\u00dfen,", "tokens": ["Wel\u00b7ches", "wir", "die", "Dicht\u00b7kunst", "hei\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tat sich auf dem Sinn des Knaben.", "tokens": ["Tat", "sich", "auf", "dem", "Sinn", "des", "Kna\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.83": {"line.1": {"text": "Und Jehuda ben Halevy", "tokens": ["Und", "Je\u00b7hu\u00b7da", "ben", "Ha\u00b7le\u00b7vy"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward nicht blo\u00df ein Schriftgelehrter,", "tokens": ["Ward", "nicht", "blo\u00df", "ein", "Schrift\u00b7ge\u00b7lehr\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Sondern auch der Dichtkunst Meister,", "tokens": ["Son\u00b7dern", "auch", "der", "Dicht\u00b7kunst", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sondern auch ein gro\u00dfer Dichter.", "tokens": ["Son\u00b7dern", "auch", "ein", "gro\u00b7\u00dfer", "Dich\u00b7ter."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["KON", "ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.84": {"line.1": {"text": "Ja, er ward ein gro\u00dfer Dichter,", "tokens": ["Ja", ",", "er", "ward", "ein", "gro\u00b7\u00dfer", "Dich\u00b7ter", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Stern und Fackel seiner Zeit,", "tokens": ["Stern", "und", "Fa\u00b7ckel", "sei\u00b7ner", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Seines Volkes Licht und Leuchte,", "tokens": ["Sei\u00b7nes", "Vol\u00b7kes", "Licht", "und", "Leuch\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eine wunderbare, gro\u00dfe", "tokens": ["Ei\u00b7ne", "wun\u00b7der\u00b7ba\u00b7re", ",", "gro\u00b7\u00dfe"], "token_info": ["word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.85": {"line.1": {"text": "Feuers\u00e4ule des Gesanges,", "tokens": ["Feu\u00b7er\u00b7s\u00e4u\u00b7le", "des", "Ge\u00b7san\u00b7ges", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Die der Schmerzenskarawane", "tokens": ["Die", "der", "Schmer\u00b7zens\u00b7ka\u00b7ra\u00b7wa\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ART", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Israels vorangezogen", "tokens": ["Is\u00b7raels", "vor\u00b7an\u00b7ge\u00b7zo\u00b7gen"], "token_info": ["word", "word"], "pos": ["NE", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In der W\u00fcste des Exils.", "tokens": ["In", "der", "W\u00fcs\u00b7te", "des", "E\u00b7xils", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.86": {"line.1": {"text": "Rein und wahrhaft, sonder Makel", "tokens": ["Rein", "und", "wahr\u00b7haft", ",", "son\u00b7der", "Ma\u00b7kel"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "ADV", "$,", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "War sein Lied, wie seine Seele \u2013", "tokens": ["War", "sein", "Lied", ",", "wie", "sei\u00b7ne", "See\u00b7le", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "$,", "PWAV", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Als der Sch\u00f6pfer sie erschaffen,", "tokens": ["Als", "der", "Sch\u00f6p\u00b7fer", "sie", "er\u00b7schaf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Diese Seele, selbstzufrieden", "tokens": ["Die\u00b7se", "See\u00b7le", ",", "selbst\u00b7zu\u00b7frie\u00b7den"], "token_info": ["word", "word", "punct", "word"], "pos": ["PDAT", "NN", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.87": {"line.1": {"text": "K\u00fc\u00dfte er die sch\u00f6ne Seele,", "tokens": ["K\u00fc\u00df\u00b7te", "er", "die", "sch\u00f6\u00b7ne", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und des Kusses holder Nachklang", "tokens": ["Und", "des", "Kus\u00b7ses", "hol\u00b7der", "Nach\u00b7klang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Bebt in jedem Lied des Dichters,", "tokens": ["Bebt", "in", "je\u00b7dem", "Lied", "des", "Dich\u00b7ters", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PIAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das geweiht durch diese Gnade.", "tokens": ["Das", "ge\u00b7weiht", "durch", "die\u00b7se", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.88": {"line.1": {"text": "Wie im Leben, so im Dichten", "tokens": ["Wie", "im", "Le\u00b7ben", ",", "so", "im", "Dich\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "$,", "ADV", "APPRART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.2": {"text": "Ist das h\u00f6chste Gut die Gnade \u2013", "tokens": ["Ist", "das", "h\u00f6chs\u00b7te", "Gut", "die", "Gna\u00b7de", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer sie hat, der kann nicht s\u00fcnd'gen,", "tokens": ["Wer", "sie", "hat", ",", "der", "kann", "nicht", "s\u00fcn\u00b7d'\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VAFIN", "$,", "PRELS", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "--+-++-+-", "measure": "anapaest.init"}, "line.4": {"text": "Nicht in Versen, noch in Prosa.", "tokens": ["Nicht", "in", "Ver\u00b7sen", ",", "noch", "in", "Pro\u00b7sa", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "NN", "$,", "ADV", "APPR", "NN", "$."], "meter": "+-+-++-+", "measure": "unknown.measure.penta"}}, "stanza.89": {"line.1": {"text": "Solchen Dichter von der Gnade", "tokens": ["Sol\u00b7chen", "Dich\u00b7ter", "von", "der", "Gna\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Gottes nennen wir Genie:", "tokens": ["Got\u00b7tes", "nen\u00b7nen", "wir", "Ge\u00b7nie", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "$."], "meter": "+---+-+", "measure": "dactylic.init"}, "line.3": {"text": "Unverantwortlicher K\u00f6nig", "tokens": ["Un\u00b7ver\u00b7ant\u00b7wort\u00b7li\u00b7cher", "K\u00f6\u00b7nig"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Des Gedankenreiches ist er.", "tokens": ["Des", "Ge\u00b7dan\u00b7ken\u00b7rei\u00b7ches", "ist", "er", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.90": {"line.1": {"text": "Nur dem Gotte steht er Rede,", "tokens": ["Nur", "dem", "Got\u00b7te", "steht", "er", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nicht dem Volke \u2013 In der Kunst,", "tokens": ["Nicht", "dem", "Vol\u00b7ke", "\u2013", "In", "der", "Kunst", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$(", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie im Leben, kann das Volk", "tokens": ["Wie", "im", "Le\u00b7ben", ",", "kann", "das", "Volk"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "APPRART", "NN", "$,", "VMFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "T\u00f6ten uns, doch niemals richten. \u2013", "tokens": ["T\u00f6\u00b7ten", "uns", ",", "doch", "nie\u00b7mals", "rich\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}