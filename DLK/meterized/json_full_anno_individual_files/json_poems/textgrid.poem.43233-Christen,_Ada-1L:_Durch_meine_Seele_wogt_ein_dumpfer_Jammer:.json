{"textgrid.poem.43233": {"metadata": {"author": {"name": "Christen, Ada", "birth": "N.A.", "death": "N.A."}, "title": "1L: Durch meine Seele wogt ein dumpfer Jammer:", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Durch meine Seele wogt ein dumpfer Jammer:", "tokens": ["Durch", "mei\u00b7ne", "See\u00b7le", "wogt", "ein", "dum\u00b7pfer", "Jam\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein junges Weib mit sch\u00f6nen, welken Z\u00fcgen,", "tokens": ["Ein", "jun\u00b7ges", "Weib", "mit", "sch\u00f6\u00b7nen", ",", "wel\u00b7ken", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "$,", "PWAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Todeszeichen, welche nimmer tr\u00fcgen,", "tokens": ["Mit", "To\u00b7des\u00b7zei\u00b7chen", ",", "wel\u00b7che", "nim\u00b7mer", "tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Liegt leise weinend in der kleinen Kammer.", "tokens": ["Liegt", "lei\u00b7se", "wei\u00b7nend", "in", "der", "klei\u00b7nen", "Kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ich fand sie heute noch vor Tages Grauen,", "tokens": ["Ich", "fand", "sie", "heu\u00b7te", "noch", "vor", "Ta\u00b7ges", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Hunde schlugen an vor einem Graben,", "tokens": ["Die", "Hun\u00b7de", "schlu\u00b7gen", "an", "vor", "ei\u00b7nem", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie lag wie todt, ich suchte sie zu laben,", "tokens": ["Sie", "lag", "wie", "todt", ",", "ich", "such\u00b7te", "sie", "zu", "la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und trug sie heim durch nebelfeuchte Auen.", "tokens": ["Und", "trug", "sie", "heim", "durch", "ne\u00b7bel\u00b7feuch\u00b7te", "Au\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ein Kn\u00e4blein hatte sie im Arme hangen,", "tokens": ["Ein", "Kn\u00e4\u00b7blein", "hat\u00b7te", "sie", "im", "Ar\u00b7me", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Kind mit tiefen, sonderbaren Blicken \u2013", "tokens": ["Ein", "Kind", "mit", "tie\u00b7fen", ",", "son\u00b7der\u00b7ba\u00b7ren", "Bli\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich mahnt an Dich sein L\u00e4cheln wie sein Nicken,", "tokens": ["Mich", "mahnt", "an", "Dich", "sein", "L\u00e4\u00b7cheln", "wie", "sein", "Ni\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dir gleicht das Antlitz mit den bleichen Wangen.", "tokens": ["Dir", "gleicht", "das", "Ant\u00b7litz", "mit", "den", "blei\u00b7chen", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ein w\u00fcster Mann hat dieses Weib verlassen;", "tokens": ["Ein", "w\u00fcs\u00b7ter", "Mann", "hat", "die\u00b7ses", "Weib", "ver\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er kam hierher, um Gold, um Gl\u00fcck zu suchen \u2013", "tokens": ["Er", "kam", "hier\u00b7her", ",", "um", "Gold", ",", "um", "Gl\u00fcck", "zu", "su\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,", "KOUI", "NN", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er fand nur Hunger, lernte bald verfluchen", "tokens": ["Er", "fand", "nur", "Hun\u00b7ger", ",", "lern\u00b7te", "bald", "ver\u00b7flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die karge Erde und die Menschen hassen.", "tokens": ["Die", "kar\u00b7ge", "Er\u00b7de", "und", "die", "Men\u00b7schen", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Er ging von ihr. \u2013 Ob er das Gl\u00fcck gefunden,", "tokens": ["Er", "ging", "von", "ihr", ".", "\u2013", "Ob", "er", "das", "Gl\u00fcck", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "$.", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob er sie lie\u00df, um einsam zu verderben?", "tokens": ["Ob", "er", "sie", "lie\u00df", ",", "um", "ein\u00b7sam", "zu", "ver\u00b7der\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "KOUI", "ADJD", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie wei\u00df es nicht. \u2013 Sie wird verlassen sterben", "tokens": ["Sie", "wei\u00df", "es", "nicht", ".", "\u2013", "Sie", "wird", "ver\u00b7las\u00b7sen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "PPER", "VAFIN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An Noth und Elend und an Herzenswunden.", "tokens": ["An", "Noth", "und", "E\u00b7lend", "und", "an", "Her\u00b7zens\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Schon zucken um den Mund die grauen Schatten,", "tokens": ["Schon", "zu\u00b7cken", "um", "den", "Mund", "die", "grau\u00b7en", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und bald mit s\u00fc\u00dfen, liebeweichen T\u00f6nen,", "tokens": ["Und", "bald", "mit", "s\u00fc\u00b7\u00dfen", ",", "lie\u00b7be\u00b7wei\u00b7chen", "T\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und bald mit Schluchzen, angstvoll hei\u00dfem St\u00f6hnen,", "tokens": ["Und", "bald", "mit", "Schluch\u00b7zen", ",", "angst\u00b7voll", "hei\u00b7\u00dfem", "St\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem\u00fcthig stets, ruft sie nach ihrem Gatten ...", "tokens": ["De\u00b7m\u00fct\u00b7hig", "stets", ",", "ruft", "sie", "nach", "ih\u00b7rem", "Gat\u00b7ten", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Durch meine Seele wogt ein dumpfer Jammer:", "tokens": ["Durch", "mei\u00b7ne", "See\u00b7le", "wogt", "ein", "dum\u00b7pfer", "Jam\u00b7mer", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein junges Weib mit sch\u00f6nen, welken Z\u00fcgen,", "tokens": ["Ein", "jun\u00b7ges", "Weib", "mit", "sch\u00f6\u00b7nen", ",", "wel\u00b7ken", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "$,", "PWAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Todeszeichen, welche nimmer tr\u00fcgen,", "tokens": ["Mit", "To\u00b7des\u00b7zei\u00b7chen", ",", "wel\u00b7che", "nim\u00b7mer", "tr\u00fc\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Liegt leise weinend in der kleinen Kammer.", "tokens": ["Liegt", "lei\u00b7se", "wei\u00b7nend", "in", "der", "klei\u00b7nen", "Kam\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "VVPP", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ich fand sie heute noch vor Tages Grauen,", "tokens": ["Ich", "fand", "sie", "heu\u00b7te", "noch", "vor", "Ta\u00b7ges", "Grau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Hunde schlugen an vor einem Graben,", "tokens": ["Die", "Hun\u00b7de", "schlu\u00b7gen", "an", "vor", "ei\u00b7nem", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie lag wie todt, ich suchte sie zu laben,", "tokens": ["Sie", "lag", "wie", "todt", ",", "ich", "such\u00b7te", "sie", "zu", "la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ADJD", "$,", "PPER", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und trug sie heim durch nebelfeuchte Auen.", "tokens": ["Und", "trug", "sie", "heim", "durch", "ne\u00b7bel\u00b7feuch\u00b7te", "Au\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Ein Kn\u00e4blein hatte sie im Arme hangen,", "tokens": ["Ein", "Kn\u00e4\u00b7blein", "hat\u00b7te", "sie", "im", "Ar\u00b7me", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ein Kind mit tiefen, sonderbaren Blicken \u2013", "tokens": ["Ein", "Kind", "mit", "tie\u00b7fen", ",", "son\u00b7der\u00b7ba\u00b7ren", "Bli\u00b7cken", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "$,", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich mahnt an Dich sein L\u00e4cheln wie sein Nicken,", "tokens": ["Mich", "mahnt", "an", "Dich", "sein", "L\u00e4\u00b7cheln", "wie", "sein", "Ni\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "PPOSAT", "NN", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dir gleicht das Antlitz mit den bleichen Wangen.", "tokens": ["Dir", "gleicht", "das", "Ant\u00b7litz", "mit", "den", "blei\u00b7chen", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Ein w\u00fcster Mann hat dieses Weib verlassen;", "tokens": ["Ein", "w\u00fcs\u00b7ter", "Mann", "hat", "die\u00b7ses", "Weib", "ver\u00b7las\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PDAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Er kam hierher, um Gold, um Gl\u00fcck zu suchen \u2013", "tokens": ["Er", "kam", "hier\u00b7her", ",", "um", "Gold", ",", "um", "Gl\u00fcck", "zu", "su\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,", "KOUI", "NN", "$,", "KOUI", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er fand nur Hunger, lernte bald verfluchen", "tokens": ["Er", "fand", "nur", "Hun\u00b7ger", ",", "lern\u00b7te", "bald", "ver\u00b7flu\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "NN", "$,", "VVFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die karge Erde und die Menschen hassen.", "tokens": ["Die", "kar\u00b7ge", "Er\u00b7de", "und", "die", "Men\u00b7schen", "has\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Er ging von ihr. \u2013 Ob er das Gl\u00fcck gefunden,", "tokens": ["Er", "ging", "von", "ihr", ".", "\u2013", "Ob", "er", "das", "Gl\u00fcck", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "$.", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob er sie lie\u00df, um einsam zu verderben?", "tokens": ["Ob", "er", "sie", "lie\u00df", ",", "um", "ein\u00b7sam", "zu", "ver\u00b7der\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "KOUI", "ADJD", "PTKZU", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Sie wei\u00df es nicht. \u2013 Sie wird verlassen sterben", "tokens": ["Sie", "wei\u00df", "es", "nicht", ".", "\u2013", "Sie", "wird", "ver\u00b7las\u00b7sen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "$(", "PPER", "VAFIN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "An Noth und Elend und an Herzenswunden.", "tokens": ["An", "Noth", "und", "E\u00b7lend", "und", "an", "Her\u00b7zens\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Schon zucken um den Mund die grauen Schatten,", "tokens": ["Schon", "zu\u00b7cken", "um", "den", "Mund", "die", "grau\u00b7en", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und bald mit s\u00fc\u00dfen, liebeweichen T\u00f6nen,", "tokens": ["Und", "bald", "mit", "s\u00fc\u00b7\u00dfen", ",", "lie\u00b7be\u00b7wei\u00b7chen", "T\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und bald mit Schluchzen, angstvoll hei\u00dfem St\u00f6hnen,", "tokens": ["Und", "bald", "mit", "Schluch\u00b7zen", ",", "angst\u00b7voll", "hei\u00b7\u00dfem", "St\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "$,", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem\u00fcthig stets, ruft sie nach ihrem Gatten ...", "tokens": ["De\u00b7m\u00fct\u00b7hig", "stets", ",", "ruft", "sie", "nach", "ih\u00b7rem", "Gat\u00b7ten", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "$,", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}