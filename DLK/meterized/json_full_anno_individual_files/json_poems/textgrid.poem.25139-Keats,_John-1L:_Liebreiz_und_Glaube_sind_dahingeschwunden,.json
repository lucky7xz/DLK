{"textgrid.poem.25139": {"metadata": {"author": {"name": "Keats, John", "birth": "N.A.", "death": "N.A."}, "title": "1L: Liebreiz und Glaube sind dahingeschwunden,", "genre": "verse", "period": "N.A.", "pub_year": 1817, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Liebreiz und Glaube sind dahingeschwunden,", "tokens": ["Lieb\u00b7reiz", "und", "Glau\u00b7be", "sind", "da\u00b7hin\u00b7ge\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Denn ziehn wir jetzt aufs freie Feld hinaus,", "tokens": ["Denn", "ziehn", "wir", "jetzt", "aufs", "frei\u00b7e", "Feld", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "APZR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gr\u00fc\u00dft kein Altar, drauf Kranz und Blumenstrau\u00df", "tokens": ["Gr\u00fc\u00dft", "kein", "Al\u00b7tar", ",", "drauf", "Kranz", "und", "Blu\u00b7men\u00b7strau\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PAV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Als frommes Opfer frohen Tod gefunden.", "tokens": ["Als", "from\u00b7mes", "Op\u00b7fer", "fro\u00b7hen", "Tod", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Und keine M\u00e4dchen ziehn in ersten Stunden", "tokens": ["Und", "kei\u00b7ne", "M\u00e4d\u00b7chen", "ziehn", "in", "ers\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Tags auf Floras weites Land heraus,", "tokens": ["Des", "Tags", "auf", "Flo\u00b7ras", "wei\u00b7tes", "Land", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit Rosen, Veilchen, Korn und Blattgekraus", "tokens": ["Mit", "Ro\u00b7sen", ",", "Veil\u00b7chen", ",", "Korn", "und", "Blatt\u00b7ge\u00b7kraus"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem Mai den Dank der Jugend zu bekunden.", "tokens": ["Dem", "Mai", "den", "Dank", "der", "Ju\u00b7gend", "zu", "be\u00b7kun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Doch andre Lust \u2013 und gr\u00f6\u00dfre \u2013 bleibt zu pfl\u00fccken", "tokens": ["Doch", "and\u00b7re", "Lust", "\u2013", "und", "gr\u00f6\u00df\u00b7re", "\u2013", "bleibt", "zu", "pfl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$(", "KON", "VVFIN", "$(", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wird auf meinen Weg mir Blumen streuen:", "tokens": ["Und", "wird", "auf", "mei\u00b7nen", "Weg", "mir", "Blu\u00b7men", "streu\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vermag auch heut kein Pan mehr zu entz\u00fccken,", "tokens": ["Ver\u00b7mag", "auch", "heut", "kein", "Pan", "mehr", "zu", "ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "So wird doch tiefre Freude mich erneuen,", "tokens": ["So", "wird", "doch", "tief\u00b7re", "Freu\u00b7de", "mich", "er\u00b7neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJA", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00fc\u00dft' ich mit dieser Gabe zu begl\u00fccken", "tokens": ["W\u00fc\u00dft'", "ich", "mit", "die\u00b7ser", "Ga\u00b7be", "zu", "be\u00b7gl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und einen Mann wie du bist zu erfreuen.", "tokens": ["Und", "ei\u00b7nen", "Mann", "wie", "du", "bist", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KOKOM", "PPER", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Liebreiz und Glaube sind dahingeschwunden,", "tokens": ["Lieb\u00b7reiz", "und", "Glau\u00b7be", "sind", "da\u00b7hin\u00b7ge\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Denn ziehn wir jetzt aufs freie Feld hinaus,", "tokens": ["Denn", "ziehn", "wir", "jetzt", "aufs", "frei\u00b7e", "Feld", "hin\u00b7aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN", "APZR", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gr\u00fc\u00dft kein Altar, drauf Kranz und Blumenstrau\u00df", "tokens": ["Gr\u00fc\u00dft", "kein", "Al\u00b7tar", ",", "drauf", "Kranz", "und", "Blu\u00b7men\u00b7strau\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PIAT", "NN", "$,", "PAV", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Als frommes Opfer frohen Tod gefunden.", "tokens": ["Als", "from\u00b7mes", "Op\u00b7fer", "fro\u00b7hen", "Tod", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und keine M\u00e4dchen ziehn in ersten Stunden", "tokens": ["Und", "kei\u00b7ne", "M\u00e4d\u00b7chen", "ziehn", "in", "ers\u00b7ten", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Des Tags auf Floras weites Land heraus,", "tokens": ["Des", "Tags", "auf", "Flo\u00b7ras", "wei\u00b7tes", "Land", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Mit Rosen, Veilchen, Korn und Blattgekraus", "tokens": ["Mit", "Ro\u00b7sen", ",", "Veil\u00b7chen", ",", "Korn", "und", "Blatt\u00b7ge\u00b7kraus"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dem Mai den Dank der Jugend zu bekunden.", "tokens": ["Dem", "Mai", "den", "Dank", "der", "Ju\u00b7gend", "zu", "be\u00b7kun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Doch andre Lust \u2013 und gr\u00f6\u00dfre \u2013 bleibt zu pfl\u00fccken", "tokens": ["Doch", "and\u00b7re", "Lust", "\u2013", "und", "gr\u00f6\u00df\u00b7re", "\u2013", "bleibt", "zu", "pfl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$(", "KON", "VVFIN", "$(", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und wird auf meinen Weg mir Blumen streuen:", "tokens": ["Und", "wird", "auf", "mei\u00b7nen", "Weg", "mir", "Blu\u00b7men", "streu\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Vermag auch heut kein Pan mehr zu entz\u00fccken,", "tokens": ["Ver\u00b7mag", "auch", "heut", "kein", "Pan", "mehr", "zu", "ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "So wird doch tiefre Freude mich erneuen,", "tokens": ["So", "wird", "doch", "tief\u00b7re", "Freu\u00b7de", "mich", "er\u00b7neu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADJA", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00fc\u00dft' ich mit dieser Gabe zu begl\u00fccken", "tokens": ["W\u00fc\u00dft'", "ich", "mit", "die\u00b7ser", "Ga\u00b7be", "zu", "be\u00b7gl\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und einen Mann wie du bist zu erfreuen.", "tokens": ["Und", "ei\u00b7nen", "Mann", "wie", "du", "bist", "zu", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "KOKOM", "PPER", "VAFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}