{"textgrid.poem.62646": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "Auf einen in der Arzeney erhaltenen Doctor-Hut", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie? irr ich? mag das Alterthum,", "tokens": ["Wie", "?", "irr", "ich", "?", "mag", "das", "Al\u00b7ter\u00b7thum", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "NN", "PPER", "$.", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und die mit Silber-Haaren prangen,", "tokens": ["Und", "die", "mit", "Sil\u00b7ber\u00b7Haa\u00b7ren", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wissenschaften und den Ruhm", "tokens": ["Die", "Wis\u00b7sen\u00b7schaf\u00b7ten", "und", "den", "Ruhm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur einzig und allein zum Eigenthum erlangen?", "tokens": ["Nur", "ein\u00b7zig", "und", "al\u00b7lein", "zum", "Ei\u00b7gen\u00b7thum", "er\u00b7lan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Soll denn Hyg\u00e4ens zarter Sohn", "tokens": ["Soll", "denn", "Hy\u00b7g\u00e4\u00b7ens", "zar\u00b7ter", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Wissenschaft nicht auch erforschen k\u00f6nnen?", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "nicht", "auch", "er\u00b7for\u00b7schen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ist ihn nicht gleicher Rang zu g\u00f6nnen?", "tokens": ["Ist", "ihn", "nicht", "glei\u00b7cher", "Rang", "zu", "g\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wahr ", "tokens": ["So", "wahr"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "So wahr mu\u00df man die\u00df Recht auch jungen Aerzten lassen.", "tokens": ["So", "wahr", "mu\u00df", "man", "die\u00df", "Recht", "auch", "jun\u00b7gen", "A\u00b7erz\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PIS", "PDS", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "Man saget zwar: Ein graues Haupt", "tokens": ["Man", "sa\u00b7get", "zwar", ":", "Ein", "grau\u00b7es", "Haupt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4chst mit den Jahren auch an Wissen,", "tokens": ["W\u00e4chst", "mit", "den", "Jah\u00b7ren", "auch", "an", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und was so mancher Sinn nicht glaubt,", "tokens": ["Und", "was", "so", "man\u00b7cher", "Sinn", "nicht", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PIAT", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das zeigt sein kluger Mund in Rathen und in Schl\u00fcssen.", "tokens": ["Das", "zeigt", "sein", "klu\u00b7ger", "Mund", "in", "Ra\u00b7then", "und", "in", "Schl\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Amt ziert die Bedachtsamkeit,", "tokens": ["Sein", "Amt", "ziert", "die", "Be\u00b7dacht\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er sorgt mit Flei\u00df den Schaden zu bek\u00e4mpfen,", "tokens": ["Er", "sorgt", "mit", "Flei\u00df", "den", "Scha\u00b7den", "zu", "be\u00b7k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Zu hindern, wehren und zu d\u00e4mpfen;", "tokens": ["Zu", "hin\u00b7dern", ",", "weh\u00b7ren", "und", "zu", "d\u00e4mp\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Daher so Gunst als Gl\u00fcck ihm stets die H\u00e4nde beut;", "tokens": ["Da\u00b7her", "so", "Gunst", "als", "Gl\u00fcck", "ihm", "stets", "die", "H\u00e4n\u00b7de", "beut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "KOUS", "NN", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, man ergiebt sich ihm in allen,", "tokens": ["Ja", ",", "man", "er\u00b7giebt", "sich", "ihm", "in", "al\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PIS", "VVFIN", "PRF", "PPER", "APPR", "PIAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und l\u00e4\u00dft sich seinen Rath und F\u00fchrung wohlgefallen.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "sei\u00b7nen", "Rath", "und", "F\u00fch\u00b7rung", "wohl\u00b7ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Wissenschaft pflegt ordentlich", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "pflegt", "or\u00b7dent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Ehren-Herold abzugeben;", "tokens": ["Den", "Eh\u00b7ren\u00b7He\u00b7rold", "ab\u00b7zu\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum mu\u00df, (die Weisheit steigt durch sich,)", "tokens": ["Drum", "mu\u00df", ",", "(", "die", "Weis\u00b7heit", "steigt", "durch", "sich", ",", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VMFIN", "$,", "$(", "ART", "NN", "VVFIN", "APPR", "PRF", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein solch erfahrnes Haupt in hohen Ansehn schweben.", "tokens": ["Ein", "solch", "er\u00b7fahr\u00b7nes", "Haupt", "in", "ho\u00b7hen", "An\u00b7sehn", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein solcher schwingt sich nach und nach", "tokens": ["Ein", "sol\u00b7cher", "schwingt", "sich", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seinem Fu\u00df auf gr\u00f6\u00dfre Ehren Spitzen,", "tokens": ["Mit", "sei\u00b7nem", "Fu\u00df", "auf", "gr\u00f6\u00df\u00b7re", "Eh\u00b7ren", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Man sieht ihn neben F\u00fcrsten sitzen;", "tokens": ["Man", "sieht", "ihn", "ne\u00b7ben", "F\u00fcrs\u00b7ten", "sit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So, da\u00df er noch zuletzt das finstere Gemach", "tokens": ["So", ",", "da\u00df", "er", "noch", "zu\u00b7letzt", "das", "fins\u00b7te\u00b7re", "Ge\u00b7mach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit viel und grossen Ruhm erlanget,", "tokens": ["Mit", "viel", "und", "gros\u00b7sen", "Ruhm", "er\u00b7lan\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und als ein weiser Mann auch noch im Grabe pranget.", "tokens": ["Und", "als", "ein", "wei\u00b7ser", "Mann", "auch", "noch", "im", "Gra\u00b7be", "pran\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Hingegen heists: hat Mevius,", "tokens": ["Hin\u00b7ge\u00b7gen", "heists", ":", "hat", "Me\u00b7vius", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der noch nicht zweymahl funfzehn tr\u00e4get,", "tokens": ["Der", "noch", "nicht", "zwey\u00b7mahl", "funf\u00b7zehn", "tr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Kr\u00e4uter, jeden Spiritus,", "tokens": ["Die", "Kr\u00e4u\u00b7ter", ",", "je\u00b7den", "Spi\u00b7ri\u00b7tus", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den ganzen Krankheits-Schwarm erforscht und \u00fcberleget?", "tokens": ["Den", "gan\u00b7zen", "Krank\u00b7heits\u00b7Schwarm", "er\u00b7forscht", "und", "\u00fc\u00b7ber\u00b7le\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, nein, er hat noch nicht genug", "tokens": ["Nein", ",", "nein", ",", "er", "hat", "noch", "nicht", "ge\u00b7nug"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hyg\u00e4ens Reich und Schulen durchgegangen,", "tokens": ["Hy\u00b7g\u00e4\u00b7ens", "Reich", "und", "Schu\u00b7len", "durch\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und ihr nach W\u00fcrden angehangen.", "tokens": ["Und", "ihr", "nach", "W\u00fcr\u00b7den", "an\u00b7ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer will sich ihm vertraun? Die Welt w\u00e4r ja zu klug,", "tokens": ["Wer", "will", "sich", "ihm", "ver\u00b7traun", "?", "Die", "Welt", "w\u00e4r", "ja", "zu", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "PPER", "VVINF", "$.", "ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn sie sich recht mit Flei\u00df betr\u00f6ge,", "tokens": ["Wenn", "sie", "sich", "recht", "mit", "Flei\u00df", "be\u00b7tr\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und einen jungen Arzt in Noth zu Rathe z\u00f6ge.", "tokens": ["Und", "ei\u00b7nen", "jun\u00b7gen", "Arzt", "in", "Noth", "zu", "Ra\u00b7the", "z\u00f6\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "In B\u00e4rten wird wohl ohne Streit", "tokens": ["In", "B\u00e4r\u00b7ten", "wird", "wohl", "oh\u00b7ne", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr Witz und mehr Erk\u00e4ntni\u00df stecken;", "tokens": ["Mehr", "Witz", "und", "mehr", "Er\u00b7k\u00e4nt\u00b7ni\u00df", "ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und folglich mu\u00df das Ehren-Kleid", "tokens": ["Und", "folg\u00b7lich", "mu\u00df", "das", "Eh\u00b7ren\u00b7Kleid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch nur den kalten Leib betagter M\u00e4nner decken.", "tokens": ["Auch", "nur", "den", "kal\u00b7ten", "Leib", "be\u00b7tag\u00b7ter", "M\u00e4n\u00b7ner", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur \u00e4chte K\u00e4mpfer kriegen Lohn,", "tokens": ["Nur", "\u00e4ch\u00b7te", "K\u00e4mp\u00b7fer", "krie\u00b7gen", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Streiter, die, so stark sie nur vermochten,", "tokens": ["Und", "Strei\u00b7ter", ",", "die", ",", "so", "stark", "sie", "nur", "ver\u00b7moch\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "$,", "ADV", "ADJD", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor andrer Wohl und Gl\u00fcck gefochten,", "tokens": ["Vor", "an\u00b7drer", "Wohl", "und", "Gl\u00fcck", "ge\u00b7foch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die tragen Ruhm und Lob und W\u00fcrdigkeit davon.", "tokens": ["Die", "tra\u00b7gen", "Ruhm", "und", "Lob", "und", "W\u00fcr\u00b7dig\u00b7keit", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So, wie ein Unterscheid in Gaben;", "tokens": ["So", ",", "wie", "ein", "Un\u00b7ter\u00b7scheid", "in", "Ga\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So mu\u00df das Alterthum auch einges Vorrecht haben.", "tokens": ["So", "mu\u00df", "das", "Al\u00b7ter\u00b7thum", "auch", "ein\u00b7ges", "Vor\u00b7recht", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gemach! gemach! die\u00df harte Wort", "tokens": ["Ge\u00b7mach", "!", "ge\u00b7mach", "!", "die\u00df", "har\u00b7te", "Wort"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Lauft der Erfahrung stracks zuwider.", "tokens": ["Lauft", "der", "Er\u00b7fah\u00b7rung", "stracks", "zu\u00b7wi\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Wie mancher Grau-Kopf hier und dort", "tokens": ["Wie", "man\u00b7cher", "Grau\u00b7Kopf", "hier", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ist am Verstand ein Kind, und hat doch starre Glieder.", "tokens": ["Ist", "am", "Ver\u00b7stand", "ein", "Kind", ",", "und", "hat", "doch", "star\u00b7re", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ART", "NN", "$,", "KON", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df ist wohl wahr, das Alterthum", "tokens": ["Die\u00df", "ist", "wohl", "wahr", ",", "das", "Al\u00b7ter\u00b7thum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ist oftermahls durch Ubung weit gekommen,", "tokens": ["Ist", "of\u00b7ter\u00b7mahls", "durch", "U\u00b7bung", "weit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Und hat viel gutes wahrgenommen.", "tokens": ["Und", "hat", "viel", "gu\u00b7tes", "wahr\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Doch daraus folget nicht, da\u00df sich um gleichen Ruhm", "tokens": ["Doch", "da\u00b7raus", "fol\u00b7get", "nicht", ",", "da\u00df", "sich", "um", "glei\u00b7chen", "Ruhm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PTKNEG", "$,", "KOUS", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nicht auch ein muntrer Kopf bew\u00fcrbe,", "tokens": ["Nicht", "auch", "ein", "mun\u00b7trer", "Kopf", "be\u00b7w\u00fcr\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und wohl so jung als klug, und auch in Ehren st\u00fcrbe.", "tokens": ["Und", "wohl", "so", "jung", "als", "klug", ",", "und", "auch", "in", "Eh\u00b7ren", "st\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KOKOM", "ADJD", "$,", "KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Das Alter wird zum Forschen schwach,", "tokens": ["Das", "Al\u00b7ter", "wird", "zum", "For\u00b7schen", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Arbeit mat und oft verdrossen,", "tokens": ["Zur", "Ar\u00b7beit", "mat", "und", "oft", "ver\u00b7dros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kein frischer Saft, kein Lebens Bach", "tokens": ["Kein", "fri\u00b7scher", "Saft", ",", "kein", "Le\u00b7bens", "Bach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt in den todten Geist, zur neuen Kraft geflossen.", "tokens": ["Kommt", "in", "den", "tod\u00b7ten", "Geist", ",", "zur", "neu\u00b7en", "Kraft", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Flei\u00df und Geschicklichkeit verfliegt,", "tokens": ["Flei\u00df", "und", "Ge\u00b7schick\u00b7lich\u00b7keit", "ver\u00b7fliegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und ruft man ihn aus Noth zum Kranken-Bette;", "tokens": ["Und", "ruft", "man", "ihn", "aus", "Noth", "zum", "Kran\u00b7ken\u00b7Bet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So seufzt er: Wenn ich Kr\u00e4fte h\u00e4tte!", "tokens": ["So", "seufzt", "er", ":", "Wenn", "ich", "Kr\u00e4f\u00b7te", "h\u00e4t\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KOUS", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich kan nicht, weil mich nun die Schwachheit selbst besiegt.", "tokens": ["Ich", "kan", "nicht", ",", "weil", "mich", "nun", "die", "Schwach\u00b7heit", "selbst", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beschaut die abgezehrten Knochen,", "tokens": ["Be\u00b7schaut", "die", "ab\u00b7ge\u00b7zehr\u00b7ten", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Des Leibes fester Bau ist leider! nun zerbrochen.", "tokens": ["Des", "Lei\u00b7bes", "fes\u00b7ter", "Bau", "ist", "lei\u00b7der", "!", "nun", "zer\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "$.", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Dergleichen kennt die Jugend nicht;", "tokens": ["Derg\u00b7lei\u00b7chen", "kennt", "die", "Ju\u00b7gend", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Geister sind belebt und munter;", "tokens": ["Die", "Geis\u00b7ter", "sind", "be\u00b7lebt", "und", "mun\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hyg\u00e4ens Dienst wird treu verricht;", "tokens": ["Hy\u00b7g\u00e4\u00b7ens", "Dienst", "wird", "treu", "ver\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es geht an keinem Tag das grosse Welt-Licht unter:", "tokens": ["Es", "geht", "an", "kei\u00b7nem", "Tag", "das", "gros\u00b7se", "Welt\u00b7Licht", "un\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "ART", "ADJA", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man habe denn mit Vorbedacht,", "tokens": ["Man", "ha\u00b7be", "denn", "mit", "Vor\u00b7be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(wenn andre sich durch Thorheit kenntbar machen.)", "tokens": ["(", "wenn", "and\u00b7re", "sich", "durch", "Thor\u00b7heit", "kennt\u00b7bar", "ma\u00b7chen", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PIS", "PRF", "APPR", "NN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "In der Natur und andern Sachen", "tokens": ["In", "der", "Na\u00b7tur", "und", "an\u00b7dern", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Manch neues Wunderwerk ersehn und vorgebracht.", "tokens": ["Manch", "neu\u00b7es", "Wun\u00b7der\u00b7werk", "er\u00b7sehn", "und", "vor\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein J\u00fcngling hat in wenig Stunden", "tokens": ["Ein", "J\u00fcng\u00b7ling", "hat", "in", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Oft mehr als mancher Greis, dieweil er lebt, erfunden.", "tokens": ["Oft", "mehr", "als", "man\u00b7cher", "Greis", ",", "die\u00b7weil", "er", "lebt", ",", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "PIAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Es ist dem Herrn der Creatur", "tokens": ["Es", "ist", "dem", "Herrn", "der", "Crea\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auch niemahls in den Sinn gekommen,", "tokens": ["Auch", "nie\u00b7mahls", "in", "den", "Sinn", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er zu Priester der Natur", "tokens": ["Da\u00df", "er", "zu", "Pries\u00b7ter", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der grauen H\u00e4upter Zahl nur schlechthin angenommen.", "tokens": ["Der", "grau\u00b7en", "H\u00e4up\u00b7ter", "Zahl", "nur", "schlecht\u00b7hin", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, nein, sich l\u00e4\u00dft sein freyer Geist", "tokens": ["Nein", ",", "nein", ",", "sich", "l\u00e4\u00dft", "sein", "frey\u00b7er", "Geist"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PRF", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht an die Zeit und an die Jahre heften;", "tokens": ["Nicht", "an", "die", "Zeit", "und", "an", "die", "Jah\u00b7re", "hef\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er macht zu gleichen Amts-Gesch\u00e4ften", "tokens": ["Er", "macht", "zu", "glei\u00b7chen", "Amts\u00b7Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das junge Blut geschickt; So, da\u00df es stetig heist:", "tokens": ["Das", "jun\u00b7ge", "Blut", "ge\u00b7schickt", ";", "So", ",", "da\u00df", "es", "ste\u00b7tig", "heist", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "ADV", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Herr und Geber aller Gaben,", "tokens": ["Der", "Herr", "und", "Ge\u00b7ber", "al\u00b7ler", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "L\u00e4\u00dft nicht sein theures Pfund in junger Brust vergraben.", "tokens": ["L\u00e4\u00dft", "nicht", "sein", "theu\u00b7res", "Pfund", "in", "jun\u00b7ger", "Brust", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Man wendet zwar darwider ein,", "tokens": ["Man", "wen\u00b7det", "zwar", "dar\u00b7wi\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Jugend lie\u00df die Zeit verstreichen:", "tokens": ["Die", "Ju\u00b7gend", "lie\u00df", "die", "Zeit", "ver\u00b7strei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, wer wird so th\u00f6richt seyn,", "tokens": ["Al\u00b7lein", ",", "wer", "wird", "so", "th\u00f6\u00b7richt", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jedes junge Haupt der tollen Brut vergleichen?", "tokens": ["Und", "je\u00b7des", "jun\u00b7ge", "Haupt", "der", "tol\u00b7len", "Brut", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer klug ist, der erkauft die Zeit,", "tokens": ["Wer", "klug", "ist", ",", "der", "er\u00b7kauft", "die", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "PRELS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und h\u00e4lt so gar die Stunden vor verlohren,", "tokens": ["Und", "h\u00e4lt", "so", "gar", "die", "Stun\u00b7den", "vor", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da er kein gutes Werk gebohren.", "tokens": ["Da", "er", "kein", "gu\u00b7tes", "Werk", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durchwandert manch Athen, und fraget nah und weit,", "tokens": ["Durch\u00b7wan\u00b7dert", "manch", "A\u00b7then", ",", "und", "fra\u00b7get", "nah", "und", "weit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KON", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Ich wei\u00df, ihr werdt die Nachricht h\u00f6ren:", "tokens": ["Ich", "wei\u00df", ",", "ihr", "werdt", "die", "Nach\u00b7richt", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Es giebt nicht wenige, die Kunst und Weisheit ehren.", "tokens": ["Es", "giebt", "nicht", "we\u00b7ni\u00b7ge", ",", "die", "Kunst", "und", "Weis\u00b7heit", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PIS", "$,", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Deswegen krieget auch ihr Flei\u00df", "tokens": ["Des\u00b7we\u00b7gen", "krie\u00b7get", "auch", "ihr", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihr Bem\u00fchen Lorber-Kronen;", "tokens": ["Und", "ihr", "Be\u00b7m\u00fc\u00b7hen", "Lor\u00b7ber\u00b7Kro\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ehre suchet ihren Schwei\u00df,", "tokens": ["Die", "Eh\u00b7re", "su\u00b7chet", "ih\u00b7ren", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viel nur m\u00f6glich ist, mit Hoheit zu belohnen.", "tokens": ["So", "viel", "nur", "m\u00f6g\u00b7lich", "ist", ",", "mit", "Ho\u00b7heit", "zu", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "VAFIN", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchsucht ein Reich, beseht ein Land,", "tokens": ["Durch\u00b7sucht", "ein", "Reich", ",", "be\u00b7seht", "ein", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr werdet da viel muntre F\u00fcsse sehen,", "tokens": ["Ihr", "wer\u00b7det", "da", "viel", "mun\u00b7tre", "F\u00fcs\u00b7se", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die in dem Ehren-Tempel stehen.", "tokens": ["Die", "in", "dem", "Eh\u00b7ren\u00b7Tem\u00b7pel", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier macht sie Thesium, dort Selemin bekannt,", "tokens": ["Hier", "macht", "sie", "The\u00b7si\u00b7um", ",", "dort", "Se\u00b7le\u00b7min", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "ADV", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier will sie Leseminum schm\u00fccken,", "tokens": ["Hier", "will", "sie", "Le\u00b7se\u00b7mi\u00b7num", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dort sucht sie Lirium dem Kayser zuzuschicken.", "tokens": ["Dort", "sucht", "sie", "Li\u00b7ri\u00b7um", "dem", "Kay\u00b7ser", "zu\u00b7zu\u00b7schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Jedoch, was wolt ihr ferne gehn?", "tokens": ["Je\u00b7doch", ",", "was", "wolt", "ihr", "fer\u00b7ne", "gehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eilt nur nach Erfurts Ph\u00f6bus-Tempel;", "tokens": ["Eilt", "nur", "nach", "Er\u00b7furts", "Ph\u00f6\u00b7bus\u00b7Tem\u00b7pel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da k\u00f6nnt ihr heute Wunder sehn;", "tokens": ["Da", "k\u00f6nnt", "ihr", "heu\u00b7te", "Wun\u00b7der", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da zeigt sich abermahls ein herrliches Exempel:", "tokens": ["Da", "zeigt", "sich", "a\u00b7ber\u00b7mahls", "ein", "herr\u00b7li\u00b7ches", "Ex\u00b7em\u00b7pel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Da\u00df Jugend Kunst und Weisheit sch\u00e4tzt.", "tokens": ["Da\u00df", "Ju\u00b7gend", "Kunst", "und", "Weis\u00b7heit", "sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum f\u00fchret auch die grosse Meditrine", "tokens": ["Drum", "f\u00fch\u00b7ret", "auch", "die", "gros\u00b7se", "Me\u00b7di\u00b7tri\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Kind auf diese Ehren-B\u00fchne,", "tokens": ["Ihr", "Kind", "auf", "die\u00b7se", "Eh\u00b7ren\u00b7B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem sie den ", "tokens": ["Dem", "sie", "den"], "token_info": ["word", "word", "word"], "pos": ["ART", "PPER", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ihr zarter Ku\u00df soll ihn bedienen.", "tokens": ["Ihr", "zar\u00b7ter", "Ku\u00df", "soll", "ihn", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So mu\u00df durch Wissenschaft und Ruhm die Jugend gr\u00fcnen.", "tokens": ["So", "mu\u00df", "durch", "Wis\u00b7sen\u00b7schaft", "und", "Ruhm", "die", "Ju\u00b7gend", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Wo aber bleibet meine Pflicht", "tokens": ["Wo", "a\u00b7ber", "blei\u00b7bet", "mei\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An deinem hohen ", "tokens": ["An", "dei\u00b7nem", "ho\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der Abtrag ist schon eingericht.", "tokens": ["Der", "Ab\u00b7trag", "ist", "schon", "ein\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ehre f\u00fchre dich best\u00e4ndig auf das Beste.", "tokens": ["Die", "Eh\u00b7re", "f\u00fch\u00b7re", "dich", "be\u00b7st\u00e4n\u00b7dig", "auf", "das", "Bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Gl\u00fccke weiche nicht von dir;", "tokens": ["Das", "Gl\u00fc\u00b7cke", "wei\u00b7che", "nicht", "von", "dir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Lebens-F\u00fcrst und Seegens-Herr der Fluren,", "tokens": ["Der", "Le\u00b7bens\u00b7F\u00fcrst", "und", "See\u00b7gens\u00b7Herr", "der", "Flu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der benedeye deine Curen,", "tokens": ["Der", "be\u00b7ne\u00b7de\u00b7ye", "dei\u00b7ne", "Cu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.8": {"text": "Und halte dich gesund; so kanst du nach Geb\u00fchr,", "tokens": ["Und", "hal\u00b7te", "dich", "ge\u00b7sund", ";", "so", "kanst", "du", "nach", "Ge\u00b7b\u00fchr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$.", "ADV", "VMFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dein anvertrautes Amt verwalten.", "tokens": ["Dein", "an\u00b7ver\u00b7trau\u00b7tes", "Amt", "ver\u00b7wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gott lasse dich, doch sp\u00e4t, in Ruh und Gl\u00fcck erkalten.", "tokens": ["Gott", "las\u00b7se", "dich", ",", "doch", "sp\u00e4t", ",", "in", "Ruh", "und", "Gl\u00fcck", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "ADV", "ADJD", "$,", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Wie? irr ich? mag das Alterthum,", "tokens": ["Wie", "?", "irr", "ich", "?", "mag", "das", "Al\u00b7ter\u00b7thum", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "NN", "PPER", "$.", "VMFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und die mit Silber-Haaren prangen,", "tokens": ["Und", "die", "mit", "Sil\u00b7ber\u00b7Haa\u00b7ren", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wissenschaften und den Ruhm", "tokens": ["Die", "Wis\u00b7sen\u00b7schaf\u00b7ten", "und", "den", "Ruhm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur einzig und allein zum Eigenthum erlangen?", "tokens": ["Nur", "ein\u00b7zig", "und", "al\u00b7lein", "zum", "Ei\u00b7gen\u00b7thum", "er\u00b7lan\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Soll denn Hyg\u00e4ens zarter Sohn", "tokens": ["Soll", "denn", "Hy\u00b7g\u00e4\u00b7ens", "zar\u00b7ter", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Wissenschaft nicht auch erforschen k\u00f6nnen?", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "nicht", "auch", "er\u00b7for\u00b7schen", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "ADV", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ist ihn nicht gleicher Rang zu g\u00f6nnen?", "tokens": ["Ist", "ihn", "nicht", "glei\u00b7cher", "Rang", "zu", "g\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So wahr ", "tokens": ["So", "wahr"], "token_info": ["word", "word"], "pos": ["ADV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.9": {"text": "Und ", "tokens": ["Und"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.10": {"text": "So wahr mu\u00df man die\u00df Recht auch jungen Aerzten lassen.", "tokens": ["So", "wahr", "mu\u00df", "man", "die\u00df", "Recht", "auch", "jun\u00b7gen", "A\u00b7erz\u00b7ten", "las\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VMFIN", "PIS", "PDS", "NN", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.14": {"line.1": {"text": "Man saget zwar: Ein graues Haupt", "tokens": ["Man", "sa\u00b7get", "zwar", ":", "Ein", "grau\u00b7es", "Haupt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "W\u00e4chst mit den Jahren auch an Wissen,", "tokens": ["W\u00e4chst", "mit", "den", "Jah\u00b7ren", "auch", "an", "Wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ADV", "APPR", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und was so mancher Sinn nicht glaubt,", "tokens": ["Und", "was", "so", "man\u00b7cher", "Sinn", "nicht", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "PIAT", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das zeigt sein kluger Mund in Rathen und in Schl\u00fcssen.", "tokens": ["Das", "zeigt", "sein", "klu\u00b7ger", "Mund", "in", "Ra\u00b7then", "und", "in", "Schl\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sein Amt ziert die Bedachtsamkeit,", "tokens": ["Sein", "Amt", "ziert", "die", "Be\u00b7dacht\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er sorgt mit Flei\u00df den Schaden zu bek\u00e4mpfen,", "tokens": ["Er", "sorgt", "mit", "Flei\u00df", "den", "Scha\u00b7den", "zu", "be\u00b7k\u00e4mp\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Zu hindern, wehren und zu d\u00e4mpfen;", "tokens": ["Zu", "hin\u00b7dern", ",", "weh\u00b7ren", "und", "zu", "d\u00e4mp\u00b7fen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,", "VVINF", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Daher so Gunst als Gl\u00fcck ihm stets die H\u00e4nde beut;", "tokens": ["Da\u00b7her", "so", "Gunst", "als", "Gl\u00fcck", "ihm", "stets", "die", "H\u00e4n\u00b7de", "beut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "KOUS", "NN", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ja, man ergiebt sich ihm in allen,", "tokens": ["Ja", ",", "man", "er\u00b7giebt", "sich", "ihm", "in", "al\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PIS", "VVFIN", "PRF", "PPER", "APPR", "PIAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und l\u00e4\u00dft sich seinen Rath und F\u00fchrung wohlgefallen.", "tokens": ["Und", "l\u00e4\u00dft", "sich", "sei\u00b7nen", "Rath", "und", "F\u00fch\u00b7rung", "wohl\u00b7ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Die Wissenschaft pflegt ordentlich", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "pflegt", "or\u00b7dent\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADJD"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Ehren-Herold abzugeben;", "tokens": ["Den", "Eh\u00b7ren\u00b7He\u00b7rold", "ab\u00b7zu\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum mu\u00df, (die Weisheit steigt durch sich,)", "tokens": ["Drum", "mu\u00df", ",", "(", "die", "Weis\u00b7heit", "steigt", "durch", "sich", ",", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VMFIN", "$,", "$(", "ART", "NN", "VVFIN", "APPR", "PRF", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein solch erfahrnes Haupt in hohen Ansehn schweben.", "tokens": ["Ein", "solch", "er\u00b7fahr\u00b7nes", "Haupt", "in", "ho\u00b7hen", "An\u00b7sehn", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein solcher schwingt sich nach und nach", "tokens": ["Ein", "sol\u00b7cher", "schwingt", "sich", "nach", "und", "nach"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "VVFIN", "PRF", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit seinem Fu\u00df auf gr\u00f6\u00dfre Ehren Spitzen,", "tokens": ["Mit", "sei\u00b7nem", "Fu\u00df", "auf", "gr\u00f6\u00df\u00b7re", "Eh\u00b7ren", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Man sieht ihn neben F\u00fcrsten sitzen;", "tokens": ["Man", "sieht", "ihn", "ne\u00b7ben", "F\u00fcrs\u00b7ten", "sit\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So, da\u00df er noch zuletzt das finstere Gemach", "tokens": ["So", ",", "da\u00df", "er", "noch", "zu\u00b7letzt", "das", "fins\u00b7te\u00b7re", "Ge\u00b7mach"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADV", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit viel und grossen Ruhm erlanget,", "tokens": ["Mit", "viel", "und", "gros\u00b7sen", "Ruhm", "er\u00b7lan\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "KON", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und als ein weiser Mann auch noch im Grabe pranget.", "tokens": ["Und", "als", "ein", "wei\u00b7ser", "Mann", "auch", "noch", "im", "Gra\u00b7be", "pran\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "ADJA", "NN", "ADV", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Hingegen heists: hat Mevius,", "tokens": ["Hin\u00b7ge\u00b7gen", "heists", ":", "hat", "Me\u00b7vius", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "VAFIN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Der noch nicht zweymahl funfzehn tr\u00e4get,", "tokens": ["Der", "noch", "nicht", "zwey\u00b7mahl", "funf\u00b7zehn", "tr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PTKNEG", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Kr\u00e4uter, jeden Spiritus,", "tokens": ["Die", "Kr\u00e4u\u00b7ter", ",", "je\u00b7den", "Spi\u00b7ri\u00b7tus", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den ganzen Krankheits-Schwarm erforscht und \u00fcberleget?", "tokens": ["Den", "gan\u00b7zen", "Krank\u00b7heits\u00b7Schwarm", "er\u00b7forscht", "und", "\u00fc\u00b7ber\u00b7le\u00b7get", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, nein, er hat noch nicht genug", "tokens": ["Nein", ",", "nein", ",", "er", "hat", "noch", "nicht", "ge\u00b7nug"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VAFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hyg\u00e4ens Reich und Schulen durchgegangen,", "tokens": ["Hy\u00b7g\u00e4\u00b7ens", "Reich", "und", "Schu\u00b7len", "durch\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und ihr nach W\u00fcrden angehangen.", "tokens": ["Und", "ihr", "nach", "W\u00fcr\u00b7den", "an\u00b7ge\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wer will sich ihm vertraun? Die Welt w\u00e4r ja zu klug,", "tokens": ["Wer", "will", "sich", "ihm", "ver\u00b7traun", "?", "Die", "Welt", "w\u00e4r", "ja", "zu", "klug", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "PPER", "VVINF", "$.", "ART", "NN", "VAFIN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wenn sie sich recht mit Flei\u00df betr\u00f6ge,", "tokens": ["Wenn", "sie", "sich", "recht", "mit", "Flei\u00df", "be\u00b7tr\u00f6\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und einen jungen Arzt in Noth zu Rathe z\u00f6ge.", "tokens": ["Und", "ei\u00b7nen", "jun\u00b7gen", "Arzt", "in", "Noth", "zu", "Ra\u00b7the", "z\u00f6\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "In B\u00e4rten wird wohl ohne Streit", "tokens": ["In", "B\u00e4r\u00b7ten", "wird", "wohl", "oh\u00b7ne", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mehr Witz und mehr Erk\u00e4ntni\u00df stecken;", "tokens": ["Mehr", "Witz", "und", "mehr", "Er\u00b7k\u00e4nt\u00b7ni\u00df", "ste\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und folglich mu\u00df das Ehren-Kleid", "tokens": ["Und", "folg\u00b7lich", "mu\u00df", "das", "Eh\u00b7ren\u00b7Kleid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch nur den kalten Leib betagter M\u00e4nner decken.", "tokens": ["Auch", "nur", "den", "kal\u00b7ten", "Leib", "be\u00b7tag\u00b7ter", "M\u00e4n\u00b7ner", "de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nur \u00e4chte K\u00e4mpfer kriegen Lohn,", "tokens": ["Nur", "\u00e4ch\u00b7te", "K\u00e4mp\u00b7fer", "krie\u00b7gen", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und Streiter, die, so stark sie nur vermochten,", "tokens": ["Und", "Strei\u00b7ter", ",", "die", ",", "so", "stark", "sie", "nur", "ver\u00b7moch\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "$,", "ADV", "ADJD", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Vor andrer Wohl und Gl\u00fcck gefochten,", "tokens": ["Vor", "an\u00b7drer", "Wohl", "und", "Gl\u00fcck", "ge\u00b7foch\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die tragen Ruhm und Lob und W\u00fcrdigkeit davon.", "tokens": ["Die", "tra\u00b7gen", "Ruhm", "und", "Lob", "und", "W\u00fcr\u00b7dig\u00b7keit", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So, wie ein Unterscheid in Gaben;", "tokens": ["So", ",", "wie", "ein", "Un\u00b7ter\u00b7scheid", "in", "Ga\u00b7ben", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So mu\u00df das Alterthum auch einges Vorrecht haben.", "tokens": ["So", "mu\u00df", "das", "Al\u00b7ter\u00b7thum", "auch", "ein\u00b7ges", "Vor\u00b7recht", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gemach! gemach! die\u00df harte Wort", "tokens": ["Ge\u00b7mach", "!", "ge\u00b7mach", "!", "die\u00df", "har\u00b7te", "Wort"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "ADV", "$.", "PDS", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Lauft der Erfahrung stracks zuwider.", "tokens": ["Lauft", "der", "Er\u00b7fah\u00b7rung", "stracks", "zu\u00b7wi\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ADJD", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "Wie mancher Grau-Kopf hier und dort", "tokens": ["Wie", "man\u00b7cher", "Grau\u00b7Kopf", "hier", "und", "dort"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "ADV", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Ist am Verstand ein Kind, und hat doch starre Glieder.", "tokens": ["Ist", "am", "Ver\u00b7stand", "ein", "Kind", ",", "und", "hat", "doch", "star\u00b7re", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NN", "ART", "NN", "$,", "KON", "VAFIN", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die\u00df ist wohl wahr, das Alterthum", "tokens": ["Die\u00df", "ist", "wohl", "wahr", ",", "das", "Al\u00b7ter\u00b7thum"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Ist oftermahls durch Ubung weit gekommen,", "tokens": ["Ist", "of\u00b7ter\u00b7mahls", "durch", "U\u00b7bung", "weit", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Und hat viel gutes wahrgenommen.", "tokens": ["Und", "hat", "viel", "gu\u00b7tes", "wahr\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Doch daraus folget nicht, da\u00df sich um gleichen Ruhm", "tokens": ["Doch", "da\u00b7raus", "fol\u00b7get", "nicht", ",", "da\u00df", "sich", "um", "glei\u00b7chen", "Ruhm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PTKNEG", "$,", "KOUS", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Nicht auch ein muntrer Kopf bew\u00fcrbe,", "tokens": ["Nicht", "auch", "ein", "mun\u00b7trer", "Kopf", "be\u00b7w\u00fcr\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Und wohl so jung als klug, und auch in Ehren st\u00fcrbe.", "tokens": ["Und", "wohl", "so", "jung", "als", "klug", ",", "und", "auch", "in", "Eh\u00b7ren", "st\u00fcr\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KOKOM", "ADJD", "$,", "KON", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Das Alter wird zum Forschen schwach,", "tokens": ["Das", "Al\u00b7ter", "wird", "zum", "For\u00b7schen", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zur Arbeit mat und oft verdrossen,", "tokens": ["Zur", "Ar\u00b7beit", "mat", "und", "oft", "ver\u00b7dros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "KON", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kein frischer Saft, kein Lebens Bach", "tokens": ["Kein", "fri\u00b7scher", "Saft", ",", "kein", "Le\u00b7bens", "Bach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$,", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kommt in den todten Geist, zur neuen Kraft geflossen.", "tokens": ["Kommt", "in", "den", "tod\u00b7ten", "Geist", ",", "zur", "neu\u00b7en", "Kraft", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Flei\u00df und Geschicklichkeit verfliegt,", "tokens": ["Flei\u00df", "und", "Ge\u00b7schick\u00b7lich\u00b7keit", "ver\u00b7fliegt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVPP", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und ruft man ihn aus Noth zum Kranken-Bette;", "tokens": ["Und", "ruft", "man", "ihn", "aus", "Noth", "zum", "Kran\u00b7ken\u00b7Bet\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So seufzt er: Wenn ich Kr\u00e4fte h\u00e4tte!", "tokens": ["So", "seufzt", "er", ":", "Wenn", "ich", "Kr\u00e4f\u00b7te", "h\u00e4t\u00b7te", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KOUS", "PPER", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ich kan nicht, weil mich nun die Schwachheit selbst besiegt.", "tokens": ["Ich", "kan", "nicht", ",", "weil", "mich", "nun", "die", "Schwach\u00b7heit", "selbst", "be\u00b7siegt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Beschaut die abgezehrten Knochen,", "tokens": ["Be\u00b7schaut", "die", "ab\u00b7ge\u00b7zehr\u00b7ten", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Des Leibes fester Bau ist leider! nun zerbrochen.", "tokens": ["Des", "Lei\u00b7bes", "fes\u00b7ter", "Bau", "ist", "lei\u00b7der", "!", "nun", "zer\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VAFIN", "ADV", "$.", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Dergleichen kennt die Jugend nicht;", "tokens": ["Derg\u00b7lei\u00b7chen", "kennt", "die", "Ju\u00b7gend", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Geister sind belebt und munter;", "tokens": ["Die", "Geis\u00b7ter", "sind", "be\u00b7lebt", "und", "mun\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "KON", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Hyg\u00e4ens Dienst wird treu verricht;", "tokens": ["Hy\u00b7g\u00e4\u00b7ens", "Dienst", "wird", "treu", "ver\u00b7richt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es geht an keinem Tag das grosse Welt-Licht unter:", "tokens": ["Es", "geht", "an", "kei\u00b7nem", "Tag", "das", "gros\u00b7se", "Welt\u00b7Licht", "un\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIAT", "NN", "ART", "ADJA", "NN", "APPR", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man habe denn mit Vorbedacht,", "tokens": ["Man", "ha\u00b7be", "denn", "mit", "Vor\u00b7be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(wenn andre sich durch Thorheit kenntbar machen.)", "tokens": ["(", "wenn", "and\u00b7re", "sich", "durch", "Thor\u00b7heit", "kennt\u00b7bar", "ma\u00b7chen", ".", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PIS", "PRF", "APPR", "NN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "In der Natur und andern Sachen", "tokens": ["In", "der", "Na\u00b7tur", "und", "an\u00b7dern", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Manch neues Wunderwerk ersehn und vorgebracht.", "tokens": ["Manch", "neu\u00b7es", "Wun\u00b7der\u00b7werk", "er\u00b7sehn", "und", "vor\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VVINF", "KON", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ein J\u00fcngling hat in wenig Stunden", "tokens": ["Ein", "J\u00fcng\u00b7ling", "hat", "in", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Oft mehr als mancher Greis, dieweil er lebt, erfunden.", "tokens": ["Oft", "mehr", "als", "man\u00b7cher", "Greis", ",", "die\u00b7weil", "er", "lebt", ",", "er\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "PIAT", "KOKOM", "PIAT", "NN", "$,", "KOUS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Es ist dem Herrn der Creatur", "tokens": ["Es", "ist", "dem", "Herrn", "der", "Crea\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Auch niemahls in den Sinn gekommen,", "tokens": ["Auch", "nie\u00b7mahls", "in", "den", "Sinn", "ge\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df er zu Priester der Natur", "tokens": ["Da\u00df", "er", "zu", "Pries\u00b7ter", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der grauen H\u00e4upter Zahl nur schlechthin angenommen.", "tokens": ["Der", "grau\u00b7en", "H\u00e4up\u00b7ter", "Zahl", "nur", "schlecht\u00b7hin", "an\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Nein, nein, sich l\u00e4\u00dft sein freyer Geist", "tokens": ["Nein", ",", "nein", ",", "sich", "l\u00e4\u00dft", "sein", "frey\u00b7er", "Geist"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PRF", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht an die Zeit und an die Jahre heften;", "tokens": ["Nicht", "an", "die", "Zeit", "und", "an", "die", "Jah\u00b7re", "hef\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Er macht zu gleichen Amts-Gesch\u00e4ften", "tokens": ["Er", "macht", "zu", "glei\u00b7chen", "Amts\u00b7Ge\u00b7sch\u00e4f\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das junge Blut geschickt; So, da\u00df es stetig heist:", "tokens": ["Das", "jun\u00b7ge", "Blut", "ge\u00b7schickt", ";", "So", ",", "da\u00df", "es", "ste\u00b7tig", "heist", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "ADV", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Herr und Geber aller Gaben,", "tokens": ["Der", "Herr", "und", "Ge\u00b7ber", "al\u00b7ler", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "L\u00e4\u00dft nicht sein theures Pfund in junger Brust vergraben.", "tokens": ["L\u00e4\u00dft", "nicht", "sein", "theu\u00b7res", "Pfund", "in", "jun\u00b7ger", "Brust", "ver\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PPOSAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Man wendet zwar darwider ein,", "tokens": ["Man", "wen\u00b7det", "zwar", "dar\u00b7wi\u00b7der", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Jugend lie\u00df die Zeit verstreichen:", "tokens": ["Die", "Ju\u00b7gend", "lie\u00df", "die", "Zeit", "ver\u00b7strei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Allein, wer wird so th\u00f6richt seyn,", "tokens": ["Al\u00b7lein", ",", "wer", "wird", "so", "th\u00f6\u00b7richt", "seyn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VAFIN", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jedes junge Haupt der tollen Brut vergleichen?", "tokens": ["Und", "je\u00b7des", "jun\u00b7ge", "Haupt", "der", "tol\u00b7len", "Brut", "ver\u00b7glei\u00b7chen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer klug ist, der erkauft die Zeit,", "tokens": ["Wer", "klug", "ist", ",", "der", "er\u00b7kauft", "die", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$,", "PRELS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und h\u00e4lt so gar die Stunden vor verlohren,", "tokens": ["Und", "h\u00e4lt", "so", "gar", "die", "Stun\u00b7den", "vor", "ver\u00b7loh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "ART", "NN", "APPR", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Da er kein gutes Werk gebohren.", "tokens": ["Da", "er", "kein", "gu\u00b7tes", "Werk", "ge\u00b7boh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Durchwandert manch Athen, und fraget nah und weit,", "tokens": ["Durch\u00b7wan\u00b7dert", "manch", "A\u00b7then", ",", "und", "fra\u00b7get", "nah", "und", "weit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "KON", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Ich wei\u00df, ihr werdt die Nachricht h\u00f6ren:", "tokens": ["Ich", "wei\u00df", ",", "ihr", "werdt", "die", "Nach\u00b7richt", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Es giebt nicht wenige, die Kunst und Weisheit ehren.", "tokens": ["Es", "giebt", "nicht", "we\u00b7ni\u00b7ge", ",", "die", "Kunst", "und", "Weis\u00b7heit", "eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PIS", "$,", "ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Deswegen krieget auch ihr Flei\u00df", "tokens": ["Des\u00b7we\u00b7gen", "krie\u00b7get", "auch", "ihr", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihr Bem\u00fchen Lorber-Kronen;", "tokens": ["Und", "ihr", "Be\u00b7m\u00fc\u00b7hen", "Lor\u00b7ber\u00b7Kro\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ehre suchet ihren Schwei\u00df,", "tokens": ["Die", "Eh\u00b7re", "su\u00b7chet", "ih\u00b7ren", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So viel nur m\u00f6glich ist, mit Hoheit zu belohnen.", "tokens": ["So", "viel", "nur", "m\u00f6g\u00b7lich", "ist", ",", "mit", "Ho\u00b7heit", "zu", "be\u00b7loh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "ADJD", "VAFIN", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Durchsucht ein Reich, beseht ein Land,", "tokens": ["Durch\u00b7sucht", "ein", "Reich", ",", "be\u00b7seht", "ein", "Land", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihr werdet da viel muntre F\u00fcsse sehen,", "tokens": ["Ihr", "wer\u00b7det", "da", "viel", "mun\u00b7tre", "F\u00fcs\u00b7se", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die in dem Ehren-Tempel stehen.", "tokens": ["Die", "in", "dem", "Eh\u00b7ren\u00b7Tem\u00b7pel", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Hier macht sie Thesium, dort Selemin bekannt,", "tokens": ["Hier", "macht", "sie", "The\u00b7si\u00b7um", ",", "dort", "Se\u00b7le\u00b7min", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "ADV", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Hier will sie Leseminum schm\u00fccken,", "tokens": ["Hier", "will", "sie", "Le\u00b7se\u00b7mi\u00b7num", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Dort sucht sie Lirium dem Kayser zuzuschicken.", "tokens": ["Dort", "sucht", "sie", "Li\u00b7ri\u00b7um", "dem", "Kay\u00b7ser", "zu\u00b7zu\u00b7schi\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Jedoch, was wolt ihr ferne gehn?", "tokens": ["Je\u00b7doch", ",", "was", "wolt", "ihr", "fer\u00b7ne", "gehn", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Eilt nur nach Erfurts Ph\u00f6bus-Tempel;", "tokens": ["Eilt", "nur", "nach", "Er\u00b7furts", "Ph\u00f6\u00b7bus\u00b7Tem\u00b7pel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NE", "NE", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da k\u00f6nnt ihr heute Wunder sehn;", "tokens": ["Da", "k\u00f6nnt", "ihr", "heu\u00b7te", "Wun\u00b7der", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da zeigt sich abermahls ein herrliches Exempel:", "tokens": ["Da", "zeigt", "sich", "a\u00b7ber\u00b7mahls", "ein", "herr\u00b7li\u00b7ches", "Ex\u00b7em\u00b7pel", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Da\u00df Jugend Kunst und Weisheit sch\u00e4tzt.", "tokens": ["Da\u00df", "Ju\u00b7gend", "Kunst", "und", "Weis\u00b7heit", "sch\u00e4tzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Drum f\u00fchret auch die grosse Meditrine", "tokens": ["Drum", "f\u00fch\u00b7ret", "auch", "die", "gros\u00b7se", "Me\u00b7di\u00b7tri\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Ihr Kind auf diese Ehren-B\u00fchne,", "tokens": ["Ihr", "Kind", "auf", "die\u00b7se", "Eh\u00b7ren\u00b7B\u00fch\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Dem sie den ", "tokens": ["Dem", "sie", "den"], "token_info": ["word", "word", "word"], "pos": ["ART", "PPER", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Ihr zarter Ku\u00df soll ihn bedienen.", "tokens": ["Ihr", "zar\u00b7ter", "Ku\u00df", "soll", "ihn", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "So mu\u00df durch Wissenschaft und Ruhm die Jugend gr\u00fcnen.", "tokens": ["So", "mu\u00df", "durch", "Wis\u00b7sen\u00b7schaft", "und", "Ruhm", "die", "Ju\u00b7gend", "gr\u00fc\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "APPR", "NN", "KON", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Wo aber bleibet meine Pflicht", "tokens": ["Wo", "a\u00b7ber", "blei\u00b7bet", "mei\u00b7ne", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An deinem hohen ", "tokens": ["An", "dei\u00b7nem", "ho\u00b7hen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der Abtrag ist schon eingericht.", "tokens": ["Der", "Ab\u00b7trag", "ist", "schon", "ein\u00b7ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Ehre f\u00fchre dich best\u00e4ndig auf das Beste.", "tokens": ["Die", "Eh\u00b7re", "f\u00fch\u00b7re", "dich", "be\u00b7st\u00e4n\u00b7dig", "auf", "das", "Bes\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Das Gl\u00fccke weiche nicht von dir;", "tokens": ["Das", "Gl\u00fc\u00b7cke", "wei\u00b7che", "nicht", "von", "dir", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "PTKNEG", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Lebens-F\u00fcrst und Seegens-Herr der Fluren,", "tokens": ["Der", "Le\u00b7bens\u00b7F\u00fcrst", "und", "See\u00b7gens\u00b7Herr", "der", "Flu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Der benedeye deine Curen,", "tokens": ["Der", "be\u00b7ne\u00b7de\u00b7ye", "dei\u00b7ne", "Cu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+---+--+-", "measure": "trochaic.tri.relaxed"}, "line.8": {"text": "Und halte dich gesund; so kanst du nach Geb\u00fchr,", "tokens": ["Und", "hal\u00b7te", "dich", "ge\u00b7sund", ";", "so", "kanst", "du", "nach", "Ge\u00b7b\u00fchr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVPP", "$.", "ADV", "VMFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Dein anvertrautes Amt verwalten.", "tokens": ["Dein", "an\u00b7ver\u00b7trau\u00b7tes", "Amt", "ver\u00b7wal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gott lasse dich, doch sp\u00e4t, in Ruh und Gl\u00fcck erkalten.", "tokens": ["Gott", "las\u00b7se", "dich", ",", "doch", "sp\u00e4t", ",", "in", "Ruh", "und", "Gl\u00fcck", "er\u00b7kal\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "$,", "ADV", "ADJD", "$,", "APPR", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}