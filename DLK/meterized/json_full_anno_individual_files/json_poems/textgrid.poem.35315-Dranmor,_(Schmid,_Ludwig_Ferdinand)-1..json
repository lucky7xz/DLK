{"textgrid.poem.35315": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Milliarden kommen und verschwinden wieder", "tokens": ["Mil\u00b7li\u00b7ar\u00b7den", "kom\u00b7men", "und", "ver\u00b7schwin\u00b7den", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVINF", "KON", "VVFIN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Im gro\u00dfen All nach kurzer Lebensreise;", "tokens": ["Im", "gro\u00b7\u00dfen", "All", "nach", "kur\u00b7zer", "Le\u00b7bens\u00b7rei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Giganten, Zwerge, Kinder oder Greise,", "tokens": ["Gi\u00b7gan\u00b7ten", ",", "Zwer\u00b7ge", ",", "Kin\u00b7der", "o\u00b7der", "Grei\u00b7se", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir sind nur einer Kette morsche Glieder.", "tokens": ["Wir", "sind", "nur", "ei\u00b7ner", "Ket\u00b7te", "mor\u00b7sche", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Erde m\u00e4\u00dfigt nie den immergleichen,", "tokens": ["Die", "Er\u00b7de", "m\u00e4\u00b7\u00dfigt", "nie", "den", "im\u00b7mer\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den steten Lauf. Wir gehen rasch zu Grunde;", "tokens": ["Den", "ste\u00b7ten", "Lauf", ".", "Wir", "ge\u00b7hen", "rasch", "zu", "Grun\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleichg\u00fcltig sieht mit jeglicher Sekunde", "tokens": ["Gleich\u00b7g\u00fcl\u00b7tig", "sieht", "mit", "jeg\u00b7li\u00b7cher", "Se\u00b7kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Sonne neue Wesen, neue Leichen.", "tokens": ["Die", "Son\u00b7ne", "neu\u00b7e", "We\u00b7sen", ",", "neu\u00b7e", "Lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Nur was bewu\u00dftlos der Natur entsprossen,", "tokens": ["Nur", "was", "be\u00b7wu\u00dft\u00b7los", "der", "Na\u00b7tur", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "H\u00e4lt an der Scholle fest mit starken Ranken;", "tokens": ["H\u00e4lt", "an", "der", "Schol\u00b7le", "fest", "mit", "star\u00b7ken", "Ran\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Menschheit wurden t\u00f6tliche Gedanken", "tokens": ["Der", "Menschheit", "wur\u00b7den", "t\u00f6t\u00b7li\u00b7che", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als fr\u00fche Mahnung ins Gehirn gegossen.", "tokens": ["Als", "fr\u00fc\u00b7he", "Mah\u00b7nung", "ins", "Ge\u00b7hirn", "ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Es m\u00f6chte, wen zu edeln Seelenleiden", "tokens": ["Es", "m\u00f6ch\u00b7te", ",", "wen", "zu", "e\u00b7deln", "See\u00b7len\u00b7lei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die gro\u00dfe Pflegemutter auserkoren,", "tokens": ["Die", "gro\u00b7\u00dfe", "Pfle\u00b7ge\u00b7mut\u00b7ter", "au\u00b7ser\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Einst leuchtend, gleich des Himmels Meteoren,", "tokens": ["Einst", "leuch\u00b7tend", ",", "gleich", "des", "Him\u00b7mels", "Me\u00b7te\u00b7o\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch unverg\u00e4nglich von der Erde scheiden.", "tokens": ["Doch", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "von", "der", "Er\u00b7de", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Hier aber will er herrschen und besitzen,", "tokens": ["Hier", "a\u00b7ber", "will", "er", "herr\u00b7schen", "und", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Kunst, des Wissens letztes Wort ergr\u00fcnden,", "tokens": ["Der", "Kunst", ",", "des", "Wis\u00b7sens", "letz\u00b7tes", "Wort", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der starren Mitwelt seine Macht verk\u00fcnden", "tokens": ["Der", "star\u00b7ren", "Mit\u00b7welt", "sei\u00b7ne", "Macht", "ver\u00b7k\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit k\u00fchnen Thaten oder Geistesblitzen.", "tokens": ["Mit", "k\u00fch\u00b7nen", "Tha\u00b7ten", "o\u00b7der", "Geis\u00b7tes\u00b7blit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Mag auch sein Blut aus tiefen Wunden flie\u00dfen,", "tokens": ["Mag", "auch", "sein", "Blut", "aus", "tie\u00b7fen", "Wun\u00b7den", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Sieger gr\u00fc\u00dfen schmetternde Fanfaren,", "tokens": ["Den", "Sie\u00b7ger", "gr\u00fc\u00b7\u00dfen", "schmet\u00b7tern\u00b7de", "Fan\u00b7fa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn endlich seinem Blick, dem festen, klaren,", "tokens": ["Wenn", "end\u00b7lich", "sei\u00b7nem", "Blick", ",", "dem", "fes\u00b7ten", ",", "kla\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Erde letzte Wunder sich erschlie\u00dfen.", "tokens": ["Der", "Er\u00b7de", "letz\u00b7te", "Wun\u00b7der", "sich", "er\u00b7schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Den Pflegling, der sich stolz emporgerungen,", "tokens": ["Den", "Pfleg\u00b7ling", ",", "der", "sich", "stolz", "em\u00b7por\u00b7ge\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie l\u00e4\u00dft ihn an den fernsten K\u00fcsten landen;", "tokens": ["Sie", "l\u00e4\u00dft", "ihn", "an", "den", "ferns\u00b7ten", "K\u00fcs\u00b7ten", "lan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schon ist sein Dampfro\u00df bis zum Fu\u00df der Anden", "tokens": ["Schon", "ist", "sein", "Dam\u00b7pfro\u00df", "bis", "zum", "Fu\u00df", "der", "An\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bis zum Himalaja vorgedrungen,", "tokens": ["Und", "bis", "zum", "Hi\u00b7ma\u00b7la\u00b7ja", "vor\u00b7ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Da\u00df dort die Adler in die L\u00fcfte rauschen,", "tokens": ["Da\u00df", "dort", "die", "Ad\u00b7ler", "in", "die", "L\u00fcf\u00b7te", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Versprengte Herden durch die Steppen jagen,", "tokens": ["Ver\u00b7spreng\u00b7te", "Her\u00b7den", "durch", "die", "Step\u00b7pen", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und Indianer, weit ins Land verschlagen,", "tokens": ["Und", "In\u00b7di\u00b7a\u00b7ner", ",", "weit", "ins", "Land", "ver\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entsetzt dem neuen Schrei des Fortschritts lauschen;", "tokens": ["Ent\u00b7setzt", "dem", "neu\u00b7en", "Schrei", "des", "Fort\u00b7schritts", "lau\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Da\u00df hier die L\u00f6wen durch die Schluchten br\u00fcllen,", "tokens": ["Da\u00df", "hier", "die", "L\u00f6\u00b7wen", "durch", "die", "Schluch\u00b7ten", "br\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Elefanten durch die W\u00e4lder traben,", "tokens": ["Die", "E\u00b7lef\u00b7an\u00b7ten", "durch", "die", "W\u00e4l\u00b7der", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Tiger sich im Bambusrohr begraben", "tokens": ["Die", "Ti\u00b7ger", "sich", "im", "Bam\u00b7bus\u00b7rohr", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und so der Zeiten Machtgebot erf\u00fcllen;", "tokens": ["Und", "so", "der", "Zei\u00b7ten", "Macht\u00b7ge\u00b7bot", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Da\u00df, wenn das Unget\u00fcm auf sicherm Damme", "tokens": ["Da\u00df", ",", "wenn", "das", "Un\u00b7ge\u00b7t\u00fcm", "auf", "si\u00b7cherm", "Dam\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Schnaubend dahinf\u00e4hrt, tausend Krokodille", "tokens": ["Schnau\u00b7bend", "da\u00b7hin\u00b7f\u00e4hrt", ",", "tau\u00b7send", "Kro\u00b7ko\u00b7dil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "CARD", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Auf einmal in der heil'gen Str\u00f6me Stille", "tokens": ["Auf", "ein\u00b7mal", "in", "der", "heil'\u00b7gen", "Str\u00f6\u00b7me", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich pfeilschnell retten aus dem Uferschlamme,", "tokens": ["Sich", "pfeil\u00b7schnell", "ret\u00b7ten", "aus", "dem", "U\u00b7fer\u00b7schlam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Und wenn es \u00fcber die granitnen Br\u00fccken", "tokens": ["Und", "wenn", "es", "\u00fc\u00b7ber", "die", "gra\u00b7nit\u00b7nen", "Br\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und durch die Tunnels donnert, und der Boden", "tokens": ["Und", "durch", "die", "Tun\u00b7nels", "don\u00b7nert", ",", "und", "der", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ringsum erzittert, sich in den Pagoden", "tokens": ["Ring\u00b7sum", "er\u00b7zit\u00b7tert", ",", "sich", "in", "den", "Pa\u00b7go\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PRF", "APPR", "ART", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Die G\u00f6tzenbilder bis zur Erde b\u00fccken.", "tokens": ["Die", "G\u00f6t\u00b7zen\u00b7bil\u00b7der", "bis", "zur", "Er\u00b7de", "b\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Bewegung, Fortschritt predigt das Jahrhundert;", "tokens": ["Be\u00b7we\u00b7gung", ",", "Fort\u00b7schritt", "pre\u00b7digt", "das", "Jahr\u00b7hun\u00b7dert", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir lachen derer, die zur\u00fcckgeblieben,", "tokens": ["Wir", "la\u00b7chen", "de\u00b7rer", ",", "die", "zu\u00b7r\u00fcck\u00b7ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fchlen uns gewaltsam fortgetrieben", "tokens": ["Und", "f\u00fch\u00b7len", "uns", "ge\u00b7walt\u00b7sam", "fort\u00b7ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und sind darob zuweilen selbst verwundert.", "tokens": ["Und", "sind", "da\u00b7rob", "zu\u00b7wei\u00b7len", "selbst", "ver\u00b7wun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Wir wissen kaum, warum wir vorw\u00e4rts schauen;", "tokens": ["Wir", "wis\u00b7sen", "kaum", ",", "wa\u00b7rum", "wir", "vor\u00b7w\u00e4rts", "schau\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ersch\u00fcttert ist der sch\u00f6ne Christenglaube;", "tokens": ["Er\u00b7sch\u00fct\u00b7tert", "ist", "der", "sch\u00f6\u00b7ne", "Chris\u00b7ten\u00b7glau\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch m\u00e4chtig bleibt der Drang, mit unserm Staube", "tokens": ["Doch", "m\u00e4ch\u00b7tig", "bleibt", "der", "Drang", ",", "mit", "un\u00b7serm", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Nachwelt neue Tempel aufzubauen.", "tokens": ["Der", "Nach\u00b7welt", "neu\u00b7e", "Tem\u00b7pel", "auf\u00b7zu\u00b7bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Sie aber wird zu andern G\u00f6ttern beten", "tokens": ["Sie", "a\u00b7ber", "wird", "zu", "an\u00b7dern", "G\u00f6t\u00b7tern", "be\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und unsern Werken wenig Achtung zollen", "tokens": ["Und", "un\u00b7sern", "Wer\u00b7ken", "we\u00b7nig", "Ach\u00b7tung", "zol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und dem Verh\u00e4ngnis selber trotzen wollen", "tokens": ["Und", "dem", "Ver\u00b7h\u00e4ng\u00b7nis", "sel\u00b7ber", "trot\u00b7zen", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit neuen Helden, Denkern und Propheten.", "tokens": ["Mit", "neu\u00b7en", "Hel\u00b7den", ",", "Den\u00b7kern", "und", "Pro\u00b7phe\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Auch ", "tokens": ["Auch"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und keiner kann des Lichtes Quelle finden;", "tokens": ["Und", "kei\u00b7ner", "kann", "des", "Lich\u00b7tes", "Quel\u00b7le", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wir alle, die wir denken und empfinden,", "tokens": ["Wir", "al\u00b7le", ",", "die", "wir", "den\u00b7ken", "und", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir m\u00fcssen unbefriedigt untergehen.", "tokens": ["Wir", "m\u00fcs\u00b7sen", "un\u00b7be\u00b7frie\u00b7digt", "un\u00b7ter\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "O, trotz der Dunkelheit des Todespfades", "tokens": ["O", ",", "trotz", "der", "Dun\u00b7kel\u00b7heit", "des", "To\u00b7des\u00b7pfa\u00b7des"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Fortdauern? \u2013 Wort des Zweifels und des Truges!", "tokens": ["Fort\u00b7dau\u00b7ern", "?", "\u2013", "Wort", "des", "Zwei\u00b7fels", "und", "des", "Tru\u00b7ges", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr dort \u2013 ein Schemen des Gedankenfluges,", "tokens": ["F\u00fcr", "dort", "\u2013", "ein", "Sche\u00b7men", "des", "Ge\u00b7dan\u00b7ken\u00b7flu\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr hier \u2013 ein mattrer Schlag des Zeitenrades.", "tokens": ["F\u00fcr", "hier", "\u2013", "ein", "mat\u00b7trer", "Schlag", "des", "Zei\u00b7ten\u00b7ra\u00b7des", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Was sind der Kampf, die Wissenschaft, die Dichtung,", "tokens": ["Was", "sind", "der", "Kampf", ",", "die", "Wis\u00b7sen\u00b7schaft", ",", "die", "Dich\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn uns die Frist so k\u00e4rglich zugemessen? \u2013", "tokens": ["Wenn", "uns", "die", "Frist", "so", "k\u00e4rg\u00b7lich", "zu\u00b7ge\u00b7mes\u00b7sen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nichts als ein zorniges Sichselbstvergessen,", "tokens": ["Nichts", "als", "ein", "zor\u00b7ni\u00b7ges", "Sich\u00b7selbst\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Fliehen vor dem einen Wort: Vernichtung.", "tokens": ["Ein", "Flie\u00b7hen", "vor", "dem", "ei\u00b7nen", "Wort", ":", "Ver\u00b7nich\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Milliarden kommen und verschwinden wieder", "tokens": ["Mil\u00b7li\u00b7ar\u00b7den", "kom\u00b7men", "und", "ver\u00b7schwin\u00b7den", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVINF", "KON", "VVFIN", "ADV"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.2": {"text": "Im gro\u00dfen All nach kurzer Lebensreise;", "tokens": ["Im", "gro\u00b7\u00dfen", "All", "nach", "kur\u00b7zer", "Le\u00b7bens\u00b7rei\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Giganten, Zwerge, Kinder oder Greise,", "tokens": ["Gi\u00b7gan\u00b7ten", ",", "Zwer\u00b7ge", ",", "Kin\u00b7der", "o\u00b7der", "Grei\u00b7se", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir sind nur einer Kette morsche Glieder.", "tokens": ["Wir", "sind", "nur", "ei\u00b7ner", "Ket\u00b7te", "mor\u00b7sche", "Glie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Die Erde m\u00e4\u00dfigt nie den immergleichen,", "tokens": ["Die", "Er\u00b7de", "m\u00e4\u00b7\u00dfigt", "nie", "den", "im\u00b7mer\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den steten Lauf. Wir gehen rasch zu Grunde;", "tokens": ["Den", "ste\u00b7ten", "Lauf", ".", "Wir", "ge\u00b7hen", "rasch", "zu", "Grun\u00b7de", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Gleichg\u00fcltig sieht mit jeglicher Sekunde", "tokens": ["Gleich\u00b7g\u00fcl\u00b7tig", "sieht", "mit", "jeg\u00b7li\u00b7cher", "Se\u00b7kun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Die Sonne neue Wesen, neue Leichen.", "tokens": ["Die", "Son\u00b7ne", "neu\u00b7e", "We\u00b7sen", ",", "neu\u00b7e", "Lei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Nur was bewu\u00dftlos der Natur entsprossen,", "tokens": ["Nur", "was", "be\u00b7wu\u00dft\u00b7los", "der", "Na\u00b7tur", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "ADJD", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "H\u00e4lt an der Scholle fest mit starken Ranken;", "tokens": ["H\u00e4lt", "an", "der", "Schol\u00b7le", "fest", "mit", "star\u00b7ken", "Ran\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Menschheit wurden t\u00f6tliche Gedanken", "tokens": ["Der", "Menschheit", "wur\u00b7den", "t\u00f6t\u00b7li\u00b7che", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als fr\u00fche Mahnung ins Gehirn gegossen.", "tokens": ["Als", "fr\u00fc\u00b7he", "Mah\u00b7nung", "ins", "Ge\u00b7hirn", "ge\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Es m\u00f6chte, wen zu edeln Seelenleiden", "tokens": ["Es", "m\u00f6ch\u00b7te", ",", "wen", "zu", "e\u00b7deln", "See\u00b7len\u00b7lei\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "PWS", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die gro\u00dfe Pflegemutter auserkoren,", "tokens": ["Die", "gro\u00b7\u00dfe", "Pfle\u00b7ge\u00b7mut\u00b7ter", "au\u00b7ser\u00b7ko\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Einst leuchtend, gleich des Himmels Meteoren,", "tokens": ["Einst", "leuch\u00b7tend", ",", "gleich", "des", "Him\u00b7mels", "Me\u00b7te\u00b7o\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "$,", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Doch unverg\u00e4nglich von der Erde scheiden.", "tokens": ["Doch", "un\u00b7ver\u00b7g\u00e4ng\u00b7lich", "von", "der", "Er\u00b7de", "schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Hier aber will er herrschen und besitzen,", "tokens": ["Hier", "a\u00b7ber", "will", "er", "herr\u00b7schen", "und", "be\u00b7sit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Der Kunst, des Wissens letztes Wort ergr\u00fcnden,", "tokens": ["Der", "Kunst", ",", "des", "Wis\u00b7sens", "letz\u00b7tes", "Wort", "er\u00b7gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der starren Mitwelt seine Macht verk\u00fcnden", "tokens": ["Der", "star\u00b7ren", "Mit\u00b7welt", "sei\u00b7ne", "Macht", "ver\u00b7k\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit k\u00fchnen Thaten oder Geistesblitzen.", "tokens": ["Mit", "k\u00fch\u00b7nen", "Tha\u00b7ten", "o\u00b7der", "Geis\u00b7tes\u00b7blit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Mag auch sein Blut aus tiefen Wunden flie\u00dfen,", "tokens": ["Mag", "auch", "sein", "Blut", "aus", "tie\u00b7fen", "Wun\u00b7den", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "PPOSAT", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den Sieger gr\u00fc\u00dfen schmetternde Fanfaren,", "tokens": ["Den", "Sie\u00b7ger", "gr\u00fc\u00b7\u00dfen", "schmet\u00b7tern\u00b7de", "Fan\u00b7fa\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wenn endlich seinem Blick, dem festen, klaren,", "tokens": ["Wenn", "end\u00b7lich", "sei\u00b7nem", "Blick", ",", "dem", "fes\u00b7ten", ",", "kla\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Erde letzte Wunder sich erschlie\u00dfen.", "tokens": ["Der", "Er\u00b7de", "letz\u00b7te", "Wun\u00b7der", "sich", "er\u00b7schlie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Den Pflegling, der sich stolz emporgerungen,", "tokens": ["Den", "Pfleg\u00b7ling", ",", "der", "sich", "stolz", "em\u00b7por\u00b7ge\u00b7run\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Sie l\u00e4\u00dft ihn an den fernsten K\u00fcsten landen;", "tokens": ["Sie", "l\u00e4\u00dft", "ihn", "an", "den", "ferns\u00b7ten", "K\u00fcs\u00b7ten", "lan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Schon ist sein Dampfro\u00df bis zum Fu\u00df der Anden", "tokens": ["Schon", "ist", "sein", "Dam\u00b7pfro\u00df", "bis", "zum", "Fu\u00df", "der", "An\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "APPR", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und bis zum Himalaja vorgedrungen,", "tokens": ["Und", "bis", "zum", "Hi\u00b7ma\u00b7la\u00b7ja", "vor\u00b7ge\u00b7drun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Da\u00df dort die Adler in die L\u00fcfte rauschen,", "tokens": ["Da\u00df", "dort", "die", "Ad\u00b7ler", "in", "die", "L\u00fcf\u00b7te", "rau\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Versprengte Herden durch die Steppen jagen,", "tokens": ["Ver\u00b7spreng\u00b7te", "Her\u00b7den", "durch", "die", "Step\u00b7pen", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und Indianer, weit ins Land verschlagen,", "tokens": ["Und", "In\u00b7di\u00b7a\u00b7ner", ",", "weit", "ins", "Land", "ver\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "ADJD", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Entsetzt dem neuen Schrei des Fortschritts lauschen;", "tokens": ["Ent\u00b7setzt", "dem", "neu\u00b7en", "Schrei", "des", "Fort\u00b7schritts", "lau\u00b7schen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Da\u00df hier die L\u00f6wen durch die Schluchten br\u00fcllen,", "tokens": ["Da\u00df", "hier", "die", "L\u00f6\u00b7wen", "durch", "die", "Schluch\u00b7ten", "br\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Elefanten durch die W\u00e4lder traben,", "tokens": ["Die", "E\u00b7lef\u00b7an\u00b7ten", "durch", "die", "W\u00e4l\u00b7der", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Tiger sich im Bambusrohr begraben", "tokens": ["Die", "Ti\u00b7ger", "sich", "im", "Bam\u00b7bus\u00b7rohr", "be\u00b7gra\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PRF", "APPRART", "NN", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und so der Zeiten Machtgebot erf\u00fcllen;", "tokens": ["Und", "so", "der", "Zei\u00b7ten", "Macht\u00b7ge\u00b7bot", "er\u00b7f\u00fcl\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Da\u00df, wenn das Unget\u00fcm auf sicherm Damme", "tokens": ["Da\u00df", ",", "wenn", "das", "Un\u00b7ge\u00b7t\u00fcm", "auf", "si\u00b7cherm", "Dam\u00b7me"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Schnaubend dahinf\u00e4hrt, tausend Krokodille", "tokens": ["Schnau\u00b7bend", "da\u00b7hin\u00b7f\u00e4hrt", ",", "tau\u00b7send", "Kro\u00b7ko\u00b7dil\u00b7le"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "CARD", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "Auf einmal in der heil'gen Str\u00f6me Stille", "tokens": ["Auf", "ein\u00b7mal", "in", "der", "heil'\u00b7gen", "Str\u00f6\u00b7me", "Stil\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sich pfeilschnell retten aus dem Uferschlamme,", "tokens": ["Sich", "pfeil\u00b7schnell", "ret\u00b7ten", "aus", "dem", "U\u00b7fer\u00b7schlam\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Und wenn es \u00fcber die granitnen Br\u00fccken", "tokens": ["Und", "wenn", "es", "\u00fc\u00b7ber", "die", "gra\u00b7nit\u00b7nen", "Br\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und durch die Tunnels donnert, und der Boden", "tokens": ["Und", "durch", "die", "Tun\u00b7nels", "don\u00b7nert", ",", "und", "der", "Bo\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "KON", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ringsum erzittert, sich in den Pagoden", "tokens": ["Ring\u00b7sum", "er\u00b7zit\u00b7tert", ",", "sich", "in", "den", "Pa\u00b7go\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "PRF", "APPR", "ART", "NN"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Die G\u00f6tzenbilder bis zur Erde b\u00fccken.", "tokens": ["Die", "G\u00f6t\u00b7zen\u00b7bil\u00b7der", "bis", "zur", "Er\u00b7de", "b\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Bewegung, Fortschritt predigt das Jahrhundert;", "tokens": ["Be\u00b7we\u00b7gung", ",", "Fort\u00b7schritt", "pre\u00b7digt", "das", "Jahr\u00b7hun\u00b7dert", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wir lachen derer, die zur\u00fcckgeblieben,", "tokens": ["Wir", "la\u00b7chen", "de\u00b7rer", ",", "die", "zu\u00b7r\u00fcck\u00b7ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PDS", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fchlen uns gewaltsam fortgetrieben", "tokens": ["Und", "f\u00fch\u00b7len", "uns", "ge\u00b7walt\u00b7sam", "fort\u00b7ge\u00b7trie\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und sind darob zuweilen selbst verwundert.", "tokens": ["Und", "sind", "da\u00b7rob", "zu\u00b7wei\u00b7len", "selbst", "ver\u00b7wun\u00b7dert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Wir wissen kaum, warum wir vorw\u00e4rts schauen;", "tokens": ["Wir", "wis\u00b7sen", "kaum", ",", "wa\u00b7rum", "wir", "vor\u00b7w\u00e4rts", "schau\u00b7en", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ersch\u00fcttert ist der sch\u00f6ne Christenglaube;", "tokens": ["Er\u00b7sch\u00fct\u00b7tert", "ist", "der", "sch\u00f6\u00b7ne", "Chris\u00b7ten\u00b7glau\u00b7be", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch m\u00e4chtig bleibt der Drang, mit unserm Staube", "tokens": ["Doch", "m\u00e4ch\u00b7tig", "bleibt", "der", "Drang", ",", "mit", "un\u00b7serm", "Stau\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "$,", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Der Nachwelt neue Tempel aufzubauen.", "tokens": ["Der", "Nach\u00b7welt", "neu\u00b7e", "Tem\u00b7pel", "auf\u00b7zu\u00b7bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Sie aber wird zu andern G\u00f6ttern beten", "tokens": ["Sie", "a\u00b7ber", "wird", "zu", "an\u00b7dern", "G\u00f6t\u00b7tern", "be\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VAFIN", "APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und unsern Werken wenig Achtung zollen", "tokens": ["Und", "un\u00b7sern", "Wer\u00b7ken", "we\u00b7nig", "Ach\u00b7tung", "zol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und dem Verh\u00e4ngnis selber trotzen wollen", "tokens": ["Und", "dem", "Ver\u00b7h\u00e4ng\u00b7nis", "sel\u00b7ber", "trot\u00b7zen", "wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mit neuen Helden, Denkern und Propheten.", "tokens": ["Mit", "neu\u00b7en", "Hel\u00b7den", ",", "Den\u00b7kern", "und", "Pro\u00b7phe\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Auch ", "tokens": ["Auch"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Und keiner kann des Lichtes Quelle finden;", "tokens": ["Und", "kei\u00b7ner", "kann", "des", "Lich\u00b7tes", "Quel\u00b7le", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wir alle, die wir denken und empfinden,", "tokens": ["Wir", "al\u00b7le", ",", "die", "wir", "den\u00b7ken", "und", "emp\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "VVINF", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Wir m\u00fcssen unbefriedigt untergehen.", "tokens": ["Wir", "m\u00fcs\u00b7sen", "un\u00b7be\u00b7frie\u00b7digt", "un\u00b7ter\u00b7ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "O, trotz der Dunkelheit des Todespfades", "tokens": ["O", ",", "trotz", "der", "Dun\u00b7kel\u00b7heit", "des", "To\u00b7des\u00b7pfa\u00b7des"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Fortdauern? \u2013 Wort des Zweifels und des Truges!", "tokens": ["Fort\u00b7dau\u00b7ern", "?", "\u2013", "Wort", "des", "Zwei\u00b7fels", "und", "des", "Tru\u00b7ges", "!"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "F\u00fcr dort \u2013 ein Schemen des Gedankenfluges,", "tokens": ["F\u00fcr", "dort", "\u2013", "ein", "Sche\u00b7men", "des", "Ge\u00b7dan\u00b7ken\u00b7flu\u00b7ges", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "F\u00fcr hier \u2013 ein mattrer Schlag des Zeitenrades.", "tokens": ["F\u00fcr", "hier", "\u2013", "ein", "mat\u00b7trer", "Schlag", "des", "Zei\u00b7ten\u00b7ra\u00b7des", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Was sind der Kampf, die Wissenschaft, die Dichtung,", "tokens": ["Was", "sind", "der", "Kampf", ",", "die", "Wis\u00b7sen\u00b7schaft", ",", "die", "Dich\u00b7tung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Wenn uns die Frist so k\u00e4rglich zugemessen? \u2013", "tokens": ["Wenn", "uns", "die", "Frist", "so", "k\u00e4rg\u00b7lich", "zu\u00b7ge\u00b7mes\u00b7sen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "ADJD", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Nichts als ein zorniges Sichselbstvergessen,", "tokens": ["Nichts", "als", "ein", "zor\u00b7ni\u00b7ges", "Sich\u00b7selbst\u00b7ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein Fliehen vor dem einen Wort: Vernichtung.", "tokens": ["Ein", "Flie\u00b7hen", "vor", "dem", "ei\u00b7nen", "Wort", ":", "Ver\u00b7nich\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ART", "NN", "$.", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}