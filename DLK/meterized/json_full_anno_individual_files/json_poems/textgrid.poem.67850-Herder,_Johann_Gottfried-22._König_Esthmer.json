{"textgrid.poem.67850": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "22. K\u00f6nig Esthmer", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Horcht mir zu, ihr lieben Leut,", "tokens": ["Horcht", "mir", "zu", ",", "ihr", "lie\u00b7ben", "Leut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Neigt euer Ohr mir dar;", "tokens": ["Neigt", "eu\u00b7er", "Ohr", "mir", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich sing euch von ein'm Bruder Paar,", "tokens": ["Ich", "sing", "euch", "von", "ein'm", "Bru\u00b7der", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als je nur Eines war.", "tokens": ["Als", "je", "nur", "Ei\u00b7nes", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIS", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der Eine von ihnen hie\u00df Adler jung,", "tokens": ["Der", "Ei\u00b7ne", "von", "ih\u00b7nen", "hie\u00df", "Ad\u00b7ler", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "PPER", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Andre K\u00f6nig Esthmer.", "tokens": ["Der", "And\u00b7re", "K\u00f6\u00b7nig", "Esth\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie waren so wackre M\u00e4nner in Thaten,", "tokens": ["Sie", "wa\u00b7ren", "so", "wack\u00b7re", "M\u00e4n\u00b7ner", "in", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als immer nah und ferne.", "tokens": ["Als", "im\u00b7mer", "nah", "und", "fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und als sie trunken einst Bier und Wein", "tokens": ["Und", "als", "sie", "trun\u00b7ken", "einst", "Bier", "und", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In K\u00f6nig Esthmers Hallen:", "tokens": ["In", "K\u00f6\u00b7nig", "Esth\u00b7mers", "Hal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwann wollt ihr nehmen ein Weib euch, Bruder,", "tokens": ["\u00bb", "wann", "wollt", "ihr", "neh\u00b7men", "ein", "Weib", "euch", ",", "Bru\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "VVFIN", "ART", "NN", "PPER", "$,", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Weib zur Freud uns allen?\u00ab", "tokens": ["Ein", "Weib", "zur", "Freud", "uns", "al\u00b7len", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PPER", "PIAT", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Denn besprach's K\u00f6nig Esthmer,", "tokens": ["Denn", "be\u00b7sprach's", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Antwort't ihm hastiglich:", "tokens": ["Ant\u00b7wort't", "ihm", "has\u00b7tig\u00b7lich", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbich wei\u00df kein Maid in allem Land,", "tokens": ["\u00bb", "ich", "wei\u00df", "kein", "Maid", "in", "al\u00b7lem", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die w\u00e4r ein Weib f\u00fcr mich.\u00ab", "tokens": ["Die", "w\u00e4r", "ein", "Weib", "f\u00fcr", "mich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbk\u00f6nig Adland hat eine Tochter, Bruder,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "Ad\u00b7land", "hat", "ei\u00b7ne", "Toch\u00b7ter", ",", "Bru\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "NN", "VAFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Jeder nennt sie fein und sch\u00f6n;", "tokens": ["Je\u00b7der", "nennt", "sie", "fein", "und", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4r ich hier K\u00f6nig an Eurer Statt,", "tokens": ["W\u00e4r", "ich", "hier", "K\u00f6\u00b7nig", "an", "Eu\u00b7rer", "Statt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Die Dam' w\u00e4r K\u00f6nigin.\u00ab", "tokens": ["Die", "Dam'", "w\u00e4r", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Sprach: \u00bbrath mir, rath mir, lieber Bruder,", "tokens": ["Sprach", ":", "\u00bb", "rath", "mir", ",", "rath", "mir", ",", "lie\u00b7ber", "Bru\u00b7der", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch's lust'ge Engelland", "tokens": ["Durch's", "lust'\u00b7ge", "En\u00b7gel\u00b7land"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo sollen wir einen Boten finden,", "tokens": ["Wo", "sol\u00b7len", "wir", "ei\u00b7nen", "Bo\u00b7ten", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der zwischen uns sey zur Hand.\u00ab", "tokens": ["Der", "zwi\u00b7schen", "uns", "sey", "zur", "Hand", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "PPER", "VAFIN", "APPRART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sprach: \u00bbIhr m\u00fcst reiten selbst, mein Bruder;", "tokens": ["Sprach", ":", "\u00bb", "Ihr", "m\u00fcst", "rei\u00b7ten", "selbst", ",", "mein", "Bru\u00b7der", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VMFIN", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will euch kompaneyn.", "tokens": ["Ich", "will", "euch", "kom\u00b7pa\u00b7neyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl mancher ist durch Boten betrogen;", "tokens": ["Wohl", "man\u00b7cher", "ist", "durch", "Bo\u00b7ten", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich f\u00fcrcht', auch ihr m\u00f6cht's seyn.\u00ab", "tokens": ["Ich", "f\u00fcrcht'", ",", "auch", "ihr", "m\u00f6cht's", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PPER", "VMFIN", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und also puzten sie sich zu reiten,", "tokens": ["Und", "al\u00b7so", "puz\u00b7ten", "sie", "sich", "zu", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "PTKZU", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gepuzt war beider Ro\u00df;", "tokens": ["Ge\u00b7puzt", "war", "bei\u00b7der", "Ro\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen zu Adlands Hallen,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Golde gl\u00e4nzt ihr Tro\u00df.", "tokens": ["Von", "Gol\u00b7de", "gl\u00e4nzt", "ihr", "Tro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und als sie kamen zu Adlands Hallen,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wohl vor das hohe Thor,", "tokens": ["Wohl", "vor", "das", "ho\u00b7he", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Allda sie fanden K\u00f6nig Adland selbst,", "tokens": ["All\u00b7da", "sie", "fan\u00b7den", "K\u00f6\u00b7nig", "Ad\u00b7land", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Macht ihnen auf das Thor.", "tokens": ["Macht", "ih\u00b7nen", "auf", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbnun Gott mit Euch, K\u00f6nig Adland gut,", "tokens": ["\u00bb", "nun", "Gott", "mit", "Euch", ",", "K\u00f6\u00b7nig", "Ad\u00b7land", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NN", "APPR", "PPER", "$,", "NN", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gott mit Euch immer und hier!\u00ab", "tokens": ["Gott", "mit", "Euch", "im\u00b7mer", "und", "hier", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPER", "ADV", "KON", "ADV", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Sprach: \u00bbWillkomm, willkomm, K\u00f6nig Esthmer,", "tokens": ["Sprach", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Recht herzlich willkomm mir!\u00ab", "tokens": ["Recht", "herz\u00b7lich", "will\u00b7komm", "mir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJD", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "\u00bbihr habt eine Tochter, sprach Adler jung,", "tokens": ["\u00bb", "ihr", "habt", "ei\u00b7ne", "Toch\u00b7ter", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Jeder nennt sie fein und sch\u00f6n.", "tokens": ["Je\u00b7der", "nennt", "sie", "fein", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Bruder will sie nehmen zum Weib,", "tokens": ["Mein", "Bru\u00b7der", "will", "sie", "neh\u00b7men", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Zu Englands K\u00f6nigin.\u00ab", "tokens": ["Zu", "En\u00b7glands", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "\u00bbund gestern war um meine Tochter hier", "tokens": ["\u00bb", "und", "ge\u00b7stern", "war", "um", "mei\u00b7ne", "Toch\u00b7ter", "hier"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "VAFIN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "K\u00f6nig Bremor aus Spaniens Reich,", "tokens": ["K\u00f6\u00b7nig", "Bre\u00b7mor", "aus", "Spa\u00b7ni\u00b7ens", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und da nickt sie ihr Nein ihm zu;", "tokens": ["Und", "da", "nickt", "sie", "ihr", "Nein", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ich f\u00fcrcht, sie thuts auch euch.\u00ab", "tokens": ["Ich", "f\u00fcrcht", ",", "sie", "thuts", "auch", "euch", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "\u00bbder K\u00f6nig von Spanien ist ein garst'ger Heid,", "tokens": ["\u00bb", "der", "K\u00f6\u00b7nig", "von", "Spa\u00b7ni\u00b7en", "ist", "ein", "gar\u00b7st'\u00b7ger", "Heid", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und glaubt an Mahomet.", "tokens": ["Und", "glaubt", "an", "Ma\u00b7ho\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "'s w\u00e4r Jammer um solch ein sch\u00f6nes Maid,", "tokens": ["'s", "w\u00e4r", "Jam\u00b7mer", "um", "solch", "ein", "sch\u00f6\u00b7nes", "Maid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PIAT", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da\u00df so ein Hund sie h\u00e4tt!\u00ab", "tokens": ["Da\u00df", "so", "ein", "Hund", "sie", "h\u00e4tt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "\u00bbaber sagt mir, (K\u00f6nig Esthmer sprach's)", "tokens": ["\u00bb", "a\u00b7ber", "sagt", "mir", ",", "(", "K\u00f6\u00b7nig", "Esth\u00b7mer", "sprach's", ")"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "$(", "NE", "NE", "NE", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ich bitt euch, sagt mirs zu,", "tokens": ["Ich", "bitt", "euch", ",", "sagt", "mirs", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df morgen ich Eure Tochter seh,", "tokens": ["Da\u00df", "mor\u00b7gen", "ich", "Eu\u00b7re", "Toch\u00b7ter", "seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eh ich wegreiten thu.\u00ab", "tokens": ["Eh", "ich", "weg\u00b7rei\u00b7ten", "thu", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VVFIN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.15": {"line.1": {"text": "\u00bbund w\u00e4rs gleich sieben und noch mehr Jahr,", "tokens": ["\u00bb", "und", "w\u00e4rs", "gleich", "sie\u00b7ben", "und", "noch", "mehr", "Jahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "ADV", "VVINF", "KON", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Seit sie war in der Hall,", "tokens": ["Seit", "sie", "war", "in", "der", "Hall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So soll sie kommen um Euretwillen,", "tokens": ["So", "soll", "sie", "kom\u00b7men", "um", "Eu\u00b7ret\u00b7wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zur Freud den G\u00e4sten all.\u00ab", "tokens": ["Zur", "Freud", "den", "G\u00e4s\u00b7ten", "all", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PIAT", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Ab denn kam die sch\u00f6ne Maid", "tokens": ["Ab", "denn", "kam", "die", "sch\u00f6\u00b7ne", "Maid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Jungfraun reicher Zahl,", "tokens": ["Mit", "Jung\u00b7fraun", "rei\u00b7cher", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl halb einhundert Ritter stolz", "tokens": ["Wohl", "halb", "ein\u00b7hun\u00b7dert", "Rit\u00b7ter", "stolz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einleiten sie zur Hall,", "tokens": ["Ein\u00b7lei\u00b7ten", "sie", "zur", "Hall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und noch so mancher Edelknab',", "tokens": ["Und", "noch", "so", "man\u00b7cher", "E\u00b7del\u00b7knab'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn'n aufzuwarten all.", "tokens": ["Ihn'n", "auf\u00b7zu\u00b7war\u00b7ten", "all", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Die Goldst\u00fcck' all an ihrem Haupt,", "tokens": ["Die", "Gold\u00b7st\u00fcck", "all", "an", "ih\u00b7rem", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hingen bis zu den Knien,", "tokens": ["Sie", "hin\u00b7gen", "bis", "zu", "den", "Kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und jeder Ring an ihrem Fing'r", "tokens": ["Und", "je\u00b7der", "Ring", "an", "ih\u00b7rem", "Fing'r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein heller Demant schien.", "tokens": ["Ein", "hel\u00b7ler", "De\u00b7mant", "schien", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Sprach: \u00bbGr\u00fc\u00df euch Gott, meine Dame sch\u00f6n!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "euch", "Gott", ",", "mei\u00b7ne", "Da\u00b7me", "sch\u00f6n", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "$,", "PPOSAT", "NN", "ADJD", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sprach: \u00bbGr\u00fc\u00df euch Gott allhier!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "euch", "Gott", "all\u00b7hier", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sprach: \u00bbWillkomm, willkomm, K\u00f6nig Esthmer,", "tokens": ["Sprach", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Recht herzlich willkomm mir!", "tokens": ["Recht", "herz\u00b7lich", "will\u00b7komm", "mir", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Und liebt ihr mich denn, als ihr sagt,", "tokens": ["Und", "liebt", "ihr", "mich", "denn", ",", "als", "ihr", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So herzlich und so treu,", "tokens": ["So", "herz\u00b7lich", "und", "so", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Warum ihr immer nur kommen seyd,", "tokens": ["Wa\u00b7rum", "ihr", "im\u00b7mer", "nur", "kom\u00b7men", "seyd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVINF", "VAFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Geb Gott, euch gl\u00fccklich sey!\u00ab", "tokens": ["Geb", "Gott", ",", "euch", "gl\u00fcck\u00b7lich", "sey", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "$,", "PPER", "ADJD", "VAFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Ein denn, sprach der Vater theur:", "tokens": ["Ein", "denn", ",", "sprach", "der", "Va\u00b7ter", "theur", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbmeine Tochter, Nein ich sag!", "tokens": ["\u00bb", "mei\u00b7ne", "Toch\u00b7ter", ",", "Nein", "ich", "sag", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PTKANT", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bedenk der K\u00f6nig von Spanien,", "tokens": ["Be\u00b7denk", "der", "K\u00f6\u00b7nig", "von", "Spa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was der sprach gestertag.", "tokens": ["Was", "der", "sprach", "ge\u00b7ster\u00b7tag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.21": {"line.1": {"text": "Wollt st\u00fcrzen ein mir Schl\u00f6ss'r und Hall'n?", "tokens": ["Wollt", "st\u00fcr\u00b7zen", "ein", "mir", "Schl\u00f6ss'r", "und", "Hall'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wollt rauben das Leben mir?", "tokens": ["Wollt", "rau\u00b7ben", "das", "Le\u00b7ben", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "NN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "F\u00fcrwahr, ich f\u00fcrcht' des Heiden Grimm,", "tokens": ["F\u00fcr\u00b7wahr", ",", "ich", "f\u00fcrcht'", "des", "Hei\u00b7den", "Grimm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn ich dies zugeb' dir.\u00ab", "tokens": ["Wenn", "ich", "dies", "zu\u00b7geb'", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "\u00bbeure Schl\u00f6sser und eure Th\u00fcrme, Vater,", "tokens": ["\u00bb", "eu\u00b7re", "Schl\u00f6s\u00b7ser", "und", "eu\u00b7re", "Th\u00fcr\u00b7me", ",", "Va\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sind stark und vest gebaut,", "tokens": ["Sind", "stark", "und", "vest", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und darum wei\u00df ich nicht, was Euch", "tokens": ["Und", "da\u00b7rum", "wei\u00df", "ich", "nicht", ",", "was", "Euch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcrm garst'gen Heiden graut.", "tokens": ["F\u00fcrm", "gar\u00b7st'\u00b7gen", "Hei\u00b7den", "graut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "K\u00f6nig Esthmer, gebt mir Euer Wort,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", ",", "gebt", "mir", "Eu\u00b7er", "Wort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Beym Himmel und rechter Hand,", "tokens": ["Beym", "Him\u00b7mel", "und", "rech\u00b7ter", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df ihr mich nehmen wollt zum Weib,", "tokens": ["Da\u00df", "ihr", "mich", "neh\u00b7men", "wollt", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur K\u00f6n'gin in Eur Land.\u00ab", "tokens": ["Zur", "K\u00f6n'\u00b7gin", "in", "Eur", "Land", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "K\u00f6nig Esthmer freudig gab sein Wort,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "freu\u00b7dig", "gab", "sein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJD", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Beym Himmel und rechter Hand,", "tokens": ["Beym", "Him\u00b7mel", "und", "rech\u00b7ter", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df er sie nehmen wollt zum Weib,", "tokens": ["Da\u00df", "er", "sie", "neh\u00b7men", "wollt", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur K\u00f6n'gin in sein Land.", "tokens": ["Zur", "K\u00f6n'\u00b7gin", "in", "sein", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Nahm Urlaub von der sch\u00f6nen Braut,", "tokens": ["Nahm", "Ur\u00b7laub", "von", "der", "sch\u00f6\u00b7nen", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu gehn schnell in sein Reich,", "tokens": ["Zu", "gehn", "schnell", "in", "sein", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu suchen Herzog', Ritter und Grafen,", "tokens": ["Zu", "su\u00b7chen", "Her\u00b7zo\u00b7g'", ",", "Rit\u00b7ter", "und", "Gra\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie heimzuf\u00fchren gleich.", "tokens": ["Sie", "heim\u00b7zu\u00b7f\u00fch\u00b7ren", "gleich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Sie hatten geritten eine Meile kaum,", "tokens": ["Sie", "hat\u00b7ten", "ge\u00b7rit\u00b7ten", "ei\u00b7ne", "Mei\u00b7le", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eine Meile weit hinan,", "tokens": ["Ei\u00b7ne", "Mei\u00b7le", "weit", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als ein th\u00e4t kommen der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "th\u00e4t", "kom\u00b7men", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit manchem K\u00e4mpfersmann.", "tokens": ["Mit", "man\u00b7chem", "K\u00e4mp\u00b7fers\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Als ein th\u00e4t kommen der Span'sche K\u00f6nig,", "tokens": ["Als", "ein", "th\u00e4t", "kom\u00b7men", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit manchem grimmen Baron,", "tokens": ["Mit", "man\u00b7chem", "grim\u00b7men", "Ba\u00b7ron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Noch heut zu freyn K\u00f6nig Adlands Tochter,", "tokens": ["Noch", "heut", "zu", "freyn", "K\u00f6\u00b7nig", "Ad\u00b7lands", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und morgen zu ziehn davon.", "tokens": ["Und", "mor\u00b7gen", "zu", "ziehn", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Stracks sandt sie K\u00f6nig Esthmer'n nach,", "tokens": ["Stracks", "sandt", "sie", "K\u00f6\u00b7nig", "Esth\u00b7mer'n", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schnell als bitter ihr graut,", "tokens": ["So", "schnell", "als", "bit\u00b7ter", "ihr", "graut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sollt eilig kommen und k\u00e4mpfen um sie,", "tokens": ["Sollt", "ei\u00b7lig", "kom\u00b7men", "und", "k\u00e4mp\u00b7fen", "um", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVINF", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder immer aufgeben die Braut.", "tokens": ["O\u00b7der", "im\u00b7mer", "auf\u00b7ge\u00b7ben", "die", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.29": {"line.1": {"text": "Ein' Weil' der Edelknabe kam,", "tokens": ["Ein'", "Weil'", "der", "E\u00b7del\u00b7kna\u00b7be", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein' ander Weil' er lief,", "tokens": ["Ein'", "an\u00b7der", "Weil'", "er", "lief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis er K\u00f6nig Esthmern eingeholt,", "tokens": ["Bis", "er", "K\u00f6\u00b7nig", "Esth\u00b7mern", "ein\u00b7ge\u00b7holt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und schnell und hastig rief:", "tokens": ["Und", "schnell", "und", "has\u00b7tig", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "\u00bbzeitung, Zeitung, K\u00f6nig Esthmer!\u00ab", "tokens": ["\u00bb", "zei\u00b7tung", ",", "Zei\u00b7tung", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "$,", "NN", "$,", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbund was f\u00fcr Zeitung dann?\u00ab", "tokens": ["\u00bb", "und", "was", "f\u00fcr", "Zei\u00b7tung", "dann", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "APPR", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Zeitung mu\u00df ich euch sagen,", "tokens": ["\u00bb", "o", "Zei\u00b7tung", "mu\u00df", "ich", "euch", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die euch wohl schwer seyn kann.", "tokens": ["Die", "euch", "wohl", "schwer", "seyn", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Ihr hattet geritten eine Meile kaum,", "tokens": ["Ihr", "hat\u00b7tet", "ge\u00b7rit\u00b7ten", "ei\u00b7ne", "Mei\u00b7le", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eine Meile weit hinan,", "tokens": ["Ei\u00b7ne", "Mei\u00b7le", "weit", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als ein schon kam der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "schon", "kam", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit manchem K\u00e4mpfersmann.", "tokens": ["Mit", "man\u00b7chem", "K\u00e4mp\u00b7fers\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Als ein schon kam der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "schon", "kam", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit manchem grimmen Baron,", "tokens": ["Mit", "man\u00b7chem", "grim\u00b7men", "Ba\u00b7ron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Noch heut zu freyn K\u00f6nig Adlands Tochter,", "tokens": ["Noch", "heut", "zu", "freyn", "K\u00f6\u00b7nig", "Ad\u00b7lands", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und morgen zu ziehn davon.", "tokens": ["Und", "mor\u00b7gen", "zu", "ziehn", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.33": {"line.1": {"text": "Die Dame sch\u00f6n Euch freundlich gr\u00fc\u00dft,", "tokens": ["Die", "Da\u00b7me", "sch\u00f6n", "Euch", "freund\u00b7lich", "gr\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr und bitter ihr graut,", "tokens": ["So", "sehr", "und", "bit\u00b7ter", "ihr", "graut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Spricht: Ihr m\u00fcst kommen und fechten um sie,", "tokens": ["Spricht", ":", "Ihr", "m\u00fcst", "kom\u00b7men", "und", "fech\u00b7ten", "um", "sie", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "VMFIN", "VVINF", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Od'r immer aufgeben die Braut.\u00ab", "tokens": ["Od'r", "im\u00b7mer", "auf\u00b7ge\u00b7ben", "die", "Braut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.34": {"line.1": {"text": "Sprach: \u00bbrath mir, rath mir, lieber Bruder,", "tokens": ["Sprach", ":", "\u00bb", "rath", "mir", ",", "rath", "mir", ",", "lie\u00b7ber", "Bru\u00b7der", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Wort und ich geh's ein,", "tokens": ["Dein", "Wort", "und", "ich", "geh's", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wes Weges sollen wir gehn und fechten?", "tokens": ["Wes", "We\u00b7ges", "sol\u00b7len", "wir", "gehn", "und", "fech\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gerettet mu\u00df sie seyn.\u00ab", "tokens": ["Ge\u00b7ret\u00b7tet", "mu\u00df", "sie", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "\u00bbnun horcht mir zu, sprach Adler jung,", "tokens": ["\u00bb", "nun", "horcht", "mir", "zu", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Wort und geht es ein,", "tokens": ["Mein", "Wort", "und", "geht", "es", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So will ich gleich euch zeigen den Weg,", "tokens": ["So", "will", "ich", "gleich", "euch", "zei\u00b7gen", "den", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da sie kann gerettet seyn.", "tokens": ["Da", "sie", "kann", "ge\u00b7ret\u00b7tet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.36": {"line.1": {"text": "Meine Mutter war aus Westenland,", "tokens": ["Mei\u00b7ne", "Mut\u00b7ter", "war", "aus", "Wes\u00b7ten\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Gelehrt in Schreiberei,", "tokens": ["Ge\u00b7lehrt", "in", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als ich noch zur Schule ging,", "tokens": ["Und", "als", "ich", "noch", "zur", "Schu\u00b7le", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bracht sie mir auch was bei.", "tokens": ["Bracht", "sie", "mir", "auch", "was", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Da w\u00e4chst ein Kraut im Felde hier,", "tokens": ["Da", "w\u00e4chst", "ein", "Kraut", "im", "Fel\u00b7de", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wer es kennet, traun,", "tokens": ["Und", "wer", "es", "ken\u00b7net", ",", "traun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der, ist er wei\u00df wie Milch und Blut,", "tokens": ["Der", ",", "ist", "er", "wei\u00df", "wie", "Milch", "und", "Blut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VAFIN", "PPER", "VVFIN", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dadurch schwarz und braun.", "tokens": ["Wird", "da\u00b7durch", "schwarz", "und", "braun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Und ist er dunkel, schwarz und braun,", "tokens": ["Und", "ist", "er", "dun\u00b7kel", ",", "schwarz", "und", "braun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht's schnell ihn wei\u00df und roth,", "tokens": ["Macht's", "schnell", "ihn", "wei\u00df", "und", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "PPER", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ist kein Schwert in Engelland,", "tokens": ["Und", "ist", "kein", "Schwert", "in", "En\u00b7gel\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das k\u00f6nnt ihm bringen Noth.", "tokens": ["Das", "k\u00f6nnt", "ihm", "brin\u00b7gen", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Und Ihr sollt seyn ein Harfner, Bruder,", "tokens": ["Und", "Ihr", "sollt", "seyn", "ein", "Harf\u00b7ner", ",", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Ein'r aus Norden pflegt,", "tokens": ["Wie", "Ein'r", "aus", "Nor\u00b7den", "pflegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ich will seyn eur Singer, Bruder,", "tokens": ["Und", "ich", "will", "seyn", "eur", "Sin\u00b7ger", ",", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VAINF", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der euch die Harfe tr\u00e4gt.", "tokens": ["Der", "euch", "die", "Har\u00b7fe", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Und Ihr sollt seyn der beste Harfner,", "tokens": ["Und", "Ihr", "sollt", "seyn", "der", "bes\u00b7te", "Harf\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der je die Harfe schlug,", "tokens": ["Der", "je", "die", "Har\u00b7fe", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ich will seyn der beste Singer,", "tokens": ["Und", "ich", "will", "seyn", "der", "bes\u00b7te", "Sin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der je die Harfe trug.", "tokens": ["Der", "je", "die", "Har\u00b7fe", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Und soll uns aufstehn auf der Stirn,", "tokens": ["Und", "soll", "uns", "auf\u00b7stehn", "auf", "der", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und All's durch Schreiberei,", "tokens": ["Und", "All's", "durch", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df wir im ganzen Christenthum", "tokens": ["Da\u00df", "wir", "im", "gan\u00b7zen", "Chris\u00b7ten\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wohl sind die K\u00fchnsten zwei.\u00ab", "tokens": ["Wohl", "sind", "die", "K\u00fchns\u00b7ten", "zwei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "CARD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Und so sie puzten sich zu reit'n,", "tokens": ["Und", "so", "sie", "puz\u00b7ten", "sich", "zu", "reit'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gepuzt war beider Ro\u00df,", "tokens": ["Ge\u00b7puzt", "war", "bei\u00b7der", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen zu Adlands Hall'n,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hall'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Golde gl\u00e4nzt ihr Tro\u00df.", "tokens": ["Von", "Gol\u00b7de", "gl\u00e4nzt", "ihr", "Tro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Und als sie kamen zu Adlands Hall'n", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hall'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wohl vor das veste Thor,", "tokens": ["Wohl", "vor", "das", "ves\u00b7te", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da fanden sie einen Pf\u00f6rtner stolz,", "tokens": ["Da", "fan\u00b7den", "sie", "ei\u00b7nen", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der aufthun sollt das Thor.", "tokens": ["Der", "auf\u00b7thun", "sollt", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Sprach: \u00bbGr\u00fc\u00df dich Gott, du Pf\u00f6rtner stolz!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "dich", "Gott", ",", "du", "Pf\u00f6rt\u00b7ner", "stolz", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "$,", "PPER", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbGr\u00fc\u00df dich Gott allhier!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "dich", "Gott", "all\u00b7hier", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbnun willkomm, sprach der Pf\u00f6rtner stolz,", "tokens": ["\u00bb", "nun", "will\u00b7komm", ",", "sprach", "der", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von wannen seyd denn ihr?\u00ab", "tokens": ["Von", "wan\u00b7nen", "seyd", "denn", "ihr", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VAFIN", "KON", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "\u00bbwir sind zwei Harfner, sprach Adler jung,", "tokens": ["\u00bb", "wir", "sind", "zwei", "Harf\u00b7ner", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "CARD", "NN", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus Nordland kommen wir;", "tokens": ["Aus", "Nord\u00b7land", "kom\u00b7men", "wir", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind angekommen, mit anzuschaun", "tokens": ["Sind", "an\u00b7ge\u00b7kom\u00b7men", ",", "mit", "an\u00b7zu\u00b7schaun"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "APPR", "VVIZU"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die reiche Hochzeit hier.\u00ab", "tokens": ["Die", "rei\u00b7che", "Hoch\u00b7zeit", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.46": {"line.1": {"text": "Sprach: \u00bbUnd Eur Farb ist wei\u00df und roth,", "tokens": ["Sprach", ":", "\u00bb", "Und", "Eur", "Farb", "ist", "wei\u00df", "und", "roth", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und Eur' ist schwarz und braun;", "tokens": ["Und", "Eur'", "ist", "schwarz", "und", "braun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "K\u00f6nig Ehstmer (Esthmer) und sein Bruder ist hier,", "tokens": ["K\u00f6\u00b7nig", "Eh\u00b7stmer", "(", "Esth\u00b7mer", ")", "und", "sein", "Bru\u00b7der", "ist", "hier", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "NN", "$(", "KON", "PPOSAT", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Will ich ansagen, traun!\u00ab", "tokens": ["Will", "ich", "an\u00b7sa\u00b7gen", ",", "traun", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Ab sie zogen ein'n Ring von Gold,", "tokens": ["Ab", "sie", "zo\u00b7gen", "ein'n", "Ring", "von", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ihn legend an Pf\u00f6rtners Arm:", "tokens": ["Ihn", "le\u00b7gend", "an", "Pf\u00f6rt\u00b7ners", "Arm", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwir woll'n nicht dir, du Pf\u00f6rtner stolz,", "tokens": ["\u00bb", "wir", "woll'n", "nicht", "dir", ",", "du", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PTKNEG", "PPER", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du uns nicht sagen Harm!\u00ab", "tokens": ["Du", "uns", "nicht", "sa\u00b7gen", "Harm", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PRF", "PTKNEG", "VVINF", "NN", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.48": {"line.1": {"text": "Ernst er ansah K\u00f6nig Esthmer,", "tokens": ["Ernst", "er", "an\u00b7sah", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dann ernst auf seinen Ring,", "tokens": ["Dann", "ernst", "auf", "sei\u00b7nen", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann \u00f6fnet er ihnen das Gitterthor,", "tokens": ["Dann", "\u00f6f\u00b7net", "er", "ih\u00b7nen", "das", "Git\u00b7ter\u00b7thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sonst th\u00e4t ers um kein Ding.", "tokens": ["Sonst", "th\u00e4t", "ers", "um", "kein", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "K\u00f6nig Esthmer schwung sich ab vom Ro\u00df", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "schwung", "sich", "ab", "vom", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "PRF", "PTKVZ", "APPRART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "An K\u00f6nigs Halle hart.", "tokens": ["An", "K\u00f6\u00b7nigs", "Hal\u00b7le", "hart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Schaum, der stand vor Pferds Gebi\u00df,", "tokens": ["Der", "Schaum", ",", "der", "stand", "vor", "Pferds", "Ge\u00b7bi\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War wie K\u00f6nig Bremors Bart.", "tokens": ["War", "wie", "K\u00f6\u00b7nig", "Bre\u00b7mors", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "NN", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.50": {"line.1": {"text": "Sprach: \u00bbStall dein Ro\u00df, du Harfner stolz,", "tokens": ["Sprach", ":", "\u00bb", "Stall", "dein", "Ro\u00df", ",", "du", "Harf\u00b7ner", "stolz", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "PPOSAT", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh, stall es in den Stall!", "tokens": ["Geh", ",", "stall", "es", "in", "den", "Stall", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein'm solchen Harfner es nicht ziemt,", "tokens": ["Ein'm", "sol\u00b7chen", "Harf\u00b7ner", "es", "nicht", "ziemt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu stall'n in K\u00f6nigs Hall.\u00ab", "tokens": ["Zu", "stall'n", "in", "K\u00f6\u00b7nigs", "Hall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "VVFIN", "APPR", "NN", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "\u00bbich hab ein'n Jungen, der Harfner sprach,", "tokens": ["\u00bb", "ich", "hab", "ein'n", "Jun\u00b7gen", ",", "der", "Harf\u00b7ner", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der ist so keck und k\u00fchn,", "tokens": ["Der", "ist", "so", "keck", "und", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich wollt' ich f\u00e4nd' einmal den Mann,", "tokens": ["Ich", "wollt'", "ich", "f\u00e4nd'", "ein\u00b7mal", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der einst ihn z\u00fcchtigt' \u2013 ihn!\u00ab", "tokens": ["Der", "einst", "ihn", "z\u00fcch\u00b7tigt'", "\u2013", "ihn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADV", "PPER", "VVFIN", "$(", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "\u00bbdu sprichst wohl stolz, sprach der Heiden K\u00f6n'g,", "tokens": ["\u00bb", "du", "sprichst", "wohl", "stolz", ",", "sprach", "der", "Hei\u00b7den", "K\u00f6n'g", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADJD", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Du Harfner hier zu mir:", "tokens": ["Du", "Harf\u00b7ner", "hier", "zu", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da ist ein Mann in dieser Hall,", "tokens": ["Da", "ist", "ein", "Mann", "in", "die\u00b7ser", "Hall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Eins gibt ihm und dir.\u00ab", "tokens": ["Der", "Eins", "gibt", "ihm", "und", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "PPER", "$.", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.53": {"line.1": {"text": "\u00bbo la\u00df ihn kommen, der Harfner sprach,", "tokens": ["\u00bb", "o", "la\u00df", "ihn", "kom\u00b7men", ",", "der", "Harf\u00b7ner", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "VVIMP", "PPER", "VVINF", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich m\u00f6cht' ihn gern doch sehn.", "tokens": ["Ich", "m\u00f6cht'", "ihn", "gern", "doch", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn er's diesem gegeben hat,", "tokens": ["Und", "wenn", "er's", "die\u00b7sem", "ge\u00b7ge\u00b7ben", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PDAT", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Soll's \u00fcber mich ergehn.\u00ab", "tokens": ["Soll's", "\u00fc\u00b7ber", "mich", "er\u00b7gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Ab denn kam der K\u00e4mpfersmann,", "tokens": ["Ab", "denn", "kam", "der", "K\u00e4mp\u00b7fers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und schaut ihm ins Gesicht.", "tokens": ["Und", "schaut", "ihm", "ins", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Um alles Gold auf aller Welt", "tokens": ["Um", "al\u00b7les", "Gold", "auf", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dorft er sich nahn ihm nicht.", "tokens": ["Dorft", "er", "sich", "nahn", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PPER", "PTKNEG", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.55": {"line.1": {"text": "\u00bbund wie nun, K\u00e4mpfer? der K\u00f6nig sprach,", "tokens": ["\u00bb", "und", "wie", "nun", ",", "K\u00e4mp\u00b7fer", "?", "der", "K\u00f6\u00b7nig", "sprach", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "ADV", "$,", "NN", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und was kommt dir jezt bei?\u00ab", "tokens": ["Und", "was", "kommt", "dir", "jezt", "bei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er sprach: \u00bbDa stehts auf seiner Stirn,", "tokens": ["Er", "sprach", ":", "\u00bb", "Da", "stehts", "auf", "sei\u00b7ner", "Stirn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Alles durch Schreiberei!", "tokens": ["Und", "Al\u00b7les", "durch", "Schrei\u00b7be\u00b7rei", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Um alles Gold auf aller Welt", "tokens": ["Um", "al\u00b7les", "Gold", "auf", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich ihm nicht nahe bei.\u00ab", "tokens": ["Ich", "ihm", "nicht", "na\u00b7he", "bei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.56": {"line.1": {"text": "K\u00f6nig Esthmer dann die Harfe zog,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "dann", "die", "Har\u00b7fe", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und spielt darauf so s\u00fc\u00df.", "tokens": ["Und", "spielt", "da\u00b7rauf", "so", "s\u00fc\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aufstarrt die Braut an K\u00f6nigs Seit';", "tokens": ["Auf\u00b7starrt", "die", "Braut", "an", "K\u00f6\u00b7nigs", "Seit'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Heiden macht's Verdrie\u00df.", "tokens": ["Dem", "Hei\u00b7den", "macht's", "Ver\u00b7drie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.57": {"line.1": {"text": "\u00bbhalt ein dein' Harf, du Harfner stolz,", "tokens": ["\u00bb", "halt", "ein", "dein'", "Harf", ",", "du", "Harf\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "PPOSAT", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Halt ein, ich sag es dir,", "tokens": ["Halt", "ein", ",", "ich", "sag", "es", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn spielst du fort, als du beginnst,", "tokens": ["Denn", "spielst", "du", "fort", ",", "als", "du", "be\u00b7ginnst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meine Braut entspielst du mir.\u00ab", "tokens": ["Mei\u00b7ne", "Braut", "ent\u00b7spielst", "du", "mir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.58": {"line.1": {"text": "Er ri\u00df, er ri\u00df aufs neu die Harf,", "tokens": ["Er", "ri\u00df", ",", "er", "ri\u00df", "aufs", "neu", "die", "Harf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er spielt so sch\u00f6n und frei;", "tokens": ["Er", "spielt", "so", "sch\u00f6n", "und", "frei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Braut, die ward so wohlgemuth,", "tokens": ["Die", "Braut", ",", "die", "ward", "so", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lacht Eins und zwei und drei.", "tokens": ["Lacht", "Eins", "und", "zwei", "und", "drei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "CARD", "KON", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "\u00bbgib mir dein' Hart, der K\u00f6nig sprach,", "tokens": ["\u00bb", "gib", "mir", "dein'", "Hart", ",", "der", "K\u00f6\u00b7nig", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein' Harf und Saiten all,", "tokens": ["Dein'", "Harf", "und", "Sai\u00b7ten", "all", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "PIAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und so viel Goldst\u00fcck sollt du hab'n,", "tokens": ["Und", "so", "viel", "Gold\u00b7st\u00fcck", "sollt", "du", "hab'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als ihrer Saiten Zahl.\u00ab", "tokens": ["Als", "ih\u00b7rer", "Sai\u00b7ten", "Zahl", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.60": {"line.1": {"text": "\u00bbund was wollt ihr thun mit der Harf,", "tokens": ["\u00bb", "und", "was", "wollt", "ihr", "thun", "mit", "der", "Harf", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wenn ich sie Euch lassen th\u00e4t?\u00ab", "tokens": ["Wenn", "ich", "sie", "Euch", "las\u00b7sen", "th\u00e4t", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbmeine Braut so spielen wohlgemuth,", "tokens": ["\u00bb", "mei\u00b7ne", "Braut", "so", "spie\u00b7len", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "ADV", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn wir nun gehn zu Bett.\u00ab", "tokens": ["Wenn", "wir", "nun", "gehn", "zu", "Bett", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.61": {"line.1": {"text": "\u00bbso la\u00df mir denn deine sch\u00f6ne Braut", "tokens": ["\u00bb", "so", "la\u00df", "mir", "denn", "dei\u00b7ne", "sch\u00f6\u00b7ne", "Braut"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVIMP", "PPER", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So pr\u00e4chtig \u00fcber All',", "tokens": ["So", "pr\u00e4ch\u00b7tig", "\u00fc\u00b7ber", "All'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und so viel Goldst\u00fcck sollt du hab'n,", "tokens": ["Und", "so", "viel", "Gold\u00b7st\u00fcck", "sollt", "du", "hab'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Ring hier in der Hall.\u00ab", "tokens": ["Als", "Ring", "hier", "in", "der", "Hall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "\u00bbund was wolltst du mit der sch\u00f6nen Braut,", "tokens": ["\u00bb", "und", "was", "wolltst", "du", "mit", "der", "sch\u00f6\u00b7nen", "Braut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VMFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenn ich dir sie lassen th\u00e4t?", "tokens": ["Wenn", "ich", "dir", "sie", "las\u00b7sen", "th\u00e4t", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ziemt sich doch mehr f\u00fcr mich als dich,", "tokens": ["Ziemt", "sich", "doch", "mehr", "f\u00fcr", "mich", "als", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "APPR", "PPER", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sch\u00f6ne f\u00fchren zu Bett.\u00ab", "tokens": ["Die", "Sch\u00f6\u00b7ne", "f\u00fch\u00b7ren", "zu", "Bett", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.63": {"line.1": {"text": "Er spielt' aufs neu, strich laut und klar,", "tokens": ["Er", "spielt'", "aufs", "neu", ",", "strich", "laut", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJD", "$,", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Adler sang darein:", "tokens": ["Und", "Ad\u00b7ler", "sang", "da\u00b7rein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Braut, dein treuer Liebhaber es ist,", "tokens": ["\u00bb", "o", "Braut", ",", "dein", "treu\u00b7er", "Lieb\u00b7ha\u00b7ber", "es", "ist", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PPOSAT", "ADJA", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Kein Harfner, der K\u00f6nig dein!", "tokens": ["Kein", "Harf\u00b7ner", ",", "der", "K\u00f6\u00b7nig", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ART", "NN", "PPOSAT", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.64": {"line.1": {"text": "O Braut, dein treuer Liebhaber es ist;", "tokens": ["O", "Braut", ",", "dein", "treu\u00b7er", "Lieb\u00b7ha\u00b7ber", "es", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPOSAT", "ADJA", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Blick auf, blick auf und sieh,", "tokens": ["Blick", "auf", ",", "blick", "auf", "und", "sieh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVIMP", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu retten dich vom garst'gen Heid,", "tokens": ["Zu", "ret\u00b7ten", "dich", "vom", "gar\u00b7st'\u00b7gen", "Heid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sind wir zwei kommen allhie.\u00ab", "tokens": ["Sind", "wir", "zwei", "kom\u00b7men", "all\u00b7hie", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "CARD", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.65": {"line.1": {"text": "Die Braut blickt auf, die Braut ward so roth,", "tokens": ["Die", "Braut", "blickt", "auf", ",", "die", "Braut", "ward", "so", "roth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Blickt auf und ward so roth,", "tokens": ["Blickt", "auf", "und", "ward", "so", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Inde\u00df zog Adler sein scharfes Schwert,", "tokens": ["In\u00b7de\u00df", "zog", "Ad\u00b7ler", "sein", "schar\u00b7fes", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Der Sultan, er lag todt.", "tokens": ["Der", "Sul\u00b7tan", ",", "er", "lag", "todt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Auf standen denn die K\u00e4mpfer all,", "tokens": ["Auf", "stan\u00b7den", "denn", "die", "K\u00e4mp\u00b7fer", "all", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "ART", "NN", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schrien all' in grosser Noth:", "tokens": ["Schri\u00b7en", "all'", "in", "gros\u00b7ser", "Noth", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbverr\u00e4ther, hast den K\u00f6nig erschlagen \u2013", "tokens": ["\u00bb", "ver\u00b7r\u00e4\u00b7ther", ",", "hast", "den", "K\u00f6\u00b7nig", "er\u00b7schla\u00b7gen", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schnell sollt auch seyn todt.\u00ab", "tokens": ["Und", "schnell", "sollt", "auch", "seyn", "todt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VMFIN", "ADV", "PPOSAT", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.67": {"line.1": {"text": "K\u00f6nig Esthmer warf hinweg die Hart,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "warf", "hin\u00b7weg", "die", "Hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ergrif sein Schwert so schnell,", "tokens": ["Er\u00b7grif", "sein", "Schwert", "so", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Esthmer Er und Adler jung,", "tokens": ["Und", "Esth\u00b7mer", "Er", "und", "Ad\u00b7ler", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie fochten, als gegen die H\u00f6ll.", "tokens": ["Sie", "foch\u00b7ten", ",", "als", "ge\u00b7gen", "die", "H\u00f6ll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.68": {"line.1": {"text": "Und ihre Schwerter trafen so", "tokens": ["Und", "ih\u00b7re", "Schwer\u00b7ter", "tra\u00b7fen", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch H\u00fclf der Schreiberei,", "tokens": ["Durch", "H\u00fclf", "der", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df bald erschlagen die K\u00e4mpfer lagen,", "tokens": ["Da\u00df", "bald", "er\u00b7schla\u00b7gen", "die", "K\u00e4mp\u00b7fer", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder waren nicht mehr dabei.", "tokens": ["O\u00b7der", "wa\u00b7ren", "nicht", "mehr", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "PAV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.69": {"line.1": {"text": "K\u00f6nig Esthmer nahm die sch\u00f6ne Braut,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "nahm", "die", "sch\u00f6\u00b7ne", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "F\u00fchrt sie zum Weibe sich", "tokens": ["F\u00fchrt", "sie", "zum", "Wei\u00b7be", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Daheim ins lust'ge Engelland,", "tokens": ["Da\u00b7heim", "ins", "lust'\u00b7ge", "En\u00b7gel\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lebt da fr\u00f6liglich.", "tokens": ["Und", "lebt", "da", "fr\u00f6\u00b7lig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.70": {"line.1": {"text": "Horcht mir zu, ihr lieben Leut,", "tokens": ["Horcht", "mir", "zu", ",", "ihr", "lie\u00b7ben", "Leut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Neigt euer Ohr mir dar;", "tokens": ["Neigt", "eu\u00b7er", "Ohr", "mir", "dar", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich sing euch von ein'm Bruder Paar,", "tokens": ["Ich", "sing", "euch", "von", "ein'm", "Bru\u00b7der", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als je nur Eines war.", "tokens": ["Als", "je", "nur", "Ei\u00b7nes", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADV", "PIS", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Der Eine von ihnen hie\u00df Adler jung,", "tokens": ["Der", "Ei\u00b7ne", "von", "ih\u00b7nen", "hie\u00df", "Ad\u00b7ler", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "APPR", "PPER", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Der Andre K\u00f6nig Esthmer.", "tokens": ["Der", "And\u00b7re", "K\u00f6\u00b7nig", "Esth\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie waren so wackre M\u00e4nner in Thaten,", "tokens": ["Sie", "wa\u00b7ren", "so", "wack\u00b7re", "M\u00e4n\u00b7ner", "in", "Tha\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Als immer nah und ferne.", "tokens": ["Als", "im\u00b7mer", "nah", "und", "fer\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Und als sie trunken einst Bier und Wein", "tokens": ["Und", "als", "sie", "trun\u00b7ken", "einst", "Bier", "und", "Wein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "NN", "KON", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "In K\u00f6nig Esthmers Hallen:", "tokens": ["In", "K\u00f6\u00b7nig", "Esth\u00b7mers", "Hal\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwann wollt ihr nehmen ein Weib euch, Bruder,", "tokens": ["\u00bb", "wann", "wollt", "ihr", "neh\u00b7men", "ein", "Weib", "euch", ",", "Bru\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "VVFIN", "ART", "NN", "PPER", "$,", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ein Weib zur Freud uns allen?\u00ab", "tokens": ["Ein", "Weib", "zur", "Freud", "uns", "al\u00b7len", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PPER", "PIAT", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.73": {"line.1": {"text": "Denn besprach's K\u00f6nig Esthmer,", "tokens": ["Denn", "be\u00b7sprach's", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Antwort't ihm hastiglich:", "tokens": ["Ant\u00b7wort't", "ihm", "has\u00b7tig\u00b7lich", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "PPER", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbich wei\u00df kein Maid in allem Land,", "tokens": ["\u00bb", "ich", "wei\u00df", "kein", "Maid", "in", "al\u00b7lem", "Land", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PIAT", "NN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die w\u00e4r ein Weib f\u00fcr mich.\u00ab", "tokens": ["Die", "w\u00e4r", "ein", "Weib", "f\u00fcr", "mich", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.74": {"line.1": {"text": "\u00bbk\u00f6nig Adland hat eine Tochter, Bruder,", "tokens": ["\u00bb", "k\u00f6\u00b7nig", "Ad\u00b7land", "hat", "ei\u00b7ne", "Toch\u00b7ter", ",", "Bru\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "NN", "VAFIN", "ART", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Jeder nennt sie fein und sch\u00f6n;", "tokens": ["Je\u00b7der", "nennt", "sie", "fein", "und", "sch\u00f6n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "W\u00e4r ich hier K\u00f6nig an Eurer Statt,", "tokens": ["W\u00e4r", "ich", "hier", "K\u00f6\u00b7nig", "an", "Eu\u00b7rer", "Statt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Die Dam' w\u00e4r K\u00f6nigin.\u00ab", "tokens": ["Die", "Dam'", "w\u00e4r", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.75": {"line.1": {"text": "Sprach: \u00bbrath mir, rath mir, lieber Bruder,", "tokens": ["Sprach", ":", "\u00bb", "rath", "mir", ",", "rath", "mir", ",", "lie\u00b7ber", "Bru\u00b7der", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Durch's lust'ge Engelland", "tokens": ["Durch's", "lust'\u00b7ge", "En\u00b7gel\u00b7land"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo sollen wir einen Boten finden,", "tokens": ["Wo", "sol\u00b7len", "wir", "ei\u00b7nen", "Bo\u00b7ten", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der zwischen uns sey zur Hand.\u00ab", "tokens": ["Der", "zwi\u00b7schen", "uns", "sey", "zur", "Hand", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "PPER", "VAFIN", "APPRART", "NN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.76": {"line.1": {"text": "Sprach: \u00bbIhr m\u00fcst reiten selbst, mein Bruder;", "tokens": ["Sprach", ":", "\u00bb", "Ihr", "m\u00fcst", "rei\u00b7ten", "selbst", ",", "mein", "Bru\u00b7der", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VMFIN", "VVFIN", "ADV", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich will euch kompaneyn.", "tokens": ["Ich", "will", "euch", "kom\u00b7pa\u00b7neyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl mancher ist durch Boten betrogen;", "tokens": ["Wohl", "man\u00b7cher", "ist", "durch", "Bo\u00b7ten", "be\u00b7tro\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich f\u00fcrcht', auch ihr m\u00f6cht's seyn.\u00ab", "tokens": ["Ich", "f\u00fcrcht'", ",", "auch", "ihr", "m\u00f6cht's", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PPER", "VMFIN", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.77": {"line.1": {"text": "Und also puzten sie sich zu reiten,", "tokens": ["Und", "al\u00b7so", "puz\u00b7ten", "sie", "sich", "zu", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "PTKZU", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gepuzt war beider Ro\u00df;", "tokens": ["Ge\u00b7puzt", "war", "bei\u00b7der", "Ro\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen zu Adlands Hallen,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Golde gl\u00e4nzt ihr Tro\u00df.", "tokens": ["Von", "Gol\u00b7de", "gl\u00e4nzt", "ihr", "Tro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.78": {"line.1": {"text": "Und als sie kamen zu Adlands Hallen,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wohl vor das hohe Thor,", "tokens": ["Wohl", "vor", "das", "ho\u00b7he", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Allda sie fanden K\u00f6nig Adland selbst,", "tokens": ["All\u00b7da", "sie", "fan\u00b7den", "K\u00f6\u00b7nig", "Ad\u00b7land", "selbst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "NN", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Macht ihnen auf das Thor.", "tokens": ["Macht", "ih\u00b7nen", "auf", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.79": {"line.1": {"text": "\u00bbnun Gott mit Euch, K\u00f6nig Adland gut,", "tokens": ["\u00bb", "nun", "Gott", "mit", "Euch", ",", "K\u00f6\u00b7nig", "Ad\u00b7land", "gut", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "NN", "APPR", "PPER", "$,", "NN", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gott mit Euch immer und hier!\u00ab", "tokens": ["Gott", "mit", "Euch", "im\u00b7mer", "und", "hier", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PPER", "ADV", "KON", "ADV", "$.", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Sprach: \u00bbWillkomm, willkomm, K\u00f6nig Esthmer,", "tokens": ["Sprach", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Recht herzlich willkomm mir!\u00ab", "tokens": ["Recht", "herz\u00b7lich", "will\u00b7komm", "mir", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADJD", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.80": {"line.1": {"text": "\u00bbihr habt eine Tochter, sprach Adler jung,", "tokens": ["\u00bb", "ihr", "habt", "ei\u00b7ne", "Toch\u00b7ter", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Jeder nennt sie fein und sch\u00f6n.", "tokens": ["Je\u00b7der", "nennt", "sie", "fein", "und", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mein Bruder will sie nehmen zum Weib,", "tokens": ["Mein", "Bru\u00b7der", "will", "sie", "neh\u00b7men", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Zu Englands K\u00f6nigin.\u00ab", "tokens": ["Zu", "En\u00b7glands", "K\u00f6\u00b7ni\u00b7gin", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.81": {"line.1": {"text": "\u00bbund gestern war um meine Tochter hier", "tokens": ["\u00bb", "und", "ge\u00b7stern", "war", "um", "mei\u00b7ne", "Toch\u00b7ter", "hier"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "ADV", "VAFIN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "K\u00f6nig Bremor aus Spaniens Reich,", "tokens": ["K\u00f6\u00b7nig", "Bre\u00b7mor", "aus", "Spa\u00b7ni\u00b7ens", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "APPR", "NE", "NE", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Und da nickt sie ihr Nein ihm zu;", "tokens": ["Und", "da", "nickt", "sie", "ihr", "Nein", "ihm", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PPER", "PTKVZ", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ich f\u00fcrcht, sie thuts auch euch.\u00ab", "tokens": ["Ich", "f\u00fcrcht", ",", "sie", "thuts", "auch", "euch", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ADV", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.82": {"line.1": {"text": "\u00bbder K\u00f6nig von Spanien ist ein garst'ger Heid,", "tokens": ["\u00bb", "der", "K\u00f6\u00b7nig", "von", "Spa\u00b7ni\u00b7en", "ist", "ein", "gar\u00b7st'\u00b7ger", "Heid", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und glaubt an Mahomet.", "tokens": ["Und", "glaubt", "an", "Ma\u00b7ho\u00b7met", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "'s w\u00e4r Jammer um solch ein sch\u00f6nes Maid,", "tokens": ["'s", "w\u00e4r", "Jam\u00b7mer", "um", "solch", "ein", "sch\u00f6\u00b7nes", "Maid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "PIAT", "ART", "ADJA", "NN", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Da\u00df so ein Hund sie h\u00e4tt!\u00ab", "tokens": ["Da\u00df", "so", "ein", "Hund", "sie", "h\u00e4tt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "VAFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.83": {"line.1": {"text": "\u00bbaber sagt mir, (K\u00f6nig Esthmer sprach's)", "tokens": ["\u00bb", "a\u00b7ber", "sagt", "mir", ",", "(", "K\u00f6\u00b7nig", "Esth\u00b7mer", "sprach's", ")"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "$,", "$(", "NE", "NE", "NE", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ich bitt euch, sagt mirs zu,", "tokens": ["Ich", "bitt", "euch", ",", "sagt", "mirs", "zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df morgen ich Eure Tochter seh,", "tokens": ["Da\u00df", "mor\u00b7gen", "ich", "Eu\u00b7re", "Toch\u00b7ter", "seh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Eh ich wegreiten thu.\u00ab", "tokens": ["Eh", "ich", "weg\u00b7rei\u00b7ten", "thu", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "VVFIN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.84": {"line.1": {"text": "\u00bbund w\u00e4rs gleich sieben und noch mehr Jahr,", "tokens": ["\u00bb", "und", "w\u00e4rs", "gleich", "sie\u00b7ben", "und", "noch", "mehr", "Jahr", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "VAFIN", "ADV", "VVINF", "KON", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Seit sie war in der Hall,", "tokens": ["Seit", "sie", "war", "in", "der", "Hall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "So soll sie kommen um Euretwillen,", "tokens": ["So", "soll", "sie", "kom\u00b7men", "um", "Eu\u00b7ret\u00b7wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Zur Freud den G\u00e4sten all.\u00ab", "tokens": ["Zur", "Freud", "den", "G\u00e4s\u00b7ten", "all", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PIAT", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "Ab denn kam die sch\u00f6ne Maid", "tokens": ["Ab", "denn", "kam", "die", "sch\u00f6\u00b7ne", "Maid"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mit Jungfraun reicher Zahl,", "tokens": ["Mit", "Jung\u00b7fraun", "rei\u00b7cher", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wohl halb einhundert Ritter stolz", "tokens": ["Wohl", "halb", "ein\u00b7hun\u00b7dert", "Rit\u00b7ter", "stolz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Einleiten sie zur Hall,", "tokens": ["Ein\u00b7lei\u00b7ten", "sie", "zur", "Hall", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und noch so mancher Edelknab',", "tokens": ["Und", "noch", "so", "man\u00b7cher", "E\u00b7del\u00b7knab'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn'n aufzuwarten all.", "tokens": ["Ihn'n", "auf\u00b7zu\u00b7war\u00b7ten", "all", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "Die Goldst\u00fcck' all an ihrem Haupt,", "tokens": ["Die", "Gold\u00b7st\u00fcck", "all", "an", "ih\u00b7rem", "Haupt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PIAT", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hingen bis zu den Knien,", "tokens": ["Sie", "hin\u00b7gen", "bis", "zu", "den", "Kni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und jeder Ring an ihrem Fing'r", "tokens": ["Und", "je\u00b7der", "Ring", "an", "ih\u00b7rem", "Fing'r"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein heller Demant schien.", "tokens": ["Ein", "hel\u00b7ler", "De\u00b7mant", "schien", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.87": {"line.1": {"text": "Sprach: \u00bbGr\u00fc\u00df euch Gott, meine Dame sch\u00f6n!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "euch", "Gott", ",", "mei\u00b7ne", "Da\u00b7me", "sch\u00f6n", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "$,", "PPOSAT", "NN", "ADJD", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sprach: \u00bbGr\u00fc\u00df euch Gott allhier!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "euch", "Gott", "all\u00b7hier", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sprach: \u00bbWillkomm, willkomm, K\u00f6nig Esthmer,", "tokens": ["Sprach", ":", "\u00bb", "Will\u00b7komm", ",", "will\u00b7komm", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "ADJD", "$,", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Recht herzlich willkomm mir!", "tokens": ["Recht", "herz\u00b7lich", "will\u00b7komm", "mir", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.88": {"line.1": {"text": "Und liebt ihr mich denn, als ihr sagt,", "tokens": ["Und", "liebt", "ihr", "mich", "denn", ",", "als", "ihr", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PRF", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So herzlich und so treu,", "tokens": ["So", "herz\u00b7lich", "und", "so", "treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Warum ihr immer nur kommen seyd,", "tokens": ["Wa\u00b7rum", "ihr", "im\u00b7mer", "nur", "kom\u00b7men", "seyd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVINF", "VAFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Geb Gott, euch gl\u00fccklich sey!\u00ab", "tokens": ["Geb", "Gott", ",", "euch", "gl\u00fcck\u00b7lich", "sey", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "NN", "$,", "PPER", "ADJD", "VAFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.89": {"line.1": {"text": "Ein denn, sprach der Vater theur:", "tokens": ["Ein", "denn", ",", "sprach", "der", "Va\u00b7ter", "theur", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbmeine Tochter, Nein ich sag!", "tokens": ["\u00bb", "mei\u00b7ne", "Toch\u00b7ter", ",", "Nein", "ich", "sag", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "$,", "PTKANT", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Bedenk der K\u00f6nig von Spanien,", "tokens": ["Be\u00b7denk", "der", "K\u00f6\u00b7nig", "von", "Spa\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Was der sprach gestertag.", "tokens": ["Was", "der", "sprach", "ge\u00b7ster\u00b7tag", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "VVFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.90": {"line.1": {"text": "Wollt st\u00fcrzen ein mir Schl\u00f6ss'r und Hall'n?", "tokens": ["Wollt", "st\u00fcr\u00b7zen", "ein", "mir", "Schl\u00f6ss'r", "und", "Hall'n", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wollt rauben das Leben mir?", "tokens": ["Wollt", "rau\u00b7ben", "das", "Le\u00b7ben", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "ART", "NN", "PPER", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "F\u00fcrwahr, ich f\u00fcrcht' des Heiden Grimm,", "tokens": ["F\u00fcr\u00b7wahr", ",", "ich", "f\u00fcrcht'", "des", "Hei\u00b7den", "Grimm", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "VVFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wenn ich dies zugeb' dir.\u00ab", "tokens": ["Wenn", "ich", "dies", "zu\u00b7geb'", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PDS", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.91": {"line.1": {"text": "\u00bbeure Schl\u00f6sser und eure Th\u00fcrme, Vater,", "tokens": ["\u00bb", "eu\u00b7re", "Schl\u00f6s\u00b7ser", "und", "eu\u00b7re", "Th\u00fcr\u00b7me", ",", "Va\u00b7ter", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "KON", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Sind stark und vest gebaut,", "tokens": ["Sind", "stark", "und", "vest", "ge\u00b7baut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und darum wei\u00df ich nicht, was Euch", "tokens": ["Und", "da\u00b7rum", "wei\u00df", "ich", "nicht", ",", "was", "Euch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PAV", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "F\u00fcrm garst'gen Heiden graut.", "tokens": ["F\u00fcrm", "gar\u00b7st'\u00b7gen", "Hei\u00b7den", "graut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.92": {"line.1": {"text": "K\u00f6nig Esthmer, gebt mir Euer Wort,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", ",", "gebt", "mir", "Eu\u00b7er", "Wort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Beym Himmel und rechter Hand,", "tokens": ["Beym", "Him\u00b7mel", "und", "rech\u00b7ter", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df ihr mich nehmen wollt zum Weib,", "tokens": ["Da\u00df", "ihr", "mich", "neh\u00b7men", "wollt", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur K\u00f6n'gin in Eur Land.\u00ab", "tokens": ["Zur", "K\u00f6n'\u00b7gin", "in", "Eur", "Land", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.93": {"line.1": {"text": "K\u00f6nig Esthmer freudig gab sein Wort,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "freu\u00b7dig", "gab", "sein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADJD", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Beym Himmel und rechter Hand,", "tokens": ["Beym", "Him\u00b7mel", "und", "rech\u00b7ter", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Da\u00df er sie nehmen wollt zum Weib,", "tokens": ["Da\u00df", "er", "sie", "neh\u00b7men", "wollt", "zum", "Weib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zur K\u00f6n'gin in sein Land.", "tokens": ["Zur", "K\u00f6n'\u00b7gin", "in", "sein", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.94": {"line.1": {"text": "Nahm Urlaub von der sch\u00f6nen Braut,", "tokens": ["Nahm", "Ur\u00b7laub", "von", "der", "sch\u00f6\u00b7nen", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu gehn schnell in sein Reich,", "tokens": ["Zu", "gehn", "schnell", "in", "sein", "Reich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu suchen Herzog', Ritter und Grafen,", "tokens": ["Zu", "su\u00b7chen", "Her\u00b7zo\u00b7g'", ",", "Rit\u00b7ter", "und", "Gra\u00b7fen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie heimzuf\u00fchren gleich.", "tokens": ["Sie", "heim\u00b7zu\u00b7f\u00fch\u00b7ren", "gleich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.95": {"line.1": {"text": "Sie hatten geritten eine Meile kaum,", "tokens": ["Sie", "hat\u00b7ten", "ge\u00b7rit\u00b7ten", "ei\u00b7ne", "Mei\u00b7le", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eine Meile weit hinan,", "tokens": ["Ei\u00b7ne", "Mei\u00b7le", "weit", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als ein th\u00e4t kommen der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "th\u00e4t", "kom\u00b7men", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJD", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Mit manchem K\u00e4mpfersmann.", "tokens": ["Mit", "man\u00b7chem", "K\u00e4mp\u00b7fers\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.96": {"line.1": {"text": "Als ein th\u00e4t kommen der Span'sche K\u00f6nig,", "tokens": ["Als", "ein", "th\u00e4t", "kom\u00b7men", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mit manchem grimmen Baron,", "tokens": ["Mit", "man\u00b7chem", "grim\u00b7men", "Ba\u00b7ron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Noch heut zu freyn K\u00f6nig Adlands Tochter,", "tokens": ["Noch", "heut", "zu", "freyn", "K\u00f6\u00b7nig", "Ad\u00b7lands", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und morgen zu ziehn davon.", "tokens": ["Und", "mor\u00b7gen", "zu", "ziehn", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.97": {"line.1": {"text": "Stracks sandt sie K\u00f6nig Esthmer'n nach,", "tokens": ["Stracks", "sandt", "sie", "K\u00f6\u00b7nig", "Esth\u00b7mer'n", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "NN", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So schnell als bitter ihr graut,", "tokens": ["So", "schnell", "als", "bit\u00b7ter", "ihr", "graut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sollt eilig kommen und k\u00e4mpfen um sie,", "tokens": ["Sollt", "ei\u00b7lig", "kom\u00b7men", "und", "k\u00e4mp\u00b7fen", "um", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJD", "VVINF", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder immer aufgeben die Braut.", "tokens": ["O\u00b7der", "im\u00b7mer", "auf\u00b7ge\u00b7ben", "die", "Braut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.98": {"line.1": {"text": "Ein' Weil' der Edelknabe kam,", "tokens": ["Ein'", "Weil'", "der", "E\u00b7del\u00b7kna\u00b7be", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein' ander Weil' er lief,", "tokens": ["Ein'", "an\u00b7der", "Weil'", "er", "lief", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bis er K\u00f6nig Esthmern eingeholt,", "tokens": ["Bis", "er", "K\u00f6\u00b7nig", "Esth\u00b7mern", "ein\u00b7ge\u00b7holt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und schnell und hastig rief:", "tokens": ["Und", "schnell", "und", "has\u00b7tig", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.99": {"line.1": {"text": "\u00bbzeitung, Zeitung, K\u00f6nig Esthmer!\u00ab", "tokens": ["\u00bb", "zei\u00b7tung", ",", "Zei\u00b7tung", ",", "K\u00f6\u00b7nig", "Esth\u00b7mer", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "$,", "NN", "$,", "NN", "NN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00bbund was f\u00fcr Zeitung dann?\u00ab", "tokens": ["\u00bb", "und", "was", "f\u00fcr", "Zei\u00b7tung", "dann", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PWS", "APPR", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Zeitung mu\u00df ich euch sagen,", "tokens": ["\u00bb", "o", "Zei\u00b7tung", "mu\u00df", "ich", "euch", "sa\u00b7gen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die euch wohl schwer seyn kann.", "tokens": ["Die", "euch", "wohl", "schwer", "seyn", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.100": {"line.1": {"text": "Ihr hattet geritten eine Meile kaum,", "tokens": ["Ihr", "hat\u00b7tet", "ge\u00b7rit\u00b7ten", "ei\u00b7ne", "Mei\u00b7le", "kaum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Eine Meile weit hinan,", "tokens": ["Ei\u00b7ne", "Mei\u00b7le", "weit", "hi\u00b7nan", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als ein schon kam der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "schon", "kam", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit manchem K\u00e4mpfersmann.", "tokens": ["Mit", "man\u00b7chem", "K\u00e4mp\u00b7fers\u00b7mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.101": {"line.1": {"text": "Als ein schon kam der Span'sche K\u00f6nig", "tokens": ["Als", "ein", "schon", "kam", "der", "Span'\u00b7sche", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit manchem grimmen Baron,", "tokens": ["Mit", "man\u00b7chem", "grim\u00b7men", "Ba\u00b7ron", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Noch heut zu freyn K\u00f6nig Adlands Tochter,", "tokens": ["Noch", "heut", "zu", "freyn", "K\u00f6\u00b7nig", "Ad\u00b7lands", "Toch\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und morgen zu ziehn davon.", "tokens": ["Und", "mor\u00b7gen", "zu", "ziehn", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKZU", "VVINF", "PAV", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.102": {"line.1": {"text": "Die Dame sch\u00f6n Euch freundlich gr\u00fc\u00dft,", "tokens": ["Die", "Da\u00b7me", "sch\u00f6n", "Euch", "freund\u00b7lich", "gr\u00fc\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So sehr und bitter ihr graut,", "tokens": ["So", "sehr", "und", "bit\u00b7ter", "ihr", "graut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "KON", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Spricht: Ihr m\u00fcst kommen und fechten um sie,", "tokens": ["Spricht", ":", "Ihr", "m\u00fcst", "kom\u00b7men", "und", "fech\u00b7ten", "um", "sie", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PPER", "VMFIN", "VVINF", "KON", "VVFIN", "APPR", "PPER", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Od'r immer aufgeben die Braut.\u00ab", "tokens": ["Od'r", "im\u00b7mer", "auf\u00b7ge\u00b7ben", "die", "Braut", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "VVFIN", "ART", "NN", "$.", "$("], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.103": {"line.1": {"text": "Sprach: \u00bbrath mir, rath mir, lieber Bruder,", "tokens": ["Sprach", ":", "\u00bb", "rath", "mir", ",", "rath", "mir", ",", "lie\u00b7ber", "Bru\u00b7der", ","], "token_info": ["word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Wort und ich geh's ein,", "tokens": ["Dein", "Wort", "und", "ich", "geh's", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPER", "NE", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wes Weges sollen wir gehn und fechten?", "tokens": ["Wes", "We\u00b7ges", "sol\u00b7len", "wir", "gehn", "und", "fech\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VMFIN", "PPER", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Gerettet mu\u00df sie seyn.\u00ab", "tokens": ["Ge\u00b7ret\u00b7tet", "mu\u00df", "sie", "seyn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVPP", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.104": {"line.1": {"text": "\u00bbnun horcht mir zu, sprach Adler jung,", "tokens": ["\u00bb", "nun", "horcht", "mir", "zu", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Wort und geht es ein,", "tokens": ["Mein", "Wort", "und", "geht", "es", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So will ich gleich euch zeigen den Weg,", "tokens": ["So", "will", "ich", "gleich", "euch", "zei\u00b7gen", "den", "Weg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da sie kann gerettet seyn.", "tokens": ["Da", "sie", "kann", "ge\u00b7ret\u00b7tet", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.105": {"line.1": {"text": "Meine Mutter war aus Westenland,", "tokens": ["Mei\u00b7ne", "Mut\u00b7ter", "war", "aus", "Wes\u00b7ten\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Gelehrt in Schreiberei,", "tokens": ["Ge\u00b7lehrt", "in", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als ich noch zur Schule ging,", "tokens": ["Und", "als", "ich", "noch", "zur", "Schu\u00b7le", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bracht sie mir auch was bei.", "tokens": ["Bracht", "sie", "mir", "auch", "was", "bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.106": {"line.1": {"text": "Da w\u00e4chst ein Kraut im Felde hier,", "tokens": ["Da", "w\u00e4chst", "ein", "Kraut", "im", "Fel\u00b7de", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wer es kennet, traun,", "tokens": ["Und", "wer", "es", "ken\u00b7net", ",", "traun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VVINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der, ist er wei\u00df wie Milch und Blut,", "tokens": ["Der", ",", "ist", "er", "wei\u00df", "wie", "Milch", "und", "Blut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "VAFIN", "PPER", "VVFIN", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wird dadurch schwarz und braun.", "tokens": ["Wird", "da\u00b7durch", "schwarz", "und", "braun", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PAV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.107": {"line.1": {"text": "Und ist er dunkel, schwarz und braun,", "tokens": ["Und", "ist", "er", "dun\u00b7kel", ",", "schwarz", "und", "braun", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht's schnell ihn wei\u00df und roth,", "tokens": ["Macht's", "schnell", "ihn", "wei\u00df", "und", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "PPER", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ist kein Schwert in Engelland,", "tokens": ["Und", "ist", "kein", "Schwert", "in", "En\u00b7gel\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das k\u00f6nnt ihm bringen Noth.", "tokens": ["Das", "k\u00f6nnt", "ihm", "brin\u00b7gen", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "VVINF", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.108": {"line.1": {"text": "Und Ihr sollt seyn ein Harfner, Bruder,", "tokens": ["Und", "Ihr", "sollt", "seyn", "ein", "Harf\u00b7ner", ",", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Ein'r aus Norden pflegt,", "tokens": ["Wie", "Ein'r", "aus", "Nor\u00b7den", "pflegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ich will seyn eur Singer, Bruder,", "tokens": ["Und", "ich", "will", "seyn", "eur", "Sin\u00b7ger", ",", "Bru\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "VAINF", "PPOSAT", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der euch die Harfe tr\u00e4gt.", "tokens": ["Der", "euch", "die", "Har\u00b7fe", "tr\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.109": {"line.1": {"text": "Und Ihr sollt seyn der beste Harfner,", "tokens": ["Und", "Ihr", "sollt", "seyn", "der", "bes\u00b7te", "Harf\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der je die Harfe schlug,", "tokens": ["Der", "je", "die", "Har\u00b7fe", "schlug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und ich will seyn der beste Singer,", "tokens": ["Und", "ich", "will", "seyn", "der", "bes\u00b7te", "Sin\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der je die Harfe trug.", "tokens": ["Der", "je", "die", "Har\u00b7fe", "trug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.110": {"line.1": {"text": "Und soll uns aufstehn auf der Stirn,", "tokens": ["Und", "soll", "uns", "auf\u00b7stehn", "auf", "der", "Stirn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und All's durch Schreiberei,", "tokens": ["Und", "All's", "durch", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df wir im ganzen Christenthum", "tokens": ["Da\u00df", "wir", "im", "gan\u00b7zen", "Chris\u00b7ten\u00b7thum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wohl sind die K\u00fchnsten zwei.\u00ab", "tokens": ["Wohl", "sind", "die", "K\u00fchns\u00b7ten", "zwei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "CARD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.111": {"line.1": {"text": "Und so sie puzten sich zu reit'n,", "tokens": ["Und", "so", "sie", "puz\u00b7ten", "sich", "zu", "reit'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "VVFIN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gepuzt war beider Ro\u00df,", "tokens": ["Ge\u00b7puzt", "war", "bei\u00b7der", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und als sie kamen zu Adlands Hall'n,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hall'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von Golde gl\u00e4nzt ihr Tro\u00df.", "tokens": ["Von", "Gol\u00b7de", "gl\u00e4nzt", "ihr", "Tro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.112": {"line.1": {"text": "Und als sie kamen zu Adlands Hall'n", "tokens": ["Und", "als", "sie", "ka\u00b7men", "zu", "Ad\u00b7lands", "Hall'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPR", "NN", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wohl vor das veste Thor,", "tokens": ["Wohl", "vor", "das", "ves\u00b7te", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da fanden sie einen Pf\u00f6rtner stolz,", "tokens": ["Da", "fan\u00b7den", "sie", "ei\u00b7nen", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der aufthun sollt das Thor.", "tokens": ["Der", "auf\u00b7thun", "sollt", "das", "Thor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.113": {"line.1": {"text": "Sprach: \u00bbGr\u00fc\u00df dich Gott, du Pf\u00f6rtner stolz!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "dich", "Gott", ",", "du", "Pf\u00f6rt\u00b7ner", "stolz", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "$,", "PPER", "NN", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbGr\u00fc\u00df dich Gott allhier!\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gr\u00fc\u00df", "dich", "Gott", "all\u00b7hier", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "VVIMP", "PPER", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbnun willkomm, sprach der Pf\u00f6rtner stolz,", "tokens": ["\u00bb", "nun", "will\u00b7komm", ",", "sprach", "der", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$,", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von wannen seyd denn ihr?\u00ab", "tokens": ["Von", "wan\u00b7nen", "seyd", "denn", "ihr", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VAFIN", "KON", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.114": {"line.1": {"text": "\u00bbwir sind zwei Harfner, sprach Adler jung,", "tokens": ["\u00bb", "wir", "sind", "zwei", "Harf\u00b7ner", ",", "sprach", "Ad\u00b7ler", "jung", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "CARD", "NN", "$,", "VVFIN", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Aus Nordland kommen wir;", "tokens": ["Aus", "Nord\u00b7land", "kom\u00b7men", "wir", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sind angekommen, mit anzuschaun", "tokens": ["Sind", "an\u00b7ge\u00b7kom\u00b7men", ",", "mit", "an\u00b7zu\u00b7schaun"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "VVPP", "$,", "APPR", "VVIZU"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die reiche Hochzeit hier.\u00ab", "tokens": ["Die", "rei\u00b7che", "Hoch\u00b7zeit", "hier", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.115": {"line.1": {"text": "Sprach: \u00bbUnd Eur Farb ist wei\u00df und roth,", "tokens": ["Sprach", ":", "\u00bb", "Und", "Eur", "Farb", "ist", "wei\u00df", "und", "roth", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "KON", "PPOSAT", "NN", "VAFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Und Eur' ist schwarz und braun;", "tokens": ["Und", "Eur'", "ist", "schwarz", "und", "braun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "K\u00f6nig Ehstmer (Esthmer) und sein Bruder ist hier,", "tokens": ["K\u00f6\u00b7nig", "Eh\u00b7stmer", "(", "Esth\u00b7mer", ")", "und", "sein", "Bru\u00b7der", "ist", "hier", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "NN", "$(", "KON", "PPOSAT", "NN", "VAFIN", "ADV", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.4": {"text": "Will ich ansagen, traun!\u00ab", "tokens": ["Will", "ich", "an\u00b7sa\u00b7gen", ",", "traun", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["VMFIN", "PPER", "VVINF", "$,", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.116": {"line.1": {"text": "Ab sie zogen ein'n Ring von Gold,", "tokens": ["Ab", "sie", "zo\u00b7gen", "ein'n", "Ring", "von", "Gold", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Ihn legend an Pf\u00f6rtners Arm:", "tokens": ["Ihn", "le\u00b7gend", "an", "Pf\u00f6rt\u00b7ners", "Arm", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwir woll'n nicht dir, du Pf\u00f6rtner stolz,", "tokens": ["\u00bb", "wir", "woll'n", "nicht", "dir", ",", "du", "Pf\u00f6rt\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VMFIN", "PTKNEG", "PPER", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du uns nicht sagen Harm!\u00ab", "tokens": ["Du", "uns", "nicht", "sa\u00b7gen", "Harm", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PRF", "PTKNEG", "VVINF", "NN", "$.", "$("], "meter": "---+-+", "measure": "unknown.measure.di"}}, "stanza.117": {"line.1": {"text": "Ernst er ansah K\u00f6nig Esthmer,", "tokens": ["Ernst", "er", "an\u00b7sah", "K\u00f6\u00b7nig", "Esth\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "VVFIN", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Dann ernst auf seinen Ring,", "tokens": ["Dann", "ernst", "auf", "sei\u00b7nen", "Ring", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Dann \u00f6fnet er ihnen das Gitterthor,", "tokens": ["Dann", "\u00f6f\u00b7net", "er", "ih\u00b7nen", "das", "Git\u00b7ter\u00b7thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sonst th\u00e4t ers um kein Ding.", "tokens": ["Sonst", "th\u00e4t", "ers", "um", "kein", "Ding", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.118": {"line.1": {"text": "K\u00f6nig Esthmer schwung sich ab vom Ro\u00df", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "schwung", "sich", "ab", "vom", "Ro\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "VVFIN", "PRF", "PTKVZ", "APPRART", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "An K\u00f6nigs Halle hart.", "tokens": ["An", "K\u00f6\u00b7nigs", "Hal\u00b7le", "hart", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Schaum, der stand vor Pferds Gebi\u00df,", "tokens": ["Der", "Schaum", ",", "der", "stand", "vor", "Pferds", "Ge\u00b7bi\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "War wie K\u00f6nig Bremors Bart.", "tokens": ["War", "wie", "K\u00f6\u00b7nig", "Bre\u00b7mors", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "NN", "NE", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.119": {"line.1": {"text": "Sprach: \u00bbStall dein Ro\u00df, du Harfner stolz,", "tokens": ["Sprach", ":", "\u00bb", "Stall", "dein", "Ro\u00df", ",", "du", "Harf\u00b7ner", "stolz", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "PPOSAT", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Geh, stall es in den Stall!", "tokens": ["Geh", ",", "stall", "es", "in", "den", "Stall", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein'm solchen Harfner es nicht ziemt,", "tokens": ["Ein'm", "sol\u00b7chen", "Harf\u00b7ner", "es", "nicht", "ziemt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zu stall'n in K\u00f6nigs Hall.\u00ab", "tokens": ["Zu", "stall'n", "in", "K\u00f6\u00b7nigs", "Hall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "VVFIN", "APPR", "NN", "NE", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.120": {"line.1": {"text": "\u00bbich hab ein'n Jungen, der Harfner sprach,", "tokens": ["\u00bb", "ich", "hab", "ein'n", "Jun\u00b7gen", ",", "der", "Harf\u00b7ner", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der ist so keck und k\u00fchn,", "tokens": ["Der", "ist", "so", "keck", "und", "k\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich wollt' ich f\u00e4nd' einmal den Mann,", "tokens": ["Ich", "wollt'", "ich", "f\u00e4nd'", "ein\u00b7mal", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der einst ihn z\u00fcchtigt' \u2013 ihn!\u00ab", "tokens": ["Der", "einst", "ihn", "z\u00fcch\u00b7tigt'", "\u2013", "ihn", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "ADV", "PPER", "VVFIN", "$(", "PPER", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.121": {"line.1": {"text": "\u00bbdu sprichst wohl stolz, sprach der Heiden K\u00f6n'g,", "tokens": ["\u00bb", "du", "sprichst", "wohl", "stolz", ",", "sprach", "der", "Hei\u00b7den", "K\u00f6n'g", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ADV", "ADJD", "$,", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-+", "measure": "dactylic.init"}, "line.2": {"text": "Du Harfner hier zu mir:", "tokens": ["Du", "Harf\u00b7ner", "hier", "zu", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da ist ein Mann in dieser Hall,", "tokens": ["Da", "ist", "ein", "Mann", "in", "die\u00b7ser", "Hall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Eins gibt ihm und dir.\u00ab", "tokens": ["Der", "Eins", "gibt", "ihm", "und", "dir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "KON", "PPER", "$.", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.122": {"line.1": {"text": "\u00bbo la\u00df ihn kommen, der Harfner sprach,", "tokens": ["\u00bb", "o", "la\u00df", "ihn", "kom\u00b7men", ",", "der", "Harf\u00b7ner", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "VVIMP", "PPER", "VVINF", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich m\u00f6cht' ihn gern doch sehn.", "tokens": ["Ich", "m\u00f6cht'", "ihn", "gern", "doch", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und wenn er's diesem gegeben hat,", "tokens": ["Und", "wenn", "er's", "die\u00b7sem", "ge\u00b7ge\u00b7ben", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PDAT", "VVPP", "VAFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Soll's \u00fcber mich ergehn.\u00ab", "tokens": ["Soll's", "\u00fc\u00b7ber", "mich", "er\u00b7gehn", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "APPR", "PPER", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.123": {"line.1": {"text": "Ab denn kam der K\u00e4mpfersmann,", "tokens": ["Ab", "denn", "kam", "der", "K\u00e4mp\u00b7fers\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und schaut ihm ins Gesicht.", "tokens": ["Und", "schaut", "ihm", "ins", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Um alles Gold auf aller Welt", "tokens": ["Um", "al\u00b7les", "Gold", "auf", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dorft er sich nahn ihm nicht.", "tokens": ["Dorft", "er", "sich", "nahn", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "PPER", "PTKNEG", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.124": {"line.1": {"text": "\u00bbund wie nun, K\u00e4mpfer? der K\u00f6nig sprach,", "tokens": ["\u00bb", "und", "wie", "nun", ",", "K\u00e4mp\u00b7fer", "?", "der", "K\u00f6\u00b7nig", "sprach", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWAV", "ADV", "$,", "NN", "$.", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und was kommt dir jezt bei?\u00ab", "tokens": ["Und", "was", "kommt", "dir", "jezt", "bei", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er sprach: \u00bbDa stehts auf seiner Stirn,", "tokens": ["Er", "sprach", ":", "\u00bb", "Da", "stehts", "auf", "sei\u00b7ner", "Stirn", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Alles durch Schreiberei!", "tokens": ["Und", "Al\u00b7les", "durch", "Schrei\u00b7be\u00b7rei", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Um alles Gold auf aller Welt", "tokens": ["Um", "al\u00b7les", "Gold", "auf", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PIAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ich ihm nicht nahe bei.\u00ab", "tokens": ["Ich", "ihm", "nicht", "na\u00b7he", "bei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.125": {"line.1": {"text": "K\u00f6nig Esthmer dann die Harfe zog,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "dann", "die", "Har\u00b7fe", "zog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Und spielt darauf so s\u00fc\u00df.", "tokens": ["Und", "spielt", "da\u00b7rauf", "so", "s\u00fc\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Aufstarrt die Braut an K\u00f6nigs Seit';", "tokens": ["Auf\u00b7starrt", "die", "Braut", "an", "K\u00f6\u00b7nigs", "Seit'", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Heiden macht's Verdrie\u00df.", "tokens": ["Dem", "Hei\u00b7den", "macht's", "Ver\u00b7drie\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.126": {"line.1": {"text": "\u00bbhalt ein dein' Harf, du Harfner stolz,", "tokens": ["\u00bb", "halt", "ein", "dein'", "Harf", ",", "du", "Harf\u00b7ner", "stolz", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ART", "PPOSAT", "NN", "$,", "PPER", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Halt ein, ich sag es dir,", "tokens": ["Halt", "ein", ",", "ich", "sag", "es", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PTKVZ", "$,", "PPER", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn spielst du fort, als du beginnst,", "tokens": ["Denn", "spielst", "du", "fort", ",", "als", "du", "be\u00b7ginnst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Meine Braut entspielst du mir.\u00ab", "tokens": ["Mei\u00b7ne", "Braut", "ent\u00b7spielst", "du", "mir", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.127": {"line.1": {"text": "Er ri\u00df, er ri\u00df aufs neu die Harf,", "tokens": ["Er", "ri\u00df", ",", "er", "ri\u00df", "aufs", "neu", "die", "Harf", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "APPRART", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er spielt so sch\u00f6n und frei;", "tokens": ["Er", "spielt", "so", "sch\u00f6n", "und", "frei", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Braut, die ward so wohlgemuth,", "tokens": ["Die", "Braut", ",", "die", "ward", "so", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Lacht Eins und zwei und drei.", "tokens": ["Lacht", "Eins", "und", "zwei", "und", "drei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "CARD", "KON", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.128": {"line.1": {"text": "\u00bbgib mir dein' Hart, der K\u00f6nig sprach,", "tokens": ["\u00bb", "gib", "mir", "dein'", "Hart", ",", "der", "K\u00f6\u00b7nig", "sprach", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein' Harf und Saiten all,", "tokens": ["Dein'", "Harf", "und", "Sai\u00b7ten", "all", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "PIAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und so viel Goldst\u00fcck sollt du hab'n,", "tokens": ["Und", "so", "viel", "Gold\u00b7st\u00fcck", "sollt", "du", "hab'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als ihrer Saiten Zahl.\u00ab", "tokens": ["Als", "ih\u00b7rer", "Sai\u00b7ten", "Zahl", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.129": {"line.1": {"text": "\u00bbund was wollt ihr thun mit der Harf,", "tokens": ["\u00bb", "und", "was", "wollt", "ihr", "thun", "mit", "der", "Harf", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Wenn ich sie Euch lassen th\u00e4t?\u00ab", "tokens": ["Wenn", "ich", "sie", "Euch", "las\u00b7sen", "th\u00e4t", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbmeine Braut so spielen wohlgemuth,", "tokens": ["\u00bb", "mei\u00b7ne", "Braut", "so", "spie\u00b7len", "wohl\u00b7ge\u00b7muth", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "ADV", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Wenn wir nun gehn zu Bett.\u00ab", "tokens": ["Wenn", "wir", "nun", "gehn", "zu", "Bett", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.130": {"line.1": {"text": "\u00bbso la\u00df mir denn deine sch\u00f6ne Braut", "tokens": ["\u00bb", "so", "la\u00df", "mir", "denn", "dei\u00b7ne", "sch\u00f6\u00b7ne", "Braut"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "VVIMP", "PPER", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So pr\u00e4chtig \u00fcber All',", "tokens": ["So", "pr\u00e4ch\u00b7tig", "\u00fc\u00b7ber", "All'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PIS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und so viel Goldst\u00fcck sollt du hab'n,", "tokens": ["Und", "so", "viel", "Gold\u00b7st\u00fcck", "sollt", "du", "hab'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "NN", "VMFIN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Ring hier in der Hall.\u00ab", "tokens": ["Als", "Ring", "hier", "in", "der", "Hall", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.131": {"line.1": {"text": "\u00bbund was wolltst du mit der sch\u00f6nen Braut,", "tokens": ["\u00bb", "und", "was", "wolltst", "du", "mit", "der", "sch\u00f6\u00b7nen", "Braut", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "PWS", "VMFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Wenn ich dir sie lassen th\u00e4t?", "tokens": ["Wenn", "ich", "dir", "sie", "las\u00b7sen", "th\u00e4t", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ziemt sich doch mehr f\u00fcr mich als dich,", "tokens": ["Ziemt", "sich", "doch", "mehr", "f\u00fcr", "mich", "als", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADV", "APPR", "PPER", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sch\u00f6ne f\u00fchren zu Bett.\u00ab", "tokens": ["Die", "Sch\u00f6\u00b7ne", "f\u00fch\u00b7ren", "zu", "Bett", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.132": {"line.1": {"text": "Er spielt' aufs neu, strich laut und klar,", "tokens": ["Er", "spielt'", "aufs", "neu", ",", "strich", "laut", "und", "klar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJD", "$,", "ADJD", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und Adler sang darein:", "tokens": ["Und", "Ad\u00b7ler", "sang", "da\u00b7rein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbo Braut, dein treuer Liebhaber es ist,", "tokens": ["\u00bb", "o", "Braut", ",", "dein", "treu\u00b7er", "Lieb\u00b7ha\u00b7ber", "es", "ist", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$,", "PPOSAT", "ADJA", "NN", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Kein Harfner, der K\u00f6nig dein!", "tokens": ["Kein", "Harf\u00b7ner", ",", "der", "K\u00f6\u00b7nig", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "ART", "NN", "PPOSAT", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.133": {"line.1": {"text": "O Braut, dein treuer Liebhaber es ist;", "tokens": ["O", "Braut", ",", "dein", "treu\u00b7er", "Lieb\u00b7ha\u00b7ber", "es", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "PPOSAT", "ADJA", "NN", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Blick auf, blick auf und sieh,", "tokens": ["Blick", "auf", ",", "blick", "auf", "und", "sieh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "VVIMP", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu retten dich vom garst'gen Heid,", "tokens": ["Zu", "ret\u00b7ten", "dich", "vom", "gar\u00b7st'\u00b7gen", "Heid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPER", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sind wir zwei kommen allhie.\u00ab", "tokens": ["Sind", "wir", "zwei", "kom\u00b7men", "all\u00b7hie", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "CARD", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.134": {"line.1": {"text": "Die Braut blickt auf, die Braut ward so roth,", "tokens": ["Die", "Braut", "blickt", "auf", ",", "die", "Braut", "ward", "so", "roth", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Blickt auf und ward so roth,", "tokens": ["Blickt", "auf", "und", "ward", "so", "roth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Inde\u00df zog Adler sein scharfes Schwert,", "tokens": ["In\u00b7de\u00df", "zog", "Ad\u00b7ler", "sein", "schar\u00b7fes", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Der Sultan, er lag todt.", "tokens": ["Der", "Sul\u00b7tan", ",", "er", "lag", "todt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.135": {"line.1": {"text": "Auf standen denn die K\u00e4mpfer all,", "tokens": ["Auf", "stan\u00b7den", "denn", "die", "K\u00e4mp\u00b7fer", "all", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "ADV", "ART", "NN", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Schrien all' in grosser Noth:", "tokens": ["Schri\u00b7en", "all'", "in", "gros\u00b7ser", "Noth", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "\u00bbverr\u00e4ther, hast den K\u00f6nig erschlagen \u2013", "tokens": ["\u00bb", "ver\u00b7r\u00e4\u00b7ther", ",", "hast", "den", "K\u00f6\u00b7nig", "er\u00b7schla\u00b7gen", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und schnell sollt auch seyn todt.\u00ab", "tokens": ["Und", "schnell", "sollt", "auch", "seyn", "todt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VMFIN", "ADV", "PPOSAT", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.136": {"line.1": {"text": "K\u00f6nig Esthmer warf hinweg die Hart,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "warf", "hin\u00b7weg", "die", "Hart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Ergrif sein Schwert so schnell,", "tokens": ["Er\u00b7grif", "sein", "Schwert", "so", "schnell", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und Esthmer Er und Adler jung,", "tokens": ["Und", "Esth\u00b7mer", "Er", "und", "Ad\u00b7ler", "jung", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "KON", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie fochten, als gegen die H\u00f6ll.", "tokens": ["Sie", "foch\u00b7ten", ",", "als", "ge\u00b7gen", "die", "H\u00f6ll", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.137": {"line.1": {"text": "Und ihre Schwerter trafen so", "tokens": ["Und", "ih\u00b7re", "Schwer\u00b7ter", "tra\u00b7fen", "so"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch H\u00fclf der Schreiberei,", "tokens": ["Durch", "H\u00fclf", "der", "Schrei\u00b7be\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df bald erschlagen die K\u00e4mpfer lagen,", "tokens": ["Da\u00df", "bald", "er\u00b7schla\u00b7gen", "die", "K\u00e4mp\u00b7fer", "la\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder waren nicht mehr dabei.", "tokens": ["O\u00b7der", "wa\u00b7ren", "nicht", "mehr", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADV", "PAV", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.138": {"line.1": {"text": "K\u00f6nig Esthmer nahm die sch\u00f6ne Braut,", "tokens": ["K\u00f6\u00b7nig", "Esth\u00b7mer", "nahm", "die", "sch\u00f6\u00b7ne", "Braut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "F\u00fchrt sie zum Weibe sich", "tokens": ["F\u00fchrt", "sie", "zum", "Wei\u00b7be", "sich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Daheim ins lust'ge Engelland,", "tokens": ["Da\u00b7heim", "ins", "lust'\u00b7ge", "En\u00b7gel\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lebt da fr\u00f6liglich.", "tokens": ["Und", "lebt", "da", "fr\u00f6\u00b7lig\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}