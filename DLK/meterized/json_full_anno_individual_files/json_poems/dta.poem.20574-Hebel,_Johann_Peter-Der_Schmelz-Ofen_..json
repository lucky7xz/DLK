{"dta.poem.20574": {"metadata": {"author": {"name": "Hebel, Johann Peter", "birth": "N.A.", "death": "N.A."}, "title": "Der Schmelz-Ofen .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1803", "urn": "urn:nbn:de:kobv:b4-200905192133", "language": ["de:0.99"], "booktitle": "[Hebel, Johann Peter]: Allemannische Gedichte. Karlsruhe, 1803."}, "poem": {"stanza.1": {"line.1": {"text": "Jez brennt er in der sch\u00f6nsten Art,               ", "tokens": ["Jez", "brennt", "er", "in", "der", "sch\u00f6ns\u00b7ten", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und \u2019s Wasser ruuscht, der Blosbalg gahrt,", "tokens": ["und", "'s", "Was\u00b7ser", "ruuscht", ",", "der", "Blos\u00b7balg", "gahrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "und bis a\u00df d\u2019Nacht vom Himmel fallt,", "tokens": ["und", "bis", "a\u00df", "d'\u00b7Nacht", "vom", "Him\u00b7mel", "fallt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "se w\u00fcrd die ersti Ma\u00dfle chalt.", "tokens": ["se", "w\u00fcrd", "die", "ers\u00b7ti", "Ma\u00df\u00b7le", "chalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und \u2019s Wasser ruuscht, der Blosbalg gahrt;", "tokens": ["Und", "'s", "Was\u00b7ser", "ruuscht", ",", "der", "Blos\u00b7balg", "gahrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "i ha druf hi ne Gulde g\u2019spart.", "tokens": ["i", "ha", "druf", "hi", "ne", "Gul\u00b7de", "g'\u00b7spart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "FM", "FM", "NN", "VVPP", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Gang Ch\u00fcngi, lengis alte Wi,", "tokens": ["Gang", "Ch\u00fcn\u00b7gi", ",", "len\u00b7gis", "al\u00b7te", "Wi", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "mer wen e wengli lustig sy!", "tokens": ["mer", "wen", "e", "weng\u00b7li", "lus\u00b7tig", "sy", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "FM", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ne Freudestund isch nit verwehrt;", "tokens": ["Ne", "Freu\u00b7des\u00b7tund", "isch", "nit", "ver\u00b7wehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "me gnie\u00dft mit Dank, was Gott bischert,", "tokens": ["me", "gnie\u00dft", "mit", "Dank", ",", "was", "Gott", "bi\u00b7schert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "APPR", "NN", "$,", "PRELS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "me trinkt e frische frohe Mueth,", "tokens": ["me", "trinkt", "e", "fri\u00b7sche", "fro\u00b7he", "Mu\u00b7eth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "NE", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "und druf schmekt wieder \u2019s Schaffe gut.", "tokens": ["und", "druf", "schmekt", "wie\u00b7der", "'s", "Schaf\u00b7fe", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "ADV", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "E Frendestund, e guti Stund!", "tokens": ["E", "Fren\u00b7des\u00b7tund", ",", "e", "gu\u00b7ti", "Stund", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u2019s erhaltet Lib und Chr\u00e4fte gsund;", "tokens": ["'s", "er\u00b7hal\u00b7tet", "Lib", "und", "Chr\u00e4f\u00b7te", "gsund", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "doch mu\u00df es in der Ordnig goh,", "tokens": ["doch", "mu\u00df", "es", "in", "der", "Ord\u00b7nig", "goh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sust het me Schand und Leid dervo.", "tokens": ["sust", "het", "me", "Schand", "und", "Leid", "der\u00b7vo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VAFIN", "ADJA", "NN", "KON", "NN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.5": {"line.1": {"text": "E frohe Ma, ne brave Ma!", "tokens": ["E", "fro\u00b7he", "Ma", ",", "ne", "bra\u00b7ve", "Ma", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$,", "FM", "FM", "FM", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jez schenket i, und sto\u00dfet a:", "tokens": ["Jez", "schen\u00b7ket", "i", ",", "und", "sto\u00b7\u00dfet", "a", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$,", "KON", "VVFIN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "\u201ees leb der Marggrov und si Huus!\u201c", "tokens": ["\u201e", "es", "leb", "der", "Marg\u00b7grov", "und", "si", "Huus", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NE", "KON", "NE", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ziehnt d\u2019Chappen ab, und trinket us!", "tokens": ["Ziehnt", "d'\u00b7Chap\u00b7pen", "ab", ",", "und", "trin\u00b7ket", "us", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "PTKVZ", "$,", "KON", "VVFIN", "NE", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Ne bessere Her treit d\u2019Erde nit,", "tokens": ["Ne", "bes\u00b7se\u00b7re", "Her", "treit", "d'\u00b7Er\u00b7de", "nit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PDS", "PTKNEG", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "\u2019s isch Sege, was er thut und git,", "tokens": ["'s", "isch", "Se\u00b7ge", ",", "was", "er", "thut", "und", "git", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "i cha\u2019s nit sage, wieni sott:", "tokens": ["i", "cha's", "nit", "sa\u00b7ge", ",", "wie\u00b7ni", "sott", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "VVFIN", "$,", "FM.la", "FM.la", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Vergelts em Gott! Vergelts em Gott!", "tokens": ["Ver\u00b7gelts", "em", "Gott", "!", "Ver\u00b7gelts", "em", "Gott", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$.", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Und \u2019s Bergwerch soll im Sege stoh!", "tokens": ["Und", "'s", "Berg\u00b7werch", "soll", "im", "Se\u00b7ge", "stoh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "VMFIN", "APPRART", "NN", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "\u2019s het menge Burger \u2019s Brod dervo.", "tokens": ["'s", "het", "men\u00b7ge", "Bur\u00b7ger", "'s", "Brod", "der\u00b7vo", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJA", "NN", "PPER", "NN", "NE", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Der Her Inspekter lengt in Trog,", "tokens": ["Der", "Her", "Ins\u00b7pek\u00b7ter", "lengt", "in", "Trog", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und zahlt mit Freud, es isch kei Frog.", "tokens": ["und", "zahlt", "mit", "Freud", ",", "es", "isch", "kei", "Frog", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,", "PPER", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Drum schenket i, und sto\u00dfet a!", "tokens": ["Drum", "schen\u00b7ket", "i", ",", "und", "sto\u00b7\u00dfet", "a", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "$,", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Her Inspekter isch e Ma,", "tokens": ["Der", "Her", "Ins\u00b7pek\u00b7ter", "isch", "e", "Ma", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "FM", "FM", "FM", "FM", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit \u00fcsers Gattigs L\u00fcte gmei,", "tokens": ["mit", "\u00fc\u00b7sers", "Gat\u00b7tigs", "L\u00fc\u00b7te", "gmei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und fr\u00fcndli gege gro\u00df und chlei.", "tokens": ["und", "fr\u00fcnd\u00b7li", "ge\u00b7ge", "gro\u00df", "und", "chlei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADJD", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Er schafft e gute Wi ufs Werk,", "tokens": ["Er", "schafft", "e", "gu\u00b7te", "Wi", "ufs", "Werk", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "er holt en \u00fcber Thal und Berg,", "tokens": ["er", "holt", "en", "\u00fc\u00b7ber", "Thal", "und", "Berg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "FM", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er stellt en luter uffe Tisch,", "tokens": ["er", "stellt", "en", "lu\u00b7ter", "uf\u00b7fe", "Tisch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "FM", "FM", "FM", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und mi\u00dft wie\u2019s recht und billig isch.", "tokens": ["und", "mi\u00dft", "wie's", "recht", "und", "bil\u00b7lig", "isch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADJD", "KON", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sell isch verbey, der Ma am F\u00fc\u00fcr", "tokens": ["Sell", "isch", "ver\u00b7bey", ",", "der", "Ma", "am", "F\u00fc\u00fcr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "PTKVZ", "$,", "ART", "NE", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mu\u00df z\u2019trinke ha, w\u00e4rs no so th\u00fcr;", "tokens": ["mu\u00df", "z'\u00b7trin\u00b7ke", "ha", ",", "w\u00e4rs", "no", "so", "th\u00fcr", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "NE", "$,", "VAFIN", "NE", "ADV", "ADJD", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "es rieslet menge Tropfe Schwei\u00df,", "tokens": ["es", "ries\u00b7let", "men\u00b7ge", "Trop\u00b7fe", "Schwei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "und wills nit go, men \u00e4chzet eis.", "tokens": ["und", "wills", "nit", "go", ",", "men", "\u00e4ch\u00b7zet", "eis", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PTKNEG", "NE", "$,", "FM.la", "FM.la", "FM.la", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Me streift der Schwei\u00df am Ermel ab,", "tokens": ["Me", "streift", "der", "Schwei\u00df", "am", "Er\u00b7mel", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "me schnufet, d\u2019 B\u00e4lg verstuune drab,", "tokens": ["me", "schnu\u00b7fet", ",", "d'", "B\u00e4lg", "ver\u00b7stu\u00b7u\u00b7ne", "drab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VVFIN", "$,", "NE", "NN", "VVFIN", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und mengi liebi Mitternacht", "tokens": ["und", "men\u00b7gi", "lie\u00b7bi", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "FM", "FM", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "w\u00fcrd so am hei\u00dfe Herd verwacht.", "tokens": ["w\u00fcrd", "so", "am", "hei\u00b7\u00dfe", "Herd", "ver\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Der Schmelzer isch e plogte Ma,", "tokens": ["Der", "Schmel\u00b7zer", "isch", "e", "plog\u00b7te", "Ma", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "drum bringet em\u2019s, und sto\u00dfet a:", "tokens": ["drum", "brin\u00b7get", "em's", ",", "und", "sto\u00b7\u00dfet", "a", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NE", "$,", "KON", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gsegott! Vergi\u00df di Schwei\u00df und Ach,", "tokens": ["Gse\u00b7gott", "!", "Ver\u00b7gi\u00df", "di", "Schwei\u00df", "und", "Ach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVIMP", "NE", "NN", "KON", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "\u2019s het ieden anderen au si Sach!", "tokens": ["'s", "het", "ie\u00b7den", "an\u00b7de\u00b7ren", "au", "si", "Sach", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NE", "NE", "NE", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.13": {"line.1": {"text": "Am Zahltag theiltisch doch mit kei\u2019m,", "tokens": ["Am", "Zahl\u00b7tag", "theil\u00b7tisch", "doch", "mit", "kei'm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "ADV", "APPR", "PIAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und bringsch der Lohn im Nastuch heim,", "tokens": ["und", "bringsch", "der", "Lohn", "im", "Nas\u00b7tuch", "heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "se luegt di d\u2019Marei fr\u00fcndli a,", "tokens": ["se", "luegt", "di", "d'\u00b7Ma\u00b7rei", "fr\u00fcnd\u00b7li", "a", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und seit: \u201eJ ha ne brave Ma!\u201c", "tokens": ["und", "seit", ":", "\u201e", "J", "ha", "ne", "bra\u00b7ve", "Ma", "!", "\u201c"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "$.", "$(", "FM", "FM", "FM", "FM", "FM", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Druf schlacht sie Eiern-Anken i,", "tokens": ["Druf", "schlacht", "sie", "Ei\u00b7ern\u00b7An\u00b7ken", "i", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "nndundstr\u00e4ut e wenig Imber dri;               ", "tokens": ["nn\u00b7dund\u00b7str\u00e4ut", "e", "we\u00b7nig", "Im\u00b7ber", "dri", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "sie bringt Salat und Gr\u00fcebe dra,", "tokens": ["sie", "bringt", "Sa\u00b7lat", "und", "Gr\u00fce\u00b7be", "dra", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und seit: \u201eJez i\u00df du liebe Ma!\u201c", "tokens": ["und", "seit", ":", "\u201e", "Jez", "i\u00df", "du", "lie\u00b7be", "Ma", "!", "\u201c"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "$.", "$(", "NE", "VVFIN", "PPER", "VVFIN", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und wenn e Ma si Arbet thut,", "tokens": ["Und", "wenn", "e", "Ma", "si", "Ar\u00b7bet", "thut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "NE", "NE", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "se schmekt em au si Esse gut;", "tokens": ["se", "schmekt", "em", "au", "si", "Es\u00b7se", "gut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.it", "FM.it", "FM.it", "FM.it", "FM.it", "FM.it", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "er tuuschti nit in Leid und Lieb", "tokens": ["er", "tuuschti", "nit", "in", "Leid", "und", "Lieb"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "PTKNEG", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "mit mengem riche Galge-Dieb.", "tokens": ["mit", "men\u00b7gem", "ri\u00b7che", "Gal\u00b7ge\u00b7Dieb", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.16": {"line.1": {"text": "Mer sitze do, und \u2019s schmektis wohl.", "tokens": ["Mer", "sit\u00b7ze", "do", ",", "und", "'s", "schmek\u00b7tis", "wohl", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,", "KON", "PPER", "ADV", "ADV", "$."], "meter": "-+----+-+", "measure": "dactylic.init"}, "line.2": {"text": "Gang Ch\u00fcngeli lengis no nemol,", "tokens": ["Gang", "Ch\u00fcn\u00b7ge\u00b7li", "len\u00b7gis", "no", "ne\u00b7mol", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "FM", "FM", "FM", "FM", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "wil doch der Ofe wieder goht,", "tokens": ["wil", "doch", "der", "O\u00b7fe", "wie\u00b7der", "goht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "ADV", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und \u2019s Erz im volle Ch\u00fcbel stoht!", "tokens": ["und", "'s", "Erz", "im", "vol\u00b7le", "Ch\u00fc\u00b7bel", "stoht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.17": {"line.1": {"text": "Se brenn er denn zu guter Stund,", "tokens": ["Se", "brenn", "er", "denn", "zu", "gu\u00b7ter", "Stund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und Gott erhaltich alli gsund,", "tokens": ["und", "Gott", "er\u00b7hal\u00b7tich", "al\u00b7li", "gsund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und Gott biwahrich uf der Schicht,", "tokens": ["und", "Gott", "bi\u00b7wah\u00b7rich", "uf", "der", "Schicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "a\u00df niemes Leid und Ungl\u00fcck gschicht.", "tokens": ["a\u00df", "nie\u00b7mes", "Leid", "und", "Un\u00b7gl\u00fcck", "gschicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Und chunnt in strenger Winters-Zit,", "tokens": ["Und", "chunnt", "in", "stren\u00b7ger", "Win\u00b7ter\u00b7sZit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wenn Schnee uf Berg und Firste lit,", "tokens": ["wenn", "Schnee", "uf", "Berg", "und", "Firs\u00b7te", "lit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "en arme Bub, en arme Ma,", "tokens": ["en", "ar\u00b7me", "Bub", ",", "en", "ar\u00b7me", "Ma", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "ADJA", "NN", "$,", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und stoht ans F\u00fc\u00fcr, und w\u00e4rmt si dra,", "tokens": ["und", "stoht", "ans", "F\u00fc\u00fcr", ",", "und", "w\u00e4rmt", "si", "dra", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$,", "KON", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "und bringt e par Grumbireli,", "tokens": ["und", "bringt", "e", "par", "Grum\u00b7bi\u00b7re\u00b7li", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "FM", "FM", "FM", "$,"], "meter": "-+--+---", "measure": "iambic.di.relaxed"}, "line.2": {"text": "und leits ans F\u00fc\u00fcr, und brotet sie,", "tokens": ["und", "leits", "ans", "F\u00fc\u00fcr", ",", "und", "bro\u00b7tet", "sie", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "$,", "KON", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und schloft by\u2019m Setzer uffem Erz \u2014", "tokens": ["und", "schloft", "by'm", "Set\u00b7zer", "uf\u00b7fem", "Erz"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "schlof wohl, und tr\u00f6st der Gott di Herz!", "tokens": ["schlof", "wohl", ",", "und", "tr\u00f6st", "der", "Gott", "di", "Herz", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "KON", "VVFIN", "ART", "NN", "NE", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "D\u00f6rt stoht so ein! Chumm arme Ma,", "tokens": ["D\u00f6rt", "stoht", "so", "ein", "!", "Chumm", "ar\u00b7me", "Ma", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKVZ", "$.", "NE", "ADJA", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und thue eis Bscheid, mer sto\u00dfen a!", "tokens": ["und", "thue", "eis", "Bscheid", ",", "mer", "sto\u00b7\u00dfen", "a", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "NN", "$,", "ADV", "VVFIN", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gsegott, und tr\u00f6stder Gott di Herz,", "tokens": ["Gse\u00b7gott", ",", "und", "tr\u00f6st\u00b7der", "Gott", "di", "Herz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KON", "ADJA", "NN", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "me schloft nit lieblig uffem Erz!", "tokens": ["me", "schloft", "nit", "lieb\u00b7lig", "uf\u00b7fem", "Erz", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und chunnt zur Zit e Biderma", "tokens": ["Und", "chunnt", "zur", "Zit", "e", "Bi\u00b7der\u00b7ma"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "ans F\u00fc\u00fcr, und z\u00fcndet \u2019s Pfifli a,", "tokens": ["ans", "F\u00fc\u00fcr", ",", "und", "z\u00fcn\u00b7det", "'s", "Pfif\u00b7li", "a", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KON", "VVFIN", "PPER", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und sezt si n\u00e4umen ane mit,", "tokens": ["und", "sezt", "si", "n\u00e4u\u00b7men", "a\u00b7ne", "mit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "se schmeks em wohl, und \u2014 brenn di nit!", "tokens": ["se", "schmeks", "em", "wohl", ",", "und", "brenn", "di", "nit", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["FM", "FM", "FM", "ADV", "$,", "KON", "$(", "KON", "NE", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Doch fangt e B\u00fcebli z\u2019 ", "tokens": ["Doch", "fangt", "e", "B\u00fceb\u00b7li", "z'"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "NE", "NE", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "und meint, es ch\u00f6nns, as wie ne Ma,", "tokens": ["und", "meint", ",", "es", "ch\u00f6nns", ",", "as", "wie", "ne", "Ma", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPER", "NE", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "se macht der Schmelzer churze Bricht,", "tokens": ["se", "macht", "der", "Schmel\u00b7zer", "chur\u00b7ze", "Bricht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und zieht em \u2019s Pfifli usem Gsicht.", "tokens": ["und", "zieht", "em", "'s", "Pfif\u00b7li", "u\u00b7sem", "Gsicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "PPER", "NE", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.23": {"line.1": {"text": "Er keits ins F\u00fc\u00fcr, und balgt derzu:", "tokens": ["Er", "keits", "ins", "F\u00fc\u00fcr", ",", "und", "balgt", "der\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "$,", "KON", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201edu dunderschie\u00dfige Lappi du,", "tokens": ["\u201e", "du", "dun\u00b7der\u00b7schie\u00b7\u00dfi\u00b7ge", "Lap\u00b7pi", "du", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "ADJA", "NE", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u201esug amme Zipfeli Leberwurst,", "tokens": ["\u201e", "sug", "am\u00b7me", "Zip\u00b7fe\u00b7li", "Le\u00b7ber\u00b7wurst", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM.la", "FM.la", "FM.la", "FM.la", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "\u201e\u2019s isch besser f\u00fcr so chleini Burst!\u201c", "tokens": ["\u201e", "'s", "isch", "bes\u00b7ser", "f\u00fcr", "so", "chlei\u00b7ni", "Burst", "!", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADJD", "ADJD", "APPR", "ADV", "NE", "NE", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.24": {"line.1": {"text": "\u2019s isch wohr, \u2019s git mengi Churzwiil mehr", "tokens": ["'s", "isch", "wohr", ",", "'s", "git", "men\u00b7gi", "Chur\u00b7zwiil", "mehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "ADJD", "$,", "PPER", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "----+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "am Suntig no der Chinderlehr,", "tokens": ["am", "Sun\u00b7tig", "no", "der", "Chin\u00b7der\u00b7lehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und str\u00f6mt der f\u00fc\u00fcrig Ise-Bach", "tokens": ["und", "str\u00f6mt", "der", "f\u00fc\u00fc\u00b7rig", "I\u00b7se\u00b7Bach"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJD", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "im Sand, es isch e sch\u00f6ni Sach.", "tokens": ["im", "Sand", ",", "es", "isch", "e", "sch\u00f6\u00b7ni", "Sach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPER", "FM", "FM", "FM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Frog menge Ma: \u201eSag, Nochber he!", "tokens": ["Frog", "men\u00b7ge", "Ma", ":", "\u201e", "Sag", ",", "Noch\u00b7ber", "he", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "$.", "$(", "NN", "$,", "FM", "FM", "$."], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "\u201ehesch au scho \u2019s Ise werde seh", "tokens": ["\u201e", "hesch", "au", "scho", "'s", "I\u00b7se", "wer\u00b7de", "seh"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "NE", "NE", "PPER", "NE", "VAFIN", "NE"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u201eim f\u00fc\u00fcrige Strom de Forme no?\u201c", "tokens": ["\u201e", "im", "f\u00fc\u00fc\u00b7ri\u00b7ge", "Strom", "de", "For\u00b7me", "no", "?", "\u201c"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "APPRART", "ADJA", "NN", "NE", "NE", "NE", "$.", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Was gilts, er cha nit sage: Jo!", "tokens": ["Was", "gilts", ",", "er", "cha", "nit", "sa\u00b7ge", ":", "Jo", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "PPER", "NE", "PTKNEG", "VVFIN", "$.", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Mir w\u00fcsse, wie me \u2019s Ise macht,", "tokens": ["Mir", "w\u00fcs\u00b7se", ",", "wie", "me", "'s", "I\u00b7se", "macht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "VVFIN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und wie\u2019s im Sand zu Massle bacht,", "tokens": ["und", "wie's", "im", "Sand", "zu", "Mass\u00b7le", "bacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und wiemes druf in d\u2019Schmidte bringt,", "tokens": ["und", "wie\u00b7mes", "druf", "in", "d'\u00b7Schmid\u00b7te", "bringt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "und d\u2019Luppen unterm Hammer zwingt.", "tokens": ["und", "d'\u00b7Lup\u00b7pen", "un\u00b7term", "Ham\u00b7mer", "zwingt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.27": {"line.1": {"text": "Jez schenket i, und sto\u00dfet a:", "tokens": ["Jez", "schen\u00b7ket", "i", ",", "und", "sto\u00b7\u00dfet", "a", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "$,", "KON", "VVFIN", "NE", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "der Hammer-Meister isch au ne Ma!", "tokens": ["der", "Ham\u00b7mer\u00b7Meis\u00b7ter", "isch", "au", "ne", "Ma", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "NE", "NE", "NE", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "W\u00e4r Hammer-Schmid und Zeiner nit,", "tokens": ["W\u00e4r", "Ham\u00b7mer\u00b7Schmid", "und", "Zei\u00b7ner", "nit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "KON", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "do l\u00e4g e Sach, was th\u00e4t me mit?", "tokens": ["do", "l\u00e4g", "e", "Sach", ",", "was", "th\u00e4t", "me", "mit", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "$,", "PRELS", "ADJD", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}