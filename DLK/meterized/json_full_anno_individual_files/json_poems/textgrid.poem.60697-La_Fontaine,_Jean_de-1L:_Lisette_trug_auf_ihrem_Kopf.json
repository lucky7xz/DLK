{"textgrid.poem.60697": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Lisette trug auf ihrem Kopf", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lisette trug auf ihrem Kopf", "tokens": ["Li\u00b7set\u00b7te", "trug", "auf", "ih\u00b7rem", "Kopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf rundem Kissen einen Topf", "tokens": ["Auf", "run\u00b7dem", "Kis\u00b7sen", "ei\u00b7nen", "Topf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Voll Milch zur Stadt, daselbst das Labsal zu verkaufen.", "tokens": ["Voll", "Milch", "zur", "Stadt", ",", "da\u00b7selbst", "das", "Lab\u00b7sal", "zu", "ver\u00b7kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPRART", "NN", "$,", "PAV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie hatte, um behende und bequem zu laufen,", "tokens": ["Sie", "hat\u00b7te", ",", "um", "be\u00b7hen\u00b7de", "und", "be\u00b7quem", "zu", "lau\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUI", "ADJA", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gar leichte Schuhe und ein kurzes R\u00f6ckchen an", "tokens": ["Gar", "leich\u00b7te", "Schu\u00b7he", "und", "ein", "kur\u00b7zes", "R\u00f6ck\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ging mit gro\u00dfen Schritten munter gradeaus:", "tokens": ["Und", "ging", "mit", "gro\u00b7\u00dfen", "Schrit\u00b7ten", "mun\u00b7ter", "gra\u00b7de\u00b7aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn angenehm war das, was sie im Gehen sann.", "tokens": ["Denn", "an\u00b7ge\u00b7nehm", "war", "das", ",", "was", "sie", "im", "Ge\u00b7hen", "sann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PDS", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie z\u00e4hlte im voraus", "tokens": ["Sie", "z\u00e4hl\u00b7te", "im", "vo\u00b7raus"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Das Geld schon, das sie beim Verkauf der Milch gewann;", "tokens": ["Das", "Geld", "schon", ",", "das", "sie", "beim", "Ver\u00b7kauf", "der", "Milch", "ge\u00b7wann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sie will von dem Erl\u00f6s sich hundert Eier kaufen,", "tokens": ["Sie", "will", "von", "dem", "Er\u00b7l\u00f6s", "sich", "hun\u00b7dert", "Ei\u00b7er", "kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "PRF", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Will br\u00fcten lassen, und gewi\u00df, sie h\u00e4tte dann", "tokens": ["Will", "br\u00fc\u00b7ten", "las\u00b7sen", ",", "und", "ge\u00b7wi\u00df", ",", "sie", "h\u00e4t\u00b7te", "dann"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "VVINF", "$,", "KON", "ADV", "$,", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der sch\u00f6nsten K\u00fcckchen bald den sch\u00f6nsten Haufen.", "tokens": ["Der", "sch\u00f6ns\u00b7ten", "K\u00fcck\u00b7chen", "bald", "den", "sch\u00f6ns\u00b7ten", "Hau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und weiter spann Lisette so im Laufen:", "tokens": ["Und", "wei\u00b7ter", "spann", "Li\u00b7set\u00b7te", "so", "im", "Lau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "\u00bbich werde t\u00fcchtig mich bem\u00fchen,", "tokens": ["\u00bb", "ich", "wer\u00b7de", "t\u00fcch\u00b7tig", "mich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Rund um mein kleines Haus die H\u00fchner aufzuziehen.", "tokens": ["Rund", "um", "mein", "klei\u00b7nes", "Haus", "die", "H\u00fch\u00b7ner", "auf\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.16": {"text": "Es m\u00fc\u00dfte schon der schlimmste aller F\u00fcchse sein,", "tokens": ["Es", "m\u00fc\u00df\u00b7te", "schon", "der", "schlimms\u00b7te", "al\u00b7ler", "F\u00fcch\u00b7se", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der mir genug nicht \u00fcbrig lie\u00dfe von der Schar,", "tokens": ["Der", "mir", "ge\u00b7nug", "nicht", "\u00fcb\u00b7rig", "lie\u00b7\u00dfe", "von", "der", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df ich daf\u00fcr ein junges Schwein", "tokens": ["Da\u00df", "ich", "da\u00b7f\u00fcr", "ein", "jun\u00b7ges", "Schwein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Erhandeln k\u00f6nnte. \u00dcbers Jahr", "tokens": ["Er\u00b7han\u00b7deln", "k\u00f6nn\u00b7te", ".", "\u00dc\u00b7bers", "Jahr"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VMFIN", "$.", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ist's fett gemacht und tr\u00e4gt in bar", "tokens": ["Ist's", "fett", "ge\u00b7macht", "und", "tr\u00e4gt", "in", "bar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "VVPP", "KON", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Mir dann ein nettes S\u00fcmmchen ein.", "tokens": ["Mir", "dann", "ein", "net\u00b7tes", "S\u00fcmm\u00b7chen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ich geh und kaufe eine Kuh,", "tokens": ["Ich", "geh", "und", "kau\u00b7fe", "ei\u00b7ne", "Kuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die Kuh bekommt ein K\u00e4lbchen klein \u2013", "tokens": ["Die", "Kuh", "be\u00b7kommt", "ein", "K\u00e4lb\u00b7chen", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Ach, wird das eine Freude sein,", "tokens": ["Ach", ",", "wird", "das", "ei\u00b7ne", "Freu\u00b7de", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PDS", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Wenn wir es springen sehn \u2013 juhu!\u00ab", "tokens": ["Wenn", "wir", "es", "sprin\u00b7gen", "sehn", "\u2013", "ju\u00b7hu", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVINF", "$(", "ITJ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und voller Freude sprang Lisette selber.", "tokens": ["Und", "vol\u00b7ler", "Freu\u00b7de", "sprang", "Li\u00b7set\u00b7te", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "NE", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Da tanzte ihr vom Kopf", "tokens": ["Da", "tanz\u00b7te", "ihr", "vom", "Kopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Der milchgef\u00fcllte Topf \u2013", "tokens": ["Der", "milch\u00b7ge\u00b7f\u00fcll\u00b7te", "Topf", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Ade, ihr H\u00fchner, Schweine, K\u00fch und K\u00e4lber!", "tokens": ["A\u00b7de", ",", "ihr", "H\u00fch\u00b7ner", ",", "Schwei\u00b7ne", ",", "K\u00fch", "und", "K\u00e4l\u00b7ber", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.30": {"text": "Wie sch\u00f6ne Tr\u00e4ume beim Erwachen j\u00e4h zerflie\u00dfen.", "tokens": ["Wie", "sch\u00f6\u00b7ne", "Tr\u00e4u\u00b7me", "beim", "Er\u00b7wa\u00b7chen", "j\u00e4h", "zer\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die Leute aber haben lange noch gelacht", "tokens": ["Die", "Leu\u00b7te", "a\u00b7ber", "ha\u00b7ben", "lan\u00b7ge", "noch", "ge\u00b7lacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und aus Lisettens Milchtopf einen Schwank gemacht.", "tokens": ["Und", "aus", "Li\u00b7set\u00b7tens", "Milch\u00b7topf", "ei\u00b7nen", "Schwank", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wer liebte nicht des Phantasierens holden Duft?", "tokens": ["Wer", "lieb\u00b7te", "nicht", "des", "Phan\u00b7ta\u00b7sie\u00b7rens", "hol\u00b7den", "Duft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer baute nie ein stolzes Schlo\u00df sich in die Luft?", "tokens": ["Wer", "bau\u00b7te", "nie", "ein", "stol\u00b7zes", "Schlo\u00df", "sich", "in", "die", "Luft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Pikrocholos, Pyrrhus, Lisette, kurzum alle \u2013", "tokens": ["Pik\u00b7ro\u00b7cho\u00b7los", ",", "Pyrr\u00b7hus", ",", "Li\u00b7set\u00b7te", ",", "kur\u00b7zum", "al\u00b7le", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "ADV", "PIAT", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Kl\u00fcgste gleicht dem d\u00fcmmsten Kerl in diesem Falle.", "tokens": ["Der", "Kl\u00fcgs\u00b7te", "gleicht", "dem", "d\u00fcmms\u00b7ten", "Kerl", "in", "die\u00b7sem", "Fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir tr\u00e4umen jeden Schatz der Welt in unsre Hand,", "tokens": ["Wir", "tr\u00e4u\u00b7men", "je\u00b7den", "Schatz", "der", "Welt", "in", "uns\u00b7re", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erobern Ruhm und Frauen ohne Widerstand.", "tokens": ["Er\u00b7o\u00b7bern", "Ruhm", "und", "Frau\u00b7en", "oh\u00b7ne", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bin ich allein, so fordre Riesen ich heraus,", "tokens": ["Bin", "ich", "al\u00b7lein", ",", "so", "ford\u00b7re", "Rie\u00b7sen", "ich", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADV", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich jag den Perserschah aus seinem goldnen Haus,", "tokens": ["Ich", "jag", "den", "Per\u00b7ser\u00b7schah", "aus", "sei\u00b7nem", "gold\u00b7nen", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich werde K\u00f6nig, bin geliebt von meinem Volke,", "tokens": ["Ich", "wer\u00b7de", "K\u00f6\u00b7nig", ",", "bin", "ge\u00b7liebt", "von", "mei\u00b7nem", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Kronen kommen wie der Regen aus der Wolke.", "tokens": ["Die", "Kro\u00b7nen", "kom\u00b7men", "wie", "der", "Re\u00b7gen", "aus", "der", "Wol\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Schlie\u00dft ein Besinnen wieder zu der Tr\u00e4ume Tor,", "tokens": ["Schlie\u00dft", "ein", "Be\u00b7sin\u00b7nen", "wie\u00b7der", "zu", "der", "Tr\u00e4u\u00b7me", "Tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bin ich ein armer Kauz und T\u00f6lpel wie zuvor.", "tokens": ["Bin", "ich", "ein", "ar\u00b7mer", "Kauz", "und", "T\u00f6l\u00b7pel", "wie", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "KON", "NN", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Lisette trug auf ihrem Kopf", "tokens": ["Li\u00b7set\u00b7te", "trug", "auf", "ih\u00b7rem", "Kopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf rundem Kissen einen Topf", "tokens": ["Auf", "run\u00b7dem", "Kis\u00b7sen", "ei\u00b7nen", "Topf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Voll Milch zur Stadt, daselbst das Labsal zu verkaufen.", "tokens": ["Voll", "Milch", "zur", "Stadt", ",", "da\u00b7selbst", "das", "Lab\u00b7sal", "zu", "ver\u00b7kau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "APPRART", "NN", "$,", "PAV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie hatte, um behende und bequem zu laufen,", "tokens": ["Sie", "hat\u00b7te", ",", "um", "be\u00b7hen\u00b7de", "und", "be\u00b7quem", "zu", "lau\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUI", "ADJA", "KON", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gar leichte Schuhe und ein kurzes R\u00f6ckchen an", "tokens": ["Gar", "leich\u00b7te", "Schu\u00b7he", "und", "ein", "kur\u00b7zes", "R\u00f6ck\u00b7chen", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ging mit gro\u00dfen Schritten munter gradeaus:", "tokens": ["Und", "ging", "mit", "gro\u00b7\u00dfen", "Schrit\u00b7ten", "mun\u00b7ter", "gra\u00b7de\u00b7aus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn angenehm war das, was sie im Gehen sann.", "tokens": ["Denn", "an\u00b7ge\u00b7nehm", "war", "das", ",", "was", "sie", "im", "Ge\u00b7hen", "sann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PDS", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie z\u00e4hlte im voraus", "tokens": ["Sie", "z\u00e4hl\u00b7te", "im", "vo\u00b7raus"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Das Geld schon, das sie beim Verkauf der Milch gewann;", "tokens": ["Das", "Geld", "schon", ",", "das", "sie", "beim", "Ver\u00b7kauf", "der", "Milch", "ge\u00b7wann", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PPER", "APPRART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sie will von dem Erl\u00f6s sich hundert Eier kaufen,", "tokens": ["Sie", "will", "von", "dem", "Er\u00b7l\u00f6s", "sich", "hun\u00b7dert", "Ei\u00b7er", "kau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "PRF", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Will br\u00fcten lassen, und gewi\u00df, sie h\u00e4tte dann", "tokens": ["Will", "br\u00fc\u00b7ten", "las\u00b7sen", ",", "und", "ge\u00b7wi\u00df", ",", "sie", "h\u00e4t\u00b7te", "dann"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "VVINF", "$,", "KON", "ADV", "$,", "PPER", "VAFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der sch\u00f6nsten K\u00fcckchen bald den sch\u00f6nsten Haufen.", "tokens": ["Der", "sch\u00f6ns\u00b7ten", "K\u00fcck\u00b7chen", "bald", "den", "sch\u00f6ns\u00b7ten", "Hau\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und weiter spann Lisette so im Laufen:", "tokens": ["Und", "wei\u00b7ter", "spann", "Li\u00b7set\u00b7te", "so", "im", "Lau\u00b7fen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "\u00bbich werde t\u00fcchtig mich bem\u00fchen,", "tokens": ["\u00bb", "ich", "wer\u00b7de", "t\u00fcch\u00b7tig", "mich", "be\u00b7m\u00fc\u00b7hen", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Rund um mein kleines Haus die H\u00fchner aufzuziehen.", "tokens": ["Rund", "um", "mein", "klei\u00b7nes", "Haus", "die", "H\u00fch\u00b7ner", "auf\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "VVIZU", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.16": {"text": "Es m\u00fc\u00dfte schon der schlimmste aller F\u00fcchse sein,", "tokens": ["Es", "m\u00fc\u00df\u00b7te", "schon", "der", "schlimms\u00b7te", "al\u00b7ler", "F\u00fcch\u00b7se", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der mir genug nicht \u00fcbrig lie\u00dfe von der Schar,", "tokens": ["Der", "mir", "ge\u00b7nug", "nicht", "\u00fcb\u00b7rig", "lie\u00b7\u00dfe", "von", "der", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "PTKNEG", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df ich daf\u00fcr ein junges Schwein", "tokens": ["Da\u00df", "ich", "da\u00b7f\u00fcr", "ein", "jun\u00b7ges", "Schwein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Erhandeln k\u00f6nnte. \u00dcbers Jahr", "tokens": ["Er\u00b7han\u00b7deln", "k\u00f6nn\u00b7te", ".", "\u00dc\u00b7bers", "Jahr"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VMFIN", "$.", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Ist's fett gemacht und tr\u00e4gt in bar", "tokens": ["Ist's", "fett", "ge\u00b7macht", "und", "tr\u00e4gt", "in", "bar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJD", "VVPP", "KON", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Mir dann ein nettes S\u00fcmmchen ein.", "tokens": ["Mir", "dann", "ein", "net\u00b7tes", "S\u00fcmm\u00b7chen", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Ich geh und kaufe eine Kuh,", "tokens": ["Ich", "geh", "und", "kau\u00b7fe", "ei\u00b7ne", "Kuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die Kuh bekommt ein K\u00e4lbchen klein \u2013", "tokens": ["Die", "Kuh", "be\u00b7kommt", "ein", "K\u00e4lb\u00b7chen", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Ach, wird das eine Freude sein,", "tokens": ["Ach", ",", "wird", "das", "ei\u00b7ne", "Freu\u00b7de", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VAFIN", "PDS", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Wenn wir es springen sehn \u2013 juhu!\u00ab", "tokens": ["Wenn", "wir", "es", "sprin\u00b7gen", "sehn", "\u2013", "ju\u00b7hu", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVINF", "VVINF", "$(", "ITJ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Und voller Freude sprang Lisette selber.", "tokens": ["Und", "vol\u00b7ler", "Freu\u00b7de", "sprang", "Li\u00b7set\u00b7te", "sel\u00b7ber", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "NE", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Da tanzte ihr vom Kopf", "tokens": ["Da", "tanz\u00b7te", "ihr", "vom", "Kopf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Der milchgef\u00fcllte Topf \u2013", "tokens": ["Der", "milch\u00b7ge\u00b7f\u00fcll\u00b7te", "Topf", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Ade, ihr H\u00fchner, Schweine, K\u00fch und K\u00e4lber!", "tokens": ["A\u00b7de", ",", "ihr", "H\u00fch\u00b7ner", ",", "Schwei\u00b7ne", ",", "K\u00fch", "und", "K\u00e4l\u00b7ber", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.30": {"text": "Wie sch\u00f6ne Tr\u00e4ume beim Erwachen j\u00e4h zerflie\u00dfen.", "tokens": ["Wie", "sch\u00f6\u00b7ne", "Tr\u00e4u\u00b7me", "beim", "Er\u00b7wa\u00b7chen", "j\u00e4h", "zer\u00b7flie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "APPRART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die Leute aber haben lange noch gelacht", "tokens": ["Die", "Leu\u00b7te", "a\u00b7ber", "ha\u00b7ben", "lan\u00b7ge", "noch", "ge\u00b7lacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Und aus Lisettens Milchtopf einen Schwank gemacht.", "tokens": ["Und", "aus", "Li\u00b7set\u00b7tens", "Milch\u00b7topf", "ei\u00b7nen", "Schwank", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Wer liebte nicht des Phantasierens holden Duft?", "tokens": ["Wer", "lieb\u00b7te", "nicht", "des", "Phan\u00b7ta\u00b7sie\u00b7rens", "hol\u00b7den", "Duft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer baute nie ein stolzes Schlo\u00df sich in die Luft?", "tokens": ["Wer", "bau\u00b7te", "nie", "ein", "stol\u00b7zes", "Schlo\u00df", "sich", "in", "die", "Luft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Pikrocholos, Pyrrhus, Lisette, kurzum alle \u2013", "tokens": ["Pik\u00b7ro\u00b7cho\u00b7los", ",", "Pyrr\u00b7hus", ",", "Li\u00b7set\u00b7te", ",", "kur\u00b7zum", "al\u00b7le", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "ADV", "PIAT", "$("], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Der Kl\u00fcgste gleicht dem d\u00fcmmsten Kerl in diesem Falle.", "tokens": ["Der", "Kl\u00fcgs\u00b7te", "gleicht", "dem", "d\u00fcmms\u00b7ten", "Kerl", "in", "die\u00b7sem", "Fal\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir tr\u00e4umen jeden Schatz der Welt in unsre Hand,", "tokens": ["Wir", "tr\u00e4u\u00b7men", "je\u00b7den", "Schatz", "der", "Welt", "in", "uns\u00b7re", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Erobern Ruhm und Frauen ohne Widerstand.", "tokens": ["Er\u00b7o\u00b7bern", "Ruhm", "und", "Frau\u00b7en", "oh\u00b7ne", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bin ich allein, so fordre Riesen ich heraus,", "tokens": ["Bin", "ich", "al\u00b7lein", ",", "so", "ford\u00b7re", "Rie\u00b7sen", "ich", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "$,", "ADV", "ADJA", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ich jag den Perserschah aus seinem goldnen Haus,", "tokens": ["Ich", "jag", "den", "Per\u00b7ser\u00b7schah", "aus", "sei\u00b7nem", "gold\u00b7nen", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Ich werde K\u00f6nig, bin geliebt von meinem Volke,", "tokens": ["Ich", "wer\u00b7de", "K\u00f6\u00b7nig", ",", "bin", "ge\u00b7liebt", "von", "mei\u00b7nem", "Vol\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "$,", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Kronen kommen wie der Regen aus der Wolke.", "tokens": ["Die", "Kro\u00b7nen", "kom\u00b7men", "wie", "der", "Re\u00b7gen", "aus", "der", "Wol\u00b7ke", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Schlie\u00dft ein Besinnen wieder zu der Tr\u00e4ume Tor,", "tokens": ["Schlie\u00dft", "ein", "Be\u00b7sin\u00b7nen", "wie\u00b7der", "zu", "der", "Tr\u00e4u\u00b7me", "Tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "APPR", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bin ich ein armer Kauz und T\u00f6lpel wie zuvor.", "tokens": ["Bin", "ich", "ein", "ar\u00b7mer", "Kauz", "und", "T\u00f6l\u00b7pel", "wie", "zu\u00b7vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "KON", "NN", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}