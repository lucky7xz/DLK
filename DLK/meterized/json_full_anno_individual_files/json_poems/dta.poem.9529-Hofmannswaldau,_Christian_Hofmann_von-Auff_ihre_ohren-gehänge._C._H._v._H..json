{"dta.poem.9529": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Auff ihre ohren-geh\u00e4nge.  \n C. H. v. H.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1697", "urn": "urn:nbn:de:kobv:b4-200905199377", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Zwey cronen zeigten sich an meiner liebsten ohren/", "tokens": ["Zwey", "cro\u00b7nen", "zeig\u00b7ten", "sich", "an", "mei\u00b7ner", "liebs\u00b7ten", "oh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von westen kam ihr gold/ von ost ihr diamant;", "tokens": ["Von", "wes\u00b7ten", "kam", "ihr", "gold", "/", "von", "ost", "ihr", "di\u00b7a\u00b7mant", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PPOSAT", "NN", "$(", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Di\u00df alles war verm\u00e4hlt durch eine kluge hand/", "tokens": ["Di\u00df", "al\u00b7les", "war", "ver\u00b7m\u00e4hlt", "durch", "ei\u00b7ne", "klu\u00b7ge", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VAFIN", "VVPP", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und f\u00fcr die Lesbia zu einem schmuck erkohren.", "tokens": ["Und", "f\u00fcr", "die", "Les\u00b7bia", "zu", "ei\u00b7nem", "schmuck", "er\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPR", "ART", "ADJD", "VVINF", "$."], "meter": "----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Ich wei\u00df nicht wie mir war gelegenheit gebohren/", "tokens": ["Ich", "wei\u00df", "nicht", "wie", "mir", "war", "ge\u00b7le\u00b7gen\u00b7heit", "ge\u00b7boh\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PWAV", "PPER", "VAFIN", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df ich das g\u00f6tter-bild in einem garten fand/", "tokens": ["Da\u00df", "ich", "das", "g\u00f6t\u00b7ter\u00b7bild", "in", "ei\u00b7nem", "gar\u00b7ten", "fand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ART", "VVFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Al\u00df Flora neben ihr/ Pomona vor ihr stand/", "tokens": ["Al\u00df", "Flo\u00b7ra", "ne\u00b7ben", "ihr", "/", "Po\u00b7mo\u00b7na", "vor", "ihr", "stand", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "$(", "NE", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "So hab ich dieses wort/ so diesem folgt/ verlohrem:", "tokens": ["So", "hab", "ich", "die\u00b7ses", "wort", "/", "so", "die\u00b7sem", "folgt", "/", "ver\u00b7loh\u00b7rem", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PDAT", "NN", "$(", "ADV", "PDAT", "VVFIN", "$(", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Gecr\u00f6nte K\u00f6nigin/ von mehr als tausend hertzen/", "tokens": ["Ge\u00b7cr\u00f6n\u00b7te", "K\u00f6\u00b7ni\u00b7gin", "/", "von", "mehr", "als", "tau\u00b7send", "hert\u00b7zen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "APPR", "PIAT", "KOKOM", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die kr\u00e4ftig sind entbrannt von deiner augen kertzen.", "tokens": ["Die", "kr\u00e4f\u00b7tig", "sind", "ent\u00b7brannt", "von", "dei\u00b7ner", "au\u00b7gen", "kert\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "VVPP", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Du bist des himmels kind/ und f\u00fchrst des himmels schein/", "tokens": ["Du", "bist", "des", "him\u00b7mels", "kind", "/", "und", "f\u00fchrst", "des", "him\u00b7mels", "schein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$(", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Was sag ich K\u00f6nigin? o G\u00f6ttin! sollen cronen", "tokens": ["Was", "sag", "ich", "K\u00f6\u00b7ni\u00b7gin", "?", "o", "G\u00f6t\u00b7tin", "!", "sol\u00b7len", "cro\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "NN", "$.", "FM", "NN", "$.", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der liebes-m\u00e4rtyrer/ die du gemacht/ belohnen/", "tokens": ["Der", "lie\u00b7bes\u00b7m\u00e4r\u00b7ty\u00b7rer", "/", "die", "du", "ge\u00b7macht", "/", "be\u00b7loh\u00b7nen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "$(", "PRELS", "PPER", "VVPP", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So m\u00fcsten ihrer mehr denn tausend tansend seyn.", "tokens": ["So", "m\u00fcs\u00b7ten", "ih\u00b7rer", "mehr", "denn", "tau\u00b7send", "tan\u00b7send", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADV", "ADV", "ADJD", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}