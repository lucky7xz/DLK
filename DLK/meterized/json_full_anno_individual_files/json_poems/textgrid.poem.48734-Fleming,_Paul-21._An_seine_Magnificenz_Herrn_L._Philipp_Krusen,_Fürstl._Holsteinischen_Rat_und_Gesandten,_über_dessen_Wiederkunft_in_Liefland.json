{"textgrid.poem.48734": {"metadata": {"author": {"name": "Fleming, Paul", "birth": "N.A.", "death": "N.A."}, "title": "21. An seine Magnificenz Herrn L. Philipp Krusen, F\u00fcrstl. Holsteinischen Rat und Gesandten, \u00fcber dessen Wiederkunft in Liefland", "genre": "verse", "period": "N.A.", "pub_year": 1624, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ob di\u00df zu wenig ist, denselben zu empfangen,", "tokens": ["Ob", "di\u00df", "zu", "we\u00b7nig", "ist", ",", "den\u00b7sel\u00b7ben", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "APPR", "PIS", "VAFIN", "$,", "PDS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der dir die Freiheit schafft und was darzu geh\u00f6rt,", "tokens": ["der", "dir", "die", "Frei\u00b7heit", "schafft", "und", "was", "dar\u00b7zu", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "KON", "PWS", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df unsers Pindus Preis auch wird durch dich vermehrt,", "tokens": ["da\u00df", "un\u00b7sers", "Pin\u00b7dus", "Preis", "auch", "wird", "durch", "dich", "ver\u00b7mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "VAFIN", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und da\u00df nun billich kan mein Deutschland auf dich prangen,", "tokens": ["und", "da\u00df", "nun", "bil\u00b7lich", "kan", "mein", "Deutschland", "auf", "dich", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ADJD", "VMFIN", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "so la\u00df ihn dennoch drum nicht unentgegengangen,", "tokens": ["so", "la\u00df", "ihn", "den\u00b7noch", "drum", "nicht", "un\u00b7ent\u00b7ge\u00b7gen\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Thalia, meine Lust. Er will von dir geehrt,", "tokens": ["Tha\u00b7lia", ",", "mei\u00b7ne", "Lust", ".", "Er", "will", "von", "dir", "ge\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "von dir gepriesen sein. Tu, wie du bist gelehrt.", "tokens": ["von", "dir", "ge\u00b7prie\u00b7sen", "sein", ".", "Tu", ",", "wie", "du", "bist", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$.", "NE", "$,", "PWAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geh', sieh' ihn, sprich ihn an nach dem du tr\u00e4gst Verlangen.", "tokens": ["Geh'", ",", "sieh'", "ihn", ",", "sprich", "ihn", "an", "nach", "dem", "du", "tr\u00e4gst", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "PPER", "$,", "VVFIN", "PPER", "APPR", "APPR", "PRELS", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die, diese Wiederkunft, die gl\u00fcckliche, die macht,", "tokens": ["Die", ",", "die\u00b7se", "Wie\u00b7der\u00b7kunft", ",", "die", "gl\u00fcck\u00b7li\u00b7che", ",", "die", "macht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "PDAT", "NN", "$,", "ART", "ADJA", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df nun ein jeder ist auf Fr\u00f6lichkeit bedacht,", "tokens": ["da\u00df", "nun", "ein", "je\u00b7der", "ist", "auf", "Fr\u00f6\u00b7lich\u00b7keit", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "PIS", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und spricht: Gl\u00fcck zu, Gl\u00fcck zu, zu diesem sch\u00f6nen Stande!", "tokens": ["und", "spricht", ":", "Gl\u00fcck", "zu", ",", "Gl\u00fcck", "zu", ",", "zu", "die\u00b7sem", "sch\u00f6\u00b7nen", "Stan\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "PTKVZ", "$,", "NN", "PTKVZ", "$,", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.4": {"line.1": {"text": "Solt du alleine stum, alleine b\u00e4urisch sein?", "tokens": ["Solt", "du", "al\u00b7lei\u00b7ne", "stum", ",", "al\u00b7lei\u00b7ne", "b\u00e4u\u00b7risch", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nein. Tritt mit unter sie und stimme mitte drein.", "tokens": ["Nein", ".", "Tritt", "mit", "un\u00b7ter", "sie", "und", "stim\u00b7me", "mit\u00b7te", "drein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "APPR", "APPR", "PPER", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wilkommen, Herr zur See, wilkommen Herr zu Lande!", "tokens": ["Wil\u00b7kom\u00b7men", ",", "Herr", "zur", "See", ",", "wil\u00b7kom\u00b7men", "Herr", "zu", "Lan\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPRART", "NN", "$,", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ob di\u00df zu wenig ist, denselben zu empfangen,", "tokens": ["Ob", "di\u00df", "zu", "we\u00b7nig", "ist", ",", "den\u00b7sel\u00b7ben", "zu", "emp\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "APPR", "PIS", "VAFIN", "$,", "PDS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der dir die Freiheit schafft und was darzu geh\u00f6rt,", "tokens": ["der", "dir", "die", "Frei\u00b7heit", "schafft", "und", "was", "dar\u00b7zu", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "KON", "PWS", "PAV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "da\u00df unsers Pindus Preis auch wird durch dich vermehrt,", "tokens": ["da\u00df", "un\u00b7sers", "Pin\u00b7dus", "Preis", "auch", "wird", "durch", "dich", "ver\u00b7mehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "NN", "ADV", "VAFIN", "APPR", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und da\u00df nun billich kan mein Deutschland auf dich prangen,", "tokens": ["und", "da\u00df", "nun", "bil\u00b7lich", "kan", "mein", "Deutschland", "auf", "dich", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "ADJD", "VMFIN", "PPOSAT", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "so la\u00df ihn dennoch drum nicht unentgegengangen,", "tokens": ["so", "la\u00df", "ihn", "den\u00b7noch", "drum", "nicht", "un\u00b7ent\u00b7ge\u00b7gen\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Thalia, meine Lust. Er will von dir geehrt,", "tokens": ["Tha\u00b7lia", ",", "mei\u00b7ne", "Lust", ".", "Er", "will", "von", "dir", "ge\u00b7ehrt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "von dir gepriesen sein. Tu, wie du bist gelehrt.", "tokens": ["von", "dir", "ge\u00b7prie\u00b7sen", "sein", ".", "Tu", ",", "wie", "du", "bist", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVPP", "VAINF", "$.", "NE", "$,", "PWAV", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Geh', sieh' ihn, sprich ihn an nach dem du tr\u00e4gst Verlangen.", "tokens": ["Geh'", ",", "sieh'", "ihn", ",", "sprich", "ihn", "an", "nach", "dem", "du", "tr\u00e4gst", "Ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVIMP", "PPER", "$,", "VVFIN", "PPER", "APPR", "APPR", "PRELS", "PPER", "VVFIN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Die, diese Wiederkunft, die gl\u00fcckliche, die macht,", "tokens": ["Die", ",", "die\u00b7se", "Wie\u00b7der\u00b7kunft", ",", "die", "gl\u00fcck\u00b7li\u00b7che", ",", "die", "macht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "PDAT", "NN", "$,", "ART", "ADJA", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "da\u00df nun ein jeder ist auf Fr\u00f6lichkeit bedacht,", "tokens": ["da\u00df", "nun", "ein", "je\u00b7der", "ist", "auf", "Fr\u00f6\u00b7lich\u00b7keit", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "PIS", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "und spricht: Gl\u00fcck zu, Gl\u00fcck zu, zu diesem sch\u00f6nen Stande!", "tokens": ["und", "spricht", ":", "Gl\u00fcck", "zu", ",", "Gl\u00fcck", "zu", ",", "zu", "die\u00b7sem", "sch\u00f6\u00b7nen", "Stan\u00b7de", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "PTKVZ", "$,", "NN", "PTKVZ", "$,", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Solt du alleine stum, alleine b\u00e4urisch sein?", "tokens": ["Solt", "du", "al\u00b7lei\u00b7ne", "stum", ",", "al\u00b7lei\u00b7ne", "b\u00e4u\u00b7risch", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nein. Tritt mit unter sie und stimme mitte drein.", "tokens": ["Nein", ".", "Tritt", "mit", "un\u00b7ter", "sie", "und", "stim\u00b7me", "mit\u00b7te", "drein", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "NN", "APPR", "APPR", "PPER", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wilkommen, Herr zur See, wilkommen Herr zu Lande!", "tokens": ["Wil\u00b7kom\u00b7men", ",", "Herr", "zur", "See", ",", "wil\u00b7kom\u00b7men", "Herr", "zu", "Lan\u00b7de", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "APPRART", "NN", "$,", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}