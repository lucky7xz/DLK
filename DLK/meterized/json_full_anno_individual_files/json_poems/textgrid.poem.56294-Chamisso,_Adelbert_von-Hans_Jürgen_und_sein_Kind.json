{"textgrid.poem.56294": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "Hans J\u00fcrgen und sein Kind", "genre": "verse", "period": "N.A.", "pub_year": 1832, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hans J\u00fcrgen, l\u00e4\u00dft du das Trinken nicht sein,", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "l\u00e4\u00dft", "du", "das", "Trin\u00b7ken", "nicht", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "VAINF", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und l\u00e4\u00dft nicht vom leidigen Branntewein,", "tokens": ["Und", "l\u00e4\u00dft", "nicht", "vom", "lei\u00b7di\u00b7gen", "Brann\u00b7te\u00b7wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Du wirst zur Verzweiflung mich bringen;", "tokens": ["Du", "wirst", "zur", "Ver\u00b7zwei\u00b7flung", "mich", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Im Weiher dort ist's bald geschehn,", "tokens": ["Im", "Wei\u00b7her", "dort", "ist's", "bald", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da wirst du dein Kind mich ertr\u00e4nken sehn,", "tokens": ["Da", "wirst", "du", "dein", "Kind", "mich", "er\u00b7tr\u00e4n\u00b7ken", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mich selbst hinunter springen. \u2013", "tokens": ["Mich", "selbst", "hin\u00b7un\u00b7ter", "sprin\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ach Frau, sei mir darum nicht gram,", "tokens": ["Ach", "Frau", ",", "sei", "mir", "da\u00b7rum", "nicht", "gram", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VAFIN", "PPER", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00df selber kaum, wie gestern es kam,", "tokens": ["Wei\u00df", "sel\u00b7ber", "kaum", ",", "wie", "ge\u00b7stern", "es", "kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der goldene L\u00f6w ist schuldig;", "tokens": ["Der", "gol\u00b7de\u00b7ne", "L\u00f6w", "ist", "schul\u00b7dig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ich kam an der Schenke vor\u00fcber und sann,", "tokens": ["Ich", "kam", "an", "der", "Schen\u00b7ke", "vor\u00b7\u00fc\u00b7ber", "und", "sann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Das Tier mich anzuglotzen begann,", "tokens": ["Das", "Tier", "mich", "an\u00b7zu\u00b7glot\u00b7zen", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVIZU", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der L\u00f6w, er glei\u00dfte so guldig.", "tokens": ["Der", "L\u00f6w", ",", "er", "glei\u00df\u00b7te", "so", "gul\u00b7dig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ich ging hinein, das war nicht gut,", "tokens": ["Ich", "ging", "hin\u00b7ein", ",", "das", "war", "nicht", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich trank, hinaus zu gehn, mir Mut,", "tokens": ["Ich", "trank", ",", "hin\u00b7aus", "zu", "gehn", ",", "mir", "Mut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APZR", "PTKZU", "VVINF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kam unter dem Tische zu liegen;", "tokens": ["Kam", "un\u00b7ter", "dem", "Ti\u00b7sche", "zu", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Wenn abermals es dem Teufel gelang,", "tokens": ["Wenn", "a\u00b7ber\u00b7mals", "es", "dem", "Teu\u00b7fel", "ge\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sei, liebes Herz, darum nicht bang,", "tokens": ["Sei", ",", "lie\u00b7bes", "Herz", ",", "da\u00b7rum", "nicht", "bang", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er soll nicht wieder mich kriegen.", "tokens": ["Er", "soll", "nicht", "wie\u00b7der", "mich", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Die Augen zu! Ein Wort, ein Mann.", "tokens": ["Die", "Au\u00b7gen", "zu", "!", "Ein", "Wort", ",", "ein", "Mann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bringe dir heut, was ich alles gewann,", "tokens": ["Ich", "brin\u00b7ge", "dir", "heut", ",", "was", "ich", "al\u00b7les", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und eine trockene Kehle.", "tokens": ["Und", "ei\u00b7ne", "tro\u00b7cke\u00b7ne", "Keh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So ging er zu seinem Meister hin,", "tokens": ["So", "ging", "er", "zu", "sei\u00b7nem", "Meis\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es lag ihm schwer in seinem Sinn,", "tokens": ["Es", "lag", "ihm", "schwer", "in", "sei\u00b7nem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es qu\u00e4lt' ihn in seiner Seele.", "tokens": ["Es", "qu\u00e4lt'", "ihn", "in", "sei\u00b7ner", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.5": {"line.1": {"text": "Und als es Feierabend war", "tokens": ["Und", "als", "es", "Fei\u00b7er\u00b7a\u00b7bend", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und heim er kam, da f\u00fchlt' er gar", "tokens": ["Und", "heim", "er", "kam", ",", "da", "f\u00fchlt'", "er", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den leidigen Durst ihn bei\u00dfen.", "tokens": ["Den", "lei\u00b7di\u00b7gen", "Durst", "ihn", "bei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die Augen zu! Er kam mit Gl\u00fcck", "tokens": ["Die", "Au\u00b7gen", "zu", "!", "Er", "kam", "mit", "Gl\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Klippe vorbei, da schaut' er zur\u00fcck,", "tokens": ["Der", "Klip\u00b7pe", "vor\u00b7bei", ",", "da", "schaut'", "er", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Er sah den L\u00f6wen so glei\u00dfen. \u2013", "tokens": ["Er", "sah", "den", "L\u00f6\u00b7wen", "so", "glei\u00b7\u00dfen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Jedweder Tugend ihren Lohn!", "tokens": ["Jed\u00b7we\u00b7der", "Tu\u00b7gend", "ih\u00b7ren", "Lohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verdient, wahrhaftig, hab ich ihn schon,", "tokens": ["Ver\u00b7di\u00b7ent", ",", "wahr\u00b7haf\u00b7tig", ",", "hab", "ich", "ihn", "schon", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "VAFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Ein Schluck darauf wird schmecken! \u2013", "tokens": ["Ein", "Schluck", "da\u00b7rauf", "wird", "schme\u00b7cken", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PAV", "VAFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und taumelnd gelangt' er und sp\u00e4t nach Haus,", "tokens": ["Und", "tau\u00b7melnd", "ge\u00b7langt'", "er", "und", "sp\u00e4t", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KON", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Die Frau sa\u00df da, sah finster aus,", "tokens": ["Die", "Frau", "sa\u00df", "da", ",", "sah", "fins\u00b7ter", "aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er mu\u00dfte vor ihr erschrecken.", "tokens": ["Er", "mu\u00df\u00b7te", "vor", "ihr", "er\u00b7schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie pr\u00fcft' ihn mit den Augen stumm;", "tokens": ["Sie", "pr\u00fcft'", "ihn", "mit", "den", "Au\u00b7gen", "stumm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ging ihm seltsam im Kopf herum,", "tokens": ["Sie", "ging", "ihm", "selt\u00b7sam", "im", "Kopf", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gedenkend der eigenen Schw\u00fcre.", "tokens": ["Ge\u00b7den\u00b7kend", "der", "ei\u00b7ge\u00b7nen", "Schw\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Sie aber schritt zu der Wiege hin,", "tokens": ["Sie", "a\u00b7ber", "schritt", "zu", "der", "Wie\u00b7ge", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und nahm das Kind, das gelegen darin,", "tokens": ["Und", "nahm", "das", "Kind", ",", "das", "ge\u00b7le\u00b7gen", "da\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "VVPP", "PAV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und eilte hinaus zur T\u00fcre.", "tokens": ["Und", "eil\u00b7te", "hin\u00b7aus", "zur", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.8": {"line.1": {"text": "Er ist da n\u00fcchtern geworden fast,", "tokens": ["Er", "ist", "da", "n\u00fcch\u00b7tern", "ge\u00b7wor\u00b7den", "fast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VAPP", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein kaltes Entsetzen hat ihn erfa\u00dft: \u2013", "tokens": ["Ein", "kal\u00b7tes", "Ent\u00b7set\u00b7zen", "hat", "ihn", "er\u00b7fa\u00dft", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Dahin, dahin gekommen! \u2013", "tokens": ["Da\u00b7hin", ",", "da\u00b7hin", "ge\u00b7kom\u00b7men", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["PAV", "$,", "PAV", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hans J\u00fcrgen, rette, rette dein Kind!", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "ret\u00b7te", ",", "ret\u00b7te", "dein", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Zum Weiher, zum Weiher! geschwind, geschwind!", "tokens": ["Zum", "Wei\u00b7her", ",", "zum", "Wei\u00b7her", "!", "ge\u00b7schwind", ",", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Sie hat den Weg genommen. \u2013", "tokens": ["Sie", "hat", "den", "Weg", "ge\u00b7nom\u00b7men", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er eilt ihr nach in vollem Lauf,", "tokens": ["Er", "eilt", "ihr", "nach", "in", "vol\u00b7lem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Pl\u00e4tschern schallt vom Weiher herauf, \u2013", "tokens": ["Ein", "Pl\u00e4t\u00b7schern", "schallt", "vom", "Wei\u00b7her", "her\u00b7auf", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nur noch die Mutter zu sehen: \u2013", "tokens": ["Nur", "noch", "die", "Mut\u00b7ter", "zu", "se\u00b7hen", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Zur\u00fcck! das Kind, ich hol es hervor,", "tokens": ["Zu\u00b7r\u00fcck", "!", "das", "Kind", ",", "ich", "hol", "es", "her\u00b7vor", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$.", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Noch halten's die schwimmenden T\u00fccher empor,", "tokens": ["Noch", "hal\u00b7ten's", "die", "schwim\u00b7men\u00b7den", "T\u00fc\u00b7cher", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Zur\u00fcck! genug ist geschehen. \u2013", "tokens": ["Zu\u00b7r\u00fcck", "!", "ge\u00b7nug", "ist", "ge\u00b7sche\u00b7hen", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PTKVZ", "$.", "ADV", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Er schreit es und springt in das Wasser hinein, \u2013", "tokens": ["Er", "schreit", "es", "und", "springt", "in", "das", "Was\u00b7ser", "hin\u00b7ein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Wasser, das mochte so tief nicht sein,", "tokens": ["Das", "Was\u00b7ser", ",", "das", "moch\u00b7te", "so", "tief", "nicht", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "ADV", "ADJD", "PTKNEG", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die Beute leicht zu erhalten.", "tokens": ["Die", "Beu\u00b7te", "leicht", "zu", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er tr\u00e4gt das Wickelkind im Arm,", "tokens": ["Er", "tr\u00e4gt", "das", "Wi\u00b7ckel\u00b7kind", "im", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und dr\u00fcckt's an die Brust so innig und warm,", "tokens": ["Und", "dr\u00fcckt's", "an", "die", "Brust", "so", "in\u00b7nig", "und", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und steigt aus dem Bade, dem kalten. \u2013", "tokens": ["Und", "steigt", "aus", "dem", "Ba\u00b7de", ",", "dem", "kal\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.11": {"line.1": {"text": "\u00bban meinem Herzen, an meiner Brust,", "tokens": ["\u00bb", "an", "mei\u00b7nem", "Her\u00b7zen", ",", "an", "mei\u00b7ner", "Brust", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Du meine Wonne, du meine Lust!\u00ab", "tokens": ["Du", "mei\u00b7ne", "Won\u00b7ne", ",", "du", "mei\u00b7ne", "Lust", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch mu\u00dft du mich nicht so kratzen.", "tokens": ["Doch", "mu\u00dft", "du", "mich", "nicht", "so", "krat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein gutes, sch\u00f6nes Kind, allein", "tokens": ["Ein", "gu\u00b7tes", ",", "sch\u00f6\u00b7nes", "Kind", ",", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es kratzet doch ganz ungemein;", "tokens": ["Es", "krat\u00b7zet", "doch", "ganz", "un\u00b7ge\u00b7mein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was hast denn du f\u00fcr Tatzen? \u2013", "tokens": ["Was", "hast", "denn", "du", "f\u00fcr", "Tat\u00b7zen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "KON", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Und wie er's n\u00e4her untersucht,", "tokens": ["Und", "wie", "er's", "n\u00e4\u00b7her", "un\u00b7ter\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkennt er den schwarzen Kater und flucht,", "tokens": ["Er\u00b7kennt", "er", "den", "schwar\u00b7zen", "Ka\u00b7ter", "und", "flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Kater, ihm zum Possen. \u2013", "tokens": ["Den", "Ka\u00b7ter", ",", "ihm", "zum", "Pos\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PPER", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach Frau, ach Frau, wo bist denn du? \u2013", "tokens": ["Ach", "Frau", ",", "ach", "Frau", ",", "wo", "bist", "denn", "du", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "NN", "$,", "XY", "NN", "$,", "PWAV", "VAFIN", "KON", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sitzt zu Hause, die T\u00fcr ist zu,", "tokens": ["Die", "sitzt", "zu", "Hau\u00b7se", ",", "die", "T\u00fcr", "ist", "zu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,", "ART", "NN", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Die T\u00fcre bleibt verschlossen. \u2013", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ach Frau, das ist ein frostiger Spa\u00df;", "tokens": ["Ach", "Frau", ",", "das", "ist", "ein", "fros\u00b7ti\u00b7ger", "Spa\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es ist so kalt, ich bin so na\u00df. \u2013", "tokens": ["Es", "ist", "so", "kalt", ",", "ich", "bin", "so", "na\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die T\u00fcre bleibt verschlossen;", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wie er pocht und flucht und l\u00e4rmt,", "tokens": ["Und", "wie", "er", "pocht", "und", "flucht", "und", "l\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und fleht und winselt und sich h\u00e4rmt,", "tokens": ["Und", "fleht", "und", "win\u00b7selt", "und", "sich", "h\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die T\u00fcre bleibt verschlossen.", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Die Nachbarsleute, die G\u00e4ste zu Hauf", "tokens": ["Die", "Nach\u00b7bars\u00b7leu\u00b7te", ",", "die", "G\u00e4s\u00b7te", "zu", "Hauf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vom goldenen L\u00f6wen pa\u00dften wohl auf,", "tokens": ["Vom", "gol\u00b7de\u00b7nen", "L\u00f6\u00b7wen", "pa\u00df\u00b7ten", "wohl", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das kann leicht einer sich denken;", "tokens": ["Das", "kann", "leicht", "ei\u00b7ner", "sich", "den\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "ART", "PRF", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die haben wacker ihn ausgelacht,", "tokens": ["Die", "ha\u00b7ben", "wa\u00b7cker", "ihn", "aus\u00b7ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und haben ein Lied auf ihn gemacht,", "tokens": ["Und", "ha\u00b7ben", "ein", "Lied", "auf", "ihn", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und singen's in allen Schenken:", "tokens": ["Und", "sin\u00b7gen's", "in", "al\u00b7len", "Schen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Hans J\u00fcrgen, rette, rette dein Kind!", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "ret\u00b7te", ",", "ret\u00b7te", "dein", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zum Weiher, zum Weiher! geschwind, geschwind!", "tokens": ["Zum", "Wei\u00b7her", ",", "zum", "Wei\u00b7her", "!", "ge\u00b7schwind", ",", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Doch lasse dich ja nicht kratzen.", "tokens": ["Doch", "las\u00b7se", "dich", "ja", "nicht", "krat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und schmeckt, Hans J\u00fcrgen, der Branntewein,", "tokens": ["Und", "schmeckt", ",", "Hans", "J\u00fcr\u00b7gen", ",", "der", "Brann\u00b7te\u00b7wein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NE", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Komm her zu dem goldenen L\u00f6wen herein,", "tokens": ["Komm", "her", "zu", "dem", "gol\u00b7de\u00b7nen", "L\u00f6\u00b7wen", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Wir singen ein Lied dir zum Platzen.", "tokens": ["Wir", "sin\u00b7gen", "ein", "Lied", "dir", "zum", "Plat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.16": {"line.1": {"text": "Hans J\u00fcrgen, l\u00e4\u00dft du das Trinken nicht sein,", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "l\u00e4\u00dft", "du", "das", "Trin\u00b7ken", "nicht", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "PTKNEG", "VAINF", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und l\u00e4\u00dft nicht vom leidigen Branntewein,", "tokens": ["Und", "l\u00e4\u00dft", "nicht", "vom", "lei\u00b7di\u00b7gen", "Brann\u00b7te\u00b7wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "APPRART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Du wirst zur Verzweiflung mich bringen;", "tokens": ["Du", "wirst", "zur", "Ver\u00b7zwei\u00b7flung", "mich", "brin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Im Weiher dort ist's bald geschehn,", "tokens": ["Im", "Wei\u00b7her", "dort", "ist's", "bald", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da wirst du dein Kind mich ertr\u00e4nken sehn,", "tokens": ["Da", "wirst", "du", "dein", "Kind", "mich", "er\u00b7tr\u00e4n\u00b7ken", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "NN", "PPER", "VVINF", "VVINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Mich selbst hinunter springen. \u2013", "tokens": ["Mich", "selbst", "hin\u00b7un\u00b7ter", "sprin\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "ADV", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Ach Frau, sei mir darum nicht gram,", "tokens": ["Ach", "Frau", ",", "sei", "mir", "da\u00b7rum", "nicht", "gram", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "VAFIN", "PPER", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wei\u00df selber kaum, wie gestern es kam,", "tokens": ["Wei\u00df", "sel\u00b7ber", "kaum", ",", "wie", "ge\u00b7stern", "es", "kam", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der goldene L\u00f6w ist schuldig;", "tokens": ["Der", "gol\u00b7de\u00b7ne", "L\u00f6w", "ist", "schul\u00b7dig", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ich kam an der Schenke vor\u00fcber und sann,", "tokens": ["Ich", "kam", "an", "der", "Schen\u00b7ke", "vor\u00b7\u00fc\u00b7ber", "und", "sann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Das Tier mich anzuglotzen begann,", "tokens": ["Das", "Tier", "mich", "an\u00b7zu\u00b7glot\u00b7zen", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVIZU", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Der L\u00f6w, er glei\u00dfte so guldig.", "tokens": ["Der", "L\u00f6w", ",", "er", "glei\u00df\u00b7te", "so", "gul\u00b7dig", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.18": {"line.1": {"text": "Ich ging hinein, das war nicht gut,", "tokens": ["Ich", "ging", "hin\u00b7ein", ",", "das", "war", "nicht", "gut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PDS", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich trank, hinaus zu gehn, mir Mut,", "tokens": ["Ich", "trank", ",", "hin\u00b7aus", "zu", "gehn", ",", "mir", "Mut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APZR", "PTKZU", "VVINF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kam unter dem Tische zu liegen;", "tokens": ["Kam", "un\u00b7ter", "dem", "Ti\u00b7sche", "zu", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Wenn abermals es dem Teufel gelang,", "tokens": ["Wenn", "a\u00b7ber\u00b7mals", "es", "dem", "Teu\u00b7fel", "ge\u00b7lang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sei, liebes Herz, darum nicht bang,", "tokens": ["Sei", ",", "lie\u00b7bes", "Herz", ",", "da\u00b7rum", "nicht", "bang", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADJA", "NN", "$,", "PAV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er soll nicht wieder mich kriegen.", "tokens": ["Er", "soll", "nicht", "wie\u00b7der", "mich", "krie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Die Augen zu! Ein Wort, ein Mann.", "tokens": ["Die", "Au\u00b7gen", "zu", "!", "Ein", "Wort", ",", "ein", "Mann", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bringe dir heut, was ich alles gewann,", "tokens": ["Ich", "brin\u00b7ge", "dir", "heut", ",", "was", "ich", "al\u00b7les", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "PWS", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "Und eine trockene Kehle.", "tokens": ["Und", "ei\u00b7ne", "tro\u00b7cke\u00b7ne", "Keh\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "So ging er zu seinem Meister hin,", "tokens": ["So", "ging", "er", "zu", "sei\u00b7nem", "Meis\u00b7ter", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Es lag ihm schwer in seinem Sinn,", "tokens": ["Es", "lag", "ihm", "schwer", "in", "sei\u00b7nem", "Sinn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es qu\u00e4lt' ihn in seiner Seele.", "tokens": ["Es", "qu\u00e4lt'", "ihn", "in", "sei\u00b7ner", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.20": {"line.1": {"text": "Und als es Feierabend war", "tokens": ["Und", "als", "es", "Fei\u00b7er\u00b7a\u00b7bend", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und heim er kam, da f\u00fchlt' er gar", "tokens": ["Und", "heim", "er", "kam", ",", "da", "f\u00fchlt'", "er", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PTKVZ", "PPER", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den leidigen Durst ihn bei\u00dfen.", "tokens": ["Den", "lei\u00b7di\u00b7gen", "Durst", "ihn", "bei\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die Augen zu! Er kam mit Gl\u00fcck", "tokens": ["Die", "Au\u00b7gen", "zu", "!", "Er", "kam", "mit", "Gl\u00fcck"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Klippe vorbei, da schaut' er zur\u00fcck,", "tokens": ["Der", "Klip\u00b7pe", "vor\u00b7bei", ",", "da", "schaut'", "er", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Er sah den L\u00f6wen so glei\u00dfen. \u2013", "tokens": ["Er", "sah", "den", "L\u00f6\u00b7wen", "so", "glei\u00b7\u00dfen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.21": {"line.1": {"text": "Jedweder Tugend ihren Lohn!", "tokens": ["Jed\u00b7we\u00b7der", "Tu\u00b7gend", "ih\u00b7ren", "Lohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verdient, wahrhaftig, hab ich ihn schon,", "tokens": ["Ver\u00b7di\u00b7ent", ",", "wahr\u00b7haf\u00b7tig", ",", "hab", "ich", "ihn", "schon", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "ADJD", "$,", "VAFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.3": {"text": "Ein Schluck darauf wird schmecken! \u2013", "tokens": ["Ein", "Schluck", "da\u00b7rauf", "wird", "schme\u00b7cken", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PAV", "VAFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und taumelnd gelangt' er und sp\u00e4t nach Haus,", "tokens": ["Und", "tau\u00b7melnd", "ge\u00b7langt'", "er", "und", "sp\u00e4t", "nach", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "KON", "ADJD", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Die Frau sa\u00df da, sah finster aus,", "tokens": ["Die", "Frau", "sa\u00df", "da", ",", "sah", "fins\u00b7ter", "aus", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "$,", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er mu\u00dfte vor ihr erschrecken.", "tokens": ["Er", "mu\u00df\u00b7te", "vor", "ihr", "er\u00b7schre\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Sie pr\u00fcft' ihn mit den Augen stumm;", "tokens": ["Sie", "pr\u00fcft'", "ihn", "mit", "den", "Au\u00b7gen", "stumm", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie ging ihm seltsam im Kopf herum,", "tokens": ["Sie", "ging", "ihm", "selt\u00b7sam", "im", "Kopf", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Gedenkend der eigenen Schw\u00fcre.", "tokens": ["Ge\u00b7den\u00b7kend", "der", "ei\u00b7ge\u00b7nen", "Schw\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Sie aber schritt zu der Wiege hin,", "tokens": ["Sie", "a\u00b7ber", "schritt", "zu", "der", "Wie\u00b7ge", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und nahm das Kind, das gelegen darin,", "tokens": ["Und", "nahm", "das", "Kind", ",", "das", "ge\u00b7le\u00b7gen", "da\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "PRELS", "VVPP", "PAV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und eilte hinaus zur T\u00fcre.", "tokens": ["Und", "eil\u00b7te", "hin\u00b7aus", "zur", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.23": {"line.1": {"text": "Er ist da n\u00fcchtern geworden fast,", "tokens": ["Er", "ist", "da", "n\u00fcch\u00b7tern", "ge\u00b7wor\u00b7den", "fast", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VAPP", "ADV", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein kaltes Entsetzen hat ihn erfa\u00dft: \u2013", "tokens": ["Ein", "kal\u00b7tes", "Ent\u00b7set\u00b7zen", "hat", "ihn", "er\u00b7fa\u00dft", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Dahin, dahin gekommen! \u2013", "tokens": ["Da\u00b7hin", ",", "da\u00b7hin", "ge\u00b7kom\u00b7men", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["PAV", "$,", "PAV", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hans J\u00fcrgen, rette, rette dein Kind!", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "ret\u00b7te", ",", "ret\u00b7te", "dein", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Zum Weiher, zum Weiher! geschwind, geschwind!", "tokens": ["Zum", "Wei\u00b7her", ",", "zum", "Wei\u00b7her", "!", "ge\u00b7schwind", ",", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Sie hat den Weg genommen. \u2013", "tokens": ["Sie", "hat", "den", "Weg", "ge\u00b7nom\u00b7men", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Er eilt ihr nach in vollem Lauf,", "tokens": ["Er", "eilt", "ihr", "nach", "in", "vol\u00b7lem", "Lauf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Pl\u00e4tschern schallt vom Weiher herauf, \u2013", "tokens": ["Ein", "Pl\u00e4t\u00b7schern", "schallt", "vom", "Wei\u00b7her", "her\u00b7auf", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Nur noch die Mutter zu sehen: \u2013", "tokens": ["Nur", "noch", "die", "Mut\u00b7ter", "zu", "se\u00b7hen", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADV", "ART", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Zur\u00fcck! das Kind, ich hol es hervor,", "tokens": ["Zu\u00b7r\u00fcck", "!", "das", "Kind", ",", "ich", "hol", "es", "her\u00b7vor", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$.", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Noch halten's die schwimmenden T\u00fccher empor,", "tokens": ["Noch", "hal\u00b7ten's", "die", "schwim\u00b7men\u00b7den", "T\u00fc\u00b7cher", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Zur\u00fcck! genug ist geschehen. \u2013", "tokens": ["Zu\u00b7r\u00fcck", "!", "ge\u00b7nug", "ist", "ge\u00b7sche\u00b7hen", ".", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PTKVZ", "$.", "ADV", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.25": {"line.1": {"text": "Er schreit es und springt in das Wasser hinein, \u2013", "tokens": ["Er", "schreit", "es", "und", "springt", "in", "das", "Was\u00b7ser", "hin\u00b7ein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,", "$("], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Das Wasser, das mochte so tief nicht sein,", "tokens": ["Das", "Was\u00b7ser", ",", "das", "moch\u00b7te", "so", "tief", "nicht", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VVFIN", "ADV", "ADJD", "PTKNEG", "VAINF", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Die Beute leicht zu erhalten.", "tokens": ["Die", "Beu\u00b7te", "leicht", "zu", "er\u00b7hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Er tr\u00e4gt das Wickelkind im Arm,", "tokens": ["Er", "tr\u00e4gt", "das", "Wi\u00b7ckel\u00b7kind", "im", "Arm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und dr\u00fcckt's an die Brust so innig und warm,", "tokens": ["Und", "dr\u00fcckt's", "an", "die", "Brust", "so", "in\u00b7nig", "und", "warm", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und steigt aus dem Bade, dem kalten. \u2013", "tokens": ["Und", "steigt", "aus", "dem", "Ba\u00b7de", ",", "dem", "kal\u00b7ten", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "ADJA", "$.", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.26": {"line.1": {"text": "\u00bban meinem Herzen, an meiner Brust,", "tokens": ["\u00bb", "an", "mei\u00b7nem", "Her\u00b7zen", ",", "an", "mei\u00b7ner", "Brust", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Du meine Wonne, du meine Lust!\u00ab", "tokens": ["Du", "mei\u00b7ne", "Won\u00b7ne", ",", "du", "mei\u00b7ne", "Lust", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,", "PPER", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Doch mu\u00dft du mich nicht so kratzen.", "tokens": ["Doch", "mu\u00dft", "du", "mich", "nicht", "so", "krat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ein gutes, sch\u00f6nes Kind, allein", "tokens": ["Ein", "gu\u00b7tes", ",", "sch\u00f6\u00b7nes", "Kind", ",", "al\u00b7lein"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Es kratzet doch ganz ungemein;", "tokens": ["Es", "krat\u00b7zet", "doch", "ganz", "un\u00b7ge\u00b7mein", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Was hast denn du f\u00fcr Tatzen? \u2013", "tokens": ["Was", "hast", "denn", "du", "f\u00fcr", "Tat\u00b7zen", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VAFIN", "KON", "PPER", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Und wie er's n\u00e4her untersucht,", "tokens": ["Und", "wie", "er's", "n\u00e4\u00b7her", "un\u00b7ter\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erkennt er den schwarzen Kater und flucht,", "tokens": ["Er\u00b7kennt", "er", "den", "schwar\u00b7zen", "Ka\u00b7ter", "und", "flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Den Kater, ihm zum Possen. \u2013", "tokens": ["Den", "Ka\u00b7ter", ",", "ihm", "zum", "Pos\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PPER", "APPRART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ach Frau, ach Frau, wo bist denn du? \u2013", "tokens": ["Ach", "Frau", ",", "ach", "Frau", ",", "wo", "bist", "denn", "du", "?", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "NN", "$,", "XY", "NN", "$,", "PWAV", "VAFIN", "KON", "PPER", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die sitzt zu Hause, die T\u00fcr ist zu,", "tokens": ["Die", "sitzt", "zu", "Hau\u00b7se", ",", "die", "T\u00fcr", "ist", "zu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NN", "$,", "ART", "NN", "VAFIN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Die T\u00fcre bleibt verschlossen. \u2013", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Ach Frau, das ist ein frostiger Spa\u00df;", "tokens": ["Ach", "Frau", ",", "das", "ist", "ein", "fros\u00b7ti\u00b7ger", "Spa\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es ist so kalt, ich bin so na\u00df. \u2013", "tokens": ["Es", "ist", "so", "kalt", ",", "ich", "bin", "so", "na\u00df", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die T\u00fcre bleibt verschlossen;", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wie er pocht und flucht und l\u00e4rmt,", "tokens": ["Und", "wie", "er", "pocht", "und", "flucht", "und", "l\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und fleht und winselt und sich h\u00e4rmt,", "tokens": ["Und", "fleht", "und", "win\u00b7selt", "und", "sich", "h\u00e4rmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "KON", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die T\u00fcre bleibt verschlossen.", "tokens": ["Die", "T\u00fc\u00b7re", "bleibt", "ver\u00b7schlos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Die Nachbarsleute, die G\u00e4ste zu Hauf", "tokens": ["Die", "Nach\u00b7bars\u00b7leu\u00b7te", ",", "die", "G\u00e4s\u00b7te", "zu", "Hauf"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vom goldenen L\u00f6wen pa\u00dften wohl auf,", "tokens": ["Vom", "gol\u00b7de\u00b7nen", "L\u00f6\u00b7wen", "pa\u00df\u00b7ten", "wohl", "auf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das kann leicht einer sich denken;", "tokens": ["Das", "kann", "leicht", "ei\u00b7ner", "sich", "den\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "ADJD", "ART", "PRF", "VVINF", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die haben wacker ihn ausgelacht,", "tokens": ["Die", "ha\u00b7ben", "wa\u00b7cker", "ihn", "aus\u00b7ge\u00b7lacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Und haben ein Lied auf ihn gemacht,", "tokens": ["Und", "ha\u00b7ben", "ein", "Lied", "auf", "ihn", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und singen's in allen Schenken:", "tokens": ["Und", "sin\u00b7gen's", "in", "al\u00b7len", "Schen\u00b7ken", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.30": {"line.1": {"text": "Hans J\u00fcrgen, rette, rette dein Kind!", "tokens": ["Hans", "J\u00fcr\u00b7gen", ",", "ret\u00b7te", ",", "ret\u00b7te", "dein", "Kind", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "VVFIN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Zum Weiher, zum Weiher! geschwind, geschwind!", "tokens": ["Zum", "Wei\u00b7her", ",", "zum", "Wei\u00b7her", "!", "ge\u00b7schwind", ",", "ge\u00b7schwind", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$.", "ADJD", "$,", "ADJD", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Doch lasse dich ja nicht kratzen.", "tokens": ["Doch", "las\u00b7se", "dich", "ja", "nicht", "krat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und schmeckt, Hans J\u00fcrgen, der Branntewein,", "tokens": ["Und", "schmeckt", ",", "Hans", "J\u00fcr\u00b7gen", ",", "der", "Brann\u00b7te\u00b7wein", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "NE", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Komm her zu dem goldenen L\u00f6wen herein,", "tokens": ["Komm", "her", "zu", "dem", "gol\u00b7de\u00b7nen", "L\u00f6\u00b7wen", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Wir singen ein Lied dir zum Platzen.", "tokens": ["Wir", "sin\u00b7gen", "ein", "Lied", "dir", "zum", "Plat\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}}}}