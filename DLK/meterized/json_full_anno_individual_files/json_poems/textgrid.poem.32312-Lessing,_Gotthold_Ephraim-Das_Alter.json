{"textgrid.poem.32312": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Das Alter", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Euch, lose M\u00e4dchen, h\u00f6r' ich sagen:", "tokens": ["Euch", ",", "lo\u00b7se", "M\u00e4d\u00b7chen", ",", "h\u00f6r'", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdu bist ja alt, Anakreon.", "tokens": ["\u00bb", "du", "bist", "ja", "alt", ",", "A\u00b7nak\u00b7re\u00b7on", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$,", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh her! du kannst den Spiegel fragen,", "tokens": ["Sieh", "her", "!", "du", "kannst", "den", "Spie\u00b7gel", "fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sieh, deine Haare schwinden schon;", "tokens": ["Sieh", ",", "dei\u00b7ne", "Haa\u00b7re", "schwin\u00b7den", "schon", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und von den trocknen Wangen", "tokens": ["Und", "von", "den", "trock\u00b7nen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist Blut' und Reiz entflohn.\u00ab \u2013", "tokens": ["Ist", "Blut'", "und", "Reiz", "ent\u00b7flohn", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wahrhaftig! ob die Wangen", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "ob", "die", "Wan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Noch mit dem Lenze prangen,", "tokens": ["Noch", "mit", "dem", "Len\u00b7ze", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.9": {"text": "Wie, oder ob den Wangen", "tokens": ["Wie", ",", "o\u00b7der", "ob", "den", "Wan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der kurze Lenz vergangen,", "tokens": ["Der", "kur\u00b7ze", "Lenz", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Das wei\u00df ich nicht; doch was ich wei\u00df,", "tokens": ["Das", "wei\u00df", "ich", "nicht", ";", "doch", "was", "ich", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$.", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Will ich euch sagen: da\u00df ein Greis,", "tokens": ["Will", "ich", "euch", "sa\u00b7gen", ":", "da\u00df", "ein", "Greis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$.", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Sein Bi\u00dfchen Zeit noch zu genie\u00dfen,", "tokens": ["Sein", "Bi\u00df\u00b7chen", "Zeit", "noch", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ein doppelt Recht hat, euch zu k\u00fcssen.", "tokens": ["Ein", "dop\u00b7pelt", "Recht", "hat", ",", "euch", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Euch, lose M\u00e4dchen, h\u00f6r' ich sagen:", "tokens": ["Euch", ",", "lo\u00b7se", "M\u00e4d\u00b7chen", ",", "h\u00f6r'", "ich", "sa\u00b7gen", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "NN", "$,", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdu bist ja alt, Anakreon.", "tokens": ["\u00bb", "du", "bist", "ja", "alt", ",", "A\u00b7nak\u00b7re\u00b7on", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$,", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sieh her! du kannst den Spiegel fragen,", "tokens": ["Sieh", "her", "!", "du", "kannst", "den", "Spie\u00b7gel", "fra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$.", "PPER", "VMFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sieh, deine Haare schwinden schon;", "tokens": ["Sieh", ",", "dei\u00b7ne", "Haa\u00b7re", "schwin\u00b7den", "schon", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPOSAT", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und von den trocknen Wangen", "tokens": ["Und", "von", "den", "trock\u00b7nen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ist Blut' und Reiz entflohn.\u00ab \u2013", "tokens": ["Ist", "Blut'", "und", "Reiz", "ent\u00b7flohn", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKVZ", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Wahrhaftig! ob die Wangen", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "ob", "die", "Wan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Noch mit dem Lenze prangen,", "tokens": ["Noch", "mit", "dem", "Len\u00b7ze", "pran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.9": {"text": "Wie, oder ob den Wangen", "tokens": ["Wie", ",", "o\u00b7der", "ob", "den", "Wan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KON", "KOUS", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Der kurze Lenz vergangen,", "tokens": ["Der", "kur\u00b7ze", "Lenz", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Das wei\u00df ich nicht; doch was ich wei\u00df,", "tokens": ["Das", "wei\u00df", "ich", "nicht", ";", "doch", "was", "ich", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$.", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Will ich euch sagen: da\u00df ein Greis,", "tokens": ["Will", "ich", "euch", "sa\u00b7gen", ":", "da\u00df", "ein", "Greis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$.", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Sein Bi\u00dfchen Zeit noch zu genie\u00dfen,", "tokens": ["Sein", "Bi\u00df\u00b7chen", "Zeit", "noch", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Ein doppelt Recht hat, euch zu k\u00fcssen.", "tokens": ["Ein", "dop\u00b7pelt", "Recht", "hat", ",", "euch", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "VAFIN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}