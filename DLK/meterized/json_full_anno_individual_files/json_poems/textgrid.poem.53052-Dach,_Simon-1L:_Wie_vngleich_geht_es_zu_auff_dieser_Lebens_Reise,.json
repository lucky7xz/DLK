{"textgrid.poem.53052": {"metadata": {"author": {"name": "Dach, Simon", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie vngleich geht es zu auff dieser Lebens Reise,", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie vngleich geht es zu auff dieser Lebens Reise,", "tokens": ["Wie", "vn\u00b7gleich", "geht", "es", "zu", "auff", "die\u00b7ser", "Le\u00b7bens", "Rei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PTKZU", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie seltzam spielt mit vns auff sonder Art vnd Weise", "tokens": ["Wie", "selt\u00b7zam", "spielt", "mit", "vns", "auff", "son\u00b7der", "Art", "vnd", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des falschen Gl\u00fcckes Rund, des angenehmen Flei\u00df", "tokens": ["Des", "fal\u00b7schen", "Gl\u00fc\u00b7ckes", "Rund", ",", "des", "an\u00b7ge\u00b7neh\u00b7men", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich Venus sonderlich wol zu gebrauchen wei\u00df.", "tokens": ["Sich", "Ve\u00b7nus", "son\u00b7der\u00b7lich", "wol", "zu", "ge\u00b7brau\u00b7chen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir ziehen alle zwar zu gleich an jhrem Wagen", "tokens": ["Wir", "zie\u00b7hen", "al\u00b7le", "zwar", "zu", "gleich", "an", "jhrem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "APPR", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Vnd sind in jhrem Dienst nach allem wolbehagen,", "tokens": ["Vnd", "sind", "in", "jhrem", "Dienst", "nach", "al\u00b7lem", "wol\u00b7be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "PIS", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Dadurch vermeinen wir zu haben jhre Gunst,", "tokens": ["Da\u00b7durch", "ver\u00b7mei\u00b7nen", "wir", "zu", "ha\u00b7ben", "jhre", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKZU", "VAINF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Erweisen allen Flei\u00df, ersparen keine Kunst.", "tokens": ["Er\u00b7wei\u00b7sen", "al\u00b7len", "Flei\u00df", ",", "er\u00b7spa\u00b7ren", "kei\u00b7ne", "Kunst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie aber lest doch nur, auff welchen sie wil, fallen", "tokens": ["Sie", "a\u00b7ber", "lest", "doch", "nur", ",", "auff", "wel\u00b7chen", "sie", "wil", ",", "fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "$,", "APPR", "PWAT", "PPER", "VMFIN", "$,", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Stralen jhrer Gunst vnd ehret den vor allen,", "tokens": ["Die", "Stra\u00b7len", "jhrer", "Gunst", "vnd", "eh\u00b7ret", "den", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "VVFIN", "ART", "APPR", "PIAT", "$,"], "meter": "-+--+-+---+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Wem sie es g\u00f6nt allein, sie hebet jhn empor", "tokens": ["Wem", "sie", "es", "g\u00f6nt", "al\u00b7lein", ",", "sie", "he\u00b7bet", "jhn", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der andern vngeacht, die leben nach wie vor", "tokens": ["Der", "an\u00b7dern", "vn\u00b7ge\u00b7acht", ",", "die", "le\u00b7ben", "nach", "wie", "vor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "APPR", "KOKOM", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Liebe Grawsamkeit zu dienst in schweren Z\u00fcgen,", "tokens": ["Der", "Lie\u00b7be", "Graw\u00b7sam\u00b7keit", "zu", "dienst", "in", "schwe\u00b7ren", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vnd steter Hertzens-Angst, davor sein grosses gn\u00fcgen", "tokens": ["Vnd", "ste\u00b7ter", "Hert\u00b7zens\u00b7Angst", ",", "da\u00b7vor", "sein", "gros\u00b7ses", "gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "PAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Br\u00e4utgam jetzt empfind, er lebet gantz befreyt,", "tokens": ["Der", "Br\u00e4ut\u00b7gam", "jetzt", "emp\u00b7find", ",", "er", "le\u00b7bet", "gantz", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJD", "$,", "PPER", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Indem er schl\u00e4fft vnd wacht in steter Sicherheit.", "tokens": ["In\u00b7dem", "er", "schl\u00e4fft", "vnd", "wacht", "in", "ste\u00b7ter", "Si\u00b7cher\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es setzet Venus jhn hoch an des Gl\u00fcckes Zinnen", "tokens": ["Es", "set\u00b7zet", "Ve\u00b7nus", "jhn", "hoch", "an", "des", "Gl\u00fc\u00b7ckes", "Zin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "PPER", "ADJD", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vnd lest jhn seine Lust nach eusserstem beginnen", "tokens": ["Vnd", "lest", "jhn", "sei\u00b7ne", "Lust", "nach", "eus\u00b7sers\u00b7tem", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Recht nehmen f\u00fcr vnd f\u00fcr, in dem sie jhme giebt", "tokens": ["Recht", "neh\u00b7men", "f\u00fcr", "vnd", "f\u00fcr", ",", "in", "dem", "sie", "jh\u00b7me", "giebt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVINF", "APPR", "KON", "APPR", "$,", "APPR", "PRELS", "PPER", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein freundlichs Frawenbild, daran er sich verliebt.", "tokens": ["Ein", "freund\u00b7lichs", "Fra\u00b7wen\u00b7bild", ",", "da\u00b7ran", "er", "sich", "ver\u00b7liebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PAV", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Nun zwar wir g\u00f6nnens jhm, vnd w\u00fcnschen jhm viel Segen,", "tokens": ["Nun", "zwar", "wir", "g\u00f6n\u00b7nens", "jhm", ",", "vnd", "w\u00fcn\u00b7schen", "jhm", "viel", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "PPER", "$,", "KON", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df er vnd seine Braut die Zeit zubringen m\u00f6gen", "tokens": ["Da\u00df", "er", "vnd", "sei\u00b7ne", "Braut", "die", "Zeit", "zu\u00b7brin\u00b7gen", "m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KON", "PPOSAT", "NN", "ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "In h\u00f6chstgew\u00fcnschter Lust, wir m\u00fcssen vnser Leid", "tokens": ["In", "h\u00f6chst\u00b7ge\u00b7w\u00fcnschter", "Lust", ",", "wir", "m\u00fcs\u00b7sen", "vn\u00b7ser", "Leid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Beklagen nur allein, da\u00df diese s\u00fcsse Frewd'", "tokens": ["Be\u00b7kla\u00b7gen", "nur", "al\u00b7lein", ",", "da\u00df", "die\u00b7se", "s\u00fcs\u00b7se", "Fre\u00b7wd'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "$,", "KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Vns kaum von fern nicht sieht, wir k\u00f6nnen nicht ersehen,", "tokens": ["Vns", "kaum", "von", "fern", "nicht", "sieht", ",", "wir", "k\u00f6n\u00b7nen", "nicht", "er\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJD", "PTKNEG", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wie es werd' einmahl noch mit vnser Lieb' ergehen,", "tokens": ["Wie", "es", "werd'", "ein\u00b7mahl", "noch", "mit", "vn\u00b7ser", "Lieb'", "er\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wir Schiffen ohne Meer, wir segeln ohne Wind,", "tokens": ["Wir", "Schif\u00b7fen", "oh\u00b7ne", "Meer", ",", "wir", "se\u00b7geln", "oh\u00b7ne", "Wind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wir sehen keinen Port, darauff man fussen k\u00fcnt',", "tokens": ["Wir", "se\u00b7hen", "kei\u00b7nen", "Port", ",", "dar\u00b7auff", "man", "fus\u00b7sen", "k\u00fcnt'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PAV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Vnd dennoch lieben wir, gleich wie die stoltze Wellen", "tokens": ["Vnd", "den\u00b7noch", "lie\u00b7ben", "wir", ",", "gleich", "wie", "die", "stolt\u00b7ze", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Im tollen Meere gehn, gef\u00fchrt al\u00df hin zur Hellen,", "tokens": ["Im", "tol\u00b7len", "Mee\u00b7re", "gehn", ",", "ge\u00b7f\u00fchrt", "al\u00df", "hin", "zur", "Hel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$,", "VVPP", "KOKOM", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die doch am andern Theil wie grosse H\u00fcgel sind", "tokens": ["Die", "doch", "am", "an\u00b7dern", "Theil", "wie", "gros\u00b7se", "H\u00fc\u00b7gel", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "ADJA", "NN", "KOKOM", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Erhaben durch die Fluth vnd strengen Nordenwind", "tokens": ["Er\u00b7ha\u00b7ben", "durch", "die", "Fluth", "vnd", "stren\u00b7gen", "Nor\u00b7den\u00b7wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Bi\u00df an der Sternen Sitz, so m\u00fcssen wir auch leben,", "tokens": ["Bi\u00df", "an", "der", "Ster\u00b7nen", "Sitz", ",", "so", "m\u00fcs\u00b7sen", "wir", "auch", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Die wir der Liebe sind zu Pflicht vnd Dienst ergeben.", "tokens": ["Die", "wir", "der", "Lie\u00b7be", "sind", "zu", "Pflicht", "vnd", "Dienst", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Der eine schwebt empor, der ander leidet Pein", "tokens": ["Der", "ei\u00b7ne", "schwebt", "em\u00b7por", ",", "der", "an\u00b7der", "lei\u00b7det", "Pein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "ADJD", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vnd mu\u00df des Gl\u00fcckes Rad vnd stete Kurtzweil seyn.", "tokens": ["Vnd", "mu\u00df", "des", "Gl\u00fc\u00b7ckes", "Rad", "vnd", "ste\u00b7te", "Kurt\u00b7zweil", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "KON", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Da kostets manchen Wunsch, da kostets manche Tr\u00e4nen,", "tokens": ["Da", "kos\u00b7tets", "man\u00b7chen", "Wunsch", ",", "da", "kos\u00b7tets", "man\u00b7che", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,", "KOUS", "NE", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Eh' vns das wird gewehrt, nach deme wir vns sehnen,", "tokens": ["Eh'", "vns", "das", "wird", "ge\u00b7wehrt", ",", "nach", "de\u00b7me", "wir", "vns", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VAFIN", "VVPP", "$,", "APPR", "PRELS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wie offte machen vns viel tausent Seufftzer matt,", "tokens": ["Wie", "off\u00b7te", "ma\u00b7chen", "vns", "viel", "tau\u00b7sent", "Seufft\u00b7zer", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADV", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "An stat der Speis' vnd Tranck macht vns das Weinen satt.", "tokens": ["An", "stat", "der", "Speis'", "vnd", "Tranck", "macht", "vns", "das", "Wei\u00b7nen", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "KON", "NN", "VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Bald nemmen wir zur Hand die sch\u00f6nen Sch\u00e4ffereyen,", "tokens": ["Bald", "nem\u00b7men", "wir", "zur", "Hand", "die", "sch\u00f6\u00b7nen", "Sch\u00e4f\u00b7fe\u00b7re\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.42": {"text": "Ob die vns m\u00f6chten noch in etwas nur erfrewen,", "tokens": ["Ob", "die", "vns", "m\u00f6ch\u00b7ten", "noch", "in", "et\u00b7was", "nur", "er\u00b7fre\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "VMFIN", "ADV", "APPR", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+---+-+---", "measure": "unknown.measure.tetra"}, "line.43": {"text": "Bald' auch den Amadis, was Naso hat gesagt", "tokens": ["Bald'", "auch", "den", "A\u00b7ma\u00b7dis", ",", "was", "Na\u00b7so", "hat", "ge\u00b7sagt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Vom Buhlen, solches vns vor Plato weit verjagt.", "tokens": ["Vom", "Buh\u00b7len", ",", "sol\u00b7ches", "vns", "vor", "Pla\u00b7to", "weit", "ver\u00b7jagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "APPR", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wir lassen alles stehn, vnd dies seyn vnser tichten,", "tokens": ["Wir", "las\u00b7sen", "al\u00b7les", "stehn", ",", "vnd", "dies", "seyn", "vn\u00b7ser", "tich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVINF", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Der allerliebsten vns mit diensten zu verpflichten,", "tokens": ["Der", "al\u00b7ler\u00b7liebs\u00b7ten", "vns", "mit", "diens\u00b7ten", "zu", "ver\u00b7pflich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "APPR", "PDS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Auff da\u00df es h\u00f6fflich sey, wir brauchen vmbschweiffs viel,", "tokens": ["Auff", "da\u00df", "es", "h\u00f6ff\u00b7lich", "sey", ",", "wir", "brau\u00b7chen", "vmb\u00b7schweiffs", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "PPER", "VVFIN", "APPRART", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Eh dann man von der Lieb' etwas gedencken wil.", "tokens": ["Eh", "dann", "man", "von", "der", "Lieb'", "et\u00b7was", "ge\u00b7den\u00b7cken", "wil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "APPR", "ART", "NN", "PIAT", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wir w\u00e4gen alle Wort auff einer Wageschalen,", "tokens": ["Wir", "w\u00e4\u00b7gen", "al\u00b7le", "Wort", "auff", "ei\u00b7ner", "Wa\u00b7ge\u00b7scha\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Besinnen hin vnd her zu vielen hundert malen,", "tokens": ["Be\u00b7sin\u00b7nen", "hin", "vnd", "her", "zu", "vie\u00b7len", "hun\u00b7dert", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "ADV", "APPR", "PIAT", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Was vorzubringen sey, die dienste zu voran", "tokens": ["Was", "vor\u00b7zu\u00b7brin\u00b7gen", "sey", ",", "die", "diens\u00b7te", "zu", "vo\u00b7ran"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVIZU", "VAFIN", "$,", "ART", "ADJA", "PTKZU", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Die werden abgeschickt das Werck zu fangen an.", "tokens": ["Die", "wer\u00b7den", "ab\u00b7ge\u00b7schickt", "das", "Werck", "zu", "fan\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "ART", "NN", "PTKZU", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Da nimbt man weiter denn gelegenheit zu sagen,", "tokens": ["Da", "nimbt", "man", "wei\u00b7ter", "denn", "ge\u00b7le\u00b7gen\u00b7heit", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Bi\u00df wegen grosser Lieb' vns endlich wir beklagen,", "tokens": ["Bi\u00df", "we\u00b7gen", "gros\u00b7ser", "Lieb'", "vns", "end\u00b7lich", "wir", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wie sie vns habe selbst das Hertz genommen ein,", "tokens": ["Wie", "sie", "vns", "ha\u00b7be", "selbst", "das", "Hertz", "ge\u00b7nom\u00b7men", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Das bey vns nichts mehr ist als bitter s\u00fcsse Pein,", "tokens": ["Das", "bey", "vns", "nichts", "mehr", "ist", "als", "bit\u00b7ter", "s\u00fcs\u00b7se", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "PIS", "ADV", "VAFIN", "KOKOM", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Vnnd was der reden mehr ein Weibsbild zu beth\u00f6ren.", "tokens": ["Vnnd", "was", "der", "re\u00b7den", "mehr", "ein", "Weibs\u00b7bild", "zu", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Wenn wir denn nun von Ihr abschl\u00e4glich' antwort h\u00f6ren,", "tokens": ["Wenn", "wir", "denn", "nun", "von", "Ihr", "ab\u00b7schl\u00e4g\u00b7lich'", "ant\u00b7wort", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-++-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.59": {"text": "Da geht das klagen an, man wil des Lebens ab", "tokens": ["Da", "geht", "das", "kla\u00b7gen", "an", ",", "man", "wil", "des", "Le\u00b7bens", "ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "VVFIN", "PTKVZ", "$,", "PIS", "VMFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Vnd meint die beste Ruh zu finden in dem Grab.", "tokens": ["Vnd", "meint", "die", "bes\u00b7te", "Ruh", "zu", "fin\u00b7den", "in", "dem", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Da mu\u00df Cupido dann vnd Venus auch herhalten,", "tokens": ["Da", "mu\u00df", "Cu\u00b7pi\u00b7do", "dann", "vnd", "Ve\u00b7nus", "auch", "her\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "ADV", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.62": {"text": "Vnd die man vor geehrt, die werden noch gescholten:", "tokens": ["Vnd", "die", "man", "vor", "ge\u00b7ehrt", ",", "die", "wer\u00b7den", "noch", "ge\u00b7schol\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "APPR", "VVPP", "$,", "PRELS", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Cupido der Tyrann' auch sie die Z\u00e4uberinn',", "tokens": ["Cu\u00b7pi\u00b7do", "der", "Ty\u00b7rann'", "auch", "sie", "die", "Z\u00e4u\u00b7be\u00b7rinn'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.64": {"text": "Ich bin von Ihr gebl\u00e4ndt, bin Kranck an Hertz' vnd Sinn.", "tokens": ["Ich", "bin", "von", "Ihr", "ge\u00b7bl\u00e4ndt", ",", "bin", "Kranck", "an", "Hertz'", "vnd", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,", "VAFIN", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Es mu\u00df die Liebst' auch dann von vns verachtet werden,", "tokens": ["Es", "mu\u00df", "die", "Liebst'", "auch", "dann", "von", "vns", "ver\u00b7ach\u00b7tet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wir schm\u00e4hen, die zuvor die sch\u00f6nste war auff Erden,", "tokens": ["Wir", "schm\u00e4\u00b7hen", ",", "die", "zu\u00b7vor", "die", "sch\u00f6ns\u00b7te", "war", "auff", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ADV", "ART", "ADJA", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Wiewols nicht hertzlich ist, im fall der b\u00f6sen Lust,", "tokens": ["Wie\u00b7wols", "nicht", "hertz\u00b7lich", "ist", ",", "im", "fall", "der", "b\u00f6\u00b7sen", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADJD", "VAFIN", "$,", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Der w\u00fctenden begier ein anders ist bewust.", "tokens": ["Der", "w\u00fc\u00b7ten\u00b7den", "be\u00b7gier", "ein", "an\u00b7ders", "ist", "be\u00b7wust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADV", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wer nur was wei\u00df vnd kan im tichten oder schreiben,", "tokens": ["Wer", "nur", "was", "wei\u00df", "vnd", "kan", "im", "tich\u00b7ten", "o\u00b7der", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PWS", "VVFIN", "KON", "VMFIN", "APPRART", "ADJA", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Der thut ihm nur die Zeit hie einig mit vertreiben,", "tokens": ["Der", "thut", "ihm", "nur", "die", "Zeit", "hie", "ei\u00b7nig", "mit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Da\u00df er sich sehr beklagt ob dero Tyranney,", "tokens": ["Da\u00df", "er", "sich", "sehr", "be\u00b7klagt", "ob", "de\u00b7ro", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "KOUS", "PRELAT", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.72": {"text": "Vmb derer willen er in Noth gerahten sey.", "tokens": ["Vmb", "de\u00b7rer", "wil\u00b7len", "er", "in", "Noth", "ge\u00b7rah\u00b7ten", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "VMFIN", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.73": {"text": "Er klaget an jhr Hertz, welchs gleichet Stahl vnd Steine,", "tokens": ["Er", "kla\u00b7get", "an", "jhr", "Hertz", ",", "welchs", "glei\u00b7chet", "Stahl", "vnd", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "PWS", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Da\u00df nie kein seufftzer nicht, wie sehr er jmmer weine,", "tokens": ["Da\u00df", "nie", "kein", "seufft\u00b7zer", "nicht", ",", "wie", "sehr", "er", "jm\u00b7mer", "wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Bewegen wil noch kan, wirfft seine Trew' jhr f\u00fcr,", "tokens": ["Be\u00b7we\u00b7gen", "wil", "noch", "kan", ",", "wirfft", "sei\u00b7ne", "Tre\u00b7w'", "jhr", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "ADV", "VMFIN", "$,", "VVFIN", "PPOSAT", "NN", "PPER", "APPR", "$,"], "meter": "-+-+-+-+-++-+", "measure": "unknown.measure.septa"}, "line.76": {"text": "Vnd macht vom Menschen sie zum grimmen ThiegerThier.", "tokens": ["Vnd", "macht", "vom", "Men\u00b7schen", "sie", "zum", "grim\u00b7men", "Thie\u00b7ger", "Thier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPER", "APPRART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Er rufft die G\u00f6tter an, die Rach' an ihr zu \u00fcben,", "tokens": ["Er", "rufft", "die", "G\u00f6t\u00b7ter", "an", ",", "die", "Rach'", "an", "ihr", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Al\u00df die geliebt wil sein, vnd doch nicht wieder lieben,", "tokens": ["Al\u00df", "die", "ge\u00b7liebt", "wil", "sein", ",", "vnd", "doch", "nicht", "wie\u00b7der", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVPP", "VMFIN", "VAINF", "$,", "KON", "ADV", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Er saget, wie sie gar jhn vmb sein Leben bring',", "tokens": ["Er", "sa\u00b7get", ",", "wie", "sie", "gar", "jhn", "vmb", "sein", "Le\u00b7ben", "bring'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Vnd wie er auch numehr fast mit dem Tode ring'.", "tokens": ["Vnd", "wie", "er", "auch", "nu\u00b7mehr", "fast", "mit", "dem", "To\u00b7de", "ring'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Hiemit vermeint er sie noch endlich zu bezwingen", "tokens": ["Hie\u00b7mit", "ver\u00b7meint", "er", "sie", "noch", "end\u00b7lich", "zu", "be\u00b7zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Vnd jhren harten Sinn zu lieben auff zu bringen,", "tokens": ["Vnd", "jhren", "har\u00b7ten", "Sinn", "zu", "lie\u00b7ben", "auff", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.83": {"text": "Die jhren stoltzen Sinn gewendet anderweit", "tokens": ["Die", "jhren", "stolt\u00b7zen", "Sinn", "ge\u00b7wen\u00b7det", "an\u00b7der\u00b7weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVPP", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.84": {"text": "Vnd frembder Liebe sich ergeben allbereit.", "tokens": ["Vnd", "fremb\u00b7der", "Lie\u00b7be", "sich", "er\u00b7ge\u00b7ben", "all\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PRF", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Vnd m\u00f6chte man nun auch gleich jhrer Gunst geniessen,", "tokens": ["Vnd", "m\u00f6ch\u00b7te", "man", "nun", "auch", "gleich", "jhrer", "Gunst", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "ADV", "ADV", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.86": {"text": "Wie selten geht es zu, da\u00df man ein gut Gewissen", "tokens": ["Wie", "sel\u00b7ten", "geht", "es", "zu", ",", "da\u00df", "man", "ein", "gut", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PIS", "ART", "ADJD", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.87": {"text": "Darob behalten solt', es ist vielmehr gefehr',", "tokens": ["Da\u00b7rob", "be\u00b7hal\u00b7ten", "solt'", ",", "es", "ist", "viel\u00b7mehr", "ge\u00b7fehr'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVINF", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Al\u00df wenn man niemals nicht von jhr geliebet wer'.", "tokens": ["Al\u00df", "wenn", "man", "nie\u00b7mals", "nicht", "von", "jhr", "ge\u00b7lie\u00b7bet", "wer'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PIS", "ADV", "PTKNEG", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Im Fall dieselbe Lust, was bringt sie nicht zu wegen?", "tokens": ["Im", "Fall", "die\u00b7sel\u00b7be", "Lust", ",", "was", "bringt", "sie", "nicht", "zu", "we\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Vor Ehren Schimpff vnd Spott, den Fluch vor guten Segen,", "tokens": ["Vor", "Eh\u00b7ren", "Schimpff", "vnd", "Spott", ",", "den", "Fluch", "vor", "gu\u00b7ten", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "KON", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Die gar zu falsche Lust, was bringt sie nicht f\u00fcr Leid?", "tokens": ["Die", "gar", "zu", "fal\u00b7sche", "Lust", ",", "was", "bringt", "sie", "nicht", "f\u00fcr", "Leid", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Sie ist der Tugend Mord, sie ist ein Raub der Zeit.", "tokens": ["Sie", "ist", "der", "Tu\u00b7gend", "Mord", ",", "sie", "ist", "ein", "Raub", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Was einem, weil er Jung, die Lieb' hat geben m\u00fcssen,", "tokens": ["Was", "ei\u00b7nem", ",", "weil", "er", "Jung", ",", "die", "Lieb'", "hat", "ge\u00b7ben", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "$,", "KOUS", "PPER", "NN", "$,", "ART", "NN", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Das mu\u00df er, wenn er alt vnd schwach, offt erstlich b\u00fcssen,", "tokens": ["Das", "mu\u00df", "er", ",", "wenn", "er", "alt", "vnd", "schwach", ",", "offt", "erst\u00b7lich", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "$,", "KOUS", "PPER", "ADJD", "KON", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Es naschet mancher jetzt so viel ohn allen Raht,", "tokens": ["Es", "na\u00b7schet", "man\u00b7cher", "jetzt", "so", "viel", "ohn", "al\u00b7len", "Raht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Da\u00df er bi\u00df in das Grab gnug zu verdawen hat.", "tokens": ["Da\u00df", "er", "bi\u00df", "in", "das", "Grab", "gnug", "zu", "ver\u00b7da\u00b7wen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.97": {"text": "Darumb wie wol sind die, so weit von solchen dingen", "tokens": ["Da\u00b7rumb", "wie", "wol", "sind", "die", ",", "so", "weit", "von", "sol\u00b7chen", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "KOKOM", "ADV", "VAFIN", "ART", "$,", "ADV", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Zu jhrem Joche mag die keusche Liebe bringen,", "tokens": ["Zu", "jhrem", "Jo\u00b7che", "mag", "die", "keu\u00b7sche", "Lie\u00b7be", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.99": {"text": "Sie sind ergeben gar der h\u00f6chsten freundligkeit,", "tokens": ["Sie", "sind", "er\u00b7ge\u00b7ben", "gar", "der", "h\u00f6chs\u00b7ten", "freund\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Verwart vnd zugedeckt vor alles Gl\u00fcckes neidt.", "tokens": ["Ver\u00b7wart", "vnd", "zu\u00b7ge\u00b7deckt", "vor", "al\u00b7les", "Gl\u00fc\u00b7ckes", "neidt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Der Br\u00e4utgam wird nun auch hiervon zu sagen wissen,", "tokens": ["Der", "Br\u00e4ut\u00b7gam", "wird", "nun", "auch", "hier\u00b7von", "zu", "sa\u00b7gen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "ADV", "PAV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Wenn er die keusche Lust mit seiner Braut wird b\u00fcssen,", "tokens": ["Wenn", "er", "die", "keu\u00b7sche", "Lust", "mit", "sei\u00b7ner", "Braut", "wird", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Es wird jhm numehr auch recht erstlich sein bekandt,", "tokens": ["Es", "wird", "jhm", "nu\u00b7mehr", "auch", "recht", "erst\u00b7lich", "sein", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VAINF", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Was Liebe sey vor Noth, die ausser diesem Stand.", "tokens": ["Was", "Lie\u00b7be", "sey", "vor", "Noth", ",", "die", "aus\u00b7ser", "die\u00b7sem", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "APPR", "NN", "$,", "PRELS", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Wie vngleich geht es zu auff dieser Lebens Reise,", "tokens": ["Wie", "vn\u00b7gleich", "geht", "es", "zu", "auff", "die\u00b7ser", "Le\u00b7bens", "Rei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PTKZU", "APPR", "PDAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie seltzam spielt mit vns auff sonder Art vnd Weise", "tokens": ["Wie", "selt\u00b7zam", "spielt", "mit", "vns", "auff", "son\u00b7der", "Art", "vnd", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "APPR", "PPER", "APPR", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des falschen Gl\u00fcckes Rund, des angenehmen Flei\u00df", "tokens": ["Des", "fal\u00b7schen", "Gl\u00fc\u00b7ckes", "Rund", ",", "des", "an\u00b7ge\u00b7neh\u00b7men", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sich Venus sonderlich wol zu gebrauchen wei\u00df.", "tokens": ["Sich", "Ve\u00b7nus", "son\u00b7der\u00b7lich", "wol", "zu", "ge\u00b7brau\u00b7chen", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NE", "ADJD", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir ziehen alle zwar zu gleich an jhrem Wagen", "tokens": ["Wir", "zie\u00b7hen", "al\u00b7le", "zwar", "zu", "gleich", "an", "jhrem", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "APPR", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Vnd sind in jhrem Dienst nach allem wolbehagen,", "tokens": ["Vnd", "sind", "in", "jhrem", "Dienst", "nach", "al\u00b7lem", "wol\u00b7be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "PPOSAT", "NN", "APPR", "PIS", "VMFIN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.7": {"text": "Dadurch vermeinen wir zu haben jhre Gunst,", "tokens": ["Da\u00b7durch", "ver\u00b7mei\u00b7nen", "wir", "zu", "ha\u00b7ben", "jhre", "Gunst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PTKZU", "VAINF", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.8": {"text": "Erweisen allen Flei\u00df, ersparen keine Kunst.", "tokens": ["Er\u00b7wei\u00b7sen", "al\u00b7len", "Flei\u00df", ",", "er\u00b7spa\u00b7ren", "kei\u00b7ne", "Kunst", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$,", "VVFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sie aber lest doch nur, auff welchen sie wil, fallen", "tokens": ["Sie", "a\u00b7ber", "lest", "doch", "nur", ",", "auff", "wel\u00b7chen", "sie", "wil", ",", "fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "$,", "APPR", "PWAT", "PPER", "VMFIN", "$,", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Stralen jhrer Gunst vnd ehret den vor allen,", "tokens": ["Die", "Stra\u00b7len", "jhrer", "Gunst", "vnd", "eh\u00b7ret", "den", "vor", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "VVFIN", "ART", "APPR", "PIAT", "$,"], "meter": "-+--+-+---+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Wem sie es g\u00f6nt allein, sie hebet jhn empor", "tokens": ["Wem", "sie", "es", "g\u00f6nt", "al\u00b7lein", ",", "sie", "he\u00b7bet", "jhn", "em\u00b7por"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der andern vngeacht, die leben nach wie vor", "tokens": ["Der", "an\u00b7dern", "vn\u00b7ge\u00b7acht", ",", "die", "le\u00b7ben", "nach", "wie", "vor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "VVFIN", "APPR", "KOKOM", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Liebe Grawsamkeit zu dienst in schweren Z\u00fcgen,", "tokens": ["Der", "Lie\u00b7be", "Graw\u00b7sam\u00b7keit", "zu", "dienst", "in", "schwe\u00b7ren", "Z\u00fc\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vnd steter Hertzens-Angst, davor sein grosses gn\u00fcgen", "tokens": ["Vnd", "ste\u00b7ter", "Hert\u00b7zens\u00b7Angst", ",", "da\u00b7vor", "sein", "gros\u00b7ses", "gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "$,", "PAV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Der Br\u00e4utgam jetzt empfind, er lebet gantz befreyt,", "tokens": ["Der", "Br\u00e4ut\u00b7gam", "jetzt", "emp\u00b7find", ",", "er", "le\u00b7bet", "gantz", "be\u00b7freyt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "ADJD", "$,", "PPER", "VVFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Indem er schl\u00e4fft vnd wacht in steter Sicherheit.", "tokens": ["In\u00b7dem", "er", "schl\u00e4fft", "vnd", "wacht", "in", "ste\u00b7ter", "Si\u00b7cher\u00b7heit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Es setzet Venus jhn hoch an des Gl\u00fcckes Zinnen", "tokens": ["Es", "set\u00b7zet", "Ve\u00b7nus", "jhn", "hoch", "an", "des", "Gl\u00fc\u00b7ckes", "Zin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "PPER", "ADJD", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Vnd lest jhn seine Lust nach eusserstem beginnen", "tokens": ["Vnd", "lest", "jhn", "sei\u00b7ne", "Lust", "nach", "eus\u00b7sers\u00b7tem", "be\u00b7gin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "PPER", "PPOSAT", "NN", "APPR", "ADJA", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Recht nehmen f\u00fcr vnd f\u00fcr, in dem sie jhme giebt", "tokens": ["Recht", "neh\u00b7men", "f\u00fcr", "vnd", "f\u00fcr", ",", "in", "dem", "sie", "jh\u00b7me", "giebt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVINF", "APPR", "KON", "APPR", "$,", "APPR", "PRELS", "PPER", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ein freundlichs Frawenbild, daran er sich verliebt.", "tokens": ["Ein", "freund\u00b7lichs", "Fra\u00b7wen\u00b7bild", ",", "da\u00b7ran", "er", "sich", "ver\u00b7liebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PAV", "PPER", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Nun zwar wir g\u00f6nnens jhm, vnd w\u00fcnschen jhm viel Segen,", "tokens": ["Nun", "zwar", "wir", "g\u00f6n\u00b7nens", "jhm", ",", "vnd", "w\u00fcn\u00b7schen", "jhm", "viel", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "ADV", "PPER", "$,", "KON", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Da\u00df er vnd seine Braut die Zeit zubringen m\u00f6gen", "tokens": ["Da\u00df", "er", "vnd", "sei\u00b7ne", "Braut", "die", "Zeit", "zu\u00b7brin\u00b7gen", "m\u00f6\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "KON", "PPOSAT", "NN", "ART", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "In h\u00f6chstgew\u00fcnschter Lust, wir m\u00fcssen vnser Leid", "tokens": ["In", "h\u00f6chst\u00b7ge\u00b7w\u00fcnschter", "Lust", ",", "wir", "m\u00fcs\u00b7sen", "vn\u00b7ser", "Leid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$,", "PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Beklagen nur allein, da\u00df diese s\u00fcsse Frewd'", "tokens": ["Be\u00b7kla\u00b7gen", "nur", "al\u00b7lein", ",", "da\u00df", "die\u00b7se", "s\u00fcs\u00b7se", "Fre\u00b7wd'"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ADV", "$,", "KOUS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Vns kaum von fern nicht sieht, wir k\u00f6nnen nicht ersehen,", "tokens": ["Vns", "kaum", "von", "fern", "nicht", "sieht", ",", "wir", "k\u00f6n\u00b7nen", "nicht", "er\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADJD", "PTKNEG", "VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Wie es werd' einmahl noch mit vnser Lieb' ergehen,", "tokens": ["Wie", "es", "werd'", "ein\u00b7mahl", "noch", "mit", "vn\u00b7ser", "Lieb'", "er\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Wir Schiffen ohne Meer, wir segeln ohne Wind,", "tokens": ["Wir", "Schif\u00b7fen", "oh\u00b7ne", "Meer", ",", "wir", "se\u00b7geln", "oh\u00b7ne", "Wind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Wir sehen keinen Port, darauff man fussen k\u00fcnt',", "tokens": ["Wir", "se\u00b7hen", "kei\u00b7nen", "Port", ",", "dar\u00b7auff", "man", "fus\u00b7sen", "k\u00fcnt'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "PAV", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Vnd dennoch lieben wir, gleich wie die stoltze Wellen", "tokens": ["Vnd", "den\u00b7noch", "lie\u00b7ben", "wir", ",", "gleich", "wie", "die", "stolt\u00b7ze", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Im tollen Meere gehn, gef\u00fchrt al\u00df hin zur Hellen,", "tokens": ["Im", "tol\u00b7len", "Mee\u00b7re", "gehn", ",", "ge\u00b7f\u00fchrt", "al\u00df", "hin", "zur", "Hel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVINF", "$,", "VVPP", "KOKOM", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Die doch am andern Theil wie grosse H\u00fcgel sind", "tokens": ["Die", "doch", "am", "an\u00b7dern", "Theil", "wie", "gros\u00b7se", "H\u00fc\u00b7gel", "sind"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "ADJA", "NN", "KOKOM", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Erhaben durch die Fluth vnd strengen Nordenwind", "tokens": ["Er\u00b7ha\u00b7ben", "durch", "die", "Fluth", "vnd", "stren\u00b7gen", "Nor\u00b7den\u00b7wind"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Bi\u00df an der Sternen Sitz, so m\u00fcssen wir auch leben,", "tokens": ["Bi\u00df", "an", "der", "Ster\u00b7nen", "Sitz", ",", "so", "m\u00fcs\u00b7sen", "wir", "auch", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Die wir der Liebe sind zu Pflicht vnd Dienst ergeben.", "tokens": ["Die", "wir", "der", "Lie\u00b7be", "sind", "zu", "Pflicht", "vnd", "Dienst", "er\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Der eine schwebt empor, der ander leidet Pein", "tokens": ["Der", "ei\u00b7ne", "schwebt", "em\u00b7por", ",", "der", "an\u00b7der", "lei\u00b7det", "Pein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "PTKVZ", "$,", "PRELS", "ADJD", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Vnd mu\u00df des Gl\u00fcckes Rad vnd stete Kurtzweil seyn.", "tokens": ["Vnd", "mu\u00df", "des", "Gl\u00fc\u00b7ckes", "Rad", "vnd", "ste\u00b7te", "Kurt\u00b7zweil", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "KON", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Da kostets manchen Wunsch, da kostets manche Tr\u00e4nen,", "tokens": ["Da", "kos\u00b7tets", "man\u00b7chen", "Wunsch", ",", "da", "kos\u00b7tets", "man\u00b7che", "Tr\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,", "KOUS", "NE", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Eh' vns das wird gewehrt, nach deme wir vns sehnen,", "tokens": ["Eh'", "vns", "das", "wird", "ge\u00b7wehrt", ",", "nach", "de\u00b7me", "wir", "vns", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PDS", "VAFIN", "VVPP", "$,", "APPR", "PRELS", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "Wie offte machen vns viel tausent Seufftzer matt,", "tokens": ["Wie", "off\u00b7te", "ma\u00b7chen", "vns", "viel", "tau\u00b7sent", "Seufft\u00b7zer", "matt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PPER", "ADV", "CARD", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "An stat der Speis' vnd Tranck macht vns das Weinen satt.", "tokens": ["An", "stat", "der", "Speis'", "vnd", "Tranck", "macht", "vns", "das", "Wei\u00b7nen", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "NN", "KON", "NN", "VVFIN", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "Bald nemmen wir zur Hand die sch\u00f6nen Sch\u00e4ffereyen,", "tokens": ["Bald", "nem\u00b7men", "wir", "zur", "Hand", "die", "sch\u00f6\u00b7nen", "Sch\u00e4f\u00b7fe\u00b7re\u00b7yen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.42": {"text": "Ob die vns m\u00f6chten noch in etwas nur erfrewen,", "tokens": ["Ob", "die", "vns", "m\u00f6ch\u00b7ten", "noch", "in", "et\u00b7was", "nur", "er\u00b7fre\u00b7wen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "PPER", "VMFIN", "ADV", "APPR", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+---+-+---", "measure": "unknown.measure.tetra"}, "line.43": {"text": "Bald' auch den Amadis, was Naso hat gesagt", "tokens": ["Bald'", "auch", "den", "A\u00b7ma\u00b7dis", ",", "was", "Na\u00b7so", "hat", "ge\u00b7sagt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "NE", "$,", "PRELS", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Vom Buhlen, solches vns vor Plato weit verjagt.", "tokens": ["Vom", "Buh\u00b7len", ",", "sol\u00b7ches", "vns", "vor", "Pla\u00b7to", "weit", "ver\u00b7jagt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "KOUS", "PPER", "APPR", "NE", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.45": {"text": "Wir lassen alles stehn, vnd dies seyn vnser tichten,", "tokens": ["Wir", "las\u00b7sen", "al\u00b7les", "stehn", ",", "vnd", "dies", "seyn", "vn\u00b7ser", "tich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVINF", "$,", "KON", "PDS", "VAFIN", "PPOSAT", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Der allerliebsten vns mit diensten zu verpflichten,", "tokens": ["Der", "al\u00b7ler\u00b7liebs\u00b7ten", "vns", "mit", "diens\u00b7ten", "zu", "ver\u00b7pflich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PPER", "APPR", "PDS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Auff da\u00df es h\u00f6fflich sey, wir brauchen vmbschweiffs viel,", "tokens": ["Auff", "da\u00df", "es", "h\u00f6ff\u00b7lich", "sey", ",", "wir", "brau\u00b7chen", "vmb\u00b7schweiffs", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "ADJD", "VAFIN", "$,", "PPER", "VVFIN", "APPRART", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Eh dann man von der Lieb' etwas gedencken wil.", "tokens": ["Eh", "dann", "man", "von", "der", "Lieb'", "et\u00b7was", "ge\u00b7den\u00b7cken", "wil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PIS", "APPR", "ART", "NN", "PIAT", "NN", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wir w\u00e4gen alle Wort auff einer Wageschalen,", "tokens": ["Wir", "w\u00e4\u00b7gen", "al\u00b7le", "Wort", "auff", "ei\u00b7ner", "Wa\u00b7ge\u00b7scha\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Besinnen hin vnd her zu vielen hundert malen,", "tokens": ["Be\u00b7sin\u00b7nen", "hin", "vnd", "her", "zu", "vie\u00b7len", "hun\u00b7dert", "ma\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "KON", "ADV", "APPR", "PIAT", "CARD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Was vorzubringen sey, die dienste zu voran", "tokens": ["Was", "vor\u00b7zu\u00b7brin\u00b7gen", "sey", ",", "die", "diens\u00b7te", "zu", "vo\u00b7ran"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "VVIZU", "VAFIN", "$,", "ART", "ADJA", "PTKZU", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Die werden abgeschickt das Werck zu fangen an.", "tokens": ["Die", "wer\u00b7den", "ab\u00b7ge\u00b7schickt", "das", "Werck", "zu", "fan\u00b7gen", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "ART", "NN", "PTKZU", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Da nimbt man weiter denn gelegenheit zu sagen,", "tokens": ["Da", "nimbt", "man", "wei\u00b7ter", "denn", "ge\u00b7le\u00b7gen\u00b7heit", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Bi\u00df wegen grosser Lieb' vns endlich wir beklagen,", "tokens": ["Bi\u00df", "we\u00b7gen", "gros\u00b7ser", "Lieb'", "vns", "end\u00b7lich", "wir", "be\u00b7kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ADJA", "NN", "PPER", "ADV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Wie sie vns habe selbst das Hertz genommen ein,", "tokens": ["Wie", "sie", "vns", "ha\u00b7be", "selbst", "das", "Hertz", "ge\u00b7nom\u00b7men", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Das bey vns nichts mehr ist als bitter s\u00fcsse Pein,", "tokens": ["Das", "bey", "vns", "nichts", "mehr", "ist", "als", "bit\u00b7ter", "s\u00fcs\u00b7se", "Pein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PPER", "PIS", "ADV", "VAFIN", "KOKOM", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Vnnd was der reden mehr ein Weibsbild zu beth\u00f6ren.", "tokens": ["Vnnd", "was", "der", "re\u00b7den", "mehr", "ein", "Weibs\u00b7bild", "zu", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "ADJA", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Wenn wir denn nun von Ihr abschl\u00e4glich' antwort h\u00f6ren,", "tokens": ["Wenn", "wir", "denn", "nun", "von", "Ihr", "ab\u00b7schl\u00e4g\u00b7lich'", "ant\u00b7wort", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-++-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.59": {"text": "Da geht das klagen an, man wil des Lebens ab", "tokens": ["Da", "geht", "das", "kla\u00b7gen", "an", ",", "man", "wil", "des", "Le\u00b7bens", "ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PDS", "VVFIN", "PTKVZ", "$,", "PIS", "VMFIN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Vnd meint die beste Ruh zu finden in dem Grab.", "tokens": ["Vnd", "meint", "die", "bes\u00b7te", "Ruh", "zu", "fin\u00b7den", "in", "dem", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.61": {"text": "Da mu\u00df Cupido dann vnd Venus auch herhalten,", "tokens": ["Da", "mu\u00df", "Cu\u00b7pi\u00b7do", "dann", "vnd", "Ve\u00b7nus", "auch", "her\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NE", "ADV", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-----+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.62": {"text": "Vnd die man vor geehrt, die werden noch gescholten:", "tokens": ["Vnd", "die", "man", "vor", "ge\u00b7ehrt", ",", "die", "wer\u00b7den", "noch", "ge\u00b7schol\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "APPR", "VVPP", "$,", "PRELS", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Cupido der Tyrann' auch sie die Z\u00e4uberinn',", "tokens": ["Cu\u00b7pi\u00b7do", "der", "Ty\u00b7rann'", "auch", "sie", "die", "Z\u00e4u\u00b7be\u00b7rinn'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADV", "PPER", "ART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.64": {"text": "Ich bin von Ihr gebl\u00e4ndt, bin Kranck an Hertz' vnd Sinn.", "tokens": ["Ich", "bin", "von", "Ihr", "ge\u00b7bl\u00e4ndt", ",", "bin", "Kranck", "an", "Hertz'", "vnd", "Sinn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVPP", "$,", "VAFIN", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Es mu\u00df die Liebst' auch dann von vns verachtet werden,", "tokens": ["Es", "mu\u00df", "die", "Liebst'", "auch", "dann", "von", "vns", "ver\u00b7ach\u00b7tet", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "ADV", "ADV", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Wir schm\u00e4hen, die zuvor die sch\u00f6nste war auff Erden,", "tokens": ["Wir", "schm\u00e4\u00b7hen", ",", "die", "zu\u00b7vor", "die", "sch\u00f6ns\u00b7te", "war", "auff", "Er\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ADV", "ART", "ADJA", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.67": {"text": "Wiewols nicht hertzlich ist, im fall der b\u00f6sen Lust,", "tokens": ["Wie\u00b7wols", "nicht", "hertz\u00b7lich", "ist", ",", "im", "fall", "der", "b\u00f6\u00b7sen", "Lust", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PTKNEG", "ADJD", "VAFIN", "$,", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Der w\u00fctenden begier ein anders ist bewust.", "tokens": ["Der", "w\u00fc\u00b7ten\u00b7den", "be\u00b7gier", "ein", "an\u00b7ders", "ist", "be\u00b7wust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADV", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Wer nur was wei\u00df vnd kan im tichten oder schreiben,", "tokens": ["Wer", "nur", "was", "wei\u00df", "vnd", "kan", "im", "tich\u00b7ten", "o\u00b7der", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PWS", "VVFIN", "KON", "VMFIN", "APPRART", "ADJA", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Der thut ihm nur die Zeit hie einig mit vertreiben,", "tokens": ["Der", "thut", "ihm", "nur", "die", "Zeit", "hie", "ei\u00b7nig", "mit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV", "ADJD", "APPR", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.71": {"text": "Da\u00df er sich sehr beklagt ob dero Tyranney,", "tokens": ["Da\u00df", "er", "sich", "sehr", "be\u00b7klagt", "ob", "de\u00b7ro", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "KOUS", "PRELAT", "NN", "$,"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.72": {"text": "Vmb derer willen er in Noth gerahten sey.", "tokens": ["Vmb", "de\u00b7rer", "wil\u00b7len", "er", "in", "Noth", "ge\u00b7rah\u00b7ten", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PDS", "VMFIN", "PPER", "APPR", "NN", "VVPP", "VAFIN", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.73": {"text": "Er klaget an jhr Hertz, welchs gleichet Stahl vnd Steine,", "tokens": ["Er", "kla\u00b7get", "an", "jhr", "Hertz", ",", "welchs", "glei\u00b7chet", "Stahl", "vnd", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,", "PWS", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Da\u00df nie kein seufftzer nicht, wie sehr er jmmer weine,", "tokens": ["Da\u00df", "nie", "kein", "seufft\u00b7zer", "nicht", ",", "wie", "sehr", "er", "jm\u00b7mer", "wei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Bewegen wil noch kan, wirfft seine Trew' jhr f\u00fcr,", "tokens": ["Be\u00b7we\u00b7gen", "wil", "noch", "kan", ",", "wirfft", "sei\u00b7ne", "Tre\u00b7w'", "jhr", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "VMFIN", "ADV", "VMFIN", "$,", "VVFIN", "PPOSAT", "NN", "PPER", "APPR", "$,"], "meter": "-+-+-+-+-++-+", "measure": "unknown.measure.septa"}, "line.76": {"text": "Vnd macht vom Menschen sie zum grimmen ThiegerThier.", "tokens": ["Vnd", "macht", "vom", "Men\u00b7schen", "sie", "zum", "grim\u00b7men", "Thie\u00b7ger", "Thier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "PPER", "APPRART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Er rufft die G\u00f6tter an, die Rach' an ihr zu \u00fcben,", "tokens": ["Er", "rufft", "die", "G\u00f6t\u00b7ter", "an", ",", "die", "Rach'", "an", "ihr", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "ART", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Al\u00df die geliebt wil sein, vnd doch nicht wieder lieben,", "tokens": ["Al\u00df", "die", "ge\u00b7liebt", "wil", "sein", ",", "vnd", "doch", "nicht", "wie\u00b7der", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "VVPP", "VMFIN", "VAINF", "$,", "KON", "ADV", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.79": {"text": "Er saget, wie sie gar jhn vmb sein Leben bring',", "tokens": ["Er", "sa\u00b7get", ",", "wie", "sie", "gar", "jhn", "vmb", "sein", "Le\u00b7ben", "bring'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Vnd wie er auch numehr fast mit dem Tode ring'.", "tokens": ["Vnd", "wie", "er", "auch", "nu\u00b7mehr", "fast", "mit", "dem", "To\u00b7de", "ring'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Hiemit vermeint er sie noch endlich zu bezwingen", "tokens": ["Hie\u00b7mit", "ver\u00b7meint", "er", "sie", "noch", "end\u00b7lich", "zu", "be\u00b7zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Vnd jhren harten Sinn zu lieben auff zu bringen,", "tokens": ["Vnd", "jhren", "har\u00b7ten", "Sinn", "zu", "lie\u00b7ben", "auff", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "PTKZU", "VVINF", "APPR", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.83": {"text": "Die jhren stoltzen Sinn gewendet anderweit", "tokens": ["Die", "jhren", "stolt\u00b7zen", "Sinn", "ge\u00b7wen\u00b7det", "an\u00b7der\u00b7weit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VVPP", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.84": {"text": "Vnd frembder Liebe sich ergeben allbereit.", "tokens": ["Vnd", "fremb\u00b7der", "Lie\u00b7be", "sich", "er\u00b7ge\u00b7ben", "all\u00b7be\u00b7reit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PRF", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Vnd m\u00f6chte man nun auch gleich jhrer Gunst geniessen,", "tokens": ["Vnd", "m\u00f6ch\u00b7te", "man", "nun", "auch", "gleich", "jhrer", "Gunst", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "ADV", "ADV", "ADV", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.86": {"text": "Wie selten geht es zu, da\u00df man ein gut Gewissen", "tokens": ["Wie", "sel\u00b7ten", "geht", "es", "zu", ",", "da\u00df", "man", "ein", "gut", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "PIS", "ART", "ADJD", "NN"], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.87": {"text": "Darob behalten solt', es ist vielmehr gefehr',", "tokens": ["Da\u00b7rob", "be\u00b7hal\u00b7ten", "solt'", ",", "es", "ist", "viel\u00b7mehr", "ge\u00b7fehr'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVINF", "VMFIN", "$,", "PPER", "VAFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Al\u00df wenn man niemals nicht von jhr geliebet wer'.", "tokens": ["Al\u00df", "wenn", "man", "nie\u00b7mals", "nicht", "von", "jhr", "ge\u00b7lie\u00b7bet", "wer'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOUS", "PIS", "ADV", "PTKNEG", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Im Fall dieselbe Lust, was bringt sie nicht zu wegen?", "tokens": ["Im", "Fall", "die\u00b7sel\u00b7be", "Lust", ",", "was", "bringt", "sie", "nicht", "zu", "we\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Vor Ehren Schimpff vnd Spott, den Fluch vor guten Segen,", "tokens": ["Vor", "Eh\u00b7ren", "Schimpff", "vnd", "Spott", ",", "den", "Fluch", "vor", "gu\u00b7ten", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "KON", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Die gar zu falsche Lust, was bringt sie nicht f\u00fcr Leid?", "tokens": ["Die", "gar", "zu", "fal\u00b7sche", "Lust", ",", "was", "bringt", "sie", "nicht", "f\u00fcr", "Leid", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ADJA", "NN", "$,", "PWS", "VVFIN", "PPER", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Sie ist der Tugend Mord, sie ist ein Raub der Zeit.", "tokens": ["Sie", "ist", "der", "Tu\u00b7gend", "Mord", ",", "sie", "ist", "ein", "Raub", "der", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Was einem, weil er Jung, die Lieb' hat geben m\u00fcssen,", "tokens": ["Was", "ei\u00b7nem", ",", "weil", "er", "Jung", ",", "die", "Lieb'", "hat", "ge\u00b7ben", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "$,", "KOUS", "PPER", "NN", "$,", "ART", "NN", "VAFIN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Das mu\u00df er, wenn er alt vnd schwach, offt erstlich b\u00fcssen,", "tokens": ["Das", "mu\u00df", "er", ",", "wenn", "er", "alt", "vnd", "schwach", ",", "offt", "erst\u00b7lich", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "$,", "KOUS", "PPER", "ADJD", "KON", "VVFIN", "$,", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Es naschet mancher jetzt so viel ohn allen Raht,", "tokens": ["Es", "na\u00b7schet", "man\u00b7cher", "jetzt", "so", "viel", "ohn", "al\u00b7len", "Raht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADV", "ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Da\u00df er bi\u00df in das Grab gnug zu verdawen hat.", "tokens": ["Da\u00df", "er", "bi\u00df", "in", "das", "Grab", "gnug", "zu", "ver\u00b7da\u00b7wen", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ADV", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.97": {"text": "Darumb wie wol sind die, so weit von solchen dingen", "tokens": ["Da\u00b7rumb", "wie", "wol", "sind", "die", ",", "so", "weit", "von", "sol\u00b7chen", "din\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "KOKOM", "ADV", "VAFIN", "ART", "$,", "ADV", "ADJD", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Zu jhrem Joche mag die keusche Liebe bringen,", "tokens": ["Zu", "jhrem", "Jo\u00b7che", "mag", "die", "keu\u00b7sche", "Lie\u00b7be", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.99": {"text": "Sie sind ergeben gar der h\u00f6chsten freundligkeit,", "tokens": ["Sie", "sind", "er\u00b7ge\u00b7ben", "gar", "der", "h\u00f6chs\u00b7ten", "freund\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Verwart vnd zugedeckt vor alles Gl\u00fcckes neidt.", "tokens": ["Ver\u00b7wart", "vnd", "zu\u00b7ge\u00b7deckt", "vor", "al\u00b7les", "Gl\u00fc\u00b7ckes", "neidt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVPP", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Der Br\u00e4utgam wird nun auch hiervon zu sagen wissen,", "tokens": ["Der", "Br\u00e4ut\u00b7gam", "wird", "nun", "auch", "hier\u00b7von", "zu", "sa\u00b7gen", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VAFIN", "ADV", "ADV", "PAV", "PTKZU", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Wenn er die keusche Lust mit seiner Braut wird b\u00fcssen,", "tokens": ["Wenn", "er", "die", "keu\u00b7sche", "Lust", "mit", "sei\u00b7ner", "Braut", "wird", "b\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Es wird jhm numehr auch recht erstlich sein bekandt,", "tokens": ["Es", "wird", "jhm", "nu\u00b7mehr", "auch", "recht", "erst\u00b7lich", "sein", "be\u00b7kandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ADJD", "VAINF", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Was Liebe sey vor Noth, die ausser diesem Stand.", "tokens": ["Was", "Lie\u00b7be", "sey", "vor", "Noth", ",", "die", "aus\u00b7ser", "die\u00b7sem", "Stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "APPR", "NN", "$,", "PRELS", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}