{"textgrid.poem.54124": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Sind Sie eine Pers\u00f6nlichkeit?", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nach einigen Schwedenp\u00fcnschen", "tokens": ["Nach", "ei\u00b7ni\u00b7gen", "Schwe\u00b7den\u00b7p\u00fcn\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "beginnen Sie zu w\u00fcnschen:", "tokens": ["be\u00b7gin\u00b7nen", "Sie", "zu", "w\u00fcn\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie drehen ganz im stillen", "tokens": ["Sie", "dre\u00b7hen", "ganz", "im", "stil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die bunten Zuckerpillen:", "tokens": ["die", "bun\u00b7ten", "Zu\u00b7cker\u00b7pil\u00b7len", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.3": {"line.1": {"text": "Man schluckt voll Wut mitunter,", "tokens": ["Man", "schluckt", "voll", "Wut", "mi\u00b7tun\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "NN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "weil man mu\u00df, so manches runter.", "tokens": ["weil", "man", "mu\u00df", ",", "so", "man\u00b7ches", "run\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "$,", "ADV", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Nacht, beim Mondenscheine,", "tokens": ["In", "der", "Nacht", ",", "beim", "Mon\u00b7den\u00b7schei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nimmt man Rache \u2013 ganz alleine:", "tokens": ["nimmt", "man", "Ra\u00b7che", "\u2013", "ganz", "al\u00b7lei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "$(", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Sie sagen im Theater:", "tokens": ["Sie", "sa\u00b7gen", "im", "The\u00b7a\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Diese Menschen . . . heiliger Vater!", "tokens": ["Die\u00b7se", "Men\u00b7schen", ".", ".", ".", "hei\u00b7li\u00b7ger", "Va\u00b7ter", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$.", "$.", "$.", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Jeder einzelne ein Hund, ein", "tokens": ["Je\u00b7der", "ein\u00b7zel\u00b7ne", "ein", "Hund", ",", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "ADJA", "ART", "NN", "$,", "ART"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "krummer \u2013", "tokens": ["krum\u00b7mer", "\u2013"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "da bin ", "tokens": ["da", "bin"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Nummer . . .", "tokens": ["Num\u00b7mer", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.6": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch \u2013!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADV", "$(", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.7": {"line.1": {"text": "Nach einigen Schwedenp\u00fcnschen", "tokens": ["Nach", "ei\u00b7ni\u00b7gen", "Schwe\u00b7den\u00b7p\u00fcn\u00b7schen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "beginnen Sie zu w\u00fcnschen:", "tokens": ["be\u00b7gin\u00b7nen", "Sie", "zu", "w\u00fcn\u00b7schen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie drehen ganz im stillen", "tokens": ["Sie", "dre\u00b7hen", "ganz", "im", "stil\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die bunten Zuckerpillen:", "tokens": ["die", "bun\u00b7ten", "Zu\u00b7cker\u00b7pil\u00b7len", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Man schluckt voll Wut mitunter,", "tokens": ["Man", "schluckt", "voll", "Wut", "mi\u00b7tun\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADJD", "NN", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "weil man mu\u00df, so manches runter.", "tokens": ["weil", "man", "mu\u00df", ",", "so", "man\u00b7ches", "run\u00b7ter", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VMFIN", "$,", "ADV", "PIS", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "In der Nacht, beim Mondenscheine,", "tokens": ["In", "der", "Nacht", ",", "beim", "Mon\u00b7den\u00b7schei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "nimmt man Rache \u2013 ganz alleine:", "tokens": ["nimmt", "man", "Ra\u00b7che", "\u2013", "ganz", "al\u00b7lei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "NN", "$(", "ADV", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.11": {"line.1": {"text": "Sie sagen im Theater:", "tokens": ["Sie", "sa\u00b7gen", "im", "The\u00b7a\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Diese Menschen . . . heiliger Vater!", "tokens": ["Die\u00b7se", "Men\u00b7schen", ".", ".", ".", "hei\u00b7li\u00b7ger", "Va\u00b7ter", "!"], "token_info": ["word", "word", "punct", "punct", "punct", "word", "word", "punct"], "pos": ["PDAT", "NN", "$.", "$.", "$.", "ADJA", "NN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Jeder einzelne ein Hund, ein", "tokens": ["Je\u00b7der", "ein\u00b7zel\u00b7ne", "ein", "Hund", ",", "ein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PIAT", "ADJA", "ART", "NN", "$,", "ART"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "krummer \u2013", "tokens": ["krum\u00b7mer", "\u2013"], "token_info": ["word", "punct"], "pos": ["ADJD", "$("], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "da bin ", "tokens": ["da", "bin"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Nummer . . .", "tokens": ["Num\u00b7mer", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.12": {"line.1": {"text": "Ach!", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Damit stehn Sie aber nicht vereinzelt da!", "tokens": ["Da\u00b7mit", "stehn", "Sie", "a\u00b7ber", "nicht", "ver\u00b7ein\u00b7zelt", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "ADV", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "So was denkt man von Florenz bis Altona!", "tokens": ["So", "was", "denkt", "man", "von", "Flo\u00b7renz", "bis", "Al\u00b7to\u00b7na", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "VVFIN", "PIS", "APPR", "NE", "APPR", "NE", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "Was Sie da so treiben, das hat lange im Gebrauch", "tokens": ["Was", "Sie", "da", "so", "trei\u00b7ben", ",", "das", "hat", "lan\u00b7ge", "im", "Ge\u00b7brauch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVINF", "$,", "PDS", "VAFIN", "ADV", "APPRART", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.5": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "der andere auch!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "der andere auch \u2013!", "tokens": ["der", "an\u00b7de\u00b7re", "auch", "\u2013", "!"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADV", "$(", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}}}}