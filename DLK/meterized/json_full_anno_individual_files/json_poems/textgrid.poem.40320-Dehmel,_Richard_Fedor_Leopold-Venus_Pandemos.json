{"textgrid.poem.40320": {"metadata": {"author": {"name": "Dehmel, Richard Fedor Leopold", "birth": "N.A.", "death": "N.A."}, "title": "Venus Pandemos", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Das war das letzte Mal. Im Nachtcaf\u00e9", "tokens": ["Das", "war", "das", "letz\u00b7te", "Mal", ".", "Im", "Nacht\u00b7ca\u00b7f\u00e9"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Vorstadt sa\u00df ich, m\u00fcde vom Geruch", "tokens": ["der", "Vor\u00b7stadt", "sa\u00df", "ich", ",", "m\u00fc\u00b7de", "vom", "Ge\u00b7ruch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der schw\u00fclen Sofapolster und des Punsches,", "tokens": ["der", "schw\u00fc\u00b7len", "So\u00b7fa\u00b7pols\u00b7ter", "und", "des", "Pun\u00b7sches", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der vor mir gl\u00fchte, und vom Frauendunst", "tokens": ["der", "vor", "mir", "gl\u00fch\u00b7te", ",", "und", "vom", "Frau\u00b7en\u00b7dunst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$,", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der feuchten Winterkleider; m\u00fcde, l\u00fcstern.", "tokens": ["der", "feuch\u00b7ten", "Win\u00b7ter\u00b7klei\u00b7der", ";", "m\u00fc\u00b7de", ",", "l\u00fcs\u00b7tern", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Die Tabakswolken schwankten vom Gel\u00e4chter", "tokens": ["Die", "Ta\u00b7baks\u00b7wol\u00b7ken", "schwank\u00b7ten", "vom", "Ge\u00b7l\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und feilschenden Gekreisch der bunten Dirnen", "tokens": ["und", "feil\u00b7schen\u00b7den", "Ge\u00b7kreisch", "der", "bun\u00b7ten", "Dir\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und Derer, die drum warben. Das Gerassel", "tokens": ["und", "De\u00b7rer", ",", "die", "drum", "war\u00b7ben", ".", "Das", "Ge\u00b7ras\u00b7sel"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "PRELS", "PAV", "VVINF", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Alfenidel\u00f6ffel am B\u00fcffet", "tokens": ["der", "Al\u00b7fe\u00b7ni\u00b7de\u00b7l\u00f6f\u00b7fel", "am", "B\u00fcf\u00b7fet"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "ermunterte den L\u00e4rm des Liebesmarktes,", "tokens": ["er\u00b7mun\u00b7ter\u00b7te", "den", "L\u00e4rm", "des", "Lie\u00b7bes\u00b7mark\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ununterbrochen, wie ein Tamburin.", "tokens": ["un\u00b7un\u00b7ter\u00b7bro\u00b7chen", ",", "wie", "ein", "Tam\u00b7bu\u00b7rin", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ich sa\u00df, den langen Mittelgang betrachtend,", "tokens": ["Ich", "sa\u00df", ",", "den", "lan\u00b7gen", "Mit\u00b7tel\u00b7gang", "be\u00b7trach\u00b7tend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und lauschte, wie das Licht des Gaskronleuchters,", "tokens": ["und", "lauschte", ",", "wie", "das", "Licht", "des", "Gas\u00b7kron\u00b7leuch\u00b7ters", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "der dr\u00fcber hing, sich m\u00fchsam mit den Farben", "tokens": ["der", "dr\u00fc\u00b7ber", "hing", ",", "sich", "m\u00fch\u00b7sam", "mit", "den", "Far\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PAV", "VVFIN", "$,", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "auf den Gesichtern um die Marmortische", "tokens": ["auf", "den", "Ge\u00b7sich\u00b7tern", "um", "die", "Mar\u00b7mor\u00b7ti\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.5": {"text": "in seiner gelben Sprache unterhielt;", "tokens": ["in", "sei\u00b7ner", "gel\u00b7ben", "Spra\u00b7che", "un\u00b7ter\u00b7hielt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wozu der schwarze Marmor blank auflachte.", "tokens": ["wo\u00b7zu", "der", "schwar\u00b7ze", "Mar\u00b7mor", "blank", "auf\u00b7lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ich war schon bei der Wahl \u2013 da teilte sich", "tokens": ["Ich", "war", "schon", "bei", "der", "Wahl", "\u2013", "da", "teil\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$(", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die rote T\u00fcrgardine neben mir:", "tokens": ["die", "ro\u00b7te", "T\u00fcr\u00b7gar\u00b7di\u00b7ne", "ne\u00b7ben", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein neues Paar trat ein. Ein kalter Zug", "tokens": ["ein", "neu\u00b7es", "Paar", "trat", "ein", ".", "Ein", "kal\u00b7ter", "Zug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "schnitt durch den hei\u00dfen Raum, und Einer fluchte;", "tokens": ["schnitt", "durch", "den", "hei\u00b7\u00dfen", "Raum", ",", "und", "Ei\u00b7ner", "fluch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "KON", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die Beiden schritten ruhig durch den Schwarm.", "tokens": ["die", "Bei\u00b7den", "schrit\u00b7ten", "ru\u00b7hig", "durch", "den", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mir grade gegen\u00fcber, quer am Ende", "tokens": ["Mir", "gra\u00b7de", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ",", "quer", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "des Ganges, als beherrschten sie den Saal,", "tokens": ["des", "Gan\u00b7ges", ",", "als", "be\u00b7herrschten", "sie", "den", "Saal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "nahmen sie Platz. Der bronzene Kronleuchter", "tokens": ["nah\u00b7men", "sie", "Platz", ".", "Der", "bron\u00b7ze\u00b7ne", "Kron\u00b7leuch\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN"], "meter": "+--+-+---+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "hing \u00fcber ihnen wie ein schwerer alter", "tokens": ["hing", "\u00fc\u00b7ber", "ih\u00b7nen", "wie", "ein", "schwe\u00b7rer", "al\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPER", "KOKOM", "ART", "ADJA", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Thronhimmel. Keiner schien das Paar zu kennen.", "tokens": ["Thron\u00b7him\u00b7mel", ".", "Kei\u00b7ner", "schien", "das", "Paar", "zu", "ken\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Doch h\u00f6rt'ich rechts von mir ein heisres Stimmchen:", "tokens": ["Doch", "h\u00f6rt'\u00b7ich", "rechts", "von", "mir", "ein", "heis\u00b7res", "Stimm\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbbejejent mu\u00df ik die woll schon wo sein.\u00ab", "tokens": ["\u00bb", "be\u00b7je\u00b7jent", "mu\u00df", "ik", "die", "woll", "schon", "wo", "sein", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "VMFIN", "NE", "ART", "ADV", "ADV", "PWAV", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Er sa\u00df ganz still. Das laute Grau der Luft", "tokens": ["Er", "sa\u00df", "ganz", "still", ".", "Das", "lau\u00b7te", "Grau", "der", "Luft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$.", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "schrak fast zur\u00fcck vor seiner krassen Stirne,", "tokens": ["schrak", "fast", "zu\u00b7r\u00fcck", "vor", "sei\u00b7ner", "kras\u00b7sen", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die wachsbleich an die schwachen Haare stie\u00df.", "tokens": ["die", "wachs\u00b7bleich", "an", "die", "schwa\u00b7chen", "Haa\u00b7re", "stie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die gro\u00dfen blassen Augenlider waren", "tokens": ["Die", "gro\u00b7\u00dfen", "blas\u00b7sen", "Au\u00b7gen\u00b7li\u00b7der", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "tief zugeklappt, auf beiden Seiten lag", "tokens": ["tief", "zu\u00b7ge\u00b7klappt", ",", "auf", "bei\u00b7den", "Sei\u00b7ten", "lag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "APPR", "PIAT", "NN", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "ihr Schatten um die eingeknickte Nase;", "tokens": ["ihr", "Schat\u00b7ten", "um", "die", "ein\u00b7ge\u00b7knick\u00b7te", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der d\u00fcrre Vollbart lie\u00df die Haut durchscheinen.", "tokens": ["der", "d\u00fcr\u00b7re", "Voll\u00b7bart", "lie\u00df", "die", "Haut", "durch\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nur wenn die \u00fcppig kleinere Gef\u00e4hrtin", "tokens": ["Nur", "wenn", "die", "\u00fcp\u00b7pig", "klei\u00b7ne\u00b7re", "Ge\u00b7f\u00e4hr\u00b7tin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ihm kichernd einen Satz zuzischelte,", "tokens": ["ihm", "ki\u00b7chernd", "ei\u00b7nen", "Satz", "zu\u00b7zi\u00b7schel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "sah man sein eines schwarzes Auge halb", "tokens": ["sah", "man", "sein", "ei\u00b7nes", "schwar\u00b7zes", "Au\u00b7ge", "halb"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPOSAT", "ART", "ADJA", "NN", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "und drehte sich sein langer d\u00fcnner Hals,", "tokens": ["und", "dreh\u00b7te", "sich", "sein", "lan\u00b7ger", "d\u00fcn\u00b7ner", "Hals", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "langsam, und kroch der nackte Kehlkopf hoch,", "tokens": ["lang\u00b7sam", ",", "und", "kroch", "der", "nack\u00b7te", "Kehl\u00b7kopf", "hoch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.13": {"text": "wie wenn ein Geier nach dem Aase ruckt.", "tokens": ["wie", "wenn", "ein", "Gei\u00b7er", "nach", "dem", "Aa\u00b7se", "ruckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Es wurde immer stiller durch den Raum;", "tokens": ["Es", "wur\u00b7de", "im\u00b7mer", "stil\u00b7ler", "durch", "den", "Raum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sie blickten Alle auf den stummen Mann", "tokens": ["sie", "blick\u00b7ten", "Al\u00b7le", "auf", "den", "stum\u00b7men", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und auf das sonderbar geduckte Weib.", "tokens": ["und", "auf", "das", "son\u00b7der\u00b7bar", "ge\u00b7duck\u00b7te", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbsie ist ganz jung\u00ab \u2013 war um mich her ein Fl\u00fcstern;", "tokens": ["\u00bb", "sie", "ist", "ganz", "jung", "\u00ab", "\u2013", "war", "um", "mich", "her", "ein", "Fl\u00fcs\u00b7tern", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$(", "$(", "VAFIN", "APPR", "PRF", "APZR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auch trank sie Milch, und gierig wie ein Kind.", "tokens": ["auch", "trank", "sie", "Milch", ",", "und", "gie\u00b7rig", "wie", "ein", "Kind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "KON", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch schien sie mir fast alt, so oft die Zunge", "tokens": ["Doch", "schien", "sie", "mir", "fast", "alt", ",", "so", "oft", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "durch eine L\u00fccke ihrer tr\u00fcben Z\u00e4hne", "tokens": ["durch", "ei\u00b7ne", "L\u00fc\u00b7cke", "ih\u00b7rer", "tr\u00fc\u00b7ben", "Z\u00e4h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "spitz aus dem zischelnden Munde zuckte, w\u00e4hrend", "tokens": ["spitz", "aus", "dem", "zi\u00b7scheln\u00b7den", "Mun\u00b7de", "zuck\u00b7te", ",", "w\u00e4h\u00b7rend"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,", "KOUS"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "ihr grauer Blick den Saal belauerte;", "tokens": ["ihr", "grau\u00b7er", "Blick", "den", "Saal", "be\u00b7lau\u00b7er\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "das Gaslicht glei\u00dfte drin wie giftiges Gr\u00fcn.", "tokens": ["das", "Gas\u00b7licht", "glei\u00df\u00b7te", "drin", "wie", "gif\u00b7ti\u00b7ges", "Gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Jetzt stand sie auf. Sein Glas war unber\u00fchrt;", "tokens": ["Jetzt", "stand", "sie", "auf", ".", "Sein", "Glas", "war", "un\u00b7be\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "ein gro\u00dfes Geldst\u00fcck gl\u00e4nzte auf dem Marmor.", "tokens": ["ein", "gro\u00b7\u00dfes", "Geld\u00b7st\u00fcck", "gl\u00e4nz\u00b7te", "auf", "dem", "Mar\u00b7mor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie ging; er folgte automatisch nach.", "tokens": ["Sie", "ging", ";", "er", "folg\u00b7te", "au\u00b7to\u00b7ma\u00b7tisch", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die rote T\u00fcrgardine tat sich zu,", "tokens": ["Die", "ro\u00b7te", "T\u00fcr\u00b7gar\u00b7di\u00b7ne", "tat", "sich", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "der kalte Zug schnitt wieder durch die Hitze,", "tokens": ["der", "kal\u00b7te", "Zug", "schnitt", "wie\u00b7der", "durch", "die", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "doch fluchte Keiner; und mir schauderte.", "tokens": ["doch", "fluch\u00b7te", "Kei\u00b7ner", ";", "und", "mir", "schau\u00b7der\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Ich blieb f\u00fcr mich \u2013 ich kannte sie auf einmal:", "tokens": ["Ich", "blieb", "f\u00fcr", "mich", "\u2013", "ich", "kann\u00b7te", "sie", "auf", "ein\u00b7mal", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$(", "PPER", "VVFIN", "PPER", "APPR", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "es war die Wollustseuche und der Tod.", "tokens": ["es", "war", "die", "Wol\u00b7lust\u00b7seu\u00b7che", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.9": {"line.1": {"text": "Weicht, ihr Schatten! \u2013 Wie sie zucken,", "tokens": ["Weicht", ",", "ihr", "Schat\u00b7ten", "!", "\u2013", "Wie", "sie", "zu\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$.", "$(", "PWAV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie die Fensterh\u00f6hlen drohn!", "tokens": ["wie", "die", "Fens\u00b7ter\u00b7h\u00f6h\u00b7len", "drohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, ihr m\u00f6gt manch Opfer schlucken;", "tokens": ["Ja", ",", "ihr", "m\u00f6gt", "manch", "Op\u00b7fer", "schlu\u00b7cken", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aber ich, ich sprech euch Hohn!", "tokens": ["a\u00b7ber", "ich", ",", "ich", "sprech", "euch", "Hohn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Laternen flackern greller,", "tokens": ["Die", "La\u00b7ter\u00b7nen", "fla\u00b7ckern", "grel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "j\u00e4h erlosch das letzte Fenster;", "tokens": ["j\u00e4h", "er\u00b7losch", "das", "letz\u00b7te", "Fens\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "jeder Stern erscheint noch heller \u2013", "tokens": ["je\u00b7der", "Stern", "er\u00b7scheint", "noch", "hel\u00b7ler", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "niemals sah ich die Nacht begl\u00e4nzter!", "tokens": ["nie\u00b7mals", "sah", "ich", "die", "Nacht", "be\u00b7gl\u00e4nz\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Ich! Denn ach \u2013: ich kannte Einen,", "tokens": ["Ich", "!", "Denn", "ach", "\u2013", ":", "ich", "kann\u00b7te", "Ei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "KON", "XY", "$(", "$.", "PPER", "VVFIN", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der sah nie zu gleicher Zeit", "tokens": ["der", "sah", "nie", "zu", "glei\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sterne, Fenster und Laternen scheinen \u2013", "tokens": ["Ster\u00b7ne", ",", "Fens\u00b7ter", "und", "La\u00b7ter\u00b7nen", "schei\u00b7nen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "dieser \u00c4rmste tut mir leid.", "tokens": ["die\u00b7ser", "\u00c4rms\u00b7te", "tut", "mir", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Beim Geschmetter einer Blechkapelle", "tokens": ["Beim", "Ge\u00b7schmet\u00b7ter", "ei\u00b7ner", "Blech\u00b7ka\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "kann er keine Nachtigall h\u00f6ren,", "tokens": ["kann", "er", "kei\u00b7ne", "Nach\u00b7ti\u00b7gall", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "ohne da\u00df sich auf der Stelle", "tokens": ["oh\u00b7ne", "da\u00df", "sich", "auf", "der", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seine zarten Ohren emp\u00f6ren.", "tokens": ["sei\u00b7ne", "zar\u00b7ten", "Oh\u00b7ren", "em\u00b7p\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Ich indessen \u2013 o Mirakel \u2013", "tokens": ["Ich", "in\u00b7des\u00b7sen", "\u2013", "o", "Mi\u00b7ra\u00b7kel", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "FM", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "h\u00f6re das Lied der Nachtigallen", "tokens": ["h\u00f6\u00b7re", "das", "Lied", "der", "Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "durch den \u00e4rgsten H\u00f6llenspektakel", "tokens": ["durch", "den", "\u00e4rgs\u00b7ten", "H\u00f6l\u00b7len\u00b7spek\u00b7ta\u00b7kel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "nur noch himmlischer erschallen.", "tokens": ["nur", "noch", "himm\u00b7li\u00b7scher", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich Barbar! ich brauch mir meine", "tokens": ["Ich", "Bar\u00b7bar", "!", "ich", "brauch", "mir", "mei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$.", "PPER", "VVFIN", "PPER", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nerven nicht zu vergesundern;", "tokens": ["Ner\u00b7ven", "nicht", "zu", "ver\u00b7ge\u00b7sun\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ich kann beim Laternenscheine", "tokens": ["ich", "kann", "beim", "La\u00b7ter\u00b7nen\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPRART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "manchen Stern erst recht bewundern.", "tokens": ["man\u00b7chen", "Stern", "erst", "recht", "be\u00b7wun\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Mir wehrt keine Kunstscheuklappe", "tokens": ["Mir", "wehrt", "kei\u00b7ne", "Kunst\u00b7scheu\u00b7klap\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "meinen freien Blick durchs Fenster,", "tokens": ["mei\u00b7nen", "frei\u00b7en", "Blick", "durchs", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "weder Holz noch Blech noch Pappe \u2013", "tokens": ["we\u00b7der", "Holz", "noch", "Blech", "noch", "Pap\u00b7pe", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "NN", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "niemals sah ich die Nacht begl\u00e4nzter!", "tokens": ["nie\u00b7mals", "sah", "ich", "die", "Nacht", "be\u00b7gl\u00e4nz\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Denn ich wei\u00df, wie Du mich Einsamen", "tokens": ["Denn", "ich", "wei\u00df", ",", "wie", "Du", "mich", "Ein\u00b7sa\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWAV", "PPER", "PRF", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "einst zum edelsten Trotz ansch\u00fcrtest,", "tokens": ["einst", "zum", "e\u00b7dels\u00b7ten", "Trotz", "an\u00b7sch\u00fcr\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "als ich dich, du Allgemeinsame,", "tokens": ["als", "ich", "dich", ",", "du", "All\u00b7ge\u00b7mein\u00b7sa\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "selbst im schmutzigsten Elend sp\u00fcrte,", "tokens": ["selbst", "im", "schmut\u00b7zigs\u00b7ten", "E\u00b7lend", "sp\u00fcr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Das war das letzte Mal. Im Nachtcaf\u00e9", "tokens": ["Das", "war", "das", "letz\u00b7te", "Mal", ".", "Im", "Nacht\u00b7ca\u00b7f\u00e9"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der Vorstadt sa\u00df ich, m\u00fcde vom Geruch", "tokens": ["der", "Vor\u00b7stadt", "sa\u00df", "ich", ",", "m\u00fc\u00b7de", "vom", "Ge\u00b7ruch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der schw\u00fclen Sofapolster und des Punsches,", "tokens": ["der", "schw\u00fc\u00b7len", "So\u00b7fa\u00b7pols\u00b7ter", "und", "des", "Pun\u00b7sches", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der vor mir gl\u00fchte, und vom Frauendunst", "tokens": ["der", "vor", "mir", "gl\u00fch\u00b7te", ",", "und", "vom", "Frau\u00b7en\u00b7dunst"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "APPR", "PPER", "VVFIN", "$,", "KON", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der feuchten Winterkleider; m\u00fcde, l\u00fcstern.", "tokens": ["der", "feuch\u00b7ten", "Win\u00b7ter\u00b7klei\u00b7der", ";", "m\u00fc\u00b7de", ",", "l\u00fcs\u00b7tern", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "ADJD", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Die Tabakswolken schwankten vom Gel\u00e4chter", "tokens": ["Die", "Ta\u00b7baks\u00b7wol\u00b7ken", "schwank\u00b7ten", "vom", "Ge\u00b7l\u00e4ch\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und feilschenden Gekreisch der bunten Dirnen", "tokens": ["und", "feil\u00b7schen\u00b7den", "Ge\u00b7kreisch", "der", "bun\u00b7ten", "Dir\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und Derer, die drum warben. Das Gerassel", "tokens": ["und", "De\u00b7rer", ",", "die", "drum", "war\u00b7ben", ".", "Das", "Ge\u00b7ras\u00b7sel"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "$,", "PRELS", "PAV", "VVINF", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "der Alfenidel\u00f6ffel am B\u00fcffet", "tokens": ["der", "Al\u00b7fe\u00b7ni\u00b7de\u00b7l\u00f6f\u00b7fel", "am", "B\u00fcf\u00b7fet"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "ermunterte den L\u00e4rm des Liebesmarktes,", "tokens": ["er\u00b7mun\u00b7ter\u00b7te", "den", "L\u00e4rm", "des", "Lie\u00b7bes\u00b7mark\u00b7tes", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "ununterbrochen, wie ein Tamburin.", "tokens": ["un\u00b7un\u00b7ter\u00b7bro\u00b7chen", ",", "wie", "ein", "Tam\u00b7bu\u00b7rin", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Ich sa\u00df, den langen Mittelgang betrachtend,", "tokens": ["Ich", "sa\u00df", ",", "den", "lan\u00b7gen", "Mit\u00b7tel\u00b7gang", "be\u00b7trach\u00b7tend", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und lauschte, wie das Licht des Gaskronleuchters,", "tokens": ["und", "lauschte", ",", "wie", "das", "Licht", "des", "Gas\u00b7kron\u00b7leuch\u00b7ters", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "der dr\u00fcber hing, sich m\u00fchsam mit den Farben", "tokens": ["der", "dr\u00fc\u00b7ber", "hing", ",", "sich", "m\u00fch\u00b7sam", "mit", "den", "Far\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PAV", "VVFIN", "$,", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "auf den Gesichtern um die Marmortische", "tokens": ["auf", "den", "Ge\u00b7sich\u00b7tern", "um", "die", "Mar\u00b7mor\u00b7ti\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.5": {"text": "in seiner gelben Sprache unterhielt;", "tokens": ["in", "sei\u00b7ner", "gel\u00b7ben", "Spra\u00b7che", "un\u00b7ter\u00b7hielt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wozu der schwarze Marmor blank auflachte.", "tokens": ["wo\u00b7zu", "der", "schwar\u00b7ze", "Mar\u00b7mor", "blank", "auf\u00b7lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Ich war schon bei der Wahl \u2013 da teilte sich", "tokens": ["Ich", "war", "schon", "bei", "der", "Wahl", "\u2013", "da", "teil\u00b7te", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$(", "ADV", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die rote T\u00fcrgardine neben mir:", "tokens": ["die", "ro\u00b7te", "T\u00fcr\u00b7gar\u00b7di\u00b7ne", "ne\u00b7ben", "mir", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein neues Paar trat ein. Ein kalter Zug", "tokens": ["ein", "neu\u00b7es", "Paar", "trat", "ein", ".", "Ein", "kal\u00b7ter", "Zug"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "schnitt durch den hei\u00dfen Raum, und Einer fluchte;", "tokens": ["schnitt", "durch", "den", "hei\u00b7\u00dfen", "Raum", ",", "und", "Ei\u00b7ner", "fluch\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$,", "KON", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "die Beiden schritten ruhig durch den Schwarm.", "tokens": ["die", "Bei\u00b7den", "schrit\u00b7ten", "ru\u00b7hig", "durch", "den", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mir grade gegen\u00fcber, quer am Ende", "tokens": ["Mir", "gra\u00b7de", "ge\u00b7gen\u00b7\u00fc\u00b7ber", ",", "quer", "am", "En\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKVZ", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "des Ganges, als beherrschten sie den Saal,", "tokens": ["des", "Gan\u00b7ges", ",", "als", "be\u00b7herrschten", "sie", "den", "Saal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "nahmen sie Platz. Der bronzene Kronleuchter", "tokens": ["nah\u00b7men", "sie", "Platz", ".", "Der", "bron\u00b7ze\u00b7ne", "Kron\u00b7leuch\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "NN", "$.", "ART", "ADJA", "NN"], "meter": "+--+-+---+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "hing \u00fcber ihnen wie ein schwerer alter", "tokens": ["hing", "\u00fc\u00b7ber", "ih\u00b7nen", "wie", "ein", "schwe\u00b7rer", "al\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPER", "KOKOM", "ART", "ADJA", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Thronhimmel. Keiner schien das Paar zu kennen.", "tokens": ["Thron\u00b7him\u00b7mel", ".", "Kei\u00b7ner", "schien", "das", "Paar", "zu", "ken\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PIS", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Doch h\u00f6rt'ich rechts von mir ein heisres Stimmchen:", "tokens": ["Doch", "h\u00f6rt'\u00b7ich", "rechts", "von", "mir", "ein", "heis\u00b7res", "Stimm\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbbejejent mu\u00df ik die woll schon wo sein.\u00ab", "tokens": ["\u00bb", "be\u00b7je\u00b7jent", "mu\u00df", "ik", "die", "woll", "schon", "wo", "sein", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVPP", "VMFIN", "NE", "ART", "ADV", "ADV", "PWAV", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Er sa\u00df ganz still. Das laute Grau der Luft", "tokens": ["Er", "sa\u00df", "ganz", "still", ".", "Das", "lau\u00b7te", "Grau", "der", "Luft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "$.", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "schrak fast zur\u00fcck vor seiner krassen Stirne,", "tokens": ["schrak", "fast", "zu\u00b7r\u00fcck", "vor", "sei\u00b7ner", "kras\u00b7sen", "Stir\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die wachsbleich an die schwachen Haare stie\u00df.", "tokens": ["die", "wachs\u00b7bleich", "an", "die", "schwa\u00b7chen", "Haa\u00b7re", "stie\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Die gro\u00dfen blassen Augenlider waren", "tokens": ["Die", "gro\u00b7\u00dfen", "blas\u00b7sen", "Au\u00b7gen\u00b7li\u00b7der", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "tief zugeklappt, auf beiden Seiten lag", "tokens": ["tief", "zu\u00b7ge\u00b7klappt", ",", "auf", "bei\u00b7den", "Sei\u00b7ten", "lag"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "APPR", "PIAT", "NN", "VVFIN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "ihr Schatten um die eingeknickte Nase;", "tokens": ["ihr", "Schat\u00b7ten", "um", "die", "ein\u00b7ge\u00b7knick\u00b7te", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "der d\u00fcrre Vollbart lie\u00df die Haut durchscheinen.", "tokens": ["der", "d\u00fcr\u00b7re", "Voll\u00b7bart", "lie\u00df", "die", "Haut", "durch\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Nur wenn die \u00fcppig kleinere Gef\u00e4hrtin", "tokens": ["Nur", "wenn", "die", "\u00fcp\u00b7pig", "klei\u00b7ne\u00b7re", "Ge\u00b7f\u00e4hr\u00b7tin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "ihm kichernd einen Satz zuzischelte,", "tokens": ["ihm", "ki\u00b7chernd", "ei\u00b7nen", "Satz", "zu\u00b7zi\u00b7schel\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "sah man sein eines schwarzes Auge halb", "tokens": ["sah", "man", "sein", "ei\u00b7nes", "schwar\u00b7zes", "Au\u00b7ge", "halb"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPOSAT", "ART", "ADJA", "NN", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "und drehte sich sein langer d\u00fcnner Hals,", "tokens": ["und", "dreh\u00b7te", "sich", "sein", "lan\u00b7ger", "d\u00fcn\u00b7ner", "Hals", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "langsam, und kroch der nackte Kehlkopf hoch,", "tokens": ["lang\u00b7sam", ",", "und", "kroch", "der", "nack\u00b7te", "Kehl\u00b7kopf", "hoch", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.13": {"text": "wie wenn ein Geier nach dem Aase ruckt.", "tokens": ["wie", "wenn", "ein", "Gei\u00b7er", "nach", "dem", "Aa\u00b7se", "ruckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Es wurde immer stiller durch den Raum;", "tokens": ["Es", "wur\u00b7de", "im\u00b7mer", "stil\u00b7ler", "durch", "den", "Raum", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "sie blickten Alle auf den stummen Mann", "tokens": ["sie", "blick\u00b7ten", "Al\u00b7le", "auf", "den", "stum\u00b7men", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und auf das sonderbar geduckte Weib.", "tokens": ["und", "auf", "das", "son\u00b7der\u00b7bar", "ge\u00b7duck\u00b7te", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbsie ist ganz jung\u00ab \u2013 war um mich her ein Fl\u00fcstern;", "tokens": ["\u00bb", "sie", "ist", "ganz", "jung", "\u00ab", "\u2013", "war", "um", "mich", "her", "ein", "Fl\u00fcs\u00b7tern", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADJD", "$(", "$(", "VAFIN", "APPR", "PRF", "APZR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auch trank sie Milch, und gierig wie ein Kind.", "tokens": ["auch", "trank", "sie", "Milch", ",", "und", "gie\u00b7rig", "wie", "ein", "Kind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,", "KON", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Doch schien sie mir fast alt, so oft die Zunge", "tokens": ["Doch", "schien", "sie", "mir", "fast", "alt", ",", "so", "oft", "die", "Zun\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "ADV", "ADJD", "$,", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "durch eine L\u00fccke ihrer tr\u00fcben Z\u00e4hne", "tokens": ["durch", "ei\u00b7ne", "L\u00fc\u00b7cke", "ih\u00b7rer", "tr\u00fc\u00b7ben", "Z\u00e4h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "spitz aus dem zischelnden Munde zuckte, w\u00e4hrend", "tokens": ["spitz", "aus", "dem", "zi\u00b7scheln\u00b7den", "Mun\u00b7de", "zuck\u00b7te", ",", "w\u00e4h\u00b7rend"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADJD", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,", "KOUS"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.9": {"text": "ihr grauer Blick den Saal belauerte;", "tokens": ["ihr", "grau\u00b7er", "Blick", "den", "Saal", "be\u00b7lau\u00b7er\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "das Gaslicht glei\u00dfte drin wie giftiges Gr\u00fcn.", "tokens": ["das", "Gas\u00b7licht", "glei\u00df\u00b7te", "drin", "wie", "gif\u00b7ti\u00b7ges", "Gr\u00fcn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.11": {"text": "Jetzt stand sie auf. Sein Glas war unber\u00fchrt;", "tokens": ["Jetzt", "stand", "sie", "auf", ".", "Sein", "Glas", "war", "un\u00b7be\u00b7r\u00fchrt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "ein gro\u00dfes Geldst\u00fcck gl\u00e4nzte auf dem Marmor.", "tokens": ["ein", "gro\u00b7\u00dfes", "Geld\u00b7st\u00fcck", "gl\u00e4nz\u00b7te", "auf", "dem", "Mar\u00b7mor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie ging; er folgte automatisch nach.", "tokens": ["Sie", "ging", ";", "er", "folg\u00b7te", "au\u00b7to\u00b7ma\u00b7tisch", "nach", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Die rote T\u00fcrgardine tat sich zu,", "tokens": ["Die", "ro\u00b7te", "T\u00fcr\u00b7gar\u00b7di\u00b7ne", "tat", "sich", "zu", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "der kalte Zug schnitt wieder durch die Hitze,", "tokens": ["der", "kal\u00b7te", "Zug", "schnitt", "wie\u00b7der", "durch", "die", "Hit\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "doch fluchte Keiner; und mir schauderte.", "tokens": ["doch", "fluch\u00b7te", "Kei\u00b7ner", ";", "und", "mir", "schau\u00b7der\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$.", "KON", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Ich blieb f\u00fcr mich \u2013 ich kannte sie auf einmal:", "tokens": ["Ich", "blieb", "f\u00fcr", "mich", "\u2013", "ich", "kann\u00b7te", "sie", "auf", "ein\u00b7mal", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$(", "PPER", "VVFIN", "PPER", "APPR", "ADV", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "es war die Wollustseuche und der Tod.", "tokens": ["es", "war", "die", "Wol\u00b7lust\u00b7seu\u00b7che", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.25": {"line.1": {"text": "Weicht, ihr Schatten! \u2013 Wie sie zucken,", "tokens": ["Weicht", ",", "ihr", "Schat\u00b7ten", "!", "\u2013", "Wie", "sie", "zu\u00b7cken", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$.", "$(", "PWAV", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "wie die Fensterh\u00f6hlen drohn!", "tokens": ["wie", "die", "Fens\u00b7ter\u00b7h\u00f6h\u00b7len", "drohn", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, ihr m\u00f6gt manch Opfer schlucken;", "tokens": ["Ja", ",", "ihr", "m\u00f6gt", "manch", "Op\u00b7fer", "schlu\u00b7cken", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "aber ich, ich sprech euch Hohn!", "tokens": ["a\u00b7ber", "ich", ",", "ich", "sprech", "euch", "Hohn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "PPER", "VVFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.26": {"line.1": {"text": "Die Laternen flackern greller,", "tokens": ["Die", "La\u00b7ter\u00b7nen", "fla\u00b7ckern", "grel\u00b7ler", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "j\u00e4h erlosch das letzte Fenster;", "tokens": ["j\u00e4h", "er\u00b7losch", "das", "letz\u00b7te", "Fens\u00b7ter", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "jeder Stern erscheint noch heller \u2013", "tokens": ["je\u00b7der", "Stern", "er\u00b7scheint", "noch", "hel\u00b7ler", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "niemals sah ich die Nacht begl\u00e4nzter!", "tokens": ["nie\u00b7mals", "sah", "ich", "die", "Nacht", "be\u00b7gl\u00e4nz\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.27": {"line.1": {"text": "Ich! Denn ach \u2013: ich kannte Einen,", "tokens": ["Ich", "!", "Denn", "ach", "\u2013", ":", "ich", "kann\u00b7te", "Ei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$.", "KON", "XY", "$(", "$.", "PPER", "VVFIN", "ART", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der sah nie zu gleicher Zeit", "tokens": ["der", "sah", "nie", "zu", "glei\u00b7cher", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sterne, Fenster und Laternen scheinen \u2013", "tokens": ["Ster\u00b7ne", ",", "Fens\u00b7ter", "und", "La\u00b7ter\u00b7nen", "schei\u00b7nen", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "dieser \u00c4rmste tut mir leid.", "tokens": ["die\u00b7ser", "\u00c4rms\u00b7te", "tut", "mir", "leid", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.28": {"line.1": {"text": "Beim Geschmetter einer Blechkapelle", "tokens": ["Beim", "Ge\u00b7schmet\u00b7ter", "ei\u00b7ner", "Blech\u00b7ka\u00b7pel\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "kann er keine Nachtigall h\u00f6ren,", "tokens": ["kann", "er", "kei\u00b7ne", "Nach\u00b7ti\u00b7gall", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "ohne da\u00df sich auf der Stelle", "tokens": ["oh\u00b7ne", "da\u00df", "sich", "auf", "der", "Stel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "KOUS", "PRF", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "seine zarten Ohren emp\u00f6ren.", "tokens": ["sei\u00b7ne", "zar\u00b7ten", "Oh\u00b7ren", "em\u00b7p\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.29": {"line.1": {"text": "Ich indessen \u2013 o Mirakel \u2013", "tokens": ["Ich", "in\u00b7des\u00b7sen", "\u2013", "o", "Mi\u00b7ra\u00b7kel", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "ADV", "$(", "FM", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "h\u00f6re das Lied der Nachtigallen", "tokens": ["h\u00f6\u00b7re", "das", "Lied", "der", "Nach\u00b7ti\u00b7gal\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "durch den \u00e4rgsten H\u00f6llenspektakel", "tokens": ["durch", "den", "\u00e4rgs\u00b7ten", "H\u00f6l\u00b7len\u00b7spek\u00b7ta\u00b7kel"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "nur noch himmlischer erschallen.", "tokens": ["nur", "noch", "himm\u00b7li\u00b7scher", "er\u00b7schal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Ich Barbar! ich brauch mir meine", "tokens": ["Ich", "Bar\u00b7bar", "!", "ich", "brauch", "mir", "mei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NN", "$.", "PPER", "VVFIN", "PPER", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Nerven nicht zu vergesundern;", "tokens": ["Ner\u00b7ven", "nicht", "zu", "ver\u00b7ge\u00b7sun\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ich kann beim Laternenscheine", "tokens": ["ich", "kann", "beim", "La\u00b7ter\u00b7nen\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPRART", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "manchen Stern erst recht bewundern.", "tokens": ["man\u00b7chen", "Stern", "erst", "recht", "be\u00b7wun\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "Mir wehrt keine Kunstscheuklappe", "tokens": ["Mir", "wehrt", "kei\u00b7ne", "Kunst\u00b7scheu\u00b7klap\u00b7pe"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "meinen freien Blick durchs Fenster,", "tokens": ["mei\u00b7nen", "frei\u00b7en", "Blick", "durchs", "Fens\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "weder Holz noch Blech noch Pappe \u2013", "tokens": ["we\u00b7der", "Holz", "noch", "Blech", "noch", "Pap\u00b7pe", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "NN", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "niemals sah ich die Nacht begl\u00e4nzter!", "tokens": ["nie\u00b7mals", "sah", "ich", "die", "Nacht", "be\u00b7gl\u00e4nz\u00b7ter", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Denn ich wei\u00df, wie Du mich Einsamen", "tokens": ["Denn", "ich", "wei\u00df", ",", "wie", "Du", "mich", "Ein\u00b7sa\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWAV", "PPER", "PRF", "NN"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "einst zum edelsten Trotz ansch\u00fcrtest,", "tokens": ["einst", "zum", "e\u00b7dels\u00b7ten", "Trotz", "an\u00b7sch\u00fcr\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "als ich dich, du Allgemeinsame,", "tokens": ["als", "ich", "dich", ",", "du", "All\u00b7ge\u00b7mein\u00b7sa\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PPER", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "selbst im schmutzigsten Elend sp\u00fcrte,", "tokens": ["selbst", "im", "schmut\u00b7zigs\u00b7ten", "E\u00b7lend", "sp\u00fcr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}}}}