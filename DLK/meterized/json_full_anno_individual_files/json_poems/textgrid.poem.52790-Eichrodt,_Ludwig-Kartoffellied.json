{"textgrid.poem.52790": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Kartoffellied", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herbei, herbei zu meinem Sang!", "tokens": ["Her\u00b7bei", ",", "her\u00b7bei", "zu", "mei\u00b7nem", "Sang", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hans, J\u00f6rgel, Michel, Stoffel!", "tokens": ["Hans", ",", "J\u00f6r\u00b7gel", ",", "Mi\u00b7chel", ",", "Stof\u00b7fel", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und singt mit mir das Ehrenlied", "tokens": ["Und", "singt", "mit", "mir", "das", "Eh\u00b7ren\u00b7lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Stifter der Kartoffel.", "tokens": ["Dem", "Stif\u00b7ter", "der", "Kar\u00b7tof\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}}, "stanza.2": {"line.1": {"text": "Franz Drake hie\u00df der brave Mann,", "tokens": ["Franz", "Dra\u00b7ke", "hie\u00df", "der", "bra\u00b7ve", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der vor zweihundert Jahren", "tokens": ["Der", "vor", "zwei\u00b7hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von England nach Amerika", "tokens": ["Von", "En\u00b7gland", "nach", "A\u00b7me\u00b7ri\u00b7ka"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Kapit\u00e4n gefahren.", "tokens": ["Als", "Ka\u00b7pi\u00b7t\u00e4n", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Europa sollte diesem Mann", "tokens": ["Eu\u00b7ro\u00b7pa", "soll\u00b7te", "die\u00b7sem", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf allen seinen Auen,", "tokens": ["Auf", "al\u00b7len", "sei\u00b7nen", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo es nur je Kartoffeln pflanzt,", "tokens": ["Wo", "es", "nur", "je", "Kar\u00b7tof\u00b7feln", "pflanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein goldnes Denkmal bauen.", "tokens": ["Ein", "gold\u00b7nes", "Denk\u00b7mal", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Salat davon, gut angemacht,", "tokens": ["Sa\u00b7lat", "da\u00b7von", ",", "gut", "an\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PAV", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Feldsalat durchschossen,", "tokens": ["Mit", "Feld\u00b7sa\u00b7lat", "durch\u00b7schos\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der wird mit gro\u00dfem Appetit", "tokens": ["Der", "wird", "mit", "gro\u00b7\u00dfem", "Ap\u00b7pe\u00b7tit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Jedermann genossen.", "tokens": ["Von", "Je\u00b7der\u00b7mann", "ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Gebr\u00e4telt schmecken sie auch gut,", "tokens": ["Ge\u00b7br\u00e4\u00b7telt", "schme\u00b7cken", "sie", "auch", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In saurer Br\u00fch' nicht minder,", "tokens": ["In", "sau\u00b7rer", "Br\u00fch'", "nicht", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Erdbirnenkn\u00f6pfe essen gern", "tokens": ["Erd\u00b7bir\u00b7nen\u00b7kn\u00f6p\u00b7fe", "es\u00b7sen", "gern"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADV"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Eltern und die Kinder.", "tokens": ["Die", "El\u00b7tern", "und", "die", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Hat Jemand sich die Haut verbrannt", "tokens": ["Hat", "Je\u00b7mand", "sich", "die", "Haut", "ver\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PRF", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hilft kein Feuersegen,", "tokens": ["Und", "hilft", "kein", "Feu\u00b7er\u00b7se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So darf er auf die Wunde nur", "tokens": ["So", "darf", "er", "auf", "die", "Wun\u00b7de", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kartoffelschabsig legen.", "tokens": ["Kar\u00b7tof\u00b7fel\u00b7schab\u00b7sig", "le\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und welche Wohlthat sind sie uns", "tokens": ["Und", "wel\u00b7che", "Wohlt\u00b7hat", "sind", "sie", "uns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Vieh damit zu m\u00e4sten!", "tokens": ["Das", "Vieh", "da\u00b7mit", "zu", "m\u00e4s\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wie viel Sorten gibt's! Jedoch", "tokens": ["Und", "wie", "viel", "Sor\u00b7ten", "gibt's", "!", "Je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAV", "PIAT", "NN", "VVFIN", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die gutsten sind die besten.", "tokens": ["Die", "guts\u00b7ten", "sind", "die", "bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ein allgemeines Lob verdient", "tokens": ["Ein", "all\u00b7ge\u00b7mei\u00b7nes", "Lob", "ver\u00b7dient"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der w\u00fcrdige Franz Drake", "tokens": ["Der", "w\u00fcr\u00b7di\u00b7ge", "Franz", "Dra\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vom F\u00fcrsten bis zum Bauersmann", "tokens": ["Vom", "F\u00fcrs\u00b7ten", "bis", "zum", "Bau\u00b7ers\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob seinem Wohlgeschmacke.", "tokens": ["Ob", "sei\u00b7nem", "Wohl\u00b7ge\u00b7schma\u00b7cke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Herbei, herbei zu meinem Sang!", "tokens": ["Her\u00b7bei", ",", "her\u00b7bei", "zu", "mei\u00b7nem", "Sang", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hans, J\u00f6rgel, Michel, Stoffel!", "tokens": ["Hans", ",", "J\u00f6r\u00b7gel", ",", "Mi\u00b7chel", ",", "Stof\u00b7fel", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und singt mit mir das Ehrenlied", "tokens": ["Und", "singt", "mit", "mir", "das", "Eh\u00b7ren\u00b7lied"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Stifter der Kartoffel.", "tokens": ["Dem", "Stif\u00b7ter", "der", "Kar\u00b7tof\u00b7fel", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}}, "stanza.10": {"line.1": {"text": "Franz Drake hie\u00df der brave Mann,", "tokens": ["Franz", "Dra\u00b7ke", "hie\u00df", "der", "bra\u00b7ve", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der vor zweihundert Jahren", "tokens": ["Der", "vor", "zwei\u00b7hun\u00b7dert", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von England nach Amerika", "tokens": ["Von", "En\u00b7gland", "nach", "A\u00b7me\u00b7ri\u00b7ka"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Kapit\u00e4n gefahren.", "tokens": ["Als", "Ka\u00b7pi\u00b7t\u00e4n", "ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Europa sollte diesem Mann", "tokens": ["Eu\u00b7ro\u00b7pa", "soll\u00b7te", "die\u00b7sem", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf allen seinen Auen,", "tokens": ["Auf", "al\u00b7len", "sei\u00b7nen", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wo es nur je Kartoffeln pflanzt,", "tokens": ["Wo", "es", "nur", "je", "Kar\u00b7tof\u00b7feln", "pflanzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein goldnes Denkmal bauen.", "tokens": ["Ein", "gold\u00b7nes", "Denk\u00b7mal", "bau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Salat davon, gut angemacht,", "tokens": ["Sa\u00b7lat", "da\u00b7von", ",", "gut", "an\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "PAV", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit Feldsalat durchschossen,", "tokens": ["Mit", "Feld\u00b7sa\u00b7lat", "durch\u00b7schos\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der wird mit gro\u00dfem Appetit", "tokens": ["Der", "wird", "mit", "gro\u00b7\u00dfem", "Ap\u00b7pe\u00b7tit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Jedermann genossen.", "tokens": ["Von", "Je\u00b7der\u00b7mann", "ge\u00b7nos\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Gebr\u00e4telt schmecken sie auch gut,", "tokens": ["Ge\u00b7br\u00e4\u00b7telt", "schme\u00b7cken", "sie", "auch", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In saurer Br\u00fch' nicht minder,", "tokens": ["In", "sau\u00b7rer", "Br\u00fch'", "nicht", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Erdbirnenkn\u00f6pfe essen gern", "tokens": ["Erd\u00b7bir\u00b7nen\u00b7kn\u00f6p\u00b7fe", "es\u00b7sen", "gern"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ADV"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Eltern und die Kinder.", "tokens": ["Die", "El\u00b7tern", "und", "die", "Kin\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Hat Jemand sich die Haut verbrannt", "tokens": ["Hat", "Je\u00b7mand", "sich", "die", "Haut", "ver\u00b7brannt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PRF", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hilft kein Feuersegen,", "tokens": ["Und", "hilft", "kein", "Feu\u00b7er\u00b7se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So darf er auf die Wunde nur", "tokens": ["So", "darf", "er", "auf", "die", "Wun\u00b7de", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Kartoffelschabsig legen.", "tokens": ["Kar\u00b7tof\u00b7fel\u00b7schab\u00b7sig", "le\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Und welche Wohlthat sind sie uns", "tokens": ["Und", "wel\u00b7che", "Wohlt\u00b7hat", "sind", "sie", "uns"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAT", "NN", "VAFIN", "PPER", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Vieh damit zu m\u00e4sten!", "tokens": ["Das", "Vieh", "da\u00b7mit", "zu", "m\u00e4s\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und wie viel Sorten gibt's! Jedoch", "tokens": ["Und", "wie", "viel", "Sor\u00b7ten", "gibt's", "!", "Je\u00b7doch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PWAV", "PIAT", "NN", "VVFIN", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die gutsten sind die besten.", "tokens": ["Die", "guts\u00b7ten", "sind", "die", "bes\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "ART", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Ein allgemeines Lob verdient", "tokens": ["Ein", "all\u00b7ge\u00b7mei\u00b7nes", "Lob", "ver\u00b7dient"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der w\u00fcrdige Franz Drake", "tokens": ["Der", "w\u00fcr\u00b7di\u00b7ge", "Franz", "Dra\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vom F\u00fcrsten bis zum Bauersmann", "tokens": ["Vom", "F\u00fcrs\u00b7ten", "bis", "zum", "Bau\u00b7ers\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob seinem Wohlgeschmacke.", "tokens": ["Ob", "sei\u00b7nem", "Wohl\u00b7ge\u00b7schma\u00b7cke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}