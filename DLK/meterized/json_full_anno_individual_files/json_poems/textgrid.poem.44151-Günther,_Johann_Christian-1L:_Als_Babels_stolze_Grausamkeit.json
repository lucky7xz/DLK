{"textgrid.poem.44151": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Als Babels stolze Grausamkeit", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Als Babels stolze Grausamkeit", "tokens": ["Als", "Ba\u00b7bels", "stol\u00b7ze", "Grau\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die L\u00e4nder gegen Morgen dr\u00fcckte", "tokens": ["Die", "L\u00e4n\u00b7der", "ge\u00b7gen", "Mor\u00b7gen", "dr\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Salems b\u00f6se Sicherheit", "tokens": ["Und", "Sa\u00b7lems", "b\u00f6\u00b7se", "Si\u00b7cher\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Tempel ins Gef\u00e4ngn\u00fc\u00df r\u00fcckte,", "tokens": ["Vom", "Tem\u00b7pel", "ins", "Ge\u00b7f\u00e4ng\u00b7n\u00fc\u00df", "r\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was schlug nicht da vor Weh und Ach,", "tokens": ["Was", "schlug", "nicht", "da", "vor", "Weh", "und", "Ach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Unruh, Angst und Ungemach", "tokens": ["Vor", "Un\u00b7ruh", ",", "Angst", "und", "Un\u00b7ge\u00b7mach"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Herzen der gestraften S\u00fcnder!", "tokens": ["Die", "Her\u00b7zen", "der", "ge\u00b7straf\u00b7ten", "S\u00fcn\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was f\u00fchlten doch nicht dazumahl", "tokens": ["Was", "f\u00fchl\u00b7ten", "doch", "nicht", "da\u00b7zu\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vor Jammer, Schande, Groll und Qual", "tokens": ["Vor", "Jam\u00b7mer", ",", "Schan\u00b7de", ",", "Groll", "und", "Qual"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die sonst verstockten Jacobskinder!", "tokens": ["Die", "sonst", "ver\u00b7stock\u00b7ten", "Ja\u00b7cobs\u00b7kin\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Der Schmuck von Zion war ein Raub", "tokens": ["Der", "Schmuck", "von", "Zi\u00b7on", "war", "ein", "Raub"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und diente blos zum Spott der Heiden,", "tokens": ["Und", "dien\u00b7te", "blos", "zum", "Spott", "der", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Altar lag voll Eis' und Staub,", "tokens": ["Der", "Al\u00b7tar", "lag", "voll", "Eis'", "und", "Staub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Harfen schwiegen an den Weiden.", "tokens": ["Die", "Har\u00b7fen", "schwie\u00b7gen", "an", "den", "Wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Solch Elend stieg fast sechzig Jahr,", "tokens": ["Solch", "E\u00b7lend", "stieg", "fast", "sech\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis Cyrus Jacobs Beystand war", "tokens": ["Bis", "Cy\u00b7rus", "Ja\u00b7cobs", "Beys\u00b7tand", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Juda schon in Hofnung lachte,", "tokens": ["Und", "Ju\u00b7da", "schon", "in", "Hof\u00b7nung", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sobald Erl\u00f6sung, H\u00fclf und Rath", "tokens": ["So\u00b7bald", "Er\u00b7l\u00f6\u00b7sung", ",", "H\u00fclf", "und", "Rath"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit Friedensbothen n\u00e4her trat", "tokens": ["Mit", "Frie\u00b7dens\u00b7bo\u00b7then", "n\u00e4\u00b7her", "trat"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und Klag und Weh zum Jauchzen machte.", "tokens": ["Und", "Klag", "und", "Weh", "zum", "Jauch\u00b7zen", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer diese Lust begreifen kan,", "tokens": ["Wer", "die\u00b7se", "Lust", "be\u00b7grei\u00b7fen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Abrahams Geschlecht empfunden,", "tokens": ["Die", "Ab\u00b7ra\u00b7hams", "Ge\u00b7schlecht", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der komm und seh die Thr\u00e4nen an,", "tokens": ["Der", "komm", "und", "seh", "die", "Thr\u00e4\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ich fast t\u00e4glich ausgewunden.", "tokens": ["Die", "ich", "fast", "t\u00e4g\u00b7lich", "aus\u00b7ge\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie flo\u00dfen vor aus Angst und Leid,", "tokens": ["Sie", "flo\u00b7\u00dfen", "vor", "aus", "Angst", "und", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie flie\u00dfen jezt vor Z\u00e4rtligkeit", "tokens": ["Sie", "flie\u00b7\u00dfen", "jezt", "vor", "Z\u00e4rt\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der endlich aufgeweckten Sinnen,", "tokens": ["Der", "end\u00b7lich", "auf\u00b7ge\u00b7weck\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die nach der L\u00e4nge starcker Noth", "tokens": ["Die", "nach", "der", "L\u00e4n\u00b7ge", "star\u00b7cker", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vor den so oft gew\u00fcntschten Tod", "tokens": ["Vor", "den", "so", "oft", "ge\u00b7w\u00fcnt\u00b7schten", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Himmel auf der Welt gewinnen.", "tokens": ["Den", "Him\u00b7mel", "auf", "der", "Welt", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die Kirche glaubt kein Wunder mehr,", "tokens": ["Die", "Kir\u00b7che", "glaubt", "kein", "Wun\u00b7der", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mu\u00df es doch gezwungen glauben;", "tokens": ["Ich", "mu\u00df", "es", "doch", "ge\u00b7zwun\u00b7gen", "glau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Schickung schlug mich allzu sehr,", "tokens": ["Die", "Schi\u00b7ckung", "schlug", "mich", "all\u00b7zu", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie lies mir alle Zuflucht rauben;", "tokens": ["Sie", "lies", "mir", "al\u00b7le", "Zu\u00b7flucht", "rau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So weit ich lief, so weit ich sah,", "tokens": ["So", "weit", "ich", "lief", ",", "so", "weit", "ich", "sah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War stets ein gr\u00f6\u00dfer Schr\u00f6cken da,", "tokens": ["War", "stets", "ein", "gr\u00f6\u00b7\u00dfer", "Schr\u00f6\u00b7cken", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und alles gieng mir zum Verderben.", "tokens": ["Und", "al\u00b7les", "gieng", "mir", "zum", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was auch dem \u00c4rmsten \u00fcbrig bleibt", "tokens": ["Was", "auch", "dem", "\u00c4rms\u00b7ten", "\u00fcb\u00b7rig", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Sclaven noch den Gram vertreibt,", "tokens": ["Und", "Scla\u00b7ven", "noch", "den", "Gram", "ver\u00b7treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Hofnung mein ich, rieth zum Sterben.", "tokens": ["Die", "Hof\u00b7nung", "mein", "ich", ",", "rieth", "zum", "Ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "PPER", "$,", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich fand mich auch gela\u00dfen drein", "tokens": ["Ich", "fand", "mich", "auch", "ge\u00b7la\u00b7\u00dfen", "drein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und lies schon Wuntsch und Sehnsucht fahren", "tokens": ["Und", "lies", "schon", "Wunt\u00b7sch", "und", "Sehn\u00b7sucht", "fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "NN", "KON", "NN", "VVINF"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und schrieb auf meinen Leichenstein:", "tokens": ["Und", "schrieb", "auf", "mei\u00b7nen", "Lei\u00b7chen\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier fiel das Alter vor den Jahren.", "tokens": ["Hier", "fiel", "das", "Al\u00b7ter", "vor", "den", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Leser, nimm dies R\u00e4thsel mit", "tokens": ["Mein", "Le\u00b7ser", ",", "nimm", "dies", "R\u00e4th\u00b7sel", "mit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVIMP", "PDS", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wi\u00dfe, was dein Fu\u00df hier tritt,", "tokens": ["Und", "wi\u00b7\u00dfe", ",", "was", "dein", "Fu\u00df", "hier", "tritt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das war vordem ein Herz voll Liebe,", "tokens": ["Das", "war", "vor\u00b7dem", "ein", "Herz", "voll", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das die Natur hervorgebracht,", "tokens": ["Das", "die", "Na\u00b7tur", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Damit der Zorn von ihrer Macht", "tokens": ["Da\u00b7mit", "der", "Zorn", "von", "ih\u00b7rer", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Zeugn\u00fc\u00df seiner St\u00e4rcke schriebe.", "tokens": ["Ein", "Zeug\u00b7n\u00fc\u00df", "sei\u00b7ner", "St\u00e4r\u00b7cke", "schrie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Dein Blat erspart mir diese Schrift,", "tokens": ["Dein", "Blat", "er\u00b7spart", "mir", "die\u00b7se", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Blat, du Engel meiner Plagen,", "tokens": ["Dein", "Blat", ",", "du", "En\u00b7gel", "mei\u00b7ner", "Pla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das gleich die rechte Stunde trift,", "tokens": ["Das", "gleich", "die", "rech\u00b7te", "Stun\u00b7de", "trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du magst dir selbst das andre sagen.", "tokens": ["Du", "magst", "dir", "selbst", "das", "and\u00b7re", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich bin vor Freuden au\u00dfer mir,", "tokens": ["Ich", "bin", "vor", "Freu\u00b7den", "au\u00b7\u00dfer", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und diese Freuden hab ich dir,", "tokens": ["Und", "die\u00b7se", "Freu\u00b7den", "hab", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Du weist warum, allein zu dancken.", "tokens": ["Du", "weist", "wa\u00b7rum", ",", "al\u00b7lein", "zu", "dan\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWAV", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Gl\u00fccke scheint vor mich zu gro\u00df,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "scheint", "vor", "mich", "zu", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ach, sprich doch Hand und Feder los,", "tokens": ["Ach", ",", "sprich", "doch", "Hand", "und", "Fe\u00b7der", "los", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADV", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wofern sie vor Entz\u00fcckung wancken.", "tokens": ["Wo\u00b7fern", "sie", "vor", "Ent\u00b7z\u00fc\u00b7ckung", "wan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Nun wird sich meine Musenschaar", "tokens": ["Nun", "wird", "sich", "mei\u00b7ne", "Mu\u00b7sen\u00b7schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den blinden Ha\u00df nicht irren la\u00dfen,", "tokens": ["Den", "blin\u00b7den", "Ha\u00df", "nicht", "ir\u00b7ren", "la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dein Haupt wie Berenicens Haar", "tokens": ["Dein", "Haupt", "wie", "Be\u00b7re\u00b7ni\u00b7cens", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit neuen Sternen einzufa\u00dfen.", "tokens": ["Mit", "neu\u00b7en", "Ster\u00b7nen", "ein\u00b7zu\u00b7fa\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.6": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.7": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.8": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.9": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.10": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.8": {"line.1": {"text": "Der Tag des Heils ist in der N\u00e4h,", "tokens": ["Der", "Tag", "des", "Heils", "ist", "in", "der", "N\u00e4h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein frommer Sinn, die Unschuldstaube,", "tokens": ["Dein", "from\u00b7mer", "Sinn", ",", "die", "Un\u00b7schuld\u00b7stau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt nach der S\u00fcndfluth, wie ich seh,", "tokens": ["Kommt", "nach", "der", "S\u00fcnd\u00b7fluth", ",", "wie", "ich", "seh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit einem Mund voll Friedenslaube.", "tokens": ["Mit", "ei\u00b7nem", "Mund", "voll", "Frie\u00b7dens\u00b7lau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach arm-, doch treue Poesie,", "tokens": ["Ach", "ar\u00b7m", ",", "doch", "treu\u00b7e", "Poe\u00b7sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "TRUNC", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Umfang doch der Debora Knie,", "tokens": ["Um\u00b7fang", "doch", "der", "De\u00b7bo\u00b7ra", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die deinen Feinden Troz gebothen;", "tokens": ["Die", "dei\u00b7nen", "Fein\u00b7den", "Troz", "ge\u00b7bo\u00b7then", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ach, Kind, begehr kein Widergelt,", "tokens": ["Ach", ",", "Kind", ",", "be\u00b7gehr", "kein", "Wi\u00b7der\u00b7gelt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du mehrst ihr Leben auf der Welt,", "tokens": ["Du", "mehrst", "ihr", "Le\u00b7ben", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sie erweckt dich von den Todten.", "tokens": ["Und", "sie", "er\u00b7weckt", "dich", "von", "den", "Tod\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Sie, sag ich, baut, erh\u00f6ht und sch\u00fczt", "tokens": ["Sie", ",", "sag", "ich", ",", "baut", ",", "er\u00b7h\u00f6ht", "und", "sch\u00fczt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "$,", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Denckmahl deiner Sch\u00f6nheitsgaben;", "tokens": ["Das", "Denck\u00b7mahl", "dei\u00b7ner", "Sch\u00f6n\u00b7heits\u00b7ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum glaube, was du ihr gen\u00fczt,", "tokens": ["Drum", "glau\u00b7be", ",", "was", "du", "ihr", "ge\u00b7n\u00fczt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PWS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nicht umsonst gethan zu haben.", "tokens": ["Doch", "nicht", "um\u00b7sonst", "ge\u00b7than", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Wi\u00dfen schl\u00e4gt durch dich den Neid.", "tokens": ["Mein", "Wi\u00b7\u00dfen", "schl\u00e4gt", "durch", "dich", "den", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach, eile doch, gew\u00fcntschte Zeit,", "tokens": ["Ach", ",", "ei\u00b7le", "doch", ",", "ge\u00b7w\u00fcnt\u00b7schte", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und bring mich [Leonoren] wieder!", "tokens": ["Und", "bring", "mich", "Le\u00b7o\u00b7no\u00b7ren", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "NE", "$(", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Sie fragt, was sie gew\u00e4rtig sey:", "tokens": ["Sie", "fragt", ",", "was", "sie", "ge\u00b7w\u00e4r\u00b7tig", "sey", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Im Leben meiner s\u00fc\u00dfen Treu,", "tokens": ["Im", "Le\u00b7ben", "mei\u00b7ner", "s\u00fc\u00b7\u00dfen", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Im Grabe meiner Ehrenlieder.", "tokens": ["Im", "Gra\u00b7be", "mei\u00b7ner", "Eh\u00b7ren\u00b7lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Als Babels stolze Grausamkeit", "tokens": ["Als", "Ba\u00b7bels", "stol\u00b7ze", "Grau\u00b7sam\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die L\u00e4nder gegen Morgen dr\u00fcckte", "tokens": ["Die", "L\u00e4n\u00b7der", "ge\u00b7gen", "Mor\u00b7gen", "dr\u00fcck\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und Salems b\u00f6se Sicherheit", "tokens": ["Und", "Sa\u00b7lems", "b\u00f6\u00b7se", "Si\u00b7cher\u00b7heit"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Tempel ins Gef\u00e4ngn\u00fc\u00df r\u00fcckte,", "tokens": ["Vom", "Tem\u00b7pel", "ins", "Ge\u00b7f\u00e4ng\u00b7n\u00fc\u00df", "r\u00fcck\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was schlug nicht da vor Weh und Ach,", "tokens": ["Was", "schlug", "nicht", "da", "vor", "Weh", "und", "Ach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor Unruh, Angst und Ungemach", "tokens": ["Vor", "Un\u00b7ruh", ",", "Angst", "und", "Un\u00b7ge\u00b7mach"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die Herzen der gestraften S\u00fcnder!", "tokens": ["Die", "Her\u00b7zen", "der", "ge\u00b7straf\u00b7ten", "S\u00fcn\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was f\u00fchlten doch nicht dazumahl", "tokens": ["Was", "f\u00fchl\u00b7ten", "doch", "nicht", "da\u00b7zu\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vor Jammer, Schande, Groll und Qual", "tokens": ["Vor", "Jam\u00b7mer", ",", "Schan\u00b7de", ",", "Groll", "und", "Qual"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "ADJD", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die sonst verstockten Jacobskinder!", "tokens": ["Die", "sonst", "ver\u00b7stock\u00b7ten", "Ja\u00b7cobs\u00b7kin\u00b7der", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Schmuck von Zion war ein Raub", "tokens": ["Der", "Schmuck", "von", "Zi\u00b7on", "war", "ein", "Raub"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und diente blos zum Spott der Heiden,", "tokens": ["Und", "dien\u00b7te", "blos", "zum", "Spott", "der", "Hei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Altar lag voll Eis' und Staub,", "tokens": ["Der", "Al\u00b7tar", "lag", "voll", "Eis'", "und", "Staub", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Harfen schwiegen an den Weiden.", "tokens": ["Die", "Har\u00b7fen", "schwie\u00b7gen", "an", "den", "Wei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Solch Elend stieg fast sechzig Jahr,", "tokens": ["Solch", "E\u00b7lend", "stieg", "fast", "sech\u00b7zig", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bis Cyrus Jacobs Beystand war", "tokens": ["Bis", "Cy\u00b7rus", "Ja\u00b7cobs", "Beys\u00b7tand", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "NE", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und Juda schon in Hofnung lachte,", "tokens": ["Und", "Ju\u00b7da", "schon", "in", "Hof\u00b7nung", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Sobald Erl\u00f6sung, H\u00fclf und Rath", "tokens": ["So\u00b7bald", "Er\u00b7l\u00f6\u00b7sung", ",", "H\u00fclf", "und", "Rath"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit Friedensbothen n\u00e4her trat", "tokens": ["Mit", "Frie\u00b7dens\u00b7bo\u00b7then", "n\u00e4\u00b7her", "trat"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und Klag und Weh zum Jauchzen machte.", "tokens": ["Und", "Klag", "und", "Weh", "zum", "Jauch\u00b7zen", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Wer diese Lust begreifen kan,", "tokens": ["Wer", "die\u00b7se", "Lust", "be\u00b7grei\u00b7fen", "kan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Abrahams Geschlecht empfunden,", "tokens": ["Die", "Ab\u00b7ra\u00b7hams", "Ge\u00b7schlecht", "emp\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der komm und seh die Thr\u00e4nen an,", "tokens": ["Der", "komm", "und", "seh", "die", "Thr\u00e4\u00b7nen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die ich fast t\u00e4glich ausgewunden.", "tokens": ["Die", "ich", "fast", "t\u00e4g\u00b7lich", "aus\u00b7ge\u00b7wun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie flo\u00dfen vor aus Angst und Leid,", "tokens": ["Sie", "flo\u00b7\u00dfen", "vor", "aus", "Angst", "und", "Leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Sie flie\u00dfen jezt vor Z\u00e4rtligkeit", "tokens": ["Sie", "flie\u00b7\u00dfen", "jezt", "vor", "Z\u00e4rt\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der endlich aufgeweckten Sinnen,", "tokens": ["Der", "end\u00b7lich", "auf\u00b7ge\u00b7weck\u00b7ten", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die nach der L\u00e4nge starcker Noth", "tokens": ["Die", "nach", "der", "L\u00e4n\u00b7ge", "star\u00b7cker", "Noth"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Vor den so oft gew\u00fcntschten Tod", "tokens": ["Vor", "den", "so", "oft", "ge\u00b7w\u00fcnt\u00b7schten", "Tod"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADV", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den Himmel auf der Welt gewinnen.", "tokens": ["Den", "Him\u00b7mel", "auf", "der", "Welt", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Die Kirche glaubt kein Wunder mehr,", "tokens": ["Die", "Kir\u00b7che", "glaubt", "kein", "Wun\u00b7der", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PIAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich mu\u00df es doch gezwungen glauben;", "tokens": ["Ich", "mu\u00df", "es", "doch", "ge\u00b7zwun\u00b7gen", "glau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVPP", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Schickung schlug mich allzu sehr,", "tokens": ["Die", "Schi\u00b7ckung", "schlug", "mich", "all\u00b7zu", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKA", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie lies mir alle Zuflucht rauben;", "tokens": ["Sie", "lies", "mir", "al\u00b7le", "Zu\u00b7flucht", "rau\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So weit ich lief, so weit ich sah,", "tokens": ["So", "weit", "ich", "lief", ",", "so", "weit", "ich", "sah", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War stets ein gr\u00f6\u00dfer Schr\u00f6cken da,", "tokens": ["War", "stets", "ein", "gr\u00f6\u00b7\u00dfer", "Schr\u00f6\u00b7cken", "da", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und alles gieng mir zum Verderben.", "tokens": ["Und", "al\u00b7les", "gieng", "mir", "zum", "Ver\u00b7der\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was auch dem \u00c4rmsten \u00fcbrig bleibt", "tokens": ["Was", "auch", "dem", "\u00c4rms\u00b7ten", "\u00fcb\u00b7rig", "bleibt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ART", "NN", "ADJD", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Sclaven noch den Gram vertreibt,", "tokens": ["Und", "Scla\u00b7ven", "noch", "den", "Gram", "ver\u00b7treibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Die Hofnung mein ich, rieth zum Sterben.", "tokens": ["Die", "Hof\u00b7nung", "mein", "ich", ",", "rieth", "zum", "Ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "PPER", "$,", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich fand mich auch gela\u00dfen drein", "tokens": ["Ich", "fand", "mich", "auch", "ge\u00b7la\u00b7\u00dfen", "drein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und lies schon Wuntsch und Sehnsucht fahren", "tokens": ["Und", "lies", "schon", "Wunt\u00b7sch", "und", "Sehn\u00b7sucht", "fah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "NN", "KON", "NN", "VVINF"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Und schrieb auf meinen Leichenstein:", "tokens": ["Und", "schrieb", "auf", "mei\u00b7nen", "Lei\u00b7chen\u00b7stein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier fiel das Alter vor den Jahren.", "tokens": ["Hier", "fiel", "das", "Al\u00b7ter", "vor", "den", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Leser, nimm dies R\u00e4thsel mit", "tokens": ["Mein", "Le\u00b7ser", ",", "nimm", "dies", "R\u00e4th\u00b7sel", "mit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "VVIMP", "PDS", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wi\u00dfe, was dein Fu\u00df hier tritt,", "tokens": ["Und", "wi\u00b7\u00dfe", ",", "was", "dein", "Fu\u00df", "hier", "tritt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das war vordem ein Herz voll Liebe,", "tokens": ["Das", "war", "vor\u00b7dem", "ein", "Herz", "voll", "Lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das die Natur hervorgebracht,", "tokens": ["Das", "die", "Na\u00b7tur", "her\u00b7vor\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Damit der Zorn von ihrer Macht", "tokens": ["Da\u00b7mit", "der", "Zorn", "von", "ih\u00b7rer", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Ein Zeugn\u00fc\u00df seiner St\u00e4rcke schriebe.", "tokens": ["Ein", "Zeug\u00b7n\u00fc\u00df", "sei\u00b7ner", "St\u00e4r\u00b7cke", "schrie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Dein Blat erspart mir diese Schrift,", "tokens": ["Dein", "Blat", "er\u00b7spart", "mir", "die\u00b7se", "Schrift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Blat, du Engel meiner Plagen,", "tokens": ["Dein", "Blat", ",", "du", "En\u00b7gel", "mei\u00b7ner", "Pla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPER", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das gleich die rechte Stunde trift,", "tokens": ["Das", "gleich", "die", "rech\u00b7te", "Stun\u00b7de", "trift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du magst dir selbst das andre sagen.", "tokens": ["Du", "magst", "dir", "selbst", "das", "and\u00b7re", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ich bin vor Freuden au\u00dfer mir,", "tokens": ["Ich", "bin", "vor", "Freu\u00b7den", "au\u00b7\u00dfer", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und diese Freuden hab ich dir,", "tokens": ["Und", "die\u00b7se", "Freu\u00b7den", "hab", "ich", "dir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Du weist warum, allein zu dancken.", "tokens": ["Du", "weist", "wa\u00b7rum", ",", "al\u00b7lein", "zu", "dan\u00b7cken", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PWAV", "$,", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Das Gl\u00fccke scheint vor mich zu gro\u00df,", "tokens": ["Das", "Gl\u00fc\u00b7cke", "scheint", "vor", "mich", "zu", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPER", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ach, sprich doch Hand und Feder los,", "tokens": ["Ach", ",", "sprich", "doch", "Hand", "und", "Fe\u00b7der", "los", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "ADV", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Wofern sie vor Entz\u00fcckung wancken.", "tokens": ["Wo\u00b7fern", "sie", "vor", "Ent\u00b7z\u00fc\u00b7ckung", "wan\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Nun wird sich meine Musenschaar", "tokens": ["Nun", "wird", "sich", "mei\u00b7ne", "Mu\u00b7sen\u00b7schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den blinden Ha\u00df nicht irren la\u00dfen,", "tokens": ["Den", "blin\u00b7den", "Ha\u00df", "nicht", "ir\u00b7ren", "la\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dein Haupt wie Berenicens Haar", "tokens": ["Dein", "Haupt", "wie", "Be\u00b7re\u00b7ni\u00b7cens", "Haar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KOKOM", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit neuen Sternen einzufa\u00dfen.", "tokens": ["Mit", "neu\u00b7en", "Ster\u00b7nen", "ein\u00b7zu\u00b7fa\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.6": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.7": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.8": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.9": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}, "line.10": {"text": ". . . . . . . . . . . . . . . . . . . . . . . . . . .", "tokens": [".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", ".", "."], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$.", "$."]}}, "stanza.17": {"line.1": {"text": "Der Tag des Heils ist in der N\u00e4h,", "tokens": ["Der", "Tag", "des", "Heils", "ist", "in", "der", "N\u00e4h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein frommer Sinn, die Unschuldstaube,", "tokens": ["Dein", "from\u00b7mer", "Sinn", ",", "die", "Un\u00b7schuld\u00b7stau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Kommt nach der S\u00fcndfluth, wie ich seh,", "tokens": ["Kommt", "nach", "der", "S\u00fcnd\u00b7fluth", ",", "wie", "ich", "seh", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mit einem Mund voll Friedenslaube.", "tokens": ["Mit", "ei\u00b7nem", "Mund", "voll", "Frie\u00b7dens\u00b7lau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ach arm-, doch treue Poesie,", "tokens": ["Ach", "ar\u00b7m", ",", "doch", "treu\u00b7e", "Poe\u00b7sie", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "TRUNC", "$,", "ADV", "ADJA", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.6": {"text": "Umfang doch der Debora Knie,", "tokens": ["Um\u00b7fang", "doch", "der", "De\u00b7bo\u00b7ra", "Knie", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Die deinen Feinden Troz gebothen;", "tokens": ["Die", "dei\u00b7nen", "Fein\u00b7den", "Troz", "ge\u00b7bo\u00b7then", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ach, Kind, begehr kein Widergelt,", "tokens": ["Ach", ",", "Kind", ",", "be\u00b7gehr", "kein", "Wi\u00b7der\u00b7gelt", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$,", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Du mehrst ihr Leben auf der Welt,", "tokens": ["Du", "mehrst", "ihr", "Le\u00b7ben", "auf", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und sie erweckt dich von den Todten.", "tokens": ["Und", "sie", "er\u00b7weckt", "dich", "von", "den", "Tod\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Sie, sag ich, baut, erh\u00f6ht und sch\u00fczt", "tokens": ["Sie", ",", "sag", "ich", ",", "baut", ",", "er\u00b7h\u00f6ht", "und", "sch\u00fczt"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$,", "VVFIN", "PPER", "$,", "VVFIN", "$,", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Denckmahl deiner Sch\u00f6nheitsgaben;", "tokens": ["Das", "Denck\u00b7mahl", "dei\u00b7ner", "Sch\u00f6n\u00b7heits\u00b7ga\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Drum glaube, was du ihr gen\u00fczt,", "tokens": ["Drum", "glau\u00b7be", ",", "was", "du", "ihr", "ge\u00b7n\u00fczt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "PWS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Doch nicht umsonst gethan zu haben.", "tokens": ["Doch", "nicht", "um\u00b7sonst", "ge\u00b7than", "zu", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Wi\u00dfen schl\u00e4gt durch dich den Neid.", "tokens": ["Mein", "Wi\u00b7\u00dfen", "schl\u00e4gt", "durch", "dich", "den", "Neid", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ach, eile doch, gew\u00fcntschte Zeit,", "tokens": ["Ach", ",", "ei\u00b7le", "doch", ",", "ge\u00b7w\u00fcnt\u00b7schte", "Zeit", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "ADV", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und bring mich [Leonoren] wieder!", "tokens": ["Und", "bring", "mich", "Le\u00b7o\u00b7no\u00b7ren", "wie\u00b7der", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$(", "NE", "$(", "ADV", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Sie fragt, was sie gew\u00e4rtig sey:", "tokens": ["Sie", "fragt", ",", "was", "sie", "ge\u00b7w\u00e4r\u00b7tig", "sey", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "PPER", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Im Leben meiner s\u00fc\u00dfen Treu,", "tokens": ["Im", "Le\u00b7ben", "mei\u00b7ner", "s\u00fc\u00b7\u00dfen", "Treu", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Im Grabe meiner Ehrenlieder.", "tokens": ["Im", "Gra\u00b7be", "mei\u00b7ner", "Eh\u00b7ren\u00b7lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}