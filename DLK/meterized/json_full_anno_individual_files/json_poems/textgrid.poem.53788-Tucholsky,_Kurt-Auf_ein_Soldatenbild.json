{"textgrid.poem.53788": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Auf ein Soldatenbild", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hoher Kragen, eingezw\u00e4ngt", "tokens": ["Ho\u00b7her", "Kra\u00b7gen", ",", "ein\u00b7ge\u00b7zw\u00e4ngt"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "in die Affenjacke;", "tokens": ["in", "die", "Af\u00b7fen\u00b7ja\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "der Zivilleib, angestrengt,", "tokens": ["der", "Zi\u00b7vil\u00b7leib", ",", "an\u00b7ge\u00b7strengt", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "weicht dem Zeitgeschmacke.", "tokens": ["weicht", "dem", "Zeit\u00b7ge\u00b7schma\u00b7cke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Fremd und leer blickt dein Gesicht.", "tokens": ["Fremd", "und", "leer", "blickt", "dein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du verstehst das Ganze nicht.", "tokens": ["Du", "ver\u00b7stehst", "das", "Gan\u00b7ze", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Letztes Bild und letzter Klang \u2013", "tokens": ["Letz\u00b7tes", "Bild", "und", "letz\u00b7ter", "Klang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "du bist weggegangen.", "tokens": ["du", "bist", "weg\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich mu\u00df nun lebenslang", "tokens": ["Und", "ich", "mu\u00df", "nun", "le\u00b7bens\u00b7lang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "mich nach beiden bangen.", "tokens": ["mich", "nach", "bei\u00b7den", "ban\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Um dich pfl\u00fcgt der Bauernpflug.", "tokens": ["Um", "dich", "pfl\u00fcgt", "der", "Bau\u00b7ern\u00b7pflug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du bist Lehm und hast genug.", "tokens": ["Du", "bist", "Lehm", "und", "hast", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Lieber, seh ich heut dich an,", "tokens": ["Lie\u00b7ber", ",", "seh", "ich", "heut", "dich", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "PPER", "ADV", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "h\u00e4\u00dflich und verkleidet,", "tokens": ["h\u00e4\u00df\u00b7lich", "und", "ver\u00b7klei\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "hab ich oft dich toten Mann", "tokens": ["hab", "ich", "oft", "dich", "to\u00b7ten", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "gr\u00fc\u00dfend sehr beneidet.", "tokens": ["gr\u00fc\u00b7\u00dfend", "sehr", "be\u00b7nei\u00b7det", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "L\u00e4use, Leutnant, blutiges Gras \u2013", "tokens": ["L\u00e4u\u00b7se", ",", "Leut\u00b7nant", ",", "blu\u00b7ti\u00b7ges", "Gras", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADJA", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Sage, wof\u00fcr tatst du das?", "tokens": ["Sa\u00b7ge", ",", "wo\u00b7f\u00fcr", "tatst", "du", "das", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Auf uns sieht derselbe Mond,", "tokens": ["Auf", "uns", "sieht", "der\u00b7sel\u00b7be", "Mond", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sehn dieselben Sterne \u2013", "tokens": ["sehn", "die\u00b7sel\u00b7ben", "Ster\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Deutschland, ewig knechtgewohnt,", "tokens": ["Deutschland", ",", "e\u00b7wig", "knecht\u00b7ge\u00b7wohnt", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "lechzt nach der Kaserne.", "tokens": ["lechzt", "nach", "der", "Ka\u00b7ser\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Qual, vier Jahr, gestohlnes Fressen", "tokens": ["Qual", ",", "vier", "Jahr", ",", "ge\u00b7stohl\u00b7nes", "Fres\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "CARD", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind vergessen \u2013 sind vergessen . . .", "tokens": ["sind", "ver\u00b7ges\u00b7sen", "\u2013", "sind", "ver\u00b7ges\u00b7sen", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "VVPP", "$(", "VAFIN", "VVPP", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Br\u00fcllend rufen Rottenlieder:", "tokens": ["Br\u00fcl\u00b7lend", "ru\u00b7fen", "Rot\u00b7ten\u00b7lie\u00b7der", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "\u00bbmorgen wieder! Morgen wieder!\u00ab", "tokens": ["\u00bb", "mor\u00b7gen", "wie\u00b7der", "!", "Mor\u00b7gen", "wie\u00b7der", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "NN", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Gru\u00df dir \u2013!", "tokens": ["Gru\u00df", "dir", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Du bist dran zerschellt:", "tokens": ["Du", "bist", "dran", "zer\u00b7schellt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "an dem letzten Dreck der Welt.", "tokens": ["an", "dem", "letz\u00b7ten", "Dreck", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Hoher Kragen, eingezw\u00e4ngt", "tokens": ["Ho\u00b7her", "Kra\u00b7gen", ",", "ein\u00b7ge\u00b7zw\u00e4ngt"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$,", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "in die Affenjacke;", "tokens": ["in", "die", "Af\u00b7fen\u00b7ja\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "der Zivilleib, angestrengt,", "tokens": ["der", "Zi\u00b7vil\u00b7leib", ",", "an\u00b7ge\u00b7strengt", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "VVPP", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "weicht dem Zeitgeschmacke.", "tokens": ["weicht", "dem", "Zeit\u00b7ge\u00b7schma\u00b7cke", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Fremd und leer blickt dein Gesicht.", "tokens": ["Fremd", "und", "leer", "blickt", "dein", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du verstehst das Ganze nicht.", "tokens": ["Du", "ver\u00b7stehst", "das", "Gan\u00b7ze", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Letztes Bild und letzter Klang \u2013", "tokens": ["Letz\u00b7tes", "Bild", "und", "letz\u00b7ter", "Klang", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "du bist weggegangen.", "tokens": ["du", "bist", "weg\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich mu\u00df nun lebenslang", "tokens": ["Und", "ich", "mu\u00df", "nun", "le\u00b7bens\u00b7lang"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VMFIN", "ADV", "VVFIN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "mich nach beiden bangen.", "tokens": ["mich", "nach", "bei\u00b7den", "ban\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Um dich pfl\u00fcgt der Bauernpflug.", "tokens": ["Um", "dich", "pfl\u00fcgt", "der", "Bau\u00b7ern\u00b7pflug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du bist Lehm und hast genug.", "tokens": ["Du", "bist", "Lehm", "und", "hast", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "KON", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Lieber, seh ich heut dich an,", "tokens": ["Lie\u00b7ber", ",", "seh", "ich", "heut", "dich", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "PPER", "ADV", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "h\u00e4\u00dflich und verkleidet,", "tokens": ["h\u00e4\u00df\u00b7lich", "und", "ver\u00b7klei\u00b7det", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "hab ich oft dich toten Mann", "tokens": ["hab", "ich", "oft", "dich", "to\u00b7ten", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "PPER", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "gr\u00fc\u00dfend sehr beneidet.", "tokens": ["gr\u00fc\u00b7\u00dfend", "sehr", "be\u00b7nei\u00b7det", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "L\u00e4use, Leutnant, blutiges Gras \u2013", "tokens": ["L\u00e4u\u00b7se", ",", "Leut\u00b7nant", ",", "blu\u00b7ti\u00b7ges", "Gras", "\u2013"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "ADJA", "NN", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Sage, wof\u00fcr tatst du das?", "tokens": ["Sa\u00b7ge", ",", "wo\u00b7f\u00fcr", "tatst", "du", "das", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "VVFIN", "PPER", "PDS", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Auf uns sieht derselbe Mond,", "tokens": ["Auf", "uns", "sieht", "der\u00b7sel\u00b7be", "Mond", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PDAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "sehn dieselben Sterne \u2013", "tokens": ["sehn", "die\u00b7sel\u00b7ben", "Ster\u00b7ne", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Deutschland, ewig knechtgewohnt,", "tokens": ["Deutschland", ",", "e\u00b7wig", "knecht\u00b7ge\u00b7wohnt", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "lechzt nach der Kaserne.", "tokens": ["lechzt", "nach", "der", "Ka\u00b7ser\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.5": {"text": "Qual, vier Jahr, gestohlnes Fressen", "tokens": ["Qual", ",", "vier", "Jahr", ",", "ge\u00b7stohl\u00b7nes", "Fres\u00b7sen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "CARD", "NN", "$,", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sind vergessen \u2013 sind vergessen . . .", "tokens": ["sind", "ver\u00b7ges\u00b7sen", "\u2013", "sind", "ver\u00b7ges\u00b7sen", ".", ".", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["VAFIN", "VVPP", "$(", "VAFIN", "VVPP", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "Br\u00fcllend rufen Rottenlieder:", "tokens": ["Br\u00fcl\u00b7lend", "ru\u00b7fen", "Rot\u00b7ten\u00b7lie\u00b7der", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "VVFIN", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "\u00bbmorgen wieder! Morgen wieder!\u00ab", "tokens": ["\u00bb", "mor\u00b7gen", "wie\u00b7der", "!", "Mor\u00b7gen", "wie\u00b7der", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "NN", "ADV", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.9": {"text": "Gru\u00df dir \u2013!", "tokens": ["Gru\u00df", "dir", "\u2013", "!"], "token_info": ["word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Du bist dran zerschellt:", "tokens": ["Du", "bist", "dran", "zer\u00b7schellt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "an dem letzten Dreck der Welt.", "tokens": ["an", "dem", "letz\u00b7ten", "Dreck", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}