{"textgrid.poem.57382": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Tiegel des Dichtenden, oder h\u00f6rst Rathgeberin lieber", "genre": "verse", "period": "N.A.", "pub_year": 1795, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Tiegel des Dichtenden, oder h\u00f6rst Rathgeberin lieber", "tokens": ["Tie\u00b7gel", "des", "Dich\u00b7ten\u00b7den", ",", "o\u00b7der", "h\u00f6rst", "Rath\u00b7ge\u00b7be\u00b7rin", "lie\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KON", "VVFIN", "NN", "ADV"], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.2": {"text": "Du dich nennen? doch welcher der Name sey, den du w\u00fchlest;", "tokens": ["Du", "dich", "nen\u00b7nen", "?", "doch", "wel\u00b7cher", "der", "Na\u00b7me", "sey", ",", "den", "du", "w\u00fch\u00b7lest", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "$.", "ADV", "PRELS", "ART", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Bist du ernster, bist tiefsinniger, als im Traumel", "tokens": ["Bist", "du", "erns\u00b7ter", ",", "bist", "tief\u00b7sin\u00b7ni\u00b7ger", ",", "als", "im", "Trau\u00b7mel"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJA", "$,", "VAFIN", "ADJD", "$,", "KOUS", "APPRART", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Flug dich der Ungeweihte kent,", "tokens": ["Flug", "dich", "der", "Un\u00b7ge\u00b7weih\u00b7te", "kent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Bist entscheidender! Wie verstumt' ich oft, und wie f\u00fchlt' ich", "tokens": ["Bist", "ent\u00b7schei\u00b7den\u00b7der", "!", "Wie", "ver\u00b7stumt'", "ich", "oft", ",", "und", "wie", "f\u00fchlt'", "ich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "ADV", "$,", "KON", "PWAV", "VVFIN", "PPER"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Bleich mich werden, wenn empor ich sah zu der H\u00f6he,", "tokens": ["Bleich", "mich", "wer\u00b7den", ",", "wenn", "em\u00b7por", "ich", "sah", "zu", "der", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VAINF", "$,", "KOUS", "PTKVZ", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Die mir zeigte dein goldener Stab! und mit welchem Hinschaun", "tokens": ["Die", "mir", "zeig\u00b7te", "dein", "gol\u00b7de\u00b7ner", "Stab", "!", "und", "mit", "wel\u00b7chem", "Hin\u00b7schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "KON", "APPR", "PWAT", "NN"], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Mass ich den einsamen, steilen Pfad!", "tokens": ["Mass", "ich", "den", "ein\u00b7sa\u00b7men", ",", "stei\u00b7len", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.3": {"line.1": {"text": "Noch erheb' ich, denk' ich zur\u00fcck an die Tiefen, in deren", "tokens": ["Noch", "er\u00b7heb'", "ich", ",", "denk'", "ich", "zu\u00b7r\u00fcck", "an", "die", "Tie\u00b7fen", ",", "in", "de\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "NN", "$,", "APPR", "PRELAT"], "meter": "+-+-+--+--+-+--", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "N\u00e4he der schwindelnde Pfad sich erhob. Darstellung gelinget", "tokens": ["N\u00e4\u00b7he", "der", "schwin\u00b7deln\u00b7de", "Pfad", "sich", "er\u00b7hob", ".", "Dar\u00b7stel\u00b7lung", "ge\u00b7lin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "PRF", "VVFIN", "$.", "NN", "VVPP"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Droben allein, nur auf dem erstiegenen fernen Gipfel,", "tokens": ["Dro\u00b7ben", "al\u00b7lein", ",", "nur", "auf", "dem", "er\u00b7stie\u00b7ge\u00b7nen", "fer\u00b7nen", "Gip\u00b7fel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "F\u00fchrt man in ihren Zauberkreis.", "tokens": ["F\u00fchrt", "man", "in", "ih\u00b7ren", "Zau\u00b7ber\u00b7kreis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Aber wer hat den Reiz, durch den die F\u00fchrungen gl\u00fccken,", "tokens": ["A\u00b7ber", "wer", "hat", "den", "Reiz", ",", "durch", "den", "die", "F\u00fch\u00b7run\u00b7gen", "gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Immer ersp\u00e4het? wer das Lebende niemals get\u00f6dtet?", "tokens": ["Im\u00b7mer", "er\u00b7sp\u00e4\u00b7het", "?", "wer", "das", "Le\u00b7ben\u00b7de", "nie\u00b7mals", "ge\u00b7t\u00f6d\u00b7tet", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PWS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "O verzeihest du auch, Rathgeberin, dass dein Wink dann", "tokens": ["O", "ver\u00b7zei\u00b7hest", "du", "auch", ",", "Rath\u00b7ge\u00b7be\u00b7rin", ",", "dass", "dein", "Wink", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Nach der H\u00f6he vergebens wies?", "tokens": ["Nach", "der", "H\u00f6\u00b7he", "ver\u00b7ge\u00b7bens", "wies", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "J\u00fcnglinge, lasset euch Beyspiele warnen. Es sey euch", "tokens": ["J\u00fcng\u00b7lin\u00b7ge", ",", "las\u00b7set", "euch", "Bey\u00b7spie\u00b7le", "war\u00b7nen", ".", "Es", "sey", "euch"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "NN", "VVINF", "$.", "PPER", "VAFIN", "PPER"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wacker das Auge, so bald an dem Zauberkreise sich Leben,", "tokens": ["Wa\u00b7cker", "das", "Au\u00b7ge", ",", "so", "bald", "an", "dem", "Zau\u00b7ber\u00b7krei\u00b7se", "sich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ADV", "ADV", "APPR", "ART", "NN", "PRF", "NN", "$,"], "meter": "+--+-+-+-+-+--+-", "measure": "iambic.septa.invert"}, "line.3": {"text": "Grosses, Leidenschaft zeigt. Darstellung gebietet festen,", "tokens": ["Gros\u00b7ses", ",", "Lei\u00b7den\u00b7schaft", "zeigt", ".", "Dar\u00b7stel\u00b7lung", "ge\u00b7bie\u00b7tet", "fes\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVFIN", "$.", "NN", "VVPP", "VVINF", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Hingehefteten Forscherblick.", "tokens": ["Hin\u00b7ge\u00b7hef\u00b7te\u00b7ten", "For\u00b7scher\u00b7blick", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.6": {"line.1": {"text": "Nicht das Auge gabet ihr euch; allein wenn ihr oft blickt,", "tokens": ["Nicht", "das", "Au\u00b7ge", "ga\u00b7bet", "ihr", "euch", ";", "al\u00b7lein", "wenn", "ihr", "oft", "blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "PPER", "PPER", "$.", "ADV", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "K\u00f6nnet, den Schlummer scheuchend, dass heller es sieht, ihr ihm geben.", "tokens": ["K\u00f6n\u00b7net", ",", "den", "Schlum\u00b7mer", "scheu\u00b7chend", ",", "dass", "hel\u00b7ler", "es", "sieht", ",", "ihr", "ihm", "ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "ART", "NN", "ADJD", "$,", "KOUS", "ADJA", "PPER", "VVFIN", "$,", "PPER", "PPER", "VVINF", "$."], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Leiterin ist sie euch nicht die Regel, (Verzeiht dem Greise,", "tokens": ["Lei\u00b7te\u00b7rin", "ist", "sie", "euch", "nicht", "die", "Re\u00b7gel", ",", "(", "Ver\u00b7zeiht", "dem", "Grei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPER", "PTKNEG", "ART", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+---+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Dass er fortspricht,) wird euch nie", "tokens": ["Dass", "er", "fort\u00b7spricht", ",", ")", "wird", "euch", "nie"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "$(", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Ihren goldenen Stab erheben: wenn euch nicht Geist ward,", "tokens": ["Ih\u00b7ren", "gol\u00b7de\u00b7nen", "Stab", "er\u00b7he\u00b7ben", ":", "wenn", "euch", "nicht", "Geist", "ward", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$.", "KOUS", "PPER", "PTKNEG", "NN", "VAFIN", "$,"], "meter": "+-+--+-+-++-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Dem die Empfindung heisser gl\u00fcht, wie ihn Bilder entflammen,", "tokens": ["Dem", "die", "Emp\u00b7fin\u00b7dung", "heis\u00b7ser", "gl\u00fcht", ",", "wie", "ihn", "Bil\u00b7der", "ent\u00b7flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJD", "VVFIN", "$,", "PWAV", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und in dem, Beherscher der Flamm' und der Glut, das Urteil", "tokens": ["Und", "in", "dem", ",", "Be\u00b7her\u00b7scher", "der", "Flamm'", "und", "der", "Glut", ",", "das", "Ur\u00b7teil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "$,", "NN", "ART", "NN", "KON", "ART", "NN", "$,", "ART", "NN"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Unbezaubert den Ausspruch thut;", "tokens": ["Un\u00b7be\u00b7zau\u00b7bert", "den", "Aus\u00b7spruch", "thut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.8": {"line.1": {"text": "Nie den goldenen Stab erheben, wenn ihr nicht alle", "tokens": ["Nie", "den", "gol\u00b7de\u00b7nen", "Stab", "er\u00b7he\u00b7ben", ",", "wenn", "ihr", "nicht", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVINF", "$,", "KOUS", "PPER", "PTKNEG", "PIAT"], "meter": "+-+--+-+-++-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Ihre Gebehrden kent, nicht ihre Winke, die Stirn nicht,", "tokens": ["Ih\u00b7re", "Ge\u00b7behr\u00b7den", "kent", ",", "nicht", "ih\u00b7re", "Win\u00b7ke", ",", "die", "Stirn", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PTKNEG", "PPOSAT", "NN", "$,", "ART", "NN", "PTKNEG", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Die nun faltig, nun sanft verbeut, nicht die helle Seele,", "tokens": ["Die", "nun", "fal\u00b7tig", ",", "nun", "sanft", "ver\u00b7beut", ",", "nicht", "die", "hel\u00b7le", "See\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ganz nicht, die stolze Griechin kent.", "tokens": ["Ganz", "nicht", ",", "die", "stol\u00b7ze", "Grie\u00b7ch\u00b7in", "kent", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.9": {"line.1": {"text": "Weniges nur, allein Zielf\u00fchrendes grub sie in ihre", "tokens": ["We\u00b7ni\u00b7ges", "nur", ",", "al\u00b7lein", "Ziel\u00b7f\u00fch\u00b7ren\u00b7des", "grub", "sie", "in", "ih\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "$,", "ADV", "NN", "VVFIN", "PPER", "APPR", "PPOSAT"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Eherne Tafel. Einiges wird hier selten, dort \u00f6fter,", "tokens": ["E\u00b7her\u00b7ne", "Ta\u00b7fel", ".", "Ei\u00b7ni\u00b7ges", "wird", "hier", "sel\u00b7ten", ",", "dort", "\u00f6f\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADV", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Aber Anderes immer gethan. Wenn von dem ihr weichet;", "tokens": ["A\u00b7ber", "An\u00b7de\u00b7res", "im\u00b7mer", "ge\u00b7than", ".", "Wenn", "von", "dem", "ihr", "wei\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVPP", "$.", "KOUS", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Habt ihr das erste nur halb gethan.", "tokens": ["Habt", "ihr", "das", "ers\u00b7te", "nur", "halb", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Auf die sch\u00f6ne Natur, auf die nur weiset sie. H\u00fcbsch ist", "tokens": ["Auf", "die", "sch\u00f6\u00b7ne", "Na\u00b7tur", ",", "auf", "die", "nur", "wei\u00b7set", "sie", ".", "H\u00fcbsch", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "PRELS", "ADV", "VVFIN", "PPER", "$.", "ADJD", "VAFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Diese nicht, ist nicht wild; hat auch furchtbare Grazie; kerkert", "tokens": ["Die\u00b7se", "nicht", ",", "ist", "nicht", "wild", ";", "hat", "auch", "furcht\u00b7ba\u00b7re", "Gra\u00b7zie", ";", "ker\u00b7kert"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "PTKNEG", "$,", "VAFIN", "PTKNEG", "ADJD", "$.", "VAFIN", "ADV", "ADJA", "NN", "$.", "VVFIN"], "meter": "+-++-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Engumkreisend nicht ein: doch mit Feinheit begr\u00e4nzt die Messung,", "tokens": ["En\u00b7gum\u00b7krei\u00b7send", "nicht", "ein", ":", "doch", "mit", "Fein\u00b7heit", "be\u00b7gr\u00e4nzt", "die", "Mes\u00b7sung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "PTKVZ", "$.", "ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Ziehet nicht selten Apelless Strich.", "tokens": ["Zie\u00b7het", "nicht", "sel\u00b7ten", "A\u00b7pel\u00b7less", "Strich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJD", "NE", "NE", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Wolt ihr der Griechin folgen; so kieset von dem, was sie lehret,", "tokens": ["Wolt", "ihr", "der", "Grie\u00b7ch\u00b7in", "fol\u00b7gen", ";", "so", "kie\u00b7set", "von", "dem", ",", "was", "sie", "leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "ADV", "VVFIN", "APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Stimmendes zu des Gesangs Erfindung, legt's auf die Wagschal,", "tokens": ["Stim\u00b7men\u00b7des", "zu", "des", "Ge\u00b7sangs", "Er\u00b7fin\u00b7dung", ",", "legt's", "auf", "die", "Wag\u00b7schal", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-+-+--++", "measure": "dactylic.di.plus"}, "line.3": {"text": "W\u00e4gt es ihr zu. Was ihr nach falschem Gewicht verbildet,", "tokens": ["W\u00e4gt", "es", "ihr", "zu", ".", "Was", "ihr", "nach", "fal\u00b7schem", "Ge\u00b7wicht", "ver\u00b7bil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "$.", "PWS", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Schimmert vielleicht; wird untergehn.", "tokens": ["Schim\u00b7mert", "viel\u00b7leicht", ";", "wird", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "VAFIN", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.12": {"line.1": {"text": "Tiegel des Dichtenden, oder h\u00f6rst Rathgeberin lieber", "tokens": ["Tie\u00b7gel", "des", "Dich\u00b7ten\u00b7den", ",", "o\u00b7der", "h\u00f6rst", "Rath\u00b7ge\u00b7be\u00b7rin", "lie\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "$,", "KON", "VVFIN", "NN", "ADV"], "meter": "+--+--+--+-+-+-", "measure": "elegiambus"}, "line.2": {"text": "Du dich nennen? doch welcher der Name sey, den du w\u00fchlest;", "tokens": ["Du", "dich", "nen\u00b7nen", "?", "doch", "wel\u00b7cher", "der", "Na\u00b7me", "sey", ",", "den", "du", "w\u00fch\u00b7lest", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "VVINF", "$.", "ADV", "PRELS", "ART", "NN", "VAFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+--+--+-+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Bist du ernster, bist tiefsinniger, als im Traumel", "tokens": ["Bist", "du", "erns\u00b7ter", ",", "bist", "tief\u00b7sin\u00b7ni\u00b7ger", ",", "als", "im", "Trau\u00b7mel"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADJA", "$,", "VAFIN", "ADJD", "$,", "KOUS", "APPRART", "NN"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Flug dich der Ungeweihte kent,", "tokens": ["Flug", "dich", "der", "Un\u00b7ge\u00b7weih\u00b7te", "kent", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.13": {"line.1": {"text": "Bist entscheidender! Wie verstumt' ich oft, und wie f\u00fchlt' ich", "tokens": ["Bist", "ent\u00b7schei\u00b7den\u00b7der", "!", "Wie", "ver\u00b7stumt'", "ich", "oft", ",", "und", "wie", "f\u00fchlt'", "ich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PTKVZ", "$.", "PWAV", "VVFIN", "PPER", "ADV", "$,", "KON", "PWAV", "VVFIN", "PPER"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Bleich mich werden, wenn empor ich sah zu der H\u00f6he,", "tokens": ["Bleich", "mich", "wer\u00b7den", ",", "wenn", "em\u00b7por", "ich", "sah", "zu", "der", "H\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "VAINF", "$,", "KOUS", "PTKVZ", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Die mir zeigte dein goldener Stab! und mit welchem Hinschaun", "tokens": ["Die", "mir", "zeig\u00b7te", "dein", "gol\u00b7de\u00b7ner", "Stab", "!", "und", "mit", "wel\u00b7chem", "Hin\u00b7schaun"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$.", "KON", "APPR", "PWAT", "NN"], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Mass ich den einsamen, steilen Pfad!", "tokens": ["Mass", "ich", "den", "ein\u00b7sa\u00b7men", ",", "stei\u00b7len", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.14": {"line.1": {"text": "Noch erheb' ich, denk' ich zur\u00fcck an die Tiefen, in deren", "tokens": ["Noch", "er\u00b7heb'", "ich", ",", "denk'", "ich", "zu\u00b7r\u00fcck", "an", "die", "Tie\u00b7fen", ",", "in", "de\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "NN", "$,", "APPR", "PRELAT"], "meter": "+-+-+--+--+-+--", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "N\u00e4he der schwindelnde Pfad sich erhob. Darstellung gelinget", "tokens": ["N\u00e4\u00b7he", "der", "schwin\u00b7deln\u00b7de", "Pfad", "sich", "er\u00b7hob", ".", "Dar\u00b7stel\u00b7lung", "ge\u00b7lin\u00b7get"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "PRF", "VVFIN", "$.", "NN", "VVPP"], "meter": "+--+--+--+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Droben allein, nur auf dem erstiegenen fernen Gipfel,", "tokens": ["Dro\u00b7ben", "al\u00b7lein", ",", "nur", "auf", "dem", "er\u00b7stie\u00b7ge\u00b7nen", "fer\u00b7nen", "Gip\u00b7fel", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "ADV", "APPR", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "F\u00fchrt man in ihren Zauberkreis.", "tokens": ["F\u00fchrt", "man", "in", "ih\u00b7ren", "Zau\u00b7ber\u00b7kreis", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Aber wer hat den Reiz, durch den die F\u00fchrungen gl\u00fccken,", "tokens": ["A\u00b7ber", "wer", "hat", "den", "Reiz", ",", "durch", "den", "die", "F\u00fch\u00b7run\u00b7gen", "gl\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "NN", "$,", "APPR", "ART", "ART", "NN", "VVINF", "$,"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Immer ersp\u00e4het? wer das Lebende niemals get\u00f6dtet?", "tokens": ["Im\u00b7mer", "er\u00b7sp\u00e4\u00b7het", "?", "wer", "das", "Le\u00b7ben\u00b7de", "nie\u00b7mals", "ge\u00b7t\u00f6d\u00b7tet", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "PWS", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+--+-+-+--+--+-", "measure": "hexameter"}, "line.3": {"text": "O verzeihest du auch, Rathgeberin, dass dein Wink dann", "tokens": ["O", "ver\u00b7zei\u00b7hest", "du", "auch", ",", "Rath\u00b7ge\u00b7be\u00b7rin", ",", "dass", "dein", "Wink", "dann"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$,", "NN", "$,", "KOUS", "PPOSAT", "NN", "ADV"], "meter": "+-+-+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Nach der H\u00f6he vergebens wies?", "tokens": ["Nach", "der", "H\u00f6\u00b7he", "ver\u00b7ge\u00b7bens", "wies", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.16": {"line.1": {"text": "J\u00fcnglinge, lasset euch Beyspiele warnen. Es sey euch", "tokens": ["J\u00fcng\u00b7lin\u00b7ge", ",", "las\u00b7set", "euch", "Bey\u00b7spie\u00b7le", "war\u00b7nen", ".", "Es", "sey", "euch"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "NN", "VVINF", "$.", "PPER", "VAFIN", "PPER"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wacker das Auge, so bald an dem Zauberkreise sich Leben,", "tokens": ["Wa\u00b7cker", "das", "Au\u00b7ge", ",", "so", "bald", "an", "dem", "Zau\u00b7ber\u00b7krei\u00b7se", "sich", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,", "ADV", "ADV", "APPR", "ART", "NN", "PRF", "NN", "$,"], "meter": "+--+-+-+-+-+--+-", "measure": "iambic.septa.invert"}, "line.3": {"text": "Grosses, Leidenschaft zeigt. Darstellung gebietet festen,", "tokens": ["Gros\u00b7ses", ",", "Lei\u00b7den\u00b7schaft", "zeigt", ".", "Dar\u00b7stel\u00b7lung", "ge\u00b7bie\u00b7tet", "fes\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "VVFIN", "$.", "NN", "VVPP", "VVINF", "$,"], "meter": "+-+--+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Hingehefteten Forscherblick.", "tokens": ["Hin\u00b7ge\u00b7hef\u00b7te\u00b7ten", "For\u00b7scher\u00b7blick", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.17": {"line.1": {"text": "Nicht das Auge gabet ihr euch; allein wenn ihr oft blickt,", "tokens": ["Nicht", "das", "Au\u00b7ge", "ga\u00b7bet", "ihr", "euch", ";", "al\u00b7lein", "wenn", "ihr", "oft", "blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VVFIN", "PPER", "PPER", "$.", "ADV", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "+-+-+--+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "K\u00f6nnet, den Schlummer scheuchend, dass heller es sieht, ihr ihm geben.", "tokens": ["K\u00f6n\u00b7net", ",", "den", "Schlum\u00b7mer", "scheu\u00b7chend", ",", "dass", "hel\u00b7ler", "es", "sieht", ",", "ihr", "ihm", "ge\u00b7ben", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "$,", "ART", "NN", "ADJD", "$,", "KOUS", "ADJA", "PPER", "VVFIN", "$,", "PPER", "PPER", "VVINF", "$."], "meter": "+--+-+--+--+--+-", "measure": "hexameter"}, "line.3": {"text": "Leiterin ist sie euch nicht die Regel, (Verzeiht dem Greise,", "tokens": ["Lei\u00b7te\u00b7rin", "ist", "sie", "euch", "nicht", "die", "Re\u00b7gel", ",", "(", "Ver\u00b7zeiht", "dem", "Grei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PPER", "PTKNEG", "ART", "NN", "$,", "$(", "VVFIN", "ART", "NN", "$,"], "meter": "+-+---+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Dass er fortspricht,) wird euch nie", "tokens": ["Dass", "er", "fort\u00b7spricht", ",", ")", "wird", "euch", "nie"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "$(", "VAFIN", "PPER", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Ihren goldenen Stab erheben: wenn euch nicht Geist ward,", "tokens": ["Ih\u00b7ren", "gol\u00b7de\u00b7nen", "Stab", "er\u00b7he\u00b7ben", ":", "wenn", "euch", "nicht", "Geist", "ward", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$.", "KOUS", "PPER", "PTKNEG", "NN", "VAFIN", "$,"], "meter": "+-+--+-+-++-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Dem die Empfindung heisser gl\u00fcht, wie ihn Bilder entflammen,", "tokens": ["Dem", "die", "Emp\u00b7fin\u00b7dung", "heis\u00b7ser", "gl\u00fcht", ",", "wie", "ihn", "Bil\u00b7der", "ent\u00b7flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "ADJD", "VVFIN", "$,", "PWAV", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und in dem, Beherscher der Flamm' und der Glut, das Urteil", "tokens": ["Und", "in", "dem", ",", "Be\u00b7her\u00b7scher", "der", "Flamm'", "und", "der", "Glut", ",", "das", "Ur\u00b7teil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "APPR", "ART", "$,", "NN", "ART", "NN", "KON", "ART", "NN", "$,", "ART", "NN"], "meter": "-+--+--+--+-+-", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "Unbezaubert den Ausspruch thut;", "tokens": ["Un\u00b7be\u00b7zau\u00b7bert", "den", "Aus\u00b7spruch", "thut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "VVFIN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.19": {"line.1": {"text": "Nie den goldenen Stab erheben, wenn ihr nicht alle", "tokens": ["Nie", "den", "gol\u00b7de\u00b7nen", "Stab", "er\u00b7he\u00b7ben", ",", "wenn", "ihr", "nicht", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN", "VVINF", "$,", "KOUS", "PPER", "PTKNEG", "PIAT"], "meter": "+-+--+-+-++-+-", "measure": "trochaic.septa.relaxed"}, "line.2": {"text": "Ihre Gebehrden kent, nicht ihre Winke, die Stirn nicht,", "tokens": ["Ih\u00b7re", "Ge\u00b7behr\u00b7den", "kent", ",", "nicht", "ih\u00b7re", "Win\u00b7ke", ",", "die", "Stirn", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$,", "PTKNEG", "PPOSAT", "NN", "$,", "ART", "NN", "PTKNEG", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Die nun faltig, nun sanft verbeut, nicht die helle Seele,", "tokens": ["Die", "nun", "fal\u00b7tig", ",", "nun", "sanft", "ver\u00b7beut", ",", "nicht", "die", "hel\u00b7le", "See\u00b7le", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "$,", "ADV", "ADJD", "VVFIN", "$,", "PTKNEG", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Ganz nicht, die stolze Griechin kent.", "tokens": ["Ganz", "nicht", ",", "die", "stol\u00b7ze", "Grie\u00b7ch\u00b7in", "kent", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.20": {"line.1": {"text": "Weniges nur, allein Zielf\u00fchrendes grub sie in ihre", "tokens": ["We\u00b7ni\u00b7ges", "nur", ",", "al\u00b7lein", "Ziel\u00b7f\u00fch\u00b7ren\u00b7des", "grub", "sie", "in", "ih\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "ADV", "$,", "ADV", "NN", "VVFIN", "PPER", "APPR", "PPOSAT"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Eherne Tafel. Einiges wird hier selten, dort \u00f6fter,", "tokens": ["E\u00b7her\u00b7ne", "Ta\u00b7fel", ".", "Ei\u00b7ni\u00b7ges", "wird", "hier", "sel\u00b7ten", ",", "dort", "\u00f6f\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PIS", "VAFIN", "ADV", "ADJD", "$,", "ADV", "ADV", "$,"], "meter": "+--+--+-+-+--+-", "measure": "hexameter"}, "line.3": {"text": "Aber Anderes immer gethan. Wenn von dem ihr weichet;", "tokens": ["A\u00b7ber", "An\u00b7de\u00b7res", "im\u00b7mer", "ge\u00b7than", ".", "Wenn", "von", "dem", "ihr", "wei\u00b7chet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADV", "VVPP", "$.", "KOUS", "APPR", "PRELS", "PPER", "VVFIN", "$."], "meter": "--+--+--+--+-+-", "measure": "anapaest.tetra.plus"}, "line.4": {"text": "Habt ihr das erste nur halb gethan.", "tokens": ["Habt", "ihr", "das", "ers\u00b7te", "nur", "halb", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Auf die sch\u00f6ne Natur, auf die nur weiset sie. H\u00fcbsch ist", "tokens": ["Auf", "die", "sch\u00f6\u00b7ne", "Na\u00b7tur", ",", "auf", "die", "nur", "wei\u00b7set", "sie", ".", "H\u00fcbsch", "ist"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$,", "APPR", "PRELS", "ADV", "VVFIN", "PPER", "$.", "ADJD", "VAFIN"], "meter": "+-+--+-+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Diese nicht, ist nicht wild; hat auch furchtbare Grazie; kerkert", "tokens": ["Die\u00b7se", "nicht", ",", "ist", "nicht", "wild", ";", "hat", "auch", "furcht\u00b7ba\u00b7re", "Gra\u00b7zie", ";", "ker\u00b7kert"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PDS", "PTKNEG", "$,", "VAFIN", "PTKNEG", "ADJD", "$.", "VAFIN", "ADV", "ADJA", "NN", "$.", "VVFIN"], "meter": "+-++-+--+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.3": {"text": "Engumkreisend nicht ein: doch mit Feinheit begr\u00e4nzt die Messung,", "tokens": ["En\u00b7gum\u00b7krei\u00b7send", "nicht", "ein", ":", "doch", "mit", "Fein\u00b7heit", "be\u00b7gr\u00e4nzt", "die", "Mes\u00b7sung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "PTKVZ", "$.", "ADV", "APPR", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Ziehet nicht selten Apelless Strich.", "tokens": ["Zie\u00b7het", "nicht", "sel\u00b7ten", "A\u00b7pel\u00b7less", "Strich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADJD", "NE", "NE", "$."], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}}, "stanza.22": {"line.1": {"text": "Wolt ihr der Griechin folgen; so kieset von dem, was sie lehret,", "tokens": ["Wolt", "ihr", "der", "Grie\u00b7ch\u00b7in", "fol\u00b7gen", ";", "so", "kie\u00b7set", "von", "dem", ",", "was", "sie", "leh\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$.", "ADV", "VVFIN", "APPR", "ART", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.2": {"text": "Stimmendes zu des Gesangs Erfindung, legt's auf die Wagschal,", "tokens": ["Stim\u00b7men\u00b7des", "zu", "des", "Ge\u00b7sangs", "Er\u00b7fin\u00b7dung", ",", "legt's", "auf", "die", "Wag\u00b7schal", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+--+--+-+-+--++", "measure": "dactylic.di.plus"}, "line.3": {"text": "W\u00e4gt es ihr zu. Was ihr nach falschem Gewicht verbildet,", "tokens": ["W\u00e4gt", "es", "ihr", "zu", ".", "Was", "ihr", "nach", "fal\u00b7schem", "Ge\u00b7wicht", "ver\u00b7bil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "PTKVZ", "$.", "PWS", "PPER", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Schimmert vielleicht; wird untergehn.", "tokens": ["Schim\u00b7mert", "viel\u00b7leicht", ";", "wird", "un\u00b7ter\u00b7gehn", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$.", "VAFIN", "VVINF", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}