{"dta.poem.3357": {"metadata": {"author": {"name": "Freiligrath, Ferdinand", "birth": "N.A.", "death": "N.A."}, "title": "Ii.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1846", "urn": "urn:nbn:de:kobv:b4-200905191464", "language": ["de:0.99"], "booktitle": "Freiligrath, Ferdinand: \u00c7a ira! Herisau, 1846."}, "poem": {"stanza.1": {"line.1": {"text": "Die ihr der V\u00f6lker heil\u2019ge Fluth abd\u00e4mmtet von", "tokens": ["Die", "ihr", "der", "V\u00f6l\u00b7ker", "heil'\u00b7ge", "Fluth", "ab\u00b7d\u00e4mm\u00b7tet", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "ADJA", "NN", "VVFIN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Freiheit Meer: \u2014", "tokens": ["der", "Frei\u00b7heit", "Meer", ":"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "NN", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ausm\u00fcndend bald, der Newa gleich, braust sie", "tokens": ["Aus\u00b7m\u00fcn\u00b7dend", "bald", ",", "der", "Ne\u00b7wa", "gleich", ",", "braust", "sie"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "ADV", "$,", "ART", "NN", "ADV", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-++-", "measure": "unknown.measure.penta"}, "line.4": {"text": "und jubelt sie einher!", "tokens": ["und", "ju\u00b7belt", "sie", "ein\u00b7her", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Den Winterfrost der Tyrannei stolz vom Genicke", "tokens": ["Den", "Win\u00b7ter\u00b7frost", "der", "Ty\u00b7ran\u00b7nei", "stolz", "vom", "Ge\u00b7ni\u00b7cke"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "sch\u00fcttelt sie,", "tokens": ["sch\u00fct\u00b7telt", "sie", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "Und schlingt hinab, den lang sie trug, den Eis-", "tokens": ["Und", "schlingt", "hin\u00b7ab", ",", "den", "lang", "sie", "trug", ",", "den", "Eis"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "ART", "ADJD", "PPER", "VVFIN", "$,", "ART", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "palast der Despotie!", "tokens": ["pa\u00b7last", "der", "Des\u00b7po\u00b7tie", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.2": {"line.1": {"text": "Noch schwelgt ihr in dem Blitzenden, und thut in", "tokens": ["Noch", "schwelgt", "ihr", "in", "dem", "Blit\u00b7zen\u00b7den", ",", "und", "thut", "in"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KON", "VVFIN", "APPR"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "eurem D\u00fcnkel, traun!", "tokens": ["eu\u00b7rem", "D\u00fcn\u00b7kel", ",", "traun", "!"], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Als k\u00e4me nun und nie der Lenz, als w\u00fcrd\u2019 es", "tokens": ["Als", "k\u00e4\u00b7me", "nun", "und", "nie", "der", "Lenz", ",", "als", "w\u00fcrd'", "es"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUS", "VVFIN", "ADV", "KON", "ADV", "ART", "NN", "$,", "KOKOM", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "nun und nimmer thau\u2019n!", "tokens": ["nun", "und", "nim\u00b7mer", "thau'n", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "KON", "ADV", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Doch m\u00e4lig steigt die Sonne schon, und weich", "tokens": ["Doch", "m\u00e4\u00b7lig", "steigt", "die", "Son\u00b7ne", "schon", ",", "und", "weich"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "ADV", "$,", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "erhebt sich schon ein Weh\u2019n;", "tokens": ["er\u00b7hebt", "sich", "schon", "ein", "Weh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Die Decke tropft, der Boden schwimmt \u2014 O,", "tokens": ["Die", "De\u00b7cke", "tropft", ",", "der", "Bo\u00b7den", "schwimmt", "O", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$(", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "schl\u00fcpfrig und gef\u00e4hrlich Geh\u2019n!", "tokens": ["schl\u00fcpf\u00b7rig", "und", "ge\u00b7f\u00e4hr\u00b7lich", "Geh'n", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Ihr aber ", "tokens": ["Ihr", "a\u00b7ber"], "token_info": ["word", "word"], "pos": ["PPER", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "und kapitulirt", "tokens": ["und", "ka\u00b7pi\u00b7tu\u00b7lirt"], "token_info": ["word", "word"], "pos": ["KON", "VVFIN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "Lang erst mit jeder Scholle noch, ob sie \u2014 von", "tokens": ["Lang", "erst", "mit", "je\u00b7der", "Schol\u00b7le", "noch", ",", "ob", "sie", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "ADV", "APPR", "PIAT", "NN", "ADV", "$,", "KOUS", "PPER", "$(", "APPR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Neuem nicht gefriert!", "tokens": ["Neu\u00b7em", "nicht", "ge\u00b7friert", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Umsonst, ihr Herrn! Kein Halten mehr! Ihr sprecht", "tokens": ["Um\u00b7sonst", ",", "ihr", "Herrn", "!", "Kein", "Hal\u00b7ten", "mehr", "!", "Ihr", "sprecht"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "PPOSAT", "NN", "$.", "PIAT", "NN", "ADV", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "den Lenz zum Winter nicht,", "tokens": ["den", "Lenz", "zum", "Win\u00b7ter", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und hat das Eis einmal gekracht, so glaubt mir!", "tokens": ["Und", "hat", "das", "Eis", "ein\u00b7mal", "ge\u00b7kracht", ",", "so", "glaubt", "mir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "VVPP", "$,", "ADV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "da\u00df es bald auch bricht!", "tokens": ["da\u00df", "es", "bald", "auch", "bricht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Dann aber hei\u00dft es wiederum: \u2014 Abw\u00e4rts mit", "tokens": ["Dann", "a\u00b7ber", "hei\u00dft", "es", "wie\u00b7de\u00b7rum", ":", "Ab\u00b7w\u00e4rts", "mit"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "$.", "$(", "ADV", "APPR"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "brausendem Ergu\u00df,", "tokens": ["brau\u00b7sen\u00b7dem", "Er\u00b7gu\u00df", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Abw\u00e4rts durch Schnee und Schollenwerk dr\u00e4ngt sich", "tokens": ["Ab\u00b7w\u00e4rts", "durch", "Schnee", "und", "Schol\u00b7len\u00b7werk", "dr\u00e4ngt", "sich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "VVFIN", "PRF"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "und macht sich Bahn der Flu\u00df!", "tokens": ["und", "macht", "sich", "Bahn", "der", "Flu\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die letzten Spuren seiner Schmach malmt er und", "tokens": ["Die", "letz\u00b7ten", "Spu\u00b7ren", "sei\u00b7ner", "Schmach", "malmt", "er", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN", "VVFIN", "PPER", "KON"], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.6": {"text": "knirscht er kurz und klein \u2014", "tokens": ["knirscht", "er", "kurz", "und", "klein"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "KON", "ADJD", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und fluthet gro\u00df und ruhig dann in\u2019s ewig freie", "tokens": ["Und", "flut\u00b7het", "gro\u00df", "und", "ru\u00b7hig", "dann", "in's", "e\u00b7wig", "frei\u00b7e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "KON", "ADJD", "ADV", "APPRART", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Meer hinein!", "tokens": ["Meer", "hin\u00b7ein", "!"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "+-+", "measure": "trochaic.di"}}}}}