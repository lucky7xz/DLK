{"textgrid.poem.57332": {"metadata": {"author": {"name": "Klopstock, Friedrich Gottlieb", "birth": "N.A.", "death": "N.A."}, "title": "1L: Sch\u00f6ne des Mays begeisterte sie, in des Griechen", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6ne des Mays begeisterte sie, in des Griechen", "tokens": ["Sch\u00f6\u00b7ne", "des", "Mays", "be\u00b7geis\u00b7ter\u00b7te", "sie", ",", "in", "des", "Grie\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NE", "VVFIN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Tage zur\u00fcck sich zu dichten; und ihr Spiel war", "tokens": ["Ta\u00b7ge", "zu\u00b7r\u00fcck", "sich", "zu", "dich\u00b7ten", ";", "und", "ihr", "Spiel", "war"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "PRF", "APPR", "ADJA", "$.", "KON", "PPOSAT", "NN", "VAFIN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Manches jener Olympiaden,", "tokens": ["Man\u00b7ches", "je\u00b7ner", "O\u00b7lym\u00b7pia\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches verschwand, und noch ist!", "tokens": ["Wel\u00b7ches", "ver\u00b7schwand", ",", "und", "noch", "ist", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KON", "ADV", "VAFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.2": {"line.1": {"text": "Manches, was Freud' in Tempe einst war, was in Elis", "tokens": ["Man\u00b7ches", ",", "was", "Freud'", "in", "Tem\u00b7pe", "einst", "war", ",", "was", "in", "E\u00b7lis"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PWS", "NN", "APPR", "NE", "ADV", "VAFIN", "$,", "PRELS", "APPR", "NE"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Palmen erwarb durch den Wettlauf und durch Lieder:", "tokens": ["Pal\u00b7men", "er\u00b7warb", "durch", "den", "Wett\u00b7lauf", "und", "durch", "Lie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "KON", "APPR", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Hergang auch aus Homers Ges\u00e4ngen", "tokens": ["Her\u00b7gang", "auch", "aus", "Ho\u00b7mers", "Ge\u00b7s\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NE", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Zauberten sie bis zu sich.", "tokens": ["Zau\u00b7ber\u00b7ten", "sie", "bis", "zu", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "PRF", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Jetzo umgab sie heiliges Graun in dem Tempel Delphi.", "tokens": ["Jet\u00b7zo", "um\u00b7gab", "sie", "hei\u00b7li\u00b7ges", "Graun", "in", "dem", "Tem\u00b7pel", "Del\u00b7phi", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "ART", "NN", "NE", "$."], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da sass auf dem Dreyfus, von des Lorbers", "tokens": ["Da", "sass", "auf", "dem", "Drey\u00b7fus", ",", "von", "des", "Lor\u00b7bers"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NE", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Opferdufte bew\u00f6lkt, die sch\u00f6ne", "tokens": ["Op\u00b7fer\u00b7duf\u00b7te", "be\u00b7w\u00f6lkt", ",", "die", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "$,", "ART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Priesterin, str\u00e4ubendes Haars,", "tokens": ["Pries\u00b7te\u00b7rin", ",", "str\u00e4u\u00b7ben\u00b7des", "Haars", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "Feurig den Blick; und Antwort erscholl dem Befrager.", "tokens": ["Feu\u00b7rig", "den", "Blick", ";", "und", "Ant\u00b7wort", "er\u00b7scholl", "dem", "Be\u00b7fra\u00b7ger", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$.", "KON", "NN", "ADJD", "ART", "NN", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Aber nun hob sie mit Eil sich von dem Dreyfuss.", "tokens": ["A\u00b7ber", "nun", "hob", "sie", "mit", "Eil", "sich", "von", "dem", "Drey\u00b7fuss", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Komt, ihr sehet ihn leer, und jetzo", "tokens": ["Komt", ",", "ihr", "se\u00b7het", "ihn", "leer", ",", "und", "jet\u00b7zo"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,", "KON", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Fraget die Priesterin euch!", "tokens": ["Fra\u00b7get", "die", "Pries\u00b7te\u00b7rin", "euch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.5": {"line.1": {"text": "\u00bbgehen wir nicht vielwegig zur\u00fcck? und wie lange", "tokens": ["\u00bb", "ge\u00b7hen", "wir", "nicht", "viel\u00b7we\u00b7gig", "zu\u00b7r\u00fcck", "?", "und", "wie", "lan\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$.", "KON", "PWAV", "ADV"], "meter": "+----+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Dauret es noch, dass, verwildert in der Irre,", "tokens": ["Dau\u00b7ret", "es", "noch", ",", "dass", ",", "ver\u00b7wil\u00b7dert", "in", "der", "Ir\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Wir uns l\u00e4cheln? dass wir den Krebsgang", "tokens": ["Wir", "uns", "l\u00e4\u00b7cheln", "?", "dass", "wir", "den", "Krebs\u00b7gang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "VVFIN", "$.", "KOUS", "PPER", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Tr\u00e4umen zu Geniusflug?", "tokens": ["Tr\u00e4u\u00b7men", "zu", "Ge\u00b7nius\u00b7flug", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Werden wir nicht noch kennen die weise Vollendung", "tokens": ["Wer\u00b7den", "wir", "nicht", "noch", "ken\u00b7nen", "die", "wei\u00b7se", "Vol\u00b7len\u00b7dung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Griechischer Kunst? und den Ausschmuck in der neuern?", "tokens": ["Grie\u00b7chi\u00b7scher", "Kunst", "?", "und", "den", "Aus\u00b7schmuck", "in", "der", "neu\u00b7ern", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "KON", "ART", "NN", "APPR", "ART", "ADJA", "$."], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nie gewahren, wie hoch der Wage", "tokens": ["Nie", "ge\u00b7wah\u00b7ren", ",", "wie", "hoch", "der", "Wa\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "PWAV", "ADJD", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Vollere Schale sich hebt?", "tokens": ["Vol\u00b7le\u00b7re", "Scha\u00b7le", "sich", "hebt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.7": {"line.1": {"text": "Sondern noch einst vom Sch\u00f6nen die Art, des Bewunderns", "tokens": ["Son\u00b7dern", "noch", "einst", "vom", "Sch\u00f6\u00b7nen", "die", "Art", ",", "des", "Be\u00b7wun\u00b7derns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "M\u00fcde, was all vor Bezaubrung in der Art sey?", "tokens": ["M\u00fc\u00b7de", ",", "was", "all", "vor", "Be\u00b7zaub\u00b7rung", "in", "der", "Art", "sey", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIAT", "APPR", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Sch\u00f6nheit giebt das Gesetz! zu Ausart,", "tokens": ["Sch\u00f6n\u00b7heit", "giebt", "das", "Ge\u00b7setz", "!", "zu", "Au\u00b7sart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$.", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wenn sie nicht huldigt, wird Art.", "tokens": ["Wenn", "sie", "nicht", "hul\u00b7digt", ",", "wird", "Art", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.8": {"line.1": {"text": "Wenn er verkent den Lorber, der mehr dem Dictator", "tokens": ["Wenn", "er", "ver\u00b7kent", "den", "Lor\u00b7ber", ",", "der", "mehr", "dem", "Dic\u00b7ta\u00b7tor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "War, wie Triumph; wird zur, Ahndung ihm nicht Scham gl\u00fchn?", "tokens": ["War", ",", "wie", "Tri\u00b7umph", ";", "wird", "zur", ",", "Ahn\u00b7dung", "ihm", "nicht", "Scham", "gl\u00fchn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "NN", "$.", "VAFIN", "APPRART", "$,", "NN", "PPER", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Denn wen nant' ich! so gross war Zesar,", "tokens": ["Denn", "wen", "nant'", "ich", "!", "so", "gross", "war", "Ze\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "ADV", "ADJD", "VAFIN", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Dass er nur Brutus nicht glich!", "tokens": ["Dass", "er", "nur", "Bru\u00b7tus", "nicht", "glich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.9": {"line.1": {"text": "Sehn wir nicht einst, wo gleichen sich darf, wer nur nachahmt,", "tokens": ["Sehn", "wir", "nicht", "einst", ",", "wo", "glei\u00b7chen", "sich", "darf", ",", "wer", "nur", "nac\u00b7hahmt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "$,", "PWAV", "VVFIN", "PRF", "VMFIN", "$,", "PWS", "ADV", "VVFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gar die Gestalt von dem Urbild noch verwahrlost,", "tokens": ["Gar", "die", "Ge\u00b7stalt", "von", "dem", "Ur\u00b7bild", "noch", "ver\u00b7wahr\u00b7lost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Der dem Griechen, da sey die vollste", "tokens": ["Der", "dem", "Grie\u00b7chen", ",", "da", "sey", "die", "volls\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "$,", "ADV", "VAFIN", "ART", "ADJA"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "B\u00fchne der L\u00e4cherlichkeit?", "tokens": ["B\u00fch\u00b7ne", "der", "L\u00e4\u00b7cher\u00b7lich\u00b7keit", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.10": {"line.1": {"text": "Sehen noch einst, wo gleichen sich darf, wer nur lernet,", "tokens": ["Se\u00b7hen", "noch", "einst", ",", "wo", "glei\u00b7chen", "sich", "darf", ",", "wer", "nur", "ler\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$,", "PWAV", "VVFIN", "PRF", "VMFIN", "$,", "PWS", "ADV", "VVFIN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Gar den Erguss des Erfinders noch mit Schlamm tr\u00fcbt',", "tokens": ["Gar", "den", "Er\u00b7guss", "des", "Er\u00b7fin\u00b7ders", "noch", "mit", "Schlamm", "tr\u00fcbt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "s' Kind dem Manne, da rag's von hohen", "tokens": ["s'", "Kind", "dem", "Man\u00b7ne", ",", "da", "rag's", "von", "ho\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN", "$,", "KOUS", "NE", "APPR", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ohren, nicht leerer, hervor?", "tokens": ["Oh\u00b7ren", ",", "nicht", "lee\u00b7rer", ",", "her\u00b7vor", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "ADJD", "$,", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.11": {"line.1": {"text": "Wird sich der Schwatz nie enden, der Philosophie heisst?", "tokens": ["Wird", "sich", "der", "Schwatz", "nie", "en\u00b7den", ",", "der", "Phi\u00b7lo\u00b7so\u00b7phie", "heisst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "ADV", "VVINF", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Werden daf\u00fcr die Ergr\u00fcndung, wo nicht Abgrund", "tokens": ["Wer\u00b7den", "da\u00b7f\u00fcr", "die", "Er\u00b7gr\u00fcn\u00b7dung", ",", "wo", "nicht", "Ab\u00b7grund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PAV", "ART", "NN", "$,", "PWAV", "PTKNEG", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist, Stillschweigen an ihm das Haupt nie", "tokens": ["Ist", ",", "Still\u00b7schwei\u00b7gen", "an", "ihm", "das", "Haupt", "nie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "NN", "APPR", "PPER", "ART", "NN", "ADV"], "meter": "-+--+--++", "measure": "prosodiakos"}, "line.4": {"text": "Heben, und herschende seyn?", "tokens": ["He\u00b7ben", ",", "und", "her\u00b7schen\u00b7de", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "ADJA", "VAINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.12": {"line.1": {"text": "Klimmen wir nie hinauf zu der H\u00f6h, wo nur wenig", "tokens": ["Klim\u00b7men", "wir", "nie", "hin\u00b7auf", "zu", "der", "H\u00f6h", ",", "wo", "nur", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,", "PWAV", "ADV", "PIS"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wahres, hier Spross, da Beschatter, dem Orkan steht,", "tokens": ["Wah\u00b7res", ",", "hier", "Spross", ",", "da", "Be\u00b7schat\u00b7ter", ",", "dem", "Or\u00b7kan", "steht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADV", "NN", "$,", "KOUS", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Und wohin du dem dichtverwachsnen", "tokens": ["Und", "wo\u00b7hin", "du", "dem", "dicht\u00b7ver\u00b7wachs\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wald' ohne Blut nicht entrinnst?", "tokens": ["Wald'", "oh\u00b7ne", "Blut", "nicht", "ent\u00b7rinnst", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.13": {"line.1": {"text": "Wenn sein Gesetz, sein Leben hinab vor dem Richtstuhl", "tokens": ["Wenn", "sein", "Ge\u00b7setz", ",", "sein", "Le\u00b7ben", "hin\u00b7ab", "vor", "dem", "Richt\u00b7stuhl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Herscher, er selbst durch ein neues noch verurtheilt;", "tokens": ["Her\u00b7scher", ",", "er", "selbst", "durch", "ein", "neu\u00b7es", "noch", "ver\u00b7urt\u00b7heilt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADV", "APPR", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ehrt' ihn da nicht zu sp\u00e4t die reinste", "tokens": ["Ehrt'", "ihn", "da", "nicht", "zu", "sp\u00e4t", "die", "reins\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "PTKA", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ehre der Obergewalt?", "tokens": ["Eh\u00b7re", "der", "O\u00b7ber\u00b7ge\u00b7walt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.14": {"line.1": {"text": "Sank er nur hier? Noch wirket es fort; wird wie Waldbrand", "tokens": ["Sank", "er", "nur", "hier", "?", "Noch", "wir\u00b7ket", "es", "fort", ";", "wird", "wie", "Wald\u00b7brand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "VAFIN", "KOKOM", "NN"], "meter": "+--+-+--++-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Lang' es noch gl\u00fchn, das Verkennen, das Verspotten", "tokens": ["Lang'", "es", "noch", "gl\u00fchn", ",", "das", "Ver\u00b7ken\u00b7nen", ",", "das", "Ver\u00b7spot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seiner Deutschen, und ach des Glaubens?", "tokens": ["Sei\u00b7ner", "Deut\u00b7schen", ",", "und", "ach", "des", "Glau\u00b7bens", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "XY", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Zauderer gruben den Brand", "tokens": ["Zau\u00b7de\u00b7rer", "gru\u00b7ben", "den", "Brand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.15": {"line.1": {"text": "L\u00e4ssiges Arms ab, lehnten sich oft auf den Spaden,", "tokens": ["L\u00e4s\u00b7si\u00b7ges", "Arms", "ab", ",", "lehn\u00b7ten", "sich", "oft", "auf", "den", "Spa\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Drangen nicht tief: und so kam's denn, und hin\u00fcber", "tokens": ["Dran\u00b7gen", "nicht", "tief", ":", "und", "so", "kam's", "denn", ",", "und", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "PTKNEG", "ADJD", "$.", "KON", "ADV", "VVFIN", "ADV", "$,", "KON", "ADV"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Leckt' es \u00fcber den Kindergraben,", "tokens": ["Leckt'", "es", "\u00fc\u00b7ber", "den", "Kin\u00b7der\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Lodert' in andres Geb\u00fcsch.", "tokens": ["Lo\u00b7dert'", "in", "and\u00b7res", "Ge\u00b7b\u00fcsch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.16": {"line.1": {"text": "Sieht er so scharf, wie uns Neuern es gleisst, die erstaunten,", "tokens": ["Sieht", "er", "so", "scharf", ",", "wie", "uns", "Neu\u00b7ern", "es", "gleisst", ",", "die", "er\u00b7staun\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Einen, wie ihn, auf dem Throne zu erblicken?", "tokens": ["Ei\u00b7nen", ",", "wie", "ihn", ",", "auf", "dem", "Thro\u00b7ne", "zu", "er\u00b7bli\u00b7cken", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "PPER", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Zeigt, wenn fester Entschluss das Herz ihm", "tokens": ["Zeigt", ",", "wenn", "fes\u00b7ter", "Ent\u00b7schluss", "das", "Herz", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADJA", "NN", "ART", "NN", "PPER"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "St\u00e4hlet, der Stolz ihn entflamt,", "tokens": ["St\u00e4h\u00b7let", ",", "der", "Stolz", "ihn", "ent\u00b7flamt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.17": {"line.1": {"text": "Tiefe diess auch des Denkens? diess etwa den Geist auch", "tokens": ["Tie\u00b7fe", "diess", "auch", "des", "Den\u00b7kens", "?", "diess", "et\u00b7wa", "den", "Geist", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PDS", "ADV", "ART", "NN", "$.", "PDS", "ADV", "ART", "NN", "ADV"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Dess, der nicht erbt die Beherschung, die schon da ist;", "tokens": ["Dess", ",", "der", "nicht", "erbt", "die", "Be\u00b7her\u00b7schung", ",", "die", "schon", "da", "ist", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PTKNEG", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Nein, Beherschung entwirft, ein Zesar,", "tokens": ["Nein", ",", "Be\u00b7her\u00b7schung", "ent\u00b7wirft", ",", "ein", "Ze\u00b7sar", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wandelt in That den Entwurf?", "tokens": ["Wan\u00b7delt", "in", "That", "den", "Ent\u00b7wurf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.18": {"line.1": {"text": "Oder gar dess, der denkender forscht, und nicht misstrent", "tokens": ["O\u00b7der", "gar", "dess", ",", "der", "den\u00b7ken\u00b7der", "forscht", ",", "und", "nicht", "miss\u00b7trent"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PDS", "$,", "PRELS", "PDS", "VVFIN", "$,", "KON", "PTKNEG", "VVPP"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gutes, und Geist? nicht um Land spielt mit des B\u00fcrgers", "tokens": ["Gu\u00b7tes", ",", "und", "Geist", "?", "nicht", "um", "Land", "spielt", "mit", "des", "B\u00fcr\u00b7gers"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "NN", "$.", "PTKNEG", "APPR", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Leben, da sich nicht th\u00f6rt, nicht w\u00e4hnt, Ruhm", "tokens": ["Le\u00b7ben", ",", "da", "sich", "nicht", "th\u00f6rt", ",", "nicht", "w\u00e4hnt", ",", "Ruhm"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "KOUS", "PRF", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wasche vom W\u00fcrfel das Blut?", "tokens": ["Wa\u00b7sche", "vom", "W\u00fcr\u00b7fel", "das", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.19": {"line.1": {"text": "Ehre w\u00fcsch' ab das schreckliche Blut? Sie verewigt's!", "tokens": ["Eh\u00b7re", "w\u00fcsch'", "ab", "das", "schreck\u00b7li\u00b7che", "Blut", "?", "Sie", "ver\u00b7ewigt's", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und ist es dann, wenn das Heer halb ins Gefild str\u00f6mt,", "tokens": ["Und", "ist", "es", "dann", ",", "wenn", "das", "Heer", "halb", "ins", "Ge\u00b7fild", "str\u00f6mt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nur unschuldig? nicht auch, wenn B\u00e4che", "tokens": ["Nur", "un\u00b7schul\u00b7dig", "?", "nicht", "auch", ",", "wenn", "B\u00e4\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$.", "PTKNEG", "ADV", "$,", "KOUS", "NN"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Rinnen, das F\u00e4hndel nicht droht?", "tokens": ["Rin\u00b7nen", ",", "das", "F\u00e4hn\u00b7del", "nicht", "droht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.20": {"line.1": {"text": "Rannen nicht viel der B\u00e4che, da sie, die Erobrung", "tokens": ["Ran\u00b7nen", "nicht", "viel", "der", "B\u00e4\u00b7che", ",", "da", "sie", ",", "die", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "$,", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Raste? nicht mehr, da Erfolg war, was Erfolg seyn", "tokens": ["Ras\u00b7te", "?", "nicht", "mehr", ",", "da", "Er\u00b7folg", "war", ",", "was", "Er\u00b7folg", "seyn"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PTKNEG", "ADV", "$,", "KOUS", "NN", "VAFIN", "$,", "PWS", "NN", "VAINF"], "meter": "+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Musste, Krieg, der beynah stets tr\u00e4chtig,", "tokens": ["Muss\u00b7te", ",", "Krieg", ",", "der", "bey\u00b7nah", "stets", "tr\u00e4ch\u00b7tig", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Schlacht dann, und Seuche dann warf?", "tokens": ["Schlacht", "dann", ",", "und", "Seu\u00b7che", "dann", "warf", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.21": {"line.1": {"text": "Lorber des F\u00fchrers dorret nicht weg, wenn ein Krieg auch", "tokens": ["Lor\u00b7ber", "des", "F\u00fch\u00b7rers", "dor\u00b7ret", "nicht", "weg", ",", "wenn", "ein", "Krieg", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Vor dem Gericht der Aurele, sich zur Schmach, steht:", "tokens": ["Vor", "dem", "Ge\u00b7richt", "der", "Au\u00b7re\u00b7le", ",", "sich", "zur", "Schmach", ",", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "PRF", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch die strahlendste Feldherrngr\u00f6sse", "tokens": ["Doch", "die", "strah\u00b7lends\u00b7te", "Feld\u00b7herrn\u00b7gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Schaffet den Scheusal nicht um!", "tokens": ["Schaf\u00b7fet", "den", "Scheu\u00b7sal", "nicht", "um", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.22": {"line.1": {"text": "Sch\u00f6n ist, und gut der Spruch des Gerichts der Aurele,", "tokens": ["Sch\u00f6n", "ist", ",", "und", "gut", "der", "Spruch", "des", "Ge\u00b7richts", "der", "Au\u00b7re\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "KON", "ADJD", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Weise: Kein Krieg kann gerecht seyn, so den tiefen", "tokens": ["Wei\u00b7se", ":", "Kein", "Krieg", "kann", "ge\u00b7recht", "seyn", ",", "so", "den", "tie\u00b7fen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PIAT", "NN", "VMFIN", "ADJD", "VAINF", "$,", "ADV", "ART", "ADJA"], "meter": "+--+--+---+-", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Grund legt ewiges Kriegs. Bet\u00fcncht ihn,", "tokens": ["Grund", "legt", "e\u00b7wi\u00b7ges", "Kriegs", ".", "Be\u00b7t\u00fcncht", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$.", "NN", "PPER", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Gleisst ihn; er wird nicht gerecht!", "tokens": ["Gleisst", "ihn", ";", "er", "wird", "nicht", "ge\u00b7recht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.23": {"line.1": {"text": "Gr\u00e4nzet es weit, das blutige Recht; nicht die Nothwehr", "tokens": ["Gr\u00e4n\u00b7zet", "es", "weit", ",", "das", "blu\u00b7ti\u00b7ge", "Recht", ";", "nicht", "die", "Noth\u00b7wehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ART", "ADJA", "NN", "$.", "PTKNEG", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hab' es allein! die Veredlung des Jahrhunderts", "tokens": ["Hab'", "es", "al\u00b7lein", "!", "die", "Ver\u00b7ed\u00b7lung", "des", "Jahr\u00b7hun\u00b7derts"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "$.", "ART", "NN", "ART", "NN"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Sey euch Schw\u00e4rmenden nichts, Throngottheit", "tokens": ["Sey", "euch", "Schw\u00e4r\u00b7men\u00b7den", "nichts", ",", "Thron\u00b7got\u00b7theit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "NN", "PIS", "$,", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Alles; er wird nicht gerecht!", "tokens": ["Al\u00b7les", ";", "er", "wird", "nicht", "ge\u00b7recht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.24": {"line.1": {"text": "Friede beascht jetzt schlummernde Glut: doch Erobrung", "tokens": ["Frie\u00b7de", "be\u00b7ascht", "jetzt", "schlum\u00b7mern\u00b7de", "Glut", ":", "doch", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADJA", "NN", "$.", "ADV", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wird nicht verziehn! und so bald sich mit der Zeiten.", "tokens": ["Wird", "nicht", "ver\u00b7ziehn", "!", "und", "so", "bald", "sich", "mit", "der", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVINF", "$.", "KON", "ADV", "ADV", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wechsel wirbelt ein Sturm; verfliegt die", "tokens": ["Wech\u00b7sel", "wir\u00b7belt", "ein", "Sturm", ";", "ver\u00b7fliegt", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "$.", "VVFIN", "ART"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Asche, wird Flamme die Glut!", "tokens": ["A\u00b7sche", ",", "wird", "Flam\u00b7me", "die", "Glut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.25": {"line.1": {"text": "Sah er vielleicht allein nicht vorher, was vor Aller", "tokens": ["Sah", "er", "viel\u00b7leicht", "al\u00b7lein", "nicht", "vor\u00b7her", ",", "was", "vor", "Al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "$,", "PRELS", "APPR", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Aug in der Fern unverh\u00fcllt lag, der Erobrung", "tokens": ["Aug", "in", "der", "Fern", "un\u00b7ver\u00b7h\u00fcllt", "lag", ",", "der", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ADJD", "VVFIN", "$,", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Jammererndte? nicht hundertf\u00e4ltig", "tokens": ["Jam\u00b7me\u00b7rernd\u00b7te", "?", "nicht", "hun\u00b7dert\u00b7f\u00e4l\u00b7tig"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "PTKNEG", "ADJD"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sprossen Gebein aus Gebein?", "tokens": ["Spros\u00b7sen", "Ge\u00b7bein", "aus", "Ge\u00b7bein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.26": {"line.1": {"text": "Himmel! er sah's, und that doch, er that, was Entsetzen", "tokens": ["Him\u00b7mel", "!", "er", "sah's", ",", "und", "that", "doch", ",", "er", "that", ",", "was", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "$,", "PWS", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Herschenden ist, die des Volkes, und die eigne", "tokens": ["Her\u00b7schen\u00b7den", "ist", ",", "die", "des", "Vol\u00b7kes", ",", "und", "die", "eig\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "PRELS", "ART", "NN", "$,", "KON", "ART", "ADJA"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Majest\u00e4t nicht entweihn, er that es,", "tokens": ["Ma\u00b7jes\u00b7t\u00e4t", "nicht", "ent\u00b7weihn", ",", "er", "that", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVINF", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Streute die schreckliche Saat!", "tokens": ["Streu\u00b7te", "die", "schreck\u00b7li\u00b7che", "Saat", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.27": {"line.1": {"text": "Tempe umrauscht sie wieder; doch geht die erhabne", "tokens": ["Tem\u00b7pe", "um\u00b7rauscht", "sie", "wie\u00b7der", ";", "doch", "geht", "die", "er\u00b7hab\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$.", "ADV", "VVFIN", "ART", "ADJA"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Priesterin, nur in der Reih mit, will des Tanzes", "tokens": ["Pries\u00b7te\u00b7rin", ",", "nur", "in", "der", "Reih", "mit", ",", "will", "des", "Tan\u00b7zes"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "VMFIN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nicht, ist tr\u00fcbe, wiewohl den Fl\u00f6ten", "tokens": ["Nicht", ",", "ist", "tr\u00fc\u00b7be", ",", "wie\u00b7wohl", "den", "Fl\u00f6\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "$,", "VAFIN", "ADJA", "$,", "KOUS", "ART", "NN"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Echo gelehriger horcht;", "tokens": ["E\u00b7cho", "ge\u00b7leh\u00b7ri\u00b7ger", "horcht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.28": {"line.1": {"text": "Frohes Gel\u00fcft die Staude beweht, und sein Leben", "tokens": ["Fro\u00b7hes", "Ge\u00b7l\u00fcft", "die", "Stau\u00b7de", "be\u00b7weht", ",", "und", "sein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hauchet, was sprosst, und sein Leben, was der Blumen", "tokens": ["Hau\u00b7chet", ",", "was", "sprosst", ",", "und", "sein", "Le\u00b7ben", ",", "was", "der", "Blu\u00b7men"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "VVFIN", "$,", "KON", "PPOSAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Kelche f\u00fcllet; zuletzt entlasten", "tokens": ["Kel\u00b7che", "f\u00fcl\u00b7let", ";", "zu\u00b7letzt", "ent\u00b7las\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "$.", "ADV", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Diese Gedanken ihr Herz:", "tokens": ["Die\u00b7se", "Ge\u00b7dan\u00b7ken", "ihr", "Herz", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPOSAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.29": {"line.1": {"text": "Feyert die Helden! Marmor und Erzt sey der Helden", "tokens": ["Fe\u00b7yert", "die", "Hel\u00b7den", "!", "Mar\u00b7mor", "und", "Erzt", "sey", "der", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$.", "NN", "KON", "NN", "VAFIN", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ewiges Maal! nicht der Marmor, und das Erzt nicht,", "tokens": ["E\u00b7wi\u00b7ges", "Maal", "!", "nicht", "der", "Mar\u00b7mor", ",", "und", "das", "Erzt", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PTKNEG", "ART", "NN", "$,", "KON", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mehr belohne, die Freude weine", "tokens": ["Mehr", "be\u00b7loh\u00b7ne", ",", "die", "Freu\u00b7de", "wei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "$,", "ART", "NN", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Denen, die Friedrich verzeihn!", "tokens": ["De\u00b7nen", ",", "die", "Fried\u00b7rich", "ver\u00b7zeihn", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "NE", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.30": {"line.1": {"text": "Ach aus dem Grabe kehr' ich zur\u00fcck, und mit Goldschrift", "tokens": ["Ach", "aus", "dem", "Gra\u00b7be", "kehr'", "ich", "zu\u00b7r\u00fcck", ",", "und", "mit", "Gold\u00b7schrift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "APPR", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Schreib' ich ans Maal der Erhabnen ... Die Entz\u00fcckung", "tokens": ["Schreib'", "ich", "ans", "Maal", "der", "Er\u00b7hab\u00b7nen", "...", "Die", "Ent\u00b7z\u00fc\u00b7ckung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$(", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Irrt mich, sie haben kein Maal! ihr Lohn sind", "tokens": ["Irrt", "mich", ",", "sie", "ha\u00b7ben", "kein", "Maal", "!", "ihr", "Lohn", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIAT", "NN", "$.", "PPOSAT", "NN", "VAFIN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Thr\u00e4nen! ich weine sie mit!", "tokens": ["Thr\u00e4\u00b7nen", "!", "ich", "wei\u00b7ne", "sie", "mit", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.31": {"line.1": {"text": "Aber erscheint auch einer, dem nicht die Verzeihung", "tokens": ["A\u00b7ber", "er\u00b7scheint", "auch", "ei\u00b7ner", ",", "dem", "nicht", "die", "Ver\u00b7zei\u00b7hung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PIS", "$,", "PRELS", "PTKNEG", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Selige Pflicht ist, vernim du der Aurele", "tokens": ["Se\u00b7li\u00b7ge", "Pflicht", "ist", ",", "ver\u00b7nim", "du", "der", "Au\u00b7re\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "+--+--+--+--", "measure": "dactylic.tetra"}, "line.3": {"text": "Zweyten Spruch: Wer erneut, dem fluche", "tokens": ["Zwey\u00b7ten", "Spruch", ":", "Wer", "er\u00b7neut", ",", "dem", "flu\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWS", "VVFIN", "$,", "ART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Selber der Siegende nach!", "tokens": ["Sel\u00b7ber", "der", "Sie\u00b7gen\u00b7de", "nach", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.32": {"line.1": {"text": "Sch\u00f6ne des Mays begeisterte sie, in des Griechen", "tokens": ["Sch\u00f6\u00b7ne", "des", "Mays", "be\u00b7geis\u00b7ter\u00b7te", "sie", ",", "in", "des", "Grie\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "ART", "NE", "VVFIN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Tage zur\u00fcck sich zu dichten; und ihr Spiel war", "tokens": ["Ta\u00b7ge", "zu\u00b7r\u00fcck", "sich", "zu", "dich\u00b7ten", ";", "und", "ihr", "Spiel", "war"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PTKVZ", "PRF", "APPR", "ADJA", "$.", "KON", "PPOSAT", "NN", "VAFIN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Manches jener Olympiaden,", "tokens": ["Man\u00b7ches", "je\u00b7ner", "O\u00b7lym\u00b7pia\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Welches verschwand, und noch ist!", "tokens": ["Wel\u00b7ches", "ver\u00b7schwand", ",", "und", "noch", "ist", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "KON", "ADV", "VAFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.33": {"line.1": {"text": "Manches, was Freud' in Tempe einst war, was in Elis", "tokens": ["Man\u00b7ches", ",", "was", "Freud'", "in", "Tem\u00b7pe", "einst", "war", ",", "was", "in", "E\u00b7lis"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "$,", "PWS", "NN", "APPR", "NE", "ADV", "VAFIN", "$,", "PRELS", "APPR", "NE"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Palmen erwarb durch den Wettlauf und durch Lieder:", "tokens": ["Pal\u00b7men", "er\u00b7warb", "durch", "den", "Wett\u00b7lauf", "und", "durch", "Lie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "KON", "APPR", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Hergang auch aus Homers Ges\u00e4ngen", "tokens": ["Her\u00b7gang", "auch", "aus", "Ho\u00b7mers", "Ge\u00b7s\u00e4n\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "APPR", "NE", "NN"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Zauberten sie bis zu sich.", "tokens": ["Zau\u00b7ber\u00b7ten", "sie", "bis", "zu", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "APPR", "PRF", "$."], "meter": "+---+-+", "measure": "dactylic.init"}}, "stanza.34": {"line.1": {"text": "Jetzo umgab sie heiliges Graun in dem Tempel Delphi.", "tokens": ["Jet\u00b7zo", "um\u00b7gab", "sie", "hei\u00b7li\u00b7ges", "Graun", "in", "dem", "Tem\u00b7pel", "Del\u00b7phi", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJA", "NN", "APPR", "ART", "NN", "NE", "$."], "meter": "+--+-+--+--+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Da sass auf dem Dreyfus, von des Lorbers", "tokens": ["Da", "sass", "auf", "dem", "Drey\u00b7fus", ",", "von", "des", "Lor\u00b7bers"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NE", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Opferdufte bew\u00f6lkt, die sch\u00f6ne", "tokens": ["Op\u00b7fer\u00b7duf\u00b7te", "be\u00b7w\u00f6lkt", ",", "die", "sch\u00f6\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVPP", "$,", "ART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Priesterin, str\u00e4ubendes Haars,", "tokens": ["Pries\u00b7te\u00b7rin", ",", "str\u00e4u\u00b7ben\u00b7des", "Haars", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.35": {"line.1": {"text": "Feurig den Blick; und Antwort erscholl dem Befrager.", "tokens": ["Feu\u00b7rig", "den", "Blick", ";", "und", "Ant\u00b7wort", "er\u00b7scholl", "dem", "Be\u00b7fra\u00b7ger", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ART", "NN", "$.", "KON", "NN", "ADJD", "ART", "NN", "$."], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Aber nun hob sie mit Eil sich von dem Dreyfuss.", "tokens": ["A\u00b7ber", "nun", "hob", "sie", "mit", "Eil", "sich", "von", "dem", "Drey\u00b7fuss", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "NN", "PRF", "APPR", "ART", "NN", "$."], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Komt, ihr sehet ihn leer, und jetzo", "tokens": ["Komt", ",", "ihr", "se\u00b7het", "ihn", "leer", ",", "und", "jet\u00b7zo"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,", "KON", "ADV"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Fraget die Priesterin euch!", "tokens": ["Fra\u00b7get", "die", "Pries\u00b7te\u00b7rin", "euch", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PPER", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.36": {"line.1": {"text": "\u00bbgehen wir nicht vielwegig zur\u00fcck? und wie lange", "tokens": ["\u00bb", "ge\u00b7hen", "wir", "nicht", "viel\u00b7we\u00b7gig", "zu\u00b7r\u00fcck", "?", "und", "wie", "lan\u00b7ge"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "VVFIN", "PPER", "PTKNEG", "ADJD", "PTKVZ", "$.", "KON", "PWAV", "ADV"], "meter": "+----+--+--+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Dauret es noch, dass, verwildert in der Irre,", "tokens": ["Dau\u00b7ret", "es", "noch", ",", "dass", ",", "ver\u00b7wil\u00b7dert", "in", "der", "Ir\u00b7re", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "$,", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Wir uns l\u00e4cheln? dass wir den Krebsgang", "tokens": ["Wir", "uns", "l\u00e4\u00b7cheln", "?", "dass", "wir", "den", "Krebs\u00b7gang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "VVFIN", "$.", "KOUS", "PPER", "ART", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Tr\u00e4umen zu Geniusflug?", "tokens": ["Tr\u00e4u\u00b7men", "zu", "Ge\u00b7nius\u00b7flug", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.37": {"line.1": {"text": "Werden wir nicht noch kennen die weise Vollendung", "tokens": ["Wer\u00b7den", "wir", "nicht", "noch", "ken\u00b7nen", "die", "wei\u00b7se", "Vol\u00b7len\u00b7dung"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Griechischer Kunst? und den Ausschmuck in der neuern?", "tokens": ["Grie\u00b7chi\u00b7scher", "Kunst", "?", "und", "den", "Aus\u00b7schmuck", "in", "der", "neu\u00b7ern", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "KON", "ART", "NN", "APPR", "ART", "ADJA", "$."], "meter": "+--+---+--+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Nie gewahren, wie hoch der Wage", "tokens": ["Nie", "ge\u00b7wah\u00b7ren", ",", "wie", "hoch", "der", "Wa\u00b7ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVINF", "$,", "PWAV", "ADJD", "ART", "NN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Vollere Schale sich hebt?", "tokens": ["Vol\u00b7le\u00b7re", "Scha\u00b7le", "sich", "hebt", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PRF", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.38": {"line.1": {"text": "Sondern noch einst vom Sch\u00f6nen die Art, des Bewunderns", "tokens": ["Son\u00b7dern", "noch", "einst", "vom", "Sch\u00f6\u00b7nen", "die", "Art", ",", "des", "Be\u00b7wun\u00b7derns"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ADV", "ADV", "APPRART", "NN", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "M\u00fcde, was all vor Bezaubrung in der Art sey?", "tokens": ["M\u00fc\u00b7de", ",", "was", "all", "vor", "Be\u00b7zaub\u00b7rung", "in", "der", "Art", "sey", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "PIAT", "APPR", "NN", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Sch\u00f6nheit giebt das Gesetz! zu Ausart,", "tokens": ["Sch\u00f6n\u00b7heit", "giebt", "das", "Ge\u00b7setz", "!", "zu", "Au\u00b7sart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$.", "APPR", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wenn sie nicht huldigt, wird Art.", "tokens": ["Wenn", "sie", "nicht", "hul\u00b7digt", ",", "wird", "Art", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VVFIN", "$,", "VAFIN", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.39": {"line.1": {"text": "Wenn er verkent den Lorber, der mehr dem Dictator", "tokens": ["Wenn", "er", "ver\u00b7kent", "den", "Lor\u00b7ber", ",", "der", "mehr", "dem", "Dic\u00b7ta\u00b7tor"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "War, wie Triumph; wird zur, Ahndung ihm nicht Scham gl\u00fchn?", "tokens": ["War", ",", "wie", "Tri\u00b7umph", ";", "wird", "zur", ",", "Ahn\u00b7dung", "ihm", "nicht", "Scham", "gl\u00fchn", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "PWAV", "NN", "$.", "VAFIN", "APPRART", "$,", "NN", "PPER", "PTKNEG", "NN", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Denn wen nant' ich! so gross war Zesar,", "tokens": ["Denn", "wen", "nant'", "ich", "!", "so", "gross", "war", "Ze\u00b7sar", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "PPER", "$.", "ADV", "ADJD", "VAFIN", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Dass er nur Brutus nicht glich!", "tokens": ["Dass", "er", "nur", "Bru\u00b7tus", "nicht", "glich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "NE", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.40": {"line.1": {"text": "Sehn wir nicht einst, wo gleichen sich darf, wer nur nachahmt,", "tokens": ["Sehn", "wir", "nicht", "einst", ",", "wo", "glei\u00b7chen", "sich", "darf", ",", "wer", "nur", "nac\u00b7hahmt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "ADV", "$,", "PWAV", "VVFIN", "PRF", "VMFIN", "$,", "PWS", "ADV", "VVFIN", "$,"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gar die Gestalt von dem Urbild noch verwahrlost,", "tokens": ["Gar", "die", "Ge\u00b7stalt", "von", "dem", "Ur\u00b7bild", "noch", "ver\u00b7wahr\u00b7lost", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Der dem Griechen, da sey die vollste", "tokens": ["Der", "dem", "Grie\u00b7chen", ",", "da", "sey", "die", "volls\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "$,", "ADV", "VAFIN", "ART", "ADJA"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "B\u00fchne der L\u00e4cherlichkeit?", "tokens": ["B\u00fch\u00b7ne", "der", "L\u00e4\u00b7cher\u00b7lich\u00b7keit", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.41": {"line.1": {"text": "Sehen noch einst, wo gleichen sich darf, wer nur lernet,", "tokens": ["Se\u00b7hen", "noch", "einst", ",", "wo", "glei\u00b7chen", "sich", "darf", ",", "wer", "nur", "ler\u00b7net", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "$,", "PWAV", "VVFIN", "PRF", "VMFIN", "$,", "PWS", "ADV", "VVFIN", "$,"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Gar den Erguss des Erfinders noch mit Schlamm tr\u00fcbt',", "tokens": ["Gar", "den", "Er\u00b7guss", "des", "Er\u00b7fin\u00b7ders", "noch", "mit", "Schlamm", "tr\u00fcbt'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "s' Kind dem Manne, da rag's von hohen", "tokens": ["s'", "Kind", "dem", "Man\u00b7ne", ",", "da", "rag's", "von", "ho\u00b7hen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "ART", "NN", "$,", "KOUS", "NE", "APPR", "ADJA"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ohren, nicht leerer, hervor?", "tokens": ["Oh\u00b7ren", ",", "nicht", "lee\u00b7rer", ",", "her\u00b7vor", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "PTKNEG", "ADJD", "$,", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.42": {"line.1": {"text": "Wird sich der Schwatz nie enden, der Philosophie heisst?", "tokens": ["Wird", "sich", "der", "Schwatz", "nie", "en\u00b7den", ",", "der", "Phi\u00b7lo\u00b7so\u00b7phie", "heisst", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ART", "NN", "ADV", "VVINF", "$,", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Werden daf\u00fcr die Ergr\u00fcndung, wo nicht Abgrund", "tokens": ["Wer\u00b7den", "da\u00b7f\u00fcr", "die", "Er\u00b7gr\u00fcn\u00b7dung", ",", "wo", "nicht", "Ab\u00b7grund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PAV", "ART", "NN", "$,", "PWAV", "PTKNEG", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Ist, Stillschweigen an ihm das Haupt nie", "tokens": ["Ist", ",", "Still\u00b7schwei\u00b7gen", "an", "ihm", "das", "Haupt", "nie"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "$,", "NN", "APPR", "PPER", "ART", "NN", "ADV"], "meter": "-+--+--++", "measure": "prosodiakos"}, "line.4": {"text": "Heben, und herschende seyn?", "tokens": ["He\u00b7ben", ",", "und", "her\u00b7schen\u00b7de", "seyn", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "ADJA", "VAINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.43": {"line.1": {"text": "Klimmen wir nie hinauf zu der H\u00f6h, wo nur wenig", "tokens": ["Klim\u00b7men", "wir", "nie", "hin\u00b7auf", "zu", "der", "H\u00f6h", ",", "wo", "nur", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,", "PWAV", "ADV", "PIS"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wahres, hier Spross, da Beschatter, dem Orkan steht,", "tokens": ["Wah\u00b7res", ",", "hier", "Spross", ",", "da", "Be\u00b7schat\u00b7ter", ",", "dem", "Or\u00b7kan", "steht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "$,", "ADV", "NN", "$,", "KOUS", "NN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Und wohin du dem dichtverwachsnen", "tokens": ["Und", "wo\u00b7hin", "du", "dem", "dicht\u00b7ver\u00b7wachs\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wald' ohne Blut nicht entrinnst?", "tokens": ["Wald'", "oh\u00b7ne", "Blut", "nicht", "ent\u00b7rinnst", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.44": {"line.1": {"text": "Wenn sein Gesetz, sein Leben hinab vor dem Richtstuhl", "tokens": ["Wenn", "sein", "Ge\u00b7setz", ",", "sein", "Le\u00b7ben", "hin\u00b7ab", "vor", "dem", "Richt\u00b7stuhl"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Herscher, er selbst durch ein neues noch verurtheilt;", "tokens": ["Her\u00b7scher", ",", "er", "selbst", "durch", "ein", "neu\u00b7es", "noch", "ver\u00b7urt\u00b7heilt", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ADV", "APPR", "ART", "ADJA", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Ehrt' ihn da nicht zu sp\u00e4t die reinste", "tokens": ["Ehrt'", "ihn", "da", "nicht", "zu", "sp\u00e4t", "die", "reins\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PTKNEG", "PTKA", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ehre der Obergewalt?", "tokens": ["Eh\u00b7re", "der", "O\u00b7ber\u00b7ge\u00b7walt", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.45": {"line.1": {"text": "Sank er nur hier? Noch wirket es fort; wird wie Waldbrand", "tokens": ["Sank", "er", "nur", "hier", "?", "Noch", "wir\u00b7ket", "es", "fort", ";", "wird", "wie", "Wald\u00b7brand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$.", "ADV", "VVFIN", "PPER", "PTKVZ", "$.", "VAFIN", "KOKOM", "NN"], "meter": "+--+-+--++-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Lang' es noch gl\u00fchn, das Verkennen, das Verspotten", "tokens": ["Lang'", "es", "noch", "gl\u00fchn", ",", "das", "Ver\u00b7ken\u00b7nen", ",", "das", "Ver\u00b7spot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["VVIMP", "PPER", "ADV", "VVINF", "$,", "ART", "NN", "$,", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Seiner Deutschen, und ach des Glaubens?", "tokens": ["Sei\u00b7ner", "Deut\u00b7schen", ",", "und", "ach", "des", "Glau\u00b7bens", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "KON", "XY", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Zauderer gruben den Brand", "tokens": ["Zau\u00b7de\u00b7rer", "gru\u00b7ben", "den", "Brand"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.46": {"line.1": {"text": "L\u00e4ssiges Arms ab, lehnten sich oft auf den Spaden,", "tokens": ["L\u00e4s\u00b7si\u00b7ges", "Arms", "ab", ",", "lehn\u00b7ten", "sich", "oft", "auf", "den", "Spa\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PTKVZ", "$,", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "$,"], "meter": "+-+-++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Drangen nicht tief: und so kam's denn, und hin\u00fcber", "tokens": ["Dran\u00b7gen", "nicht", "tief", ":", "und", "so", "kam's", "denn", ",", "und", "hin\u00b7\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "PTKNEG", "ADJD", "$.", "KON", "ADV", "VVFIN", "ADV", "$,", "KON", "ADV"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Leckt' es \u00fcber den Kindergraben,", "tokens": ["Leckt'", "es", "\u00fc\u00b7ber", "den", "Kin\u00b7der\u00b7gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Lodert' in andres Geb\u00fcsch.", "tokens": ["Lo\u00b7dert'", "in", "and\u00b7res", "Ge\u00b7b\u00fcsch", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.47": {"line.1": {"text": "Sieht er so scharf, wie uns Neuern es gleisst, die erstaunten,", "tokens": ["Sieht", "er", "so", "scharf", ",", "wie", "uns", "Neu\u00b7ern", "es", "gleisst", ",", "die", "er\u00b7staun\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "PPER", "VVFIN", "PPER", "VVFIN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+--+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Einen, wie ihn, auf dem Throne zu erblicken?", "tokens": ["Ei\u00b7nen", ",", "wie", "ihn", ",", "auf", "dem", "Thro\u00b7ne", "zu", "er\u00b7bli\u00b7cken", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "PPER", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Zeigt, wenn fester Entschluss das Herz ihm", "tokens": ["Zeigt", ",", "wenn", "fes\u00b7ter", "Ent\u00b7schluss", "das", "Herz", "ihm"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "KOUS", "ADJA", "NN", "ART", "NN", "PPER"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "St\u00e4hlet, der Stolz ihn entflamt,", "tokens": ["St\u00e4h\u00b7let", ",", "der", "Stolz", "ihn", "ent\u00b7flamt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.48": {"line.1": {"text": "Tiefe diess auch des Denkens? diess etwa den Geist auch", "tokens": ["Tie\u00b7fe", "diess", "auch", "des", "Den\u00b7kens", "?", "diess", "et\u00b7wa", "den", "Geist", "auch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PDS", "ADV", "ART", "NN", "$.", "PDS", "ADV", "ART", "NN", "ADV"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Dess, der nicht erbt die Beherschung, die schon da ist;", "tokens": ["Dess", ",", "der", "nicht", "erbt", "die", "Be\u00b7her\u00b7schung", ",", "die", "schon", "da", "ist", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "PTKNEG", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "ADV", "VAFIN", "$."], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Nein, Beherschung entwirft, ein Zesar,", "tokens": ["Nein", ",", "Be\u00b7her\u00b7schung", "ent\u00b7wirft", ",", "ein", "Ze\u00b7sar", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wandelt in That den Entwurf?", "tokens": ["Wan\u00b7delt", "in", "That", "den", "Ent\u00b7wurf", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.49": {"line.1": {"text": "Oder gar dess, der denkender forscht, und nicht misstrent", "tokens": ["O\u00b7der", "gar", "dess", ",", "der", "den\u00b7ken\u00b7der", "forscht", ",", "und", "nicht", "miss\u00b7trent"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PDS", "$,", "PRELS", "PDS", "VVFIN", "$,", "KON", "PTKNEG", "VVPP"], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Gutes, und Geist? nicht um Land spielt mit des B\u00fcrgers", "tokens": ["Gu\u00b7tes", ",", "und", "Geist", "?", "nicht", "um", "Land", "spielt", "mit", "des", "B\u00fcr\u00b7gers"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KON", "NN", "$.", "PTKNEG", "APPR", "NN", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Leben, da sich nicht th\u00f6rt, nicht w\u00e4hnt, Ruhm", "tokens": ["Le\u00b7ben", ",", "da", "sich", "nicht", "th\u00f6rt", ",", "nicht", "w\u00e4hnt", ",", "Ruhm"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["NN", "$,", "KOUS", "PRF", "PTKNEG", "VVFIN", "$,", "PTKNEG", "VVFIN", "$,", "NN"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Wasche vom W\u00fcrfel das Blut?", "tokens": ["Wa\u00b7sche", "vom", "W\u00fcr\u00b7fel", "das", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.50": {"line.1": {"text": "Ehre w\u00fcsch' ab das schreckliche Blut? Sie verewigt's!", "tokens": ["Eh\u00b7re", "w\u00fcsch'", "ab", "das", "schreck\u00b7li\u00b7che", "Blut", "?", "Sie", "ver\u00b7ewigt's", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "$."], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Und ist es dann, wenn das Heer halb ins Gefild str\u00f6mt,", "tokens": ["Und", "ist", "es", "dann", ",", "wenn", "das", "Heer", "halb", "ins", "Ge\u00b7fild", "str\u00f6mt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Nur unschuldig? nicht auch, wenn B\u00e4che", "tokens": ["Nur", "un\u00b7schul\u00b7dig", "?", "nicht", "auch", ",", "wenn", "B\u00e4\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ADJD", "$.", "PTKNEG", "ADV", "$,", "KOUS", "NN"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Rinnen, das F\u00e4hndel nicht droht?", "tokens": ["Rin\u00b7nen", ",", "das", "F\u00e4hn\u00b7del", "nicht", "droht", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.51": {"line.1": {"text": "Rannen nicht viel der B\u00e4che, da sie, die Erobrung", "tokens": ["Ran\u00b7nen", "nicht", "viel", "der", "B\u00e4\u00b7che", ",", "da", "sie", ",", "die", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "PTKNEG", "ADV", "ART", "NN", "$,", "KOUS", "PPER", "$,", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Raste? nicht mehr, da Erfolg war, was Erfolg seyn", "tokens": ["Ras\u00b7te", "?", "nicht", "mehr", ",", "da", "Er\u00b7folg", "war", ",", "was", "Er\u00b7folg", "seyn"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PTKNEG", "ADV", "$,", "KOUS", "NN", "VAFIN", "$,", "PWS", "NN", "VAINF"], "meter": "+-+++-+-+-+-", "measure": "unknown.measure.septa"}, "line.3": {"text": "Musste, Krieg, der beynah stets tr\u00e4chtig,", "tokens": ["Muss\u00b7te", ",", "Krieg", ",", "der", "bey\u00b7nah", "stets", "tr\u00e4ch\u00b7tig", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PRELS", "ADV", "ADV", "ADJD", "$,"], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Schlacht dann, und Seuche dann warf?", "tokens": ["Schlacht", "dann", ",", "und", "Seu\u00b7che", "dann", "warf", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "KON", "NN", "ADV", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.52": {"line.1": {"text": "Lorber des F\u00fchrers dorret nicht weg, wenn ein Krieg auch", "tokens": ["Lor\u00b7ber", "des", "F\u00fch\u00b7rers", "dor\u00b7ret", "nicht", "weg", ",", "wenn", "ein", "Krieg", "auch"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "VVFIN", "PTKNEG", "PTKVZ", "$,", "KOUS", "ART", "NN", "ADV"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Vor dem Gericht der Aurele, sich zur Schmach, steht:", "tokens": ["Vor", "dem", "Ge\u00b7richt", "der", "Au\u00b7re\u00b7le", ",", "sich", "zur", "Schmach", ",", "steht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$,", "PRF", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Doch die strahlendste Feldherrngr\u00f6sse", "tokens": ["Doch", "die", "strah\u00b7lends\u00b7te", "Feld\u00b7herrn\u00b7gr\u00f6s\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Schaffet den Scheusal nicht um!", "tokens": ["Schaf\u00b7fet", "den", "Scheu\u00b7sal", "nicht", "um", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.53": {"line.1": {"text": "Sch\u00f6n ist, und gut der Spruch des Gerichts der Aurele,", "tokens": ["Sch\u00f6n", "ist", ",", "und", "gut", "der", "Spruch", "des", "Ge\u00b7richts", "der", "Au\u00b7re\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "$,", "KON", "ADJD", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+--+-+--", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Weise: Kein Krieg kann gerecht seyn, so den tiefen", "tokens": ["Wei\u00b7se", ":", "Kein", "Krieg", "kann", "ge\u00b7recht", "seyn", ",", "so", "den", "tie\u00b7fen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "PIAT", "NN", "VMFIN", "ADJD", "VAINF", "$,", "ADV", "ART", "ADJA"], "meter": "+--+--+---+-", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Grund legt ewiges Kriegs. Bet\u00fcncht ihn,", "tokens": ["Grund", "legt", "e\u00b7wi\u00b7ges", "Kriegs", ".", "Be\u00b7t\u00fcncht", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJA", "NN", "$.", "NN", "PPER", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Gleisst ihn; er wird nicht gerecht!", "tokens": ["Gleisst", "ihn", ";", "er", "wird", "nicht", "ge\u00b7recht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.54": {"line.1": {"text": "Gr\u00e4nzet es weit, das blutige Recht; nicht die Nothwehr", "tokens": ["Gr\u00e4n\u00b7zet", "es", "weit", ",", "das", "blu\u00b7ti\u00b7ge", "Recht", ";", "nicht", "die", "Noth\u00b7wehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADJD", "$,", "ART", "ADJA", "NN", "$.", "PTKNEG", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hab' es allein! die Veredlung des Jahrhunderts", "tokens": ["Hab'", "es", "al\u00b7lein", "!", "die", "Ver\u00b7ed\u00b7lung", "des", "Jahr\u00b7hun\u00b7derts"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV", "$.", "ART", "NN", "ART", "NN"], "meter": "+--+--+--+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Sey euch Schw\u00e4rmenden nichts, Throngottheit", "tokens": ["Sey", "euch", "Schw\u00e4r\u00b7men\u00b7den", "nichts", ",", "Thron\u00b7got\u00b7theit"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "NN", "PIS", "$,", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Alles; er wird nicht gerecht!", "tokens": ["Al\u00b7les", ";", "er", "wird", "nicht", "ge\u00b7recht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$.", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.55": {"line.1": {"text": "Friede beascht jetzt schlummernde Glut: doch Erobrung", "tokens": ["Frie\u00b7de", "be\u00b7ascht", "jetzt", "schlum\u00b7mern\u00b7de", "Glut", ":", "doch", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "ADJA", "NN", "$.", "ADV", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Wird nicht verziehn! und so bald sich mit der Zeiten.", "tokens": ["Wird", "nicht", "ver\u00b7ziehn", "!", "und", "so", "bald", "sich", "mit", "der", "Zei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "VVINF", "$.", "KON", "ADV", "ADV", "PRF", "APPR", "ART", "NN", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Wechsel wirbelt ein Sturm; verfliegt die", "tokens": ["Wech\u00b7sel", "wir\u00b7belt", "ein", "Sturm", ";", "ver\u00b7fliegt", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "$.", "VVFIN", "ART"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Asche, wird Flamme die Glut!", "tokens": ["A\u00b7sche", ",", "wird", "Flam\u00b7me", "die", "Glut", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "NN", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.56": {"line.1": {"text": "Sah er vielleicht allein nicht vorher, was vor Aller", "tokens": ["Sah", "er", "viel\u00b7leicht", "al\u00b7lein", "nicht", "vor\u00b7her", ",", "was", "vor", "Al\u00b7ler"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADV", "$,", "PRELS", "APPR", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Aug in der Fern unverh\u00fcllt lag, der Erobrung", "tokens": ["Aug", "in", "der", "Fern", "un\u00b7ver\u00b7h\u00fcllt", "lag", ",", "der", "E\u00b7rob\u00b7rung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ADJD", "VVFIN", "$,", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Jammererndte? nicht hundertf\u00e4ltig", "tokens": ["Jam\u00b7me\u00b7rernd\u00b7te", "?", "nicht", "hun\u00b7dert\u00b7f\u00e4l\u00b7tig"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$.", "PTKNEG", "ADJD"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Sprossen Gebein aus Gebein?", "tokens": ["Spros\u00b7sen", "Ge\u00b7bein", "aus", "Ge\u00b7bein", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "APPR", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.57": {"line.1": {"text": "Himmel! er sah's, und that doch, er that, was Entsetzen", "tokens": ["Him\u00b7mel", "!", "er", "sah's", ",", "und", "that", "doch", ",", "er", "that", ",", "was", "Ent\u00b7set\u00b7zen"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "$.", "PPER", "VVFIN", "$,", "KON", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "$,", "PWS", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Herschenden ist, die des Volkes, und die eigne", "tokens": ["Her\u00b7schen\u00b7den", "ist", ",", "die", "des", "Vol\u00b7kes", ",", "und", "die", "eig\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "VAFIN", "$,", "PRELS", "ART", "NN", "$,", "KON", "ART", "ADJA"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Majest\u00e4t nicht entweihn, er that es,", "tokens": ["Ma\u00b7jes\u00b7t\u00e4t", "nicht", "ent\u00b7weihn", ",", "er", "that", "es", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "VVINF", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Streute die schreckliche Saat!", "tokens": ["Streu\u00b7te", "die", "schreck\u00b7li\u00b7che", "Saat", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.58": {"line.1": {"text": "Tempe umrauscht sie wieder; doch geht die erhabne", "tokens": ["Tem\u00b7pe", "um\u00b7rauscht", "sie", "wie\u00b7der", ";", "doch", "geht", "die", "er\u00b7hab\u00b7ne"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "$.", "ADV", "VVFIN", "ART", "ADJA"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Priesterin, nur in der Reih mit, will des Tanzes", "tokens": ["Pries\u00b7te\u00b7rin", ",", "nur", "in", "der", "Reih", "mit", ",", "will", "des", "Tan\u00b7zes"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,", "VMFIN", "ART", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Nicht, ist tr\u00fcbe, wiewohl den Fl\u00f6ten", "tokens": ["Nicht", ",", "ist", "tr\u00fc\u00b7be", ",", "wie\u00b7wohl", "den", "Fl\u00f6\u00b7ten"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "$,", "VAFIN", "ADJA", "$,", "KOUS", "ART", "NN"], "meter": "+-+-++-+-", "measure": "unknown.measure.penta"}, "line.4": {"text": "Echo gelehriger horcht;", "tokens": ["E\u00b7cho", "ge\u00b7leh\u00b7ri\u00b7ger", "horcht", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJA", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.59": {"line.1": {"text": "Frohes Gel\u00fcft die Staude beweht, und sein Leben", "tokens": ["Fro\u00b7hes", "Ge\u00b7l\u00fcft", "die", "Stau\u00b7de", "be\u00b7weht", ",", "und", "sein", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN", "VVFIN", "$,", "KON", "PPOSAT", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Hauchet, was sprosst, und sein Leben, was der Blumen", "tokens": ["Hau\u00b7chet", ",", "was", "sprosst", ",", "und", "sein", "Le\u00b7ben", ",", "was", "der", "Blu\u00b7men"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "VVFIN", "$,", "KON", "PPOSAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.3": {"text": "Kelche f\u00fcllet; zuletzt entlasten", "tokens": ["Kel\u00b7che", "f\u00fcl\u00b7let", ";", "zu\u00b7letzt", "ent\u00b7las\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "VVFIN", "$.", "ADV", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Diese Gedanken ihr Herz:", "tokens": ["Die\u00b7se", "Ge\u00b7dan\u00b7ken", "ihr", "Herz", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PPOSAT", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.60": {"line.1": {"text": "Feyert die Helden! Marmor und Erzt sey der Helden", "tokens": ["Fe\u00b7yert", "die", "Hel\u00b7den", "!", "Mar\u00b7mor", "und", "Erzt", "sey", "der", "Hel\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$.", "NN", "KON", "NN", "VAFIN", "ART", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Ewiges Maal! nicht der Marmor, und das Erzt nicht,", "tokens": ["E\u00b7wi\u00b7ges", "Maal", "!", "nicht", "der", "Mar\u00b7mor", ",", "und", "das", "Erzt", "nicht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PTKNEG", "ART", "NN", "$,", "KON", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Mehr belohne, die Freude weine", "tokens": ["Mehr", "be\u00b7loh\u00b7ne", ",", "die", "Freu\u00b7de", "wei\u00b7ne"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIAT", "ADJA", "$,", "ART", "NN", "VVFIN"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Denen, die Friedrich verzeihn!", "tokens": ["De\u00b7nen", ",", "die", "Fried\u00b7rich", "ver\u00b7zeihn", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PRELS", "NE", "VVINF", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.61": {"line.1": {"text": "Ach aus dem Grabe kehr' ich zur\u00fcck, und mit Goldschrift", "tokens": ["Ach", "aus", "dem", "Gra\u00b7be", "kehr'", "ich", "zu\u00b7r\u00fcck", ",", "und", "mit", "Gold\u00b7schrift"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "APPR", "NN"], "meter": "+--+-+--+--+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Schreib' ich ans Maal der Erhabnen ... Die Entz\u00fcckung", "tokens": ["Schreib'", "ich", "ans", "Maal", "der", "Er\u00b7hab\u00b7nen", "...", "Die", "Ent\u00b7z\u00fc\u00b7ckung"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "NN", "$(", "ART", "NN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Irrt mich, sie haben kein Maal! ihr Lohn sind", "tokens": ["Irrt", "mich", ",", "sie", "ha\u00b7ben", "kein", "Maal", "!", "ihr", "Lohn", "sind"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIAT", "NN", "$.", "PPOSAT", "NN", "VAFIN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Thr\u00e4nen! ich weine sie mit!", "tokens": ["Thr\u00e4\u00b7nen", "!", "ich", "wei\u00b7ne", "sie", "mit", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.62": {"line.1": {"text": "Aber erscheint auch einer, dem nicht die Verzeihung", "tokens": ["A\u00b7ber", "er\u00b7scheint", "auch", "ei\u00b7ner", ",", "dem", "nicht", "die", "Ver\u00b7zei\u00b7hung"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "PIS", "$,", "PRELS", "PTKNEG", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.2": {"text": "Selige Pflicht ist, vernim du der Aurele", "tokens": ["Se\u00b7li\u00b7ge", "Pflicht", "ist", ",", "ver\u00b7nim", "du", "der", "Au\u00b7re\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "+--+--+--+--", "measure": "dactylic.tetra"}, "line.3": {"text": "Zweyten Spruch: Wer erneut, dem fluche", "tokens": ["Zwey\u00b7ten", "Spruch", ":", "Wer", "er\u00b7neut", ",", "dem", "flu\u00b7che"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$.", "PWS", "VVFIN", "$,", "ART", "ADJA"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Selber der Siegende nach!", "tokens": ["Sel\u00b7ber", "der", "Sie\u00b7gen\u00b7de", "nach", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}}}}