{"textgrid.poem.31300": {"metadata": {"author": {"name": "Kleist, Heinrich von", "birth": "N.A.", "death": "N.A."}, "title": "Epilog", "genre": "verse", "period": "N.A.", "pub_year": 1794, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ruhig! Ruhig! Nur sacht! Das saust ja, Kronion, als wollten", "tokens": ["Ru\u00b7hig", "!", "Ru\u00b7hig", "!", "Nur", "sacht", "!", "Das", "saust", "ja", ",", "Kro\u00b7ni\u00b7on", ",", "als", "woll\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$.", "NE", "$.", "ADV", "VVFIN", "$.", "PDS", "VVFIN", "ADV", "$,", "NE", "$,", "KOUS", "VMFIN"], "meter": "---+-+-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Lenker und Wagen und Ro\u00df, st\u00fcrzend einschmettern zu Staub!", "tokens": ["Len\u00b7ker", "und", "Wa\u00b7gen", "und", "Ro\u00df", ",", "st\u00fcr\u00b7zend", "ein\u00b7schmet\u00b7tern", "zu", "Staub", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "KON", "NN", "$,", "ADJD", "PIS", "APPR", "NN", "$."], "meter": "+--+--++--+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Niemand, ersuch ich, \u00fcbergeprescht! Wir lieben die Fahrt schon,", "tokens": ["Nie\u00b7mand", ",", "er\u00b7such", "ich", ",", "\u00fc\u00b7ber\u00b7ge\u00b7prescht", "!", "Wir", "lie\u00b7ben", "die", "Fahrt", "schon", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "VVFIN", "PPER", "$,", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Munter gestellt, doch es sind H\u00e4ls uns und Beine uns lieb.", "tokens": ["Mun\u00b7ter", "ge\u00b7stellt", ",", "doch", "es", "sind", "H\u00e4ls", "uns", "und", "Bei\u00b7ne", "uns", "lieb", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "KON", "PPER", "VAFIN", "NN", "PPER", "KON", "NN", "PPER", "ADJD", "$."], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Dir fehlt nichts, als hinten der Schweif; auf der Warte zum mindsten", "tokens": ["Dir", "fehlt", "nichts", ",", "als", "hin\u00b7ten", "der", "Schweif", ";", "auf", "der", "War\u00b7te", "zum", "minds\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "$,", "KOUS", "ADV", "ART", "NN", "$.", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.6": {"text": "Wei\u00df noch versammelt die Zunft, nicht wo das aus will, wo ein.", "tokens": ["Wei\u00df", "noch", "ver\u00b7sam\u00b7melt", "die", "Zunft", ",", "nicht", "wo", "das", "aus", "will", ",", "wo", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "ART", "NN", "$,", "PTKNEG", "PWAV", "PDS", "APPR", "VMFIN", "$,", "PWAV", "PTKVZ", "$."], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.7": {"text": "F\u00fchr in die St\u00e4ll, ich bitte dich sehr, und la\u00df jetzt verschnaufen,", "tokens": ["F\u00fchr", "in", "die", "St\u00e4ll", ",", "ich", "bit\u00b7te", "dich", "sehr", ",", "und", "la\u00df", "jetzt", "ver\u00b7schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "KON", "VVIMP", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Da\u00df wir erw\u00e4gen zu Nacht, was wir geh\u00f6rt und gesehn.", "tokens": ["Da\u00df", "wir", "er\u00b7w\u00e4\u00b7gen", "zu", "Nacht", ",", "was", "wir", "ge\u00b7h\u00f6rt", "und", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Weit noch ist, die vorliegt, die Bahn, und mit Wasser, o Ph\u00f6bus,", "tokens": ["Weit", "noch", "ist", ",", "die", "vor\u00b7liegt", ",", "die", "Bahn", ",", "und", "mit", "Was\u00b7ser", ",", "o", "Ph\u00f6\u00b7bus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VAFIN", "$,", "PRELS", "VVPP", "$,", "ART", "NN", "$,", "KON", "APPR", "NN", "$,", "FM", "NE", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.10": {"text": "Was du den Rossen auch gibst, kochst du zuletzt doch, wie wir.", "tokens": ["Was", "du", "den", "Ros\u00b7sen", "auch", "gibst", ",", "kochst", "du", "zu\u00b7letzt", "doch", ",", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Dich auch seh ich noch schrittweis einher die prustenden f\u00fchren,", "tokens": ["Dich", "auch", "seh", "ich", "noch", "schritt\u00b7weis", "ein\u00b7her", "die", "prus\u00b7ten\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.12": {"text": "Und nicht immer, beim Zeus, sticht sie der Haber, wie heut.", "tokens": ["Und", "nicht", "im\u00b7mer", ",", "beim", "Zeus", ",", "sticht", "sie", "der", "Ha\u00b7ber", ",", "wie", "heut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "$,", "APPRART", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "$,", "PWAV", "ADV", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.2": {"line.1": {"text": "Ruhig! Ruhig! Nur sacht! Das saust ja, Kronion, als wollten", "tokens": ["Ru\u00b7hig", "!", "Ru\u00b7hig", "!", "Nur", "sacht", "!", "Das", "saust", "ja", ",", "Kro\u00b7ni\u00b7on", ",", "als", "woll\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$.", "NE", "$.", "ADV", "VVFIN", "$.", "PDS", "VVFIN", "ADV", "$,", "NE", "$,", "KOUS", "VMFIN"], "meter": "---+-+-+-+-+-+-", "measure": "unknown.measure.hexa"}, "line.2": {"text": "Lenker und Wagen und Ro\u00df, st\u00fcrzend einschmettern zu Staub!", "tokens": ["Len\u00b7ker", "und", "Wa\u00b7gen", "und", "Ro\u00df", ",", "st\u00fcr\u00b7zend", "ein\u00b7schmet\u00b7tern", "zu", "Staub", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "KON", "NN", "$,", "ADJD", "PIS", "APPR", "NN", "$."], "meter": "+--+--++--+--+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Niemand, ersuch ich, \u00fcbergeprescht! Wir lieben die Fahrt schon,", "tokens": ["Nie\u00b7mand", ",", "er\u00b7such", "ich", ",", "\u00fc\u00b7ber\u00b7ge\u00b7prescht", "!", "Wir", "lie\u00b7ben", "die", "Fahrt", "schon", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "VVFIN", "PPER", "$,", "VVPP", "$.", "PPER", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+--+-+--+-+--+-", "measure": "hexameter"}, "line.4": {"text": "Munter gestellt, doch es sind H\u00e4ls uns und Beine uns lieb.", "tokens": ["Mun\u00b7ter", "ge\u00b7stellt", ",", "doch", "es", "sind", "H\u00e4ls", "uns", "und", "Bei\u00b7ne", "uns", "lieb", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "KON", "PPER", "VAFIN", "NN", "PPER", "KON", "NN", "PPER", "ADJD", "$."], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.5": {"text": "Dir fehlt nichts, als hinten der Schweif; auf der Warte zum mindsten", "tokens": ["Dir", "fehlt", "nichts", ",", "als", "hin\u00b7ten", "der", "Schweif", ";", "auf", "der", "War\u00b7te", "zum", "minds\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIS", "$,", "KOUS", "ADV", "ART", "NN", "$.", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.6": {"text": "Wei\u00df noch versammelt die Zunft, nicht wo das aus will, wo ein.", "tokens": ["Wei\u00df", "noch", "ver\u00b7sam\u00b7melt", "die", "Zunft", ",", "nicht", "wo", "das", "aus", "will", ",", "wo", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVFIN", "ART", "NN", "$,", "PTKNEG", "PWAV", "PDS", "APPR", "VMFIN", "$,", "PWAV", "PTKVZ", "$."], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.7": {"text": "F\u00fchr in die St\u00e4ll, ich bitte dich sehr, und la\u00df jetzt verschnaufen,", "tokens": ["F\u00fchr", "in", "die", "St\u00e4ll", ",", "ich", "bit\u00b7te", "dich", "sehr", ",", "und", "la\u00df", "jetzt", "ver\u00b7schnau\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "KON", "VVIMP", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Da\u00df wir erw\u00e4gen zu Nacht, was wir geh\u00f6rt und gesehn.", "tokens": ["Da\u00df", "wir", "er\u00b7w\u00e4\u00b7gen", "zu", "Nacht", ",", "was", "wir", "ge\u00b7h\u00f6rt", "und", "ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVPP", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Weit noch ist, die vorliegt, die Bahn, und mit Wasser, o Ph\u00f6bus,", "tokens": ["Weit", "noch", "ist", ",", "die", "vor\u00b7liegt", ",", "die", "Bahn", ",", "und", "mit", "Was\u00b7ser", ",", "o", "Ph\u00f6\u00b7bus", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADV", "VAFIN", "$,", "PRELS", "VVPP", "$,", "ART", "NN", "$,", "KON", "APPR", "NN", "$,", "FM", "NE", "$,"], "meter": "+-+-+--+--+--+-", "measure": "hexameter"}, "line.10": {"text": "Was du den Rossen auch gibst, kochst du zuletzt doch, wie wir.", "tokens": ["Was", "du", "den", "Ros\u00b7sen", "auch", "gibst", ",", "kochst", "du", "zu\u00b7letzt", "doch", ",", "wie", "wir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADV", "VVFIN", "$,", "VVFIN", "PPER", "ADV", "ADV", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Dich auch seh ich noch schrittweis einher die prustenden f\u00fchren,", "tokens": ["Dich", "auch", "seh", "ich", "noch", "schritt\u00b7weis", "ein\u00b7her", "die", "prus\u00b7ten\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+--+-", "measure": "trochaic.septa.relaxed"}, "line.12": {"text": "Und nicht immer, beim Zeus, sticht sie der Haber, wie heut.", "tokens": ["Und", "nicht", "im\u00b7mer", ",", "beim", "Zeus", ",", "sticht", "sie", "der", "Ha\u00b7ber", ",", "wie", "heut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "$,", "APPRART", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "$,", "PWAV", "ADV", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}}}}