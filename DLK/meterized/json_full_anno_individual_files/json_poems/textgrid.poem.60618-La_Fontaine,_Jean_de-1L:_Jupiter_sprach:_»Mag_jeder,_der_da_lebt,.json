{"textgrid.poem.60618": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Jupiter sprach: \u00bbMag jeder, der da lebt,", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jupiter sprach: \u00bbMag jeder, der da lebt,", "tokens": ["Ju\u00b7pi\u00b7ter", "sprach", ":", "\u00bb", "Mag", "je\u00b7der", ",", "der", "da", "lebt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "$(", "VMFIN", "PIS", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "Erscheinen, um zu F\u00fc\u00dfen meiner Allmacht hier", "tokens": ["Er\u00b7schei\u00b7nen", ",", "um", "zu", "F\u00fc\u00b7\u00dfen", "mei\u00b7ner", "All\u00b7macht", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUI", "APPR", "NN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu \u00e4u\u00dfern, ob ihm etwas widerstrebt", "tokens": ["Zu", "\u00e4u\u00b7\u00dfern", ",", "ob", "ihm", "et\u00b7was", "wi\u00b7der\u00b7strebt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "An seiner Form, die er erhielt von mir;", "tokens": ["An", "sei\u00b7ner", "Form", ",", "die", "er", "er\u00b7hielt", "von", "mir", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man mag es offen sagen,", "tokens": ["Man", "mag", "es", "of\u00b7fen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich helfe ab den Klagen.", "tokens": ["Ich", "hel\u00b7fe", "ab", "den", "Kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dir, Affe, sei zuerst das Wort beschieden.", "tokens": ["Dir", ",", "Af\u00b7fe", ",", "sei", "zu\u00b7erst", "das", "Wort", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sieh alle an, vergleiche die Gestalten", "tokens": ["Sieh", "al\u00b7le", "an", ",", "ver\u00b7glei\u00b7che", "die", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PIS", "PTKVZ", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mit deiner, sage mir: bist du zufrieden?\u00ab", "tokens": ["Mit", "dei\u00b7ner", ",", "sa\u00b7ge", "mir", ":", "bist", "du", "zu\u00b7frie\u00b7den", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "$,", "VVFIN", "PPER", "$.", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbo ja! Ich darf mich f\u00fcr vollkommen halten.", "tokens": ["\u00bb", "o", "ja", "!", "Ich", "darf", "mich", "f\u00fcr", "voll\u00b7kom\u00b7men", "hal\u00b7ten", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADV", "$.", "PPER", "VMFIN", "PRF", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ich habe zwei Paar F\u00fc\u00dfe, wie die andern auch,", "tokens": ["Ich", "ha\u00b7be", "zwei", "Paar", "F\u00fc\u00b7\u00dfe", ",", "wie", "die", "an\u00b7dern", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "NN", "$,", "PWAV", "ART", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mein Bild ist gut. Doch scheint mir, da\u00df mein Bruder B\u00e4r", "tokens": ["Mein", "Bild", "ist", "gut", ".", "Doch", "scheint", "mir", ",", "da\u00df", "mein", "Bru\u00b7der", "B\u00e4r"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$.", "KON", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durchaus verpfuscht ist! Folgt er meinem Rat, der Gauch,", "tokens": ["Durc\u00b7haus", "ver\u00b7pfuscht", "ist", "!", "Folgt", "er", "mei\u00b7nem", "Rat", ",", "der", "Gauch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So l\u00e4\u00dft er nie sich malen.\u00ab Kam der B\u00e4r daher;", "tokens": ["So", "l\u00e4\u00dft", "er", "nie", "sich", "ma\u00b7len", ".", "\u00ab", "Kam", "der", "B\u00e4r", "da\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "VVINF", "$.", "$(", "NE", "ART", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man glaubte: um sich zu beklagen.", "tokens": ["Man", "glaub\u00b7te", ":", "um", "sich", "zu", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$.", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nein, weit gefehlt! Er lobte seinen K\u00f6rper sehr,", "tokens": ["Nein", ",", "weit", "ge\u00b7fehlt", "!", "Er", "lob\u00b7te", "sei\u00b7nen", "K\u00f6r\u00b7per", "sehr", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "VVPP", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Doch h\u00f6rte man ihn dies vom Elefanten sagen:", "tokens": ["Doch", "h\u00f6r\u00b7te", "man", "ihn", "dies", "vom", "E\u00b7lef\u00b7an\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "PDS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zu k\u00e4rglich sei sein Schwanz, sein Ohr zu lang und breit,", "tokens": ["Zu", "k\u00e4rg\u00b7lich", "sei", "sein", "Schwanz", ",", "sein", "Ohr", "zu", "lang", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "PTKA", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er sei zu massig, viel zu schwer.", "tokens": ["Er", "sei", "zu", "mas\u00b7sig", ",", "viel", "zu", "schwer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Der Elefant trat vor voll Selbstgef\u00e4lligkeit,", "tokens": ["Der", "E\u00b7le\u00b7fant", "trat", "vor", "voll", "Selbst\u00b7ge\u00b7f\u00e4l\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und er, der Weise, kramte aus demselben Sack:", "tokens": ["Und", "er", ",", "der", "Wei\u00b7se", ",", "kram\u00b7te", "aus", "dem\u00b7sel\u00b7ben", "Sack", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Frau Walfisch sei zu dick, durchaus nicht sein Geschmack.", "tokens": ["Frau", "Wal\u00b7fisch", "sei", "zu", "dick", ",", "durc\u00b7haus", "nicht", "sein", "Ge\u00b7schmack", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PTKA", "ADJD", "$,", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die Ameis sprach, die K\u00e4semilbe sei ein Zwerg,", "tokens": ["Die", "Am\u00b7eis", "sprach", ",", "die", "K\u00e4\u00b7se\u00b7mil\u00b7be", "sei", "ein", "Zwerg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Sie hielt sich neben ihr f\u00fcr einen ganzen Berg.", "tokens": ["Sie", "hielt", "sich", "ne\u00b7ben", "ihr", "f\u00fcr", "ei\u00b7nen", "gan\u00b7zen", "Berg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Jupiter hie\u00df sie alle weiterwandern,", "tokens": ["Ju\u00b7pi\u00b7ter", "hie\u00df", "sie", "al\u00b7le", "wei\u00b7ter\u00b7wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Da alle nur f\u00fcr andre sich beklagten.", "tokens": ["Da", "al\u00b7le", "nur", "f\u00fcr", "and\u00b7re", "sich", "be\u00b7klag\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PIS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Am h\u00f6chsten in der Tollheit aber ragten", "tokens": ["Am", "h\u00f6chs\u00b7ten", "in", "der", "Toll\u00b7heit", "a\u00b7ber", "rag\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "APPR", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Und Maulwurf vor sich selbst, glaubt gut sich jedermann,", "tokens": ["Und", "Maul\u00b7wurf", "vor", "sich", "selbst", ",", "glaubt", "gut", "sich", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PRF", "ADV", "$,", "VVFIN", "ADJD", "PRF", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Doch h\u00e4\u00dflich sind die N\u00e4chsten, die durchaus nichts taugen:", "tokens": ["Doch", "h\u00e4\u00df\u00b7lich", "sind", "die", "N\u00e4chs\u00b7ten", ",", "die", "durc\u00b7haus", "nichts", "tau\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.30": {"text": "Sich sieht man mit ganz andern Augen", "tokens": ["Sich", "sieht", "man", "mit", "ganz", "an\u00b7dern", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "PIS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Als seinen lieben Nachbar an.", "tokens": ["Als", "sei\u00b7nen", "lie\u00b7ben", "Nach\u00b7bar", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Als Quersacktr\u00e4ger l\u00e4\u00dft uns Gott durchs Leben wandern.", "tokens": ["Als", "Quer\u00b7sack\u00b7tr\u00e4\u00b7ger", "l\u00e4\u00dft", "uns", "Gott", "durchs", "Le\u00b7ben", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich kenne keinen, den ich hiervon sauber wasche:", "tokens": ["Ich", "ken\u00b7ne", "kei\u00b7nen", ",", "den", "ich", "hier\u00b7von", "sau\u00b7ber", "wa\u00b7sche", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "$,", "PRELS", "PPER", "PAV", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr eigne M\u00e4ngel dient des Quersacks Hintertasche,", "tokens": ["F\u00fcr", "eig\u00b7ne", "M\u00e4n\u00b7gel", "dient", "des", "Quer\u00b7sacks", "Hin\u00b7ter\u00b7ta\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die vordre ist gef\u00fcllt mit Fehlern all der andern.", "tokens": ["Die", "vor\u00b7dre", "ist", "ge\u00b7f\u00fcllt", "mit", "Feh\u00b7lern", "all", "der", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVPP", "APPR", "NN", "PIAT", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Jupiter sprach: \u00bbMag jeder, der da lebt,", "tokens": ["Ju\u00b7pi\u00b7ter", "sprach", ":", "\u00bb", "Mag", "je\u00b7der", ",", "der", "da", "lebt", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$.", "$(", "VMFIN", "PIS", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.2": {"text": "Erscheinen, um zu F\u00fc\u00dfen meiner Allmacht hier", "tokens": ["Er\u00b7schei\u00b7nen", ",", "um", "zu", "F\u00fc\u00b7\u00dfen", "mei\u00b7ner", "All\u00b7macht", "hier"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUI", "APPR", "NN", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu \u00e4u\u00dfern, ob ihm etwas widerstrebt", "tokens": ["Zu", "\u00e4u\u00b7\u00dfern", ",", "ob", "ihm", "et\u00b7was", "wi\u00b7der\u00b7strebt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "KOUS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "An seiner Form, die er erhielt von mir;", "tokens": ["An", "sei\u00b7ner", "Form", ",", "die", "er", "er\u00b7hielt", "von", "mir", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Man mag es offen sagen,", "tokens": ["Man", "mag", "es", "of\u00b7fen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Ich helfe ab den Klagen.", "tokens": ["Ich", "hel\u00b7fe", "ab", "den", "Kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dir, Affe, sei zuerst das Wort beschieden.", "tokens": ["Dir", ",", "Af\u00b7fe", ",", "sei", "zu\u00b7erst", "das", "Wort", "be\u00b7schie\u00b7den", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NN", "$,", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sieh alle an, vergleiche die Gestalten", "tokens": ["Sieh", "al\u00b7le", "an", ",", "ver\u00b7glei\u00b7che", "die", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PIS", "PTKVZ", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Mit deiner, sage mir: bist du zufrieden?\u00ab", "tokens": ["Mit", "dei\u00b7ner", ",", "sa\u00b7ge", "mir", ":", "bist", "du", "zu\u00b7frie\u00b7den", "?", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "$,", "VVFIN", "PPER", "$.", "VAFIN", "PPER", "ADJD", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbo ja! Ich darf mich f\u00fcr vollkommen halten.", "tokens": ["\u00bb", "o", "ja", "!", "Ich", "darf", "mich", "f\u00fcr", "voll\u00b7kom\u00b7men", "hal\u00b7ten", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "ADV", "$.", "PPER", "VMFIN", "PRF", "APPR", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ich habe zwei Paar F\u00fc\u00dfe, wie die andern auch,", "tokens": ["Ich", "ha\u00b7be", "zwei", "Paar", "F\u00fc\u00b7\u00dfe", ",", "wie", "die", "an\u00b7dern", "auch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "NN", "$,", "PWAV", "ART", "ADJA", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mein Bild ist gut. Doch scheint mir, da\u00df mein Bruder B\u00e4r", "tokens": ["Mein", "Bild", "ist", "gut", ".", "Doch", "scheint", "mir", ",", "da\u00df", "mein", "Bru\u00b7der", "B\u00e4r"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$.", "KON", "VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Durchaus verpfuscht ist! Folgt er meinem Rat, der Gauch,", "tokens": ["Durc\u00b7haus", "ver\u00b7pfuscht", "ist", "!", "Folgt", "er", "mei\u00b7nem", "Rat", ",", "der", "Gauch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$.", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So l\u00e4\u00dft er nie sich malen.\u00ab Kam der B\u00e4r daher;", "tokens": ["So", "l\u00e4\u00dft", "er", "nie", "sich", "ma\u00b7len", ".", "\u00ab", "Kam", "der", "B\u00e4r", "da\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "VVINF", "$.", "$(", "NE", "ART", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Man glaubte: um sich zu beklagen.", "tokens": ["Man", "glaub\u00b7te", ":", "um", "sich", "zu", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$.", "APPR", "PRF", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nein, weit gefehlt! Er lobte seinen K\u00f6rper sehr,", "tokens": ["Nein", ",", "weit", "ge\u00b7fehlt", "!", "Er", "lob\u00b7te", "sei\u00b7nen", "K\u00f6r\u00b7per", "sehr", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADJD", "VVPP", "$.", "PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Doch h\u00f6rte man ihn dies vom Elefanten sagen:", "tokens": ["Doch", "h\u00f6r\u00b7te", "man", "ihn", "dies", "vom", "E\u00b7lef\u00b7an\u00b7ten", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "PDS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zu k\u00e4rglich sei sein Schwanz, sein Ohr zu lang und breit,", "tokens": ["Zu", "k\u00e4rg\u00b7lich", "sei", "sein", "Schwanz", ",", "sein", "Ohr", "zu", "lang", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "PTKA", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Er sei zu massig, viel zu schwer.", "tokens": ["Er", "sei", "zu", "mas\u00b7sig", ",", "viel", "zu", "schwer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKA", "ADJD", "$,", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Der Elefant trat vor voll Selbstgef\u00e4lligkeit,", "tokens": ["Der", "E\u00b7le\u00b7fant", "trat", "vor", "voll", "Selbst\u00b7ge\u00b7f\u00e4l\u00b7lig\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und er, der Weise, kramte aus demselben Sack:", "tokens": ["Und", "er", ",", "der", "Wei\u00b7se", ",", "kram\u00b7te", "aus", "dem\u00b7sel\u00b7ben", "Sack", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ART", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Frau Walfisch sei zu dick, durchaus nicht sein Geschmack.", "tokens": ["Frau", "Wal\u00b7fisch", "sei", "zu", "dick", ",", "durc\u00b7haus", "nicht", "sein", "Ge\u00b7schmack", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "PTKA", "ADJD", "$,", "ADV", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Die Ameis sprach, die K\u00e4semilbe sei ein Zwerg,", "tokens": ["Die", "Am\u00b7eis", "sprach", ",", "die", "K\u00e4\u00b7se\u00b7mil\u00b7be", "sei", "ein", "Zwerg", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Sie hielt sich neben ihr f\u00fcr einen ganzen Berg.", "tokens": ["Sie", "hielt", "sich", "ne\u00b7ben", "ihr", "f\u00fcr", "ei\u00b7nen", "gan\u00b7zen", "Berg", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Jupiter hie\u00df sie alle weiterwandern,", "tokens": ["Ju\u00b7pi\u00b7ter", "hie\u00df", "sie", "al\u00b7le", "wei\u00b7ter\u00b7wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Da alle nur f\u00fcr andre sich beklagten.", "tokens": ["Da", "al\u00b7le", "nur", "f\u00fcr", "and\u00b7re", "sich", "be\u00b7klag\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "APPR", "PIS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.27": {"text": "Am h\u00f6chsten in der Tollheit aber ragten", "tokens": ["Am", "h\u00f6chs\u00b7ten", "in", "der", "Toll\u00b7heit", "a\u00b7ber", "rag\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "APPR", "ART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Und Maulwurf vor sich selbst, glaubt gut sich jedermann,", "tokens": ["Und", "Maul\u00b7wurf", "vor", "sich", "selbst", ",", "glaubt", "gut", "sich", "je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PRF", "ADV", "$,", "VVFIN", "ADJD", "PRF", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Doch h\u00e4\u00dflich sind die N\u00e4chsten, die durchaus nichts taugen:", "tokens": ["Doch", "h\u00e4\u00df\u00b7lich", "sind", "die", "N\u00e4chs\u00b7ten", ",", "die", "durc\u00b7haus", "nichts", "tau\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+++-+-", "measure": "unknown.measure.septa"}, "line.30": {"text": "Sich sieht man mit ganz andern Augen", "tokens": ["Sich", "sieht", "man", "mit", "ganz", "an\u00b7dern", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PRF", "VVFIN", "PIS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Als seinen lieben Nachbar an.", "tokens": ["Als", "sei\u00b7nen", "lie\u00b7ben", "Nach\u00b7bar", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Als Quersacktr\u00e4ger l\u00e4\u00dft uns Gott durchs Leben wandern.", "tokens": ["Als", "Quer\u00b7sack\u00b7tr\u00e4\u00b7ger", "l\u00e4\u00dft", "uns", "Gott", "durchs", "Le\u00b7ben", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVFIN", "PPER", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich kenne keinen, den ich hiervon sauber wasche:", "tokens": ["Ich", "ken\u00b7ne", "kei\u00b7nen", ",", "den", "ich", "hier\u00b7von", "sau\u00b7ber", "wa\u00b7sche", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "$,", "PRELS", "PPER", "PAV", "ADJD", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "F\u00fcr eigne M\u00e4ngel dient des Quersacks Hintertasche,", "tokens": ["F\u00fcr", "eig\u00b7ne", "M\u00e4n\u00b7gel", "dient", "des", "Quer\u00b7sacks", "Hin\u00b7ter\u00b7ta\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die vordre ist gef\u00fcllt mit Fehlern all der andern.", "tokens": ["Die", "vor\u00b7dre", "ist", "ge\u00b7f\u00fcllt", "mit", "Feh\u00b7lern", "all", "der", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VAFIN", "VVPP", "APPR", "NN", "PIAT", "ART", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}