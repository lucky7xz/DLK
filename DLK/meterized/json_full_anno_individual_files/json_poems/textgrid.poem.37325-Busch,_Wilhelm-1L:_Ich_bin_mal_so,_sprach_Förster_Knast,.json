{"textgrid.poem.37325": {"metadata": {"author": {"name": "Busch, Wilhelm", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich bin mal so, sprach F\u00f6rster Knast,", "genre": "verse", "period": "N.A.", "pub_year": 1870, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin mal so, sprach F\u00f6rster Knast,", "tokens": ["Ich", "bin", "mal", "so", ",", "sprach", "F\u00f6rs\u00b7ter", "Knast", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Flunkerei ist mir verha\u00dft,", "tokens": ["Die", "Flun\u00b7ke\u00b7rei", "ist", "mir", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch sieht man oft was Sonderbares.", "tokens": ["Doch", "sieht", "man", "oft", "was", "Son\u00b7der\u00b7ba\u00b7res", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "PWS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Im Fr\u00fchling vor f\u00fcnf Jahren war es,", "tokens": ["Im", "Fr\u00fch\u00b7ling", "vor", "f\u00fcnf", "Jah\u00b7ren", "war", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "CARD", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als ich stockstill, den Hahn gespannt,", "tokens": ["Als", "ich", "stock\u00b7still", ",", "den", "Hahn", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei Mondschein vor dem Walde stand.", "tokens": ["Bei", "Mond\u00b7schein", "vor", "dem", "Wal\u00b7de", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da l\u00e4\u00dft sich pl\u00f6tzlich fl\u00fcgelsausend", "tokens": ["Da", "l\u00e4\u00dft", "sich", "pl\u00f6tz\u00b7lich", "fl\u00fc\u00b7gel\u00b7sau\u00b7send"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Kranichheer, wohl an die tausend,", "tokens": ["Ein", "Kra\u00b7nich\u00b7heer", ",", "wohl", "an", "die", "tau\u00b7send", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "ART", "CARD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ganz dicht zu meinen F\u00fc\u00dfen nieder.", "tokens": ["Ganz", "dicht", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie kamen aus \u00c4gypten wieder", "tokens": ["Sie", "ka\u00b7men", "aus", "\u00c4\u00b7gyp\u00b7ten", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und dachten auf der Reise nun", "tokens": ["Und", "dach\u00b7ten", "auf", "der", "Rei\u00b7se", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sich hier ein St\u00fcndchen auszuruhn.", "tokens": ["Sich", "hier", "ein", "St\u00fcnd\u00b7chen", "aus\u00b7zu\u00b7ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich selbstverst\u00e4ndlich, schlau und sacht,", "tokens": ["Ich", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", ",", "schlau", "und", "sacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab sehr genau auf alles acht.", "tokens": ["Gab", "sehr", "ge\u00b7nau", "auf", "al\u00b7les", "acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "PIS", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Du, Hans, so rief der Oberkranich,", "tokens": ["Du", ",", "Hans", ",", "so", "rief", "der", "O\u00b7ber\u00b7kra\u00b7nich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hast heut die Wache, drum ermahn ich", "tokens": ["Hast", "heut", "die", "Wa\u00b7che", ",", "drum", "er\u00b7mahn", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PAV", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dich ernstlich, halt dich stramm und pa\u00df", "tokens": ["Dich", "ernst\u00b7lich", ",", "halt", "dich", "stramm", "und", "pa\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "$,", "VVFIN", "PPER", "VVFIN", "KON", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00f6rig auf, sonst gibt es was.", "tokens": ["Ge\u00b7h\u00f6\u00b7rig", "auf", ",", "sonst", "gibt", "es", "was", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Bald schlief ein jeder ein und s\u00e4gte.", "tokens": ["Bald", "schlief", "ein", "je\u00b7der", "ein", "und", "s\u00e4g\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "ART", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hans aber stand und \u00fcberlegte.", "tokens": ["Hans", "a\u00b7ber", "stand", "und", "\u00fc\u00b7ber\u00b7leg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Er nahm sich einen Kieselstein,", "tokens": ["Er", "nahm", "sich", "ei\u00b7nen", "Kie\u00b7sel\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erhob ihn mit dem rechten Bein", "tokens": ["Er\u00b7hob", "ihn", "mit", "dem", "rech\u00b7ten", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hielt sich auf dem linken nur", "tokens": ["Und", "hielt", "sich", "auf", "dem", "lin\u00b7ken", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Gleichgewicht und Positur.", "tokens": ["In", "Gleich\u00b7ge\u00b7wicht", "und", "Po\u00b7si\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Der arme Kerl war schrecklich m\u00fcd.", "tokens": ["Der", "ar\u00b7me", "Kerl", "war", "schreck\u00b7lich", "m\u00fcd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erst fiel das linke Augenlid,", "tokens": ["Erst", "fiel", "das", "lin\u00b7ke", "Au\u00b7gen\u00b7lid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das rechte blinzelt zwar noch schwach,", "tokens": ["Das", "rech\u00b7te", "blin\u00b7zelt", "zwar", "noch", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann aber folgt's dem andern nach.", "tokens": ["Dann", "a\u00b7ber", "folgt's", "dem", "an\u00b7dern", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er schnarcht sogar. Ich denke schon:", "tokens": ["Er", "schnarcht", "so\u00b7gar", ".", "Ich", "den\u00b7ke", "schon", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wird es dir ergehn, mein Sohn?", "tokens": ["Wie", "wird", "es", "dir", "er\u00b7gehn", ",", "mein", "Sohn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "VVINF", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So denk ich, doch im Augenblick,", "tokens": ["So", "denk", "ich", ",", "doch", "im", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als ich es dachte, geht es klick!", "tokens": ["Als", "ich", "es", "dach\u00b7te", ",", "geht", "es", "klick", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Stein fiel H\u00e4nschen auf die Zeh,", "tokens": ["Der", "Stein", "fiel", "H\u00e4n\u00b7schen", "auf", "die", "Zeh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das weckt ihn auf, er schreit auweh!", "tokens": ["Das", "weckt", "ihn", "auf", ",", "er", "schreit", "au\u00b7weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Er schaut sich um, hat mich gewittert,", "tokens": ["Er", "schaut", "sich", "um", ",", "hat", "mich", "ge\u00b7wit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.12": {"text": "Pfeift, da\u00df es Mark und Bein ersch\u00fcttert,", "tokens": ["Pfeift", ",", "da\u00df", "es", "Mark", "und", "Bein", "er\u00b7sch\u00fct\u00b7tert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und allsogleich im Winkelflug", "tokens": ["Und", "all\u00b7so\u00b7gleich", "im", "Win\u00b7kel\u00b7flug"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Entschwebt der ganze Heereszug.", "tokens": ["Ent\u00b7schwebt", "der", "gan\u00b7ze", "Hee\u00b7res\u00b7zug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich rief hurra! und schwang den Hut.", "tokens": ["Ich", "rief", "hur\u00b7ra", "!", "und", "schwang", "den", "Hut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$.", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vogel, der gefiel mir gut.", "tokens": ["Der", "Vo\u00b7gel", ",", "der", "ge\u00b7fiel", "mir", "gut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er lebt auch noch. Schon oft seither", "tokens": ["Er", "lebt", "auch", "noch", ".", "Schon", "oft", "sei\u00b7ther"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "ADV", "ADV", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sah man ihn fern am Schwarzen Meer", "tokens": ["Sah", "man", "ihn", "fern", "am", "Schwar\u00b7zen", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "APPRART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Auf einem Bein auf Posten stehn.", "tokens": ["Auf", "ei\u00b7nem", "Bein", "auf", "Pos\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Dies schreibt mein Freund, der Kapit\u00e4n,", "tokens": ["Dies", "schreibt", "mein", "Freund", ",", "der", "Ka\u00b7pi\u00b7t\u00e4n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was er sagt, ist ohne Frage", "tokens": ["Und", "was", "er", "sagt", ",", "ist", "oh\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wahr, als was ich selber sage.", "tokens": ["So", "wahr", ",", "als", "was", "ich", "sel\u00b7ber", "sa\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich bin mal so, sprach F\u00f6rster Knast,", "tokens": ["Ich", "bin", "mal", "so", ",", "sprach", "F\u00f6rs\u00b7ter", "Knast", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$,", "VVFIN", "NE", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Flunkerei ist mir verha\u00dft,", "tokens": ["Die", "Flun\u00b7ke\u00b7rei", "ist", "mir", "ver\u00b7ha\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch sieht man oft was Sonderbares.", "tokens": ["Doch", "sieht", "man", "oft", "was", "Son\u00b7der\u00b7ba\u00b7res", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "ADV", "PWS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Im Fr\u00fchling vor f\u00fcnf Jahren war es,", "tokens": ["Im", "Fr\u00fch\u00b7ling", "vor", "f\u00fcnf", "Jah\u00b7ren", "war", "es", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "CARD", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als ich stockstill, den Hahn gespannt,", "tokens": ["Als", "ich", "stock\u00b7still", ",", "den", "Hahn", "ge\u00b7spannt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bei Mondschein vor dem Walde stand.", "tokens": ["Bei", "Mond\u00b7schein", "vor", "dem", "Wal\u00b7de", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Da l\u00e4\u00dft sich pl\u00f6tzlich fl\u00fcgelsausend", "tokens": ["Da", "l\u00e4\u00dft", "sich", "pl\u00f6tz\u00b7lich", "fl\u00fc\u00b7gel\u00b7sau\u00b7send"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Kranichheer, wohl an die tausend,", "tokens": ["Ein", "Kra\u00b7nich\u00b7heer", ",", "wohl", "an", "die", "tau\u00b7send", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "ART", "CARD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ganz dicht zu meinen F\u00fc\u00dfen nieder.", "tokens": ["Ganz", "dicht", "zu", "mei\u00b7nen", "F\u00fc\u00b7\u00dfen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Sie kamen aus \u00c4gypten wieder", "tokens": ["Sie", "ka\u00b7men", "aus", "\u00c4\u00b7gyp\u00b7ten", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV"], "meter": "-+--++-+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Und dachten auf der Reise nun", "tokens": ["Und", "dach\u00b7ten", "auf", "der", "Rei\u00b7se", "nun"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Sich hier ein St\u00fcndchen auszuruhn.", "tokens": ["Sich", "hier", "ein", "St\u00fcnd\u00b7chen", "aus\u00b7zu\u00b7ruhn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Ich selbstverst\u00e4ndlich, schlau und sacht,", "tokens": ["Ich", "selbst\u00b7ver\u00b7st\u00e4nd\u00b7lich", ",", "schlau", "und", "sacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "$,", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab sehr genau auf alles acht.", "tokens": ["Gab", "sehr", "ge\u00b7nau", "auf", "al\u00b7les", "acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJD", "APPR", "PIS", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Du, Hans, so rief der Oberkranich,", "tokens": ["Du", ",", "Hans", ",", "so", "rief", "der", "O\u00b7ber\u00b7kra\u00b7nich", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "NE", "$,", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hast heut die Wache, drum ermahn ich", "tokens": ["Hast", "heut", "die", "Wa\u00b7che", ",", "drum", "er\u00b7mahn", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "PAV", "VVFIN", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Dich ernstlich, halt dich stramm und pa\u00df", "tokens": ["Dich", "ernst\u00b7lich", ",", "halt", "dich", "stramm", "und", "pa\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADJD", "$,", "VVFIN", "PPER", "VVFIN", "KON", "XY"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00f6rig auf, sonst gibt es was.", "tokens": ["Ge\u00b7h\u00f6\u00b7rig", "auf", ",", "sonst", "gibt", "es", "was", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "PIS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Bald schlief ein jeder ein und s\u00e4gte.", "tokens": ["Bald", "schlief", "ein", "je\u00b7der", "ein", "und", "s\u00e4g\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "PIAT", "ART", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Hans aber stand und \u00fcberlegte.", "tokens": ["Hans", "a\u00b7ber", "stand", "und", "\u00fc\u00b7ber\u00b7leg\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Er nahm sich einen Kieselstein,", "tokens": ["Er", "nahm", "sich", "ei\u00b7nen", "Kie\u00b7sel\u00b7stein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erhob ihn mit dem rechten Bein", "tokens": ["Er\u00b7hob", "ihn", "mit", "dem", "rech\u00b7ten", "Bein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und hielt sich auf dem linken nur", "tokens": ["Und", "hielt", "sich", "auf", "dem", "lin\u00b7ken", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Gleichgewicht und Positur.", "tokens": ["In", "Gleich\u00b7ge\u00b7wicht", "und", "Po\u00b7si\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Der arme Kerl war schrecklich m\u00fcd.", "tokens": ["Der", "ar\u00b7me", "Kerl", "war", "schreck\u00b7lich", "m\u00fcd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erst fiel das linke Augenlid,", "tokens": ["Erst", "fiel", "das", "lin\u00b7ke", "Au\u00b7gen\u00b7lid", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das rechte blinzelt zwar noch schwach,", "tokens": ["Das", "rech\u00b7te", "blin\u00b7zelt", "zwar", "noch", "schwach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dann aber folgt's dem andern nach.", "tokens": ["Dann", "a\u00b7ber", "folgt's", "dem", "an\u00b7dern", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er schnarcht sogar. Ich denke schon:", "tokens": ["Er", "schnarcht", "so\u00b7gar", ".", "Ich", "den\u00b7ke", "schon", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Wie wird es dir ergehn, mein Sohn?", "tokens": ["Wie", "wird", "es", "dir", "er\u00b7gehn", ",", "mein", "Sohn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "PPER", "VVINF", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So denk ich, doch im Augenblick,", "tokens": ["So", "denk", "ich", ",", "doch", "im", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Als ich es dachte, geht es klick!", "tokens": ["Als", "ich", "es", "dach\u00b7te", ",", "geht", "es", "klick", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der Stein fiel H\u00e4nschen auf die Zeh,", "tokens": ["Der", "Stein", "fiel", "H\u00e4n\u00b7schen", "auf", "die", "Zeh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Das weckt ihn auf, er schreit auweh!", "tokens": ["Das", "weckt", "ihn", "auf", ",", "er", "schreit", "au\u00b7weh", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKVZ", "$,", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Er schaut sich um, hat mich gewittert,", "tokens": ["Er", "schaut", "sich", "um", ",", "hat", "mich", "ge\u00b7wit\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$,", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.12": {"text": "Pfeift, da\u00df es Mark und Bein ersch\u00fcttert,", "tokens": ["Pfeift", ",", "da\u00df", "es", "Mark", "und", "Bein", "er\u00b7sch\u00fct\u00b7tert", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Und allsogleich im Winkelflug", "tokens": ["Und", "all\u00b7so\u00b7gleich", "im", "Win\u00b7kel\u00b7flug"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Entschwebt der ganze Heereszug.", "tokens": ["Ent\u00b7schwebt", "der", "gan\u00b7ze", "Hee\u00b7res\u00b7zug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ich rief hurra! und schwang den Hut.", "tokens": ["Ich", "rief", "hur\u00b7ra", "!", "und", "schwang", "den", "Hut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "$.", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Vogel, der gefiel mir gut.", "tokens": ["Der", "Vo\u00b7gel", ",", "der", "ge\u00b7fiel", "mir", "gut", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "$,", "PRELS", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er lebt auch noch. Schon oft seither", "tokens": ["Er", "lebt", "auch", "noch", ".", "Schon", "oft", "sei\u00b7ther"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$.", "ADV", "ADV", "PPOSAT"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sah man ihn fern am Schwarzen Meer", "tokens": ["Sah", "man", "ihn", "fern", "am", "Schwar\u00b7zen", "Meer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PPER", "ADJD", "APPRART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Auf einem Bein auf Posten stehn.", "tokens": ["Auf", "ei\u00b7nem", "Bein", "auf", "Pos\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Dies schreibt mein Freund, der Kapit\u00e4n,", "tokens": ["Dies", "schreibt", "mein", "Freund", ",", "der", "Ka\u00b7pi\u00b7t\u00e4n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und was er sagt, ist ohne Frage", "tokens": ["Und", "was", "er", "sagt", ",", "ist", "oh\u00b7ne", "Fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "So wahr, als was ich selber sage.", "tokens": ["So", "wahr", ",", "als", "was", "ich", "sel\u00b7ber", "sa\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}