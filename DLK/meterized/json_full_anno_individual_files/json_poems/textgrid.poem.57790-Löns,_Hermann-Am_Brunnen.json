{"textgrid.poem.57790": {"metadata": {"author": {"name": "L\u00f6ns, Hermann", "birth": "N.A.", "death": "N.A."}, "title": "Am Brunnen", "genre": "verse", "period": "N.A.", "pub_year": 1890, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was sehen denn die Leute", "tokens": ["Was", "se\u00b7hen", "denn", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mich blo\u00df so eigen an?", "tokens": ["Mich", "blo\u00df", "so", "ei\u00b7gen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als w\u00fc\u00dften sie es alle,", "tokens": ["Als", "w\u00fc\u00df\u00b7ten", "sie", "es", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPER", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was keiner wissen kann.", "tokens": ["Was", "kei\u00b7ner", "wis\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich glaube gar, sie lesens", "tokens": ["Ich", "glau\u00b7be", "gar", ",", "sie", "le\u00b7sens"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mir ab von dem Gesicht,", "tokens": ["Mir", "ab", "von", "dem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als ob sie's alle wissen,", "tokens": ["Als", "ob", "sie's", "al\u00b7le", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und das d\u00fcrfen sie doch nicht.", "tokens": ["Und", "das", "d\u00fcr\u00b7fen", "sie", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Das Wasser in dem Brunnen,", "tokens": ["Das", "Was\u00b7ser", "in", "dem", "Brun\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das sagt es mir sogleich;", "tokens": ["Das", "sagt", "es", "mir", "sog\u00b7leich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Meine Augen die sind tr\u00fcbe,", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", "die", "sind", "tr\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VAFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Wangen die sind bleich.", "tokens": ["Mei\u00b7ne", "Wan\u00b7gen", "die", "sind", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Das Wasser in dem Brunnen,", "tokens": ["Das", "Was\u00b7ser", "in", "dem", "Brun\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verschweigt wohl, was es wei\u00df;", "tokens": ["Ver\u00b7schweigt", "wohl", ",", "was", "es", "wei\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So k\u00fchl ist ja das Wasser,", "tokens": ["So", "k\u00fchl", "ist", "ja", "das", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Reue, die ist hei\u00df.", "tokens": ["Die", "Reu\u00b7e", ",", "die", "ist", "hei\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Die Reue, ja die Reue,", "tokens": ["Die", "Reu\u00b7e", ",", "ja", "die", "Reu\u00b7e", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die brennet gar zu sehr;", "tokens": ["Die", "bren\u00b7net", "gar", "zu", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKA", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das tiefe tiefe Wasser", "tokens": ["Das", "tie\u00b7fe", "tie\u00b7fe", "Was\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das gibt nichts wieder her.", "tokens": ["Das", "gibt", "nichts", "wie\u00b7der", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Was sehen denn die Leute", "tokens": ["Was", "se\u00b7hen", "denn", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mich blo\u00df so eigen an?", "tokens": ["Mich", "blo\u00df", "so", "ei\u00b7gen", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als w\u00fc\u00dften sie es alle,", "tokens": ["Als", "w\u00fc\u00df\u00b7ten", "sie", "es", "al\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "PPER", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was keiner wissen kann.", "tokens": ["Was", "kei\u00b7ner", "wis\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich glaube gar, sie lesens", "tokens": ["Ich", "glau\u00b7be", "gar", ",", "sie", "le\u00b7sens"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mir ab von dem Gesicht,", "tokens": ["Mir", "ab", "von", "dem", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als ob sie's alle wissen,", "tokens": ["Als", "ob", "sie's", "al\u00b7le", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und das d\u00fcrfen sie doch nicht.", "tokens": ["Und", "das", "d\u00fcr\u00b7fen", "sie", "doch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Das Wasser in dem Brunnen,", "tokens": ["Das", "Was\u00b7ser", "in", "dem", "Brun\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Das sagt es mir sogleich;", "tokens": ["Das", "sagt", "es", "mir", "sog\u00b7leich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PPER", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Meine Augen die sind tr\u00fcbe,", "tokens": ["Mei\u00b7ne", "Au\u00b7gen", "die", "sind", "tr\u00fc\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VAFIN", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meine Wangen die sind bleich.", "tokens": ["Mei\u00b7ne", "Wan\u00b7gen", "die", "sind", "bleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Das Wasser in dem Brunnen,", "tokens": ["Das", "Was\u00b7ser", "in", "dem", "Brun\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verschweigt wohl, was es wei\u00df;", "tokens": ["Ver\u00b7schweigt", "wohl", ",", "was", "es", "wei\u00df", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So k\u00fchl ist ja das Wasser,", "tokens": ["So", "k\u00fchl", "ist", "ja", "das", "Was\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Reue, die ist hei\u00df.", "tokens": ["Die", "Reu\u00b7e", ",", "die", "ist", "hei\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VAFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Die Reue, ja die Reue,", "tokens": ["Die", "Reu\u00b7e", ",", "ja", "die", "Reu\u00b7e", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die brennet gar zu sehr;", "tokens": ["Die", "bren\u00b7net", "gar", "zu", "sehr", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PTKA", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das tiefe tiefe Wasser", "tokens": ["Das", "tie\u00b7fe", "tie\u00b7fe", "Was\u00b7ser"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das gibt nichts wieder her.", "tokens": ["Das", "gibt", "nichts", "wie\u00b7der", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}