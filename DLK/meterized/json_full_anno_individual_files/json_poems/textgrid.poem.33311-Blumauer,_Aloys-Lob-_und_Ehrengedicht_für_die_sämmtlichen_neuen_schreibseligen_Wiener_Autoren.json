{"textgrid.poem.33311": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Lob- und Ehrengedicht f\u00fcr die s\u00e4mmtlichen neuen schreibseligen Wiener Autoren", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In einer Stadt, es ist ein n\u00e4rrisch Ding,", "tokens": ["In", "ei\u00b7ner", "Stadt", ",", "es", "ist", "ein", "n\u00e4r\u00b7risch", "Ding", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wo man, um sich zu distinquiren", "tokens": ["Wo", "man", ",", "um", "sich", "zu", "dis\u00b7tin\u00b7qui\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "$,", "KOUI", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zuweilen lieber auf allen Vieren,", "tokens": ["Zu\u00b7wei\u00b7len", "lie\u00b7ber", "auf", "al\u00b7len", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder wohl gar aus den K\u00f6pfen ging:", "tokens": ["O\u00b7der", "wohl", "gar", "aus", "den", "K\u00f6p\u00b7fen", "ging", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "(wovon zwar das Letzte zu dieser Frist", "tokens": ["(", "wo\u00b7von", "zwar", "das", "Letz\u00b7te", "zu", "die\u00b7ser", "Frist"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "ADV", "ART", "ADJA", "APPR", "PDAT", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wohl anging, weil um manche Wade", "tokens": ["Wohl", "an\u00b7ging", ",", "weil", "um", "man\u00b7che", "Wa\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die derb und voll ist weit mehr Schade,", "tokens": ["Die", "derb", "und", "voll", "ist", "weit", "mehr", "Scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als um die hohlen K\u00f6pfchen ist;)", "tokens": ["Als", "um", "die", "hoh\u00b7len", "K\u00f6pf\u00b7chen", "ist", ";)"], "token_info": ["word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In dieser Stadt wird nun viel gelesen,", "tokens": ["In", "die\u00b7ser", "Stadt", "wird", "nun", "viel", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Noch mehr geschrieben von all' dem Wesen", "tokens": ["Noch", "mehr", "ge\u00b7schrie\u00b7ben", "von", "all'", "dem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "APPR", "PIS", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Der olim geehrten Pfaffheit; anbei", "tokens": ["Der", "o\u00b7lim", "ge\u00b7ehr\u00b7ten", "Pfaff\u00b7heit", ";", "an\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NE", "ADJA", "NN", "$.", "XY"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Von Stubenm\u00e4dchen und ihren R\u00f6cken,", "tokens": ["Von", "Stu\u00b7ben\u00b7m\u00e4d\u00b7chen", "und", "ih\u00b7ren", "R\u00f6\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Von Handlung, Finanz und Polizey,", "tokens": ["Von", "Hand\u00b7lung", ",", "Fi\u00b7nanz", "und", "Po\u00b7li\u00b7zey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Von Kaufmannsdienern und ihren S\u00e4cken,", "tokens": ["Von", "Kauf\u00b7manns\u00b7die\u00b7nern", "und", "ih\u00b7ren", "S\u00e4\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.15": {"text": "Von Fr\u00e4ulein, Frauen und ihren Gecken,", "tokens": ["Von", "Fr\u00e4u\u00b7lein", ",", "Frau\u00b7en", "und", "ih\u00b7ren", "Ge\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Von Schneidern, Pensionen und Leichen,", "tokens": ["Von", "Schnei\u00b7dern", ",", "Pen\u00b7si\u00b7o\u00b7nen", "und", "Lei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Von Dienern, die ihren Herren gleichen,", "tokens": ["Von", "Die\u00b7nern", ",", "die", "ih\u00b7ren", "Her\u00b7ren", "glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Von Thieren mit langen und kurzen Ohren,", "tokens": ["Von", "Thie\u00b7ren", "mit", "lan\u00b7gen", "und", "kur\u00b7zen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Von Advokaten und Professoren,", "tokens": ["Von", "Ad\u00b7vo\u00b7ka\u00b7ten", "und", "Pro\u00b7fes\u00b7so\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Von Br\u00fcderschaften und Rosenkr\u00e4nzen,", "tokens": ["Von", "Br\u00fc\u00b7der\u00b7schaf\u00b7ten", "und", "Ro\u00b7sen\u00b7kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Von Fahnen, die zu viel flimmern und gl\u00e4nzen,", "tokens": ["Von", "Fah\u00b7nen", ",", "die", "zu", "viel", "flim\u00b7mern", "und", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "PIS", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Von B\u00e4ckern, Kaufleuten, M\u00e4cklern und Juden,", "tokens": ["Von", "B\u00e4\u00b7ckern", ",", "Kauf\u00b7leu\u00b7ten", ",", "M\u00e4ck\u00b7lern", "und", "Ju\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Von Abla\u00dfkr\u00e4mern und ihren Buden,", "tokens": ["Von", "Ab\u00b7la\u00df\u00b7kr\u00e4\u00b7mern", "und", "ih\u00b7ren", "Bu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Von Lukaszetteln und Kardinalen,", "tokens": ["Von", "Lu\u00b7kas\u00b7zet\u00b7teln", "und", "Kar\u00b7di\u00b7na\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.25": {"text": "Von Jesuiten und ihren Kabalen,", "tokens": ["Von", "Je\u00b7su\u00b7i\u00b7ten", "und", "ih\u00b7ren", "Ka\u00b7ba\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Von Fast und Pochlin und Erzthurmkn\u00f6pfen,", "tokens": ["Von", "Fast", "und", "Poch\u00b7lin", "und", "Erz\u00b7thurm\u00b7kn\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Von M\u00f6nchen und ihren hohlen K\u00f6pfen,", "tokens": ["Von", "M\u00f6n\u00b7chen", "und", "ih\u00b7ren", "hoh\u00b7len", "K\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Von Papsten und seinen sch\u00f6nen F\u00fcssen,", "tokens": ["Von", "Paps\u00b7ten", "und", "sei\u00b7nen", "sch\u00f6\u00b7nen", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "Von Damen, die gern den Pantoffel k\u00fcssen,", "tokens": ["Von", "Da\u00b7men", ",", "die", "gern", "den", "Pan\u00b7tof\u00b7fel", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Und wei\u00df der Himmel wovon noch! \u2013 Kurzum", "tokens": ["Und", "wei\u00df", "der", "Him\u00b7mel", "wo\u00b7von", "noch", "!", "\u2013", "Kur\u00b7zum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PWAV", "ADV", "$.", "$(", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Da ist kein Pudendum, noch Scandalum,", "tokens": ["Da", "ist", "kein", "Pu\u00b7den\u00b7dum", ",", "noch", "Scan\u00b7da\u00b7lum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Das nicht ein r\u00fcstiger Federheld", "tokens": ["Das", "nicht", "ein", "r\u00fcs\u00b7ti\u00b7ger", "Fe\u00b7der\u00b7held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Sammt seiner Person auf den Pranger stellt.", "tokens": ["Sammt", "sei\u00b7ner", "Per\u00b7son", "auf", "den", "Pran\u00b7ger", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Das macht, die allzeitfertigen Herr'n", "tokens": ["Das", "macht", ",", "die", "all\u00b7zeit\u00b7fer\u00b7ti\u00b7gen", "Herr'n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.35": {"text": "Die m\u00f6chten nun einmal auch gar zu gern", "tokens": ["Die", "m\u00f6ch\u00b7ten", "nun", "ein\u00b7mal", "auch", "gar", "zu", "gern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ADV", "ADV", "PTKA", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Erfahren, wie der gaffenden Welt", "tokens": ["Er\u00b7fah\u00b7ren", ",", "wie", "der", "gaf\u00b7fen\u00b7den", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.37": {"text": "Ein Kindlein aus ihren H\u00e4nden gef\u00e4llt,", "tokens": ["Ein", "Kin\u00b7dlein", "aus", "ih\u00b7ren", "H\u00e4n\u00b7den", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "D'rum drehen sie ihre P\u00fcppchen geschwinder, dann", "tokens": ["D'\u00b7rum", "dre\u00b7hen", "sie", "ih\u00b7re", "P\u00fcpp\u00b7chen", "ge\u00b7schwin\u00b7der", ",", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,", "ADV"], "meter": "+-+--+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.39": {"text": "Der fertigste T\u00f6pfer eins drehen kann,", "tokens": ["Der", "fer\u00b7tigs\u00b7te", "T\u00f6p\u00b7fer", "eins", "dre\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.40": {"text": "Und dr\u00fccken: damit man den Vater nicht", "tokens": ["Und", "dr\u00fc\u00b7cken", ":", "da\u00b7mit", "man", "den", "Va\u00b7ter", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "$.", "KOUS", "PIS", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Verkenn', ihm die Finger in's Angesicht,", "tokens": ["Ver\u00b7kenn'", ",", "ihm", "die", "Fin\u00b7ger", "in's", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.42": {"text": "Und stellen's zur Schau. \u2013 Da l\u00e4uft und gafft,", "tokens": ["Und", "stel\u00b7len's", "zur", "Schau", ".", "\u2013", "Da", "l\u00e4uft", "und", "gafft", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "$.", "$(", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.43": {"text": "Was Augen und F\u00fcsse hat, spottet und klafft,", "tokens": ["Was", "Au\u00b7gen", "und", "F\u00fcs\u00b7se", "hat", ",", "spot\u00b7tet", "und", "klafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.44": {"text": "Schilt, tadelt und lobt, klatscht, pfeifet und schm\u00e4ht,", "tokens": ["Schilt", ",", "ta\u00b7delt", "und", "lobt", ",", "klatscht", ",", "pfei\u00b7fet", "und", "schm\u00e4ht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.45": {"text": "L\u00e4\u00dft eine Stunde sich narren \u2013 und geht.", "tokens": ["L\u00e4\u00dft", "ei\u00b7ne", "Stun\u00b7de", "sich", "nar\u00b7ren", "\u2013", "und", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "VVINF", "$(", "KON", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.46": {"text": "Das Autorlein aber schl\u00e4gt, mit dem Lohn", "tokens": ["Das", "Au\u00b7tor\u00b7lein", "a\u00b7ber", "schl\u00e4gt", ",", "mit", "dem", "Lohn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Im Sacke, sein Schnippchen \u2013 und schleicht davon.", "tokens": ["Im", "Sa\u00b7cke", ",", "sein", "Schnipp\u00b7chen", "\u2013", "und", "schleicht", "da\u00b7von", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PAV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.48": {"text": "Hieraus erw\u00e4chst nun von selbst ein gar", "tokens": ["Hier\u00b7aus", "er\u00b7w\u00e4chst", "nun", "von", "selbst", "ein", "gar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "APPR", "ADV", "ART", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.49": {"text": "Erbaulich Problemchen, das lautet: Wer war", "tokens": ["Er\u00b7bau\u00b7lich", "Prob\u00b7lem\u00b7chen", ",", "das", "lau\u00b7tet", ":", "Wer", "war"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "NN", "$,", "PDS", "VVFIN", "$.", "PWS", "VAFIN"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.50": {"text": "Von beiden Seiten der gr\u00f6\u00dfte Narr? \u2013", "tokens": ["Von", "bei\u00b7den", "Sei\u00b7ten", "der", "gr\u00f6\u00df\u00b7te", "Narr", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.51": {"text": "Wag es ja keiner zu resolviren,", "tokens": ["Wag", "es", "ja", "kei\u00b7ner", "zu", "re\u00b7sol\u00b7vi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.52": {"text": "Er m\u00f6chte sein bischen Verstand risciren.", "tokens": ["Er", "m\u00f6ch\u00b7te", "sein", "bi\u00b7schen", "Ver\u00b7stand", "ris\u00b7ci\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Doch ihr, schreibseligen Knaben,", "tokens": ["Doch", "ihr", ",", "schreib\u00b7se\u00b7li\u00b7gen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00dft euch nicht st\u00f6ren in eu'rer Ruh,", "tokens": ["La\u00dft", "euch", "nicht", "st\u00f6\u00b7ren", "in", "eu'\u00b7rer", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schont eu'rer H\u00e4nde nicht, schreibet!", "tokens": ["Schont", "eu'\u00b7rer", "H\u00e4n\u00b7de", "nicht", ",", "schrei\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "$,", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihr werdet hier immer Leser haben.", "tokens": ["Ihr", "wer\u00b7det", "hier", "im\u00b7mer", "Le\u00b7ser", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ihr habt ja ein englisches Publikum,", "tokens": ["Ihr", "habt", "ja", "ein", "eng\u00b7li\u00b7sches", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Es l\u00e4\u00dft sich prellen, und lobt euch d'rum,", "tokens": ["Es", "l\u00e4\u00dft", "sich", "prel\u00b7len", ",", "und", "lobt", "euch", "d'\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denkt euch, ihr lebet in jenem Land,", "tokens": ["Denkt", "euch", ",", "ihr", "le\u00b7bet", "in", "je\u00b7nem", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Wo man einst Diebe und Beutelschneider", "tokens": ["Wo", "man", "einst", "Die\u00b7be", "und", "Beu\u00b7tel\u00b7schnei\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Des Witzes wegen noch lobenswerth fand;", "tokens": ["Des", "Wit\u00b7zes", "we\u00b7gen", "noch", "lo\u00b7bens\u00b7werth", "fand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zwar ist das Publikum leider", "tokens": ["Zwar", "ist", "das", "Pub\u00b7li\u00b7kum", "lei\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Bei uns nicht mehr im Gange, daf\u00fcr", "tokens": ["Bei", "uns", "nicht", "mehr", "im", "Gan\u00b7ge", ",", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "$,", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Erlaubt euch das Recht jetzt, jedem Herren,", "tokens": ["Er\u00b7laubt", "euch", "das", "Recht", "jetzt", ",", "je\u00b7dem", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Der's selbst so will, die Ficken zu leeren;", "tokens": ["Der's", "selbst", "so", "will", ",", "die", "Fi\u00b7cken", "zu", "lee\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und will er Ersatz, so gebt ihm daf\u00fcr", "tokens": ["Und", "will", "er", "Er\u00b7satz", ",", "so", "gebt", "ihm", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "NN", "$,", "ADV", "VVFIN", "PPER", "PAV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Den eisernen Rechtsspruch: ", "tokens": ["Den", "ei\u00b7ser\u00b7nen", "Rechts\u00b7spruch", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.3": {"line.1": {"text": "Doch mu\u00df man leben und leben lassen,", "tokens": ["Doch", "mu\u00df", "man", "le\u00b7ben", "und", "le\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "VVINF", "KON", "VVINF", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und christlich thu'n! \u2013 nicht wahr, ihr Herr'n,", "tokens": ["Und", "christ\u00b7lich", "thu'n", "!", "\u2013", "nicht", "wahr", ",", "ihr", "Herr'n", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$.", "$(", "PTKNEG", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gold'ne Spr\u00fcchelchen h\u00f6rt ihr gern?", "tokens": ["So", "gold'\u00b7ne", "Spr\u00fc\u00b7chel\u00b7chen", "h\u00f6rt", "ihr", "gern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nun gut! so legt denn eine Weile", "tokens": ["Nun", "gut", "!", "so", "legt", "denn", "ei\u00b7ne", "Wei\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Federn weg, und h\u00f6rt mir in Ruh,", "tokens": ["Die", "Fe\u00b7dern", "weg", ",", "und", "h\u00f6rt", "mir", "in", "Ruh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Als eurem handfesten Lobredner zu.", "tokens": ["Als", "eu\u00b7rem", "hand\u00b7fes\u00b7ten", "Lob\u00b7red\u00b7ner", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.4": {"line.1": {"text": "Man wei\u00df, seit jener Ehrens\u00e4ule", "tokens": ["Man", "wei\u00df", ",", "seit", "je\u00b7ner", "Eh\u00b7ren\u00b7s\u00e4u\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Lais, da\u00df auch von Metzen der Staat", "tokens": ["Der", "Lais", ",", "da\u00df", "auch", "von", "Met\u00b7zen", "der", "Staat"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ADV", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Gar manchen betr\u00e4chtlichen Vortheil hat.", "tokens": ["Gar", "man\u00b7chen", "be\u00b7tr\u00e4cht\u00b7li\u00b7chen", "Vor\u00b7theil", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Die Sach' ist erweislich; zum Beispiel, so flie\u00dft", "tokens": ["Die", "Sach'", "ist", "er\u00b7weis\u00b7lich", ";", "zum", "Bei\u00b7spiel", ",", "so", "flie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "APPRART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Der goldene Regen, der oft in Str\u00f6men", "tokens": ["Der", "gol\u00b7de\u00b7ne", "Re\u00b7gen", ",", "der", "oft", "in", "Str\u00f6\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Aus M\u00e4nnerhanden in ihren Schoos sich ergie\u00dft,", "tokens": ["Aus", "M\u00e4n\u00b7ner\u00b7han\u00b7den", "in", "ih\u00b7ren", "Schoos", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Viel sicherer wieder in kleineren Str\u00f6men", "tokens": ["Viel", "si\u00b7che\u00b7rer", "wie\u00b7der", "in", "klei\u00b7ne\u00b7ren", "Str\u00f6\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "In die Kan\u00e4le des Staates zur\u00fcck,", "tokens": ["In", "die", "Ka\u00b7n\u00e4\u00b7le", "des", "Staa\u00b7tes", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.9": {"text": "Als wenn er sich inner den heiligen D\u00e4mmen", "tokens": ["Als", "wenn", "er", "sich", "in\u00b7ner", "den", "hei\u00b7li\u00b7gen", "D\u00e4m\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Der Kl\u00f6ster sammelt, und unber\u00fchrt,", "tokens": ["Der", "Kl\u00f6s\u00b7ter", "sam\u00b7melt", ",", "und", "un\u00b7be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Zum stehenden, faulen Sumpfe wird.", "tokens": ["Zum", "ste\u00b7hen\u00b7den", ",", "fau\u00b7len", "Sump\u00b7fe", "wird", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "F\u00fcr's zweite sch\u00fctzt so ein Venusm\u00e4dchen", "tokens": ["F\u00fcr's", "zwei\u00b7te", "sch\u00fctzt", "so", "ein", "Ve\u00b7nus\u00b7m\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Die Tugend junger, ehrlicher M\u00e4dchen", "tokens": ["Die", "Tu\u00b7gend", "jun\u00b7ger", ",", "ehr\u00b7li\u00b7cher", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJA", "$,", "ADJD", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Gar sehr, indem sie \u2013 selbst l\u00e4ngst verf\u00fchrt \u2013", "tokens": ["Gar", "sehr", ",", "in\u00b7dem", "sie", "\u2013", "selbst", "l\u00e4ngst", "ver\u00b7f\u00fchrt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "$(", "ADV", "ADV", "VVPP", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Der b\u00f6sen M\u00e4nnerlust Ableiter wird.", "tokens": ["Der", "b\u00f6\u00b7sen", "M\u00e4n\u00b7ner\u00b7lust", "Ab\u00b7lei\u00b7ter", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Zum dritten f\u00fcllt so ein M\u00e4dchen den Beutel", "tokens": ["Zum", "drit\u00b7ten", "f\u00fcllt", "so", "ein", "M\u00e4d\u00b7chen", "den", "Beu\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Der Aerzte, und lehrt die liebe Jugend gar fr\u00fch", "tokens": ["Der", "A\u00b7erz\u00b7te", ",", "und", "lehrt", "die", "lie\u00b7be", "Ju\u00b7gend", "gar", "fr\u00fch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADJD"], "meter": "-++--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Mit Salomon rufen: O wie", "tokens": ["Mit", "Sa\u00b7lo\u00b7mon", "ru\u00b7fen", ":", "O", "wie"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "VVINF", "$.", "NE", "KOKOM"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Ist unter'm Monde doch alles so eitel!", "tokens": ["Ist", "un\u00b7ter'm", "Mon\u00b7de", "doch", "al\u00b7les", "so", "ei\u00b7tel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NE", "ADV", "PIS", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Nach dieser t\u00fcchtigen Apologie", "tokens": ["Nach", "die\u00b7ser", "t\u00fcch\u00b7ti\u00b7gen", "A\u00b7po\u00b7lo\u00b7gie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der M\u00e4dchen, die sonst f\u00fcr ihre S\u00fcnden", "tokens": ["Der", "M\u00e4d\u00b7chen", ",", "die", "sonst", "f\u00fcr", "ih\u00b7re", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So selten einen Lobredner finden,", "tokens": ["So", "sel\u00b7ten", "ei\u00b7nen", "Lob\u00b7red\u00b7ner", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Soll's, d\u00e4cht' ich, nun eben kein Hexenwerk sein,", "tokens": ["Soll's", ",", "d\u00e4cht'", "ich", ",", "nun", "e\u00b7ben", "kein", "He\u00b7xen\u00b7werk", "sein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$,", "ADV", "ADV", "PIAT", "NN", "VAINF", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "F\u00fcr euch auch, ihr Herrn Autorlein,", "tokens": ["F\u00fcr", "euch", "auch", ",", "ihr", "Herrn", "Au\u00b7tor\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die panegyrische Trommel zu r\u00fchren,", "tokens": ["Die", "pa\u00b7ne\u00b7gy\u00b7ri\u00b7sche", "Trom\u00b7mel", "zu", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und eu'rer Sache das Wort zu f\u00fchren.", "tokens": ["Und", "eu'\u00b7rer", "Sa\u00b7che", "das", "Wort", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "D'rum h\u00f6r', o Wien, mit beiden Ohren,", "tokens": ["D'\u00b7rum", "h\u00f6r'", ",", "o", "Wi\u00b7en", ",", "mit", "bei\u00b7den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "FM", "NE", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zahlreiche Orden deiner Autoren", "tokens": ["Der", "zahl\u00b7rei\u00b7che", "Or\u00b7den", "dei\u00b7ner", "Au\u00b7to\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist, seit man G\u00e4ns' und Papierm\u00fchlen hat,", "tokens": ["Ist", ",", "seit", "man", "G\u00e4ns'", "und", "Pa\u00b7pier\u00b7m\u00fch\u00b7len", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der n\u00fctzlichste, wichtigste Zweig im Staat.", "tokens": ["Der", "n\u00fctz\u00b7lichs\u00b7te", ",", "wich\u00b7tigs\u00b7te", "Zweig", "im", "Staat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Denn sind die Herr'n Lumpenf\u00e4rber", "tokens": ["Denn", "sind", "die", "Herr'n", "Lum\u00b7pen\u00b7f\u00e4r\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nur recht gewandte Papierverderber,", "tokens": ["Nur", "recht", "ge\u00b7wand\u00b7te", "Pa\u00b7pier\u00b7ver\u00b7der\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "So f\u00f6rdert ja ihr Handwerk gar sehr", "tokens": ["So", "f\u00f6r\u00b7dert", "ja", "ihr", "Hand\u00b7werk", "gar", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Den Absatz der Lumpen. Und wer kann mehr", "tokens": ["Den", "Ab\u00b7satz", "der", "Lum\u00b7pen", ".", "Und", "wer", "kann", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$.", "KON", "PWS", "VMFIN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Und besser Papier verderben als sie; \u2013", "tokens": ["Und", "bes\u00b7ser", "Pa\u00b7pier", "ver\u00b7der\u00b7ben", "als", "sie", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "NN", "VVFIN", "KOUS", "PPER", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ist wer, der mir nicht glaubet der gehe.", "tokens": ["Ist", "wer", ",", "der", "mir", "nicht", "glau\u00b7bet", "der", "ge\u00b7he", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "ART", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und kaufe die Lumpen, und lese sie! \u2013", "tokens": ["Und", "kau\u00b7fe", "die", "Lum\u00b7pen", ",", "und", "le\u00b7se", "sie", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Nun komme mir erst einer, und schm\u00e4he,", "tokens": ["Nun", "kom\u00b7me", "mir", "erst", "ei\u00b7ner", ",", "und", "schm\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Und sage, diese Herren sei'n", "tokens": ["Und", "sa\u00b7ge", ",", "die\u00b7se", "Her\u00b7ren", "sei'n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PDAT", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wie Hummeln im Staate, \u2013 den will ich hinein", "tokens": ["Wie", "Hum\u00b7meln", "im", "Staa\u00b7te", ",", "\u2013", "den", "will", "ich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN", "$,", "$(", "ART", "VMFIN", "PPER", "PTKVZ"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "In alle unsere Buchl\u00e4den f\u00fchren,", "tokens": ["In", "al\u00b7le", "un\u00b7se\u00b7re", "Buch\u00b7l\u00e4\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Ihm da ihre Werke produciren,", "tokens": ["Ihm", "da", "ih\u00b7re", "Wer\u00b7ke", "pro\u00b7du\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Und hat er nun sich glaubend geseh'n,", "tokens": ["Und", "hat", "er", "nun", "sich", "glau\u00b7bend", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Dann soll der Verl\u00e4umder mir eingesteh'n:", "tokens": ["Dann", "soll", "der", "Ver\u00b7l\u00e4um\u00b7der", "mir", "ein\u00b7ge\u00b7steh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Da\u00df so ein Autor mit zweien H\u00e4nden", "tokens": ["Da\u00df", "so", "ein", "Au\u00b7tor", "mit", "zwei\u00b7en", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "CARD", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.20": {"text": "Dem Staate dreimal mehr Kinder verschafft,", "tokens": ["Dem", "Staa\u00b7te", "drei\u00b7mal", "mehr", "Kin\u00b7der", "ver\u00b7schafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Als die gesammte B\u00fcrgerschaft", "tokens": ["Als", "die", "ge\u00b7samm\u00b7te", "B\u00fcr\u00b7ger\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Mit ihren hochgesegneten Lenden.", "tokens": ["Mit", "ih\u00b7ren", "hoch\u00b7ge\u00b7se\u00b7gne\u00b7ten", "Len\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.7": {"line.1": {"text": "Und ist das noch nicht genug, so sagt, wer erh\u00e4lt", "tokens": ["Und", "ist", "das", "noch", "nicht", "ge\u00b7nug", ",", "so", "sagt", ",", "wer", "er\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PDS", "ADV", "PTKNEG", "ADV", "$,", "ADV", "VVFIN", "$,", "PWS", "VVFIN"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Pressen in Athem, wer treibt sie geschwinder,", "tokens": ["Die", "Pres\u00b7sen", "in", "A\u00b7them", ",", "wer", "treibt", "sie", "ge\u00b7schwin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "PWS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Als so ein r\u00fcstiger Federheld?", "tokens": ["Als", "so", "ein", "r\u00fcs\u00b7ti\u00b7ger", "Fe\u00b7der\u00b7held", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was w\u00e4ren Buchh\u00e4ndler, Drucker und Binder", "tokens": ["Was", "w\u00e4\u00b7ren", "Buch\u00b7h\u00e4nd\u00b7ler", ",", "Dru\u00b7cker", "und", "Bin\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ohn' ihn? \u2013 Und ach, die unbarmherzigen", "tokens": ["Ohn'", "ihn", "?", "\u2013", "Und", "ach", ",", "die", "un\u00b7barm\u00b7her\u00b7zi\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "$.", "$(", "KON", "XY", "$,", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Verleger, die sonst, wie Kanibalen,", "tokens": ["Ver\u00b7le\u00b7ger", ",", "die", "sonst", ",", "wie", "Ka\u00b7ni\u00b7ba\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "$,", "PWAV", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Vom Autorgehirne sich m\u00e4steten,", "tokens": ["Vom", "Au\u00b7tor\u00b7ge\u00b7hir\u00b7ne", "sich", "m\u00e4s\u00b7te\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Die lassen sich's nun mit Weib und Kindern gefallen,", "tokens": ["Die", "las\u00b7sen", "sich's", "nun", "mit", "Weib", "und", "Kin\u00b7dern", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und lernen endlich erkennen, da\u00df man", "tokens": ["Und", "ler\u00b7nen", "end\u00b7lich", "er\u00b7ken\u00b7nen", ",", "da\u00df", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "VVINF", "$,", "KOUS", "PIS"], "meter": "-+-+--+-++", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Von Menschenhandarbeit auch leben kann.", "tokens": ["Von", "Men\u00b7schen\u00b7hand\u00b7ar\u00b7beit", "auch", "le\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Wer lehrte sie das? Wer entw\u00f6hnte sie", "tokens": ["Wer", "lehr\u00b7te", "sie", "das", "?", "Wer", "ent\u00b7w\u00f6hn\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PDS", "$.", "PWS", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Vom Menschengehirne? \u2013 Wer anders, als die,", "tokens": ["Vom", "Men\u00b7schen\u00b7ge\u00b7hir\u00b7ne", "?", "\u2013", "Wer", "an\u00b7ders", ",", "als", "die", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "$(", "PWS", "ADV", "$,", "KOUS", "ART", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Die, satt des Greuels, menschlicher dachten,", "tokens": ["Die", ",", "satt", "des", "Greu\u00b7els", ",", "menschli\u00b7cher", "dach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "KOUI", "ART", "NN", "$,", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und statt des Gehirns ihnen Handarbeit brachten?", "tokens": ["Und", "statt", "des", "Ge\u00b7hirns", "ih\u00b7nen", "Hand\u00b7ar\u00b7beit", "brach\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "NN", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.15": {"text": "Seyd stolz, ihr Herr'n, die ihr das gethan!", "tokens": ["Seyd", "stolz", ",", "ihr", "Herr'n", ",", "die", "ihr", "das", "ge\u00b7than", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PDS", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.16": {"text": "Ihr werdet unverge\u00dflich bleiben,", "tokens": ["Ihr", "wer\u00b7det", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die Menschheit wird euch obenan", "tokens": ["Die", "Menschheit", "wird", "euch", "o\u00b7be\u00b7nan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.18": {"text": "In ihre geheiligten Jahrb\u00fccher schreiben:", "tokens": ["In", "ih\u00b7re", "ge\u00b7hei\u00b7lig\u00b7ten", "Jahr\u00b7b\u00fc\u00b7cher", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Auch denken bereits an euern Lohn", "tokens": ["Auch", "den\u00b7ken", "be\u00b7reits", "an", "eu\u00b7ern", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Die Ephemeriden der Menschheit schon.", "tokens": ["Die", "E\u00b7phe\u00b7me\u00b7ri\u00b7den", "der", "Menschheit", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Und dann erst der Nutzen, den eu're Schriften", "tokens": ["Und", "dann", "erst", "der", "Nut\u00b7zen", ",", "den", "eu'\u00b7re", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In der gesammten Wienerwelt stiften!", "tokens": ["In", "der", "ge\u00b7samm\u00b7ten", "Wie\u00b7ner\u00b7welt", "stif\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durch euch kommt Licht in's Volk; denn was ihr schreibt,", "tokens": ["Durch", "euch", "kommt", "Licht", "in's", "Volk", ";", "denn", "was", "ihr", "schreibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "APPRART", "NN", "$.", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dringt bis in die K\u00e4s'- und Gew\u00fcrzkr\u00e4mmerbuden:", "tokens": ["Dringt", "bis", "in", "die", "K\u00e4s'", "und", "Ge\u00b7w\u00fcrz\u00b7kr\u00e4m\u00b7mer\u00b7bu\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "TRUNC", "KON", "NN", "$."], "meter": "----+--+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die Magd, die sonst nur Kaffeebohnen reibt,", "tokens": ["Die", "Magd", ",", "die", "sonst", "nur", "Kaf\u00b7fee\u00b7boh\u00b7nen", "reibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Schw\u00e4tzt nun von Reformen der Christen und Juden,", "tokens": ["Schw\u00e4tzt", "nun", "von", "Re\u00b7for\u00b7men", "der", "Chris\u00b7ten", "und", "Ju\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "++-++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Und wei\u00df auf ein Haar, was jeder Zweig im Staat", "tokens": ["Und", "wei\u00df", "auf", "ein", "Haar", ",", "was", "je\u00b7der", "Zweig", "im", "Staat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "APPRART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "F\u00fcr Beulen und Anomalien hat.", "tokens": ["F\u00fcr", "Beu\u00b7len", "und", "A\u00b7no\u00b7ma\u00b7li\u00b7en", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Nur ihr versteht die Kunst, nur ihr,", "tokens": ["Nur", "ihr", "ver\u00b7steht", "die", "Kunst", ",", "nur", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den niedrigsten P\u00f6bel aufzukl\u00e4ren,", "tokens": ["Den", "nied\u00b7rigs\u00b7ten", "P\u00f6\u00b7bel", "auf\u00b7zu\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ohn' da\u00df er es merkt; dann w\u00fcrdet ihr,", "tokens": ["Ohn'", "da\u00df", "er", "es", "merkt", ";", "dann", "w\u00fcr\u00b7det", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PPER", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Wie sonst geschah, ihn geradezu lehren,", "tokens": ["Wie", "sonst", "ge\u00b7schah", ",", "ihn", "ge\u00b7ra\u00b7de\u00b7zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "$,", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Dumm, wie er ist, und in seine Dummheit verliebt,", "tokens": ["Dumm", ",", "wie", "er", "ist", ",", "und", "in", "sei\u00b7ne", "Dumm\u00b7heit", "ver\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VAFIN", "$,", "KON", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Er w\u00fcrde, erbo\u00dft, gegen eu're Brosch\u00fcren sich wehren;", "tokens": ["Er", "w\u00fcr\u00b7de", ",", "er\u00b7bo\u00dft", ",", "ge\u00b7gen", "eu'\u00b7re", "Bro\u00b7sch\u00fc\u00b7ren", "sich", "weh\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.15": {"text": "Allein, ihr wi\u00dft, wie man den Kindern Arzneyen gibt,", "tokens": ["Al\u00b7lein", ",", "ihr", "wi\u00dft", ",", "wie", "man", "den", "Kin\u00b7dern", "Arz\u00b7ne\u00b7yen", "gibt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "$,", "PWAV", "PIS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "Und la\u00dft eure Bl\u00e4tter, eins nach dem andern,", "tokens": ["Und", "la\u00dft", "eu\u00b7re", "Bl\u00e4t\u00b7ter", ",", "eins", "nach", "dem", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "NN", "$,", "PIS", "APPR", "ART", "ADJA", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Als Pfefferd\u00fcten, als Zuckerpapier", "tokens": ["Als", "Pfef\u00b7fer\u00b7d\u00fc\u00b7ten", ",", "als", "Zu\u00b7cker\u00b7pa\u00b7pier"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Ganz heimlich in seine Taschen wandern.", "tokens": ["Ganz", "heim\u00b7lich", "in", "sei\u00b7ne", "Ta\u00b7schen", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "In Schenken und Bierh\u00e4usern waltet ihr:", "tokens": ["In", "Schen\u00b7ken", "und", "Bier\u00b7h\u00e4u\u00b7sern", "wal\u00b7tet", "ihr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Denn sitzet oft ein Zirkel von Schneidern,", "tokens": ["Denn", "sit\u00b7zet", "oft", "ein", "Zir\u00b7kel", "von", "Schnei\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Nichts B\u00f6ses ahnend, bei Wein und Bier,", "tokens": ["Nichts", "B\u00f6\u00b7ses", "ah\u00b7nend", ",", "bei", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVPP", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Und schw\u00e4tzt von Kriegsaffairen und Kleidern,", "tokens": ["Und", "schw\u00e4tzt", "von", "Kriegs\u00b7af\u00b7fai\u00b7ren", "und", "Klei\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Hui k\u00f6mm't, eh' sich's der Zirkel versieht,", "tokens": ["Hui", "k\u00f6m\u00b7m't", ",", "eh'", "sich's", "der", "Zir\u00b7kel", "ver\u00b7sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Ein St\u00fcckchen Holl\u00e4nderk\u00e4s', und mit", "tokens": ["Ein", "St\u00fcck\u00b7chen", "Hol\u00b7l\u00e4n\u00b7der\u00b7k\u00e4s'", ",", "und", "mit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "KON", "APPR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Ein Bl\u00e4ttchen von euch: man guckt und spitzt das Ohr", "tokens": ["Ein", "Bl\u00e4tt\u00b7chen", "von", "euch", ":", "man", "guckt", "und", "spitzt", "das", "Ohr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "$.", "PIS", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Und kann nur einer aus ihnen buchstabiren,", "tokens": ["Und", "kann", "nur", "ei\u00b7ner", "aus", "ih\u00b7nen", "buch\u00b7sta\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "So nimmt er's, und liest's seinen Trinkbr\u00fcdern vor.", "tokens": ["So", "nimmt", "er's", ",", "und", "liest's", "sei\u00b7nen", "Trink\u00b7br\u00fc\u00b7dern", "vor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "So lernt der P\u00f6bel raisonniren,", "tokens": ["So", "lernt", "der", "P\u00f6\u00b7bel", "rai\u00b7son\u00b7ni\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Und das durch euch: macht ein satyrisch Gesicht", "tokens": ["Und", "das", "durch", "euch", ":", "macht", "ein", "sa\u00b7ty\u00b7risch", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPR", "PPER", "$.", "VVFIN", "ART", "ADJD", "NN"], "meter": "--+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Zu allem, was er sieht: nennt seine Landsleut' Affen,", "tokens": ["Zu", "al\u00b7lem", ",", "was", "er", "sieht", ":", "nennt", "sei\u00b7ne", "Lands\u00b7leut'", "Af\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$.", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den Papst Tyrann, und seine Geistlichen \u2013 Pfaffen.", "tokens": ["Den", "Papst", "Ty\u00b7rann", ",", "und", "sei\u00b7ne", "Geist\u00b7li\u00b7chen", "\u2013", "Pfaf\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "KON", "PPOSAT", "NN", "$(", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "O fehlten mir doch die ", "tokens": ["O", "fehl\u00b7ten", "mir", "doch", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Aus denen sonst die Panegyriker blasen,", "tokens": ["Aus", "de\u00b7nen", "sonst", "die", "Pa\u00b7ne\u00b7gy\u00b7ri\u00b7ker", "bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.34": {"text": "Ich bliese, traun, in ellenlangen Phrasen", "tokens": ["Ich", "blie\u00b7se", ",", "traun", ",", "in", "el\u00b7len\u00b7lan\u00b7gen", "Phra\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVINF", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Der Nachwelt euer Lob in's Angesicht.", "tokens": ["Der", "Nach\u00b7welt", "eu\u00b7er", "Lob", "in's", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Und dir, o Wien, will ich mit einem Wunsche fr\u00f6hnen,", "tokens": ["Und", "dir", ",", "o", "Wi\u00b7en", ",", "will", "ich", "mit", "ei\u00b7nem", "Wun\u00b7sche", "fr\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "FM", "NE", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der soll dein Gl\u00fcck, verkennst du es nur nicht,", "tokens": ["Der", "soll", "dein", "Gl\u00fcck", ",", "ver\u00b7kennst", "du", "es", "nur", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das seiner Vollendung schon nah ist, kr\u00f6nen.", "tokens": ["Das", "sei\u00b7ner", "Vol\u00b7len\u00b7dung", "schon", "nah", "ist", ",", "kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es mehre sich in dir mit jedem Tag", "tokens": ["Es", "meh\u00b7re", "sich", "in", "dir", "mit", "je\u00b7dem", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der edle, n\u00fctzliche Schriftstellerorden:", "tokens": ["Der", "ed\u00b7le", ",", "n\u00fctz\u00b7li\u00b7che", "Schrift\u00b7stel\u00b7le\u00b7ror\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Es schreibe, was nur schreiben mag!", "tokens": ["Es", "schrei\u00b7be", ",", "was", "nur", "schrei\u00b7ben", "mag", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Metzger h\u00f6re auf vom Morden", "tokens": ["Der", "Metz\u00b7ger", "h\u00f6\u00b7re", "auf", "vom", "Mor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Des armen Vieh's, und nehme die Feder zur Hand;", "tokens": ["Des", "ar\u00b7men", "Vieh's", ",", "und", "neh\u00b7me", "die", "Fe\u00b7der", "zur", "Hand", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Schuster stecke die Ahl' an die Wand,", "tokens": ["Der", "Schus\u00b7ter", "ste\u00b7cke", "die", "Ahl'", "an", "die", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und schreibe Theorien von Schuhen;", "tokens": ["Und", "schrei\u00b7be", "The\u00b7o\u00b7ri\u00b7en", "von", "Schu\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Der Schneider la\u00df' Scheer' und Nadel ruhen,", "tokens": ["Der", "Schnei\u00b7der", "la\u00df'", "Scheer'", "und", "Na\u00b7del", "ru\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVIMP", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und schreibe von Moden ein Lehrgedicht:", "tokens": ["Und", "schrei\u00b7be", "von", "Mo\u00b7den", "ein", "Lehr\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Kein M\u00fcller mahl', kein Zimmermann hoble nicht,", "tokens": ["Kein", "M\u00fcl\u00b7ler", "mahl'", ",", "kein", "Zim\u00b7mer\u00b7mann", "hob\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Der hoble die Welt, und jener mahle", "tokens": ["Der", "hob\u00b7le", "die", "Welt", ",", "und", "je\u00b7ner", "mah\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "KON", "PDS", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Die Wahrheit zu Staub, und streu' mit satyrischer Galle", "tokens": ["Die", "Wahr\u00b7heit", "zu", "Staub", ",", "und", "streu'", "mit", "sa\u00b7ty\u00b7ri\u00b7scher", "Gal\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Vermischt, sie den Lesern in's Angesicht;", "tokens": ["Ver\u00b7mischt", ",", "sie", "den", "Le\u00b7sern", "in's", "An\u00b7ge\u00b7sicht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Der T\u00f6pfer modle am Recht; der Schmiede erhebe den Hammer", "tokens": ["Der", "T\u00f6p\u00b7fer", "mod\u00b7le", "am", "Recht", ";", "der", "Schmie\u00b7de", "er\u00b7he\u00b7be", "den", "Ham\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$.", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Der Kritik \u00fcber Theologie;", "tokens": ["Der", "Kri\u00b7tik", "\u00fc\u00b7ber", "Theo\u00b7lo\u00b7gie", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der Schreiner meublire Zimmer und Kammer", "tokens": ["Der", "Schrei\u00b7ner", "meub\u00b7li\u00b7re", "Zim\u00b7mer", "und", "Kam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Mit sch\u00f6n gegl\u00e4tteter Philosophie;", "tokens": ["Mit", "sch\u00f6n", "ge\u00b7gl\u00e4t\u00b7te\u00b7ter", "Phi\u00b7lo\u00b7so\u00b7phie", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Der Staubgewohnte Per\u00fcckenmacher k\u00e4mme", "tokens": ["Der", "Staub\u00b7ge\u00b7wohn\u00b7te", "Pe\u00b7r\u00fc\u00b7cken\u00b7ma\u00b7cher", "k\u00e4m\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Die Religion, der Weber webe Systeme:", "tokens": ["Die", "Re\u00b7li\u00b7gi\u00b7on", ",", "der", "We\u00b7ber", "we\u00b7be", "Sys\u00b7te\u00b7me", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Und so nach allen Z\u00fcnften und St\u00e4nden", "tokens": ["Und", "so", "nach", "al\u00b7len", "Z\u00fcnf\u00b7ten", "und", "St\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Thu jeder mit seinen fertigen H\u00e4nden,", "tokens": ["Thu", "je\u00b7der", "mit", "sei\u00b7nen", "fer\u00b7ti\u00b7gen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Was Autorpflicht ist! Und das, o Wien,", "tokens": ["Was", "Au\u00b7tor\u00b7pflicht", "ist", "!", "Und", "das", ",", "o", "Wi\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$.", "KON", "PDS", "$,", "FM", "NE", "$,"], "meter": "-+-+----+-", "measure": "unknown.measure.tri"}, "line.26": {"text": "Wird, glaub's dem Propheten, aller Zeiten", "tokens": ["Wird", ",", "glaub's", "dem", "Pro\u00b7phe\u00b7ten", ",", "al\u00b7ler", "Zei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "NE", "ART", "NN", "$,", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Und V\u00f6lker Augen auf dich zieh'n,", "tokens": ["Und", "V\u00f6l\u00b7ker", "Au\u00b7gen", "auf", "dich", "zieh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und deinen Ruhm bis \u00fcber die Sterne verbreiten.", "tokens": ["Und", "dei\u00b7nen", "Ruhm", "bis", "\u00fc\u00b7ber", "die", "Ster\u00b7ne", "ver\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "In einer Stadt, es ist ein n\u00e4rrisch Ding,", "tokens": ["In", "ei\u00b7ner", "Stadt", ",", "es", "ist", "ein", "n\u00e4r\u00b7risch", "Ding", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wo man, um sich zu distinquiren", "tokens": ["Wo", "man", ",", "um", "sich", "zu", "dis\u00b7tin\u00b7qui\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "$,", "KOUI", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Zuweilen lieber auf allen Vieren,", "tokens": ["Zu\u00b7wei\u00b7len", "lie\u00b7ber", "auf", "al\u00b7len", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Oder wohl gar aus den K\u00f6pfen ging:", "tokens": ["O\u00b7der", "wohl", "gar", "aus", "den", "K\u00f6p\u00b7fen", "ging", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "(wovon zwar das Letzte zu dieser Frist", "tokens": ["(", "wo\u00b7von", "zwar", "das", "Letz\u00b7te", "zu", "die\u00b7ser", "Frist"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "ADV", "ART", "ADJA", "APPR", "PDAT", "NN"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Wohl anging, weil um manche Wade", "tokens": ["Wohl", "an\u00b7ging", ",", "weil", "um", "man\u00b7che", "Wa\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die derb und voll ist weit mehr Schade,", "tokens": ["Die", "derb", "und", "voll", "ist", "weit", "mehr", "Scha\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "VAFIN", "ADJD", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Als um die hohlen K\u00f6pfchen ist;)", "tokens": ["Als", "um", "die", "hoh\u00b7len", "K\u00f6pf\u00b7chen", "ist", ";)"], "token_info": ["word", "word", "word", "word", "word", "word", "emoticon"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "In dieser Stadt wird nun viel gelesen,", "tokens": ["In", "die\u00b7ser", "Stadt", "wird", "nun", "viel", "ge\u00b7le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Noch mehr geschrieben von all' dem Wesen", "tokens": ["Noch", "mehr", "ge\u00b7schrie\u00b7ben", "von", "all'", "dem", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "APPR", "PIS", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Der olim geehrten Pfaffheit; anbei", "tokens": ["Der", "o\u00b7lim", "ge\u00b7ehr\u00b7ten", "Pfaff\u00b7heit", ";", "an\u00b7bei"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NE", "ADJA", "NN", "$.", "XY"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.12": {"text": "Von Stubenm\u00e4dchen und ihren R\u00f6cken,", "tokens": ["Von", "Stu\u00b7ben\u00b7m\u00e4d\u00b7chen", "und", "ih\u00b7ren", "R\u00f6\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Von Handlung, Finanz und Polizey,", "tokens": ["Von", "Hand\u00b7lung", ",", "Fi\u00b7nanz", "und", "Po\u00b7li\u00b7zey", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Von Kaufmannsdienern und ihren S\u00e4cken,", "tokens": ["Von", "Kauf\u00b7manns\u00b7die\u00b7nern", "und", "ih\u00b7ren", "S\u00e4\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-++-+-+-", "measure": "unknown.measure.penta"}, "line.15": {"text": "Von Fr\u00e4ulein, Frauen und ihren Gecken,", "tokens": ["Von", "Fr\u00e4u\u00b7lein", ",", "Frau\u00b7en", "und", "ih\u00b7ren", "Ge\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "Von Schneidern, Pensionen und Leichen,", "tokens": ["Von", "Schnei\u00b7dern", ",", "Pen\u00b7si\u00b7o\u00b7nen", "und", "Lei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Von Dienern, die ihren Herren gleichen,", "tokens": ["Von", "Die\u00b7nern", ",", "die", "ih\u00b7ren", "Her\u00b7ren", "glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Von Thieren mit langen und kurzen Ohren,", "tokens": ["Von", "Thie\u00b7ren", "mit", "lan\u00b7gen", "und", "kur\u00b7zen", "Oh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "KON", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Von Advokaten und Professoren,", "tokens": ["Von", "Ad\u00b7vo\u00b7ka\u00b7ten", "und", "Pro\u00b7fes\u00b7so\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Von Br\u00fcderschaften und Rosenkr\u00e4nzen,", "tokens": ["Von", "Br\u00fc\u00b7der\u00b7schaf\u00b7ten", "und", "Ro\u00b7sen\u00b7kr\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Von Fahnen, die zu viel flimmern und gl\u00e4nzen,", "tokens": ["Von", "Fah\u00b7nen", ",", "die", "zu", "viel", "flim\u00b7mern", "und", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "APPR", "PIS", "VVINF", "KON", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Von B\u00e4ckern, Kaufleuten, M\u00e4cklern und Juden,", "tokens": ["Von", "B\u00e4\u00b7ckern", ",", "Kauf\u00b7leu\u00b7ten", ",", "M\u00e4ck\u00b7lern", "und", "Ju\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Von Abla\u00dfkr\u00e4mern und ihren Buden,", "tokens": ["Von", "Ab\u00b7la\u00df\u00b7kr\u00e4\u00b7mern", "und", "ih\u00b7ren", "Bu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Von Lukaszetteln und Kardinalen,", "tokens": ["Von", "Lu\u00b7kas\u00b7zet\u00b7teln", "und", "Kar\u00b7di\u00b7na\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.25": {"text": "Von Jesuiten und ihren Kabalen,", "tokens": ["Von", "Je\u00b7su\u00b7i\u00b7ten", "und", "ih\u00b7ren", "Ka\u00b7ba\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Von Fast und Pochlin und Erzthurmkn\u00f6pfen,", "tokens": ["Von", "Fast", "und", "Poch\u00b7lin", "und", "Erz\u00b7thurm\u00b7kn\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "KON", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Von M\u00f6nchen und ihren hohlen K\u00f6pfen,", "tokens": ["Von", "M\u00f6n\u00b7chen", "und", "ih\u00b7ren", "hoh\u00b7len", "K\u00f6p\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Von Papsten und seinen sch\u00f6nen F\u00fcssen,", "tokens": ["Von", "Paps\u00b7ten", "und", "sei\u00b7nen", "sch\u00f6\u00b7nen", "F\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.29": {"text": "Von Damen, die gern den Pantoffel k\u00fcssen,", "tokens": ["Von", "Da\u00b7men", ",", "die", "gern", "den", "Pan\u00b7tof\u00b7fel", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.30": {"text": "Und wei\u00df der Himmel wovon noch! \u2013 Kurzum", "tokens": ["Und", "wei\u00df", "der", "Him\u00b7mel", "wo\u00b7von", "noch", "!", "\u2013", "Kur\u00b7zum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PWAV", "ADV", "$.", "$(", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.31": {"text": "Da ist kein Pudendum, noch Scandalum,", "tokens": ["Da", "ist", "kein", "Pu\u00b7den\u00b7dum", ",", "noch", "Scan\u00b7da\u00b7lum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Das nicht ein r\u00fcstiger Federheld", "tokens": ["Das", "nicht", "ein", "r\u00fcs\u00b7ti\u00b7ger", "Fe\u00b7der\u00b7held"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.33": {"text": "Sammt seiner Person auf den Pranger stellt.", "tokens": ["Sammt", "sei\u00b7ner", "Per\u00b7son", "auf", "den", "Pran\u00b7ger", "stellt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Das macht, die allzeitfertigen Herr'n", "tokens": ["Das", "macht", ",", "die", "all\u00b7zeit\u00b7fer\u00b7ti\u00b7gen", "Herr'n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.35": {"text": "Die m\u00f6chten nun einmal auch gar zu gern", "tokens": ["Die", "m\u00f6ch\u00b7ten", "nun", "ein\u00b7mal", "auch", "gar", "zu", "gern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "ADV", "ADV", "ADV", "ADV", "PTKA", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Erfahren, wie der gaffenden Welt", "tokens": ["Er\u00b7fah\u00b7ren", ",", "wie", "der", "gaf\u00b7fen\u00b7den", "Welt"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.37": {"text": "Ein Kindlein aus ihren H\u00e4nden gef\u00e4llt,", "tokens": ["Ein", "Kin\u00b7dlein", "aus", "ih\u00b7ren", "H\u00e4n\u00b7den", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.38": {"text": "D'rum drehen sie ihre P\u00fcppchen geschwinder, dann", "tokens": ["D'\u00b7rum", "dre\u00b7hen", "sie", "ih\u00b7re", "P\u00fcpp\u00b7chen", "ge\u00b7schwin\u00b7der", ",", "dann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PAV", "VVFIN", "PPER", "PPOSAT", "NN", "ADJD", "$,", "ADV"], "meter": "+-+--+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.39": {"text": "Der fertigste T\u00f6pfer eins drehen kann,", "tokens": ["Der", "fer\u00b7tigs\u00b7te", "T\u00f6p\u00b7fer", "eins", "dre\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.40": {"text": "Und dr\u00fccken: damit man den Vater nicht", "tokens": ["Und", "dr\u00fc\u00b7cken", ":", "da\u00b7mit", "man", "den", "Va\u00b7ter", "nicht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "$.", "KOUS", "PIS", "ART", "NN", "PTKNEG"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Verkenn', ihm die Finger in's Angesicht,", "tokens": ["Ver\u00b7kenn'", ",", "ihm", "die", "Fin\u00b7ger", "in's", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.42": {"text": "Und stellen's zur Schau. \u2013 Da l\u00e4uft und gafft,", "tokens": ["Und", "stel\u00b7len's", "zur", "Schau", ".", "\u2013", "Da", "l\u00e4uft", "und", "gafft", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "$.", "$(", "ADV", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.43": {"text": "Was Augen und F\u00fcsse hat, spottet und klafft,", "tokens": ["Was", "Au\u00b7gen", "und", "F\u00fcs\u00b7se", "hat", ",", "spot\u00b7tet", "und", "klafft", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VAFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.44": {"text": "Schilt, tadelt und lobt, klatscht, pfeifet und schm\u00e4ht,", "tokens": ["Schilt", ",", "ta\u00b7delt", "und", "lobt", ",", "klatscht", ",", "pfei\u00b7fet", "und", "schm\u00e4ht", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.45": {"text": "L\u00e4\u00dft eine Stunde sich narren \u2013 und geht.", "tokens": ["L\u00e4\u00dft", "ei\u00b7ne", "Stun\u00b7de", "sich", "nar\u00b7ren", "\u2013", "und", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PRF", "VVINF", "$(", "KON", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.46": {"text": "Das Autorlein aber schl\u00e4gt, mit dem Lohn", "tokens": ["Das", "Au\u00b7tor\u00b7lein", "a\u00b7ber", "schl\u00e4gt", ",", "mit", "dem", "Lohn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Im Sacke, sein Schnippchen \u2013 und schleicht davon.", "tokens": ["Im", "Sa\u00b7cke", ",", "sein", "Schnipp\u00b7chen", "\u2013", "und", "schleicht", "da\u00b7von", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "$(", "KON", "VVFIN", "PAV", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.48": {"text": "Hieraus erw\u00e4chst nun von selbst ein gar", "tokens": ["Hier\u00b7aus", "er\u00b7w\u00e4chst", "nun", "von", "selbst", "ein", "gar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "ADV", "APPR", "ADV", "ART", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.49": {"text": "Erbaulich Problemchen, das lautet: Wer war", "tokens": ["Er\u00b7bau\u00b7lich", "Prob\u00b7lem\u00b7chen", ",", "das", "lau\u00b7tet", ":", "Wer", "war"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "NN", "$,", "PDS", "VVFIN", "$.", "PWS", "VAFIN"], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}, "line.50": {"text": "Von beiden Seiten der gr\u00f6\u00dfte Narr? \u2013", "tokens": ["Von", "bei\u00b7den", "Sei\u00b7ten", "der", "gr\u00f6\u00df\u00b7te", "Narr", "?", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.51": {"text": "Wag es ja keiner zu resolviren,", "tokens": ["Wag", "es", "ja", "kei\u00b7ner", "zu", "re\u00b7sol\u00b7vi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PIS", "PTKZU", "VVINF", "$,"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.52": {"text": "Er m\u00f6chte sein bischen Verstand risciren.", "tokens": ["Er", "m\u00f6ch\u00b7te", "sein", "bi\u00b7schen", "Ver\u00b7stand", "ris\u00b7ci\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Doch ihr, schreibseligen Knaben,", "tokens": ["Doch", "ihr", ",", "schreib\u00b7se\u00b7li\u00b7gen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00dft euch nicht st\u00f6ren in eu'rer Ruh,", "tokens": ["La\u00dft", "euch", "nicht", "st\u00f6\u00b7ren", "in", "eu'\u00b7rer", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Schont eu'rer H\u00e4nde nicht, schreibet!", "tokens": ["Schont", "eu'\u00b7rer", "H\u00e4n\u00b7de", "nicht", ",", "schrei\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKNEG", "$,", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Ihr werdet hier immer Leser haben.", "tokens": ["Ihr", "wer\u00b7det", "hier", "im\u00b7mer", "Le\u00b7ser", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ihr habt ja ein englisches Publikum,", "tokens": ["Ihr", "habt", "ja", "ein", "eng\u00b7li\u00b7sches", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Es l\u00e4\u00dft sich prellen, und lobt euch d'rum,", "tokens": ["Es", "l\u00e4\u00dft", "sich", "prel\u00b7len", ",", "und", "lobt", "euch", "d'\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "VVFIN", "$,", "KON", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Denkt euch, ihr lebet in jenem Land,", "tokens": ["Denkt", "euch", ",", "ihr", "le\u00b7bet", "in", "je\u00b7nem", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PPER", "VVFIN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Wo man einst Diebe und Beutelschneider", "tokens": ["Wo", "man", "einst", "Die\u00b7be", "und", "Beu\u00b7tel\u00b7schnei\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "NN", "KON", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Des Witzes wegen noch lobenswerth fand;", "tokens": ["Des", "Wit\u00b7zes", "we\u00b7gen", "noch", "lo\u00b7bens\u00b7werth", "fand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Zwar ist das Publikum leider", "tokens": ["Zwar", "ist", "das", "Pub\u00b7li\u00b7kum", "lei\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.11": {"text": "Bei uns nicht mehr im Gange, daf\u00fcr", "tokens": ["Bei", "uns", "nicht", "mehr", "im", "Gan\u00b7ge", ",", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PPER", "PTKNEG", "ADV", "APPRART", "NN", "$,", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.12": {"text": "Erlaubt euch das Recht jetzt, jedem Herren,", "tokens": ["Er\u00b7laubt", "euch", "das", "Recht", "jetzt", ",", "je\u00b7dem", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "$,", "PIAT", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Der's selbst so will, die Ficken zu leeren;", "tokens": ["Der's", "selbst", "so", "will", ",", "die", "Fi\u00b7cken", "zu", "lee\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADV", "VMFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Und will er Ersatz, so gebt ihm daf\u00fcr", "tokens": ["Und", "will", "er", "Er\u00b7satz", ",", "so", "gebt", "ihm", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPER", "NN", "$,", "ADV", "VVFIN", "PPER", "PAV"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Den eisernen Rechtsspruch: ", "tokens": ["Den", "ei\u00b7ser\u00b7nen", "Rechts\u00b7spruch", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.12": {"line.1": {"text": "Doch mu\u00df man leben und leben lassen,", "tokens": ["Doch", "mu\u00df", "man", "le\u00b7ben", "und", "le\u00b7ben", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PIS", "VVINF", "KON", "VVINF", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und christlich thu'n! \u2013 nicht wahr, ihr Herr'n,", "tokens": ["Und", "christ\u00b7lich", "thu'n", "!", "\u2013", "nicht", "wahr", ",", "ihr", "Herr'n", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$.", "$(", "PTKNEG", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gold'ne Spr\u00fcchelchen h\u00f6rt ihr gern?", "tokens": ["So", "gold'\u00b7ne", "Spr\u00fc\u00b7chel\u00b7chen", "h\u00f6rt", "ihr", "gern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nun gut! so legt denn eine Weile", "tokens": ["Nun", "gut", "!", "so", "legt", "denn", "ei\u00b7ne", "Wei\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "ADV", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Die Federn weg, und h\u00f6rt mir in Ruh,", "tokens": ["Die", "Fe\u00b7dern", "weg", ",", "und", "h\u00f6rt", "mir", "in", "Ruh", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Als eurem handfesten Lobredner zu.", "tokens": ["Als", "eu\u00b7rem", "hand\u00b7fes\u00b7ten", "Lob\u00b7red\u00b7ner", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Man wei\u00df, seit jener Ehrens\u00e4ule", "tokens": ["Man", "wei\u00df", ",", "seit", "je\u00b7ner", "Eh\u00b7ren\u00b7s\u00e4u\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Lais, da\u00df auch von Metzen der Staat", "tokens": ["Der", "Lais", ",", "da\u00df", "auch", "von", "Met\u00b7zen", "der", "Staat"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "ADV", "APPR", "NN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Gar manchen betr\u00e4chtlichen Vortheil hat.", "tokens": ["Gar", "man\u00b7chen", "be\u00b7tr\u00e4cht\u00b7li\u00b7chen", "Vor\u00b7theil", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Die Sach' ist erweislich; zum Beispiel, so flie\u00dft", "tokens": ["Die", "Sach'", "ist", "er\u00b7weis\u00b7lich", ";", "zum", "Bei\u00b7spiel", ",", "so", "flie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "APPRART", "NN", "$,", "ADV", "VVFIN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.5": {"text": "Der goldene Regen, der oft in Str\u00f6men", "tokens": ["Der", "gol\u00b7de\u00b7ne", "Re\u00b7gen", ",", "der", "oft", "in", "Str\u00f6\u00b7men"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Aus M\u00e4nnerhanden in ihren Schoos sich ergie\u00dft,", "tokens": ["Aus", "M\u00e4n\u00b7ner\u00b7han\u00b7den", "in", "ih\u00b7ren", "Schoos", "sich", "er\u00b7gie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPOSAT", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+--+-+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Viel sicherer wieder in kleineren Str\u00f6men", "tokens": ["Viel", "si\u00b7che\u00b7rer", "wie\u00b7der", "in", "klei\u00b7ne\u00b7ren", "Str\u00f6\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ADV", "APPR", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.8": {"text": "In die Kan\u00e4le des Staates zur\u00fcck,", "tokens": ["In", "die", "Ka\u00b7n\u00e4\u00b7le", "des", "Staa\u00b7tes", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.9": {"text": "Als wenn er sich inner den heiligen D\u00e4mmen", "tokens": ["Als", "wenn", "er", "sich", "in\u00b7ner", "den", "hei\u00b7li\u00b7gen", "D\u00e4m\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "PPER", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.10": {"text": "Der Kl\u00f6ster sammelt, und unber\u00fchrt,", "tokens": ["Der", "Kl\u00f6s\u00b7ter", "sam\u00b7melt", ",", "und", "un\u00b7be\u00b7r\u00fchrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Zum stehenden, faulen Sumpfe wird.", "tokens": ["Zum", "ste\u00b7hen\u00b7den", ",", "fau\u00b7len", "Sump\u00b7fe", "wird", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$,", "ADJA", "NN", "VAFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "F\u00fcr's zweite sch\u00fctzt so ein Venusm\u00e4dchen", "tokens": ["F\u00fcr's", "zwei\u00b7te", "sch\u00fctzt", "so", "ein", "Ve\u00b7nus\u00b7m\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Die Tugend junger, ehrlicher M\u00e4dchen", "tokens": ["Die", "Tu\u00b7gend", "jun\u00b7ger", ",", "ehr\u00b7li\u00b7cher", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "ADJA", "$,", "ADJD", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Gar sehr, indem sie \u2013 selbst l\u00e4ngst verf\u00fchrt \u2013", "tokens": ["Gar", "sehr", ",", "in\u00b7dem", "sie", "\u2013", "selbst", "l\u00e4ngst", "ver\u00b7f\u00fchrt", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "KOUS", "PPER", "$(", "ADV", "ADV", "VVPP", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Der b\u00f6sen M\u00e4nnerlust Ableiter wird.", "tokens": ["Der", "b\u00f6\u00b7sen", "M\u00e4n\u00b7ner\u00b7lust", "Ab\u00b7lei\u00b7ter", "wird", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Zum dritten f\u00fcllt so ein M\u00e4dchen den Beutel", "tokens": ["Zum", "drit\u00b7ten", "f\u00fcllt", "so", "ein", "M\u00e4d\u00b7chen", "den", "Beu\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "VVFIN", "ADV", "ART", "NN", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Der Aerzte, und lehrt die liebe Jugend gar fr\u00fch", "tokens": ["Der", "A\u00b7erz\u00b7te", ",", "und", "lehrt", "die", "lie\u00b7be", "Ju\u00b7gend", "gar", "fr\u00fch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KON", "VVFIN", "ART", "ADJA", "NN", "ADV", "ADJD"], "meter": "-++--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Mit Salomon rufen: O wie", "tokens": ["Mit", "Sa\u00b7lo\u00b7mon", "ru\u00b7fen", ":", "O", "wie"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "VVINF", "$.", "NE", "KOKOM"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.19": {"text": "Ist unter'm Monde doch alles so eitel!", "tokens": ["Ist", "un\u00b7ter'm", "Mon\u00b7de", "doch", "al\u00b7les", "so", "ei\u00b7tel", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPRART", "NE", "ADV", "PIS", "ADV", "ADJD", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Nach dieser t\u00fcchtigen Apologie", "tokens": ["Nach", "die\u00b7ser", "t\u00fcch\u00b7ti\u00b7gen", "A\u00b7po\u00b7lo\u00b7gie"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der M\u00e4dchen, die sonst f\u00fcr ihre S\u00fcnden", "tokens": ["Der", "M\u00e4d\u00b7chen", ",", "die", "sonst", "f\u00fcr", "ih\u00b7re", "S\u00fcn\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So selten einen Lobredner finden,", "tokens": ["So", "sel\u00b7ten", "ei\u00b7nen", "Lob\u00b7red\u00b7ner", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Soll's, d\u00e4cht' ich, nun eben kein Hexenwerk sein,", "tokens": ["Soll's", ",", "d\u00e4cht'", "ich", ",", "nun", "e\u00b7ben", "kein", "He\u00b7xen\u00b7werk", "sein", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PPER", "$,", "ADV", "ADV", "PIAT", "NN", "VAINF", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.5": {"text": "F\u00fcr euch auch, ihr Herrn Autorlein,", "tokens": ["F\u00fcr", "euch", "auch", ",", "ihr", "Herrn", "Au\u00b7tor\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "$,", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die panegyrische Trommel zu r\u00fchren,", "tokens": ["Die", "pa\u00b7ne\u00b7gy\u00b7ri\u00b7sche", "Trom\u00b7mel", "zu", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Und eu'rer Sache das Wort zu f\u00fchren.", "tokens": ["Und", "eu'\u00b7rer", "Sa\u00b7che", "das", "Wort", "zu", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "D'rum h\u00f6r', o Wien, mit beiden Ohren,", "tokens": ["D'\u00b7rum", "h\u00f6r'", ",", "o", "Wi\u00b7en", ",", "mit", "bei\u00b7den", "Oh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "FM", "NE", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "--+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der zahlreiche Orden deiner Autoren", "tokens": ["Der", "zahl\u00b7rei\u00b7che", "Or\u00b7den", "dei\u00b7ner", "Au\u00b7to\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "PPOSAT", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ist, seit man G\u00e4ns' und Papierm\u00fchlen hat,", "tokens": ["Ist", ",", "seit", "man", "G\u00e4ns'", "und", "Pa\u00b7pier\u00b7m\u00fch\u00b7len", "hat", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Der n\u00fctzlichste, wichtigste Zweig im Staat.", "tokens": ["Der", "n\u00fctz\u00b7lichs\u00b7te", ",", "wich\u00b7tigs\u00b7te", "Zweig", "im", "Staat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Denn sind die Herr'n Lumpenf\u00e4rber", "tokens": ["Denn", "sind", "die", "Herr'n", "Lum\u00b7pen\u00b7f\u00e4r\u00b7ber"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Nur recht gewandte Papierverderber,", "tokens": ["Nur", "recht", "ge\u00b7wand\u00b7te", "Pa\u00b7pier\u00b7ver\u00b7der\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "So f\u00f6rdert ja ihr Handwerk gar sehr", "tokens": ["So", "f\u00f6r\u00b7dert", "ja", "ihr", "Hand\u00b7werk", "gar", "sehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "PPOSAT", "NN", "ADV", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.8": {"text": "Den Absatz der Lumpen. Und wer kann mehr", "tokens": ["Den", "Ab\u00b7satz", "der", "Lum\u00b7pen", ".", "Und", "wer", "kann", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "$.", "KON", "PWS", "VMFIN", "ADV"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Und besser Papier verderben als sie; \u2013", "tokens": ["Und", "bes\u00b7ser", "Pa\u00b7pier", "ver\u00b7der\u00b7ben", "als", "sie", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "NN", "VVFIN", "KOUS", "PPER", "$.", "$("], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Ist wer, der mir nicht glaubet der gehe.", "tokens": ["Ist", "wer", ",", "der", "mir", "nicht", "glau\u00b7bet", "der", "ge\u00b7he", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "ART", "VVFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.11": {"text": "Und kaufe die Lumpen, und lese sie! \u2013", "tokens": ["Und", "kau\u00b7fe", "die", "Lum\u00b7pen", ",", "und", "le\u00b7se", "sie", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,", "KON", "VVFIN", "PPER", "$.", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Nun komme mir erst einer, und schm\u00e4he,", "tokens": ["Nun", "kom\u00b7me", "mir", "erst", "ei\u00b7ner", ",", "und", "schm\u00e4\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "$,", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Und sage, diese Herren sei'n", "tokens": ["Und", "sa\u00b7ge", ",", "die\u00b7se", "Her\u00b7ren", "sei'n"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "PDAT", "NN", "PPOSAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Wie Hummeln im Staate, \u2013 den will ich hinein", "tokens": ["Wie", "Hum\u00b7meln", "im", "Staa\u00b7te", ",", "\u2013", "den", "will", "ich", "hin\u00b7ein"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN", "$,", "$(", "ART", "VMFIN", "PPER", "PTKVZ"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "In alle unsere Buchl\u00e4den f\u00fchren,", "tokens": ["In", "al\u00b7le", "un\u00b7se\u00b7re", "Buch\u00b7l\u00e4\u00b7den", "f\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Ihm da ihre Werke produciren,", "tokens": ["Ihm", "da", "ih\u00b7re", "Wer\u00b7ke", "pro\u00b7du\u00b7ci\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.17": {"text": "Und hat er nun sich glaubend geseh'n,", "tokens": ["Und", "hat", "er", "nun", "sich", "glau\u00b7bend", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Dann soll der Verl\u00e4umder mir eingesteh'n:", "tokens": ["Dann", "soll", "der", "Ver\u00b7l\u00e4um\u00b7der", "mir", "ein\u00b7ge\u00b7steh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Da\u00df so ein Autor mit zweien H\u00e4nden", "tokens": ["Da\u00df", "so", "ein", "Au\u00b7tor", "mit", "zwei\u00b7en", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "APPR", "CARD", "NN"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.20": {"text": "Dem Staate dreimal mehr Kinder verschafft,", "tokens": ["Dem", "Staa\u00b7te", "drei\u00b7mal", "mehr", "Kin\u00b7der", "ver\u00b7schafft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Als die gesammte B\u00fcrgerschaft", "tokens": ["Als", "die", "ge\u00b7samm\u00b7te", "B\u00fcr\u00b7ger\u00b7schaft"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Mit ihren hochgesegneten Lenden.", "tokens": ["Mit", "ih\u00b7ren", "hoch\u00b7ge\u00b7se\u00b7gne\u00b7ten", "Len\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.16": {"line.1": {"text": "Und ist das noch nicht genug, so sagt, wer erh\u00e4lt", "tokens": ["Und", "ist", "das", "noch", "nicht", "ge\u00b7nug", ",", "so", "sagt", ",", "wer", "er\u00b7h\u00e4lt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PDS", "ADV", "PTKNEG", "ADV", "$,", "ADV", "VVFIN", "$,", "PWS", "VVFIN"], "meter": "-+--+-+-+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Die Pressen in Athem, wer treibt sie geschwinder,", "tokens": ["Die", "Pres\u00b7sen", "in", "A\u00b7them", ",", "wer", "treibt", "sie", "ge\u00b7schwin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "PWS", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Als so ein r\u00fcstiger Federheld?", "tokens": ["Als", "so", "ein", "r\u00fcs\u00b7ti\u00b7ger", "Fe\u00b7der\u00b7held", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "$."], "meter": "---+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Was w\u00e4ren Buchh\u00e4ndler, Drucker und Binder", "tokens": ["Was", "w\u00e4\u00b7ren", "Buch\u00b7h\u00e4nd\u00b7ler", ",", "Dru\u00b7cker", "und", "Bin\u00b7der"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Ohn' ihn? \u2013 Und ach, die unbarmherzigen", "tokens": ["Ohn'", "ihn", "?", "\u2013", "Und", "ach", ",", "die", "un\u00b7barm\u00b7her\u00b7zi\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PPER", "$.", "$(", "KON", "XY", "$,", "ART", "NN"], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Verleger, die sonst, wie Kanibalen,", "tokens": ["Ver\u00b7le\u00b7ger", ",", "die", "sonst", ",", "wie", "Ka\u00b7ni\u00b7ba\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADV", "$,", "PWAV", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Vom Autorgehirne sich m\u00e4steten,", "tokens": ["Vom", "Au\u00b7tor\u00b7ge\u00b7hir\u00b7ne", "sich", "m\u00e4s\u00b7te\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+--+--+--", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Die lassen sich's nun mit Weib und Kindern gefallen,", "tokens": ["Die", "las\u00b7sen", "sich's", "nun", "mit", "Weib", "und", "Kin\u00b7dern", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "APPR", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Und lernen endlich erkennen, da\u00df man", "tokens": ["Und", "ler\u00b7nen", "end\u00b7lich", "er\u00b7ken\u00b7nen", ",", "da\u00df", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "VVINF", "$,", "KOUS", "PIS"], "meter": "-+-+--+-++", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Von Menschenhandarbeit auch leben kann.", "tokens": ["Von", "Men\u00b7schen\u00b7hand\u00b7ar\u00b7beit", "auch", "le\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Wer lehrte sie das? Wer entw\u00f6hnte sie", "tokens": ["Wer", "lehr\u00b7te", "sie", "das", "?", "Wer", "ent\u00b7w\u00f6hn\u00b7te", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PDS", "$.", "PWS", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Vom Menschengehirne? \u2013 Wer anders, als die,", "tokens": ["Vom", "Men\u00b7schen\u00b7ge\u00b7hir\u00b7ne", "?", "\u2013", "Wer", "an\u00b7ders", ",", "als", "die", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "$(", "PWS", "ADV", "$,", "KOUS", "ART", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.13": {"text": "Die, satt des Greuels, menschlicher dachten,", "tokens": ["Die", ",", "satt", "des", "Greu\u00b7els", ",", "menschli\u00b7cher", "dach\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "$,", "KOUI", "ART", "NN", "$,", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und statt des Gehirns ihnen Handarbeit brachten?", "tokens": ["Und", "statt", "des", "Ge\u00b7hirns", "ih\u00b7nen", "Hand\u00b7ar\u00b7beit", "brach\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PPER", "NN", "VVFIN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.15": {"text": "Seyd stolz, ihr Herr'n, die ihr das gethan!", "tokens": ["Seyd", "stolz", ",", "ihr", "Herr'n", ",", "die", "ihr", "das", "ge\u00b7than", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADJD", "$,", "PPOSAT", "NN", "$,", "PRELS", "PPER", "PDS", "VVPP", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.16": {"text": "Ihr werdet unverge\u00dflich bleiben,", "tokens": ["Ihr", "wer\u00b7det", "un\u00b7ver\u00b7ge\u00df\u00b7lich", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "Die Menschheit wird euch obenan", "tokens": ["Die", "Menschheit", "wird", "euch", "o\u00b7be\u00b7nan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.18": {"text": "In ihre geheiligten Jahrb\u00fccher schreiben:", "tokens": ["In", "ih\u00b7re", "ge\u00b7hei\u00b7lig\u00b7ten", "Jahr\u00b7b\u00fc\u00b7cher", "schrei\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+--+---+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "Auch denken bereits an euern Lohn", "tokens": ["Auch", "den\u00b7ken", "be\u00b7reits", "an", "eu\u00b7ern", "Lohn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Die Ephemeriden der Menschheit schon.", "tokens": ["Die", "E\u00b7phe\u00b7me\u00b7ri\u00b7den", "der", "Menschheit", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.17": {"line.1": {"text": "Und dann erst der Nutzen, den eu're Schriften", "tokens": ["Und", "dann", "erst", "der", "Nut\u00b7zen", ",", "den", "eu'\u00b7re", "Schrif\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "In der gesammten Wienerwelt stiften!", "tokens": ["In", "der", "ge\u00b7samm\u00b7ten", "Wie\u00b7ner\u00b7welt", "stif\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Durch euch kommt Licht in's Volk; denn was ihr schreibt,", "tokens": ["Durch", "euch", "kommt", "Licht", "in's", "Volk", ";", "denn", "was", "ihr", "schreibt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "NN", "APPRART", "NN", "$.", "KON", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dringt bis in die K\u00e4s'- und Gew\u00fcrzkr\u00e4mmerbuden:", "tokens": ["Dringt", "bis", "in", "die", "K\u00e4s'", "und", "Ge\u00b7w\u00fcrz\u00b7kr\u00e4m\u00b7mer\u00b7bu\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "ART", "TRUNC", "KON", "NN", "$."], "meter": "----+--+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Die Magd, die sonst nur Kaffeebohnen reibt,", "tokens": ["Die", "Magd", ",", "die", "sonst", "nur", "Kaf\u00b7fee\u00b7boh\u00b7nen", "reibt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Schw\u00e4tzt nun von Reformen der Christen und Juden,", "tokens": ["Schw\u00e4tzt", "nun", "von", "Re\u00b7for\u00b7men", "der", "Chris\u00b7ten", "und", "Ju\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "ART", "NN", "KON", "NN", "$,"], "meter": "++-++--+--+-", "measure": "trochaic.hexa.relaxed"}, "line.7": {"text": "Und wei\u00df auf ein Haar, was jeder Zweig im Staat", "tokens": ["Und", "wei\u00df", "auf", "ein", "Haar", ",", "was", "je\u00b7der", "Zweig", "im", "Staat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "APPRART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "F\u00fcr Beulen und Anomalien hat.", "tokens": ["F\u00fcr", "Beu\u00b7len", "und", "A\u00b7no\u00b7ma\u00b7li\u00b7en", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.9": {"text": "Nur ihr versteht die Kunst, nur ihr,", "tokens": ["Nur", "ihr", "ver\u00b7steht", "die", "Kunst", ",", "nur", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "VVFIN", "ART", "NN", "$,", "ADV", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Den niedrigsten P\u00f6bel aufzukl\u00e4ren,", "tokens": ["Den", "nied\u00b7rigs\u00b7ten", "P\u00f6\u00b7bel", "auf\u00b7zu\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ohn' da\u00df er es merkt; dann w\u00fcrdet ihr,", "tokens": ["Ohn'", "da\u00df", "er", "es", "merkt", ";", "dann", "w\u00fcr\u00b7det", "ihr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "KOUS", "PPER", "PPER", "VVFIN", "$.", "ADV", "VAFIN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.12": {"text": "Wie sonst geschah, ihn geradezu lehren,", "tokens": ["Wie", "sonst", "ge\u00b7schah", ",", "ihn", "ge\u00b7ra\u00b7de\u00b7zu", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "$,", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.13": {"text": "Dumm, wie er ist, und in seine Dummheit verliebt,", "tokens": ["Dumm", ",", "wie", "er", "ist", ",", "und", "in", "sei\u00b7ne", "Dumm\u00b7heit", "ver\u00b7liebt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "VAFIN", "$,", "KON", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}, "line.14": {"text": "Er w\u00fcrde, erbo\u00dft, gegen eu're Brosch\u00fcren sich wehren;", "tokens": ["Er", "w\u00fcr\u00b7de", ",", "er\u00b7bo\u00dft", ",", "ge\u00b7gen", "eu'\u00b7re", "Bro\u00b7sch\u00fc\u00b7ren", "sich", "weh\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "PRF", "VVINF", "$."], "meter": "-+--+--+--+--+-", "measure": "amphibrach.penta.plus"}, "line.15": {"text": "Allein, ihr wi\u00dft, wie man den Kindern Arzneyen gibt,", "tokens": ["Al\u00b7lein", ",", "ihr", "wi\u00dft", ",", "wie", "man", "den", "Kin\u00b7dern", "Arz\u00b7ne\u00b7yen", "gibt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "$,", "PWAV", "PIS", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.16": {"text": "Und la\u00dft eure Bl\u00e4tter, eins nach dem andern,", "tokens": ["Und", "la\u00dft", "eu\u00b7re", "Bl\u00e4t\u00b7ter", ",", "eins", "nach", "dem", "an\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPOSAT", "NN", "$,", "PIS", "APPR", "ART", "ADJA", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Als Pfefferd\u00fcten, als Zuckerpapier", "tokens": ["Als", "Pfef\u00b7fer\u00b7d\u00fc\u00b7ten", ",", "als", "Zu\u00b7cker\u00b7pa\u00b7pier"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["KOUS", "NN", "$,", "KOUS", "NN"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.18": {"text": "Ganz heimlich in seine Taschen wandern.", "tokens": ["Ganz", "heim\u00b7lich", "in", "sei\u00b7ne", "Ta\u00b7schen", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.19": {"text": "In Schenken und Bierh\u00e4usern waltet ihr:", "tokens": ["In", "Schen\u00b7ken", "und", "Bier\u00b7h\u00e4u\u00b7sern", "wal\u00b7tet", "ihr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Denn sitzet oft ein Zirkel von Schneidern,", "tokens": ["Denn", "sit\u00b7zet", "oft", "ein", "Zir\u00b7kel", "von", "Schnei\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.21": {"text": "Nichts B\u00f6ses ahnend, bei Wein und Bier,", "tokens": ["Nichts", "B\u00f6\u00b7ses", "ah\u00b7nend", ",", "bei", "Wein", "und", "Bier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "VVPP", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.22": {"text": "Und schw\u00e4tzt von Kriegsaffairen und Kleidern,", "tokens": ["Und", "schw\u00e4tzt", "von", "Kriegs\u00b7af\u00b7fai\u00b7ren", "und", "Klei\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.23": {"text": "Hui k\u00f6mm't, eh' sich's der Zirkel versieht,", "tokens": ["Hui", "k\u00f6m\u00b7m't", ",", "eh'", "sich's", "der", "Zir\u00b7kel", "ver\u00b7sieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["FM", "VVFIN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Ein St\u00fcckchen Holl\u00e4nderk\u00e4s', und mit", "tokens": ["Ein", "St\u00fcck\u00b7chen", "Hol\u00b7l\u00e4n\u00b7der\u00b7k\u00e4s'", ",", "und", "mit"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "NE", "$,", "KON", "APPR"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Ein Bl\u00e4ttchen von euch: man guckt und spitzt das Ohr", "tokens": ["Ein", "Bl\u00e4tt\u00b7chen", "von", "euch", ":", "man", "guckt", "und", "spitzt", "das", "Ohr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "$.", "PIS", "VVFIN", "KON", "VVFIN", "ART", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Und kann nur einer aus ihnen buchstabiren,", "tokens": ["Und", "kann", "nur", "ei\u00b7ner", "aus", "ih\u00b7nen", "buch\u00b7sta\u00b7bi\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "ART", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "So nimmt er's, und liest's seinen Trinkbr\u00fcdern vor.", "tokens": ["So", "nimmt", "er's", ",", "und", "liest's", "sei\u00b7nen", "Trink\u00b7br\u00fc\u00b7dern", "vor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "So lernt der P\u00f6bel raisonniren,", "tokens": ["So", "lernt", "der", "P\u00f6\u00b7bel", "rai\u00b7son\u00b7ni\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Und das durch euch: macht ein satyrisch Gesicht", "tokens": ["Und", "das", "durch", "euch", ":", "macht", "ein", "sa\u00b7ty\u00b7risch", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPR", "PPER", "$.", "VVFIN", "ART", "ADJD", "NN"], "meter": "--+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Zu allem, was er sieht: nennt seine Landsleut' Affen,", "tokens": ["Zu", "al\u00b7lem", ",", "was", "er", "sieht", ":", "nennt", "sei\u00b7ne", "Lands\u00b7leut'", "Af\u00b7fen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PWS", "PPER", "VVFIN", "$.", "VVFIN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Den Papst Tyrann, und seine Geistlichen \u2013 Pfaffen.", "tokens": ["Den", "Papst", "Ty\u00b7rann", ",", "und", "sei\u00b7ne", "Geist\u00b7li\u00b7chen", "\u2013", "Pfaf\u00b7fen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "KON", "PPOSAT", "NN", "$(", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.32": {"text": "O fehlten mir doch die ", "tokens": ["O", "fehl\u00b7ten", "mir", "doch", "die"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ART"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Aus denen sonst die Panegyriker blasen,", "tokens": ["Aus", "de\u00b7nen", "sonst", "die", "Pa\u00b7ne\u00b7gy\u00b7ri\u00b7ker", "bla\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.34": {"text": "Ich bliese, traun, in ellenlangen Phrasen", "tokens": ["Ich", "blie\u00b7se", ",", "traun", ",", "in", "el\u00b7len\u00b7lan\u00b7gen", "Phra\u00b7sen"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVINF", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.35": {"text": "Der Nachwelt euer Lob in's Angesicht.", "tokens": ["Der", "Nach\u00b7welt", "eu\u00b7er", "Lob", "in's", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Und dir, o Wien, will ich mit einem Wunsche fr\u00f6hnen,", "tokens": ["Und", "dir", ",", "o", "Wi\u00b7en", ",", "will", "ich", "mit", "ei\u00b7nem", "Wun\u00b7sche", "fr\u00f6h\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$,", "FM", "NE", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der soll dein Gl\u00fcck, verkennst du es nur nicht,", "tokens": ["Der", "soll", "dein", "Gl\u00fcck", ",", "ver\u00b7kennst", "du", "es", "nur", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPOSAT", "NN", "$,", "VVFIN", "PPER", "PPER", "ADV", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Das seiner Vollendung schon nah ist, kr\u00f6nen.", "tokens": ["Das", "sei\u00b7ner", "Vol\u00b7len\u00b7dung", "schon", "nah", "ist", ",", "kr\u00f6\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Es mehre sich in dir mit jedem Tag", "tokens": ["Es", "meh\u00b7re", "sich", "in", "dir", "mit", "je\u00b7dem", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Der edle, n\u00fctzliche Schriftstellerorden:", "tokens": ["Der", "ed\u00b7le", ",", "n\u00fctz\u00b7li\u00b7che", "Schrift\u00b7stel\u00b7le\u00b7ror\u00b7den", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Es schreibe, was nur schreiben mag!", "tokens": ["Es", "schrei\u00b7be", ",", "was", "nur", "schrei\u00b7ben", "mag", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der Metzger h\u00f6re auf vom Morden", "tokens": ["Der", "Metz\u00b7ger", "h\u00f6\u00b7re", "auf", "vom", "Mor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Des armen Vieh's, und nehme die Feder zur Hand;", "tokens": ["Des", "ar\u00b7men", "Vieh's", ",", "und", "neh\u00b7me", "die", "Fe\u00b7der", "zur", "Hand", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "$,", "KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Schuster stecke die Ahl' an die Wand,", "tokens": ["Der", "Schus\u00b7ter", "ste\u00b7cke", "die", "Ahl'", "an", "die", "Wand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Und schreibe Theorien von Schuhen;", "tokens": ["Und", "schrei\u00b7be", "The\u00b7o\u00b7ri\u00b7en", "von", "Schu\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NE", "APPR", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Der Schneider la\u00df' Scheer' und Nadel ruhen,", "tokens": ["Der", "Schnei\u00b7der", "la\u00df'", "Scheer'", "und", "Na\u00b7del", "ru\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVIMP", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Und schreibe von Moden ein Lehrgedicht:", "tokens": ["Und", "schrei\u00b7be", "von", "Mo\u00b7den", "ein", "Lehr\u00b7ge\u00b7dicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Kein M\u00fcller mahl', kein Zimmermann hoble nicht,", "tokens": ["Kein", "M\u00fcl\u00b7ler", "mahl'", ",", "kein", "Zim\u00b7mer\u00b7mann", "hob\u00b7le", "nicht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.14": {"text": "Der hoble die Welt, und jener mahle", "tokens": ["Der", "hob\u00b7le", "die", "Welt", ",", "und", "je\u00b7ner", "mah\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ART", "NN", "$,", "KON", "PDS", "VVFIN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "Die Wahrheit zu Staub, und streu' mit satyrischer Galle", "tokens": ["Die", "Wahr\u00b7heit", "zu", "Staub", ",", "und", "streu'", "mit", "sa\u00b7ty\u00b7ri\u00b7scher", "Gal\u00b7le"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+--+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Vermischt, sie den Lesern in's Angesicht;", "tokens": ["Ver\u00b7mischt", ",", "sie", "den", "Le\u00b7sern", "in's", "An\u00b7ge\u00b7sicht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPER", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Der T\u00f6pfer modle am Recht; der Schmiede erhebe den Hammer", "tokens": ["Der", "T\u00f6p\u00b7fer", "mod\u00b7le", "am", "Recht", ";", "der", "Schmie\u00b7de", "er\u00b7he\u00b7be", "den", "Ham\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$.", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Der Kritik \u00fcber Theologie;", "tokens": ["Der", "Kri\u00b7tik", "\u00fc\u00b7ber", "Theo\u00b7lo\u00b7gie", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Der Schreiner meublire Zimmer und Kammer", "tokens": ["Der", "Schrei\u00b7ner", "meub\u00b7li\u00b7re", "Zim\u00b7mer", "und", "Kam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Mit sch\u00f6n gegl\u00e4tteter Philosophie;", "tokens": ["Mit", "sch\u00f6n", "ge\u00b7gl\u00e4t\u00b7te\u00b7ter", "Phi\u00b7lo\u00b7so\u00b7phie", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Der Staubgewohnte Per\u00fcckenmacher k\u00e4mme", "tokens": ["Der", "Staub\u00b7ge\u00b7wohn\u00b7te", "Pe\u00b7r\u00fc\u00b7cken\u00b7ma\u00b7cher", "k\u00e4m\u00b7me"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Die Religion, der Weber webe Systeme:", "tokens": ["Die", "Re\u00b7li\u00b7gi\u00b7on", ",", "der", "We\u00b7ber", "we\u00b7be", "Sys\u00b7te\u00b7me", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Und so nach allen Z\u00fcnften und St\u00e4nden", "tokens": ["Und", "so", "nach", "al\u00b7len", "Z\u00fcnf\u00b7ten", "und", "St\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.24": {"text": "Thu jeder mit seinen fertigen H\u00e4nden,", "tokens": ["Thu", "je\u00b7der", "mit", "sei\u00b7nen", "fer\u00b7ti\u00b7gen", "H\u00e4n\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.25": {"text": "Was Autorpflicht ist! Und das, o Wien,", "tokens": ["Was", "Au\u00b7tor\u00b7pflicht", "ist", "!", "Und", "das", ",", "o", "Wi\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "VAFIN", "$.", "KON", "PDS", "$,", "FM", "NE", "$,"], "meter": "-+-+----+-", "measure": "unknown.measure.tri"}, "line.26": {"text": "Wird, glaub's dem Propheten, aller Zeiten", "tokens": ["Wird", ",", "glaub's", "dem", "Pro\u00b7phe\u00b7ten", ",", "al\u00b7ler", "Zei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "$,", "NE", "ART", "NN", "$,", "PIAT", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.27": {"text": "Und V\u00f6lker Augen auf dich zieh'n,", "tokens": ["Und", "V\u00f6l\u00b7ker", "Au\u00b7gen", "auf", "dich", "zieh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und deinen Ruhm bis \u00fcber die Sterne verbreiten.", "tokens": ["Und", "dei\u00b7nen", "Ruhm", "bis", "\u00fc\u00b7ber", "die", "Ster\u00b7ne", "ver\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}}}}}