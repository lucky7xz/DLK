{"textgrid.poem.52024": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die kurtze Satyra, verzeih es Leser mir,", "tokens": ["Die", "kurt\u00b7ze", "Sa\u00b7ty\u00b7ra", ",", "ver\u00b7zeih", "es", "Le\u00b7ser", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVIMP", "PPER", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wil ihr das Maul zu lang schon wieder lassen werden:", "tokens": ["Wil", "ihr", "das", "Maul", "zu", "lang", "schon", "wie\u00b7der", "las\u00b7sen", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKA", "ADJD", "ADV", "ADV", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo Amt und Stand und Haus mit wichtigen Beschwerden", "tokens": ["Wo", "Amt", "und", "Stand", "und", "Haus", "mit", "wich\u00b7ti\u00b7gen", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dich ja beladen hat, so weise sie von dir.", "tokens": ["Dich", "ja", "be\u00b7la\u00b7den", "hat", ",", "so", "wei\u00b7se", "sie", "von", "dir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ob Sie gleich unn\u00fctz ist, und kein Blat vor den Mund", "tokens": ["Ob", "Sie", "gleich", "un\u00b7n\u00fctz", "ist", ",", "und", "kein", "Blat", "vor", "den", "Mund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "KON", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In ihrem Schertzen nimmt, und wahr redt unterm Lachen:", "tokens": ["In", "ih\u00b7rem", "Schert\u00b7zen", "nimmt", ",", "und", "wahr", "redt", "un\u00b7term", "La\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kan sie doch Schertz und Ernst zu s\u00fc\u00dfer Mischung machen,", "tokens": ["Kan", "sie", "doch", "Schertz", "und", "Ernst", "zu", "s\u00fc\u00b7\u00dfer", "Misc\u00b7hung", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wen es verdreust, mit dem hat es wol einen Hund.", "tokens": ["Wen", "es", "ver\u00b7dreust", ",", "mit", "dem", "hat", "es", "wol", "ei\u00b7nen", "Hund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "APPR", "ART", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}}, "stanza.3": {"line.1": {"text": "La\u00df sie zu dir hienein, da, wann du m\u00fc\u00dfig bist,", "tokens": ["La\u00df", "sie", "zu", "dir", "hien\u00b7ein", ",", "da", ",", "wann", "du", "m\u00fc\u00b7\u00dfig", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPER", "PAV", "$,", "KOUS", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann aus dem Miltze gleich die Schwermuth kommt gestiegen,", "tokens": ["Wann", "aus", "dem", "Milt\u00b7ze", "gleich", "die", "Schwer\u00b7muth", "kommt", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird ein Gel\u00e4chter Sie doch alsobald besiegen,", "tokens": ["Wird", "ein", "Ge\u00b7l\u00e4ch\u00b7ter", "Sie", "doch", "al\u00b7so\u00b7bald", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn Momus selber lacht, wenn er die Verse liest.", "tokens": ["Denn", "Mo\u00b7mus", "sel\u00b7ber", "lacht", ",", "wenn", "er", "die", "Ver\u00b7se", "liest", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Die kurtze Satyra, verzeih es Leser mir,", "tokens": ["Die", "kurt\u00b7ze", "Sa\u00b7ty\u00b7ra", ",", "ver\u00b7zeih", "es", "Le\u00b7ser", "mir", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVIMP", "PPER", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wil ihr das Maul zu lang schon wieder lassen werden:", "tokens": ["Wil", "ihr", "das", "Maul", "zu", "lang", "schon", "wie\u00b7der", "las\u00b7sen", "wer\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "PTKA", "ADJD", "ADV", "ADV", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo Amt und Stand und Haus mit wichtigen Beschwerden", "tokens": ["Wo", "Amt", "und", "Stand", "und", "Haus", "mit", "wich\u00b7ti\u00b7gen", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dich ja beladen hat, so weise sie von dir.", "tokens": ["Dich", "ja", "be\u00b7la\u00b7den", "hat", ",", "so", "wei\u00b7se", "sie", "von", "dir", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVPP", "VAFIN", "$,", "ADV", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ob Sie gleich unn\u00fctz ist, und kein Blat vor den Mund", "tokens": ["Ob", "Sie", "gleich", "un\u00b7n\u00fctz", "ist", ",", "und", "kein", "Blat", "vor", "den", "Mund"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$,", "KON", "PIAT", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "In ihrem Schertzen nimmt, und wahr redt unterm Lachen:", "tokens": ["In", "ih\u00b7rem", "Schert\u00b7zen", "nimmt", ",", "und", "wahr", "redt", "un\u00b7term", "La\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "KON", "ADJD", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Kan sie doch Schertz und Ernst zu s\u00fc\u00dfer Mischung machen,", "tokens": ["Kan", "sie", "doch", "Schertz", "und", "Ernst", "zu", "s\u00fc\u00b7\u00dfer", "Misc\u00b7hung", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wen es verdreust, mit dem hat es wol einen Hund.", "tokens": ["Wen", "es", "ver\u00b7dreust", ",", "mit", "dem", "hat", "es", "wol", "ei\u00b7nen", "Hund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "APPR", "ART", "VAFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+--+--+-+--+", "measure": "dactylic.di.plus"}}, "stanza.6": {"line.1": {"text": "La\u00df sie zu dir hienein, da, wann du m\u00fc\u00dfig bist,", "tokens": ["La\u00df", "sie", "zu", "dir", "hien\u00b7ein", ",", "da", ",", "wann", "du", "m\u00fc\u00b7\u00dfig", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPER", "PAV", "$,", "KOUS", "$,", "PWAV", "PPER", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wann aus dem Miltze gleich die Schwermuth kommt gestiegen,", "tokens": ["Wann", "aus", "dem", "Milt\u00b7ze", "gleich", "die", "Schwer\u00b7muth", "kommt", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "ADV", "ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wird ein Gel\u00e4chter Sie doch alsobald besiegen,", "tokens": ["Wird", "ein", "Ge\u00b7l\u00e4ch\u00b7ter", "Sie", "doch", "al\u00b7so\u00b7bald", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn Momus selber lacht, wenn er die Verse liest.", "tokens": ["Denn", "Mo\u00b7mus", "sel\u00b7ber", "lacht", ",", "wenn", "er", "die", "Ver\u00b7se", "liest", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}