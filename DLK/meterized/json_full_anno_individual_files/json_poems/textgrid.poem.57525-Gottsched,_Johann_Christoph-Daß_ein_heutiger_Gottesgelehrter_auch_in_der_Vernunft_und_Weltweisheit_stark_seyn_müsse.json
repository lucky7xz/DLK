{"textgrid.poem.57525": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "Da\u00df ein heutiger Gottesgelehrter auch in der Vernunft und Weltweisheit stark seyn m\u00fcsse", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gl\u00fcck zu, ber\u00fchmter Mann! und auserlesner Freund!", "tokens": ["Gl\u00fcck", "zu", ",", "be\u00b7r\u00fchm\u00b7ter", "Mann", "!", "und", "au\u00b7ser\u00b7les\u00b7ner", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADJA", "NN", "$.", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie freudig bin ich doch, indem der Tag erscheint,", "tokens": ["Wie", "freu\u00b7dig", "bin", "ich", "doch", ",", "in\u00b7dem", "der", "Tag", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da deine W\u00fcrde steigt! Nun hat mein altes Hoffen", "tokens": ["Da", "dei\u00b7ne", "W\u00fcr\u00b7de", "steigt", "!", "Nun", "hat", "mein", "al\u00b7tes", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$.", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch deinen Doctorhut doch v\u00f6llig eingetroffen.", "tokens": ["Durch", "dei\u00b7nen", "Doc\u00b7tor\u00b7hut", "doch", "v\u00f6l\u00b7lig", "ein\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Besinne dich nur selbst, was ich dir oft gesagt,", "tokens": ["Be\u00b7sin\u00b7ne", "dich", "nur", "selbst", ",", "was", "ich", "dir", "oft", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,", "PWS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn du mir den Verfall der Gr\u00fcndlichkeit geklagt,", "tokens": ["Wenn", "du", "mir", "den", "Ver\u00b7fall", "der", "Gr\u00fcnd\u00b7lich\u00b7keit", "ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der unsern Glauben schimpft. Wir sahen ganze Rotten", "tokens": ["Der", "un\u00b7sern", "Glau\u00b7ben", "schimpft", ".", "Wir", "sa\u00b7hen", "gan\u00b7ze", "Rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den hohen Inbegriff des Christenthums verspotten:", "tokens": ["Den", "ho\u00b7hen", "In\u00b7be\u00b7griff", "des", "Chris\u00b7ten\u00b7thums", "ver\u00b7spot\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und gleichwohl schien die Zahl der Eifrer viel zu klein,", "tokens": ["Und", "gleich\u00b7wohl", "schien", "die", "Zahl", "der", "Eif\u00b7rer", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Streiten unge\u00fcbt, an Waffen schwach zu seyn,", "tokens": ["Im", "Strei\u00b7ten", "un\u00b7ge\u00b7\u00fcbt", ",", "an", "Waf\u00b7fen", "schwach", "zu", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die es verfechten soll. Hier regten, von der Liebe", "tokens": ["Die", "es", "ver\u00b7fech\u00b7ten", "soll", ".", "Hier", "reg\u00b7ten", ",", "von", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$.", "ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zur Gottsgelahrtheit, sich in mir die alten Triebe.", "tokens": ["Zur", "Gotts\u00b7ge\u00b7lahr\u00b7theit", ",", "sich", "in", "mir", "die", "al\u00b7ten", "Trie\u00b7be", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRF", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Indessen war mir auch dein gr\u00fcndlicher Verstand,", "tokens": ["In\u00b7des\u00b7sen", "war", "mir", "auch", "dein", "gr\u00fcnd\u00b7li\u00b7cher", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Sprachen Wissenschaft und muntrer Witz bekannt.", "tokens": ["Der", "Spra\u00b7chen", "Wis\u00b7sen\u00b7schaft", "und", "mun\u00b7trer", "Witz", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich wu\u00dfte, wie ge\u00fcbt dein s\u00fc\u00dfer Mund im Lehren,", "tokens": ["Ich", "wu\u00df\u00b7te", ",", "wie", "ge\u00b7\u00fcbt", "dein", "s\u00fc\u00b7\u00dfer", "Mund", "im", "Leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "VVPP", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Dein Kiel im Schreiben war, der Kirche Wohl zu mehren.", "tokens": ["Dein", "Kiel", "im", "Schrei\u00b7ben", "war", ",", "der", "Kir\u00b7che", "Wohl", "zu", "meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So gieng denn schon vorl\u00e4ngst mein ganzer Wunsch dahin:", "tokens": ["So", "gieng", "denn", "schon", "vor\u00b7l\u00e4ngst", "mein", "gan\u00b7zer", "Wunsch", "da\u00b7hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "(du weist, gelehrter Freund! da\u00df ich kein Schm\u00e4uchler bin.)", "tokens": ["(", "du", "weist", ",", "ge\u00b7lehr\u00b7ter", "Freund", "!", "da\u00df", "ich", "kein", "Schm\u00e4uch\u00b7ler", "bin", ".", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "KOUS", "PPER", "PIAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Dich, werther ", "tokens": ["Dich", ",", "wert\u00b7her"], "token_info": ["word", "punct", "word"], "pos": ["PPER", "$,", "PWS"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Und unsers Glaubens Schutz, der Sp\u00f6tter Trotz zu nennen.", "tokens": ["Und", "un\u00b7sers", "Glau\u00b7bens", "Schutz", ",", "der", "Sp\u00f6t\u00b7ter", "Trotz", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nunmehr trifft alles ein. Wir habens j\u00fcngst geh\u00f6rt,", "tokens": ["Nun\u00b7mehr", "trifft", "al\u00b7les", "ein", ".", "Wir", "ha\u00b7bens", "j\u00fcngst", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was du zum Probest\u00fcck und \u00f6ffentlich gelehrt:", "tokens": ["Was", "du", "zum", "Pro\u00b7be\u00b7st\u00fcck", "und", "\u00f6f\u00b7fent\u00b7lich", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie du von ", "tokens": ["Wie", "du", "von"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "So b\u00fcndig und gelehrt den seichten Grund gewiesen.", "tokens": ["So", "b\u00fcn\u00b7dig", "und", "ge\u00b7lehrt", "den", "seich\u00b7ten", "Grund", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir haben auch gesehn, wie du so meisterlich", "tokens": ["Wir", "ha\u00b7ben", "auch", "ge\u00b7sehn", ",", "wie", "du", "so", "meis\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "PWAV", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Ganz frevelhaft erk\u00fchnt, an Christi Wunderthaten", "tokens": ["Ganz", "fre\u00b7vel\u00b7haft", "er\u00b7k\u00fchnt", ",", "an", "Chris\u00b7ti", "Wun\u00b7der\u00b7tha\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "$,", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Schw\u00e4che des Gehirns und Witzes zu verrathen.", "tokens": ["Die", "Schw\u00e4\u00b7che", "des", "Ge\u00b7hirns", "und", "Wit\u00b7zes", "zu", "ver\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O! dacht ich, dieses thun die Waffen der Vernunft;", "tokens": ["O", "!", "dacht", "ich", ",", "die\u00b7ses", "thun", "die", "Waf\u00b7fen", "der", "Ver\u00b7nunft", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PDS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als deren Uebung ihm in unsrer Weisen Zunft", "tokens": ["Als", "de\u00b7ren", "Ue\u00b7bung", "ihm", "in", "uns\u00b7rer", "Wei\u00b7sen", "Zunft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRELAT", "NN", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So vielen Ruhm gebracht. Man kennt schon ", "tokens": ["So", "vie\u00b7len", "Ruhm", "ge\u00b7bracht", ".", "Man", "kennt", "schon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$.", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Man lobt die Gr\u00fcndlichkeit in jedem seiner Werke;", "tokens": ["Man", "lobt", "die", "Gr\u00fcnd\u00b7lich\u00b7keit", "in", "je\u00b7dem", "sei\u00b7ner", "Wer\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Kenntni\u00df der Natur, des Geistes und der Welt,", "tokens": ["Die", "Kennt\u00b7ni\u00df", "der", "Na\u00b7tur", ",", "des", "Geis\u00b7tes", "und", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Des Sch\u00f6pfers, dessen Kraft sie schaffet und erh\u00e4lt;", "tokens": ["Des", "Sch\u00f6p\u00b7fers", ",", "des\u00b7sen", "Kraft", "sie", "schaf\u00b7fet", "und", "er\u00b7h\u00e4lt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die schnelle Fertigkeit im Denken und Erweisen,", "tokens": ["Die", "schnel\u00b7le", "Fer\u00b7tig\u00b7keit", "im", "Den\u00b7ken", "und", "Er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und was wir sonst an ihm, seit vielen Jahren, preisen.", "tokens": ["Und", "was", "wir", "sonst", "an", "ihm", ",", "seit", "vie\u00b7len", "Jah\u00b7ren", ",", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "APPR", "PPER", "$,", "APPR", "PIAT", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das alles steht ihm bey, das hat ihn stark gemacht,", "tokens": ["Das", "al\u00b7les", "steht", "ihm", "bey", ",", "das", "hat", "ihn", "stark", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PDS", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df er der Feinde Spott in Sicherheit verlacht;", "tokens": ["Da\u00df", "er", "der", "Fein\u00b7de", "Spott", "in", "Si\u00b7cher\u00b7heit", "ver\u00b7lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der Glaubensl\u00e4strer Schwarm so ruhig widerleget,", "tokens": ["Der", "Glau\u00b7bens\u00b7l\u00e4st\u00b7rer", "Schwarm", "so", "ru\u00b7hig", "wi\u00b7der\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und ihrer Zweifel Heer so leicht zu Boden schl\u00e4get.", "tokens": ["Und", "ih\u00b7rer", "Zwei\u00b7fel", "Heer", "so", "leicht", "zu", "Bo\u00b7den", "schl\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "ADV", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "So soll, so mu\u00df es gehn, wenn man den Glauben sch\u00fctzt!", "tokens": ["So", "soll", ",", "so", "mu\u00df", "es", "gehn", ",", "wenn", "man", "den", "Glau\u00b7ben", "sch\u00fctzt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier hilft die Bibel nichts, die sonst so herrlich n\u00fctzt,", "tokens": ["Hier", "hilft", "die", "Bi\u00b7bel", "nichts", ",", "die", "sonst", "so", "herr\u00b7lich", "n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "$,", "PRELS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn man mit Ketzern k\u00e4mpft: denn deren freches Wagen", "tokens": ["Wenn", "man", "mit", "Ket\u00b7zern", "k\u00e4mpft", ":", "denn", "de\u00b7ren", "fre\u00b7ches", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$.", "KON", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kann mancher starke Spruch gewaltig niederschlagen.", "tokens": ["Kann", "man\u00b7cher", "star\u00b7ke", "Spruch", "ge\u00b7wal\u00b7tig", "nie\u00b7der\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer Gottes Wort erkennt, die Offenbarung ehrt,", "tokens": ["Wer", "Got\u00b7tes", "Wort", "er\u00b7kennt", ",", "die", "Of\u00b7fen\u00b7ba\u00b7rung", "ehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Geistes Sinn erforscht, die M\u00e4nner Gottes h\u00f6rt,", "tokens": ["Des", "Geis\u00b7tes", "Sinn", "er\u00b7forscht", ",", "die", "M\u00e4n\u00b7ner", "Got\u00b7tes", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der l\u00e4\u00dft sich durch die Kraft der Schrift am besten lenken;", "tokens": ["Der", "l\u00e4\u00dft", "sich", "durch", "die", "Kraft", "der", "Schrift", "am", "bes\u00b7ten", "len\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da darf man au\u00dfer ihr an keine Gr\u00fcnde denken.", "tokens": ["Da", "darf", "man", "au\u00b7\u00dfer", "ihr", "an", "kei\u00b7ne", "Gr\u00fcn\u00b7de", "den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "PPOSAT", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo aber die Vernunft sich selber Weihrauch streut,", "tokens": ["Wo", "a\u00b7ber", "die", "Ver\u00b7nunft", "sich", "sel\u00b7ber", "Weih\u00b7rauch", "streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PRF", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Schrift nicht h\u00f6ren will, von Vorurtheilen schreyt,", "tokens": ["Die", "Schrift", "nicht", "h\u00f6\u00b7ren", "will", ",", "von", "Vor\u00b7urt\u00b7hei\u00b7len", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nur falsche Schl\u00fcsse macht, und aus vermeynten Gr\u00fcnden", "tokens": ["Nur", "fal\u00b7sche", "Schl\u00fcs\u00b7se", "macht", ",", "und", "aus", "ver\u00b7meyn\u00b7ten", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$,", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die zweifelhafte Spur der Wahrheit sucht zu finden;", "tokens": ["Die", "zwei\u00b7fel\u00b7haf\u00b7te", "Spur", "der", "Wahr\u00b7heit", "sucht", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da mu\u00df ein Glaubensheld auch anders widerstehn;", "tokens": ["Da", "mu\u00df", "ein", "Glau\u00b7bens\u00b7held", "auch", "an\u00b7ders", "wi\u00b7der\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er selbst mu\u00df in das Feld der Weisheitlehren gehn;", "tokens": ["Er", "selbst", "mu\u00df", "in", "das", "Feld", "der", "Weis\u00b7heit\u00b7leh\u00b7ren", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Aus Quellen der Natur der Wahrheit B\u00e4che leiten,", "tokens": ["Aus", "Quel\u00b7len", "der", "Na\u00b7tur", "der", "Wahr\u00b7heit", "B\u00e4\u00b7che", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und die Vern\u00fcnftler selbst aus der Vernunft bestreiten.", "tokens": ["Und", "die", "Ver\u00b7n\u00fcnft\u00b7ler", "selbst", "aus", "der", "Ver\u00b7nunft", "be\u00b7strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das fodert unsre Zeit, darinn sich jene Brut", "tokens": ["Das", "fo\u00b7dert", "uns\u00b7re", "Zeit", ",", "da\u00b7rinn", "sich", "je\u00b7ne", "Brut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PAV", "PRF", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sp\u00f6tter aufgemacht, die mit so frecher Wuth", "tokens": ["Der", "Sp\u00f6t\u00b7ter", "auf\u00b7ge\u00b7macht", ",", "die", "mit", "so", "fre\u00b7cher", "Wuth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "PRELS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Glaubens Burg best\u00fcrmt. Es sind nicht Ketzereyen;", "tokens": ["Des", "Glau\u00b7bens", "Burg", "be\u00b7st\u00fcrmt", ".", "Es", "sind", "nicht", "Ket\u00b7ze\u00b7re\u00b7yen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$.", "PPER", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Man will sich von dem Joch des Christenthums befreyen!", "tokens": ["Man", "will", "sich", "von", "dem", "Joch", "des", "Chris\u00b7ten\u00b7thums", "be\u00b7fre\u00b7yen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Das wird gef\u00e4hrlicher von neuem auferweckt,", "tokens": ["Das", "wird", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", "von", "neu\u00b7em", "au\u00b7fer\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verst\u00e4rket, ausgeputzt, erg\u00e4nzet und vermehret:", "tokens": ["Ver\u00b7st\u00e4r\u00b7ket", ",", "aus\u00b7ge\u00b7putzt", ",", "er\u00b7g\u00e4n\u00b7zet", "und", "ver\u00b7meh\u00b7ret", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dadurch wird hier und dar der Kirche Flor versehret.", "tokens": ["Da\u00b7durch", "wird", "hier", "und", "dar", "der", "Kir\u00b7che", "Flor", "ver\u00b7seh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "KON", "PAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn was ein ", "tokens": ["Denn", "was", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "Das ist dem Christenthum zum Untergang ersonnen.", "tokens": ["Das", "ist", "dem", "Chris\u00b7ten\u00b7thum", "zum", "Un\u00b7ter\u00b7gang", "er\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hingegen, was ", "tokens": ["Hin\u00b7ge\u00b7gen", ",", "was"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$,", "PWS"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Das braucht itzt gr\u00f6\u00dfre Kunst. So gar die gute Bahn,", "tokens": ["Das", "braucht", "itzt", "gr\u00f6\u00df\u00b7re", "Kunst", ".", "So", "gar", "die", "gu\u00b7te", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJA", "NN", "$.", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die sonst ", "tokens": ["Die", "sonst"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.16": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Der b\u00fcndigste Beweis scheint itzo noch zu klein:", "tokens": ["Der", "b\u00fcn\u00b7digs\u00b7te", "Be\u00b7weis", "scheint", "it\u00b7zo", "noch", "zu", "klein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er soll noch gr\u00fcndlicher, ja unumst\u00f6\u00dflich seyn.", "tokens": ["Er", "soll", "noch", "gr\u00fcnd\u00b7li\u00b7cher", ",", "ja", "un\u00b7um\u00b7st\u00f6\u00df\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So mu\u00dften endlich auch die Kirchenlehrer denken,", "tokens": ["So", "mu\u00df\u00b7ten", "end\u00b7lich", "auch", "die", "Kir\u00b7chen\u00b7leh\u00b7rer", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Durch Regeln der Vernunft die Sp\u00f6tter einzuschr\u00e4nken.", "tokens": ["Durch", "Re\u00b7geln", "der", "Ver\u00b7nunft", "die", "Sp\u00f6t\u00b7ter", "ein\u00b7zu\u00b7schr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die\u00df war schon ", "tokens": ["Die\u00df", "war", "schon"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "In London, jedes Jahr, in diesem Glaubensstreit", "tokens": ["In", "Lon\u00b7don", ",", "je\u00b7des", "Jahr", ",", "in", "die\u00b7sem", "Glau\u00b7bens\u00b7streit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "PIAT", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Lehrer achtmal k\u00e4mpft, die Wahrheit zu verfechten.", "tokens": ["Ein", "Leh\u00b7rer", "acht\u00b7mal", "k\u00e4mpft", ",", "die", "Wahr\u00b7heit", "zu", "ver\u00b7fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier wu\u00dfte ", "tokens": ["Hier", "wu\u00df\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "So k\u00e4mpfte ", "tokens": ["So", "k\u00e4mpf\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Auch ", "tokens": ["Auch"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Wo bleibt ein ", "tokens": ["Wo", "bleibt", "ein"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.8": {"text": "Hier wies sich der Verstand in aufgekl\u00e4rter F\u00fclle!", "tokens": ["Hier", "wies", "sich", "der", "Ver\u00b7stand", "in", "auf\u00b7ge\u00b7kl\u00e4r\u00b7ter", "F\u00fcl\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die lauterste Vernunft verwarf der Thorheit Gift,", "tokens": ["Die", "lau\u00b7ters\u00b7te", "Ver\u00b7nunft", "ver\u00b7warf", "der", "Thor\u00b7heit", "Gift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und rettete die Kraft und G\u00f6ttlichkeit der Schrift.", "tokens": ["Und", "ret\u00b7te\u00b7te", "die", "Kraft", "und", "G\u00f6tt\u00b7lich\u00b7keit", "der", "Schrift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Weisheit sch\u00fctzte den, von welchem sie entsprossen,", "tokens": ["Die", "Weis\u00b7heit", "sch\u00fctz\u00b7te", "den", ",", "von", "wel\u00b7chem", "sie", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und f\u00fchrte zu dem Quell, aus welchem sie geflossen.", "tokens": ["Und", "f\u00fchr\u00b7te", "zu", "dem", "Quell", ",", "aus", "wel\u00b7chem", "sie", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Sch\u00f6pfer der Vernunft scheut ihre Pr\u00fcfung nicht,", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "der", "Ver\u00b7nunft", "scheut", "ih\u00b7re", "Pr\u00fc\u00b7fung", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er ha\u00dft den Aberwitz, nicht des Verstandes Licht.", "tokens": ["Er", "ha\u00dft", "den", "A\u00b7ber\u00b7witz", ",", "nicht", "des", "Ver\u00b7stan\u00b7des", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wer dieses recht gebraucht, der wird, aus guten Gr\u00fcnden,", "tokens": ["Wer", "die\u00b7ses", "recht", "ge\u00b7braucht", ",", "der", "wird", ",", "aus", "gu\u00b7ten", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJD", "VVPP", "$,", "PRELS", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Weg zum Christenthum und zur Erleuchtung finden.", "tokens": ["Den", "Weg", "zum", "Chris\u00b7ten\u00b7thum", "und", "zur", "Er\u00b7leuch\u00b7tung", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Auf denn, gelehrter Freund! die\u00df Werk geh\u00f6rt f\u00fcr dich.", "tokens": ["Auf", "denn", ",", "ge\u00b7lehr\u00b7ter", "Freund", "!", "die\u00df", "Werk", "ge\u00b7h\u00f6rt", "f\u00fcr", "dich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "ADJA", "NN", "$.", "PDS", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Lutherthum steht fest, die Wahrheit freuet sich,", "tokens": ["Das", "Lu\u00b7ther\u00b7thum", "steht", "fest", ",", "die", "Wahr\u00b7heit", "freu\u00b7et", "sich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil Leipzig dich erh\u00f6ht, und dich auf gr\u00f6\u00dfre Stuffen,", "tokens": ["Weil", "Leip\u00b7zig", "dich", "er\u00b7h\u00f6ht", ",", "und", "dich", "auf", "gr\u00f6\u00df\u00b7re", "Stuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "VVFIN", "$,", "KON", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Glauben zum Gewinn, so feyerlich geruffen.", "tokens": ["Dem", "Glau\u00b7ben", "zum", "Ge\u00b7winn", ",", "so", "fey\u00b7er\u00b7lich", "ge\u00b7ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hast du nicht vormals schon in Schriften dargethan,", "tokens": ["Hast", "du", "nicht", "vor\u00b7mals", "schon", "in", "Schrif\u00b7ten", "dar\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df die Philosophie den Ketzern steuren kann?", "tokens": ["Da\u00df", "die", "Phi\u00b7lo\u00b7so\u00b7phie", "den", "Ket\u00b7zern", "steu\u00b7ren", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt f\u00e4hrst du weiter fort, und hilfst die Sp\u00f6ttereyen", "tokens": ["Itzt", "f\u00e4hrst", "du", "wei\u00b7ter", "fort", ",", "und", "hilfst", "die", "Sp\u00f6t\u00b7te\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Der starkvermeynten Brut, durch die Vernunft, zerstreuen.", "tokens": ["Der", "stark\u00b7ver\u00b7meyn\u00b7ten", "Brut", ",", "durch", "die", "Ver\u00b7nunft", ",", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geselle dich demnach den gro\u00dfen M\u00e4nnern bey,", "tokens": ["Ge\u00b7sel\u00b7le", "dich", "dem\u00b7nach", "den", "gro\u00b7\u00dfen", "M\u00e4n\u00b7nern", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PAV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die solches l\u00e4ngst gethan. Verwirf die Phantasey,", "tokens": ["Die", "sol\u00b7ches", "l\u00e4ngst", "ge\u00b7than", ".", "Ver\u00b7wirf", "die", "Phan\u00b7ta\u00b7sey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVPP", "$.", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df ein ", "tokens": ["Da\u00df", "ein"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.12": {"text": "Die Weisheit, die Vernunft und das Naturlicht hassen,", "tokens": ["Die", "Weis\u00b7heit", ",", "die", "Ver\u00b7nunft", "und", "das", "Na\u00b7tur\u00b7licht", "has\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ja ganz verschw\u00f6ren mu\u00df. Sey stets der Wahrheit Freund,", "tokens": ["Ja", "ganz", "ver\u00b7schw\u00f6\u00b7ren", "mu\u00df", ".", "Sey", "stets", "der", "Wahr\u00b7heit", "Freund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "VVINF", "VMFIN", "$.", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dem Aberglauben gram, und aller Sp\u00f6tter Feind.", "tokens": ["Dem", "A\u00b7berg\u00b7lau\u00b7ben", "gram", ",", "und", "al\u00b7ler", "Sp\u00f6t\u00b7ter", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dein Beyspiel mache wahr, da\u00df wohlerwiesne Lehren", "tokens": ["Dein", "Bey\u00b7spiel", "ma\u00b7che", "wahr", ",", "da\u00df", "woh\u00b7ler\u00b7wies\u00b7ne", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Des Glaubens Aehnlichkeit auf keine Weise st\u00f6ren;", "tokens": ["Des", "Glau\u00b7bens", "A\u00b7ehn\u00b7lich\u00b7keit", "auf", "kei\u00b7ne", "Wei\u00b7se", "st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Da\u00df Gott, der Weisheit Brunn, kein Freund der Tyranney,", "tokens": ["Da\u00df", "Gott", ",", "der", "Weis\u00b7heit", "Brunn", ",", "kein", "Freund", "der", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ART", "NN", "NE", "$,", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und unser Lutherthum kein K\u00f6hlerglaube sey,", "tokens": ["Und", "un\u00b7ser", "Lu\u00b7ther\u00b7thum", "kein", "K\u00f6h\u00b7ler\u00b7glau\u00b7be", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Dem Licht und Ordnung fehlt: so wird in sp\u00e4ten Tagen", "tokens": ["Dem", "Licht", "und", "Ord\u00b7nung", "fehlt", ":", "so", "wird", "in", "sp\u00e4\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$.", "ADV", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die wahre Kirche noch von deinem Ruhme sagen.", "tokens": ["Die", "wah\u00b7re", "Kir\u00b7che", "noch", "von", "dei\u00b7nem", "Ruh\u00b7me", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Gl\u00fcck zu, ber\u00fchmter Mann! und auserlesner Freund!", "tokens": ["Gl\u00fcck", "zu", ",", "be\u00b7r\u00fchm\u00b7ter", "Mann", "!", "und", "au\u00b7ser\u00b7les\u00b7ner", "Freund", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "ADJA", "NN", "$.", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wie freudig bin ich doch, indem der Tag erscheint,", "tokens": ["Wie", "freu\u00b7dig", "bin", "ich", "doch", ",", "in\u00b7dem", "der", "Tag", "er\u00b7scheint", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da deine W\u00fcrde steigt! Nun hat mein altes Hoffen", "tokens": ["Da", "dei\u00b7ne", "W\u00fcr\u00b7de", "steigt", "!", "Nun", "hat", "mein", "al\u00b7tes", "Hof\u00b7fen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$.", "ADV", "VAFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Durch deinen Doctorhut doch v\u00f6llig eingetroffen.", "tokens": ["Durch", "dei\u00b7nen", "Doc\u00b7tor\u00b7hut", "doch", "v\u00f6l\u00b7lig", "ein\u00b7ge\u00b7trof\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Besinne dich nur selbst, was ich dir oft gesagt,", "tokens": ["Be\u00b7sin\u00b7ne", "dich", "nur", "selbst", ",", "was", "ich", "dir", "oft", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "$,", "PWS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn du mir den Verfall der Gr\u00fcndlichkeit geklagt,", "tokens": ["Wenn", "du", "mir", "den", "Ver\u00b7fall", "der", "Gr\u00fcnd\u00b7lich\u00b7keit", "ge\u00b7klagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der unsern Glauben schimpft. Wir sahen ganze Rotten", "tokens": ["Der", "un\u00b7sern", "Glau\u00b7ben", "schimpft", ".", "Wir", "sa\u00b7hen", "gan\u00b7ze", "Rot\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Den hohen Inbegriff des Christenthums verspotten:", "tokens": ["Den", "ho\u00b7hen", "In\u00b7be\u00b7griff", "des", "Chris\u00b7ten\u00b7thums", "ver\u00b7spot\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und gleichwohl schien die Zahl der Eifrer viel zu klein,", "tokens": ["Und", "gleich\u00b7wohl", "schien", "die", "Zahl", "der", "Eif\u00b7rer", "viel", "zu", "klein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Streiten unge\u00fcbt, an Waffen schwach zu seyn,", "tokens": ["Im", "Strei\u00b7ten", "un\u00b7ge\u00b7\u00fcbt", ",", "an", "Waf\u00b7fen", "schwach", "zu", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die es verfechten soll. Hier regten, von der Liebe", "tokens": ["Die", "es", "ver\u00b7fech\u00b7ten", "soll", ".", "Hier", "reg\u00b7ten", ",", "von", "der", "Lie\u00b7be"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "$.", "ADV", "VVFIN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Zur Gottsgelahrtheit, sich in mir die alten Triebe.", "tokens": ["Zur", "Gotts\u00b7ge\u00b7lahr\u00b7theit", ",", "sich", "in", "mir", "die", "al\u00b7ten", "Trie\u00b7be", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRF", "APPR", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Indessen war mir auch dein gr\u00fcndlicher Verstand,", "tokens": ["In\u00b7des\u00b7sen", "war", "mir", "auch", "dein", "gr\u00fcnd\u00b7li\u00b7cher", "Ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Der Sprachen Wissenschaft und muntrer Witz bekannt.", "tokens": ["Der", "Spra\u00b7chen", "Wis\u00b7sen\u00b7schaft", "und", "mun\u00b7trer", "Witz", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Ich wu\u00dfte, wie ge\u00fcbt dein s\u00fc\u00dfer Mund im Lehren,", "tokens": ["Ich", "wu\u00df\u00b7te", ",", "wie", "ge\u00b7\u00fcbt", "dein", "s\u00fc\u00b7\u00dfer", "Mund", "im", "Leh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "VVPP", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Dein Kiel im Schreiben war, der Kirche Wohl zu mehren.", "tokens": ["Dein", "Kiel", "im", "Schrei\u00b7ben", "war", ",", "der", "Kir\u00b7che", "Wohl", "zu", "meh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "So gieng denn schon vorl\u00e4ngst mein ganzer Wunsch dahin:", "tokens": ["So", "gieng", "denn", "schon", "vor\u00b7l\u00e4ngst", "mein", "gan\u00b7zer", "Wunsch", "da\u00b7hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "(du weist, gelehrter Freund! da\u00df ich kein Schm\u00e4uchler bin.)", "tokens": ["(", "du", "weist", ",", "ge\u00b7lehr\u00b7ter", "Freund", "!", "da\u00df", "ich", "kein", "Schm\u00e4uch\u00b7ler", "bin", ".", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "ADJA", "NN", "$.", "KOUS", "PPER", "PIAT", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Dich, werther ", "tokens": ["Dich", ",", "wert\u00b7her"], "token_info": ["word", "punct", "word"], "pos": ["PPER", "$,", "PWS"], "meter": "+-+", "measure": "trochaic.di"}, "line.20": {"text": "Und unsers Glaubens Schutz, der Sp\u00f6tter Trotz zu nennen.", "tokens": ["Und", "un\u00b7sers", "Glau\u00b7bens", "Schutz", ",", "der", "Sp\u00f6t\u00b7ter", "Trotz", "zu", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "$,", "ART", "NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Nunmehr trifft alles ein. Wir habens j\u00fcngst geh\u00f6rt,", "tokens": ["Nun\u00b7mehr", "trifft", "al\u00b7les", "ein", ".", "Wir", "ha\u00b7bens", "j\u00fcngst", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$.", "PPER", "VAFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was du zum Probest\u00fcck und \u00f6ffentlich gelehrt:", "tokens": ["Was", "du", "zum", "Pro\u00b7be\u00b7st\u00fcck", "und", "\u00f6f\u00b7fent\u00b7lich", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "KON", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wie du von ", "tokens": ["Wie", "du", "von"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "So b\u00fcndig und gelehrt den seichten Grund gewiesen.", "tokens": ["So", "b\u00fcn\u00b7dig", "und", "ge\u00b7lehrt", "den", "seich\u00b7ten", "Grund", "ge\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "VVPP", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wir haben auch gesehn, wie du so meisterlich", "tokens": ["Wir", "ha\u00b7ben", "auch", "ge\u00b7sehn", ",", "wie", "du", "so", "meis\u00b7ter\u00b7lich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "$,", "PWAV", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Ganz frevelhaft erk\u00fchnt, an Christi Wunderthaten", "tokens": ["Ganz", "fre\u00b7vel\u00b7haft", "er\u00b7k\u00fchnt", ",", "an", "Chris\u00b7ti", "Wun\u00b7der\u00b7tha\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVPP", "$,", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die Schw\u00e4che des Gehirns und Witzes zu verrathen.", "tokens": ["Die", "Schw\u00e4\u00b7che", "des", "Ge\u00b7hirns", "und", "Wit\u00b7zes", "zu", "ver\u00b7ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "O! dacht ich, dieses thun die Waffen der Vernunft;", "tokens": ["O", "!", "dacht", "ich", ",", "die\u00b7ses", "thun", "die", "Waf\u00b7fen", "der", "Ver\u00b7nunft", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PDS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als deren Uebung ihm in unsrer Weisen Zunft", "tokens": ["Als", "de\u00b7ren", "Ue\u00b7bung", "ihm", "in", "uns\u00b7rer", "Wei\u00b7sen", "Zunft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PRELAT", "NN", "PPER", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So vielen Ruhm gebracht. Man kennt schon ", "tokens": ["So", "vie\u00b7len", "Ruhm", "ge\u00b7bracht", ".", "Man", "kennt", "schon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$.", "PIS", "VVFIN", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Man lobt die Gr\u00fcndlichkeit in jedem seiner Werke;", "tokens": ["Man", "lobt", "die", "Gr\u00fcnd\u00b7lich\u00b7keit", "in", "je\u00b7dem", "sei\u00b7ner", "Wer\u00b7ke", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Die Kenntni\u00df der Natur, des Geistes und der Welt,", "tokens": ["Die", "Kennt\u00b7ni\u00df", "der", "Na\u00b7tur", ",", "des", "Geis\u00b7tes", "und", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Des Sch\u00f6pfers, dessen Kraft sie schaffet und erh\u00e4lt;", "tokens": ["Des", "Sch\u00f6p\u00b7fers", ",", "des\u00b7sen", "Kraft", "sie", "schaf\u00b7fet", "und", "er\u00b7h\u00e4lt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELAT", "NN", "PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die schnelle Fertigkeit im Denken und Erweisen,", "tokens": ["Die", "schnel\u00b7le", "Fer\u00b7tig\u00b7keit", "im", "Den\u00b7ken", "und", "Er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPRART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und was wir sonst an ihm, seit vielen Jahren, preisen.", "tokens": ["Und", "was", "wir", "sonst", "an", "ihm", ",", "seit", "vie\u00b7len", "Jah\u00b7ren", ",", "prei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "APPR", "PPER", "$,", "APPR", "PIAT", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Das alles steht ihm bey, das hat ihn stark gemacht,", "tokens": ["Das", "al\u00b7les", "steht", "ihm", "bey", ",", "das", "hat", "ihn", "stark", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PDS", "VAFIN", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Da\u00df er der Feinde Spott in Sicherheit verlacht;", "tokens": ["Da\u00df", "er", "der", "Fein\u00b7de", "Spott", "in", "Si\u00b7cher\u00b7heit", "ver\u00b7lacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Der Glaubensl\u00e4strer Schwarm so ruhig widerleget,", "tokens": ["Der", "Glau\u00b7bens\u00b7l\u00e4st\u00b7rer", "Schwarm", "so", "ru\u00b7hig", "wi\u00b7der\u00b7le\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Und ihrer Zweifel Heer so leicht zu Boden schl\u00e4get.", "tokens": ["Und", "ih\u00b7rer", "Zwei\u00b7fel", "Heer", "so", "leicht", "zu", "Bo\u00b7den", "schl\u00e4\u00b7get", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "NN", "ADV", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "So soll, so mu\u00df es gehn, wenn man den Glauben sch\u00fctzt!", "tokens": ["So", "soll", ",", "so", "mu\u00df", "es", "gehn", ",", "wenn", "man", "den", "Glau\u00b7ben", "sch\u00fctzt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "$,", "ADV", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier hilft die Bibel nichts, die sonst so herrlich n\u00fctzt,", "tokens": ["Hier", "hilft", "die", "Bi\u00b7bel", "nichts", ",", "die", "sonst", "so", "herr\u00b7lich", "n\u00fctzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PIS", "$,", "PRELS", "ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wenn man mit Ketzern k\u00e4mpft: denn deren freches Wagen", "tokens": ["Wenn", "man", "mit", "Ket\u00b7zern", "k\u00e4mpft", ":", "denn", "de\u00b7ren", "fre\u00b7ches", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN", "VVFIN", "$.", "KON", "PRELAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kann mancher starke Spruch gewaltig niederschlagen.", "tokens": ["Kann", "man\u00b7cher", "star\u00b7ke", "Spruch", "ge\u00b7wal\u00b7tig", "nie\u00b7der\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIAT", "ADJA", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wer Gottes Wort erkennt, die Offenbarung ehrt,", "tokens": ["Wer", "Got\u00b7tes", "Wort", "er\u00b7kennt", ",", "die", "Of\u00b7fen\u00b7ba\u00b7rung", "ehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des Geistes Sinn erforscht, die M\u00e4nner Gottes h\u00f6rt,", "tokens": ["Des", "Geis\u00b7tes", "Sinn", "er\u00b7forscht", ",", "die", "M\u00e4n\u00b7ner", "Got\u00b7tes", "h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der l\u00e4\u00dft sich durch die Kraft der Schrift am besten lenken;", "tokens": ["Der", "l\u00e4\u00dft", "sich", "durch", "die", "Kraft", "der", "Schrift", "am", "bes\u00b7ten", "len\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "PTKA", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da darf man au\u00dfer ihr an keine Gr\u00fcnde denken.", "tokens": ["Da", "darf", "man", "au\u00b7\u00dfer", "ihr", "an", "kei\u00b7ne", "Gr\u00fcn\u00b7de", "den\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "PPOSAT", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo aber die Vernunft sich selber Weihrauch streut,", "tokens": ["Wo", "a\u00b7ber", "die", "Ver\u00b7nunft", "sich", "sel\u00b7ber", "Weih\u00b7rauch", "streut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PRF", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Schrift nicht h\u00f6ren will, von Vorurtheilen schreyt,", "tokens": ["Die", "Schrift", "nicht", "h\u00f6\u00b7ren", "will", ",", "von", "Vor\u00b7urt\u00b7hei\u00b7len", "schreyt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVINF", "VMFIN", "$,", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nur falsche Schl\u00fcsse macht, und aus vermeynten Gr\u00fcnden", "tokens": ["Nur", "fal\u00b7sche", "Schl\u00fcs\u00b7se", "macht", ",", "und", "aus", "ver\u00b7meyn\u00b7ten", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN", "$,", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die zweifelhafte Spur der Wahrheit sucht zu finden;", "tokens": ["Die", "zwei\u00b7fel\u00b7haf\u00b7te", "Spur", "der", "Wahr\u00b7heit", "sucht", "zu", "fin\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Da mu\u00df ein Glaubensheld auch anders widerstehn;", "tokens": ["Da", "mu\u00df", "ein", "Glau\u00b7bens\u00b7held", "auch", "an\u00b7ders", "wi\u00b7der\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er selbst mu\u00df in das Feld der Weisheitlehren gehn;", "tokens": ["Er", "selbst", "mu\u00df", "in", "das", "Feld", "der", "Weis\u00b7heit\u00b7leh\u00b7ren", "gehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Aus Quellen der Natur der Wahrheit B\u00e4che leiten,", "tokens": ["Aus", "Quel\u00b7len", "der", "Na\u00b7tur", "der", "Wahr\u00b7heit", "B\u00e4\u00b7che", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Und die Vern\u00fcnftler selbst aus der Vernunft bestreiten.", "tokens": ["Und", "die", "Ver\u00b7n\u00fcnft\u00b7ler", "selbst", "aus", "der", "Ver\u00b7nunft", "be\u00b7strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Das fodert unsre Zeit, darinn sich jene Brut", "tokens": ["Das", "fo\u00b7dert", "uns\u00b7re", "Zeit", ",", "da\u00b7rinn", "sich", "je\u00b7ne", "Brut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PAV", "PRF", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Sp\u00f6tter aufgemacht, die mit so frecher Wuth", "tokens": ["Der", "Sp\u00f6t\u00b7ter", "auf\u00b7ge\u00b7macht", ",", "die", "mit", "so", "fre\u00b7cher", "Wuth"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVPP", "$,", "PRELS", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des Glaubens Burg best\u00fcrmt. Es sind nicht Ketzereyen;", "tokens": ["Des", "Glau\u00b7bens", "Burg", "be\u00b7st\u00fcrmt", ".", "Es", "sind", "nicht", "Ket\u00b7ze\u00b7re\u00b7yen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$.", "PPER", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Man will sich von dem Joch des Christenthums befreyen!", "tokens": ["Man", "will", "sich", "von", "dem", "Joch", "des", "Chris\u00b7ten\u00b7thums", "be\u00b7fre\u00b7yen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Das wird gef\u00e4hrlicher von neuem auferweckt,", "tokens": ["Das", "wird", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", "von", "neu\u00b7em", "au\u00b7fer\u00b7weckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "APPR", "ADJA", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Verst\u00e4rket, ausgeputzt, erg\u00e4nzet und vermehret:", "tokens": ["Ver\u00b7st\u00e4r\u00b7ket", ",", "aus\u00b7ge\u00b7putzt", ",", "er\u00b7g\u00e4n\u00b7zet", "und", "ver\u00b7meh\u00b7ret", ":"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Dadurch wird hier und dar der Kirche Flor versehret.", "tokens": ["Da\u00b7durch", "wird", "hier", "und", "dar", "der", "Kir\u00b7che", "Flor", "ver\u00b7seh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "ADV", "KON", "PAV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Denn was ein ", "tokens": ["Denn", "was", "ein"], "token_info": ["word", "word", "word"], "pos": ["KON", "PWS", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.10": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.11": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.12": {"text": "Das ist dem Christenthum zum Untergang ersonnen.", "tokens": ["Das", "ist", "dem", "Chris\u00b7ten\u00b7thum", "zum", "Un\u00b7ter\u00b7gang", "er\u00b7son\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Hingegen, was ", "tokens": ["Hin\u00b7ge\u00b7gen", ",", "was"], "token_info": ["word", "punct", "word"], "pos": ["ADV", "$,", "PWS"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.14": {"text": "Das braucht itzt gr\u00f6\u00dfre Kunst. So gar die gute Bahn,", "tokens": ["Das", "braucht", "itzt", "gr\u00f6\u00df\u00b7re", "Kunst", ".", "So", "gar", "die", "gu\u00b7te", "Bahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJA", "NN", "$.", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Die sonst ", "tokens": ["Die", "sonst"], "token_info": ["word", "word"], "pos": ["ART", "ADV"], "meter": "-+", "measure": "iambic.single"}, "line.16": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.17": {"text": "Der b\u00fcndigste Beweis scheint itzo noch zu klein:", "tokens": ["Der", "b\u00fcn\u00b7digs\u00b7te", "Be\u00b7weis", "scheint", "it\u00b7zo", "noch", "zu", "klein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Er soll noch gr\u00fcndlicher, ja unumst\u00f6\u00dflich seyn.", "tokens": ["Er", "soll", "noch", "gr\u00fcnd\u00b7li\u00b7cher", ",", "ja", "un\u00b7um\u00b7st\u00f6\u00df\u00b7lich", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "$,", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "So mu\u00dften endlich auch die Kirchenlehrer denken,", "tokens": ["So", "mu\u00df\u00b7ten", "end\u00b7lich", "auch", "die", "Kir\u00b7chen\u00b7leh\u00b7rer", "den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Durch Regeln der Vernunft die Sp\u00f6tter einzuschr\u00e4nken.", "tokens": ["Durch", "Re\u00b7geln", "der", "Ver\u00b7nunft", "die", "Sp\u00f6t\u00b7ter", "ein\u00b7zu\u00b7schr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die\u00df war schon ", "tokens": ["Die\u00df", "war", "schon"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "In London, jedes Jahr, in diesem Glaubensstreit", "tokens": ["In", "Lon\u00b7don", ",", "je\u00b7des", "Jahr", ",", "in", "die\u00b7sem", "Glau\u00b7bens\u00b7streit"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NE", "$,", "PIAT", "NN", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein Lehrer achtmal k\u00e4mpft, die Wahrheit zu verfechten.", "tokens": ["Ein", "Leh\u00b7rer", "acht\u00b7mal", "k\u00e4mpft", ",", "die", "Wahr\u00b7heit", "zu", "ver\u00b7fech\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier wu\u00dfte ", "tokens": ["Hier", "wu\u00df\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "So k\u00e4mpfte ", "tokens": ["So", "k\u00e4mpf\u00b7te"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Auch ", "tokens": ["Auch"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Wo bleibt ein ", "tokens": ["Wo", "bleibt", "ein"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART"], "meter": "+--", "measure": "dactylic.init"}, "line.8": {"text": "Hier wies sich der Verstand in aufgekl\u00e4rter F\u00fclle!", "tokens": ["Hier", "wies", "sich", "der", "Ver\u00b7stand", "in", "auf\u00b7ge\u00b7kl\u00e4r\u00b7ter", "F\u00fcl\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die lauterste Vernunft verwarf der Thorheit Gift,", "tokens": ["Die", "lau\u00b7ters\u00b7te", "Ver\u00b7nunft", "ver\u00b7warf", "der", "Thor\u00b7heit", "Gift", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und rettete die Kraft und G\u00f6ttlichkeit der Schrift.", "tokens": ["Und", "ret\u00b7te\u00b7te", "die", "Kraft", "und", "G\u00f6tt\u00b7lich\u00b7keit", "der", "Schrift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die Weisheit sch\u00fctzte den, von welchem sie entsprossen,", "tokens": ["Die", "Weis\u00b7heit", "sch\u00fctz\u00b7te", "den", ",", "von", "wel\u00b7chem", "sie", "ent\u00b7spros\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "$,", "APPR", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Und f\u00fchrte zu dem Quell, aus welchem sie geflossen.", "tokens": ["Und", "f\u00fchr\u00b7te", "zu", "dem", "Quell", ",", "aus", "wel\u00b7chem", "sie", "ge\u00b7flos\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Sch\u00f6pfer der Vernunft scheut ihre Pr\u00fcfung nicht,", "tokens": ["Der", "Sch\u00f6p\u00b7fer", "der", "Ver\u00b7nunft", "scheut", "ih\u00b7re", "Pr\u00fc\u00b7fung", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er ha\u00dft den Aberwitz, nicht des Verstandes Licht.", "tokens": ["Er", "ha\u00dft", "den", "A\u00b7ber\u00b7witz", ",", "nicht", "des", "Ver\u00b7stan\u00b7des", "Licht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PTKNEG", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Wer dieses recht gebraucht, der wird, aus guten Gr\u00fcnden,", "tokens": ["Wer", "die\u00b7ses", "recht", "ge\u00b7braucht", ",", "der", "wird", ",", "aus", "gu\u00b7ten", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJD", "VVPP", "$,", "PRELS", "VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den Weg zum Christenthum und zur Erleuchtung finden.", "tokens": ["Den", "Weg", "zum", "Chris\u00b7ten\u00b7thum", "und", "zur", "Er\u00b7leuch\u00b7tung", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Auf denn, gelehrter Freund! die\u00df Werk geh\u00f6rt f\u00fcr dich.", "tokens": ["Auf", "denn", ",", "ge\u00b7lehr\u00b7ter", "Freund", "!", "die\u00df", "Werk", "ge\u00b7h\u00f6rt", "f\u00fcr", "dich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$,", "ADJA", "NN", "$.", "PDS", "NN", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Das Lutherthum steht fest, die Wahrheit freuet sich,", "tokens": ["Das", "Lu\u00b7ther\u00b7thum", "steht", "fest", ",", "die", "Wahr\u00b7heit", "freu\u00b7et", "sich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil Leipzig dich erh\u00f6ht, und dich auf gr\u00f6\u00dfre Stuffen,", "tokens": ["Weil", "Leip\u00b7zig", "dich", "er\u00b7h\u00f6ht", ",", "und", "dich", "auf", "gr\u00f6\u00df\u00b7re", "Stuf\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "PPER", "VVFIN", "$,", "KON", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem Glauben zum Gewinn, so feyerlich geruffen.", "tokens": ["Dem", "Glau\u00b7ben", "zum", "Ge\u00b7winn", ",", "so", "fey\u00b7er\u00b7lich", "ge\u00b7ruf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$,", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Hast du nicht vormals schon in Schriften dargethan,", "tokens": ["Hast", "du", "nicht", "vor\u00b7mals", "schon", "in", "Schrif\u00b7ten", "dar\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Da\u00df die Philosophie den Ketzern steuren kann?", "tokens": ["Da\u00df", "die", "Phi\u00b7lo\u00b7so\u00b7phie", "den", "Ket\u00b7zern", "steu\u00b7ren", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt f\u00e4hrst du weiter fort, und hilfst die Sp\u00f6ttereyen", "tokens": ["Itzt", "f\u00e4hrst", "du", "wei\u00b7ter", "fort", ",", "und", "hilfst", "die", "Sp\u00f6t\u00b7te\u00b7re\u00b7yen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Der starkvermeynten Brut, durch die Vernunft, zerstreuen.", "tokens": ["Der", "stark\u00b7ver\u00b7meyn\u00b7ten", "Brut", ",", "durch", "die", "Ver\u00b7nunft", ",", "zer\u00b7streu\u00b7en", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "ART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Geselle dich demnach den gro\u00dfen M\u00e4nnern bey,", "tokens": ["Ge\u00b7sel\u00b7le", "dich", "dem\u00b7nach", "den", "gro\u00b7\u00dfen", "M\u00e4n\u00b7nern", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "PAV", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die solches l\u00e4ngst gethan. Verwirf die Phantasey,", "tokens": ["Die", "sol\u00b7ches", "l\u00e4ngst", "ge\u00b7than", ".", "Ver\u00b7wirf", "die", "Phan\u00b7ta\u00b7sey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVPP", "$.", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df ein ", "tokens": ["Da\u00df", "ein"], "token_info": ["word", "word"], "pos": ["KOUS", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.12": {"text": "Die Weisheit, die Vernunft und das Naturlicht hassen,", "tokens": ["Die", "Weis\u00b7heit", ",", "die", "Ver\u00b7nunft", "und", "das", "Na\u00b7tur\u00b7licht", "has\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Ja ganz verschw\u00f6ren mu\u00df. Sey stets der Wahrheit Freund,", "tokens": ["Ja", "ganz", "ver\u00b7schw\u00f6\u00b7ren", "mu\u00df", ".", "Sey", "stets", "der", "Wahr\u00b7heit", "Freund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "VVINF", "VMFIN", "$.", "VAFIN", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Dem Aberglauben gram, und aller Sp\u00f6tter Feind.", "tokens": ["Dem", "A\u00b7berg\u00b7lau\u00b7ben", "gram", ",", "und", "al\u00b7ler", "Sp\u00f6t\u00b7ter", "Feind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "$,", "KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Dein Beyspiel mache wahr, da\u00df wohlerwiesne Lehren", "tokens": ["Dein", "Bey\u00b7spiel", "ma\u00b7che", "wahr", ",", "da\u00df", "woh\u00b7ler\u00b7wies\u00b7ne", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKVZ", "$,", "KOUS", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Des Glaubens Aehnlichkeit auf keine Weise st\u00f6ren;", "tokens": ["Des", "Glau\u00b7bens", "A\u00b7ehn\u00b7lich\u00b7keit", "auf", "kei\u00b7ne", "Wei\u00b7se", "st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Da\u00df Gott, der Weisheit Brunn, kein Freund der Tyranney,", "tokens": ["Da\u00df", "Gott", ",", "der", "Weis\u00b7heit", "Brunn", ",", "kein", "Freund", "der", "Ty\u00b7ran\u00b7ney", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "ART", "NN", "NE", "$,", "PIAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und unser Lutherthum kein K\u00f6hlerglaube sey,", "tokens": ["Und", "un\u00b7ser", "Lu\u00b7ther\u00b7thum", "kein", "K\u00f6h\u00b7ler\u00b7glau\u00b7be", "sey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Dem Licht und Ordnung fehlt: so wird in sp\u00e4ten Tagen", "tokens": ["Dem", "Licht", "und", "Ord\u00b7nung", "fehlt", ":", "so", "wird", "in", "sp\u00e4\u00b7ten", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$.", "ADV", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Die wahre Kirche noch von deinem Ruhme sagen.", "tokens": ["Die", "wah\u00b7re", "Kir\u00b7che", "noch", "von", "dei\u00b7nem", "Ruh\u00b7me", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}