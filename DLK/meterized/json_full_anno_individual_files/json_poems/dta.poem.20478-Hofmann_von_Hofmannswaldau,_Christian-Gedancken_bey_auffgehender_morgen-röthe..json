{"dta.poem.20478": {"metadata": {"author": {"name": "Hofmann von Hofmannswaldau, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Gedancken bey auffgehender  \n morgen-r\u00f6the.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1695", "urn": "urn:nbn:de:kobv:b4-200905197751", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Aurora deine ersten blicken/", "tokens": ["Au\u00b7ro\u00b7ra", "dei\u00b7ne", "ers\u00b7ten", "bli\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "ADJA", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der purpur triefft aus deiner hand/", "tokens": ["Der", "pur\u00b7pur", "triefft", "aus", "dei\u00b7ner", "hand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du suchst durch dieses reine pfand", "tokens": ["Du", "suchst", "durch", "die\u00b7ses", "rei\u00b7ne", "pfand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die welt und alles zu erqvicken/", "tokens": ["Die", "welt", "und", "al\u00b7les", "zu", "er\u00b7qvi\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "PIS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und machst die bahn von gold und nectar voll/", "tokens": ["Und", "machst", "die", "bahn", "von", "gold", "und", "nec\u00b7tar", "voll", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Darauff dein Ph\u00f6bus lauffen soll.", "tokens": ["Dar\u00b7auff", "dein", "Ph\u00f6\u00b7bus", "lauf\u00b7fen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein iedes blat bey meinen f\u00fcssen/", "tokens": ["Ein", "ie\u00b7des", "blat", "bey", "mei\u00b7nen", "f\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPOSAT", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein ieder vogel \u00fcber mir/", "tokens": ["Ein", "ie\u00b7der", "vo\u00b7gel", "\u00fc\u00b7ber", "mir", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verehret dich und opffert dir;", "tokens": ["Ver\u00b7eh\u00b7ret", "dich", "und", "opf\u00b7fert", "dir", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KON", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und giebet uns mit lust zu wissen/", "tokens": ["Und", "gie\u00b7bet", "uns", "mit", "lust", "zu", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wie itzt dein glantz und deiner wunder-pracht", "tokens": ["Wie", "itzt", "dein", "glantz", "und", "dei\u00b7ner", "wun\u00b7der\u00b7pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Verjagt das leid und d\u00e4mpfft die nacht.", "tokens": ["Ver\u00b7jagt", "das", "leid", "und", "d\u00e4mpfft", "die", "nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Du heist den unmuth von uns scheiden/", "tokens": ["Du", "heist", "den", "un\u00b7muth", "von", "uns", "schei\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "PPER", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die blumen weinen dir vor lust.", "tokens": ["Die", "blu\u00b7men", "wei\u00b7nen", "dir", "vor", "lust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "PPER", "APPR", "NN", "$."], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Du \u00f6ffnest deine bunte brust.", "tokens": ["Du", "\u00f6ff\u00b7nest", "dei\u00b7ne", "bun\u00b7te", "brust", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In wilden p\u00fcschen/ thal und heiden.", "tokens": ["In", "wil\u00b7den", "p\u00fc\u00b7schen", "/", "thal", "und", "hei\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$(", "NE", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Nur die/ so dir fast gleichen zierrath f\u00fchrt/", "tokens": ["Nur", "die", "/", "so", "dir", "fast", "glei\u00b7chen", "zier\u00b7rath", "f\u00fchrt", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "$(", "ADV", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wird nicht durch deine pracht ger\u00fchrt.", "tokens": ["Wird", "nicht", "durch", "dei\u00b7ne", "pracht", "ge\u00b7r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Corinne l\u00e4st sich nicht bewegen/", "tokens": ["Co\u00b7rin\u00b7ne", "l\u00e4st", "sich", "nicht", "be\u00b7we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du f\u00e4ll\u2019st ihr w\u00fcten nicht dahin/", "tokens": ["Du", "f\u00e4ll'st", "ihr", "w\u00fc\u00b7ten", "nicht", "da\u00b7hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "PTKNEG", "PAV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie wei\u00df den kalten Tyger-sinn/", "tokens": ["Sie", "wei\u00df", "den", "kal\u00b7ten", "Ty\u00b7ger\u00b7sinn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht abzuthun/ nicht weg zu legen.", "tokens": ["Nicht", "ab\u00b7zu\u00b7thun", "/", "nicht", "weg", "zu", "le\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVIZU", "$(", "PTKNEG", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie speiset mich mit angst und ", "tokens": ["Sie", "spei\u00b7set", "mich", "mit", "angst", "und"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "VVPP", "KON"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Wie du die welt mit lieblichkeit.", "tokens": ["Wie", "du", "die", "welt", "mit", "lieb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ihr harter geist wei\u00df nicht zu biegen/", "tokens": ["Ihr", "har\u00b7ter", "geist", "wei\u00df", "nicht", "zu", "bie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PTKNEG", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr ha\u00df der geht nicht mehr zu ruh/", "tokens": ["Ihr", "ha\u00df", "der", "geht", "nicht", "mehr", "zu", "ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er will stets munter seyn wie du/", "tokens": ["Er", "will", "stets", "mun\u00b7ter", "seyn", "wie", "du", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADJD", "VAINF", "KOKOM", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und gegen mich zu felde liegen;", "tokens": ["Und", "ge\u00b7gen", "mich", "zu", "fel\u00b7de", "lie\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRF", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Sie macht/ da\u00df mir dein angenehmer schein", "tokens": ["Sie", "macht", "/", "da\u00df", "mir", "dein", "an\u00b7ge\u00b7neh\u00b7mer", "schein"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Den plitzen \u00e4hnlich d\u00fcnckt zu seyn.", "tokens": ["Den", "plit\u00b7zen", "\u00e4hn\u00b7lich", "d\u00fcnckt", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Aurora brich doch diese sinnen/", "tokens": ["Au\u00b7ro\u00b7ra", "brich", "doch", "die\u00b7se", "sin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PDS", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und lege diesen hohen muth!", "tokens": ["Und", "le\u00b7ge", "die\u00b7sen", "ho\u00b7hen", "muth", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So dir nur schimpff/ mir unrecht thut.", "tokens": ["So", "dir", "nur", "schimpff", "/", "mir", "un\u00b7recht", "thut", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "ADV", "VVFIN", "$(", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Komm/ tilge ferner ihr beginnen.", "tokens": ["Komm", "/", "til\u00b7ge", "fer\u00b7ner", "ihr", "be\u00b7gin\u00b7nen", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "VVFIN", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Legstu mir nun dergleichen kleinod zu/", "tokens": ["Legs\u00b7tu", "mir", "nun", "derg\u00b7lei\u00b7chen", "klei\u00b7nod", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIS", "NN", "PTKZU", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "So werd\u2019 ich wieder roth wie du.", "tokens": ["So", "werd'", "ich", "wie\u00b7der", "roth", "wie", "du", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Du must den kalten schnee vertreiben/", "tokens": ["Du", "must", "den", "kal\u00b7ten", "schnee", "ver\u00b7trei\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So unter warmen bergen ist/", "tokens": ["So", "un\u00b7ter", "war\u00b7men", "ber\u00b7gen", "ist", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "VVINF", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und mich zu martern hat erkiest/", "tokens": ["Und", "mich", "zu", "mar\u00b7tern", "hat", "er\u00b7kiest", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst kan und wei\u00df ich nicht zu bleiben.", "tokens": ["Sonst", "kan", "und", "wei\u00df", "ich", "nicht", "zu", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "KON", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Aurora wilstu wie Corinne seyn?", "tokens": ["Au\u00b7ro\u00b7ra", "wils\u00b7tu", "wie", "Co\u00b7rin\u00b7ne", "seyn", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "KOKOM", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Du lauffst und l\u00e4st mich hier allein!", "tokens": ["Du", "lauffst", "und", "l\u00e4st", "mich", "hier", "al\u00b7lein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}