{"textgrid.poem.52774": {"metadata": {"author": {"name": "Eichrodt, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1859, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In vollen Z\u00fcgen schl\u00fcrf' ich", "tokens": ["In", "vol\u00b7len", "Z\u00fc\u00b7gen", "schl\u00fcr\u00b7f'", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die destillirte Luft,", "tokens": ["Die", "des\u00b7til\u00b7lir\u00b7te", "Luft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit meinem Stabe sch\u00fcrf ich", "tokens": ["Mit", "mei\u00b7nem", "Sta\u00b7be", "sch\u00fcrf", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem K\u00e4fer eine Gruft.", "tokens": ["Dem", "K\u00e4\u00b7fer", "ei\u00b7ne", "Gruft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die Bl\u00fcthenb\u00e4ume schneien,", "tokens": ["Die", "Bl\u00fc\u00b7then\u00b7b\u00e4u\u00b7me", "schnei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es weint die Nachtigall \u2013", "tokens": ["Es", "weint", "die", "Nach\u00b7ti\u00b7gall", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich will ihn dir verzeihen,", "tokens": ["Ich", "will", "ihn", "dir", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Herz, den Wiederhall.", "tokens": ["Mein", "Herz", ",", "den", "Wie\u00b7der\u00b7hall", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "O Fr\u00fchling, heiliger Fr\u00fchling,", "tokens": ["O", "Fr\u00fch\u00b7ling", ",", "hei\u00b7li\u00b7ger", "Fr\u00fch\u00b7ling", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie bist du g\u00f6ttlich sch\u00f6n \u2013", "tokens": ["Wie", "bist", "du", "g\u00f6tt\u00b7lich", "sch\u00f6n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich sehe den ", "tokens": ["Ich", "se\u00b7he", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "+---", "measure": "dactylic.init"}, "line.4": {"text": "Dort auch spazieren gehn.", "tokens": ["Dort", "auch", "spa\u00b7zie\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "In vollen Z\u00fcgen schl\u00fcrf' ich", "tokens": ["In", "vol\u00b7len", "Z\u00fc\u00b7gen", "schl\u00fcr\u00b7f'", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die destillirte Luft,", "tokens": ["Die", "des\u00b7til\u00b7lir\u00b7te", "Luft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit meinem Stabe sch\u00fcrf ich", "tokens": ["Mit", "mei\u00b7nem", "Sta\u00b7be", "sch\u00fcrf", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dem K\u00e4fer eine Gruft.", "tokens": ["Dem", "K\u00e4\u00b7fer", "ei\u00b7ne", "Gruft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Die Bl\u00fcthenb\u00e4ume schneien,", "tokens": ["Die", "Bl\u00fc\u00b7then\u00b7b\u00e4u\u00b7me", "schnei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es weint die Nachtigall \u2013", "tokens": ["Es", "weint", "die", "Nach\u00b7ti\u00b7gall", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich will ihn dir verzeihen,", "tokens": ["Ich", "will", "ihn", "dir", "ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mein Herz, den Wiederhall.", "tokens": ["Mein", "Herz", ",", "den", "Wie\u00b7der\u00b7hall", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "O Fr\u00fchling, heiliger Fr\u00fchling,", "tokens": ["O", "Fr\u00fch\u00b7ling", ",", "hei\u00b7li\u00b7ger", "Fr\u00fch\u00b7ling", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wie bist du g\u00f6ttlich sch\u00f6n \u2013", "tokens": ["Wie", "bist", "du", "g\u00f6tt\u00b7lich", "sch\u00f6n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADJD", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich sehe den ", "tokens": ["Ich", "se\u00b7he", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "+---", "measure": "dactylic.init"}, "line.4": {"text": "Dort auch spazieren gehn.", "tokens": ["Dort", "auch", "spa\u00b7zie\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}