{"dta.poem.19879": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "Die  \n  Weiber von Weinsberg.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Wer sagt mir an, wo Weinsberg liegt?               ", "tokens": ["Wer", "sagt", "mir", "an", ",", "wo", "Weins\u00b7berg", "liegt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sol seyn ein wakres St\u00e4dtchen,", "tokens": ["Sol", "seyn", "ein", "wak\u00b7res", "St\u00e4dt\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sol haben, from und klug gewiegt,", "tokens": ["Sol", "ha\u00b7ben", ",", "from", "und", "klug", "ge\u00b7wiegt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$,", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Weiberchen und M\u00e4dchen.", "tokens": ["Viel", "Wei\u00b7ber\u00b7chen", "und", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "K\u00f6mt mir einmal das Freien ein,", "tokens": ["K\u00f6mt", "mir", "ein\u00b7mal", "das", "Frei\u00b7en", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.6": {"text": "So werd\u2019 ich eins aus Weinsberg frei\u2019n.", "tokens": ["So", "werd'", "ich", "eins", "aus", "Weins\u00b7berg", "frei'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Einsmals der Kaiser Konrad war", "tokens": ["Eins\u00b7mals", "der", "Kai\u00b7ser", "Kon\u00b7rad", "war"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NE", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dem guten St\u00e4dtlein b\u00f6se,", "tokens": ["Dem", "gu\u00b7ten", "St\u00e4dt\u00b7lein", "b\u00f6\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und r\u00fckt\u2019 heran mit Kriegesschaar", "tokens": ["Und", "r\u00fc\u00b7kt'", "he\u00b7ran", "mit", "Krie\u00b7ges\u00b7schaar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "NN"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Und Reisigenget\u00f6se,", "tokens": ["Und", "Rei\u00b7si\u00b7gen\u00b7ge\u00b7t\u00f6\u00b7se", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Umlagert\u2019 es, mit Ros und Man,", "tokens": ["Um\u00b7la\u00b7gert'", "es", ",", "mit", "Ros", "und", "Man", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "NE", "KON", "PIS", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.6": {"text": "Und schos und rante drauf und dran.", "tokens": ["Und", "schos", "und", "ran\u00b7te", "drauf", "und", "dran", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "VVFIN", "PTKVZ", "KON", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Und als das St\u00e4dtlein widerstand,", "tokens": ["Und", "als", "das", "St\u00e4dt\u00b7lein", "wi\u00b7der\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Troz allen seinen N\u00f6ten,", "tokens": ["Troz", "al\u00b7len", "sei\u00b7nen", "N\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da lies er, hoch von Grim entbrant,", "tokens": ["Da", "lies", "er", ",", "hoch", "von", "Grim", "ent\u00b7brant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ADJD", "APPR", "NE", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Herold \u2019nein trompeten:", "tokens": ["Den", "He\u00b7rold", "'n\u00b7ein", "trom\u00b7pe\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Ihr Schurken, komm\u2019 ich \u2019nein, so wist,", "tokens": ["Ihr", "Schur\u00b7ken", ",", "komm'", "ich", "'n\u00b7ein", ",", "so", "wist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "PPER", "NE", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Sol h\u00e4ngen, was die Wand bepist.", "tokens": ["Sol", "h\u00e4n\u00b7gen", ",", "was", "die", "Wand", "be\u00b7pist", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,", "PRELS", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Drob, als er den Avis also", "tokens": ["Drob", ",", "als", "er", "den", "A\u00b7vis", "al\u00b7so"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "ART", "NN", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hinein trompeten lassen,", "tokens": ["Hin\u00b7ein", "trom\u00b7pe\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Gab\u2019s lautes Zetermordio,", "tokens": ["Gab's", "lau\u00b7tes", "Ze\u00b7ter\u00b7mor\u00b7dio", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu Haus und auf den Gassen.", "tokens": ["Zu", "Haus", "und", "auf", "den", "Gas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das Brod war theuer in der Stadt;", "tokens": ["Das", "Brod", "war", "theu\u00b7er", "in", "der", "Stadt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch theurer noch war guter Rath.", "tokens": ["Doch", "theu\u00b7rer", "noch", "war", "gu\u00b7ter", "Rath", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "\u201eo weh, mir armen Korydon!", "tokens": ["\u201e", "o", "weh", ",", "mir", "ar\u00b7men", "Ko\u00b7ry\u00b7don", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "FM", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "O weh mir! die Pastores", "tokens": ["O", "weh", "mir", "!", "die", "Pas\u00b7to\u00b7res"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$.", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Schrie\u2019n: Kyrie Eleyson!", "tokens": ["Schrie'n", ":", "Ky\u00b7rie", "E\u00b7ley\u00b7son", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "NE", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wir gehn, wir gehn kapores!", "tokens": ["Wir", "gehn", ",", "wir", "gehn", "ka\u00b7po\u00b7res", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "O weh, mir armen Korydon!", "tokens": ["O", "weh", ",", "mir", "ar\u00b7men", "Ko\u00b7ry\u00b7don", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Es jukt mir an der Kehle schon.\u201e", "tokens": ["Es", "jukt", "mir", "an", "der", "Keh\u00b7le", "schon", ".", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Doch wann\u2019s Matth\u00e4\u2019 am lezten ist,", "tokens": ["Doch", "wann's", "Mat\u00b7th\u00e4'", "am", "lez\u00b7ten", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Troz Rathen, Thun und Beten,", "tokens": ["Troz", "Ra\u00b7then", ",", "Thun", "und", "Be\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So rettet oft noch Weiberlist", "tokens": ["So", "ret\u00b7tet", "oft", "noch", "Wei\u00b7ber\u00b7list"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus Aengsten und aus N\u00f6ten.", "tokens": ["Aus", "A\u00b7engs\u00b7ten", "und", "aus", "N\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn Pfaffentrug und Weiberlist", "tokens": ["Denn", "Pfaf\u00b7fen\u00b7trug", "und", "Wei\u00b7ber\u00b7list"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gehn \u00fcber alles, wie ihr wist.", "tokens": ["Gehn", "\u00fc\u00b7ber", "al\u00b7les", ",", "wie", "ihr", "wist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIS", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Ein junges Weibchen Lobesan,", "tokens": ["Ein", "jun\u00b7ges", "Weib\u00b7chen", "Lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seit gestern erst getrauet,", "tokens": ["Seit", "ge\u00b7stern", "erst", "ge\u00b7trau\u00b7et", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "VVFIN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Giebt einen klugen Einfal an,", "tokens": ["Giebt", "ei\u00b7nen", "klu\u00b7gen", "Ein\u00b7fal", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der alles Volk erbauet;", "tokens": ["Der", "al\u00b7les", "Volk", "er\u00b7bau\u00b7et", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Den ihr, sofern ihr anders wolt,", "tokens": ["Den", "ihr", ",", "so\u00b7fern", "ihr", "an\u00b7ders", "wolt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "KOUS", "PPER", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Belachen und beklatschen solt.", "tokens": ["Be\u00b7la\u00b7chen", "und", "be\u00b7klat\u00b7schen", "solt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Zur Zeit der stillen Mitternacht", "tokens": ["Zur", "Zeit", "der", "stil\u00b7len", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die sch\u00f6nste Ambassade", "tokens": ["Die", "sch\u00f6ns\u00b7te", "Am\u00b7bas\u00b7sa\u00b7de"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Von Weibern sich ins Lager macht,", "tokens": ["Von", "Wei\u00b7bern", "sich", "ins", "La\u00b7ger", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und bettelt dort um Gnade.", "tokens": ["Und", "bet\u00b7telt", "dort", "um", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie bettelt sanft, sie bettelt f\u00fcs,", "tokens": ["Sie", "bet\u00b7telt", "sanft", ",", "sie", "bet\u00b7telt", "f\u00fcs", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "PPER", "VVFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Erh\u00e4lt doch aber nichts, als dies:", "tokens": ["Er\u00b7h\u00e4lt", "doch", "a\u00b7ber", "nichts", ",", "als", "dies", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "PIS", "$,", "KOUS", "PDS", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "\u201edie Weiber solten Abzug han,", "tokens": ["\u201e", "die", "Wei\u00b7ber", "sol\u00b7ten", "Ab\u00b7zug", "han", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "PIAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit ihren besten Sch\u00e4zen,", "tokens": ["Mit", "ih\u00b7ren", "bes\u00b7ten", "Sch\u00e4\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was \u00fcbrig bliebe, wolte man", "tokens": ["Was", "\u00fcb\u00b7rig", "blie\u00b7be", ",", "wol\u00b7te", "man"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "ADJD", "VVFIN", "$,", "VMFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zerhauen und zerfezen.\u201e", "tokens": ["Zer\u00b7hau\u00b7en", "und", "zer\u00b7fe\u00b7zen", ".", "\u201e"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit der Kapitulation", "tokens": ["Mit", "der", "Ka\u00b7pi\u00b7tu\u00b7la\u00b7ti\u00b7on"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Schleicht die Gesandschaft tr\u00fcb davon.", "tokens": ["Schleicht", "die", "Ge\u00b7sand\u00b7schaft", "tr\u00fcb", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ADJD", "PAV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.10": {"line.1": {"text": "Drauf, als der Morgen bricht hervor,", "tokens": ["Drauf", ",", "als", "der", "Mor\u00b7gen", "bricht", "her\u00b7vor", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gebt Achtung! Was geschiehet?", "tokens": ["Gebt", "Ach\u00b7tung", "!", "Was", "ge\u00b7schie\u00b7het", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVIMP", "NN", "$.", "PWS", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es \u00f6fnet sich das n\u00e4chste Thor,", "tokens": ["Es", "\u00f6f\u00b7net", "sich", "das", "n\u00e4chs\u00b7te", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und jedes Weibchen ziehet,", "tokens": ["Und", "je\u00b7des", "Weib\u00b7chen", "zie\u00b7het", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mit ihrem M\u00e4nchen schwer im Sak,", "tokens": ["Mit", "ih\u00b7rem", "M\u00e4n\u00b7chen", "schwer", "im", "Sak", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So wahr ich lebe! Huckepak. \u2014", "tokens": ["So", "wahr", "ich", "le\u00b7be", "!", "Hu\u00b7cke\u00b7pak", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "PPER", "VVFIN", "$.", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Manch Hofschranz suchte zwar sofort", "tokens": ["Manch", "Hof\u00b7schranz", "such\u00b7te", "zwar", "so\u00b7fort"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Knifchen zu vereiteln;", "tokens": ["Das", "Knifc\u00b7hen", "zu", "ver\u00b7ei\u00b7teln", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch Konrad sprach: \u201eEin Kaiserwort", "tokens": ["Doch", "Kon\u00b7rad", "sprach", ":", "\u201e", "Ein", "Kai\u00b7ser\u00b7wort"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word"], "pos": ["KON", "NE", "VVFIN", "$.", "$(", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sol man nicht drehn noch deuteln.", "tokens": ["Sol", "man", "nicht", "drehn", "noch", "deu\u00b7teln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "PTKNEG", "CARD", "ADV", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Ha bravo! rief er, bravo so!", "tokens": ["Ha", "bra\u00b7vo", "!", "rief", "er", ",", "bra\u00b7vo", "so", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "ITJ", "$.", "VVFIN", "PPER", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Meint\u2019 unsre Frau es auch nur so!\u201e", "tokens": ["Meint'", "uns\u00b7re", "Frau", "es", "auch", "nur", "so", "!", "\u201e"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PPER", "ADV", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Er gab Pardon und ein Banket,", "tokens": ["Er", "gab", "Par\u00b7don", "und", "ein", "Ban\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Sch\u00f6nen zu gefallen.", "tokens": ["Den", "Sch\u00f6\u00b7nen", "zu", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da ward gegeigt, da ward trompet\u2019t,", "tokens": ["Da", "ward", "ge\u00b7geigt", ",", "da", "ward", "trom\u00b7pet't", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "ADV", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und durchgetanzt mit allen,", "tokens": ["Und", "durch\u00b7ge\u00b7tanzt", "mit", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PIAT", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wie mit der Burgemeisterin,", "tokens": ["Wie", "mit", "der", "Bur\u00b7ge\u00b7meis\u00b7te\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "So mit der Besenbinderin. \u2014", "tokens": ["So", "mit", "der", "Be\u00b7sen\u00b7bin\u00b7de\u00b7rin", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.13": {"line.1": {"text": "Ei! sagt mir doch, wo Weinsberg liegt?", "tokens": ["Ei", "!", "sagt", "mir", "doch", ",", "wo", "Weins\u00b7berg", "liegt", "?"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "VVFIN", "PPER", "ADV", "$,", "PWAV", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist gar ein wakres St\u00e4dtchen.", "tokens": ["Ist", "gar", "ein", "wak\u00b7res", "St\u00e4dt\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat, treu und from und klug gewiegt,", "tokens": ["Hat", ",", "treu", "und", "from", "und", "klug", "ge\u00b7wiegt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "ADJD", "KON", "ADJD", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Viel Weiberchen und M\u00e4dchen.", "tokens": ["Viel", "Wei\u00b7ber\u00b7chen", "und", "M\u00e4d\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ich mus, k\u00f6mt mir das Freien ein,", "tokens": ["Ich", "mus", ",", "k\u00f6mt", "mir", "das", "Frei\u00b7en", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcrwahr! mus Eins aus Weinsberg frei\u2019n.", "tokens": ["F\u00fcr\u00b7wahr", "!", "mus", "Eins", "aus", "Weins\u00b7berg", "frei'", "n."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["NN", "$.", "VMFIN", "NN", "APPR", "NE", "NE", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}