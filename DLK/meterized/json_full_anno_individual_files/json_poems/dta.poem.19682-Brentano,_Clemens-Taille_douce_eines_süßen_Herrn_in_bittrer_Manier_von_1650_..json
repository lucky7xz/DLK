{"dta.poem.19682": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Taille douce eines s\u00fc\u00dfen Herrn in bittrer  \n Manier von 1650 .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "H\u00f6rt zu, ein neuer Pantalon ist auf dem Markt an-               ", "tokens": ["H\u00f6rt", "zu", ",", "ein", "neu\u00b7er", "Pan\u00b7ta\u00b7lon", "ist", "auf", "dem", "Markt", "an"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PTKVZ", "$,", "ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "kommen,", "tokens": ["kom\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Den Charletan jagt er davon, hat selbst den Platz ge-", "tokens": ["Den", "Char\u00b7le\u00b7tan", "jagt", "er", "da\u00b7von", ",", "hat", "selbst", "den", "Platz", "ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "PAV", "$,", "VAFIN", "ADV", "ART", "NN", "TRUNC"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "nommen,", "tokens": ["nom\u00b7men", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der seltsam Kund in einer Stund wird tausend Possen", "tokens": ["Der", "selt\u00b7sam", "Kund", "in", "ei\u00b7ner", "Stund", "wird", "tau\u00b7send", "Pos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "APPR", "ART", "NN", "VAFIN", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "rei\u00dfen,", "tokens": ["rei\u00b7\u00dfen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Bist du ein Mann, trutz schau ihn an und's Lachen thu'", "tokens": ["Bist", "du", "ein", "Mann", ",", "trutz", "schau", "ihn", "an", "un\u00b7d's", "La\u00b7chen", "thu'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "ADJD", "VVFIN", "PPER", "PTKVZ", "KON", "NN", "VVFIN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "verbei\u00dfen.", "tokens": ["ver\u00b7bei\u00b7\u00dfen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.2": {"line.1": {"text": "Was ist das f\u00fcr ein Strobelhaar, sind's Igel oder", "tokens": ["Was", "ist", "das", "f\u00fcr", "ein", "Stro\u00b7bel\u00b7haar", ",", "sin\u00b7d's", "I\u00b7gel", "o\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ART", "NN", "$,", "ADJA", "NN", "KON"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ratzen?", "tokens": ["Rat\u00b7zen", "?"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Vielleicht nur einmal in dem Jahr thu'n k\u00e4mmen ihn die", "tokens": ["Viel\u00b7leicht", "nur", "ein\u00b7mal", "in", "dem", "Jahr", "thu'n", "k\u00e4m\u00b7men", "ihn", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "VVFIN", "PPER", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Katzen.", "tokens": ["Kat\u00b7zen", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Sein Haar ist g'wi\u00df ein Storchennest, krumm hin und", "tokens": ["Sein", "Haar", "ist", "g'\u00b7wi\u00df", "ein", "Stor\u00b7chen\u00b7nest", ",", "krumm", "hin", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ART", "NN", "$,", "ADJD", "PTKVZ", "KON"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "wieder bogen,", "tokens": ["wie\u00b7der", "bo\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Er hat ein Schopf wie ein Wiedhopf, viel Volks darein", "tokens": ["Er", "hat", "ein", "Schopf", "wie", "ein", "Wied\u00b7hopf", ",", "viel", "Volks", "da\u00b7rein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "KOKOM", "ART", "NN", "$,", "PIAT", "NN", "PAV"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "erzogen.", "tokens": ["er\u00b7zo\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.3": {"line.1": {"text": "Am linken Ohr h\u00e4ngt ihm herab ein a la Mode Zot-", "tokens": ["Am", "lin\u00b7ken", "Ohr", "h\u00e4ngt", "ihm", "her\u00b7ab", "ein", "a", "la", "Mo\u00b7de", "Zot"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "ART", "FM", "FM", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "ten,", "tokens": ["ten", ","], "token_info": ["word", "punct"], "pos": ["FM", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Den darf er gar nicht stutzen ab, bey Leibstraf ists ver-", "tokens": ["Den", "darf", "er", "gar", "nicht", "stut\u00b7zen", "ab", ",", "bey", "Leibs\u00b7traf", "ists", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "ADV", "PTKNEG", "VVFIN", "PTKVZ", "$,", "APPR", "NN", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "boten,", "tokens": ["bo\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "D\u00fcnkt ihm sehr toll, wie ihm die Woll herumschwebt vor", "tokens": ["D\u00fcnkt", "ihm", "sehr", "toll", ",", "wie", "ihm", "die", "Woll", "her\u00b7um\u00b7schwebt", "vor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "PWAV", "PPER", "ART", "NN", "VVFIN", "APPR"], "meter": "+--+-+-+-++-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "den Augen,", "tokens": ["den", "Au\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Ist lang und dick, f\u00fcr einen Strick thu't es dem Henker", "tokens": ["Ist", "lang", "und", "dick", ",", "f\u00fcr", "ei\u00b7nen", "Strick", "thu't", "es", "dem", "Hen\u00b7ker"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "taugen.", "tokens": ["tau\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.4": {"line.1": {"text": "Bald flicht er ihn wie einen Zopf, thut ihn zusammen-", "tokens": ["Bald", "flicht", "er", "ihn", "wie", "ei\u00b7nen", "Zopf", ",", "thut", "ihn", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "KOKOM", "ART", "NN", "$,", "VVFIN", "PPER", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "drehen,", "tokens": ["dre\u00b7hen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "L\u00e4st rausser schaun ein'n kleinen Schopf, damit man ihn", "tokens": ["L\u00e4st", "raus\u00b7ser", "schaun", "ein'n", "klei\u00b7nen", "Schopf", ",", "da\u00b7mit", "man", "ihn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PIS", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "thut kennen,", "tokens": ["thut", "ken\u00b7nen", ","], "token_info": ["word", "word", "punct"], "pos": ["VVFIN", "VVINF", "$,"], "meter": "---", "measure": "unknown.measure.zero"}, "line.5": {"text": "Er bindt darein ein Nestel ein, das er bey'm Kr\u00e4mer", "tokens": ["Er", "bindt", "da\u00b7rein", "ein", "Nes\u00b7tel", "ein", ",", "das", "er", "bey'm", "Kr\u00e4\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "ART", "NN", "PTKVZ", "$,", "PRELS", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "funden,", "tokens": ["fun\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Ein Dama nennt, die ihn nit kennt; sagt, hab's ihm", "tokens": ["Ein", "Da\u00b7ma", "nennt", ",", "die", "ihn", "nit", "kennt", ";", "sagt", ",", "hab's", "ihm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVFIN", "$.", "VVFIN", "$,", "VAFIN", "PPER"], "meter": "+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.8": {"text": "eingebunden.", "tokens": ["ein\u00b7ge\u00b7bun\u00b7den", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.5": {"line.1": {"text": "Der Huth ist voller Federb\u00fcsch, als ob er wollte flie-", "tokens": ["Der", "Huth", "ist", "vol\u00b7ler", "Fe\u00b7der\u00b7b\u00fcsch", ",", "als", "ob", "er", "woll\u00b7te", "flie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJA", "NN", "$,", "KOKOM", "KOUS", "PPER", "VMFIN", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "gen,", "tokens": ["gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Er g\u00e4b ein'n guten Flederwisch, damit man kehrt die", "tokens": ["Er", "g\u00e4b", "ein'n", "gu\u00b7ten", "Fle\u00b7der\u00b7wisch", ",", "da\u00b7mit", "man", "kehrt", "die"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PIS", "VVFIN", "ART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Stiegen,", "tokens": ["Stie\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Er macht's mit Flei\u00df hell gelb halb wei\u00df fein scheckigt wie", "tokens": ["Er", "macht's", "mit", "Flei\u00df", "hell", "gelb", "halb", "wei\u00df", "fein", "sche\u00b7ckigt", "wie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADJD", "ADJD", "ADJD", "VVFIN", "ADJD", "VVFIN", "KOKOM"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "die Narren,", "tokens": ["die", "Nar\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Er schmieget sich sch\u00f6n, und fliegt davon, will hier nicht", "tokens": ["Er", "schmie\u00b7get", "sich", "sch\u00f6n", ",", "und", "fliegt", "da\u00b7von", ",", "will", "hier", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "$,", "KON", "VVFIN", "PAV", "$,", "VMFIN", "ADV", "PTKNEG"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "l\u00e4nger harren.", "tokens": ["l\u00e4n\u00b7ger", "har\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "Der Bart ist spitzig \u00fcberaus, krum hin und her gezo-", "tokens": ["Der", "Bart", "ist", "spit\u00b7zig", "\u00fc\u00b7be\u00b7raus", ",", "krum", "hin", "und", "her", "ge\u00b7zo"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "PTKVZ", "$,", "VVIMP", "PTKVZ", "KON", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "gen,", "tokens": ["gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Mich d\u00e4ucht es sey ein Fledermau\u00df ihm f\u00fcr das Maul", "tokens": ["Mich", "d\u00e4ucht", "es", "sey", "ein", "Fle\u00b7der\u00b7mau\u00df", "ihm", "f\u00fcr", "das", "Maul"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VAFIN", "ART", "NN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "geflogen,", "tokens": ["ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Mich d\u00fcnkt wie da\u00df ihm bey der Nas die Fl\u00fcgel sie", "tokens": ["Mich", "d\u00fcnkt", "wie", "da\u00df", "ihm", "bey", "der", "Nas", "die", "Fl\u00fc\u00b7gel", "sie"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KOKOM", "KOUS", "PPER", "APPR", "ART", "NN", "ART", "NN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "ausbreite.", "tokens": ["aus\u00b7brei\u00b7te", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Ein sch\u00f6ne Art von Ratzenbart, thu't Noth, da\u00df man ihn", "tokens": ["Ein", "sch\u00f6\u00b7ne", "Art", "von", "Rat\u00b7zen\u00b7bart", ",", "thu't", "Noth", ",", "da\u00df", "man", "ihn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "$,", "VVFIN", "NN", "$,", "KOUS", "PIS", "PPER"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "schneide.", "tokens": ["schnei\u00b7de", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.7": {"line.1": {"text": "Das Streichen w\u00e4hrt den ganzen Tag und sonderlich am", "tokens": ["Das", "Strei\u00b7chen", "w\u00e4hrt", "den", "gan\u00b7zen", "Tag", "und", "son\u00b7der\u00b7lich", "am"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "KON", "ADJD", "APPRART"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Morgen", "tokens": ["Mor\u00b7gen"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Bis er sich schickt, macht ihm viel Plag, und wunder-", "tokens": ["Bis", "er", "sich", "schickt", ",", "macht", "ihm", "viel", "Plag", ",", "und", "wun\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "$,", "VVFIN", "PPER", "PIAT", "NN", "$,", "KON", "TRUNC"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "gro\u00dfe Sorgen,", "tokens": ["gro\u00b7\u00dfe", "Sor\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Mu\u00df spitzig seyn, ein N\u00e4delein k\u00f6nnt man damit ein-", "tokens": ["Mu\u00df", "spit\u00b7zig", "seyn", ",", "ein", "N\u00e4\u00b7de\u00b7lein", "k\u00f6nnt", "man", "da\u00b7mit", "ein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADJD", "VAINF", "$,", "ART", "NN", "VVFIN", "PIS", "PAV", "TRUNC"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "f\u00f6del'n,", "tokens": ["f\u00f6\u00b7del'n", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Es hat kein End, all beyde H\u00e4nd haben daran zu", "tokens": ["Es", "hat", "kein", "End", ",", "all", "bey\u00b7de", "H\u00e4nd", "ha\u00b7ben", "da\u00b7ran", "zu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PIAT", "PIAT", "NN", "VAFIN", "PAV", "PTKZU"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "kn\u00f6del'n.", "tokens": ["kn\u00f6\u00b7del'", "n."], "token_info": ["word", "abbreviation"], "pos": ["XY", "XY"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.8": {"line.1": {"text": "Ein Leilach, wenn's erklecken kann, braucht er f\u00fcr einen", "tokens": ["Ein", "Lei\u00b7lach", ",", "wenn's", "er\u00b7kle\u00b7cken", "kann", ",", "braucht", "er", "f\u00fcr", "ei\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "KOUS", "VVINF", "VMFIN", "$,", "VVFIN", "PPER", "APPR", "ART"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Kragen,", "tokens": ["Kra\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ein Hasengarn h\u00e4ngt unten dran, Zahmwildprett drinn", "tokens": ["Ein", "Ha\u00b7sen\u00b7garn", "h\u00e4ngt", "un\u00b7ten", "dran", ",", "Zahm\u00b7wild\u00b7prett", "drinn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "PAV", "$,", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "zu jagen,", "tokens": ["zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Er dient ihm statt als Fazolett, das Maul thut er dran", "tokens": ["Er", "dient", "ihm", "statt", "als", "Fa\u00b7zo\u00b7lett", ",", "das", "Maul", "thut", "er", "dran"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KOKOM", "NN", "$,", "ART", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "putzen,", "tokens": ["put\u00b7zen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "St\u00e4rkt ihn mit Schmutz, der Hudelbutz, mit Falten thut", "tokens": ["St\u00e4rkt", "ihn", "mit", "Schmutz", ",", "der", "Hu\u00b7del\u00b7butz", ",", "mit", "Fal\u00b7ten", "thut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$,", "ART", "NN", "$,", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "er stutzen.", "tokens": ["er", "stut\u00b7zen", "."], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.9": {"line.1": {"text": "Um seinen Hals tr\u00e4gt er zumal ein breite rothe Bin-", "tokens": ["Um", "sei\u00b7nen", "Hals", "tr\u00e4gt", "er", "zu\u00b7mal", "ein", "brei\u00b7te", "ro\u00b7the", "Bin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ART", "ADJA", "ADJA", "TRUNC"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "den,", "tokens": ["den", ","], "token_info": ["word", "punct"], "pos": ["ART", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Damit ihn kein Catharr befall, er k\u00f6nnt sonst nicht mehr", "tokens": ["Da\u00b7mit", "ihn", "kein", "Cat\u00b7harr", "be\u00b7fall", ",", "er", "k\u00f6nnt", "sonst", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIAT", "NE", "NE", "$,", "PPER", "VVFIN", "ADV", "PTKNEG", "ADV"], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.4": {"text": "schlingen,", "tokens": ["schlin\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Das H\u00e4lsle das ist wei\u00df und rein; es m\u00f6chts die Sonn", "tokens": ["Das", "H\u00e4ls\u00b7le", "das", "ist", "wei\u00df", "und", "rein", ";", "es", "m\u00f6chts", "die", "Sonn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PDS", "VAFIN", "ADJD", "KON", "ADJD", "$.", "PPER", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "verbrennen,", "tokens": ["ver\u00b7bren\u00b7nen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Der lose Tropf verdeckt den Kropf, man m\u00f6g't den Schelm", "tokens": ["Der", "lo\u00b7se", "Tropf", "ver\u00b7deckt", "den", "Kropf", ",", "man", "m\u00f6g't", "den", "Schelm"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,", "PIS", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "sonst kennen.", "tokens": ["sonst", "ken\u00b7nen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.10": {"line.1": {"text": "Zu dem Reitmantel, den er tr\u00e4gt, kaum zwanzig Ellen", "tokens": ["Zu", "dem", "Reit\u00b7man\u00b7tel", ",", "den", "er", "tr\u00e4gt", ",", "kaum", "zwan\u00b7zig", "El\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "ADV", "CARD", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "klecken,", "tokens": ["kle\u00b7cken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "In Ermeln, die er \u00fcberschl\u00e4gt, k\u00f6nnt er zwei Dieb ver-", "tokens": ["In", "Er\u00b7meln", ",", "die", "er", "\u00fc\u00b7bersc\u00b7hl\u00e4gt", ",", "k\u00f6nnt", "er", "zwei", "Dieb", "ver"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "CARD", "NN", "TRUNC"], "meter": "-+---+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "stecken.", "tokens": ["ste\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Das Tuch ist roth, es w\u00e4re noth, wenns giebt ein'n", "tokens": ["Das", "Tuch", "ist", "roth", ",", "es", "w\u00e4\u00b7re", "noth", ",", "wenns", "giebt", "ein'n"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "PPER", "VAFIN", "NN", "$,", "KOUS", "VVFIN", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "gro\u00dfen Regen,", "tokens": ["gro\u00b7\u00dfen", "Re\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Da\u00df allemal ein Futteral er dr\u00fcber th\u00e4t anle-", "tokens": ["Da\u00df", "al\u00b7le\u00b7mal", "ein", "Fut\u00b7te\u00b7ral", "er", "dr\u00fc\u00b7ber", "th\u00e4t", "an\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PAV", "VVFIN", "TRUNC"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "gen.", "tokens": ["gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-", "measure": "single.down"}}, "stanza.11": {"line.1": {"text": "Da braucht es M\u00fch und Arbeit viel den Mantel recht zu", "tokens": ["Da", "braucht", "es", "M\u00fch", "und", "Ar\u00b7beit", "viel", "den", "Man\u00b7tel", "recht", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "ADV", "ART", "NN", "ADJD", "PTKZU"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "tragen,", "tokens": ["tra\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Wenn er hinauf ihn ziehen will; so runzelt er den Kra-", "tokens": ["Wenn", "er", "hin\u00b7auf", "ihn", "zie\u00b7hen", "will", ";", "so", "run\u00b7zelt", "er", "den", "Kra"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PPER", "VVINF", "VMFIN", "$.", "ADV", "VVFIN", "PPER", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "gen,", "tokens": ["gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Er mu\u00df allzeit auf einer Seit, gar weit hinunter han-", "tokens": ["Er", "mu\u00df", "all\u00b7zeit", "auf", "ei\u00b7ner", "Seit", ",", "gar", "weit", "hin\u00b7un\u00b7ter", "han"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "ART", "NN", "$,", "ADV", "ADJD", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.6": {"text": "gen,", "tokens": ["gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Liegt viel daran, da\u00df man auch kann in sch\u00f6nem Wam-", "tokens": ["Liegt", "viel", "da\u00b7ran", ",", "da\u00df", "man", "auch", "kann", "in", "sch\u00f6\u00b7nem", "Wam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PAV", "$,", "KOUS", "PIS", "ADV", "VMFIN", "APPR", "ADJA", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "mes prangen.", "tokens": ["mes", "pran\u00b7gen", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.12": {"line.1": {"text": "Das Wammes wie ein Vogelhaus zerhauen und zersto-", "tokens": ["Das", "Wam\u00b7mes", "wie", "ein", "Vo\u00b7gel\u00b7haus", "zer\u00b7hau\u00b7en", "und", "zer\u00b7sto"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "VVINF", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "chen,", "tokens": ["chen", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Ach Gott wie mancher Vogelstrau\u00df ist aus und eingekro-", "tokens": ["Ach", "Gott", "wie", "man\u00b7cher", "Vo\u00b7gel\u00b7strau\u00df", "ist", "aus", "und", "ein\u00b7ge\u00b7kro"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "KOKOM", "PIAT", "NN", "VAFIN", "PTKVZ", "KON", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "chen,", "tokens": ["chen", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Es ist darbey ein Vortheil neu, kanns nit besser zer-", "tokens": ["Es", "ist", "dar\u00b7bey", "ein", "Vor\u00b7theil", "neu", ",", "kanns", "nit", "bes\u00b7ser", "zer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PAV", "ART", "NN", "ADJD", "$,", "VMFIN", "PTKNEG", "ADJD", "TRUNC"], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "rei\u00dfen,", "tokens": ["rei\u00b7\u00dfen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Er besserts noch, giebt nur ein Loch, wenn zwei zusam-", "tokens": ["Er", "bes\u00b7serts", "noch", ",", "giebt", "nur", "ein", "Loch", ",", "wenn", "zwei", "zu\u00b7sam"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADV", "ADV", "$,", "VVFIN", "ADV", "ART", "NN", "$,", "KOUS", "CARD", "TRUNC"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "menschlei\u00dfen.", "tokens": ["mensc\u00b7hlei\u00b7\u00dfen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.13": {"line.1": {"text": "Damit er noch mehr Luft empfang, thut er die Kn\u00f6pf", "tokens": ["Da\u00b7mit", "er", "noch", "mehr", "Luft", "emp\u00b7fang", ",", "thut", "er", "die", "Kn\u00f6pf"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "aufschlie\u00dfen;", "tokens": ["auf\u00b7schlie\u00b7\u00dfen", ";"], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Im Winter ist ihm hei\u00df und bang, er w\u00fcrd sonst schwitzen", "tokens": ["Im", "Win\u00b7ter", "ist", "ihm", "hei\u00df", "und", "bang", ",", "er", "w\u00fcrd", "sonst", "schwit\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$,", "PPER", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "m\u00fcssen.", "tokens": ["m\u00fcs\u00b7sen", "."], "token_info": ["word", "punct"], "pos": ["VMFIN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der Nestel viel ohn' Maa\u00df und Ziel sind um und um", "tokens": ["Der", "Nes\u00b7tel", "viel", "ohn'", "Maa\u00df", "und", "Ziel", "sind", "um", "und", "um"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "KON", "NN", "VAFIN", "APPR", "KON", "KOUI"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "herbunden,", "tokens": ["her\u00b7bun\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Er geb wohl ab ein Nestel Schwab, wie man schon l\u00e4ngst", "tokens": ["Er", "geb", "wohl", "ab", "ein", "Nes\u00b7tel", "Schwab", ",", "wie", "man", "schon", "l\u00e4ngst"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN", "NE", "$,", "PWAV", "PIS", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "hat funden.", "tokens": ["hat", "fun\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.14": {"line.1": {"text": "Die T\u00e4tzle wie die Pattenfleck, jetzt auf jetzt nieder schlin-", "tokens": ["Die", "T\u00e4tz\u00b7le", "wie", "die", "Pat\u00b7ten\u00b7fleck", ",", "jetzt", "auf", "jetzt", "nie\u00b7der", "schlin"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "$,", "ADV", "APPR", "ADV", "PTKVZ", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "gen,", "tokens": ["gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Wann er die H\u00e4nd' vom Leib hin rek't, thu'n hin und", "tokens": ["Wann", "er", "die", "H\u00e4nd'", "vom", "Leib", "hin", "rek't", ",", "thu'n", "hin", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "APPRART", "NN", "ADV", "VVFIN", "$,", "VVFIN", "PTKVZ", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wieder schwingen,", "tokens": ["wie\u00b7der", "schwin\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.5": {"text": "Hat H\u00e4ndsche an, die man wohl kann ein halbe Meil", "tokens": ["Hat", "H\u00e4nd\u00b7sche", "an", ",", "die", "man", "wohl", "kann", "ein", "hal\u00b7be", "Meil"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKVZ", "$,", "PRELS", "PIS", "ADV", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "weit schmecken,", "tokens": ["weit", "schme\u00b7cken", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Wo das nit w\u00e4r; so r\u00f6che er gleich allen andern", "tokens": ["Wo", "das", "nit", "w\u00e4r", ";", "so", "r\u00f6\u00b7che", "er", "gleich", "al\u00b7len", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PDS", "PTKNEG", "VAFIN", "$.", "ADV", "VVFIN", "PPER", "ADV", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "B\u00f6cken.", "tokens": ["B\u00f6\u00b7cken", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.15": {"line.1": {"text": "Er wei\u00df gar nit mehr wie er soll den Degen jetzt an-", "tokens": ["Er", "wei\u00df", "gar", "nit", "mehr", "wie", "er", "soll", "den", "De\u00b7gen", "jetzt", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "KOKOM", "PPER", "VMFIN", "ART", "NN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "henken,", "tokens": ["hen\u00b7ken", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Er will sich nirgend schicken wol, hat zwanz'gerley Be-", "tokens": ["Er", "will", "sich", "nir\u00b7gend", "schi\u00b7cken", "wol", ",", "hat", "zwanz'\u00b7ger\u00b7ley", "Be"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "ADV", "VVFIN", "ADV", "$,", "VAFIN", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "denken,", "tokens": ["den\u00b7ken", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Thu't ihn vielmehr ganz hinten her, als an der Seite", "tokens": ["Thu't", "ihn", "viel\u00b7mehr", "ganz", "hin\u00b7ten", "her", ",", "als", "an", "der", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "$,", "KOUS", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.6": {"text": "tragen,", "tokens": ["tra\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Es leben noch all, die er zumal in einem Streich er-", "tokens": ["Es", "le\u00b7ben", "noch", "all", ",", "die", "er", "zu\u00b7mal", "in", "ei\u00b7nem", "Streich", "er"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "$,", "PRELS", "PPER", "ADV", "APPR", "ART", "NN", "TRUNC"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "schlagen.", "tokens": ["schla\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.16": {"line.1": {"text": "Die Bloderhosen um die Bein sind weiter als um d' Len-", "tokens": ["Die", "Blo\u00b7der\u00b7ho\u00b7sen", "um", "die", "Bein", "sind", "wei\u00b7ter", "als", "um", "d'", "Len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VAFIN", "ADV", "KOKOM", "APPR", "NE", "TRUNC"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.2": {"text": "den,", "tokens": ["den", ","], "token_info": ["word", "punct"], "pos": ["ART", "$,"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Die krumme Schenkel sieht man nie, damit sie ihn nit", "tokens": ["Die", "krum\u00b7me", "Schen\u00b7kel", "sieht", "man", "nie", ",", "da\u00b7mit", "sie", "ihn", "nit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PIS", "ADV", "$,", "KOUS", "PPER", "PPER", "PTKNEG"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "sch\u00e4nden,", "tokens": ["sch\u00e4n\u00b7den", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Ein Spangen weit, drey Finger breit sind sie am End", "tokens": ["Ein", "Span\u00b7gen", "weit", ",", "drey", "Fin\u00b7ger", "breit", "sind", "sie", "am", "End"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "$,", "CARD", "NN", "ADJD", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "aufschnitten,", "tokens": ["auf\u00b7schnit\u00b7ten", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Dort kratzt er sich, wenn er ein Stich von ", "tokens": ["Dort", "kratzt", "er", "sich", ",", "wenn", "er", "ein", "Stich", "von"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "erlitten.", "tokens": ["er\u00b7lit\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.17": {"line.1": {"text": "Gro\u00df Fischerstiefel hat er an, so weit als ein Wasch-", "tokens": ["Gro\u00df", "Fi\u00b7scher\u00b7stie\u00b7fel", "hat", "er", "an", ",", "so", "weit", "als", "ein", "Wasch"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "VAFIN", "PPER", "PTKVZ", "$,", "ADV", "ADJD", "KOKOM", "ART", "TRUNC"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "k\u00fcbel,", "tokens": ["k\u00fc\u00b7bel", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Nit g'nugsam er d'rein prangen kann, wiewohl sie stehn", "tokens": ["Nit", "g'\u00b7nug\u00b7sam", "er", "d'\u00b7rein", "pran\u00b7gen", "kann", ",", "wie\u00b7wohl", "sie", "stehn"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "PPER", "ADV", "VVFIN", "VMFIN", "$,", "KOUS", "PPER", "VVINF"], "meter": "+-+--+-+-+-+-+", "measure": "trochaic.septa.relaxed"}, "line.4": {"text": "gar \u00fcbel.", "tokens": ["gar", "\u00fc\u00b7bel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Ein Regenfa\u00df kann man zum Spa\u00df gar leicht daraus", "tokens": ["Ein", "Re\u00b7gen\u00b7fa\u00df", "kann", "man", "zum", "Spa\u00df", "gar", "leicht", "da\u00b7raus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "PIS", "APPRART", "NN", "ADV", "ADJD", "PAV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "formiren,", "tokens": ["for\u00b7mi\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+--", "measure": "dactylic.init"}, "line.7": {"text": "Sie waklen nicht, sind fest gericht, auf St\u00f6cklein sich", "tokens": ["Sie", "wak\u00b7len", "nicht", ",", "sind", "fest", "ge\u00b7richt", ",", "auf", "St\u00f6c\u00b7klein", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "VAFIN", "ADJD", "VVPP", "$,", "APPR", "NN", "PRF"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "fundiren.", "tokens": ["fun\u00b7di\u00b7ren", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+--", "measure": "dactylic.init"}}, "stanza.18": {"line.1": {"text": "Gro\u00df Sporenleder hat er an, gar weit ein halbe", "tokens": ["Gro\u00df", "Spo\u00b7ren\u00b7le\u00b7der", "hat", "er", "an", ",", "gar", "weit", "ein", "hal\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "VAFIN", "PPER", "PTKVZ", "$,", "ADV", "ADJD", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ellen,", "tokens": ["El\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["NE", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Gallotschen hangen unten dran, mag alles nit erz\u00e4h-", "tokens": ["Gal\u00b7lot\u00b7schen", "han\u00b7gen", "un\u00b7ten", "dran", ",", "mag", "al\u00b7les", "nit", "er\u00b7z\u00e4h"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ADV", "PAV", "$,", "VMFIN", "PIS", "PTKNEG", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "len,", "tokens": ["len", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Wie ein Pflugrad er Spornen hat, mit Resonant hell", "tokens": ["Wie", "ein", "Pflu\u00b7grad", "er", "Spor\u00b7nen", "hat", ",", "mit", "Re\u00b7so\u00b7nant", "hell"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "PPER", "NN", "VAFIN", "$,", "APPR", "NN", "ADJD"], "meter": "--+--+-+-+--+", "measure": "anapaest.di.plus"}, "line.6": {"text": "klingen,", "tokens": ["klin\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Wie wohl er sie, vielleicht gar nie aufs Pferd hinauf thut", "tokens": ["Wie", "wohl", "er", "sie", ",", "viel\u00b7leicht", "gar", "nie", "aufs", "Pferd", "hin\u00b7auf", "thut"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "PPER", "PPER", "$,", "ADV", "ADV", "ADV", "APPRART", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "schwingen.", "tokens": ["schwin\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.19": {"line.1": {"text": "Der trutzig Gsell tritt da herein, als wollt er alle", "tokens": ["Der", "trut\u00b7zig", "Gsell", "tritt", "da", "her\u00b7ein", ",", "als", "wollt", "er", "al\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "NN", "VVFIN", "ADV", "PTKVZ", "$,", "KOUS", "VMFIN", "PPER", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "fressen,", "tokens": ["fres\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Ist allzeit doch beim Sonnenschein beim Ofen hinge-", "tokens": ["Ist", "all\u00b7zeit", "doch", "beim", "Son\u00b7nen\u00b7schein", "beim", "O\u00b7fen", "hin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "APPRART", "NN", "APPRART", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "sessen.", "tokens": ["ses\u00b7sen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Die deutsche Sprach ist all sein Sach, kann kein Hund", "tokens": ["Die", "deut\u00b7sche", "Sprach", "ist", "all", "sein", "Sach", ",", "kann", "kein", "Hund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PIAT", "PPOSAT", "NN", "$,", "VMFIN", "PIAT", "NN"], "meter": "-+-+----+-+", "measure": "unknown.measure.tetra"}, "line.6": {"text": "anders loken;", "tokens": ["an\u00b7ders", "lo\u00b7ken", ";"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Sein Vater sizt und Stecken schnizt, sein Mutter spinnt", "tokens": ["Sein", "Va\u00b7ter", "sizt", "und", "Ste\u00b7cken", "schnizt", ",", "sein", "Mut\u00b7ter", "spinnt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "KON", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "am Rocken.", "tokens": ["am", "Ro\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.20": {"line.1": {"text": "K\u00f6mmt er zur Burst (Gesellschaft), thut er zur Stund", "tokens": ["K\u00f6mmt", "er", "zur", "Burst", "(", "Ge\u00b7sell\u00b7schaft", ")", ",", "thut", "er", "zur", "Stund"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "$(", "NN", "$(", "$,", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Basalamana schneiden,", "tokens": ["Ba\u00b7sa\u00b7la\u00b7ma\u00b7na", "schnei\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Zieht seinen Huth, f\u00e4hrt zu dem Mund, sagt Servitor", "tokens": ["Zieht", "sei\u00b7nen", "Huth", ",", "f\u00e4hrt", "zu", "dem", "Mund", ",", "sagt", "Ser\u00b7vi\u00b7tor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "von weitem.", "tokens": ["von", "wei\u00b7tem", "."], "token_info": ["word", "word", "punct"], "pos": ["APPR", "ADJA", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Macht Cortesie, biegt doch die Knie, gar nicht oder gar", "tokens": ["Macht", "Cor\u00b7te\u00b7sie", ",", "biegt", "doch", "die", "Knie", ",", "gar", "nicht", "o\u00b7der", "gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "VVFIN", "ADV", "ART", "NN", "$,", "ADV", "PTKNEG", "KON", "ADV"], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "wenig,", "tokens": ["we\u00b7nig", ","], "token_info": ["word", "punct"], "pos": ["ADV", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Das Haupt er buckt, die Achseln zuckt ", "tokens": ["Das", "Haupt", "er", "buckt", ",", "die", "Ach\u00b7seln", "zuckt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "terth\u00e4nig.", "tokens": ["ter\u00b7th\u00e4\u00b7nig", "."], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.21": {"line.1": {"text": "Wann er dann in die Kirche geht, auf ein Fu\u00df kniet er", "tokens": ["Wann", "er", "dann", "in", "die", "Kir\u00b7che", "geht", ",", "auf", "ein", "Fu\u00df", "kniet", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN", "PPER"], "meter": "--+--+-+--+--", "measure": "anapaest.di.plus"}, "line.2": {"text": "nieder,", "tokens": ["nie\u00b7der", ","], "token_info": ["word", "punct"], "pos": ["PTKVZ", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Er macht kein Kreuz, spricht kein Gebet, er gafft nur hin", "tokens": ["Er", "macht", "kein", "Kreuz", ",", "spricht", "kein", "Ge\u00b7bet", ",", "er", "gafft", "nur", "hin"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "VVFIN", "PIAT", "NN", "$,", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "und wieder,", "tokens": ["und", "wie\u00b7der", ","], "token_info": ["word", "word", "punct"], "pos": ["KON", "ADV", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Er dreht sein Bart zusammen hart, streicht die Razzen-", "tokens": ["Er", "dreht", "sein", "Bart", "zu\u00b7sam\u00b7men", "hart", ",", "streicht", "die", "Raz\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "ADJD", "$,", "VVFIN", "ART", "TRUNC"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "schnauz zur Seiten,", "tokens": ["schnauz", "zur", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.7": {"text": "Gar weit von hinn mit feinem Sinn thut er spazieren", "tokens": ["Gar", "weit", "von", "hinn", "mit", "fei\u00b7nem", "Sinn", "thut", "er", "spa\u00b7zie\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ADV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "reiten.", "tokens": ["rei\u00b7ten", "."], "token_info": ["word", "punct"], "pos": ["VVFIN", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.22": {"line.1": {"text": "Sein Red' ist lauter Phantasie, viel schw\u00e4tzen und viel", "tokens": ["Sein", "Red'", "ist", "lau\u00b7ter", "Phan\u00b7ta\u00b7sie", ",", "viel", "schw\u00e4t\u00b7zen", "und", "viel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PIAT", "NN", "$,", "ADV", "VVINF", "KON", "ADV"], "meter": "-+-+-+---+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "l\u00fcgen,", "tokens": ["l\u00fc\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Er l\u00fcgt daher ohn alle Scheu, bis sich die Balken", "tokens": ["Er", "l\u00fcgt", "da\u00b7her", "ohn", "al\u00b7le", "Scheu", ",", "bis", "sich", "die", "Bal\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "APPR", "PIAT", "NN", "$,", "KOUS", "PRF", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "biegen,", "tokens": ["bie\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Erz\u00e4hlet frei, wie da\u00df er sey in fremdem Land' ge-", "tokens": ["Er\u00b7z\u00e4h\u00b7let", "frei", ",", "wie", "da\u00df", "er", "sey", "in", "frem\u00b7dem", "Land'", "ge"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$,", "KOKOM", "KOUS", "PPER", "VAFIN", "APPR", "ADJA", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "wesen,", "tokens": ["we\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Er k\u00f6nn viel Sprach, kann allem nach ja kaum ein Buch-", "tokens": ["Er", "k\u00f6nn", "viel", "Sprach", ",", "kann", "al\u00b7lem", "nach", "ja", "kaum", "ein", "Buch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "$,", "VMFIN", "PIS", "APPR", "ADV", "ADV", "ART", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "stab lesen.", "tokens": ["stab", "le\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.23": {"line.1": {"text": "Er l\u00fcgt daher manch Ritterthat, die er nit hat be-", "tokens": ["Er", "l\u00fcgt", "da\u00b7her", "manch", "Rit\u00b7ter\u00b7that", ",", "die", "er", "nit", "hat", "be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "PIAT", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VAFIN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "gangen,", "tokens": ["gan\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Wie er belagert jene Stadt und jenen Kriegsmann", "tokens": ["Wie", "er", "be\u00b7la\u00b7gert", "je\u00b7ne", "Stadt", "und", "je\u00b7nen", "Kriegs\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "VVFIN", "PDAT", "NN", "KON", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "g'fangen,", "tokens": ["g'\u00b7fan\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "In einem Streich hab er zugleich zwei K\u00fcrassier er-", "tokens": ["In", "ei\u00b7nem", "Streich", "hab", "er", "zu\u00b7gleich", "zwei", "K\u00fc\u00b7ras\u00b7sier", "er"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "ADV", "CARD", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "schlagen,", "tokens": ["schla\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Kein todten Hund hat er verwundt, er thet daran ver-", "tokens": ["Kein", "tod\u00b7ten", "Hund", "hat", "er", "ver\u00b7wundt", ",", "er", "thet", "da\u00b7ran", "ver"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,", "PPER", "VVFIN", "PAV", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "zagen.", "tokens": ["za\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.24": {"line.1": {"text": "Wann er dann auf die Fechtschul geht, sich da zu", "tokens": ["Wann", "er", "dann", "auf", "die", "Fecht\u00b7schul", "geht", ",", "sich", "da", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "NN", "VVFIN", "$,", "PRF", "ADV", "PTKZU"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "exerziren,", "tokens": ["ex\u00b7er\u00b7zi\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Und einer ihm entgegen steht, die Wehr thut presen-", "tokens": ["Und", "ei\u00b7ner", "ihm", "ent\u00b7ge\u00b7gen", "steht", ",", "die", "Wehr", "thut", "pre\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ART", "PPER", "PTKVZ", "VVFIN", "$,", "ART", "NN", "VVFIN", "TRUNC"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "tiren,", "tokens": ["ti\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Da zuckt er zwar, darf doch nit gar, er thut zu leztens", "tokens": ["Da", "zuckt", "er", "zwar", ",", "darf", "doch", "nit", "gar", ",", "er", "thut", "zu", "lez\u00b7tens"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "VMFIN", "ADV", "PTKNEG", "ADV", "$,", "PPER", "VVFIN", "APPR", "NE"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "wagen,", "tokens": ["wa\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "F\u00e4ngt fechten, er mu\u00df wohl dran, man th\u00e4t ihn sonst", "tokens": ["F\u00e4ngt", "fech\u00b7ten", ",", "er", "mu\u00df", "wohl", "dran", ",", "man", "th\u00e4t", "ihn", "sonst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "VVINF", "$,", "PPER", "VMFIN", "ADV", "PAV", "$,", "PIS", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "ausjagen.", "tokens": ["aus\u00b7ja\u00b7gen", "."], "token_info": ["word", "punct"], "pos": ["VVPP", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.25": {"line.1": {"text": "Jezt nimmt er ein Postur an sich, jezt spanisch, jezt", "tokens": ["Jezt", "nimmt", "er", "ein", "Pos\u00b7tur", "an", "sich", ",", "jezt", "spa\u00b7nisch", ",", "jezt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "PRF", "$,", "ADV", "ADJD", "$,", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "franz\u00f6sisch,", "tokens": ["fran\u00b7z\u00f6\u00b7sisch", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Passiert jezt durch, jezt \u00fcber sich, haut drein zulezt po-", "tokens": ["Pas\u00b7siert", "jezt", "durch", ",", "jezt", "\u00fc\u00b7ber", "sich", ",", "haut", "drein", "zu\u00b7lezt", "po"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "ADV", "PTKVZ", "$,", "ADV", "APPR", "PRF", "$,", "VVFIN", "ADV", "ADV", "TRUNC"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "l\u00e4ckisch,", "tokens": ["l\u00e4\u00b7ckisch", ","], "token_info": ["word", "punct"], "pos": ["ADJD", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Weil er nichts kann, so geht er an, und thut die Nas'", "tokens": ["Weil", "er", "nichts", "kann", ",", "so", "geht", "er", "an", ",", "und", "thut", "die", "Nas'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PIS", "VMFIN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "verstossen,", "tokens": ["ver\u00b7stos\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVPP", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Das rothe Blut verderbt den Muth, ihm schmecken nit", "tokens": ["Das", "ro\u00b7the", "Blut", "ver\u00b7derbt", "den", "Muth", ",", "ihm", "schme\u00b7cken", "nit"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "solch Possen.", "tokens": ["solch", "Pos\u00b7sen", "."], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.26": {"line.1": {"text": "Auf dem Tanzboden l\u00e4\u00dft er sich im Jahr nit zweimal", "tokens": ["Auf", "dem", "Tanz\u00b7bo\u00b7den", "l\u00e4\u00dft", "er", "sich", "im", "Jahr", "nit", "zwei\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PRF", "APPRART", "NN", "PTKNEG", "ADV"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "sehen,", "tokens": ["se\u00b7hen", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "H\u00fcpft in die H\u00f6h ganz wunderlich, kann nichts als rum-", "tokens": ["H\u00fcpft", "in", "die", "H\u00f6h", "ganz", "wun\u00b7der\u00b7lich", ",", "kann", "nichts", "als", "rum"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ADV", "ADJD", "$,", "VMFIN", "PIS", "KOKOM", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "mer drehen,", "tokens": ["mer", "dre\u00b7hen", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$,"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Macht Capriol, als w\u00e4r er toll, thut hin und wieder", "tokens": ["Macht", "Cap\u00b7ri\u00b7ol", ",", "als", "w\u00e4r", "er", "toll", ",", "thut", "hin", "und", "wie\u00b7der"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "KOKOM", "VAFIN", "PPER", "ADJD", "$,", "VVFIN", "PTKVZ", "KON", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "fallen,", "tokens": ["fal\u00b7len", ","], "token_info": ["word", "punct"], "pos": ["VVINF", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Hurtig dazu, gleich einer Kuh, f\u00e4llt nieder, das thut", "tokens": ["Hur\u00b7tig", "da\u00b7zu", ",", "gleich", "ei\u00b7ner", "Kuh", ",", "f\u00e4llt", "nie\u00b7der", ",", "das", "thut"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADJD", "PAV", "$,", "ADV", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$,", "PDS", "VVFIN"], "meter": "+-+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "knallen.", "tokens": ["knal\u00b7len", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "+-", "measure": "trochaic.single"}}, "stanza.27": {"line.1": {"text": "Die Reitschul sucht er selten heim, er thut vorbei nur", "tokens": ["Die", "Reit\u00b7schul", "sucht", "er", "sel\u00b7ten", "heim", ",", "er", "thut", "vor\u00b7bei", "nur"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,", "PPER", "VVFIN", "ADV", "ADV"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "schnurren,", "tokens": ["schnur\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Er hat ein hinkend Pferd daheim, ein alte Kr\u00e4mer", "tokens": ["Er", "hat", "ein", "hin\u00b7kend", "Pferd", "da\u00b7heim", ",", "ein", "al\u00b7te", "Kr\u00e4\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "VVPP", "NN", "PTKVZ", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Gurren,", "tokens": ["Gur\u00b7ren", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Giebt ihr kein Heu, kein Futterei, l\u00e4\u00dft sie nur ewig", "tokens": ["Giebt", "ihr", "kein", "Heu", ",", "kein", "Fut\u00b7te\u00b7rei", ",", "l\u00e4\u00dft", "sie", "nur", "e\u00b7wig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "$,", "PIAT", "NN", "$,", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "grasen,", "tokens": ["gra\u00b7sen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Sie geht den Zelt bis da\u00df sie f\u00e4llt, den vierten Schritt", "tokens": ["Sie", "geht", "den", "Zelt", "bis", "da\u00df", "sie", "f\u00e4llt", ",", "den", "vier\u00b7ten", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "KOUS", "PPER", "VVFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "auf d' Nasen.", "tokens": ["auf", "d'", "Na\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.28": {"line.1": {"text": "Hiemit so end ich mein Gesang, vom Allomodo ge-", "tokens": ["Hie\u00b7mit", "so", "end", "ich", "mein", "Ge\u00b7sang", ",", "vom", "Al\u00b7lo\u00b7mo\u00b7do", "ge"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "VVPP", "PPER", "PPOSAT", "NN", "$,", "APPRART", "NE", "TRUNC"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.2": {"text": "sungen,", "tokens": ["sun\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Wer es nit leiden mag der gang und binde mir die", "tokens": ["Wer", "es", "nit", "lei\u00b7den", "mag", "der", "gang", "und", "bin\u00b7de", "mir", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "PTKNEG", "VVINF", "VMFIN", "ART", "NN", "KON", "VVFIN", "PPER", "ART"], "meter": "-+-+-+-+-+-++", "measure": "unknown.measure.septa"}, "line.4": {"text": "Zungen,", "tokens": ["Zun\u00b7gen", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "Der Eitelkeit zu dieser Zeit, dienen viel solcher Lap-", "tokens": ["Der", "Ei\u00b7tel\u00b7keit", "zu", "die\u00b7ser", "Zeit", ",", "die\u00b7nen", "viel", "sol\u00b7cher", "Lap"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV", "PIAT", "TRUNC"], "meter": "-+-+-+-+---+-+", "measure": "unknown.measure.hexa"}, "line.6": {"text": "pen,", "tokens": ["pen", ","], "token_info": ["word", "punct"], "pos": ["VVFIN", "$,"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Die dazumal verdienen all eine gro\u00dfe Narrenkap-", "tokens": ["Die", "da\u00b7zu\u00b7mal", "ver\u00b7die\u00b7nen", "all", "ei\u00b7ne", "gro\u00b7\u00dfe", "Nar\u00b7ren\u00b7kap"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PIAT", "ART", "ADJA", "TRUNC"], "meter": "-+-+-+--+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "pen.", "tokens": ["pen", "."], "token_info": ["word", "punct"], "pos": ["VVINF", "$."], "meter": "-", "measure": "single.down"}}}}}