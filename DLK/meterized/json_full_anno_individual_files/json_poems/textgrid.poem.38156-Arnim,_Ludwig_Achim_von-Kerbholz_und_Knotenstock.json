{"textgrid.poem.38156": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Kerbholz und Knotenstock", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Seyd lustig und fr\u00f6hlich", "tokens": ["Seyd", "lus\u00b7tig", "und", "fr\u00f6h\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "KON", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Ihr Handwerksgesellen,", "tokens": ["Ihr", "Hand\u00b7werks\u00b7ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Denn es kommt die Zeit,", "tokens": ["Denn", "es", "kommt", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Die uns all erfreut;", "tokens": ["Die", "uns", "all", "er\u00b7freut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Sie ist schon da!", "tokens": ["Sie", "ist", "schon", "da", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Feierabend genommen", "tokens": ["Fei\u00b7er\u00b7a\u00b7bend", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word"], "pos": ["ADJD", "VVPP"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "In der Still,", "tokens": ["In", "der", "Still", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "--+", "measure": "anapaest.init"}, "line.4": {"text": "Reden nicht zu viel,", "tokens": ["Re\u00b7den", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Brauchen nicht viel Wort!", "tokens": ["Brau\u00b7chen", "nicht", "viel", "Wort", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PIAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wo wir werden hinkommen,", "tokens": ["Wo", "wir", "wer\u00b7den", "hin\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Reisen ist kein Schand,", "tokens": ["Rei\u00b7sen", "ist", "kein", "Schand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Zu Wasser und zu Land,", "tokens": ["Zu", "Was\u00b7ser", "und", "zu", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gehn auch Abends zu Bier.", "tokens": ["Gehn", "auch", "A\u00b7bends", "zu", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.4": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wo wir werden hinkommen,", "tokens": ["Wo", "wir", "wer\u00b7den", "hin\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "In das Oesterreich,", "tokens": ["In", "das", "O\u00b7es\u00b7ter\u00b7reich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Gilt uns alles gleich,", "tokens": ["Gilt", "uns", "al\u00b7les", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wien ist die Hauptstadt!", "tokens": ["Wi\u00b7en", "ist", "die", "Haupt\u00b7stadt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Kaiser, K\u00f6niginn zu sehn,", "tokens": ["Kai\u00b7ser", ",", "K\u00f6\u00b7ni\u00b7ginn", "zu", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas zu erlernen,", "tokens": ["Et\u00b7was", "zu", "er\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von Bescheidenheit,", "tokens": ["Von", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Von der H\u00f6flichkeit,", "tokens": ["Von", "der", "H\u00f6f\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wie auch von Manier!", "tokens": ["Wie", "auch", "von", "Ma\u00b7nier", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.6": {"line.1": {"text": "Pre\u00dfburg in Ungarn,", "tokens": ["Pre\u00df\u00b7burg", "in", "Un\u00b7garn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hat uns bezwungen,", "tokens": ["Hat", "uns", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Breslau in der Schlesing,", "tokens": ["Bres\u00b7lau", "in", "der", "Schle\u00b7sing", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Bin ich schon gewesen,", "tokens": ["Bin", "ich", "schon", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Das gef\u00e4llt mir wohl.", "tokens": ["Das", "ge\u00b7f\u00e4llt", "mir", "wohl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Moskau in Ru\u00dfland,", "tokens": ["Mos\u00b7kau", "in", "Ru\u00df\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Allerlei Leder sind mir da bekannt,", "tokens": ["Al\u00b7ler\u00b7lei", "Le\u00b7der", "sind", "mir", "da", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Juchten und Korduan,", "tokens": ["Juch\u00b7ten", "und", "Kor\u00b7du\u00b7an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zucker und Marzipan", "tokens": ["Zu\u00b7cker", "und", "Mar\u00b7zi\u00b7pan"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "I\u00dft man allda zum Fr\u00fchst\u00fcck.", "tokens": ["I\u00dft", "man", "all\u00b7da", "zum", "Fr\u00fch\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.8": {"line.1": {"text": "Botzen in Ellischland,", "tokens": ["Bot\u00b7zen", "in", "El\u00b7lischland", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Inspruck im Tirolerland,", "tokens": ["I\u00b7nspruck", "im", "Ti\u00b7ro\u00b7ler\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setz mich auf das Meer", "tokens": ["Setz", "mich", "auf", "das", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Fahre hin und her,", "tokens": ["Fah\u00b7re", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Nach Holland hinein.", "tokens": ["Nach", "Hol\u00b7land", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.9": {"line.1": {"text": "Amsterdam in Holland,", "tokens": ["A\u00b7mster\u00b7dam", "in", "Hol\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sch\u00f6ne Farben sind uns wohlbekannt,", "tokens": ["Sch\u00f6\u00b7ne", "Far\u00b7ben", "sind", "uns", "wohl\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gr\u00fcn und blau,", "tokens": ["Gr\u00fcn", "und", "blau", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Scharlachroth,", "tokens": ["Schar\u00b7la\u00b7ch\u00b7roth", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Karmasinfarbroth.", "tokens": ["Kar\u00b7ma\u00b7sin\u00b7far\u00b7broth", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Haben einen weiten Gang", "tokens": ["Ha\u00b7ben", "ei\u00b7nen", "wei\u00b7ten", "Gang"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort in das Tirooolerland,", "tokens": ["Fort", "in", "das", "Ti\u00b7ro\u00b7o\u00b7o\u00b7ler\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Frankreich in Paris,", "tokens": ["Fran\u00b7kreich", "in", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wo ich meine Stiefel lie\u00df,", "tokens": ["Wo", "ich", "mei\u00b7ne", "Stie\u00b7fel", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist allda ein Lazareth!", "tokens": ["Ist", "all\u00b7da", "ein", "La\u00b7za\u00b7reth", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Dresden in Sachsen,", "tokens": ["Dres\u00b7den", "in", "Sach\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo die sch\u00f6nen M\u00e4del auf den B\u00e4umen wachsen,", "tokens": ["Wo", "die", "sch\u00f6\u00b7nen", "M\u00e4\u00b7del", "auf", "den", "B\u00e4u\u00b7men", "wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "H\u00e4tt' ich dran gedacht,", "tokens": ["H\u00e4tt'", "ich", "dran", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4tt' ich eine mitgebracht,", "tokens": ["H\u00e4tt'", "ich", "ei\u00b7ne", "mit\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "F\u00fcr den Altgesellen auf der Post.", "tokens": ["F\u00fcr", "den", "Alt\u00b7ge\u00b7sel\u00b7len", "auf", "der", "Post", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Prag in B\u00f6hmen, mag ich auch nicht seyn,", "tokens": ["Prag", "in", "B\u00f6h\u00b7men", ",", "mag", "ich", "auch", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seyn so viele Juden darein,", "tokens": ["Seyn", "so", "vie\u00b7le", "Ju\u00b7den", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "PIAT", "NN", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Alle liebe Tag", "tokens": ["Al\u00b7le", "lie\u00b7be", "Tag"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Ist es eine Klag,", "tokens": ["Ist", "es", "ei\u00b7ne", "Klag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Da\u00df eine Mordthat geschach.", "tokens": ["Da\u00df", "ei\u00b7ne", "Mord\u00b7that", "ge\u00b7schach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.13": {"line.1": {"text": "Drei\u00dfig tausend gro\u00df und klein", "tokens": ["Drei\u00b7\u00dfig", "tau\u00b7send", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "CARD", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Studitutidenten thun drin seyn,", "tokens": ["Stu\u00b7di\u00b7tu\u00b7ti\u00b7den\u00b7ten", "thun", "drin", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Jederzeit", "tokens": ["Je\u00b7der\u00b7zeit"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Ist es ihre Freud,", "tokens": ["Ist", "es", "ih\u00b7re", "Freud", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wenn sie machen brave Beut.", "tokens": ["Wenn", "sie", "ma\u00b7chen", "bra\u00b7ve", "Beut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "K\u00f6nnen Juden vexiren,", "tokens": ["K\u00f6n\u00b7nen", "Ju\u00b7den", "ve\u00b7xi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Recht tribuliren,", "tokens": ["Recht", "tri\u00b7bu\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "++-+-", "measure": "iambic.di"}, "line.3": {"text": "Sie gehen her", "tokens": ["Sie", "ge\u00b7hen", "her"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Mit Schweinenschmeer", "tokens": ["Mit", "Schwei\u00b7nen\u00b7schmeer"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Schmieren sie ihnen die B\u00e4rt.", "tokens": ["Schmie\u00b7ren", "sie", "ih\u00b7nen", "die", "B\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.15": {"line.1": {"text": "Haben noch einen harten Stand", "tokens": ["Ha\u00b7ben", "noch", "ei\u00b7nen", "har\u00b7ten", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Bis nunter ins Kravattenland,", "tokens": ["Bis", "nun\u00b7ter", "ins", "Kra\u00b7vat\u00b7ten\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Sitz ich auf der Sau", "tokens": ["Sitz", "ich", "auf", "der", "Sau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und herummer schau,", "tokens": ["Und", "her\u00b7um\u00b7mer", "schau", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,"], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Belgrad ist schon da.", "tokens": ["Bel\u00b7grad", "ist", "schon", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Nun adje Heidelberg,", "tokens": ["Nun", "ad\u00b7je", "Hei\u00b7del\u00b7berg", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Bist eine rechte Staatsherberg,", "tokens": ["Bist", "ei\u00b7ne", "rech\u00b7te", "Staats\u00b7her\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ist ganz still,", "tokens": ["Ist", "ganz", "still", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wenn man will", "tokens": ["Wenn", "man", "will"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "VMFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Singen die ganze Nacht.", "tokens": ["Sin\u00b7gen", "die", "gan\u00b7ze", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.17": {"line.1": {"text": "Nun adje du werthe Stadt,", "tokens": ["Nun", "ad\u00b7je", "du", "wert\u00b7he", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Weil es ausgeregnet hat,", "tokens": ["Weil", "es", "aus\u00b7ge\u00b7reg\u00b7net", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Parableh", "tokens": ["Mit", "dem", "Pa\u00b7rab\u00b7leh"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Geh ich nach der See,", "tokens": ["Geh", "ich", "nach", "der", "See", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wenn ich komm vom gro\u00dfen Fa\u00df.", "tokens": ["Wenn", "ich", "komm", "vom", "gro\u00b7\u00dfen", "Fa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Seyd lustig und fr\u00f6hlich", "tokens": ["Seyd", "lus\u00b7tig", "und", "fr\u00f6h\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["VAIMP", "ADJD", "KON", "ADJD"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Ihr Handwerksgesellen,", "tokens": ["Ihr", "Hand\u00b7werks\u00b7ge\u00b7sel\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Denn es kommt die Zeit,", "tokens": ["Denn", "es", "kommt", "die", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Die uns all erfreut;", "tokens": ["Die", "uns", "all", "er\u00b7freut", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PIAT", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Sie ist schon da!", "tokens": ["Sie", "ist", "schon", "da", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.19": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Feierabend genommen", "tokens": ["Fei\u00b7er\u00b7a\u00b7bend", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word"], "pos": ["ADJD", "VVPP"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "In der Still,", "tokens": ["In", "der", "Still", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "--+", "measure": "anapaest.init"}, "line.4": {"text": "Reden nicht zu viel,", "tokens": ["Re\u00b7den", "nicht", "zu", "viel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PTKA", "PIS", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Brauchen nicht viel Wort!", "tokens": ["Brau\u00b7chen", "nicht", "viel", "Wort", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "PIAT", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wo wir werden hinkommen,", "tokens": ["Wo", "wir", "wer\u00b7den", "hin\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Reisen ist kein Schand,", "tokens": ["Rei\u00b7sen", "ist", "kein", "Schand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Zu Wasser und zu Land,", "tokens": ["Zu", "Was\u00b7ser", "und", "zu", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Gehn auch Abends zu Bier.", "tokens": ["Gehn", "auch", "A\u00b7bends", "zu", "Bier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.21": {"line.1": {"text": "Wir haben uns besonnen,", "tokens": ["Wir", "ha\u00b7ben", "uns", "be\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wo wir werden hinkommen,", "tokens": ["Wo", "wir", "wer\u00b7den", "hin\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VAFIN", "VVPP", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "In das Oesterreich,", "tokens": ["In", "das", "O\u00b7es\u00b7ter\u00b7reich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Gilt uns alles gleich,", "tokens": ["Gilt", "uns", "al\u00b7les", "gleich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIS", "ADV", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wien ist die Hauptstadt!", "tokens": ["Wi\u00b7en", "ist", "die", "Haupt\u00b7stadt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Kaiser, K\u00f6niginn zu sehn,", "tokens": ["Kai\u00b7ser", ",", "K\u00f6\u00b7ni\u00b7ginn", "zu", "sehn", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Etwas zu erlernen,", "tokens": ["Et\u00b7was", "zu", "er\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Von Bescheidenheit,", "tokens": ["Von", "Be\u00b7schei\u00b7den\u00b7heit", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Von der H\u00f6flichkeit,", "tokens": ["Von", "der", "H\u00f6f\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wie auch von Manier!", "tokens": ["Wie", "auch", "von", "Ma\u00b7nier", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "APPR", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.23": {"line.1": {"text": "Pre\u00dfburg in Ungarn,", "tokens": ["Pre\u00df\u00b7burg", "in", "Un\u00b7garn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Hat uns bezwungen,", "tokens": ["Hat", "uns", "be\u00b7zwun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Breslau in der Schlesing,", "tokens": ["Bres\u00b7lau", "in", "der", "Schle\u00b7sing", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Bin ich schon gewesen,", "tokens": ["Bin", "ich", "schon", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VAPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Das gef\u00e4llt mir wohl.", "tokens": ["Das", "ge\u00b7f\u00e4llt", "mir", "wohl", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Moskau in Ru\u00dfland,", "tokens": ["Mos\u00b7kau", "in", "Ru\u00df\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Allerlei Leder sind mir da bekannt,", "tokens": ["Al\u00b7ler\u00b7lei", "Le\u00b7der", "sind", "mir", "da", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Juchten und Korduan,", "tokens": ["Juch\u00b7ten", "und", "Kor\u00b7du\u00b7an", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Zucker und Marzipan", "tokens": ["Zu\u00b7cker", "und", "Mar\u00b7zi\u00b7pan"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.5": {"text": "I\u00dft man allda zum Fr\u00fchst\u00fcck.", "tokens": ["I\u00dft", "man", "all\u00b7da", "zum", "Fr\u00fch\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.25": {"line.1": {"text": "Botzen in Ellischland,", "tokens": ["Bot\u00b7zen", "in", "El\u00b7lischland", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Inspruck im Tirolerland,", "tokens": ["I\u00b7nspruck", "im", "Ti\u00b7ro\u00b7ler\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setz mich auf das Meer", "tokens": ["Setz", "mich", "auf", "das", "Meer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Fahre hin und her,", "tokens": ["Fah\u00b7re", "hin", "und", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Nach Holland hinein.", "tokens": ["Nach", "Hol\u00b7land", "hin\u00b7ein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.26": {"line.1": {"text": "Amsterdam in Holland,", "tokens": ["A\u00b7mster\u00b7dam", "in", "Hol\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sch\u00f6ne Farben sind uns wohlbekannt,", "tokens": ["Sch\u00f6\u00b7ne", "Far\u00b7ben", "sind", "uns", "wohl\u00b7be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Gr\u00fcn und blau,", "tokens": ["Gr\u00fcn", "und", "blau", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Scharlachroth,", "tokens": ["Schar\u00b7la\u00b7ch\u00b7roth", ","], "token_info": ["word", "punct"], "pos": ["NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Karmasinfarbroth.", "tokens": ["Kar\u00b7ma\u00b7sin\u00b7far\u00b7broth", "."], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Haben einen weiten Gang", "tokens": ["Ha\u00b7ben", "ei\u00b7nen", "wei\u00b7ten", "Gang"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort in das Tirooolerland,", "tokens": ["Fort", "in", "das", "Ti\u00b7ro\u00b7o\u00b7o\u00b7ler\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Frankreich in Paris,", "tokens": ["Fran\u00b7kreich", "in", "Pa\u00b7ris", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "Wo ich meine Stiefel lie\u00df,", "tokens": ["Wo", "ich", "mei\u00b7ne", "Stie\u00b7fel", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist allda ein Lazareth!", "tokens": ["Ist", "all\u00b7da", "ein", "La\u00b7za\u00b7reth", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.28": {"line.1": {"text": "Dresden in Sachsen,", "tokens": ["Dres\u00b7den", "in", "Sach\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo die sch\u00f6nen M\u00e4del auf den B\u00e4umen wachsen,", "tokens": ["Wo", "die", "sch\u00f6\u00b7nen", "M\u00e4\u00b7del", "auf", "den", "B\u00e4u\u00b7men", "wach\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "H\u00e4tt' ich dran gedacht,", "tokens": ["H\u00e4tt'", "ich", "dran", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PAV", "VVPP", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00e4tt' ich eine mitgebracht,", "tokens": ["H\u00e4tt'", "ich", "ei\u00b7ne", "mit\u00b7ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "F\u00fcr den Altgesellen auf der Post.", "tokens": ["F\u00fcr", "den", "Alt\u00b7ge\u00b7sel\u00b7len", "auf", "der", "Post", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.29": {"line.1": {"text": "Prag in B\u00f6hmen, mag ich auch nicht seyn,", "tokens": ["Prag", "in", "B\u00f6h\u00b7men", ",", "mag", "ich", "auch", "nicht", "seyn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "VMFIN", "PPER", "ADV", "PTKNEG", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Seyn so viele Juden darein,", "tokens": ["Seyn", "so", "vie\u00b7le", "Ju\u00b7den", "da\u00b7rein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "PIAT", "NN", "PAV", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Alle liebe Tag", "tokens": ["Al\u00b7le", "lie\u00b7be", "Tag"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Ist es eine Klag,", "tokens": ["Ist", "es", "ei\u00b7ne", "Klag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Da\u00df eine Mordthat geschach.", "tokens": ["Da\u00df", "ei\u00b7ne", "Mord\u00b7that", "ge\u00b7schach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADJD", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.30": {"line.1": {"text": "Drei\u00dfig tausend gro\u00df und klein", "tokens": ["Drei\u00b7\u00dfig", "tau\u00b7send", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "CARD", "ADJD", "KON", "ADJD"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Studitutidenten thun drin seyn,", "tokens": ["Stu\u00b7di\u00b7tu\u00b7ti\u00b7den\u00b7ten", "thun", "drin", "seyn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "ADV", "VAINF", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Jederzeit", "tokens": ["Je\u00b7der\u00b7zeit"], "token_info": ["word"], "pos": ["NN"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Ist es ihre Freud,", "tokens": ["Ist", "es", "ih\u00b7re", "Freud", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wenn sie machen brave Beut.", "tokens": ["Wenn", "sie", "ma\u00b7chen", "bra\u00b7ve", "Beut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVINF", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.31": {"line.1": {"text": "K\u00f6nnen Juden vexiren,", "tokens": ["K\u00f6n\u00b7nen", "Ju\u00b7den", "ve\u00b7xi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VMFIN", "NN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Recht tribuliren,", "tokens": ["Recht", "tri\u00b7bu\u00b7li\u00b7ren", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$,"], "meter": "++-+-", "measure": "iambic.di"}, "line.3": {"text": "Sie gehen her", "tokens": ["Sie", "ge\u00b7hen", "her"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKVZ"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Mit Schweinenschmeer", "tokens": ["Mit", "Schwei\u00b7nen\u00b7schmeer"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Schmieren sie ihnen die B\u00e4rt.", "tokens": ["Schmie\u00b7ren", "sie", "ih\u00b7nen", "die", "B\u00e4rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.32": {"line.1": {"text": "Haben noch einen harten Stand", "tokens": ["Ha\u00b7ben", "noch", "ei\u00b7nen", "har\u00b7ten", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Bis nunter ins Kravattenland,", "tokens": ["Bis", "nun\u00b7ter", "ins", "Kra\u00b7vat\u00b7ten\u00b7land", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Sitz ich auf der Sau", "tokens": ["Sitz", "ich", "auf", "der", "Sau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Und herummer schau,", "tokens": ["Und", "her\u00b7um\u00b7mer", "schau", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,"], "meter": "--+-+", "measure": "anapaest.init"}, "line.5": {"text": "Belgrad ist schon da.", "tokens": ["Bel\u00b7grad", "ist", "schon", "da", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.33": {"line.1": {"text": "Nun adje Heidelberg,", "tokens": ["Nun", "ad\u00b7je", "Hei\u00b7del\u00b7berg", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Bist eine rechte Staatsherberg,", "tokens": ["Bist", "ei\u00b7ne", "rech\u00b7te", "Staats\u00b7her\u00b7berg", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Ist ganz still,", "tokens": ["Ist", "ganz", "still", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Wenn man will", "tokens": ["Wenn", "man", "will"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PIS", "VMFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "Singen die ganze Nacht.", "tokens": ["Sin\u00b7gen", "die", "gan\u00b7ze", "Nacht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.34": {"line.1": {"text": "Nun adje du werthe Stadt,", "tokens": ["Nun", "ad\u00b7je", "du", "wert\u00b7he", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Weil es ausgeregnet hat,", "tokens": ["Weil", "es", "aus\u00b7ge\u00b7reg\u00b7net", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mit dem Parableh", "tokens": ["Mit", "dem", "Pa\u00b7rab\u00b7leh"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Geh ich nach der See,", "tokens": ["Geh", "ich", "nach", "der", "See", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Wenn ich komm vom gro\u00dfen Fa\u00df.", "tokens": ["Wenn", "ich", "komm", "vom", "gro\u00b7\u00dfen", "Fa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}