{"dta.poem.9228": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Ii.  \n Ein Muster von alten Ertz-Complimenten.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Maedgen/ hat sie sich geschminckt/", "tokens": ["Maed\u00b7gen", "/", "hat", "sie", "sich", "ge\u00b7schminckt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "PPER", "PRF", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil die rosen-rothen straalen", "tokens": ["Weil", "die", "ro\u00b7sen\u00b7ro\u00b7then", "straa\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Den beliebten schein bemahlen/", "tokens": ["Den", "be\u00b7lieb\u00b7ten", "schein", "be\u00b7mah\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der aus ihren wangen blinckt?", "tokens": ["Der", "aus", "ih\u00b7ren", "wan\u00b7gen", "blinckt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ist sie von natur so sch\u00f6ne?", "tokens": ["Ist", "sie", "von", "na\u00b7tur", "so", "sch\u00f6\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "ADV", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Nein/ ach nein/ wie mich bed\u00fcnckt/", "tokens": ["Nein", "/", "ach", "nein", "/", "wie", "mich", "be\u00b7d\u00fcnckt", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "XY", "PTKANT", "$(", "PWAV", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Dieses ist ihr blo\u00df geh\u00f6ne/", "tokens": ["Die\u00b7ses", "ist", "ihr", "blo\u00df", "ge\u00b7h\u00f6\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4dgen/ hat sie sich geschminckt.", "tokens": ["M\u00e4d\u00b7gen", "/", "hat", "sie", "sich", "ge\u00b7schminckt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "2. M\u00e4dgen hat sie sich geschminckt?", "tokens": ["M\u00e4d\u00b7gen", "hat", "sie", "sich", "ge\u00b7schminckt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mein herr nachbar der mu\u00df eben", "tokens": ["Mein", "herr", "nach\u00b7bar", "der", "mu\u00df", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "APPR", "ART", "VMFIN", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Diese meynung von sich geben/", "tokens": ["Die\u00b7se", "mey\u00b7nung", "von", "sich", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sieht sie nicht/ wie er mir winckt?", "tokens": ["Sieht", "sie", "nicht", "/", "wie", "er", "mir", "winckt", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKNEG", "$(", "PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sol ich die gedancken sagen/", "tokens": ["Sol", "ich", "die", "ge\u00b7dan\u00b7cken", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Die er heimlich an mich bringt?", "tokens": ["Die", "er", "heim\u00b7lich", "an", "mich", "bringt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Gelt/ ich sol noch einmahl fragen/", "tokens": ["Gelt", "/", "ich", "sol", "noch", "ein\u00b7mahl", "fra\u00b7gen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VMFIN", "ADV", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4dgen/ hat sie sich geschminckt?", "tokens": ["M\u00e4d\u00b7gen", "/", "hat", "sie", "sich", "ge\u00b7schminckt", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "3. M\u00e4dgen hat sie sich geschminckt?", "tokens": ["M\u00e4d\u00b7gen", "hat", "sie", "sich", "ge\u00b7schminckt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Halt/ ich wil denselben h\u00f6ren/", "tokens": ["Halt", "/", "ich", "wil", "den\u00b7sel\u00b7ben", "h\u00f6\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VMFIN", "PDS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Welcher ihr zu lieb und ehren", "tokens": ["Wel\u00b7cher", "ihr", "zu", "lieb", "und", "eh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAT", "PPOSAT", "PTKA", "ADJD", "KON", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Eines auf gesundheit trinckt/", "tokens": ["Ei\u00b7nes", "auf", "ge\u00b7sund\u00b7heit", "trinckt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Der wird sich so viel entbrechen/", "tokens": ["Der", "wird", "sich", "so", "viel", "ent\u00b7bre\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PRF", "ADV", "ADV", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und so fern es ihn bed\u00fcnckt/", "tokens": ["Und", "so", "fern", "es", "ihn", "be\u00b7d\u00fcnckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PPER", "PPER", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Eben dieses urtheil sprechen:", "tokens": ["E\u00b7ben", "die\u00b7ses", "ur\u00b7theil", "spre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4dgen sie hat sich geschminckt.", "tokens": ["M\u00e4d\u00b7gen", "sie", "hat", "sich", "ge\u00b7schminckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VAFIN", "PRF", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.4": {"line.1": {"text": "4. M\u00e4dgen hat sie sich geschminckt?", "tokens": ["M\u00e4d\u00b7gen", "hat", "sie", "sich", "ge\u00b7schminckt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "PRF", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Ach/ sie sey doch nicht so sch\u00f6ne/", "tokens": ["Ach", "/", "sie", "sey", "doch", "nicht", "so", "sch\u00f6\u00b7ne", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$(", "PPER", "VAFIN", "ADV", "PTKNEG", "ADV", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil uns arme b\u00fcrger s\u00f6hne", "tokens": ["Weil", "uns", "ar\u00b7me", "b\u00fcr\u00b7ger", "s\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sonst die liebe gar umringt:", "tokens": ["Sonst", "die", "lie\u00b7be", "gar", "um\u00b7ringt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wo ihr die sch\u00f6ne frage", "tokens": ["Und", "wo", "ihr", "die", "sch\u00f6\u00b7ne", "fra\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "----+-+-", "measure": "unknown.measure.di"}, "line.6": {"text": "Jrgend in die nase stinckt/", "tokens": ["Jr\u00b7gend", "in", "die", "na\u00b7se", "stinckt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "So verzeih sie/ da\u00df ich sage/", "tokens": ["So", "ver\u00b7zeih", "sie", "/", "da\u00df", "ich", "sa\u00b7ge", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "$(", "KOUS", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "M\u00e4dgen/ sie hat sich geschminckt.", "tokens": ["M\u00e4d\u00b7gen", "/", "sie", "hat", "sich", "ge\u00b7schminckt", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PPER", "VAFIN", "PRF", "VVPP", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}}}}