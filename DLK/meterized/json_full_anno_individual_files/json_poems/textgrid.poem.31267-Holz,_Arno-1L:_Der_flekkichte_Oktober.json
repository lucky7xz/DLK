{"textgrid.poem.31267": {"metadata": {"author": {"name": "Holz, Arno", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der flekkichte Oktober", "genre": "verse", "period": "N.A.", "pub_year": 1896, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der flekkichte Oktober", "tokens": ["Der", "flek\u00b7kich\u00b7te", "Ok\u00b7to\u00b7ber"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "hat alles bundt vermahlt/", "tokens": ["hat", "al\u00b7les", "bundt", "ver\u00b7mahlt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mit \u00d6pffeln au\u00df Zinober", "tokens": ["mit", "\u00d6pf\u00b7feln", "au\u00df", "Zi\u00b7no\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die reiffe ", "tokens": ["die", "reif\u00b7fe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "schon schallt durch Pusch und Str\u00e4uche", "tokens": ["schon", "schallt", "durch", "Pusch", "und", "Str\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "In solchen s\u00fcssen Tagen/", "tokens": ["In", "sol\u00b7chen", "s\u00fcs\u00b7sen", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hertz-werthe Br\u00fcder ihr/", "tokens": ["Hertz\u00b7wert\u00b7he", "Br\u00fc\u00b7der", "ihr", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "f\u00fcllt man sich bi\u00df zum Kragen", "tokens": ["f\u00fcllt", "man", "sich", "bi\u00df", "zum", "Kra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "die Haut voll Malvasir.", "tokens": ["die", "Haut", "voll", "Mal\u00b7va\u00b7sir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das M\u00e4ssergen kricht Scharten", "tokens": ["Das", "M\u00e4s\u00b7ser\u00b7gen", "kricht", "Schar\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "und fast geht man entzwey", "tokens": ["und", "fast", "geht", "man", "ent\u00b7zwey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PTKVZ"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "bey Schweinernem mit Schwarten/", "tokens": ["bey", "Schwei\u00b7ner\u00b7nem", "mit", "Schwar\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "bei Stokk-Fisch und Salbey.", "tokens": ["bei", "Stok\u00b7k\u00b7Fisch", "und", "Sal\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Mirtyllgen/ s\u00fcsse Taube/", "tokens": ["Mir\u00b7tyll\u00b7gen", "/", "s\u00fcs\u00b7se", "Tau\u00b7be", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "kom/ d\u00e4kke uns den Disch", "tokens": ["kom", "/", "d\u00e4k\u00b7ke", "uns", "den", "Disch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "in dihser Purpur-Laube/", "tokens": ["in", "dih\u00b7ser", "Pur\u00b7pur\u00b7Lau\u00b7be", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "noch sind wir jung und frisch.", "tokens": ["noch", "sind", "wir", "jung", "und", "frisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Noch kr\u00e4chtzen nicht die Raben/", "tokens": ["Noch", "kr\u00e4cht\u00b7zen", "nicht", "die", "Ra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wormit ", "tokens": ["wor\u00b7mit"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "noch kr\u00e4fftgen uns die Gaben/", "tokens": ["noch", "kr\u00e4fft\u00b7gen", "uns", "die", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "die uns ", "tokens": ["die", "uns"], "token_info": ["word", "word"], "pos": ["ART", "PPER"], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "kein Finger dhut uns weh", "tokens": ["kein", "Fin\u00b7ger", "dhut", "uns", "weh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "bey sch\u00f6n ber\u00e4uchten Schincken/", "tokens": ["bey", "sch\u00f6n", "be\u00b7r\u00e4uch\u00b7ten", "Schin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "darzu wa\u00df Sp\u00e4kk-Gelee.", "tokens": ["dar\u00b7zu", "wa\u00df", "Sp\u00e4k\u00b7k\u00b7Ge\u00b7lee", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Fast mehr al\u00df ", "tokens": ["Fast", "mehr", "al\u00df"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "erfreun itzt unsern Sinn", "tokens": ["er\u00b7freun", "itzt", "un\u00b7sern", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "mit ihren Gr\u00fcbgens drin!", "tokens": ["mit", "ih\u00b7ren", "Gr\u00fcb\u00b7gens", "drin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wir lassen nichts verderben/", "tokens": ["Wir", "las\u00b7sen", "nichts", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wir geben kein Qwartir", "tokens": ["wir", "ge\u00b7ben", "kein", "Qwar\u00b7tir"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.3": {"text": "und fr\u00f6lig m\u00fcssen sterben", "tokens": ["und", "fr\u00f6\u00b7lig", "m\u00fcs\u00b7sen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "drey Gl\u00e4sgens oder vier.", "tokens": ["drey", "Gl\u00e4s\u00b7gens", "o\u00b7der", "vier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und brommts uns gleich im K\u00f6pffgen/", "tokens": ["Und", "brommts", "uns", "gleich", "im", "K\u00f6pff\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "da\u00df ist uns einerley/", "tokens": ["da\u00df", "ist", "uns", "ei\u00b7ner\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "nur bitte ja kein Tr\u00f6pffgen", "tokens": ["nur", "bit\u00b7te", "ja", "kein", "Tr\u00f6pff\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Maul-ab und neben-bey!", "tokens": ["Maul\u00b7ab", "und", "ne\u00b7ben\u00b7bey", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Moseller und Veltliner/", "tokens": ["Mo\u00b7sel\u00b7ler", "und", "Velt\u00b7li\u00b7ner", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$("], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "zu allem jauchtz ich Ja/", "tokens": ["zu", "al\u00b7lem", "jauchtz", "ich", "Ja", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "PPER", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rosazer/ Marziminer/", "tokens": ["Ro\u00b7sa\u00b7zer", "/", "Mar\u00b7zi\u00b7mi\u00b7ner", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Tokay und Mallaga.", "tokens": ["To\u00b7kay", "und", "Mal\u00b7la\u00b7ga", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nur bloh\u00df kein Knikke-Peter/", "tokens": ["Nur", "bloh\u00df", "kein", "Knik\u00b7ke\u00b7Pe\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wenn alle ", "tokens": ["wenn", "al\u00b7le"], "token_info": ["word", "word"], "pos": ["KOUS", "PIS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "w\u00fcrd ich wie pa\u00dflich seyn!", "tokens": ["w\u00fcrd", "ich", "wie", "pa\u00df\u00b7lich", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Bald ist itzt wohl gelitten", "tokens": ["Bald", "ist", "itzt", "wohl", "ge\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "die g\u00f6ldne M\u00e4rtens-Gantz/", "tokens": ["die", "g\u00f6ld\u00b7ne", "M\u00e4r\u00b7tens\u00b7Gantz", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Oliwckens/ Kappern/ Qwitten", "tokens": ["O\u00b7liw\u00b7ckens", "/", "Kap\u00b7pern", "/", "Qwit\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NE", "$(", "NN", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "stopfft man ihr untern Schwantz.", "tokens": ["stopfft", "man", "ihr", "un\u00b7tern", "Schwantz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "For Wilt-Pr\u00e4tt und Basteten", "tokens": ["For", "Wil\u00b7tPr\u00e4tt", "und", "Bas\u00b7te\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "KON", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.6": {"text": "ist dan die r\u00e4chte Zeit \u2013", "tokens": ["ist", "dan", "die", "r\u00e4ch\u00b7te", "Zeit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "la\u00dft andre knien und beten/", "tokens": ["la\u00dft", "and\u00b7re", "kni\u00b7en", "und", "be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "KON", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "ich ", "tokens": ["ich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}}, "stanza.8": {"line.1": {"text": "Der flekkichte Oktober", "tokens": ["Der", "flek\u00b7kich\u00b7te", "Ok\u00b7to\u00b7ber"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "hat alles bundt vermahlt/", "tokens": ["hat", "al\u00b7les", "bundt", "ver\u00b7mahlt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADJD", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "mit \u00d6pffeln au\u00df Zinober", "tokens": ["mit", "\u00d6pf\u00b7feln", "au\u00df", "Zi\u00b7no\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "die reiffe ", "tokens": ["die", "reif\u00b7fe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "schon schallt durch Pusch und Str\u00e4uche", "tokens": ["schon", "schallt", "durch", "Pusch", "und", "Str\u00e4u\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "In solchen s\u00fcssen Tagen/", "tokens": ["In", "sol\u00b7chen", "s\u00fcs\u00b7sen", "Ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hertz-werthe Br\u00fcder ihr/", "tokens": ["Hertz\u00b7wert\u00b7he", "Br\u00fc\u00b7der", "ihr", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "f\u00fcllt man sich bi\u00df zum Kragen", "tokens": ["f\u00fcllt", "man", "sich", "bi\u00df", "zum", "Kra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "die Haut voll Malvasir.", "tokens": ["die", "Haut", "voll", "Mal\u00b7va\u00b7sir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Das M\u00e4ssergen kricht Scharten", "tokens": ["Das", "M\u00e4s\u00b7ser\u00b7gen", "kricht", "Schar\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "und fast geht man entzwey", "tokens": ["und", "fast", "geht", "man", "ent\u00b7zwey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PTKVZ"], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.7": {"text": "bey Schweinernem mit Schwarten/", "tokens": ["bey", "Schwei\u00b7ner\u00b7nem", "mit", "Schwar\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "bei Stokk-Fisch und Salbey.", "tokens": ["bei", "Stok\u00b7k\u00b7Fisch", "und", "Sal\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Mirtyllgen/ s\u00fcsse Taube/", "tokens": ["Mir\u00b7tyll\u00b7gen", "/", "s\u00fcs\u00b7se", "Tau\u00b7be", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "kom/ d\u00e4kke uns den Disch", "tokens": ["kom", "/", "d\u00e4k\u00b7ke", "uns", "den", "Disch"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "in dihser Purpur-Laube/", "tokens": ["in", "dih\u00b7ser", "Pur\u00b7pur\u00b7Lau\u00b7be", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "noch sind wir jung und frisch.", "tokens": ["noch", "sind", "wir", "jung", "und", "frisch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Noch kr\u00e4chtzen nicht die Raben/", "tokens": ["Noch", "kr\u00e4cht\u00b7zen", "nicht", "die", "Ra\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wormit ", "tokens": ["wor\u00b7mit"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "noch kr\u00e4fftgen uns die Gaben/", "tokens": ["noch", "kr\u00e4fft\u00b7gen", "uns", "die", "Ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "die uns ", "tokens": ["die", "uns"], "token_info": ["word", "word"], "pos": ["ART", "PPER"], "meter": "-+", "measure": "iambic.single"}}, "stanza.11": {"line.1": {"text": "kein Finger dhut uns weh", "tokens": ["kein", "Fin\u00b7ger", "dhut", "uns", "weh"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "bey sch\u00f6n ber\u00e4uchten Schincken/", "tokens": ["bey", "sch\u00f6n", "be\u00b7r\u00e4uch\u00b7ten", "Schin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "darzu wa\u00df Sp\u00e4kk-Gelee.", "tokens": ["dar\u00b7zu", "wa\u00df", "Sp\u00e4k\u00b7k\u00b7Ge\u00b7lee", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Fast mehr al\u00df ", "tokens": ["Fast", "mehr", "al\u00df"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PIAT", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "erfreun itzt unsern Sinn", "tokens": ["er\u00b7freun", "itzt", "un\u00b7sern", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "mit ihren Gr\u00fcbgens drin!", "tokens": ["mit", "ih\u00b7ren", "Gr\u00fcb\u00b7gens", "drin", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wir lassen nichts verderben/", "tokens": ["Wir", "las\u00b7sen", "nichts", "ver\u00b7der\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "wir geben kein Qwartir", "tokens": ["wir", "ge\u00b7ben", "kein", "Qwar\u00b7tir"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-++-", "measure": "unknown.measure.tri"}, "line.3": {"text": "und fr\u00f6lig m\u00fcssen sterben", "tokens": ["und", "fr\u00f6\u00b7lig", "m\u00fcs\u00b7sen", "ster\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJD", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "drey Gl\u00e4sgens oder vier.", "tokens": ["drey", "Gl\u00e4s\u00b7gens", "o\u00b7der", "vier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "KON", "CARD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Und brommts uns gleich im K\u00f6pffgen/", "tokens": ["Und", "brommts", "uns", "gleich", "im", "K\u00f6pff\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "da\u00df ist uns einerley/", "tokens": ["da\u00df", "ist", "uns", "ei\u00b7ner\u00b7ley", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "nur bitte ja kein Tr\u00f6pffgen", "tokens": ["nur", "bit\u00b7te", "ja", "kein", "Tr\u00f6pff\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Maul-ab und neben-bey!", "tokens": ["Maul\u00b7ab", "und", "ne\u00b7ben\u00b7bey", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Moseller und Veltliner/", "tokens": ["Mo\u00b7sel\u00b7ler", "und", "Velt\u00b7li\u00b7ner", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$("], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.2": {"text": "zu allem jauchtz ich Ja/", "tokens": ["zu", "al\u00b7lem", "jauchtz", "ich", "Ja", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "PPER", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rosazer/ Marziminer/", "tokens": ["Ro\u00b7sa\u00b7zer", "/", "Mar\u00b7zi\u00b7mi\u00b7ner", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Tokay und Mallaga.", "tokens": ["To\u00b7kay", "und", "Mal\u00b7la\u00b7ga", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nur bloh\u00df kein Knikke-Peter/", "tokens": ["Nur", "bloh\u00df", "kein", "Knik\u00b7ke\u00b7Pe\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "wenn alle ", "tokens": ["wenn", "al\u00b7le"], "token_info": ["word", "word"], "pos": ["KOUS", "PIS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "zu ", "tokens": ["zu"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "w\u00fcrd ich wie pa\u00dflich seyn!", "tokens": ["w\u00fcrd", "ich", "wie", "pa\u00df\u00b7lich", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Bald ist itzt wohl gelitten", "tokens": ["Bald", "ist", "itzt", "wohl", "ge\u00b7lit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "die g\u00f6ldne M\u00e4rtens-Gantz/", "tokens": ["die", "g\u00f6ld\u00b7ne", "M\u00e4r\u00b7tens\u00b7Gantz", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Oliwckens/ Kappern/ Qwitten", "tokens": ["O\u00b7liw\u00b7ckens", "/", "Kap\u00b7pern", "/", "Qwit\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["NE", "$(", "NN", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "stopfft man ihr untern Schwantz.", "tokens": ["stopfft", "man", "ihr", "un\u00b7tern", "Schwantz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "For Wilt-Pr\u00e4tt und Basteten", "tokens": ["For", "Wil\u00b7tPr\u00e4tt", "und", "Bas\u00b7te\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NE", "KON", "NN"], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.6": {"text": "ist dan die r\u00e4chte Zeit \u2013", "tokens": ["ist", "dan", "die", "r\u00e4ch\u00b7te", "Zeit", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "la\u00dft andre knien und beten/", "tokens": ["la\u00dft", "and\u00b7re", "kni\u00b7en", "und", "be\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "VVFIN", "KON", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "ich ", "tokens": ["ich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}}}}}