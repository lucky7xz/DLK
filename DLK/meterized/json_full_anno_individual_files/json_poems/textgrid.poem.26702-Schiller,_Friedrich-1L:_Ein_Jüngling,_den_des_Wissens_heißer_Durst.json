{"textgrid.poem.26702": {"metadata": {"author": {"name": "Schiller, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein J\u00fcngling, den des Wissens hei\u00dfer Durst", "genre": "verse", "period": "N.A.", "pub_year": 1782, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein J\u00fcngling, den des Wissens hei\u00dfer Durst", "tokens": ["Ein", "J\u00fcng\u00b7ling", ",", "den", "des", "Wis\u00b7sens", "hei\u00b7\u00dfer", "Durst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nach Sais in \u00c4gypten trieb, der Priester", "tokens": ["Nach", "Sais", "in", "\u00c4\u00b7gyp\u00b7ten", "trieb", ",", "der", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "APPR", "NN", "VVFIN", "$,", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geheime Weisheit zu erlernen, hatte", "tokens": ["Ge\u00b7hei\u00b7me", "Weis\u00b7heit", "zu", "er\u00b7ler\u00b7nen", ",", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$,", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon manchen Grad mit schnellem Geist durcheilt,", "tokens": ["Schon", "man\u00b7chen", "Grad", "mit", "schnel\u00b7lem", "Geist", "durch\u00b7eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Stets ri\u00df ihn seine Forschbegierde weiter,", "tokens": ["Stets", "ri\u00df", "ihn", "sei\u00b7ne", "Forschbe\u00b7gier\u00b7de", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und kaum bes\u00e4nftigte der Hierophant", "tokens": ["Und", "kaum", "be\u00b7s\u00e4nf\u00b7tig\u00b7te", "der", "Hie\u00b7ro\u00b7phant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Den ungeduldig Strebenden. \u00bbWas hab ich,", "tokens": ["Den", "un\u00b7ge\u00b7dul\u00b7dig", "Stre\u00b7ben\u00b7den", ".", "\u00bb", "Was", "hab", "ich", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$.", "$(", "PWS", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wenn ich nicht alles habe?\u00ab sprach der J\u00fcngling.", "tokens": ["Wenn", "ich", "nicht", "al\u00b7les", "ha\u00b7be", "?", "\u00ab", "sprach", "der", "J\u00fcng\u00b7ling", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PIS", "VAFIN", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbgibts etwa hier ein Weniger und Mehr?", "tokens": ["\u00bb", "gibts", "et\u00b7wa", "hier", "ein", "We\u00b7ni\u00b7ger", "und", "Mehr", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ist deine Wahrheit wie der Sinne Gl\u00fcck", "tokens": ["Ist", "dei\u00b7ne", "Wahr\u00b7heit", "wie", "der", "Sin\u00b7ne", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Nur eine Summe, die man gr\u00f6\u00dfer, kleiner", "tokens": ["Nur", "ei\u00b7ne", "Sum\u00b7me", ",", "die", "man", "gr\u00f6\u00b7\u00dfer", ",", "klei\u00b7ner"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PIS", "ADJD", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Besitzen kann und immer doch besitzt?", "tokens": ["Be\u00b7sit\u00b7zen", "kann", "und", "im\u00b7mer", "doch", "be\u00b7sitzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ist sie nicht eine einzge, ungeteilte?", "tokens": ["Ist", "sie", "nicht", "ei\u00b7ne", "einz\u00b7ge", ",", "un\u00b7ge\u00b7teil\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "$,", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Nimm einen Ton aus einer Harmonie,", "tokens": ["Nimm", "ei\u00b7nen", "Ton", "aus", "ei\u00b7ner", "Har\u00b7mo\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Nimm eine Farbe aus dem Regenbogen,", "tokens": ["Nimm", "ei\u00b7ne", "Far\u00b7be", "aus", "dem", "Re\u00b7gen\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und alles, was dir bleibt, ist nichts, solang", "tokens": ["Und", "al\u00b7les", ",", "was", "dir", "bleibt", ",", "ist", "nichts", ",", "so\u00b7lang"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "PIS", "$,", "XY"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Das sch\u00f6ne All der T\u00f6ne fehlt und Farben.\u00ab", "tokens": ["Das", "sch\u00f6\u00b7ne", "All", "der", "T\u00f6\u00b7ne", "fehlt", "und", "Far\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Indem sie einst so sprachen, standen sie", "tokens": ["In\u00b7dem", "sie", "einst", "so", "spra\u00b7chen", ",", "stan\u00b7den", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In einer einsamen Rotonde still,", "tokens": ["In", "ei\u00b7ner", "ein\u00b7sa\u00b7men", "Ro\u00b7ton\u00b7de", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo ein verschleiert Bild von Riesengr\u00f6\u00dfe", "tokens": ["Wo", "ein", "ver\u00b7schlei\u00b7ert", "Bild", "von", "Rie\u00b7sen\u00b7gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "VVPP", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem J\u00fcngling in die Augen fiel. Verwundert", "tokens": ["Dem", "J\u00fcng\u00b7ling", "in", "die", "Au\u00b7gen", "fiel", ".", "Ver\u00b7wun\u00b7dert"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Blickt er den F\u00fchrer an und spricht: \u00bbWas ists,", "tokens": ["Blickt", "er", "den", "F\u00fch\u00b7rer", "an", "und", "spricht", ":", "\u00bb", "Was", "ists", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "PWS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das hinter diesem Schleier sich verbirgt?\u00ab", "tokens": ["Das", "hin\u00b7ter", "die\u00b7sem", "Schlei\u00b7er", "sich", "ver\u00b7birgt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "APPR", "PDAT", "NN", "PRF", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbdie Wahrheit\u00ab, ist die Antwort. \u2013 \u00bbWie?\u00ab ruft jener,", "tokens": ["\u00bb", "die", "Wahr\u00b7heit", "\u00ab", ",", "ist", "die", "Ant\u00b7wort", ".", "\u2013", "\u00bb", "Wie", "?", "\u00ab", "ruft", "je\u00b7ner", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$,", "VAFIN", "ART", "NN", "$.", "$(", "$(", "PWAV", "$.", "$(", "VVFIN", "PDS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbnach Wahrheit streb ich ja allein, und diese", "tokens": ["\u00bb", "nach", "Wahr\u00b7heit", "streb", "ich", "ja", "al\u00b7lein", ",", "und", "die\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "APPR", "NN", "VVFIN", "PPER", "ADV", "ADV", "$,", "KON", "PDS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Gerade ist es, die man mir verh\u00fcllt?\u00ab", "tokens": ["Ge\u00b7ra\u00b7de", "ist", "es", ",", "die", "man", "mir", "ver\u00b7h\u00fcllt", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PRELS", "PIS", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "\u00bbdas mache mit der Gottheit aus\u00ab, versetzt", "tokens": ["\u00bb", "das", "ma\u00b7che", "mit", "der", "Got\u00b7theit", "aus", "\u00ab", ",", "ver\u00b7setzt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PDS", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$(", "$,", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Hierophant. \u00bbKein Sterblicher, sagt sie,", "tokens": ["Der", "Hie\u00b7ro\u00b7phant", ".", "\u00bb", "Kein", "Sterb\u00b7li\u00b7cher", ",", "sagt", "sie", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "R\u00fcckt diesen Schleier, bis ich selbst ihn hebe.", "tokens": ["R\u00fcckt", "die\u00b7sen", "Schlei\u00b7er", ",", "bis", "ich", "selbst", "ihn", "he\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$,", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wer mit ungeweihter, schuldger Hand", "tokens": ["Und", "wer", "mit", "un\u00b7ge\u00b7weih\u00b7ter", ",", "schuld\u00b7ger", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Den heiligen, verbotnen fr\u00fcher hebt,", "tokens": ["Den", "hei\u00b7li\u00b7gen", ",", "ver\u00b7bot\u00b7nen", "fr\u00fc\u00b7her", "hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der, spricht die Gottheit \u2013\u00ab \u2013", "tokens": ["Der", ",", "spricht", "die", "Got\u00b7theit", "\u2013", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "$,", "VVFIN", "ART", "NN", "$(", "$(", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "\u00bbnun?\u00ab \u2013 \u00bbDer ", "tokens": ["\u00bb", "nun", "?", "\u00ab", "\u2013", "\u00bb", "Der"], "token_info": ["punct", "word", "punct", "punct", "punct", "punct", "word"], "pos": ["$(", "ADV", "$.", "$(", "$(", "$(", "ART"], "meter": "-+", "measure": "iambic.single"}}, "stanza.4": {"line.1": {"text": "\u00bbein seltsamer Orakelspruch! Du selbst,", "tokens": ["\u00bb", "ein", "selt\u00b7sa\u00b7mer", "O\u00b7ra\u00b7kel\u00b7spruch", "!", "Du", "selbst", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du h\u00e4ttest also niemals ihn gehoben?\u00ab", "tokens": ["Du", "h\u00e4t\u00b7test", "al\u00b7so", "nie\u00b7mals", "ihn", "ge\u00b7ho\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbich? Wahrlich nicht! Und war auch nie dazu", "tokens": ["\u00bb", "ich", "?", "Wahr\u00b7lich", "nicht", "!", "Und", "war", "auch", "nie", "da\u00b7zu"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "$.", "ADV", "PTKNEG", "$.", "KON", "VAFIN", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Versucht.\u00ab \u2013 \u00bbDas fass ich nicht. Wenn von der Wahrheit", "tokens": ["Ver\u00b7sucht", ".", "\u00ab", "\u2013", "\u00bb", "Das", "fass", "ich", "nicht", ".", "Wenn", "von", "der", "Wahr\u00b7heit"], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "$(", "$(", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "$.", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nur diese d\u00fcnne Scheidewand mich trennte \u2013\u00ab", "tokens": ["Nur", "die\u00b7se", "d\u00fcn\u00b7ne", "Schei\u00b7de\u00b7wand", "mich", "trenn\u00b7te", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "PPER", "VVFIN", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "\u00bbund ein Gesetz\u00ab, f\u00e4llt ihm sein F\u00fchrer ein.", "tokens": ["\u00bb", "und", "ein", "Ge\u00b7setz", "\u00ab", ",", "f\u00e4llt", "ihm", "sein", "F\u00fch\u00b7rer", "ein", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ART", "NN", "$(", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbgewichtiger, mein Sohn, als du es meinst,", "tokens": ["\u00bb", "ge\u00b7wich\u00b7ti\u00b7ger", ",", "mein", "Sohn", ",", "als", "du", "es", "meinst", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ist dieser d\u00fcnne Flor \u2013 f\u00fcr deine Hand", "tokens": ["Ist", "die\u00b7ser", "d\u00fcn\u00b7ne", "Flor", "\u2013", "f\u00fcr", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Zwar leicht, doch zentnerschwer f\u00fcr dein Gewissen.\u00ab", "tokens": ["Zwar", "leicht", ",", "doch", "zent\u00b7ner\u00b7schwer", "f\u00fcr", "dein", "Ge\u00b7wis\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der J\u00fcngling ging gedankenvoll nach Hause.", "tokens": ["Der", "J\u00fcng\u00b7ling", "ging", "ge\u00b7dan\u00b7ken\u00b7voll", "nach", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihm raubt des Wissens brennende Begier", "tokens": ["Ihm", "raubt", "des", "Wis\u00b7sens", "bren\u00b7nen\u00b7de", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Schlaf, er w\u00e4lzt sich gl\u00fchend auf dem Lager", "tokens": ["Den", "Schlaf", ",", "er", "w\u00e4lzt", "sich", "gl\u00fc\u00b7hend", "auf", "dem", "La\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und rafft sich auf um Mitternacht. Zum Tempel", "tokens": ["Und", "rafft", "sich", "auf", "um", "Mit\u00b7ter\u00b7nacht", ".", "Zum", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPR", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fchrt unfreiwillig ihn der scheue Tritt.", "tokens": ["F\u00fchrt", "un\u00b7frei\u00b7wil\u00b7lig", "ihn", "der", "scheu\u00b7e", "Tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Leicht ward es ihm, die Mauer zu ersteigen,", "tokens": ["Leicht", "ward", "es", "ihm", ",", "die", "Mau\u00b7er", "zu", "er\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und mitten in das Innre der Rotonde", "tokens": ["Und", "mit\u00b7ten", "in", "das", "Inn\u00b7re", "der", "Ro\u00b7ton\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Tr\u00e4gt ein beherzter Sprung den Wagenden.", "tokens": ["Tr\u00e4gt", "ein", "be\u00b7herz\u00b7ter", "Sprung", "den", "Wa\u00b7gen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.6": {"line.1": {"text": "Hier steht er nun, und grauenvoll umf\u00e4ngt", "tokens": ["Hier", "steht", "er", "nun", ",", "und", "grau\u00b7en\u00b7voll", "um\u00b7f\u00e4ngt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Einsamen die lebenlose Stille,", "tokens": ["Den", "Ein\u00b7sa\u00b7men", "die", "le\u00b7ben\u00b7lo\u00b7se", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die nur der Tritte hohler Widerhall", "tokens": ["Die", "nur", "der", "Trit\u00b7te", "hoh\u00b7ler", "Wi\u00b7der\u00b7hall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In den geheimen Gr\u00fcften unterbricht.", "tokens": ["In", "den", "ge\u00b7hei\u00b7men", "Gr\u00fcf\u00b7ten", "un\u00b7ter\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von oben durch der Kuppel \u00d6ffnung wirft", "tokens": ["Von", "o\u00b7ben", "durch", "der", "Kup\u00b7pel", "\u00d6ff\u00b7nung", "wirft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der Mond den bleichen, silberblauen Schein,", "tokens": ["Der", "Mond", "den", "blei\u00b7chen", ",", "sil\u00b7ber\u00b7blau\u00b7en", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und furchtbar wie ein gegenw\u00e4rtger Gott", "tokens": ["Und", "furcht\u00b7bar", "wie", "ein", "ge\u00b7gen\u00b7w\u00e4rt\u00b7ger", "Gott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ergl\u00e4nzt durch des Gew\u00f6lbes Finsternisse", "tokens": ["Er\u00b7gl\u00e4nzt", "durch", "des", "Ge\u00b7w\u00f6l\u00b7bes", "Fins\u00b7ter\u00b7nis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "In ihrem langen Schleier die Gestalt.", "tokens": ["In", "ih\u00b7rem", "lan\u00b7gen", "Schlei\u00b7er", "die", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Er tritt hinan mit ungewissem Schritt,", "tokens": ["Er", "tritt", "hi\u00b7nan", "mit", "un\u00b7ge\u00b7wis\u00b7sem", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Schon will die freche Hand das Heilige ber\u00fchren,", "tokens": ["Schon", "will", "die", "fre\u00b7che", "Hand", "das", "Hei\u00b7li\u00b7ge", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da zuckt es hei\u00df und k\u00fchl durch sein Gebein", "tokens": ["Da", "zuckt", "es", "hei\u00df", "und", "k\u00fchl", "durch", "sein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und st\u00f6\u00dft ihn weg mit unsichtbarem Arme.", "tokens": ["Und", "st\u00f6\u00dft", "ihn", "weg", "mit", "un\u00b7sicht\u00b7ba\u00b7rem", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ungl\u00fccklicher, was willst du tun? So ruft", "tokens": ["Un\u00b7gl\u00fcck\u00b7li\u00b7cher", ",", "was", "willst", "du", "tun", "?", "So", "ruft"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In seinem Innern eine treue Stimme.", "tokens": ["In", "sei\u00b7nem", "In\u00b7nern", "ei\u00b7ne", "treu\u00b7e", "Stim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Versuchen den Allheiligen willst du?", "tokens": ["Ver\u00b7su\u00b7chen", "den", "All\u00b7hei\u00b7li\u00b7gen", "willst", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VMFIN", "PPER", "$."], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Kein Sterblicher, sprach des Orakels Mund,", "tokens": ["Kein", "Sterb\u00b7li\u00b7cher", ",", "sprach", "des", "O\u00b7ra\u00b7kels", "Mund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "R\u00fcckt diesen Schleier, bis ich selbst ihn hebe.", "tokens": ["R\u00fcckt", "die\u00b7sen", "Schlei\u00b7er", ",", "bis", "ich", "selbst", "ihn", "he\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$,", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Doch setzte nicht derselbe Mund hinzu:", "tokens": ["Doch", "setz\u00b7te", "nicht", "der\u00b7sel\u00b7be", "Mund", "hin\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wer diesen Schleier hebt, soll Wahrheit schauen?", "tokens": ["Wer", "die\u00b7sen", "Schlei\u00b7er", "hebt", ",", "soll", "Wahr\u00b7heit", "schau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbsei hinter ihm, was will! Ich heb ihn auf.\u00ab", "tokens": ["\u00bb", "sei", "hin\u00b7ter", "ihm", ",", "was", "will", "!", "Ich", "heb", "ihn", "auf", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "APPR", "PPER", "$,", "PWS", "VMFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "(er rufts mit lauter Stimm.) \u00bbIch will sie schauen.\u00ab Schauen!", "tokens": ["(", "er", "rufts", "mit", "lau\u00b7ter", "Stimm", ".", ")", "\u00bb", "Ich", "will", "sie", "schau\u00b7en", ".", "\u00ab", "Schau\u00b7en", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "$(", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gellt ihm ein langes Echo spottend nach.", "tokens": ["Gellt", "ihm", "ein", "lan\u00b7ges", "E\u00b7cho", "spot\u00b7tend", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Er sprichts und hat den Schleier aufgedeckt.", "tokens": ["Er", "sprichts", "und", "hat", "den", "Schlei\u00b7er", "auf\u00b7ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nun, fragt ihr, und was zeigte sich ihm hier?", "tokens": ["Nun", ",", "fragt", "ihr", ",", "und", "was", "zeig\u00b7te", "sich", "ihm", "hier", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KON", "PWS", "VVFIN", "PRF", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich wei\u00df es nicht. Besinnungslos und bleich,", "tokens": ["Ich", "wei\u00df", "es", "nicht", ".", "Be\u00b7sin\u00b7nungs\u00b7los", "und", "bleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So fanden ihn am andern Tag die Priester", "tokens": ["So", "fan\u00b7den", "ihn", "am", "an\u00b7dern", "Tag", "die", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Am Fu\u00dfgestell der Isis ausgestreckt.", "tokens": ["Am", "Fu\u00df\u00b7ge\u00b7stell", "der", "I\u00b7sis", "aus\u00b7ge\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was er allda gesehen und erfahren,", "tokens": ["Was", "er", "all\u00b7da", "ge\u00b7se\u00b7hen", "und", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VVPP", "KON", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Hat seine Zunge nie bekannt. Auf ewig", "tokens": ["Hat", "sei\u00b7ne", "Zun\u00b7ge", "nie", "be\u00b7kannt", ".", "Auf", "e\u00b7wig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "APPR", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "War seines Lebens Heiterkeit dahin,", "tokens": ["War", "sei\u00b7nes", "Le\u00b7bens", "Hei\u00b7ter\u00b7keit", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ihn ri\u00df ein tiefer Gram zum fr\u00fchen Grabe.", "tokens": ["Ihn", "ri\u00df", "ein", "tie\u00b7fer", "Gram", "zum", "fr\u00fc\u00b7hen", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbweh dem\u00ab, dies war sein warnungsvolles Wort,", "tokens": ["\u00bb", "weh", "dem", "\u00ab", ",", "dies", "war", "sein", "war\u00b7nungs\u00b7vol\u00b7les", "Wort", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "$(", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wenn ungest\u00fcme Frager in ihn drangen,", "tokens": ["Wenn", "un\u00b7ge\u00b7st\u00fc\u00b7me", "Fra\u00b7ger", "in", "ihn", "dran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbweh dem, der zu der Wahrheit geht durch Schuld,", "tokens": ["\u00bb", "weh", "dem", ",", "der", "zu", "der", "Wahr\u00b7heit", "geht", "durch", "Schuld", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sie wird ihm nimmermehr erfreulich sein.\u00ab", "tokens": ["Sie", "wird", "ihm", "nim\u00b7mer\u00b7mehr", "er\u00b7freu\u00b7lich", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Ein J\u00fcngling, den des Wissens hei\u00dfer Durst", "tokens": ["Ein", "J\u00fcng\u00b7ling", ",", "den", "des", "Wis\u00b7sens", "hei\u00b7\u00dfer", "Durst"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nach Sais in \u00c4gypten trieb, der Priester", "tokens": ["Nach", "Sais", "in", "\u00c4\u00b7gyp\u00b7ten", "trieb", ",", "der", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "APPR", "NN", "VVFIN", "$,", "ART", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Geheime Weisheit zu erlernen, hatte", "tokens": ["Ge\u00b7hei\u00b7me", "Weis\u00b7heit", "zu", "er\u00b7ler\u00b7nen", ",", "hat\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADJA", "NN", "PTKZU", "VVINF", "$,", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Schon manchen Grad mit schnellem Geist durcheilt,", "tokens": ["Schon", "man\u00b7chen", "Grad", "mit", "schnel\u00b7lem", "Geist", "durch\u00b7eilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Stets ri\u00df ihn seine Forschbegierde weiter,", "tokens": ["Stets", "ri\u00df", "ihn", "sei\u00b7ne", "Forschbe\u00b7gier\u00b7de", "wei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und kaum bes\u00e4nftigte der Hierophant", "tokens": ["Und", "kaum", "be\u00b7s\u00e4nf\u00b7tig\u00b7te", "der", "Hie\u00b7ro\u00b7phant"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Den ungeduldig Strebenden. \u00bbWas hab ich,", "tokens": ["Den", "un\u00b7ge\u00b7dul\u00b7dig", "Stre\u00b7ben\u00b7den", ".", "\u00bb", "Was", "hab", "ich", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$.", "$(", "PWS", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wenn ich nicht alles habe?\u00ab sprach der J\u00fcngling.", "tokens": ["Wenn", "ich", "nicht", "al\u00b7les", "ha\u00b7be", "?", "\u00ab", "sprach", "der", "J\u00fcng\u00b7ling", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PIS", "VAFIN", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbgibts etwa hier ein Weniger und Mehr?", "tokens": ["\u00bb", "gibts", "et\u00b7wa", "hier", "ein", "We\u00b7ni\u00b7ger", "und", "Mehr", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "ADV", "ADV", "ART", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ist deine Wahrheit wie der Sinne Gl\u00fcck", "tokens": ["Ist", "dei\u00b7ne", "Wahr\u00b7heit", "wie", "der", "Sin\u00b7ne", "Gl\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "KOKOM", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Nur eine Summe, die man gr\u00f6\u00dfer, kleiner", "tokens": ["Nur", "ei\u00b7ne", "Sum\u00b7me", ",", "die", "man", "gr\u00f6\u00b7\u00dfer", ",", "klei\u00b7ner"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PIS", "ADJD", "$,", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Besitzen kann und immer doch besitzt?", "tokens": ["Be\u00b7sit\u00b7zen", "kann", "und", "im\u00b7mer", "doch", "be\u00b7sitzt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "KON", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Ist sie nicht eine einzge, ungeteilte?", "tokens": ["Ist", "sie", "nicht", "ei\u00b7ne", "einz\u00b7ge", ",", "un\u00b7ge\u00b7teil\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ART", "ADJA", "$,", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Nimm einen Ton aus einer Harmonie,", "tokens": ["Nimm", "ei\u00b7nen", "Ton", "aus", "ei\u00b7ner", "Har\u00b7mo\u00b7nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Nimm eine Farbe aus dem Regenbogen,", "tokens": ["Nimm", "ei\u00b7ne", "Far\u00b7be", "aus", "dem", "Re\u00b7gen\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Und alles, was dir bleibt, ist nichts, solang", "tokens": ["Und", "al\u00b7les", ",", "was", "dir", "bleibt", ",", "ist", "nichts", ",", "so\u00b7lang"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "PIS", "$,", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "PIS", "$,", "XY"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Das sch\u00f6ne All der T\u00f6ne fehlt und Farben.\u00ab", "tokens": ["Das", "sch\u00f6\u00b7ne", "All", "der", "T\u00f6\u00b7ne", "fehlt", "und", "Far\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Indem sie einst so sprachen, standen sie", "tokens": ["In\u00b7dem", "sie", "einst", "so", "spra\u00b7chen", ",", "stan\u00b7den", "sie"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVFIN", "$,", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "In einer einsamen Rotonde still,", "tokens": ["In", "ei\u00b7ner", "ein\u00b7sa\u00b7men", "Ro\u00b7ton\u00b7de", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wo ein verschleiert Bild von Riesengr\u00f6\u00dfe", "tokens": ["Wo", "ein", "ver\u00b7schlei\u00b7ert", "Bild", "von", "Rie\u00b7sen\u00b7gr\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "VVPP", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem J\u00fcngling in die Augen fiel. Verwundert", "tokens": ["Dem", "J\u00fcng\u00b7ling", "in", "die", "Au\u00b7gen", "fiel", ".", "Ver\u00b7wun\u00b7dert"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$.", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Blickt er den F\u00fchrer an und spricht: \u00bbWas ists,", "tokens": ["Blickt", "er", "den", "F\u00fch\u00b7rer", "an", "und", "spricht", ":", "\u00bb", "Was", "ists", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "PWS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Das hinter diesem Schleier sich verbirgt?\u00ab", "tokens": ["Das", "hin\u00b7ter", "die\u00b7sem", "Schlei\u00b7er", "sich", "ver\u00b7birgt", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "APPR", "PDAT", "NN", "PRF", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbdie Wahrheit\u00ab, ist die Antwort. \u2013 \u00bbWie?\u00ab ruft jener,", "tokens": ["\u00bb", "die", "Wahr\u00b7heit", "\u00ab", ",", "ist", "die", "Ant\u00b7wort", ".", "\u2013", "\u00bb", "Wie", "?", "\u00ab", "ruft", "je\u00b7ner", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$,", "VAFIN", "ART", "NN", "$.", "$(", "$(", "PWAV", "$.", "$(", "VVFIN", "PDS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "\u00bbnach Wahrheit streb ich ja allein, und diese", "tokens": ["\u00bb", "nach", "Wahr\u00b7heit", "streb", "ich", "ja", "al\u00b7lein", ",", "und", "die\u00b7se"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "APPR", "NN", "VVFIN", "PPER", "ADV", "ADV", "$,", "KON", "PDS"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Gerade ist es, die man mir verh\u00fcllt?\u00ab", "tokens": ["Ge\u00b7ra\u00b7de", "ist", "es", ",", "die", "man", "mir", "ver\u00b7h\u00fcllt", "?", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PRELS", "PIS", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "\u00bbdas mache mit der Gottheit aus\u00ab, versetzt", "tokens": ["\u00bb", "das", "ma\u00b7che", "mit", "der", "Got\u00b7theit", "aus", "\u00ab", ",", "ver\u00b7setzt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word"], "pos": ["$(", "PDS", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$(", "$,", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der Hierophant. \u00bbKein Sterblicher, sagt sie,", "tokens": ["Der", "Hie\u00b7ro\u00b7phant", ".", "\u00bb", "Kein", "Sterb\u00b7li\u00b7cher", ",", "sagt", "sie", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "$(", "PIAT", "NN", "$,", "VVFIN", "PPER", "$,"], "meter": "--+--+--+-", "measure": "anapaest.tri.plus"}, "line.3": {"text": "R\u00fcckt diesen Schleier, bis ich selbst ihn hebe.", "tokens": ["R\u00fcckt", "die\u00b7sen", "Schlei\u00b7er", ",", "bis", "ich", "selbst", "ihn", "he\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$,", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und wer mit ungeweihter, schuldger Hand", "tokens": ["Und", "wer", "mit", "un\u00b7ge\u00b7weih\u00b7ter", ",", "schuld\u00b7ger", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "PWS", "APPR", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Den heiligen, verbotnen fr\u00fcher hebt,", "tokens": ["Den", "hei\u00b7li\u00b7gen", ",", "ver\u00b7bot\u00b7nen", "fr\u00fc\u00b7her", "hebt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der, spricht die Gottheit \u2013\u00ab \u2013", "tokens": ["Der", ",", "spricht", "die", "Got\u00b7theit", "\u2013", "\u00ab", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "$,", "VVFIN", "ART", "NN", "$(", "$(", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "\u00bbnun?\u00ab \u2013 \u00bbDer ", "tokens": ["\u00bb", "nun", "?", "\u00ab", "\u2013", "\u00bb", "Der"], "token_info": ["punct", "word", "punct", "punct", "punct", "punct", "word"], "pos": ["$(", "ADV", "$.", "$(", "$(", "$(", "ART"], "meter": "-+", "measure": "iambic.single"}}, "stanza.12": {"line.1": {"text": "\u00bbein seltsamer Orakelspruch! Du selbst,", "tokens": ["\u00bb", "ein", "selt\u00b7sa\u00b7mer", "O\u00b7ra\u00b7kel\u00b7spruch", "!", "Du", "selbst", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$.", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du h\u00e4ttest also niemals ihn gehoben?\u00ab", "tokens": ["Du", "h\u00e4t\u00b7test", "al\u00b7so", "nie\u00b7mals", "ihn", "ge\u00b7ho\u00b7ben", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PPER", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbich? Wahrlich nicht! Und war auch nie dazu", "tokens": ["\u00bb", "ich", "?", "Wahr\u00b7lich", "nicht", "!", "Und", "war", "auch", "nie", "da\u00b7zu"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "$.", "ADV", "PTKNEG", "$.", "KON", "VAFIN", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Versucht.\u00ab \u2013 \u00bbDas fass ich nicht. Wenn von der Wahrheit", "tokens": ["Ver\u00b7sucht", ".", "\u00ab", "\u2013", "\u00bb", "Das", "fass", "ich", "nicht", ".", "Wenn", "von", "der", "Wahr\u00b7heit"], "token_info": ["word", "punct", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$.", "$(", "$(", "$(", "PDS", "VVFIN", "PPER", "PTKNEG", "$.", "KOUS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Nur diese d\u00fcnne Scheidewand mich trennte \u2013\u00ab", "tokens": ["Nur", "die\u00b7se", "d\u00fcn\u00b7ne", "Schei\u00b7de\u00b7wand", "mich", "trenn\u00b7te", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PDAT", "ADJA", "NN", "PPER", "VVFIN", "$(", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "\u00bbund ein Gesetz\u00ab, f\u00e4llt ihm sein F\u00fchrer ein.", "tokens": ["\u00bb", "und", "ein", "Ge\u00b7setz", "\u00ab", ",", "f\u00e4llt", "ihm", "sein", "F\u00fch\u00b7rer", "ein", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ART", "NN", "$(", "$,", "VVFIN", "PPER", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbgewichtiger, mein Sohn, als du es meinst,", "tokens": ["\u00bb", "ge\u00b7wich\u00b7ti\u00b7ger", ",", "mein", "Sohn", ",", "als", "du", "es", "meinst", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ist dieser d\u00fcnne Flor \u2013 f\u00fcr deine Hand", "tokens": ["Ist", "die\u00b7ser", "d\u00fcn\u00b7ne", "Flor", "\u2013", "f\u00fcr", "dei\u00b7ne", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDAT", "ADJA", "NN", "$(", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Zwar leicht, doch zentnerschwer f\u00fcr dein Gewissen.\u00ab", "tokens": ["Zwar", "leicht", ",", "doch", "zent\u00b7ner\u00b7schwer", "f\u00fcr", "dein", "Ge\u00b7wis\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Der J\u00fcngling ging gedankenvoll nach Hause.", "tokens": ["Der", "J\u00fcng\u00b7ling", "ging", "ge\u00b7dan\u00b7ken\u00b7voll", "nach", "Hau\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ihm raubt des Wissens brennende Begier", "tokens": ["Ihm", "raubt", "des", "Wis\u00b7sens", "bren\u00b7nen\u00b7de", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Den Schlaf, er w\u00e4lzt sich gl\u00fchend auf dem Lager", "tokens": ["Den", "Schlaf", ",", "er", "w\u00e4lzt", "sich", "gl\u00fc\u00b7hend", "auf", "dem", "La\u00b7ger"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PPER", "VVFIN", "PRF", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und rafft sich auf um Mitternacht. Zum Tempel", "tokens": ["Und", "rafft", "sich", "auf", "um", "Mit\u00b7ter\u00b7nacht", ".", "Zum", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "APPR", "NN", "$.", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "F\u00fchrt unfreiwillig ihn der scheue Tritt.", "tokens": ["F\u00fchrt", "un\u00b7frei\u00b7wil\u00b7lig", "ihn", "der", "scheu\u00b7e", "Tritt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Leicht ward es ihm, die Mauer zu ersteigen,", "tokens": ["Leicht", "ward", "es", "ihm", ",", "die", "Mau\u00b7er", "zu", "er\u00b7stei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "PPER", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und mitten in das Innre der Rotonde", "tokens": ["Und", "mit\u00b7ten", "in", "das", "Inn\u00b7re", "der", "Ro\u00b7ton\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Tr\u00e4gt ein beherzter Sprung den Wagenden.", "tokens": ["Tr\u00e4gt", "ein", "be\u00b7herz\u00b7ter", "Sprung", "den", "Wa\u00b7gen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+--", "measure": "unknown.measure.tetra"}}, "stanza.14": {"line.1": {"text": "Hier steht er nun, und grauenvoll umf\u00e4ngt", "tokens": ["Hier", "steht", "er", "nun", ",", "und", "grau\u00b7en\u00b7voll", "um\u00b7f\u00e4ngt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KON", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Den Einsamen die lebenlose Stille,", "tokens": ["Den", "Ein\u00b7sa\u00b7men", "die", "le\u00b7ben\u00b7lo\u00b7se", "Stil\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die nur der Tritte hohler Widerhall", "tokens": ["Die", "nur", "der", "Trit\u00b7te", "hoh\u00b7ler", "Wi\u00b7der\u00b7hall"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In den geheimen Gr\u00fcften unterbricht.", "tokens": ["In", "den", "ge\u00b7hei\u00b7men", "Gr\u00fcf\u00b7ten", "un\u00b7ter\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Von oben durch der Kuppel \u00d6ffnung wirft", "tokens": ["Von", "o\u00b7ben", "durch", "der", "Kup\u00b7pel", "\u00d6ff\u00b7nung", "wirft"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "APPR", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der Mond den bleichen, silberblauen Schein,", "tokens": ["Der", "Mond", "den", "blei\u00b7chen", ",", "sil\u00b7ber\u00b7blau\u00b7en", "Schein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und furchtbar wie ein gegenw\u00e4rtger Gott", "tokens": ["Und", "furcht\u00b7bar", "wie", "ein", "ge\u00b7gen\u00b7w\u00e4rt\u00b7ger", "Gott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ergl\u00e4nzt durch des Gew\u00f6lbes Finsternisse", "tokens": ["Er\u00b7gl\u00e4nzt", "durch", "des", "Ge\u00b7w\u00f6l\u00b7bes", "Fins\u00b7ter\u00b7nis\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "In ihrem langen Schleier die Gestalt.", "tokens": ["In", "ih\u00b7rem", "lan\u00b7gen", "Schlei\u00b7er", "die", "Ge\u00b7stalt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Er tritt hinan mit ungewissem Schritt,", "tokens": ["Er", "tritt", "hi\u00b7nan", "mit", "un\u00b7ge\u00b7wis\u00b7sem", "Schritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Schon will die freche Hand das Heilige ber\u00fchren,", "tokens": ["Schon", "will", "die", "fre\u00b7che", "Hand", "das", "Hei\u00b7li\u00b7ge", "be\u00b7r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da zuckt es hei\u00df und k\u00fchl durch sein Gebein", "tokens": ["Da", "zuckt", "es", "hei\u00df", "und", "k\u00fchl", "durch", "sein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und st\u00f6\u00dft ihn weg mit unsichtbarem Arme.", "tokens": ["Und", "st\u00f6\u00dft", "ihn", "weg", "mit", "un\u00b7sicht\u00b7ba\u00b7rem", "Ar\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ungl\u00fccklicher, was willst du tun? So ruft", "tokens": ["Un\u00b7gl\u00fcck\u00b7li\u00b7cher", ",", "was", "willst", "du", "tun", "?", "So", "ruft"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$.", "ADV", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "In seinem Innern eine treue Stimme.", "tokens": ["In", "sei\u00b7nem", "In\u00b7nern", "ei\u00b7ne", "treu\u00b7e", "Stim\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Versuchen den Allheiligen willst du?", "tokens": ["Ver\u00b7su\u00b7chen", "den", "All\u00b7hei\u00b7li\u00b7gen", "willst", "du", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VMFIN", "PPER", "$."], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Kein Sterblicher, sprach des Orakels Mund,", "tokens": ["Kein", "Sterb\u00b7li\u00b7cher", ",", "sprach", "des", "O\u00b7ra\u00b7kels", "Mund", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "R\u00fcckt diesen Schleier, bis ich selbst ihn hebe.", "tokens": ["R\u00fcckt", "die\u00b7sen", "Schlei\u00b7er", ",", "bis", "ich", "selbst", "ihn", "he\u00b7be", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDAT", "NN", "$,", "KOUS", "PPER", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Doch setzte nicht derselbe Mund hinzu:", "tokens": ["Doch", "setz\u00b7te", "nicht", "der\u00b7sel\u00b7be", "Mund", "hin\u00b7zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wer diesen Schleier hebt, soll Wahrheit schauen?", "tokens": ["Wer", "die\u00b7sen", "Schlei\u00b7er", "hebt", ",", "soll", "Wahr\u00b7heit", "schau\u00b7en", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbsei hinter ihm, was will! Ich heb ihn auf.\u00ab", "tokens": ["\u00bb", "sei", "hin\u00b7ter", "ihm", ",", "was", "will", "!", "Ich", "heb", "ihn", "auf", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VAFIN", "APPR", "PPER", "$,", "PWS", "VMFIN", "$.", "PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "(er rufts mit lauter Stimm.) \u00bbIch will sie schauen.\u00ab Schauen!", "tokens": ["(", "er", "rufts", "mit", "lau\u00b7ter", "Stimm", ".", ")", "\u00bb", "Ich", "will", "sie", "schau\u00b7en", ".", "\u00ab", "Schau\u00b7en", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "APPR", "PIAT", "NN", "$.", "$(", "$(", "PPER", "VMFIN", "PPER", "VVINF", "$.", "$(", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gellt ihm ein langes Echo spottend nach.", "tokens": ["Gellt", "ihm", "ein", "lan\u00b7ges", "E\u00b7cho", "spot\u00b7tend", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Er sprichts und hat den Schleier aufgedeckt.", "tokens": ["Er", "sprichts", "und", "hat", "den", "Schlei\u00b7er", "auf\u00b7ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nun, fragt ihr, und was zeigte sich ihm hier?", "tokens": ["Nun", ",", "fragt", "ihr", ",", "und", "was", "zeig\u00b7te", "sich", "ihm", "hier", "?"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "$,", "KON", "PWS", "VVFIN", "PRF", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ich wei\u00df es nicht. Besinnungslos und bleich,", "tokens": ["Ich", "wei\u00df", "es", "nicht", ".", "Be\u00b7sin\u00b7nungs\u00b7los", "und", "bleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "$.", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So fanden ihn am andern Tag die Priester", "tokens": ["So", "fan\u00b7den", "ihn", "am", "an\u00b7dern", "Tag", "die", "Pries\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Am Fu\u00dfgestell der Isis ausgestreckt.", "tokens": ["Am", "Fu\u00df\u00b7ge\u00b7stell", "der", "I\u00b7sis", "aus\u00b7ge\u00b7streckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Was er allda gesehen und erfahren,", "tokens": ["Was", "er", "all\u00b7da", "ge\u00b7se\u00b7hen", "und", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PAV", "VVPP", "KON", "VVINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.7": {"text": "Hat seine Zunge nie bekannt. Auf ewig", "tokens": ["Hat", "sei\u00b7ne", "Zun\u00b7ge", "nie", "be\u00b7kannt", ".", "Auf", "e\u00b7wig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADJD", "$.", "APPR", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "War seines Lebens Heiterkeit dahin,", "tokens": ["War", "sei\u00b7nes", "Le\u00b7bens", "Hei\u00b7ter\u00b7keit", "da\u00b7hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Ihn ri\u00df ein tiefer Gram zum fr\u00fchen Grabe.", "tokens": ["Ihn", "ri\u00df", "ein", "tie\u00b7fer", "Gram", "zum", "fr\u00fc\u00b7hen", "Gra\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbweh dem\u00ab, dies war sein warnungsvolles Wort,", "tokens": ["\u00bb", "weh", "dem", "\u00ab", ",", "dies", "war", "sein", "war\u00b7nungs\u00b7vol\u00b7les", "Wort", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "$(", "$,", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wenn ungest\u00fcme Frager in ihn drangen,", "tokens": ["Wenn", "un\u00b7ge\u00b7st\u00fc\u00b7me", "Fra\u00b7ger", "in", "ihn", "dran\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "\u00bbweh dem, der zu der Wahrheit geht durch Schuld,", "tokens": ["\u00bb", "weh", "dem", ",", "der", "zu", "der", "Wahr\u00b7heit", "geht", "durch", "Schuld", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Sie wird ihm nimmermehr erfreulich sein.\u00ab", "tokens": ["Sie", "wird", "ihm", "nim\u00b7mer\u00b7mehr", "er\u00b7freu\u00b7lich", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADJD", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}