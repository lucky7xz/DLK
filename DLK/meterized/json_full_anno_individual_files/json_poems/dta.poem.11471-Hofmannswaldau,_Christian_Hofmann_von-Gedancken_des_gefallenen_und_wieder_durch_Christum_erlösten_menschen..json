{"dta.poem.11471": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Gedancken des gefallenen und wieder  \n durch Christum erl\u00f6sten menschen.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "O Heilige Dreyeinigkeit!", "tokens": ["O", "Hei\u00b7li\u00b7ge", "Drey\u00b7ei\u00b7nig\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie seelig war ich doch, als ich zur g\u00f6ldnen zeit", "tokens": ["Wie", "see\u00b7lig", "war", "ich", "doch", ",", "als", "ich", "zur", "g\u00f6ld\u00b7nen", "zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ADV", "$,", "KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Dein theures ebenbild, so w\u00fcrcklich war, als hie\u00df!", "tokens": ["Dein", "theu\u00b7res", "e\u00b7ben\u00b7bild", ",", "so", "w\u00fcrck\u00b7lich", "war", ",", "als", "hie\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "ADV", "ADJD", "VAFIN", "$,", "KOUS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Da warest du mein gut, mein ruhm, mein paradies.", "tokens": ["Da", "wa\u00b7rest", "du", "mein", "gut", ",", "mein", "ruhm", ",", "mein", "pa\u00b7ra\u00b7dies", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PPOSAT", "ADJD", "$,", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ach aber! ach die goldne zeit", "tokens": ["Ach", "a\u00b7ber", "!", "ach", "die", "gold\u00b7ne", "zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$.", "XY", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward bald zu finstrem bley, als ich der unschuld kleid", "tokens": ["Ward", "bald", "zu", "fins\u00b7trem", "bley", ",", "als", "ich", "der", "un\u00b7schuld", "kleid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So liederlich verschertzt, das wahre gut verflucht,", "tokens": ["So", "lie\u00b7der\u00b7lich", "ver\u00b7schertzt", ",", "das", "wah\u00b7re", "gut", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "$,", "ART", "ADJA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und in des satans hand gut, ehr und lust gesucht.", "tokens": ["Und", "in", "des", "sa\u00b7tans", "hand", "gut", ",", "ehr", "und", "lust", "ge\u00b7sucht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ADJD", "$,", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Da gieng dein ebenbild dahin;", "tokens": ["Da", "gieng", "dein", "e\u00b7ben\u00b7bild", "da\u00b7hin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df ich itzund ein bild der b\u00f6sen schlange bin,", "tokens": ["Da\u00df", "ich", "it\u00b7zund", "ein", "bild", "der", "b\u00f6\u00b7sen", "schlan\u00b7ge", "bin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN", "ART", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weil ich ihr l\u00fcgen-wort der wahrheit vorgesetzt,", "tokens": ["Weil", "ich", "ihr", "l\u00fc\u00b7gen\u00b7wort", "der", "wahr\u00b7heit", "vor\u00b7ge\u00b7setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und den, der alles ist, als lauter nichts gesch\u00e4tzt.", "tokens": ["Und", "den", ",", "der", "al\u00b7les", "ist", ",", "als", "lau\u00b7ter", "nichts", "ge\u00b7sch\u00e4tzt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "PIS", "VAFIN", "$,", "KOUS", "PIAT", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Ach! w\u00e4r ich nichts, ich s\u00fcnden-knecht!", "tokens": ["Ach", "!", "w\u00e4r", "ich", "nichts", ",", "ich", "s\u00fcn\u00b7den\u00b7knecht", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$.", "VAFIN", "PPER", "PIS", "$,", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So w\u00e4r ich, als ein nichts, von dem erz\u00fcrnten recht", "tokens": ["So", "w\u00e4r", "ich", ",", "als", "ein", "nichts", ",", "von", "dem", "er\u00b7z\u00fcrn\u00b7ten", "recht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "ART", "PIS", "$,", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und von dem urtheil frey, das der, so alles ist,", "tokens": ["Und", "von", "dem", "ur\u00b7theil", "frey", ",", "das", "der", ",", "so", "al\u00b7les", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "$,", "ADV", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Jtzt, leider! \u00fcber mich verdammten s\u00fcnder liest.", "tokens": ["Jtzt", ",", "lei\u00b7der", "!", "\u00fc\u00b7ber", "mich", "ver\u00b7damm\u00b7ten", "s\u00fcn\u00b7der", "liest", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$.", "APPR", "PPER", "VVFIN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Werd ich von deinem zorn erw\u00fcrgt?", "tokens": ["Werd", "ich", "von", "dei\u00b7nem", "zorn", "er\u00b7w\u00fcrgt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist nirgends keine klufft, die mich vor dir verbirgt?", "tokens": ["Ist", "nir\u00b7gends", "kei\u00b7ne", "klufft", ",", "die", "mich", "vor", "dir", "ver\u00b7birgt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "$,", "PRELS", "PRF", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ach nein! Dein donner schl\u00e4gt auch in den abgrund ein,", "tokens": ["Ach", "nein", "!", "Dein", "don\u00b7ner", "schl\u00e4gt", "auch", "in", "den", "ab\u00b7grund", "ein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKANT", "$.", "PPOSAT", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wen du treffen wilst, kan nirgend sicher seyn.", "tokens": ["Und", "wen", "du", "tref\u00b7fen", "wilst", ",", "kan", "nir\u00b7gend", "si\u00b7cher", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "VMFIN", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Der grimm hat seinen freyen lauff.", "tokens": ["Der", "grimm", "hat", "sei\u00b7nen", "frey\u00b7en", "lauff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weh mir! wo soll ich hin? Der himmel thut sich auf.", "tokens": ["Weh", "mir", "!", "wo", "soll", "ich", "hin", "?", "Der", "him\u00b7mel", "thut", "sich", "auf", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "PWAV", "VMFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VVFIN", "PRF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Weh mir! nun bin ich hin! Nun mu\u00df ich untergehn!", "tokens": ["Weh", "mir", "!", "nun", "bin", "ich", "hin", "!", "Nun", "mu\u00df", "ich", "un\u00b7ter\u00b7gehn", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "ADV", "VAFIN", "PPER", "PTKVZ", "$.", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Denn welch gesch\u00f6pffe kan vor seinem sch\u00f6pffer stehn?", "tokens": ["Denn", "welch", "ge\u00b7sch\u00f6pf\u00b7fe", "kan", "vor", "sei\u00b7nem", "sch\u00f6pf\u00b7fer", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "VMFIN", "APPR", "PPOSAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Doch irr ich? oder seh ich recht?", "tokens": ["Doch", "irr", "ich", "?", "o\u00b7der", "seh", "ich", "recht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "$.", "KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mich deucht, (o s\u00fcsser blick vor mich verworffnen knecht!)", "tokens": ["Mich", "deucht", ",", "(", "o", "s\u00fcs\u00b7ser", "blick", "vor", "mich", "ver\u00b7worff\u00b7nen", "knecht", "!", ")"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "$(", "FM", "ADJA", "NN", "APPR", "PPER", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Des h\u00f6chsten liebe l\u00e4st den thron des himmels stehn,", "tokens": ["Des", "h\u00f6chs\u00b7ten", "lie\u00b7be", "l\u00e4st", "den", "thron", "des", "him\u00b7mels", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "VVFIN", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und will mir unverhofft mit trost entgegen gehn.", "tokens": ["Und", "will", "mir", "un\u00b7ver\u00b7hofft", "mit", "trost", "ent\u00b7ge\u00b7gen", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "So ist es: GOtt erniedrigt sich,", "tokens": ["So", "ist", "es", ":", "Gott", "er\u00b7nied\u00b7rigt", "sich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$.", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und wird, o wunder-werck! ein armer mensch, wie ich.", "tokens": ["Und", "wird", ",", "o", "wun\u00b7der\u00b7\u00b7werck", "!", "ein", "ar\u00b7mer", "mensch", ",", "wie", "ich", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "FM", "NN", "$.", "ART", "ADJA", "NN", "$,", "PWAV", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Das wort nimmt fleisch und blut in einer jungfrau an:", "tokens": ["Das", "wort", "nimmt", "fleisch", "und", "blut", "in", "ei\u00b7ner", "jung\u00b7frau", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "KON", "NN", "APPR", "ART", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Damit ich durch das wort im geiste leben kan.", "tokens": ["Da\u00b7mit", "ich", "durch", "das", "wort", "im", "geis\u00b7te", "le\u00b7ben", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "APPRART", "ADJA", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "O unvergleichlicher entschlu\u00df!", "tokens": ["O", "un\u00b7ver\u00b7gleich\u00b7li\u00b7cher", "ent\u00b7schlu\u00df", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das leben kommt und stirbt, weil ich sonst sterben mu\u00df.", "tokens": ["Das", "le\u00b7ben", "kommt", "und", "stirbt", ",", "weil", "ich", "sonst", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gott nimmt durch seinen tod dem tode seine macht,", "tokens": ["Gott", "nimmt", "durch", "sei\u00b7nen", "tod", "dem", "to\u00b7de", "sei\u00b7ne", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "ART", "NN", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und st\u00fcrtzt der schlangen wuth, die mich zu fall gebracht.", "tokens": ["Und", "st\u00fcrtzt", "der", "schlan\u00b7gen", "wuth", ",", "die", "mich", "zu", "fall", "ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PRF", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Die unschuld selbst zahlt meine schuld,", "tokens": ["Die", "un\u00b7schuld", "selbst", "zahlt", "mei\u00b7ne", "schuld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPOSAT", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und GOttes eyfer stillt die leidende geduld,", "tokens": ["Und", "Got\u00b7tes", "ey\u00b7fer", "stillt", "die", "lei\u00b7den\u00b7de", "ge\u00b7duld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Den eyfer, den mein fleisch, den meine missethat,", "tokens": ["Den", "ey\u00b7fer", ",", "den", "mein", "fleisch", ",", "den", "mei\u00b7ne", "mis\u00b7se\u00b7that", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "NN", "$,", "PRELS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und mein verruchtes hertz allein entz\u00fcndet hat.", "tokens": ["Und", "mein", "ver\u00b7ruch\u00b7tes", "hertz", "al\u00b7lein", "ent\u00b7z\u00fcn\u00b7det", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Die lust, den ehrgeitz, und den neid,", "tokens": ["Die", "lust", ",", "den", "ehr\u00b7geitz", ",", "und", "den", "neid", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "B\u00fc\u00dft JEsus, der mich liebt durch unverdiente schmach,", "tokens": ["B\u00fc\u00dft", "Je\u00b7sus", ",", "der", "mich", "liebt", "durch", "un\u00b7ver\u00b7dien\u00b7te", "schmach", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PRELS", "PPER", "VVFIN", "APPR", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch strenge d\u00fcrfftigkeit und hartes ungemach.", "tokens": ["Durch", "stren\u00b7ge", "d\u00fcr\u00b7ff\u00b7tig\u00b7keit", "und", "har\u00b7tes", "un\u00b7ge\u00b7mach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Nun schau ich recht, o Heilge Drey!", "tokens": ["Nun", "schau", "ich", "recht", ",", "o", "Heil\u00b7ge", "Drey", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "FM", "FM", "CARD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df deines hertzens grund ein brunn der liebe sey:", "tokens": ["Da\u00df", "dei\u00b7nes", "hert\u00b7zens", "grund", "ein", "brunn", "der", "lie\u00b7be", "sey", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ART", "NN", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem du deinen feind so unaussprechlich liebst,", "tokens": ["In\u00b7dem", "du", "dei\u00b7nen", "feind", "so", "un\u00b7aus\u00b7sprech\u00b7lich", "liebst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dich dem b\u00fcssenden in Christo wiedergiebst.", "tokens": ["Und", "dich", "dem", "b\u00fcs\u00b7sen\u00b7den", "in", "Chris\u00b7to", "wie\u00b7der\u00b7giebst", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "ADJA", "APPR", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Wiewohl ich bleib ein klotz und scheit,", "tokens": ["Wie\u00b7wohl", "ich", "bleib", "ein", "klotz", "und", "scheit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "ART", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo mir dein starcker geist nicht krafft zur busse leiht:", "tokens": ["Wo", "mir", "dein", "star\u00b7cker", "geist", "nicht", "krafft", "zur", "bus\u00b7se", "leiht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "PTKNEG", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Denn satan bildet sich durch hochmuth, geitz und lust", "tokens": ["Denn", "sa\u00b7tan", "bil\u00b7det", "sich", "durch", "hoch\u00b7muth", ",", "geitz", "und", "lust"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PRF", "APPR", "NN", "$,", "VVIMP", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Noch immer, wie zuvor, in meiner offnen brust.", "tokens": ["Noch", "im\u00b7mer", ",", "wie", "zu\u00b7vor", ",", "in", "mei\u00b7ner", "off\u00b7nen", "brust", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PWAV", "ADV", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Drum hilff, da\u00df des erl\u00f6sers geist", "tokens": ["Drum", "hilff", ",", "da\u00df", "des", "er\u00b7l\u00f6\u00b7sers", "geist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PAV", "NN", "$,", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In mir den g\u00f6tzen-bau des teufels niederreist:", "tokens": ["In", "mir", "den", "g\u00f6t\u00b7zen\u00b7bau", "des", "teu\u00b7fels", "nie\u00b7der\u00b7reist", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df ich durch busse, glaub und liebe davon frey,", "tokens": ["Da\u00df", "ich", "durch", "bus\u00b7se", ",", "glaub", "und", "lie\u00b7be", "da\u00b7von", "frey", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "$,", "VVFIN", "KON", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und dir zum ebenbild aufs neu geschaffen sey.", "tokens": ["Und", "dir", "zum", "e\u00b7ben\u00b7bild", "aufs", "neu", "ge\u00b7schaf\u00b7fen", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPRART", "ADV", "APPRART", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}