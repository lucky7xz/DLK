{"textgrid.poem.32814": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Mein Sch\u00e4fer, ach! der ist bescheiden!", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Mein Sch\u00e4fer, ach! der ist bescheiden!", "tokens": ["Mein", "Sch\u00e4\u00b7fer", ",", "ach", "!", "der", "ist", "be\u00b7schei\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ITJ", "$.", "ART", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er liebt mich, z\u00e4rtlich liebt er mich!", "tokens": ["Er", "liebt", "mich", ",", "z\u00e4rt\u00b7lich", "liebt", "er", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADJD", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Innbegriff von seinen Freuden,", "tokens": ["Der", "Inn\u00b7be\u00b7griff", "von", "sei\u00b7nen", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sagt er mir \u00f6fters, sey nur ich:", "tokens": ["Sagt", "er", "mir", "\u00f6f\u00b7ters", ",", "sey", "nur", "ich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "VAFIN", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bleibt er allezeit bescheiden.", "tokens": ["Doch", "bleibt", "er", "al\u00b7le\u00b7zeit", "be\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "J\u00fcngst lie\u00df die Mutter uns alleine;", "tokens": ["J\u00fcngst", "lie\u00df", "die", "Mut\u00b7ter", "uns", "al\u00b7lei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was denkst du, ist alsdenn geschehn?", "tokens": ["Was", "denkst", "du", ",", "ist", "als\u00b7denn", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da stand er starr, gleich einem Steine,", "tokens": ["Da", "stand", "er", "starr", ",", "gleich", "ei\u00b7nem", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Guckt in den Hut, und wolte gehn,", "tokens": ["Guckt", "in", "den", "Hut", ",", "und", "wol\u00b7te", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "KON", "VMFIN", "VVINF", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ach! wir waren ganz alleine!", "tokens": ["Und", "ach", "!", "wir", "wa\u00b7ren", "ganz", "al\u00b7lei\u00b7ne", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Mein Sch\u00e4fer, ach! der ist bescheiden!", "tokens": ["Mein", "Sch\u00e4\u00b7fer", ",", "ach", "!", "der", "ist", "be\u00b7schei\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ITJ", "$.", "ART", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er liebt mich, z\u00e4rtlich liebt er mich!", "tokens": ["Er", "liebt", "mich", ",", "z\u00e4rt\u00b7lich", "liebt", "er", "mich", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ADJD", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Innbegriff von seinen Freuden,", "tokens": ["Der", "Inn\u00b7be\u00b7griff", "von", "sei\u00b7nen", "Freu\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sagt er mir \u00f6fters, sey nur ich:", "tokens": ["Sagt", "er", "mir", "\u00f6f\u00b7ters", ",", "sey", "nur", "ich", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "ADV", "$,", "VAFIN", "ADV", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bleibt er allezeit bescheiden.", "tokens": ["Doch", "bleibt", "er", "al\u00b7le\u00b7zeit", "be\u00b7schei\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "J\u00fcngst lie\u00df die Mutter uns alleine;", "tokens": ["J\u00fcngst", "lie\u00df", "die", "Mut\u00b7ter", "uns", "al\u00b7lei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was denkst du, ist alsdenn geschehn?", "tokens": ["Was", "denkst", "du", ",", "ist", "als\u00b7denn", "ge\u00b7schehn", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da stand er starr, gleich einem Steine,", "tokens": ["Da", "stand", "er", "starr", ",", "gleich", "ei\u00b7nem", "Stei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Guckt in den Hut, und wolte gehn,", "tokens": ["Guckt", "in", "den", "Hut", ",", "und", "wol\u00b7te", "gehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "KON", "VMFIN", "VVINF", "$,"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ach! wir waren ganz alleine!", "tokens": ["Und", "ach", "!", "wir", "wa\u00b7ren", "ganz", "al\u00b7lei\u00b7ne", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "XY", "$.", "PPER", "VAFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}