{"textgrid.poem.47089": {"metadata": {"author": {"name": "R\u00fcckert, Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich w\u00fcnschte, da\u00df du reichlicher gemessen", "genre": "verse", "period": "N.A.", "pub_year": 1827, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich w\u00fcnschte, da\u00df du reichlicher gemessen", "tokens": ["Ich", "w\u00fcnschte", ",", "da\u00df", "du", "reich\u00b7li\u00b7cher", "ge\u00b7mes\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mir h\u00e4ttest einst dein L\u00e4cheln, Gr\u00fc\u00dfen, Blicken,", "tokens": ["Mir", "h\u00e4t\u00b7test", "einst", "dein", "L\u00e4\u00b7cheln", ",", "Gr\u00fc\u00b7\u00dfen", ",", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich mich h\u00e4tte d\u00fcrfen mehr erquicken", "tokens": ["Da\u00df", "ich", "mich", "h\u00e4t\u00b7te", "d\u00fcr\u00b7fen", "mehr", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und mehr mich jetzt erquickt' Erinn'rung dessen.", "tokens": ["Und", "mehr", "mich", "jetzt", "er\u00b7quickt'", "Er\u00b7inn'\u00b7rung", "des\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ADV", "VVFIN", "NN", "PDS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "O nein! ich w\u00fcnschte, da\u00df du ganz vergessen", "tokens": ["O", "nein", "!", "ich", "w\u00fcnschte", ",", "da\u00df", "du", "ganz", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Mich h\u00e4ttest, mir geschenkt kein einzig Nicken;", "tokens": ["Mich", "h\u00e4t\u00b7test", ",", "mir", "ge\u00b7schenkt", "kein", "ein\u00b7zig", "Ni\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVPP", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So w\u00fcrde des Verlustes Weh umstricken", "tokens": ["So", "w\u00fcr\u00b7de", "des", "Ver\u00b7lus\u00b7tes", "Weh", "um\u00b7stri\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mich minder nun, je minder ich besessen.", "tokens": ["Mich", "min\u00b7der", "nun", ",", "je", "min\u00b7der", "ich", "be\u00b7ses\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$,", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Nein, dennoch w\u00fcnscht' ich, da\u00df du mehr begnaden", "tokens": ["Nein", ",", "den\u00b7noch", "w\u00fcnscht'", "ich", ",", "da\u00df", "du", "mehr", "be\u00b7gna\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mich h\u00e4ttest m\u00f6gen mit den s\u00fc\u00dfen Gaben,", "tokens": ["Mich", "h\u00e4t\u00b7test", "m\u00f6\u00b7gen", "mit", "den", "s\u00fc\u00b7\u00dfen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Obwohl sie jetzt mich so mit Weh beladen.", "tokens": ["Ob\u00b7wohl", "sie", "jetzt", "mich", "so", "mit", "Weh", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Ja, w\u00fcnschen m\u00f6cht' ich's nur, um Stoff zu haben,", "tokens": ["Ja", ",", "w\u00fcn\u00b7schen", "m\u00f6cht'", "ich's", "nur", ",", "um", "Stoff", "zu", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVINF", "VMFIN", "PIS", "ADV", "$,", "KOUI", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch mehr f\u00fcr dich in Thr\u00e4nen mich zu baden,", "tokens": ["Noch", "mehr", "f\u00fcr", "dich", "in", "Thr\u00e4\u00b7nen", "mich", "zu", "ba\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch mehr f\u00fcr dich in Schmerz mich zu begraben.", "tokens": ["Noch", "mehr", "f\u00fcr", "dich", "in", "Schmerz", "mich", "zu", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Ich w\u00fcnschte, da\u00df du reichlicher gemessen", "tokens": ["Ich", "w\u00fcnschte", ",", "da\u00df", "du", "reich\u00b7li\u00b7cher", "ge\u00b7mes\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Mir h\u00e4ttest einst dein L\u00e4cheln, Gr\u00fc\u00dfen, Blicken,", "tokens": ["Mir", "h\u00e4t\u00b7test", "einst", "dein", "L\u00e4\u00b7cheln", ",", "Gr\u00fc\u00b7\u00dfen", ",", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PPOSAT", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df ich mich h\u00e4tte d\u00fcrfen mehr erquicken", "tokens": ["Da\u00df", "ich", "mich", "h\u00e4t\u00b7te", "d\u00fcr\u00b7fen", "mehr", "er\u00b7qui\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "VMFIN", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und mehr mich jetzt erquickt' Erinn'rung dessen.", "tokens": ["Und", "mehr", "mich", "jetzt", "er\u00b7quickt'", "Er\u00b7inn'\u00b7rung", "des\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "ADV", "VVFIN", "NN", "PDS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "O nein! ich w\u00fcnschte, da\u00df du ganz vergessen", "tokens": ["O", "nein", "!", "ich", "w\u00fcnschte", ",", "da\u00df", "du", "ganz", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "PTKANT", "$.", "PPER", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVPP"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Mich h\u00e4ttest, mir geschenkt kein einzig Nicken;", "tokens": ["Mich", "h\u00e4t\u00b7test", ",", "mir", "ge\u00b7schenkt", "kein", "ein\u00b7zig", "Ni\u00b7cken", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVPP", "PIAT", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So w\u00fcrde des Verlustes Weh umstricken", "tokens": ["So", "w\u00fcr\u00b7de", "des", "Ver\u00b7lus\u00b7tes", "Weh", "um\u00b7stri\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Mich minder nun, je minder ich besessen.", "tokens": ["Mich", "min\u00b7der", "nun", ",", "je", "min\u00b7der", "ich", "be\u00b7ses\u00b7sen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$,", "ADV", "ADV", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Nein, dennoch w\u00fcnscht' ich, da\u00df du mehr begnaden", "tokens": ["Nein", ",", "den\u00b7noch", "w\u00fcnscht'", "ich", ",", "da\u00df", "du", "mehr", "be\u00b7gna\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mich h\u00e4ttest m\u00f6gen mit den s\u00fc\u00dfen Gaben,", "tokens": ["Mich", "h\u00e4t\u00b7test", "m\u00f6\u00b7gen", "mit", "den", "s\u00fc\u00b7\u00dfen", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VMFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Obwohl sie jetzt mich so mit Weh beladen.", "tokens": ["Ob\u00b7wohl", "sie", "jetzt", "mich", "so", "mit", "Weh", "be\u00b7la\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ja, w\u00fcnschen m\u00f6cht' ich's nur, um Stoff zu haben,", "tokens": ["Ja", ",", "w\u00fcn\u00b7schen", "m\u00f6cht'", "ich's", "nur", ",", "um", "Stoff", "zu", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVINF", "VMFIN", "PIS", "ADV", "$,", "KOUI", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Noch mehr f\u00fcr dich in Thr\u00e4nen mich zu baden,", "tokens": ["Noch", "mehr", "f\u00fcr", "dich", "in", "Thr\u00e4\u00b7nen", "mich", "zu", "ba\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Noch mehr f\u00fcr dich in Schmerz mich zu begraben.", "tokens": ["Noch", "mehr", "f\u00fcr", "dich", "in", "Schmerz", "mich", "zu", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "APPR", "NN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}