{"textgrid.poem.42919": {"metadata": {"author": {"name": "Ringelnatz, Joachim", "birth": "N.A.", "death": "N.A."}, "title": "Zimmerm\u00e4dchen", "genre": "verse", "period": "N.A.", "pub_year": 1908, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Zimmerm\u00e4dchen der Hotels,", "tokens": ["Die", "Zim\u00b7mer\u00b7m\u00e4d\u00b7chen", "der", "Ho\u00b7tels", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die meine Betten schlagen und dann gl\u00e4tten,", "tokens": ["Die", "mei\u00b7ne", "Bet\u00b7ten", "schla\u00b7gen", "und", "dann", "gl\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ach wenn sie doch ein wenig Ahnung h\u00e4tten", "tokens": ["Ach", "wenn", "sie", "doch", "ein", "we\u00b7nig", "Ah\u00b7nung", "h\u00e4t\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "ART", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vom Unterschiede zwischen Polster und Fels.", "tokens": ["Vom", "Un\u00b7ter\u00b7schie\u00b7de", "zwi\u00b7schen", "Pols\u00b7ter", "und", "Fels", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.2": {"line.1": {"text": "Ach w\u00fc\u00dftet ihr, wie s\u00fc\u00df ihr f\u00fcr mich ausseht", "tokens": ["Ach", "w\u00fc\u00df\u00b7tet", "ihr", ",", "wie", "s\u00fc\u00df", "ihr", "f\u00fcr", "mich", "aus\u00b7seht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "VVFIN", "PPER", "$,", "PWAV", "ADJD", "PPER", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Im Arbeitskleid, ihr Engel der Hotels!", "tokens": ["Im", "Ar\u00b7beits\u00b7kleid", ",", "ihr", "En\u00b7gel", "der", "Ho\u00b7tels", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.3": {"line.1": {"text": "Wenn wirklich eine heimlich mit mir ausgeht,", "tokens": ["Wenn", "wirk\u00b7lich", "ei\u00b7ne", "heim\u00b7lich", "mit", "mir", "aus\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dann tr\u00e4gt sie Seide und tr\u00e4gt sogar Pelz,", "tokens": ["Dann", "tr\u00e4gt", "sie", "Sei\u00b7de", "und", "tr\u00e4gt", "so\u00b7gar", "Pelz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "KON", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sei's auch nur Wunderwandlung Hasenfells.", "tokens": ["Sei's", "auch", "nur", "Wun\u00b7der\u00b7wand\u00b7lung", "Ha\u00b7sen\u00b7fells", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Dann im Caf\u00e9 kr\u00fcmmt ihr beim Tasseheben", "tokens": ["Dann", "im", "Ca\u00b7f\u00e9", "kr\u00fcmmt", "ihr", "beim", "Tas\u00b7se\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den kleinen, roten Finger nach Manier.", "tokens": ["Den", "klei\u00b7nen", ",", "ro\u00b7ten", "Fin\u00b7ger", "nach", "Ma\u00b7nier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Und du merkst nicht, wie gern ich doch mit dir", "tokens": ["Und", "du", "merkst", "nicht", ",", "wie", "gern", "ich", "doch", "mit", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Oft eine Stunde m\u00f6chte unmanierlich leben.", "tokens": ["Oft", "ei\u00b7ne", "Stun\u00b7de", "m\u00f6ch\u00b7te", "un\u00b7ma\u00b7nier\u00b7lich", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und w\u00fcrde dann \u2013 nebst Geld \u2013 als Souvenir", "tokens": ["Und", "w\u00fcr\u00b7de", "dann", "\u2013", "nebst", "Geld", "\u2013", "als", "Sou\u00b7ve\u00b7nir"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "$(", "APPR", "NN", "$(", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein schlie\u00dfend, stilles, zartes Streicheln geben.", "tokens": ["Ein", "schlie\u00b7\u00dfend", ",", "stil\u00b7les", ",", "zar\u00b7tes", "Strei\u00b7cheln", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ADJA", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und w\u00fcrdet ihr dies Streicheln doch nicht sp\u00fcren.", "tokens": ["Und", "w\u00fcr\u00b7det", "ihr", "dies", "Strei\u00b7cheln", "doch", "nicht", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PDS", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn ihr bedient nur Nummern an den T\u00fcren.", "tokens": ["Denn", "ihr", "be\u00b7dient", "nur", "Num\u00b7mern", "an", "den", "T\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und wenn sie schlichte Ehre eng verschlie\u00dfen,", "tokens": ["Und", "wenn", "sie", "schlich\u00b7te", "Eh\u00b7re", "eng", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann dienen sie, da andere genie\u00dfen.", "tokens": ["Dann", "die\u00b7nen", "sie", ",", "da", "an\u00b7de\u00b7re", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Hab ich euch tausendmal in Korridoren", "tokens": ["Hab", "ich", "euch", "tau\u00b7send\u00b7mal", "in", "Kor\u00b7ri\u00b7do\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hei\u00df zugesehn und heiser angesehn,", "tokens": ["Hei\u00df", "zu\u00b7ge\u00b7sehn", "und", "hei\u00b7ser", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was ich ertr\u00e4umte, war voraus verloren.", "tokens": ["Was", "ich", "er\u00b7tr\u00e4um\u00b7te", ",", "war", "vo\u00b7raus", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn meine Liebe k\u00f6nnt ihr nicht verstehn.", "tokens": ["Denn", "mei\u00b7ne", "Lie\u00b7be", "k\u00f6nnt", "ihr", "nicht", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Die Zimmerm\u00e4dchen der Hotels,", "tokens": ["Die", "Zim\u00b7mer\u00b7m\u00e4d\u00b7chen", "der", "Ho\u00b7tels", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Die meine Betten schlagen und dann gl\u00e4tten,", "tokens": ["Die", "mei\u00b7ne", "Bet\u00b7ten", "schla\u00b7gen", "und", "dann", "gl\u00e4t\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "KON", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ach wenn sie doch ein wenig Ahnung h\u00e4tten", "tokens": ["Ach", "wenn", "sie", "doch", "ein", "we\u00b7nig", "Ah\u00b7nung", "h\u00e4t\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "KOUS", "PPER", "ADV", "ART", "PIAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Vom Unterschiede zwischen Polster und Fels.", "tokens": ["Vom", "Un\u00b7ter\u00b7schie\u00b7de", "zwi\u00b7schen", "Pols\u00b7ter", "und", "Fels", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.10": {"line.1": {"text": "Ach w\u00fc\u00dftet ihr, wie s\u00fc\u00df ihr f\u00fcr mich ausseht", "tokens": ["Ach", "w\u00fc\u00df\u00b7tet", "ihr", ",", "wie", "s\u00fc\u00df", "ihr", "f\u00fcr", "mich", "aus\u00b7seht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "VVFIN", "PPER", "$,", "PWAV", "ADJD", "PPER", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Im Arbeitskleid, ihr Engel der Hotels!", "tokens": ["Im", "Ar\u00b7beits\u00b7kleid", ",", "ihr", "En\u00b7gel", "der", "Ho\u00b7tels", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Wenn wirklich eine heimlich mit mir ausgeht,", "tokens": ["Wenn", "wirk\u00b7lich", "ei\u00b7ne", "heim\u00b7lich", "mit", "mir", "aus\u00b7geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dann tr\u00e4gt sie Seide und tr\u00e4gt sogar Pelz,", "tokens": ["Dann", "tr\u00e4gt", "sie", "Sei\u00b7de", "und", "tr\u00e4gt", "so\u00b7gar", "Pelz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "KON", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sei's auch nur Wunderwandlung Hasenfells.", "tokens": ["Sei's", "auch", "nur", "Wun\u00b7der\u00b7wand\u00b7lung", "Ha\u00b7sen\u00b7fells", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Dann im Caf\u00e9 kr\u00fcmmt ihr beim Tasseheben", "tokens": ["Dann", "im", "Ca\u00b7f\u00e9", "kr\u00fcmmt", "ihr", "beim", "Tas\u00b7se\u00b7he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Den kleinen, roten Finger nach Manier.", "tokens": ["Den", "klei\u00b7nen", ",", "ro\u00b7ten", "Fin\u00b7ger", "nach", "Ma\u00b7nier", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Und du merkst nicht, wie gern ich doch mit dir", "tokens": ["Und", "du", "merkst", "nicht", ",", "wie", "gern", "ich", "doch", "mit", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "ADV", "PPER", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Oft eine Stunde m\u00f6chte unmanierlich leben.", "tokens": ["Oft", "ei\u00b7ne", "Stun\u00b7de", "m\u00f6ch\u00b7te", "un\u00b7ma\u00b7nier\u00b7lich", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und w\u00fcrde dann \u2013 nebst Geld \u2013 als Souvenir", "tokens": ["Und", "w\u00fcr\u00b7de", "dann", "\u2013", "nebst", "Geld", "\u2013", "als", "Sou\u00b7ve\u00b7nir"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "ADV", "$(", "APPR", "NN", "$(", "KOUS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ein schlie\u00dfend, stilles, zartes Streicheln geben.", "tokens": ["Ein", "schlie\u00b7\u00dfend", ",", "stil\u00b7les", ",", "zar\u00b7tes", "Strei\u00b7cheln", "ge\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "ADJA", "$,", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Und w\u00fcrdet ihr dies Streicheln doch nicht sp\u00fcren.", "tokens": ["Und", "w\u00fcr\u00b7det", "ihr", "dies", "Strei\u00b7cheln", "doch", "nicht", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PDS", "NN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Denn ihr bedient nur Nummern an den T\u00fcren.", "tokens": ["Denn", "ihr", "be\u00b7dient", "nur", "Num\u00b7mern", "an", "den", "T\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Und wenn sie schlichte Ehre eng verschlie\u00dfen,", "tokens": ["Und", "wenn", "sie", "schlich\u00b7te", "Eh\u00b7re", "eng", "ver\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "NN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Dann dienen sie, da andere genie\u00dfen.", "tokens": ["Dann", "die\u00b7nen", "sie", ",", "da", "an\u00b7de\u00b7re", "ge\u00b7nie\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Hab ich euch tausendmal in Korridoren", "tokens": ["Hab", "ich", "euch", "tau\u00b7send\u00b7mal", "in", "Kor\u00b7ri\u00b7do\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hei\u00df zugesehn und heiser angesehn,", "tokens": ["Hei\u00df", "zu\u00b7ge\u00b7sehn", "und", "hei\u00b7ser", "an\u00b7ge\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Was ich ertr\u00e4umte, war voraus verloren.", "tokens": ["Was", "ich", "er\u00b7tr\u00e4um\u00b7te", ",", "war", "vo\u00b7raus", "ver\u00b7lo\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Denn meine Liebe k\u00f6nnt ihr nicht verstehn.", "tokens": ["Denn", "mei\u00b7ne", "Lie\u00b7be", "k\u00f6nnt", "ihr", "nicht", "ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}