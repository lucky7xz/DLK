{"textgrid.poem.60233": {"metadata": {"author": {"name": "Karsch, Anna Louisa", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der gro\u00dfe Kato war kein Weiser,", "genre": "verse", "period": "N.A.", "pub_year": 1771, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der gro\u00dfe Kato war kein Weiser,", "tokens": ["Der", "gro\u00b7\u00dfe", "Ka\u00b7to", "war", "kein", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er in Utika dem Schicksal widersprach,", "tokens": ["Als", "er", "in", "U\u00b7ti\u00b7ka", "dem", "Schick\u00b7sal", "wi\u00b7der\u00b7sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wegen C\u00e4sars Lorberreiser,", "tokens": ["Und", "we\u00b7gen", "C\u00e4\u00b7sars", "Lor\u00b7berr\u00b7ei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich w\u00fcthend in die Leber stach:", "tokens": ["Sich", "w\u00fct\u00b7hend", "in", "die", "Le\u00b7ber", "stach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Das B\u00fcrgerblut ward nicht gerochen,", "tokens": ["Das", "B\u00fcr\u00b7ger\u00b7blut", "ward", "nicht", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Roms Freyheit nicht besch\u00fctzt, und ihre Fesseln nicht", "tokens": ["Roms", "Frey\u00b7heit", "nicht", "be\u00b7sch\u00fctzt", ",", "und", "ih\u00b7re", "Fes\u00b7seln", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "PTKNEG", "VVPP", "$,", "KON", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch seine wilde That zerbrochen;", "tokens": ["Durch", "sei\u00b7ne", "wil\u00b7de", "That", "zer\u00b7bro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nie sing' ich ihm ein Lobgedicht.", "tokens": ["Nie", "sing'", "ich", "ihm", "ein", "Lob\u00b7ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Dich aber m\u00f6cht' ich gern besingen,", "tokens": ["Dich", "a\u00b7ber", "m\u00f6cht'", "ich", "gern", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du, der dein Leben des Erhaltens werth gesch\u00e4tzt,", "tokens": ["Du", ",", "der", "dein", "Le\u00b7ben", "des", "Er\u00b7hal\u00b7tens", "werth", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mit der gr\u00f6\u00dften Quaal zu ringen,", "tokens": ["Und", "mit", "der", "gr\u00f6\u00df\u00b7ten", "Qua\u00b7al", "zu", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sich heldenm\u00fcthig vorgesetzt.", "tokens": ["Sich", "hel\u00b7den\u00b7m\u00fct\u00b7hig", "vor\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "So viel hat Herkul kaum gelitten,", "tokens": ["So", "viel", "hat", "Her\u00b7kul", "kaum", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da des Centauren Blut ihm durch und durch entbrannt,", "tokens": ["Da", "des", "Cen\u00b7tau\u00b7ren", "Blut", "ihm", "durch", "und", "durch", "ent\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "PPER", "APPR", "KON", "APPR", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als bey zweytausend Messerschnitten", "tokens": ["Als", "bey", "zweyt\u00b7au\u00b7send", "Mes\u00b7ser\u00b7schnit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Arztes \u2013 deine Brust empfand.", "tokens": ["Des", "Arz\u00b7tes", "\u2013", "dei\u00b7ne", "Brust", "emp\u00b7fand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Noch staunet Schmucker in Gedanken;", "tokens": ["Noch", "stau\u00b7net", "Schmu\u00b7cker", "in", "Ge\u00b7dan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er sieht dich unter seiner kunstber\u00fchmten Hand", "tokens": ["Er", "sieht", "dich", "un\u00b7ter", "sei\u00b7ner", "kunst\u00b7be\u00b7r\u00fchm\u00b7ten", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Noch immer ohne Zuck und Wanken;", "tokens": ["Noch", "im\u00b7mer", "oh\u00b7ne", "Zuck", "und", "Wan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In keinem Blick ist Widerstand.", "tokens": ["In", "kei\u00b7nem", "Blick", "ist", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Wenn er zum Schaudern wird bewogen,", "tokens": ["Wenn", "er", "zum", "Schau\u00b7dern", "wird", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So munterst du ihn auf, so wird nach deiner Art", "tokens": ["So", "mun\u00b7terst", "du", "ihn", "auf", ",", "so", "wird", "nach", "dei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Mund zum L\u00e4cheln sanft verzogen", "tokens": ["Der", "Mund", "zum", "L\u00e4\u00b7cheln", "sanft", "ver\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit gro\u00dfer Geistesgegenwart.", "tokens": ["Mit", "gro\u00b7\u00dfer", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Du wolltest leben, und du lebtest", "tokens": ["Du", "woll\u00b7test", "le\u00b7ben", ",", "und", "du", "leb\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr deine Kinder, und auch f\u00fcr die feine Welt,", "tokens": ["F\u00fcr", "dei\u00b7ne", "Kin\u00b7der", ",", "und", "auch", "f\u00fcr", "die", "fei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In welcher du dir Ruhm erstrebtest,", "tokens": ["In", "wel\u00b7cher", "du", "dir", "Ruhm", "er\u00b7streb\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die manch Geschenk von dir erh\u00e4lt.", "tokens": ["Die", "manch", "Ge\u00b7schenk", "von", "dir", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Kein Stoikus war in dem alten", "tokens": ["Kein", "Stoi\u00b7kus", "war", "in", "dem", "al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "ART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gestrengen Sparta mehr voll Muth und Schmerzenstrutz,", "tokens": ["Ge\u00b7stren\u00b7gen", "Spar\u00b7ta", "mehr", "voll", "Muth", "und", "Schmer\u00b7zen\u00b7strutz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als Zimmermann, der sich erhalten,", "tokens": ["Als", "Zim\u00b7mer\u00b7mann", ",", "der", "sich", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Marter, zum gemeinen Nutz.", "tokens": ["Durch", "Mar\u00b7ter", ",", "zum", "ge\u00b7mei\u00b7nen", "Nutz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Du bist gesund f\u00fcr tausend Kranken,", "tokens": ["Du", "bist", "ge\u00b7sund", "f\u00fcr", "tau\u00b7send", "Kran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die du von Charons Kahn in Jahresfrist zur\u00fcck", "tokens": ["Die", "du", "von", "Cha\u00b7rons", "Kahn", "in", "Jah\u00b7res\u00b7frist", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NE", "NN", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ins Leben zeuchst, und alle danken", "tokens": ["Ins", "Le\u00b7ben", "zeuchst", ",", "und", "al\u00b7le", "dan\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "KON", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dir ihres neuen Daseyns Gl\u00fcck:", "tokens": ["Dir", "ih\u00b7res", "neu\u00b7en", "Da\u00b7seyns", "Gl\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Du lebst f\u00fcr Aesculapens S\u00f6hne", "tokens": ["Du", "lebst", "f\u00fcr", "A\u00b7e\u00b7scu\u00b7la\u00b7pens", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die von dir lernen, und o! Freund, vielleicht, vielleicht", "tokens": ["Die", "von", "dir", "ler\u00b7nen", ",", "und", "o", "!", "Freund", ",", "viel\u00b7leicht", ",", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "APPR", "PPER", "VVINF", "$,", "KON", "FM", "$.", "NN", "$,", "ADV", "$,", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Lebst du auch noch f\u00fcr eine Sch\u00f6ne,", "tokens": ["Lebst", "du", "auch", "noch", "f\u00fcr", "ei\u00b7ne", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir an sanftem Herzen gleicht,", "tokens": ["Die", "dir", "an", "sanf\u00b7tem", "Her\u00b7zen", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Die irgendwo f\u00fcr dich gebohren", "tokens": ["Die", "ir\u00b7gend\u00b7wo", "f\u00fcr", "dich", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und auferzogen von der Huldg\u00f6ttinnen Flei\u00df,", "tokens": ["Und", "auf\u00b7er\u00b7zo\u00b7gen", "von", "der", "Huld\u00b7g\u00f6t\u00b7tin\u00b7nen", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Das Kleinod, welches du verloren,", "tokens": ["Das", "Klei\u00b7nod", ",", "wel\u00b7ches", "du", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Gattinn \u2013 zu ersetzen wei\u00df.", "tokens": ["Die", "Gat\u00b7tinn", "\u2013", "zu", "er\u00b7set\u00b7zen", "wei\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Der gro\u00dfe Kato war kein Weiser,", "tokens": ["Der", "gro\u00b7\u00dfe", "Ka\u00b7to", "war", "kein", "Wei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als er in Utika dem Schicksal widersprach,", "tokens": ["Als", "er", "in", "U\u00b7ti\u00b7ka", "dem", "Schick\u00b7sal", "wi\u00b7der\u00b7sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wegen C\u00e4sars Lorberreiser,", "tokens": ["Und", "we\u00b7gen", "C\u00e4\u00b7sars", "Lor\u00b7berr\u00b7ei\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "NE", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich w\u00fcthend in die Leber stach:", "tokens": ["Sich", "w\u00fct\u00b7hend", "in", "die", "Le\u00b7ber", "stach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Das B\u00fcrgerblut ward nicht gerochen,", "tokens": ["Das", "B\u00fcr\u00b7ger\u00b7blut", "ward", "nicht", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Roms Freyheit nicht besch\u00fctzt, und ihre Fesseln nicht", "tokens": ["Roms", "Frey\u00b7heit", "nicht", "be\u00b7sch\u00fctzt", ",", "und", "ih\u00b7re", "Fes\u00b7seln", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "PTKNEG", "VVPP", "$,", "KON", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch seine wilde That zerbrochen;", "tokens": ["Durch", "sei\u00b7ne", "wil\u00b7de", "That", "zer\u00b7bro\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nie sing' ich ihm ein Lobgedicht.", "tokens": ["Nie", "sing'", "ich", "ihm", "ein", "Lob\u00b7ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Dich aber m\u00f6cht' ich gern besingen,", "tokens": ["Dich", "a\u00b7ber", "m\u00f6cht'", "ich", "gern", "be\u00b7sin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Du, der dein Leben des Erhaltens werth gesch\u00e4tzt,", "tokens": ["Du", ",", "der", "dein", "Le\u00b7ben", "des", "Er\u00b7hal\u00b7tens", "werth", "ge\u00b7sch\u00e4tzt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "PPOSAT", "NN", "ART", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und mit der gr\u00f6\u00dften Quaal zu ringen,", "tokens": ["Und", "mit", "der", "gr\u00f6\u00df\u00b7ten", "Qua\u00b7al", "zu", "rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "---+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sich heldenm\u00fcthig vorgesetzt.", "tokens": ["Sich", "hel\u00b7den\u00b7m\u00fct\u00b7hig", "vor\u00b7ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "So viel hat Herkul kaum gelitten,", "tokens": ["So", "viel", "hat", "Her\u00b7kul", "kaum", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da des Centauren Blut ihm durch und durch entbrannt,", "tokens": ["Da", "des", "Cen\u00b7tau\u00b7ren", "Blut", "ihm", "durch", "und", "durch", "ent\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "NN", "PPER", "APPR", "KON", "APPR", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als bey zweytausend Messerschnitten", "tokens": ["Als", "bey", "zweyt\u00b7au\u00b7send", "Mes\u00b7ser\u00b7schnit\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Des Arztes \u2013 deine Brust empfand.", "tokens": ["Des", "Arz\u00b7tes", "\u2013", "dei\u00b7ne", "Brust", "emp\u00b7fand", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Noch staunet Schmucker in Gedanken;", "tokens": ["Noch", "stau\u00b7net", "Schmu\u00b7cker", "in", "Ge\u00b7dan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Er sieht dich unter seiner kunstber\u00fchmten Hand", "tokens": ["Er", "sieht", "dich", "un\u00b7ter", "sei\u00b7ner", "kunst\u00b7be\u00b7r\u00fchm\u00b7ten", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Noch immer ohne Zuck und Wanken;", "tokens": ["Noch", "im\u00b7mer", "oh\u00b7ne", "Zuck", "und", "Wan\u00b7ken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In keinem Blick ist Widerstand.", "tokens": ["In", "kei\u00b7nem", "Blick", "ist", "Wi\u00b7der\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wenn er zum Schaudern wird bewogen,", "tokens": ["Wenn", "er", "zum", "Schau\u00b7dern", "wird", "be\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "So munterst du ihn auf, so wird nach deiner Art", "tokens": ["So", "mun\u00b7terst", "du", "ihn", "auf", ",", "so", "wird", "nach", "dei\u00b7ner", "Art"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der Mund zum L\u00e4cheln sanft verzogen", "tokens": ["Der", "Mund", "zum", "L\u00e4\u00b7cheln", "sanft", "ver\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit gro\u00dfer Geistesgegenwart.", "tokens": ["Mit", "gro\u00b7\u00dfer", "Geis\u00b7tes\u00b7ge\u00b7gen\u00b7wart", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Du wolltest leben, und du lebtest", "tokens": ["Du", "woll\u00b7test", "le\u00b7ben", ",", "und", "du", "leb\u00b7test"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$,", "KON", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "F\u00fcr deine Kinder, und auch f\u00fcr die feine Welt,", "tokens": ["F\u00fcr", "dei\u00b7ne", "Kin\u00b7der", ",", "und", "auch", "f\u00fcr", "die", "fei\u00b7ne", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In welcher du dir Ruhm erstrebtest,", "tokens": ["In", "wel\u00b7cher", "du", "dir", "Ruhm", "er\u00b7streb\u00b7test", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die manch Geschenk von dir erh\u00e4lt.", "tokens": ["Die", "manch", "Ge\u00b7schenk", "von", "dir", "er\u00b7h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Kein Stoikus war in dem alten", "tokens": ["Kein", "Stoi\u00b7kus", "war", "in", "dem", "al\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "APPR", "ART", "ADJA"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Gestrengen Sparta mehr voll Muth und Schmerzenstrutz,", "tokens": ["Ge\u00b7stren\u00b7gen", "Spar\u00b7ta", "mehr", "voll", "Muth", "und", "Schmer\u00b7zen\u00b7strutz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "ADJD", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als Zimmermann, der sich erhalten,", "tokens": ["Als", "Zim\u00b7mer\u00b7mann", ",", "der", "sich", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Durch Marter, zum gemeinen Nutz.", "tokens": ["Durch", "Mar\u00b7ter", ",", "zum", "ge\u00b7mei\u00b7nen", "Nutz", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Du bist gesund f\u00fcr tausend Kranken,", "tokens": ["Du", "bist", "ge\u00b7sund", "f\u00fcr", "tau\u00b7send", "Kran\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die du von Charons Kahn in Jahresfrist zur\u00fcck", "tokens": ["Die", "du", "von", "Cha\u00b7rons", "Kahn", "in", "Jah\u00b7res\u00b7frist", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "NE", "NN", "APPR", "NN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ins Leben zeuchst, und alle danken", "tokens": ["Ins", "Le\u00b7ben", "zeuchst", ",", "und", "al\u00b7le", "dan\u00b7ken"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "$,", "KON", "PIS", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dir ihres neuen Daseyns Gl\u00fcck:", "tokens": ["Dir", "ih\u00b7res", "neu\u00b7en", "Da\u00b7seyns", "Gl\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Du lebst f\u00fcr Aesculapens S\u00f6hne", "tokens": ["Du", "lebst", "f\u00fcr", "A\u00b7e\u00b7scu\u00b7la\u00b7pens", "S\u00f6h\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die von dir lernen, und o! Freund, vielleicht, vielleicht", "tokens": ["Die", "von", "dir", "ler\u00b7nen", ",", "und", "o", "!", "Freund", ",", "viel\u00b7leicht", ",", "viel\u00b7leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["ART", "APPR", "PPER", "VVINF", "$,", "KON", "FM", "$.", "NN", "$,", "ADV", "$,", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Lebst du auch noch f\u00fcr eine Sch\u00f6ne,", "tokens": ["Lebst", "du", "auch", "noch", "f\u00fcr", "ei\u00b7ne", "Sch\u00f6\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die dir an sanftem Herzen gleicht,", "tokens": ["Die", "dir", "an", "sanf\u00b7tem", "Her\u00b7zen", "gleicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die irgendwo f\u00fcr dich gebohren", "tokens": ["Die", "ir\u00b7gend\u00b7wo", "f\u00fcr", "dich", "ge\u00b7boh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PPER", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und auferzogen von der Huldg\u00f6ttinnen Flei\u00df,", "tokens": ["Und", "auf\u00b7er\u00b7zo\u00b7gen", "von", "der", "Huld\u00b7g\u00f6t\u00b7tin\u00b7nen", "Flei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVPP", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Das Kleinod, welches du verloren,", "tokens": ["Das", "Klei\u00b7nod", ",", "wel\u00b7ches", "du", "ver\u00b7lo\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Gattinn \u2013 zu ersetzen wei\u00df.", "tokens": ["Die", "Gat\u00b7tinn", "\u2013", "zu", "er\u00b7set\u00b7zen", "wei\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}