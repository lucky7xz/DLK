{"textgrid.poem.26379": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Schicksal schon seit \u00d6dipus", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Schicksal schon seit \u00d6dipus", "tokens": ["Ein", "Schick\u00b7sal", "schon", "seit", "\u00d6\u00b7di\u00b7pus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An jedem sich erf\u00fcllen mu\u00df,", "tokens": ["An", "je\u00b7dem", "sich", "er\u00b7f\u00fcl\u00b7len", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Und hier sei langsam euch enth\u00fcllt,", "tokens": ["Und", "hier", "sei", "lang\u00b7sam", "euch", "ent\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Welch Schicksal sich an mir erf\u00fcllt.", "tokens": ["Welch", "Schick\u00b7sal", "sich", "an", "mir", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.3": {"line.1": {"text": "Die Jahre gehen, wie man wei\u00df,", "tokens": ["Die", "Jah\u00b7re", "ge\u00b7hen", ",", "wie", "man", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Winter kalt, im Sommer hei\u00df.", "tokens": ["Im", "Win\u00b7ter", "kalt", ",", "im", "Som\u00b7mer", "hei\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Nicht nur mit hei\u00df und kalten Wangen,", "tokens": ["Nicht", "nur", "mit", "hei\u00df", "und", "kal\u00b7ten", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind auch die Jahre mir vergangen.", "tokens": ["Sind", "auch", "die", "Jah\u00b7re", "mir", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Es war in meiner Vaterstadt,", "tokens": ["Es", "war", "in", "mei\u00b7ner", "Va\u00b7ter\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort fand ein Wiedersehen statt,", "tokens": ["Dort", "fand", "ein", "Wie\u00b7der\u00b7se\u00b7hen", "statt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Um Folgen von dem Wiedersehn", "tokens": ["Um", "Fol\u00b7gen", "von", "dem", "Wie\u00b7der\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tut sich das ganze Buch jetzt drehn.", "tokens": ["Tut", "sich", "das", "gan\u00b7ze", "Buch", "jetzt", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "In meiner Stadt steht auch ein Schlo\u00df", "tokens": ["In", "mei\u00b7ner", "Stadt", "steht", "auch", "ein", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und drinnen wuchs der Amor gro\u00df,", "tokens": ["Und", "drin\u00b7nen", "wuchs", "der", "A\u00b7mor", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Bisch\u00f6fe bauten dieses Haus,", "tokens": ["Bi\u00b7sch\u00f6\u00b7fe", "bau\u00b7ten", "die\u00b7ses", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und flott sieht's wie bei G\u00f6ttern aus.", "tokens": ["Und", "flott", "sieht's", "wie", "bei", "G\u00f6t\u00b7tern", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "KOKOM", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Dort sind Tanz-, Spiel- und Spiegelsaal,", "tokens": ["Dort", "sind", "Tanz", ",", "Spiel", "und", "Spie\u00b7gel\u00b7saal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "TRUNC", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und drei\u00dfig K\u00fcchen auf einmal.", "tokens": ["Und", "drei\u00b7\u00dfig", "K\u00fc\u00b7chen", "auf", "ein\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dreihundert S\u00e4le gibt es nur,", "tokens": ["Drei\u00b7hun\u00b7dert", "S\u00e4\u00b7le", "gibt", "es", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo man genie\u00dft Gott und Natur.", "tokens": ["Wo", "man", "ge\u00b7nie\u00dft", "Gott", "und", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Im Garten, in versch\u00e4mten Lauben,", "tokens": ["Im", "Gar\u00b7ten", ",", "in", "ver\u00b7sch\u00e4m\u00b7ten", "Lau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df man an Seligkeiten glauben.", "tokens": ["Mu\u00df", "man", "an", "Se\u00b7lig\u00b7kei\u00b7ten", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "S\u00fc\u00df Nacktes spielte hier Verstecken,", "tokens": ["S\u00fc\u00df", "Nack\u00b7tes", "spiel\u00b7te", "hier", "Ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Amor lie\u00df sich gern entdecken.", "tokens": ["Und", "A\u00b7mor", "lie\u00df", "sich", "gern", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Ist er gemei\u00dfelt nur aus Stein,", "tokens": ["Ist", "er", "ge\u00b7mei\u00b7\u00dfelt", "nur", "aus", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fl\u00f6\u00dft er doch andern Leben ein.", "tokens": ["Fl\u00f6\u00dft", "er", "doch", "an\u00b7dern", "Le\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Wein liegt hinter der Kellerpfort',", "tokens": ["Wein", "liegt", "hin\u00b7ter", "der", "Kel\u00b7ler\u00b7pfort'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Der tr\u00e4gt das Herz gar hitzig fort,", "tokens": ["Der", "tr\u00e4gt", "das", "Herz", "gar", "hit\u00b7zig", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Er bockt in Flaschen sehr markant,", "tokens": ["Er", "bockt", "in", "Fla\u00b7schen", "sehr", "mar\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man hat Bocksbeutel ihn genannt.", "tokens": ["Man", "hat", "Bocks\u00b7beu\u00b7tel", "ihn", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und oft an hei\u00dfem Nachmittag,", "tokens": ["Und", "oft", "an", "hei\u00b7\u00dfem", "Nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Gott selbst nicht regieren mag,", "tokens": ["Wenn", "Gott", "selbst", "nicht", "re\u00b7gie\u00b7ren", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Tat Bischof und Pr\u00e4lat sich laben,", "tokens": ["Tat", "Bi\u00b7schof", "und", "Pr\u00e4\u00b7lat", "sich", "la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "PRF", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dem Wein sie die Regentschaft gaben.", "tokens": ["Dem", "Wein", "sie", "die", "Re\u00b7gent\u00b7schaft", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.18": {"line.1": {"text": "Mit Nichten und verwandten Damen", "tokens": ["Mit", "Nich\u00b7ten", "und", "ver\u00b7wand\u00b7ten", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Karussellsaal sie hinkamen,", "tokens": ["Zum", "Ka\u00b7rus\u00b7sell\u00b7saal", "sie", "hin\u00b7ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Die Pferdlein dort aus Holz nur sind,", "tokens": ["Die", "Pferd\u00b7lein", "dort", "aus", "Holz", "nur", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch dreht man sie, so macht das Wind.", "tokens": ["Doch", "dreht", "man", "sie", ",", "so", "macht", "das", "Wind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Denn war die Mahlzeit gar zu hei\u00df,", "tokens": ["Denn", "war", "die", "Mahl\u00b7zeit", "gar", "zu", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00fchlt man sich gern den Erdenschwei\u00df.", "tokens": ["K\u00fchlt", "man", "sich", "gern", "den", "Er\u00b7den\u00b7schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.21": {"line.1": {"text": "Man nimmt die Damen auf den Scho\u00df,", "tokens": ["Man", "nimmt", "die", "Da\u00b7men", "auf", "den", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fromm ist stets ein lackiertes Ro\u00df,", "tokens": ["Fromm", "ist", "stets", "ein", "la\u00b7ckier\u00b7tes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Und mit Musik dreht sich das Holz,", "tokens": ["Und", "mit", "Mu\u00b7sik", "dreht", "sich", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und jedes Pferdchen b\u00e4umt sich stolz.", "tokens": ["Und", "je\u00b7des", "Pferd\u00b7chen", "b\u00e4umt", "sich", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Die Dame, jung oder gereift,", "tokens": ["Die", "Da\u00b7me", ",", "jung", "o\u00b7der", "ge\u00b7reift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stets gern nach dem Bocksbeutel greift.", "tokens": ["Stets", "gern", "nach", "dem", "Bocks\u00b7beu\u00b7tel", "greift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.24": {"line.1": {"text": "Ein Bischof ist auch keine Kuh,", "tokens": ["Ein", "Bi\u00b7schof", "ist", "auch", "kei\u00b7ne", "Kuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hei\u00df trinkt er der Dame zu.", "tokens": ["Und", "hei\u00df", "trinkt", "er", "der", "Da\u00b7me", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.25": {"line.1": {"text": "\u00bbgebenedeit sei die Natur,", "tokens": ["\u00bb", "ge\u00b7be\u00b7ne\u00b7deit", "sei", "die", "Na\u00b7tur", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Hebt hoch das Glas, ", "tokens": ["Hebt", "hoch", "das", "Glas", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.26": {"line.1": {"text": "Und die Pr\u00e4laten rufen's nach:", "tokens": ["Und", "die", "Pr\u00e4\u00b7la\u00b7ten", "ru\u00b7fen's", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Das Volk, das auf dem Schlo\u00dfplatz steht,", "tokens": ["Das", "Volk", ",", "das", "auf", "dem", "Schlo\u00df\u00b7platz", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Franz\u00f6sisch nicht sofort versteht.", "tokens": ["Fran\u00b7z\u00f6\u00b7sisch", "nicht", "so\u00b7fort", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.28": {"line.1": {"text": "Hoch Schorle Morle, ruft es wieder,", "tokens": ["Hoch", "Schor\u00b7le", "Mor\u00b7le", ",", "ruft", "es", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Amor steigt zum Volk hernieder.", "tokens": ["Und", "A\u00b7mor", "steigt", "zum", "Volk", "her\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Kommt aus den Kellern dann die Nacht,", "tokens": ["Kommt", "aus", "den", "Kel\u00b7lern", "dann", "die", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Rotwein rot jed' Fenster lacht. \u2013", "tokens": ["Wie", "Rot\u00b7wein", "rot", "jed'", "Fens\u00b7ter", "lacht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "ADJD", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.30": {"line.1": {"text": "Heut ist's in Schlo\u00df und Garten still,", "tokens": ["Heut", "ist's", "in", "Schlo\u00df", "und", "Gar\u00b7ten", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der kleine Gott mal schlafen will.", "tokens": ["Der", "klei\u00b7ne", "Gott", "mal", "schla\u00b7fen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "\u00bbhoch Schorle Morle,\u00ab dacht' ich laut,", "tokens": ["\u00bb", "hoch", "Schor\u00b7le", "Mor\u00b7le", ",", "\u00ab", "dacht'", "ich", "laut", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "NN", "$,", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil's keiner sich zu rufen traut,", "tokens": ["Weil's", "kei\u00b7ner", "sich", "zu", "ru\u00b7fen", "traut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.32": {"line.1": {"text": "Denn offen ist dem Volk der Garten.", "tokens": ["Denn", "of\u00b7fen", "ist", "dem", "Volk", "der", "Gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Nachtigallen s\u00fc\u00df aufwarten", "tokens": ["Wo", "Nach\u00b7ti\u00b7gal\u00b7len", "s\u00fc\u00df", "auf\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Und wo noch Amoretten stehn,", "tokens": ["Und", "wo", "noch", "A\u00b7mo\u00b7ret\u00b7ten", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da hatte ich ein Wiedersehn.", "tokens": ["Da", "hat\u00b7te", "ich", "ein", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Ging in den Lauben auf und nieder,", "tokens": ["Ging", "in", "den", "Lau\u00b7ben", "auf", "und", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich erkannte jemand wieder.", "tokens": ["Und", "ich", "er\u00b7kann\u00b7te", "je\u00b7mand", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Wir gingen rund um ein Bass\u00e4ng,", "tokens": ["Wir", "gin\u00b7gen", "rund", "um", "ein", "Bas\u00b7s\u00e4ng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fast Aug' in Aug', der Weg war eng,", "tokens": ["Fast", "Aug'", "in", "Aug'", ",", "der", "Weg", "war", "eng", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Wie W\u00fcrfelaugen fiel ihr Blick,", "tokens": ["Wie", "W\u00fcr\u00b7fe\u00b7lau\u00b7gen", "fiel", "ihr", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir w\u00fcrfelten um mein Geschick.", "tokens": ["Wir", "w\u00fcr\u00b7fel\u00b7ten", "um", "mein", "Ge\u00b7schick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.37": {"line.1": {"text": "Glieder spielten ihr wie die Reben,", "tokens": ["Glie\u00b7der", "spiel\u00b7ten", "ihr", "wie", "die", "Re\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wo unter Bl\u00e4ttern Tr\u00e4ublein leben,", "tokens": ["Wo", "un\u00b7ter", "Bl\u00e4t\u00b7tern", "Tr\u00e4ub\u00b7lein", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Sie trug die Handschuh in der Hand,", "tokens": ["Sie", "trug", "die", "Hand\u00b7schuh", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Ehering war der bekannt,", "tokens": ["Kein", "E\u00b7he\u00b7ring", "war", "der", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Die H\u00e4nde wei\u00df wie Sahnenflecken", "tokens": ["Die", "H\u00e4n\u00b7de", "wei\u00df", "wie", "Sah\u00b7nen\u00b7fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mochte man gern vom Kleid ablecken.", "tokens": ["Moch\u00b7te", "man", "gern", "vom", "Kleid", "ab\u00b7le\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.40": {"line.1": {"text": "Sie klopft den Amor auf den Bauch", "tokens": ["Sie", "klopft", "den", "A\u00b7mor", "auf", "den", "Bauch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Stein in dem Akazienstrauch.", "tokens": ["Aus", "Stein", "in", "dem", "A\u00b7ka\u00b7zi\u00b7en\u00b7strauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.41": {"line.1": {"text": "Der alte Amor lachte froh,", "tokens": ["Der", "al\u00b7te", "A\u00b7mor", "lach\u00b7te", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm wackelt der Sandsteinpopo.", "tokens": ["Ihm", "wa\u00b7ckelt", "der", "Sand\u00b7ste\u00b7in\u00b7po\u00b7po", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.42": {"line.1": {"text": "\u00bbdu bist schon l\u00e4ngst ein Ehemann,\u00ab", "tokens": ["\u00bb", "du", "bist", "schon", "l\u00e4ngst", "ein", "E\u00b7he\u00b7mann", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach sie, \u00bbman sieht dir's gar nicht an.\u00ab", "tokens": ["Sprach", "sie", ",", "\u00bb", "man", "sieht", "dir's", "gar", "nicht", "an", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "$(", "PIS", "VVFIN", "PIS", "ADV", "PTKNEG", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.43": {"line.1": {"text": "Sie fragte: \u00bbBist du gl\u00fccklich jetzt?\u00ab", "tokens": ["Sie", "frag\u00b7te", ":", "\u00bb", "Bist", "du", "gl\u00fcck\u00b7lich", "jetzt", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VAFIN", "PPER", "ADJD", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat sich auf die Bank gesetzt.", "tokens": ["Und", "hat", "sich", "auf", "die", "Bank", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Ich setzte mich ganz still daneben,", "tokens": ["Ich", "setz\u00b7te", "mich", "ganz", "still", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbGl\u00fccklich bin ich f\u00fcr das Leben.\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gl\u00fcck\u00b7lich", "bin", "ich", "f\u00fcr", "das", "Le\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "ADJD", "VAFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Fragte nicht, ob sie gl\u00fccklich ist,", "tokens": ["Frag\u00b7te", "nicht", ",", "ob", "sie", "gl\u00fcck\u00b7lich", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie sprach: \u00bbIch freu' mich, wenn du's bist.\u00ab", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "freu'", "mich", ",", "wenn", "du's", "bist", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Schwarz war sie wie ein Mohrenkind,", "tokens": ["Schwarz", "war", "sie", "wie", "ein", "Moh\u00b7ren\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ganz schwarz durch und durch stets sind.", "tokens": ["Die", "ganz", "schwarz", "durch", "und", "durch", "stets", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "KON", "APPR", "ADV", "VAFIN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.47": {"line.1": {"text": "Wenn ich mein Alter r\u00fcckw\u00e4rts schiebe,", "tokens": ["Wenn", "ich", "mein", "Al\u00b7ter", "r\u00fcck\u00b7w\u00e4rts", "schie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War sie einst meine Jugendliebe.", "tokens": ["War", "sie", "einst", "mei\u00b7ne", "Ju\u00b7gend\u00b7lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Damals stand bei der Stadt ein Haus,", "tokens": ["Da\u00b7mals", "stand", "bei", "der", "Stadt", "ein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ein Mohrenkopf sah dort heraus,", "tokens": ["Ein", "Moh\u00b7ren\u00b7kopf", "sah", "dort", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Ich kam dort oft zu ihrer Mutter,", "tokens": ["Ich", "kam", "dort", "oft", "zu", "ih\u00b7rer", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bestellend f\u00fcr den Vater Butter.", "tokens": ["Be\u00b7stel\u00b7lend", "f\u00fcr", "den", "Va\u00b7ter", "But\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Der Mohrenkopf war n\u00e4mlich keiner,", "tokens": ["Der", "Moh\u00b7ren\u00b7kopf", "war", "n\u00e4m\u00b7lich", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein M\u00e4dchen war er, braun und br\u00e4uner,", "tokens": ["Ein", "M\u00e4d\u00b7chen", "war", "er", ",", "braun", "und", "br\u00e4u\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Mit echten Locken, ungelogen,", "tokens": ["Mit", "ech\u00b7ten", "Lo\u00b7cken", ",", "un\u00b7ge\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab's probiert und dran gezogen;", "tokens": ["Ich", "hab's", "pro\u00b7biert", "und", "dran", "ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "VVFIN", "KON", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Wie Hobelsp\u00e4ne kraus, doch schwarz,", "tokens": ["Wie", "Ho\u00b7bel\u00b7sp\u00e4\u00b7ne", "kraus", ",", "doch", "schwarz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "PTKVZ", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gl\u00e4nzend wie am Baum das Harz.", "tokens": ["Und", "gl\u00e4n\u00b7zend", "wie", "am", "Baum", "das", "Harz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Mit ihr durft ich zum Stall hingehn,", "tokens": ["Mit", "ihr", "durft", "ich", "zum", "Stall", "hin\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und K\u00fche in der N\u00e4he sehn,", "tokens": ["Und", "K\u00fc\u00b7he", "in", "der", "N\u00e4\u00b7he", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Sie wohnte n\u00e4mlich mehr am Land,", "tokens": ["Sie", "wohn\u00b7te", "n\u00e4m\u00b7lich", "mehr", "am", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich selber war nur stadtbekannt.", "tokens": ["Ich", "sel\u00b7ber", "war", "nur", "stadt\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Im Kuhstall war's gar liebesam,", "tokens": ["Im", "Kuh\u00b7stall", "wa\u00b7r's", "gar", "lie\u00b7be\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Irdischer Duft mein Herz benahm,", "tokens": ["Ir\u00b7di\u00b7scher", "Duft", "mein", "Herz", "be\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.56": {"line.1": {"text": "Ich war ein Knabe, sie ein Kind,", "tokens": ["Ich", "war", "ein", "Kna\u00b7be", ",", "sie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jener Duft, der kam vom Rind.", "tokens": ["Und", "je\u00b7ner", "Duft", ",", "der", "kam", "vom", "Rind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PRELS", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.57": {"line.1": {"text": "Sie war elf Jahre, ich dreizehn,", "tokens": ["Sie", "war", "elf", "Jah\u00b7re", ",", "ich", "drei\u00b7zehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lernte eben das Rauchen,", "tokens": ["Ich", "lern\u00b7te", "e\u00b7ben", "das", "Rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.58": {"line.1": {"text": "Wir suchten dunkle Ecken aus,", "tokens": ["Wir", "such\u00b7ten", "dunk\u00b7le", "E\u00b7cken", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort waren wir mehr als zu Haus.", "tokens": ["Dort", "wa\u00b7ren", "wir", "mehr", "als", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Den ersten Ku\u00df, von dem man spricht,", "tokens": ["Den", "ers\u00b7ten", "Ku\u00df", ",", "von", "dem", "man", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab ich ihr in das Angesicht,", "tokens": ["Gab", "ich", "ihr", "in", "das", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.60": {"line.1": {"text": "Doch, sagte sie, da\u00df sie sich sch\u00e4me,", "tokens": ["Doch", ",", "sag\u00b7te", "sie", ",", "da\u00df", "sie", "sich", "sch\u00e4\u00b7me", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil leicht ein Kind beim K\u00fcssen k\u00e4me.", "tokens": ["Weil", "leicht", "ein", "Kind", "beim", "K\u00fcs\u00b7sen", "k\u00e4\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.61": {"line.1": {"text": "Das war die Ansicht ihrerseits,", "tokens": ["Das", "war", "die", "An\u00b7sicht", "ih\u00b7rer\u00b7seits", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich selber wu\u00dfte mehr bereits,", "tokens": ["Ich", "sel\u00b7ber", "wu\u00df\u00b7te", "mehr", "be\u00b7reits", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.62": {"line.1": {"text": "Ich sagte, da\u00df es nicht so w\u00e4r',", "tokens": ["Ich", "sag\u00b7te", ",", "da\u00df", "es", "nicht", "so", "w\u00e4r'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie aber wollte mal nicht mehr.", "tokens": ["Sie", "a\u00b7ber", "woll\u00b7te", "mal", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.63": {"line.1": {"text": "Und jeden Tag ging Balthasar", "tokens": ["Und", "je\u00b7den", "Tag", "ging", "Balt\u00b7ha\u00b7sar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Mohrenkopf, der keiner war.", "tokens": ["Zum", "Moh\u00b7ren\u00b7kopf", ",", "der", "kei\u00b7ner", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.64": {"line.1": {"text": "Da\u00df ich genehm auch ihrer Mutter,", "tokens": ["Da\u00df", "ich", "ge\u00b7nehm", "auch", "ih\u00b7rer", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bestellt' ich t\u00e4glich viele Butter.", "tokens": ["Be\u00b7stellt'", "ich", "t\u00e4g\u00b7lich", "vie\u00b7le", "But\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.65": {"line.1": {"text": "Was t\u00e4glich da an Butter war,", "tokens": ["Was", "t\u00e4g\u00b7lich", "da", "an", "But\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das kaufte ich und zahlte bar.", "tokens": ["Das", "kauf\u00b7te", "ich", "und", "zahl\u00b7te", "bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.66": {"line.1": {"text": "Denn ich versetzte, was ich hatte,", "tokens": ["Denn", "ich", "ver\u00b7setz\u00b7te", ",", "was", "ich", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sogar am Bett die Vorlegmatte.", "tokens": ["So\u00b7gar", "am", "Bett", "die", "Vor\u00b7leg\u00b7mat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.67": {"line.1": {"text": "Doch da die Butter leicht verdirbt,", "tokens": ["Doch", "da", "die", "But\u00b7ter", "leicht", "ver\u00b7dirbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die man von K\u00fchen sich erwirbt,", "tokens": ["Die", "man", "von", "K\u00fc\u00b7hen", "sich", "er\u00b7wirbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.68": {"line.1": {"text": "Und da\u00df der Vater nichts erf\u00fchre,", "tokens": ["Und", "da\u00df", "der", "Va\u00b7ter", "nichts", "er\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Legt' ich's bei H\u00e4usern in die T\u00fcre.", "tokens": ["Legt'", "ich's", "bei", "H\u00e4u\u00b7sern", "in", "die", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "So wie man Findelkinder macht,", "tokens": ["So", "wie", "man", "Fin\u00b7del\u00b7kin\u00b7der", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn man die T\u00fcren nicht bewacht.", "tokens": ["Wenn", "man", "die", "T\u00fc\u00b7ren", "nicht", "be\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.70": {"line.1": {"text": "Dies Mohrle sah ich pl\u00f6tzlich wieder,", "tokens": ["Dies", "Mohr\u00b7le", "sah", "ich", "pl\u00f6tz\u00b7lich", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da sang mein Herze Bubenlieder,", "tokens": ["Da", "sang", "mein", "Her\u00b7ze", "Bu\u00b7ben\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.71": {"line.1": {"text": "Auf einmal war das ganze Land", "tokens": ["Auf", "ein\u00b7mal", "war", "das", "gan\u00b7ze", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ein Spielkasten mir bekannt.", "tokens": ["Wie", "ein", "Spiel\u00b7kas\u00b7ten", "mir", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.72": {"line.1": {"text": "Vom Riesenturm her hinter Bergen,", "tokens": ["Vom", "Rie\u00b7sen\u00b7turm", "her", "hin\u00b7ter", "Ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War mir's, als k\u00e4m' ich zu den Zwergen,", "tokens": ["War", "mir's", ",", "als", "k\u00e4m'", "ich", "zu", "den", "Zwer\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "$,", "KOUS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Wo alles sich von selbst verstand,", "tokens": ["Wo", "al\u00b7les", "sich", "von", "selbst", "ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Gold wurde der Gartensand,", "tokens": ["Zu", "Gold", "wur\u00b7de", "der", "Gar\u00b7ten\u00b7sand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.74": {"line.1": {"text": "Die Rose f\u00e4llt dir in den Scho\u00df,", "tokens": ["Die", "Ro\u00b7se", "f\u00e4llt", "dir", "in", "den", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00d6ffnest du still die H\u00e4nde blo\u00df.", "tokens": ["\u00d6ff\u00b7nest", "du", "still", "die", "H\u00e4n\u00b7de", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Im Gl\u00fcck ich wie ein B\u00e4r mich fand,", "tokens": ["Im", "Gl\u00fcck", "ich", "wie", "ein", "B\u00e4r", "mich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "KOKOM", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ungl\u00fcck schien mir interessant,", "tokens": ["Un\u00b7gl\u00fcck", "schien", "mir", "in\u00b7ter\u00b7es\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.76": {"line.1": {"text": "Gl\u00fccklich zu sein, fand ich fast dumm", "tokens": ["Gl\u00fcck\u00b7lich", "zu", "sein", ",", "fand", "ich", "fast", "dumm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VAINF", "$,", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und sah mich gern nach Ungl\u00fcck um.", "tokens": ["Und", "sah", "mich", "gern", "nach", "Un\u00b7gl\u00fcck", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Ich tat nach ihren Augen birschen,", "tokens": ["Ich", "tat", "nach", "ih\u00b7ren", "Au\u00b7gen", "bir\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die hingen da schwarz wie Herzkirschen,", "tokens": ["Die", "hin\u00b7gen", "da", "schwarz", "wie", "Herz\u00b7kir\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+--+-++-", "measure": "iambic.tetra.relaxed"}}, "stanza.78": {"line.1": {"text": "Ich wollt' schon eine Leiter holen", "tokens": ["Ich", "wollt'", "schon", "ei\u00b7ne", "Lei\u00b7ter", "ho\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00e4tte wie als Bub' gestohlen.", "tokens": ["Und", "h\u00e4t\u00b7te", "wie", "als", "Bub'", "ge\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.79": {"line.1": {"text": "Pl\u00f6tzlich fiel sie mir in die Rede,", "tokens": ["Pl\u00f6tz\u00b7lich", "fiel", "sie", "mir", "in", "die", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Fragte: Welch Ohr ihr klingen t\u00e4te?", "tokens": ["Frag\u00b7te", ":", "Welch", "Ohr", "ihr", "klin\u00b7gen", "t\u00e4\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PIAT", "NN", "PPER", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.80": {"line.1": {"text": "Ob's rechts oder im linken sei?", "tokens": ["Ob's", "rechts", "o\u00b7der", "im", "lin\u00b7ken", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KON", "APPRART", "ADJA", "VAFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Mit Eile riet ich falsch dabei.", "tokens": ["Mit", "Ei\u00b7le", "riet", "ich", "falsch", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.81": {"line.1": {"text": "\u00bbdann wird jetzt schlecht von mir gesprochen,\u00ab", "tokens": ["\u00bb", "dann", "wird", "jetzt", "schlecht", "von", "mir", "ge\u00b7spro\u00b7chen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach sie und hat sacht abgebrochen,", "tokens": ["Sprach", "sie", "und", "hat", "sacht", "ab\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KON", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.82": {"line.1": {"text": "Meinte, sie k\u00f6nnt' nicht weitergehn,", "tokens": ["Mein\u00b7te", ",", "sie", "k\u00f6nnt'", "nicht", "wei\u00b7ter\u00b7gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie gr\u00fc\u00dfte, und ich durft' nachsehn.", "tokens": ["Sie", "gr\u00fc\u00df\u00b7te", ",", "und", "ich", "durft'", "nach\u00b7sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.83": {"line.1": {"text": "Ein Schicksal schon seit \u00d6dipus", "tokens": ["Ein", "Schick\u00b7sal", "schon", "seit", "\u00d6\u00b7di\u00b7pus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An jedem sich erf\u00fcllen mu\u00df,", "tokens": ["An", "je\u00b7dem", "sich", "er\u00b7f\u00fcl\u00b7len", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.84": {"line.1": {"text": "Und hier sei langsam euch enth\u00fcllt,", "tokens": ["Und", "hier", "sei", "lang\u00b7sam", "euch", "ent\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADJD", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Welch Schicksal sich an mir erf\u00fcllt.", "tokens": ["Welch", "Schick\u00b7sal", "sich", "an", "mir", "er\u00b7f\u00fcllt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PRF", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}}, "stanza.85": {"line.1": {"text": "Die Jahre gehen, wie man wei\u00df,", "tokens": ["Die", "Jah\u00b7re", "ge\u00b7hen", ",", "wie", "man", "wei\u00df", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Im Winter kalt, im Sommer hei\u00df.", "tokens": ["Im", "Win\u00b7ter", "kalt", ",", "im", "Som\u00b7mer", "hei\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.86": {"line.1": {"text": "Nicht nur mit hei\u00df und kalten Wangen,", "tokens": ["Nicht", "nur", "mit", "hei\u00df", "und", "kal\u00b7ten", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ADJD", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sind auch die Jahre mir vergangen.", "tokens": ["Sind", "auch", "die", "Jah\u00b7re", "mir", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.87": {"line.1": {"text": "Es war in meiner Vaterstadt,", "tokens": ["Es", "war", "in", "mei\u00b7ner", "Va\u00b7ter\u00b7stadt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort fand ein Wiedersehen statt,", "tokens": ["Dort", "fand", "ein", "Wie\u00b7der\u00b7se\u00b7hen", "statt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.88": {"line.1": {"text": "Um Folgen von dem Wiedersehn", "tokens": ["Um", "Fol\u00b7gen", "von", "dem", "Wie\u00b7der\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUI", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Tut sich das ganze Buch jetzt drehn.", "tokens": ["Tut", "sich", "das", "gan\u00b7ze", "Buch", "jetzt", "drehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "ART", "ADJA", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.89": {"line.1": {"text": "In meiner Stadt steht auch ein Schlo\u00df", "tokens": ["In", "mei\u00b7ner", "Stadt", "steht", "auch", "ein", "Schlo\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und drinnen wuchs der Amor gro\u00df,", "tokens": ["Und", "drin\u00b7nen", "wuchs", "der", "A\u00b7mor", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NE", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.90": {"line.1": {"text": "Bisch\u00f6fe bauten dieses Haus,", "tokens": ["Bi\u00b7sch\u00f6\u00b7fe", "bau\u00b7ten", "die\u00b7ses", "Haus", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und flott sieht's wie bei G\u00f6ttern aus.", "tokens": ["Und", "flott", "sieht's", "wie", "bei", "G\u00f6t\u00b7tern", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "KOKOM", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.91": {"line.1": {"text": "Dort sind Tanz-, Spiel- und Spiegelsaal,", "tokens": ["Dort", "sind", "Tanz", ",", "Spiel", "und", "Spie\u00b7gel\u00b7saal", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "TRUNC", "$,", "TRUNC", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und drei\u00dfig K\u00fcchen auf einmal.", "tokens": ["Und", "drei\u00b7\u00dfig", "K\u00fc\u00b7chen", "auf", "ein\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "APPR", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.92": {"line.1": {"text": "Dreihundert S\u00e4le gibt es nur,", "tokens": ["Drei\u00b7hun\u00b7dert", "S\u00e4\u00b7le", "gibt", "es", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo man genie\u00dft Gott und Natur.", "tokens": ["Wo", "man", "ge\u00b7nie\u00dft", "Gott", "und", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.93": {"line.1": {"text": "Im Garten, in versch\u00e4mten Lauben,", "tokens": ["Im", "Gar\u00b7ten", ",", "in", "ver\u00b7sch\u00e4m\u00b7ten", "Lau\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mu\u00df man an Seligkeiten glauben.", "tokens": ["Mu\u00df", "man", "an", "Se\u00b7lig\u00b7kei\u00b7ten", "glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.94": {"line.1": {"text": "S\u00fc\u00df Nacktes spielte hier Verstecken,", "tokens": ["S\u00fc\u00df", "Nack\u00b7tes", "spiel\u00b7te", "hier", "Ver\u00b7ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Amor lie\u00df sich gern entdecken.", "tokens": ["Und", "A\u00b7mor", "lie\u00df", "sich", "gern", "ent\u00b7de\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.95": {"line.1": {"text": "Ist er gemei\u00dfelt nur aus Stein,", "tokens": ["Ist", "er", "ge\u00b7mei\u00b7\u00dfelt", "nur", "aus", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fl\u00f6\u00dft er doch andern Leben ein.", "tokens": ["Fl\u00f6\u00dft", "er", "doch", "an\u00b7dern", "Le\u00b7ben", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.96": {"line.1": {"text": "Wein liegt hinter der Kellerpfort',", "tokens": ["Wein", "liegt", "hin\u00b7ter", "der", "Kel\u00b7ler\u00b7pfort'", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "Der tr\u00e4gt das Herz gar hitzig fort,", "tokens": ["Der", "tr\u00e4gt", "das", "Herz", "gar", "hit\u00b7zig", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.97": {"line.1": {"text": "Er bockt in Flaschen sehr markant,", "tokens": ["Er", "bockt", "in", "Fla\u00b7schen", "sehr", "mar\u00b7kant", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man hat Bocksbeutel ihn genannt.", "tokens": ["Man", "hat", "Bocks\u00b7beu\u00b7tel", "ihn", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "NE", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Und oft an hei\u00dfem Nachmittag,", "tokens": ["Und", "oft", "an", "hei\u00b7\u00dfem", "Nach\u00b7mit\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn Gott selbst nicht regieren mag,", "tokens": ["Wenn", "Gott", "selbst", "nicht", "re\u00b7gie\u00b7ren", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Tat Bischof und Pr\u00e4lat sich laben,", "tokens": ["Tat", "Bi\u00b7schof", "und", "Pr\u00e4\u00b7lat", "sich", "la\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "PRF", "VVINF", "$,"], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dem Wein sie die Regentschaft gaben.", "tokens": ["Dem", "Wein", "sie", "die", "Re\u00b7gent\u00b7schaft", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.100": {"line.1": {"text": "Mit Nichten und verwandten Damen", "tokens": ["Mit", "Nich\u00b7ten", "und", "ver\u00b7wand\u00b7ten", "Da\u00b7men"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Karussellsaal sie hinkamen,", "tokens": ["Zum", "Ka\u00b7rus\u00b7sell\u00b7saal", "sie", "hin\u00b7ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Die Pferdlein dort aus Holz nur sind,", "tokens": ["Die", "Pferd\u00b7lein", "dort", "aus", "Holz", "nur", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPR", "NN", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch dreht man sie, so macht das Wind.", "tokens": ["Doch", "dreht", "man", "sie", ",", "so", "macht", "das", "Wind", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PPER", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.102": {"line.1": {"text": "Denn war die Mahlzeit gar zu hei\u00df,", "tokens": ["Denn", "war", "die", "Mahl\u00b7zeit", "gar", "zu", "hei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00fchlt man sich gern den Erdenschwei\u00df.", "tokens": ["K\u00fchlt", "man", "sich", "gern", "den", "Er\u00b7den\u00b7schwei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PRF", "ADV", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.103": {"line.1": {"text": "Man nimmt die Damen auf den Scho\u00df,", "tokens": ["Man", "nimmt", "die", "Da\u00b7men", "auf", "den", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fromm ist stets ein lackiertes Ro\u00df,", "tokens": ["Fromm", "ist", "stets", "ein", "la\u00b7ckier\u00b7tes", "Ro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.104": {"line.1": {"text": "Und mit Musik dreht sich das Holz,", "tokens": ["Und", "mit", "Mu\u00b7sik", "dreht", "sich", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und jedes Pferdchen b\u00e4umt sich stolz.", "tokens": ["Und", "je\u00b7des", "Pferd\u00b7chen", "b\u00e4umt", "sich", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.105": {"line.1": {"text": "Die Dame, jung oder gereift,", "tokens": ["Die", "Da\u00b7me", ",", "jung", "o\u00b7der", "ge\u00b7reift", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Stets gern nach dem Bocksbeutel greift.", "tokens": ["Stets", "gern", "nach", "dem", "Bocks\u00b7beu\u00b7tel", "greift", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}}, "stanza.106": {"line.1": {"text": "Ein Bischof ist auch keine Kuh,", "tokens": ["Ein", "Bi\u00b7schof", "ist", "auch", "kei\u00b7ne", "Kuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hei\u00df trinkt er der Dame zu.", "tokens": ["Und", "hei\u00df", "trinkt", "er", "der", "Da\u00b7me", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.107": {"line.1": {"text": "\u00bbgebenedeit sei die Natur,", "tokens": ["\u00bb", "ge\u00b7be\u00b7ne\u00b7deit", "sei", "die", "Na\u00b7tur", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVPP", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Hebt hoch das Glas, ", "tokens": ["Hebt", "hoch", "das", "Glas", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.108": {"line.1": {"text": "Und die Pr\u00e4laten rufen's nach:", "tokens": ["Und", "die", "Pr\u00e4\u00b7la\u00b7ten", "ru\u00b7fen's", "nach", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.109": {"line.1": {"text": "Das Volk, das auf dem Schlo\u00dfplatz steht,", "tokens": ["Das", "Volk", ",", "das", "auf", "dem", "Schlo\u00df\u00b7platz", "steht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Franz\u00f6sisch nicht sofort versteht.", "tokens": ["Fran\u00b7z\u00f6\u00b7sisch", "nicht", "so\u00b7fort", "ver\u00b7steht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.110": {"line.1": {"text": "Hoch Schorle Morle, ruft es wieder,", "tokens": ["Hoch", "Schor\u00b7le", "Mor\u00b7le", ",", "ruft", "es", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und Amor steigt zum Volk hernieder.", "tokens": ["Und", "A\u00b7mor", "steigt", "zum", "Volk", "her\u00b7nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.111": {"line.1": {"text": "Kommt aus den Kellern dann die Nacht,", "tokens": ["Kommt", "aus", "den", "Kel\u00b7lern", "dann", "die", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie Rotwein rot jed' Fenster lacht. \u2013", "tokens": ["Wie", "Rot\u00b7wein", "rot", "jed'", "Fens\u00b7ter", "lacht", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "ADJD", "PIAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.112": {"line.1": {"text": "Heut ist's in Schlo\u00df und Garten still,", "tokens": ["Heut", "ist's", "in", "Schlo\u00df", "und", "Gar\u00b7ten", "still", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "KON", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der kleine Gott mal schlafen will.", "tokens": ["Der", "klei\u00b7ne", "Gott", "mal", "schla\u00b7fen", "will", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.113": {"line.1": {"text": "\u00bbhoch Schorle Morle,\u00ab dacht' ich laut,", "tokens": ["\u00bb", "hoch", "Schor\u00b7le", "Mor\u00b7le", ",", "\u00ab", "dacht'", "ich", "laut", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "NN", "$,", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weil's keiner sich zu rufen traut,", "tokens": ["Weil's", "kei\u00b7ner", "sich", "zu", "ru\u00b7fen", "traut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.114": {"line.1": {"text": "Denn offen ist dem Volk der Garten.", "tokens": ["Denn", "of\u00b7fen", "ist", "dem", "Volk", "der", "Gar\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Nachtigallen s\u00fc\u00df aufwarten", "tokens": ["Wo", "Nach\u00b7ti\u00b7gal\u00b7len", "s\u00fc\u00df", "auf\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "ADJD", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.115": {"line.1": {"text": "Und wo noch Amoretten stehn,", "tokens": ["Und", "wo", "noch", "A\u00b7mo\u00b7ret\u00b7ten", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da hatte ich ein Wiedersehn.", "tokens": ["Da", "hat\u00b7te", "ich", "ein", "Wie\u00b7der\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.116": {"line.1": {"text": "Ging in den Lauben auf und nieder,", "tokens": ["Ging", "in", "den", "Lau\u00b7ben", "auf", "und", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und ich erkannte jemand wieder.", "tokens": ["Und", "ich", "er\u00b7kann\u00b7te", "je\u00b7mand", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PIS", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.117": {"line.1": {"text": "Wir gingen rund um ein Bass\u00e4ng,", "tokens": ["Wir", "gin\u00b7gen", "rund", "um", "ein", "Bas\u00b7s\u00e4ng", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fast Aug' in Aug', der Weg war eng,", "tokens": ["Fast", "Aug'", "in", "Aug'", ",", "der", "Weg", "war", "eng", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NN", "$,", "ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.118": {"line.1": {"text": "Wie W\u00fcrfelaugen fiel ihr Blick,", "tokens": ["Wie", "W\u00fcr\u00b7fe\u00b7lau\u00b7gen", "fiel", "ihr", "Blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wir w\u00fcrfelten um mein Geschick.", "tokens": ["Wir", "w\u00fcr\u00b7fel\u00b7ten", "um", "mein", "Ge\u00b7schick", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.119": {"line.1": {"text": "Glieder spielten ihr wie die Reben,", "tokens": ["Glie\u00b7der", "spiel\u00b7ten", "ihr", "wie", "die", "Re\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Wo unter Bl\u00e4ttern Tr\u00e4ublein leben,", "tokens": ["Wo", "un\u00b7ter", "Bl\u00e4t\u00b7tern", "Tr\u00e4ub\u00b7lein", "le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.120": {"line.1": {"text": "Sie trug die Handschuh in der Hand,", "tokens": ["Sie", "trug", "die", "Hand\u00b7schuh", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Ehering war der bekannt,", "tokens": ["Kein", "E\u00b7he\u00b7ring", "war", "der", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ART", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.121": {"line.1": {"text": "Die H\u00e4nde wei\u00df wie Sahnenflecken", "tokens": ["Die", "H\u00e4n\u00b7de", "wei\u00df", "wie", "Sah\u00b7nen\u00b7fle\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mochte man gern vom Kleid ablecken.", "tokens": ["Moch\u00b7te", "man", "gern", "vom", "Kleid", "ab\u00b7le\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.122": {"line.1": {"text": "Sie klopft den Amor auf den Bauch", "tokens": ["Sie", "klopft", "den", "A\u00b7mor", "auf", "den", "Bauch"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus Stein in dem Akazienstrauch.", "tokens": ["Aus", "Stein", "in", "dem", "A\u00b7ka\u00b7zi\u00b7en\u00b7strauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.123": {"line.1": {"text": "Der alte Amor lachte froh,", "tokens": ["Der", "al\u00b7te", "A\u00b7mor", "lach\u00b7te", "froh", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm wackelt der Sandsteinpopo.", "tokens": ["Ihm", "wa\u00b7ckelt", "der", "Sand\u00b7ste\u00b7in\u00b7po\u00b7po", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.124": {"line.1": {"text": "\u00bbdu bist schon l\u00e4ngst ein Ehemann,\u00ab", "tokens": ["\u00bb", "du", "bist", "schon", "l\u00e4ngst", "ein", "E\u00b7he\u00b7mann", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach sie, \u00bbman sieht dir's gar nicht an.\u00ab", "tokens": ["Sprach", "sie", ",", "\u00bb", "man", "sieht", "dir's", "gar", "nicht", "an", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$,", "$(", "PIS", "VVFIN", "PIS", "ADV", "PTKNEG", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.125": {"line.1": {"text": "Sie fragte: \u00bbBist du gl\u00fccklich jetzt?\u00ab", "tokens": ["Sie", "frag\u00b7te", ":", "\u00bb", "Bist", "du", "gl\u00fcck\u00b7lich", "jetzt", "?", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VAFIN", "PPER", "ADJD", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und hat sich auf die Bank gesetzt.", "tokens": ["Und", "hat", "sich", "auf", "die", "Bank", "ge\u00b7setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PRF", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Ich setzte mich ganz still daneben,", "tokens": ["Ich", "setz\u00b7te", "mich", "ganz", "still", "da\u00b7ne\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "PAV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach: \u00bbGl\u00fccklich bin ich f\u00fcr das Leben.\u00ab", "tokens": ["Sprach", ":", "\u00bb", "Gl\u00fcck\u00b7lich", "bin", "ich", "f\u00fcr", "das", "Le\u00b7ben", ".", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$.", "$(", "ADJD", "VAFIN", "PPER", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.127": {"line.1": {"text": "Fragte nicht, ob sie gl\u00fccklich ist,", "tokens": ["Frag\u00b7te", "nicht", ",", "ob", "sie", "gl\u00fcck\u00b7lich", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "KOUS", "PPER", "ADJD", "VAFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie sprach: \u00bbIch freu' mich, wenn du's bist.\u00ab", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "freu'", "mich", ",", "wenn", "du's", "bist", ".", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "PPER", "$,", "KOUS", "PIS", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.128": {"line.1": {"text": "Schwarz war sie wie ein Mohrenkind,", "tokens": ["Schwarz", "war", "sie", "wie", "ein", "Moh\u00b7ren\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die ganz schwarz durch und durch stets sind.", "tokens": ["Die", "ganz", "schwarz", "durch", "und", "durch", "stets", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "KON", "APPR", "ADV", "VAFIN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}}, "stanza.129": {"line.1": {"text": "Wenn ich mein Alter r\u00fcckw\u00e4rts schiebe,", "tokens": ["Wenn", "ich", "mein", "Al\u00b7ter", "r\u00fcck\u00b7w\u00e4rts", "schie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War sie einst meine Jugendliebe.", "tokens": ["War", "sie", "einst", "mei\u00b7ne", "Ju\u00b7gend\u00b7lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.130": {"line.1": {"text": "Damals stand bei der Stadt ein Haus,", "tokens": ["Da\u00b7mals", "stand", "bei", "der", "Stadt", "ein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.2": {"text": "Ein Mohrenkopf sah dort heraus,", "tokens": ["Ein", "Moh\u00b7ren\u00b7kopf", "sah", "dort", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.131": {"line.1": {"text": "Ich kam dort oft zu ihrer Mutter,", "tokens": ["Ich", "kam", "dort", "oft", "zu", "ih\u00b7rer", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bestellend f\u00fcr den Vater Butter.", "tokens": ["Be\u00b7stel\u00b7lend", "f\u00fcr", "den", "Va\u00b7ter", "But\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.132": {"line.1": {"text": "Der Mohrenkopf war n\u00e4mlich keiner,", "tokens": ["Der", "Moh\u00b7ren\u00b7kopf", "war", "n\u00e4m\u00b7lich", "kei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "PIS", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein M\u00e4dchen war er, braun und br\u00e4uner,", "tokens": ["Ein", "M\u00e4d\u00b7chen", "war", "er", ",", "braun", "und", "br\u00e4u\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ADJD", "KON", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.133": {"line.1": {"text": "Mit echten Locken, ungelogen,", "tokens": ["Mit", "ech\u00b7ten", "Lo\u00b7cken", ",", "un\u00b7ge\u00b7lo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich hab's probiert und dran gezogen;", "tokens": ["Ich", "hab's", "pro\u00b7biert", "und", "dran", "ge\u00b7zo\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "VVFIN", "KON", "PAV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.134": {"line.1": {"text": "Wie Hobelsp\u00e4ne kraus, doch schwarz,", "tokens": ["Wie", "Ho\u00b7bel\u00b7sp\u00e4\u00b7ne", "kraus", ",", "doch", "schwarz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "NN", "PTKVZ", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gl\u00e4nzend wie am Baum das Harz.", "tokens": ["Und", "gl\u00e4n\u00b7zend", "wie", "am", "Baum", "das", "Harz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.135": {"line.1": {"text": "Mit ihr durft ich zum Stall hingehn,", "tokens": ["Mit", "ihr", "durft", "ich", "zum", "Stall", "hin\u00b7gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "PPER", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und K\u00fche in der N\u00e4he sehn,", "tokens": ["Und", "K\u00fc\u00b7he", "in", "der", "N\u00e4\u00b7he", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.136": {"line.1": {"text": "Sie wohnte n\u00e4mlich mehr am Land,", "tokens": ["Sie", "wohn\u00b7te", "n\u00e4m\u00b7lich", "mehr", "am", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich selber war nur stadtbekannt.", "tokens": ["Ich", "sel\u00b7ber", "war", "nur", "stadt\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.137": {"line.1": {"text": "Im Kuhstall war's gar liebesam,", "tokens": ["Im", "Kuh\u00b7stall", "wa\u00b7r's", "gar", "lie\u00b7be\u00b7sam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Irdischer Duft mein Herz benahm,", "tokens": ["Ir\u00b7di\u00b7scher", "Duft", "mein", "Herz", "be\u00b7nahm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.138": {"line.1": {"text": "Ich war ein Knabe, sie ein Kind,", "tokens": ["Ich", "war", "ein", "Kna\u00b7be", ",", "sie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und jener Duft, der kam vom Rind.", "tokens": ["Und", "je\u00b7ner", "Duft", ",", "der", "kam", "vom", "Rind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "$,", "PRELS", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.139": {"line.1": {"text": "Sie war elf Jahre, ich dreizehn,", "tokens": ["Sie", "war", "elf", "Jah\u00b7re", ",", "ich", "drei\u00b7zehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "CARD", "NN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich lernte eben das Rauchen,", "tokens": ["Ich", "lern\u00b7te", "e\u00b7ben", "das", "Rau\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.140": {"line.1": {"text": "Wir suchten dunkle Ecken aus,", "tokens": ["Wir", "such\u00b7ten", "dunk\u00b7le", "E\u00b7cken", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dort waren wir mehr als zu Haus.", "tokens": ["Dort", "wa\u00b7ren", "wir", "mehr", "als", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "KOKOM", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.141": {"line.1": {"text": "Den ersten Ku\u00df, von dem man spricht,", "tokens": ["Den", "ers\u00b7ten", "Ku\u00df", ",", "von", "dem", "man", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPR", "PRELS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gab ich ihr in das Angesicht,", "tokens": ["Gab", "ich", "ihr", "in", "das", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.142": {"line.1": {"text": "Doch, sagte sie, da\u00df sie sich sch\u00e4me,", "tokens": ["Doch", ",", "sag\u00b7te", "sie", ",", "da\u00df", "sie", "sich", "sch\u00e4\u00b7me", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VVFIN", "PPER", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weil leicht ein Kind beim K\u00fcssen k\u00e4me.", "tokens": ["Weil", "leicht", "ein", "Kind", "beim", "K\u00fcs\u00b7sen", "k\u00e4\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.143": {"line.1": {"text": "Das war die Ansicht ihrerseits,", "tokens": ["Das", "war", "die", "An\u00b7sicht", "ih\u00b7rer\u00b7seits", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich selber wu\u00dfte mehr bereits,", "tokens": ["Ich", "sel\u00b7ber", "wu\u00df\u00b7te", "mehr", "be\u00b7reits", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.144": {"line.1": {"text": "Ich sagte, da\u00df es nicht so w\u00e4r',", "tokens": ["Ich", "sag\u00b7te", ",", "da\u00df", "es", "nicht", "so", "w\u00e4r'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie aber wollte mal nicht mehr.", "tokens": ["Sie", "a\u00b7ber", "woll\u00b7te", "mal", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "ADV", "PTKNEG", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.145": {"line.1": {"text": "Und jeden Tag ging Balthasar", "tokens": ["Und", "je\u00b7den", "Tag", "ging", "Balt\u00b7ha\u00b7sar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zum Mohrenkopf, der keiner war.", "tokens": ["Zum", "Moh\u00b7ren\u00b7kopf", ",", "der", "kei\u00b7ner", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "PIS", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.146": {"line.1": {"text": "Da\u00df ich genehm auch ihrer Mutter,", "tokens": ["Da\u00df", "ich", "ge\u00b7nehm", "auch", "ih\u00b7rer", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Bestellt' ich t\u00e4glich viele Butter.", "tokens": ["Be\u00b7stellt'", "ich", "t\u00e4g\u00b7lich", "vie\u00b7le", "But\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.147": {"line.1": {"text": "Was t\u00e4glich da an Butter war,", "tokens": ["Was", "t\u00e4g\u00b7lich", "da", "an", "But\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das kaufte ich und zahlte bar.", "tokens": ["Das", "kauf\u00b7te", "ich", "und", "zahl\u00b7te", "bar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.148": {"line.1": {"text": "Denn ich versetzte, was ich hatte,", "tokens": ["Denn", "ich", "ver\u00b7setz\u00b7te", ",", "was", "ich", "hat\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sogar am Bett die Vorlegmatte.", "tokens": ["So\u00b7gar", "am", "Bett", "die", "Vor\u00b7leg\u00b7mat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.149": {"line.1": {"text": "Doch da die Butter leicht verdirbt,", "tokens": ["Doch", "da", "die", "But\u00b7ter", "leicht", "ver\u00b7dirbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die man von K\u00fchen sich erwirbt,", "tokens": ["Die", "man", "von", "K\u00fc\u00b7hen", "sich", "er\u00b7wirbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.150": {"line.1": {"text": "Und da\u00df der Vater nichts erf\u00fchre,", "tokens": ["Und", "da\u00df", "der", "Va\u00b7ter", "nichts", "er\u00b7f\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Legt' ich's bei H\u00e4usern in die T\u00fcre.", "tokens": ["Legt'", "ich's", "bei", "H\u00e4u\u00b7sern", "in", "die", "T\u00fc\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.151": {"line.1": {"text": "So wie man Findelkinder macht,", "tokens": ["So", "wie", "man", "Fin\u00b7del\u00b7kin\u00b7der", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "PIS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wenn man die T\u00fcren nicht bewacht.", "tokens": ["Wenn", "man", "die", "T\u00fc\u00b7ren", "nicht", "be\u00b7wacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.152": {"line.1": {"text": "Dies Mohrle sah ich pl\u00f6tzlich wieder,", "tokens": ["Dies", "Mohr\u00b7le", "sah", "ich", "pl\u00f6tz\u00b7lich", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Da sang mein Herze Bubenlieder,", "tokens": ["Da", "sang", "mein", "Her\u00b7ze", "Bu\u00b7ben\u00b7lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.153": {"line.1": {"text": "Auf einmal war das ganze Land", "tokens": ["Auf", "ein\u00b7mal", "war", "das", "gan\u00b7ze", "Land"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie ein Spielkasten mir bekannt.", "tokens": ["Wie", "ein", "Spiel\u00b7kas\u00b7ten", "mir", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.154": {"line.1": {"text": "Vom Riesenturm her hinter Bergen,", "tokens": ["Vom", "Rie\u00b7sen\u00b7turm", "her", "hin\u00b7ter", "Ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APZR", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "War mir's, als k\u00e4m' ich zu den Zwergen,", "tokens": ["War", "mir's", ",", "als", "k\u00e4m'", "ich", "zu", "den", "Zwer\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "$,", "KOUS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.155": {"line.1": {"text": "Wo alles sich von selbst verstand,", "tokens": ["Wo", "al\u00b7les", "sich", "von", "selbst", "ver\u00b7stand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PRF", "APPR", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Gold wurde der Gartensand,", "tokens": ["Zu", "Gold", "wur\u00b7de", "der", "Gar\u00b7ten\u00b7sand", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}}, "stanza.156": {"line.1": {"text": "Die Rose f\u00e4llt dir in den Scho\u00df,", "tokens": ["Die", "Ro\u00b7se", "f\u00e4llt", "dir", "in", "den", "Scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00d6ffnest du still die H\u00e4nde blo\u00df.", "tokens": ["\u00d6ff\u00b7nest", "du", "still", "die", "H\u00e4n\u00b7de", "blo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.157": {"line.1": {"text": "Im Gl\u00fcck ich wie ein B\u00e4r mich fand,", "tokens": ["Im", "Gl\u00fcck", "ich", "wie", "ein", "B\u00e4r", "mich", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "KOKOM", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ungl\u00fcck schien mir interessant,", "tokens": ["Un\u00b7gl\u00fcck", "schien", "mir", "in\u00b7ter\u00b7es\u00b7sant", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.158": {"line.1": {"text": "Gl\u00fccklich zu sein, fand ich fast dumm", "tokens": ["Gl\u00fcck\u00b7lich", "zu", "sein", ",", "fand", "ich", "fast", "dumm"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "PTKZU", "VAINF", "$,", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und sah mich gern nach Ungl\u00fcck um.", "tokens": ["Und", "sah", "mich", "gern", "nach", "Un\u00b7gl\u00fcck", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.159": {"line.1": {"text": "Ich tat nach ihren Augen birschen,", "tokens": ["Ich", "tat", "nach", "ih\u00b7ren", "Au\u00b7gen", "bir\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die hingen da schwarz wie Herzkirschen,", "tokens": ["Die", "hin\u00b7gen", "da", "schwarz", "wie", "Herz\u00b7kir\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+--+-++-", "measure": "iambic.tetra.relaxed"}}, "stanza.160": {"line.1": {"text": "Ich wollt' schon eine Leiter holen", "tokens": ["Ich", "wollt'", "schon", "ei\u00b7ne", "Lei\u00b7ter", "ho\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00e4tte wie als Bub' gestohlen.", "tokens": ["Und", "h\u00e4t\u00b7te", "wie", "als", "Bub'", "ge\u00b7stoh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.161": {"line.1": {"text": "Pl\u00f6tzlich fiel sie mir in die Rede,", "tokens": ["Pl\u00f6tz\u00b7lich", "fiel", "sie", "mir", "in", "die", "Re\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.2": {"text": "Fragte: Welch Ohr ihr klingen t\u00e4te?", "tokens": ["Frag\u00b7te", ":", "Welch", "Ohr", "ihr", "klin\u00b7gen", "t\u00e4\u00b7te", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "PIAT", "NN", "PPER", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.162": {"line.1": {"text": "Ob's rechts oder im linken sei?", "tokens": ["Ob's", "rechts", "o\u00b7der", "im", "lin\u00b7ken", "sei", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "KON", "APPRART", "ADJA", "VAFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.2": {"text": "Mit Eile riet ich falsch dabei.", "tokens": ["Mit", "Ei\u00b7le", "riet", "ich", "falsch", "da\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADJD", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.163": {"line.1": {"text": "\u00bbdann wird jetzt schlecht von mir gesprochen,\u00ab", "tokens": ["\u00bb", "dann", "wird", "jetzt", "schlecht", "von", "mir", "ge\u00b7spro\u00b7chen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VAFIN", "ADV", "ADJD", "APPR", "PPER", "VVPP", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach sie und hat sacht abgebrochen,", "tokens": ["Sprach", "sie", "und", "hat", "sacht", "ab\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "KON", "VAFIN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.164": {"line.1": {"text": "Meinte, sie k\u00f6nnt' nicht weitergehn,", "tokens": ["Mein\u00b7te", ",", "sie", "k\u00f6nnt'", "nicht", "wei\u00b7ter\u00b7gehn", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PPER", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Sie gr\u00fc\u00dfte, und ich durft' nachsehn.", "tokens": ["Sie", "gr\u00fc\u00df\u00b7te", ",", "und", "ich", "durft'", "nach\u00b7sehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}