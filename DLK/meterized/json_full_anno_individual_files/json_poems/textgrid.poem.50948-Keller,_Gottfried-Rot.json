{"textgrid.poem.50948": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "Rot", "genre": "verse", "period": "N.A.", "pub_year": 1850, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbich bin rot und hab's erwogen", "tokens": ["\u00bb", "ich", "bin", "rot", "und", "hab's", "er\u00b7wo\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "KON", "NE", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und verk\u00fcnd es unverweilt!", "tokens": ["Und", "ver\u00b7k\u00fcnd", "es", "un\u00b7ver\u00b7weilt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gek\u00f6pft sei jeder, welcher", "tokens": ["Und", "ge\u00b7k\u00f6pft", "sei", "je\u00b7der", ",", "wel\u00b7cher"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVPP", "VAFIN", "PIS", "$,", "PRELS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Prinzip nicht mit mir teilt!\u00ab", "tokens": ["Das", "Prin\u00b7zip", "nicht", "mit", "mir", "teilt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Also in des Baders Stube", "tokens": ["Al\u00b7so", "in", "des", "Ba\u00b7ders", "Stu\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rt ich einen, der dies sprach,", "tokens": ["H\u00f6rt", "ich", "ei\u00b7nen", ",", "der", "dies", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "$,", "PRELS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eben als 'nem feisten B\u00e4cker", "tokens": ["E\u00b7ben", "als", "'nem", "feis\u00b7ten", "B\u00e4\u00b7cker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jener in die Ader stach.", "tokens": ["Je\u00b7ner", "in", "die", "A\u00b7der", "stach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und des Blutes muntrer Bogen", "tokens": ["Und", "des", "Blu\u00b7tes", "mun\u00b7trer", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem dicken drallen Arm", "tokens": ["Aus", "dem", "di\u00b7cken", "dral\u00b7len", "Arm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fiel dem Sprecher auf die Nase,", "tokens": ["Fiel", "dem", "Spre\u00b7cher", "auf", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie begr\u00fc\u00dfend freundlich warm!", "tokens": ["Sie", "be\u00b7gr\u00fc\u00b7\u00dfend", "freund\u00b7lich", "warm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Bleich entsetzt fuhr er zusammen,", "tokens": ["Bleich", "ent\u00b7setzt", "fuhr", "er", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wusch darauf sich siebenmal;", "tokens": ["Wusch", "da\u00b7rauf", "sich", "sie\u00b7ben\u00b7mal", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "PRF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch noch lang r\u00fcmpft' sich die Nase,", "tokens": ["Doch", "noch", "lang", "r\u00fcmpft'", "sich", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.4": {"text": "F\u00fchlt' noch lang den warmen Strahl.", "tokens": ["F\u00fchlt'", "noch", "lang", "den", "war\u00b7men", "Strahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Eine Ros' im Wetterscheine", "tokens": ["Ei\u00b7ne", "Ros'", "im", "Wet\u00b7ter\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sah ich bl\u00fchen brennend rot;", "tokens": ["Sah", "ich", "bl\u00fc\u00b7hen", "bren\u00b7nend", "rot", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Becher sah ich gl\u00fchen,", "tokens": ["Ei\u00b7nen", "Be\u00b7cher", "sah", "ich", "gl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der noch tiefre R\u00f6te bot!", "tokens": ["Der", "noch", "tief\u00b7re", "R\u00f6\u00b7te", "bot", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Aber rief etwa die Knospe", "tokens": ["A\u00b7ber", "rief", "et\u00b7wa", "die", "Knos\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vorher, da\u00df sie rot wollt sein?", "tokens": ["Vor\u00b7her", ",", "da\u00df", "sie", "rot", "wollt", "sein", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Schrie der junge gr\u00fcne Weinstock:", "tokens": ["Schrie", "der", "jun\u00b7ge", "gr\u00fc\u00b7ne", "Wein\u00b7stock", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich will geben roten Wein?", "tokens": ["Ich", "will", "ge\u00b7ben", "ro\u00b7ten", "Wein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.7": {"line.1": {"text": "Nein, der ewig goldengr\u00fcne", "tokens": ["Nein", ",", "der", "e\u00b7wig", "gol\u00b7den\u00b7gr\u00fc\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PRELS", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Baum des Lebens tut das nie,", "tokens": ["Baum", "des", "Le\u00b7bens", "tut", "das", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das tut nur die ewig graue,", "tokens": ["Das", "tut", "nur", "die", "e\u00b7wig", "grau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJD", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Graue Eselstheorie!", "tokens": ["Grau\u00b7e", "E\u00b7sel\u00b7sthe\u00b7o\u00b7rie", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Manches Br\u00fcnnlein mag noch springen", "tokens": ["Man\u00b7ches", "Br\u00fcnn\u00b7lein", "mag", "noch", "sprin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In das Gras mit rotem Schein;", "tokens": ["In", "das", "Gras", "mit", "ro\u00b7tem", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch der Freiheit echter, rechter", "tokens": ["Doch", "der", "Frei\u00b7heit", "ech\u00b7ter", ",", "rech\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "ADJD", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Letzter Sieg wird trocken sein.", "tokens": ["Letz\u00b7ter", "Sieg", "wird", "tro\u00b7cken", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "\u00bbich bin rot und hab's erwogen", "tokens": ["\u00bb", "ich", "bin", "rot", "und", "hab's", "er\u00b7wo\u00b7gen"], "token_info": ["punct", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "KON", "NE", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und verk\u00fcnd es unverweilt!", "tokens": ["Und", "ver\u00b7k\u00fcnd", "es", "un\u00b7ver\u00b7weilt", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und gek\u00f6pft sei jeder, welcher", "tokens": ["Und", "ge\u00b7k\u00f6pft", "sei", "je\u00b7der", ",", "wel\u00b7cher"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVPP", "VAFIN", "PIS", "$,", "PRELS"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Das Prinzip nicht mit mir teilt!\u00ab", "tokens": ["Das", "Prin\u00b7zip", "nicht", "mit", "mir", "teilt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKNEG", "APPR", "PPER", "VVFIN", "$.", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Also in des Baders Stube", "tokens": ["Al\u00b7so", "in", "des", "Ba\u00b7ders", "Stu\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00f6rt ich einen, der dies sprach,", "tokens": ["H\u00f6rt", "ich", "ei\u00b7nen", ",", "der", "dies", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "$,", "PRELS", "PDS", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Eben als 'nem feisten B\u00e4cker", "tokens": ["E\u00b7ben", "als", "'nem", "feis\u00b7ten", "B\u00e4\u00b7cker"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Jener in die Ader stach.", "tokens": ["Je\u00b7ner", "in", "die", "A\u00b7der", "stach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und des Blutes muntrer Bogen", "tokens": ["Und", "des", "Blu\u00b7tes", "mun\u00b7trer", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Aus dem dicken drallen Arm", "tokens": ["Aus", "dem", "di\u00b7cken", "dral\u00b7len", "Arm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Fiel dem Sprecher auf die Nase,", "tokens": ["Fiel", "dem", "Spre\u00b7cher", "auf", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie begr\u00fc\u00dfend freundlich warm!", "tokens": ["Sie", "be\u00b7gr\u00fc\u00b7\u00dfend", "freund\u00b7lich", "warm", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Bleich entsetzt fuhr er zusammen,", "tokens": ["Bleich", "ent\u00b7setzt", "fuhr", "er", "zu\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wusch darauf sich siebenmal;", "tokens": ["Wusch", "da\u00b7rauf", "sich", "sie\u00b7ben\u00b7mal", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PAV", "PRF", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch noch lang r\u00fcmpft' sich die Nase,", "tokens": ["Doch", "noch", "lang", "r\u00fcmpft'", "sich", "die", "Na\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "--++-+-+", "measure": "anapaest.init"}, "line.4": {"text": "F\u00fchlt' noch lang den warmen Strahl.", "tokens": ["F\u00fchlt'", "noch", "lang", "den", "war\u00b7men", "Strahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Eine Ros' im Wetterscheine", "tokens": ["Ei\u00b7ne", "Ros'", "im", "Wet\u00b7ter\u00b7schei\u00b7ne"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sah ich bl\u00fchen brennend rot;", "tokens": ["Sah", "ich", "bl\u00fc\u00b7hen", "bren\u00b7nend", "rot", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVFIN", "ADJD", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Einen Becher sah ich gl\u00fchen,", "tokens": ["Ei\u00b7nen", "Be\u00b7cher", "sah", "ich", "gl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der noch tiefre R\u00f6te bot!", "tokens": ["Der", "noch", "tief\u00b7re", "R\u00f6\u00b7te", "bot", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Aber rief etwa die Knospe", "tokens": ["A\u00b7ber", "rief", "et\u00b7wa", "die", "Knos\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Vorher, da\u00df sie rot wollt sein?", "tokens": ["Vor\u00b7her", ",", "da\u00df", "sie", "rot", "wollt", "sein", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "ADJD", "VMFIN", "VAINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Schrie der junge gr\u00fcne Weinstock:", "tokens": ["Schrie", "der", "jun\u00b7ge", "gr\u00fc\u00b7ne", "Wein\u00b7stock", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich will geben roten Wein?", "tokens": ["Ich", "will", "ge\u00b7ben", "ro\u00b7ten", "Wein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "VVINF", "ADJA", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.15": {"line.1": {"text": "Nein, der ewig goldengr\u00fcne", "tokens": ["Nein", ",", "der", "e\u00b7wig", "gol\u00b7den\u00b7gr\u00fc\u00b7ne"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "PRELS", "ADJD", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Baum des Lebens tut das nie,", "tokens": ["Baum", "des", "Le\u00b7bens", "tut", "das", "nie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "VVFIN", "PDS", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das tut nur die ewig graue,", "tokens": ["Das", "tut", "nur", "die", "e\u00b7wig", "grau\u00b7e", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJD", "ADJA", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Graue Eselstheorie!", "tokens": ["Grau\u00b7e", "E\u00b7sel\u00b7sthe\u00b7o\u00b7rie", "!"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Manches Br\u00fcnnlein mag noch springen", "tokens": ["Man\u00b7ches", "Br\u00fcnn\u00b7lein", "mag", "noch", "sprin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "ADV", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In das Gras mit rotem Schein;", "tokens": ["In", "das", "Gras", "mit", "ro\u00b7tem", "Schein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch der Freiheit echter, rechter", "tokens": ["Doch", "der", "Frei\u00b7heit", "ech\u00b7ter", ",", "rech\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["KON", "ART", "NN", "ADJD", "$,", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Letzter Sieg wird trocken sein.", "tokens": ["Letz\u00b7ter", "Sieg", "wird", "tro\u00b7cken", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}