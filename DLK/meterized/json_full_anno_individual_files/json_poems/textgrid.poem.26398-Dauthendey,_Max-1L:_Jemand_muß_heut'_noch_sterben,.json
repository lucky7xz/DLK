{"textgrid.poem.26398": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "1L: Jemand mu\u00df heut' noch sterben,", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jemand mu\u00df heut' noch sterben,", "tokens": ["Je\u00b7mand", "mu\u00df", "heut'", "noch", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Hund heult so heut' Nacht!", "tokens": ["Ein", "Hund", "heult", "so", "heut'", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Z\u00e4hn' klappern wie Scherben,", "tokens": ["Die", "Z\u00e4hn'", "klap\u00b7pern", "wie", "Scher\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jed' Amme Kreuze macht.", "tokens": ["Jed'", "Am\u00b7me", "Kreu\u00b7ze", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "In sich geb\u00fcckt wie Kn\u00e4ule", "tokens": ["In", "sich", "ge\u00b7b\u00fcckt", "wie", "Kn\u00e4u\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "VVPP", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zwei Kreuz' noch Jede macht.", "tokens": ["Zwei", "Kreuz'", "noch", "Je\u00b7de", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Endlos ist's Hundsgeheule,", "tokens": ["End\u00b7los", "ist's", "Hunds\u00b7ge\u00b7heu\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja, Jemand stirbt heut Nacht! \u2013", "tokens": ["Ja", ",", "Je\u00b7mand", "stirbt", "heut", "Nacht", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "PIS", "VVFIN", "ADV", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Und eine Amme wieder", "tokens": ["Und", "ei\u00b7ne", "Am\u00b7me", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach: \u00bbAlles nimmt ein End,", "tokens": ["Sprach", ":", "\u00bb", "Al\u00b7les", "nimmt", "ein", "End", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Enden tun alle Lieder,", "tokens": ["En\u00b7den", "tun", "al\u00b7le", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Man ist das schon gew\u00f6hnt.", "tokens": ["Man", "ist", "das", "schon", "ge\u00b7w\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Durch Horchen h\u00f6rt man eben,", "tokens": ["Durch", "Hor\u00b7chen", "h\u00f6rt", "man", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie man beim Reden spricht.", "tokens": ["Wie", "man", "beim", "Re\u00b7den", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz w\u00e4r' heut' noch am Leben,", "tokens": ["Heinz", "w\u00e4r'", "heut'", "noch", "am", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Horchte Babette nicht.", "tokens": ["Horch\u00b7te", "Ba\u00b7bet\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "$."], "meter": "+----+", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "So denk' ich mir das Ganze:", "tokens": ["So", "denk'", "ich", "mir", "das", "Gan\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Teufel war im Spiel.", "tokens": ["Der", "Teu\u00b7fel", "war", "im", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Oft sitzt an einer Wanze", "tokens": ["Oft", "sitzt", "an", "ei\u00b7ner", "Wan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Pech, wann er es will.\u00ab", "tokens": ["Sein", "Pech", ",", "wann", "er", "es", "will", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPER", "PPER", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Die sieben andern Ammen", "tokens": ["Die", "sie\u00b7ben", "an\u00b7dern", "Am\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mu\u00dften ans Herz sich fassen.", "tokens": ["Mu\u00df\u00b7ten", "ans", "Herz", "sich", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie r\u00fcckten eng zusammen", "tokens": ["Sie", "r\u00fcck\u00b7ten", "eng", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und stellten fort die Tassen.", "tokens": ["Und", "stell\u00b7ten", "fort", "die", "Tas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Babett tut Schornstein fegen,", "tokens": ["Ba\u00b7bett", "tut", "Schorn\u00b7stein", "fe\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wird Schornsteinrat genannt.", "tokens": ["Wird", "Schorn\u00b7stein\u00b7rat", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und schwarz ist sie deswegen", "tokens": ["Und", "schwarz", "ist", "sie", "des\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dadurch stadtbekannt.", "tokens": ["Und", "da\u00b7durch", "stadt\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Einmal da rutscht sie 'runter,", "tokens": ["Ein\u00b7mal", "da", "rutscht", "sie", "'r\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NE", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Herrn Heinz just in die Arm'.", "tokens": ["Herrn", "Heinz", "just", "in", "die", "Arm'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Dach fiel sie hinunter,", "tokens": ["Vom", "Dach", "fiel", "sie", "hin\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Noch war sie ganz ru\u00dfwarm.", "tokens": ["Noch", "war", "sie", "ganz", "ru\u00df\u00b7warm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Er trug sie in sein Zimmer", "tokens": ["Er", "trug", "sie", "in", "sein", "Zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wusch sie etwas klar.", "tokens": ["Und", "wusch", "sie", "et\u00b7was", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und daraus ward was schlimmer,", "tokens": ["Und", "da\u00b7raus", "ward", "was", "schlim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Etwas, was furchtbar war.", "tokens": ["Et\u00b7was", ",", "was", "furcht\u00b7bar", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "N\u00e4mlich 'ne Mordgeschichte", "tokens": ["N\u00e4m\u00b7lich", "'ne", "Mord\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Entstand aus diesem Akt.", "tokens": ["Ent\u00b7stand", "aus", "die\u00b7sem", "Ak\u00b7t."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["NN", "APPR", "PDAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Vorher da schlo\u00df im Schornstein", "tokens": ["Vor\u00b7her", "da", "schlo\u00df", "im", "Schorn\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der Teufel seinen Pakt.", "tokens": ["Der", "Teu\u00b7fel", "sei\u00b7nen", "Pakt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Teufel kam gekrochen,", "tokens": ["Der", "Teu\u00b7fel", "kam", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach: \u00bbBabett, kriegst 'nen Mann,", "tokens": ["Sprach", ":", "\u00bb", "Ba\u00b7bett", ",", "kriegst", "'nen", "Mann", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn nach so'n so viel Wochen", "tokens": ["Wenn", "nach", "so'n", "so", "viel", "Wo\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADV", "ADV", "PIAT", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Ich mir ihn holen kann.", "tokens": ["Ich", "mir", "ihn", "ho\u00b7len", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Du mu\u00dft ihm dann erz\u00e4hlen,", "tokens": ["Du", "mu\u00dft", "ihm", "dann", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was ich Dir sagen tu.", "tokens": ["Was", "ich", "Dir", "sa\u00b7gen", "tu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn nur so darfst Du w\u00e4hlen", "tokens": ["Denn", "nur", "so", "darfst", "Du", "w\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und gibst dem Teufel Ruh.", "tokens": ["Und", "gibst", "dem", "Teu\u00b7fel", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Daf\u00fcr darfst Du auch k\u00fcssen,", "tokens": ["Da\u00b7f\u00fcr", "darfst", "Du", "auch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kriegst einen ganzen Mann.", "tokens": ["Kriegst", "ei\u00b7nen", "gan\u00b7zen", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du kannst nichts Be\u00dfres m\u00fcssen.\u00ab", "tokens": ["Du", "kannst", "nichts", "Be\u00df\u00b7res", "m\u00fcs\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PIS", "VMFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was liegt der Babett d'ran!", "tokens": ["Was", "liegt", "der", "Ba\u00b7bett", "d'\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "Kaum ist sie einverstanden,", "tokens": ["Kaum", "ist", "sie", "ein\u00b7ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schmei\u00dft Jemand sie vom Dach.", "tokens": ["Schmei\u00dft", "Je\u00b7mand", "sie", "vom", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie tut bei Heinzen landen \u2013", "tokens": ["Sie", "tut", "bei", "Hein\u00b7zen", "lan\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Teufel sieht ihr nach.", "tokens": ["Der", "Teu\u00b7fel", "sieht", "ihr", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Der Heinz hat sie gewaschen,", "tokens": ["Der", "Heinz", "hat", "sie", "ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und als sie rein genug,", "tokens": ["Und", "als", "sie", "rein", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "L\u00e4\u00dft sie Heinz K\u00fcsse naschen,", "tokens": ["L\u00e4\u00dft", "sie", "Heinz", "K\u00fcs\u00b7se", "na\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nascht selber zart und klug.", "tokens": ["Nascht", "sel\u00b7ber", "zart", "und", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Bald lebten sie wie Tauben,", "tokens": ["Bald", "leb\u00b7ten", "sie", "wie", "Tau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie liebte selbstbewu\u00dft,", "tokens": ["Sie", "lieb\u00b7te", "selbst\u00b7be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Tat seine Lampen schrauben,", "tokens": ["Tat", "sei\u00b7ne", "Lam\u00b7pen", "schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Wenn eine Lampe ru\u00dft.", "tokens": ["Wenn", "ei\u00b7ne", "Lam\u00b7pe", "ru\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Des Morgens stieg sie wieder", "tokens": ["Des", "Mor\u00b7gens", "stieg", "sie", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zum Schornsteine hinauf,", "tokens": ["Zum", "Schorn\u00b7stei\u00b7ne", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,"], "meter": "-+---+", "measure": "dactylic.init"}, "line.3": {"text": "Abends zu Heinz hernieder;", "tokens": ["A\u00b7bends", "zu", "Heinz", "her\u00b7nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Das war ihr Lebenslauf.", "tokens": ["Das", "war", "ihr", "Le\u00b7bens\u00b7lauf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Doch endlich nach acht Wochen,", "tokens": ["Doch", "end\u00b7lich", "nach", "acht", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da kam dann der Termin.", "tokens": ["Da", "kam", "dann", "der", "Ter\u00b7min", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Teufel kam gekrochen,", "tokens": ["Der", "Teu\u00b7fel", "kam", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sa\u00df im Kamine drin.", "tokens": ["Sa\u00df", "im", "Ka\u00b7mi\u00b7ne", "drin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Babett gleich einem Storchen", "tokens": ["Ba\u00b7bett", "gleich", "ei\u00b7nem", "Stor\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kehrt just beim Advokat.", "tokens": ["Kehrt", "just", "beim", "Ad\u00b7vo\u00b7kat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf einem Bein zu horchen", "tokens": ["Auf", "ei\u00b7nem", "Bein", "zu", "hor\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie die Gewohnheit hat.", "tokens": ["Sie", "die", "Ge\u00b7wohn\u00b7heit", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Dort war grad' Herrenessen.", "tokens": ["Dort", "war", "grad'", "Her\u00b7re\u00b7nes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man renommierte sehr,", "tokens": ["Man", "re\u00b7nom\u00b7mier\u00b7te", "sehr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und bei dem besten Fressen", "tokens": ["Und", "bei", "dem", "bes\u00b7ten", "Fres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fiel \u00fcber Heinz man her.", "tokens": ["Fiel", "\u00fc\u00b7ber", "Heinz", "man", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Man sprach, man k\u00f6nnt' nicht z\u00e4hlen,", "tokens": ["Man", "sprach", ",", "man", "k\u00f6nnt'", "nicht", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie gro\u00df sein Harem sei.", "tokens": ["Wie", "gro\u00df", "sein", "Ha\u00b7rem", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er t\u00e4t' die M\u00e4dchen sch\u00e4len", "tokens": ["Er", "t\u00e4t'", "die", "M\u00e4d\u00b7chen", "sch\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und liebte sie zu Brei.", "tokens": ["Und", "lieb\u00b7te", "sie", "zu", "Brei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Und alle Frauen w\u00fc\u00dften,", "tokens": ["Und", "al\u00b7le", "Frau\u00b7en", "w\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu hitzig ging er um.", "tokens": ["Zu", "hit\u00b7zig", "ging", "er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch all' ihn lieben m\u00fc\u00dften,", "tokens": ["Doch", "all'", "ihn", "lie\u00b7ben", "m\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur eine bliebe stumm.", "tokens": ["Nur", "ei\u00b7ne", "blie\u00b7be", "stumm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "\u00bbund diese seltne eine\u00ab,", "tokens": ["\u00bb", "und", "die\u00b7se", "selt\u00b7ne", "ei\u00b7ne", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PDS", "VVFIN", "ART", "$(", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Lachte der Advokat,", "tokens": ["Lach\u00b7te", "der", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbist eine selten Reine,", "tokens": ["\u00bb", "ist", "ei\u00b7ne", "sel\u00b7ten", "Rei\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die ich mal k\u00fcssen tat.\u00ab", "tokens": ["Die", "ich", "mal", "k\u00fcs\u00b7sen", "tat", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Die Ohren der Babette,", "tokens": ["Die", "Oh\u00b7ren", "der", "Ba\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Die wuchsen riesengro\u00df.", "tokens": ["Die", "wuch\u00b7sen", "rie\u00b7sen\u00b7gro\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie doch keine h\u00e4tte!", "tokens": ["Wenn", "sie", "doch", "kei\u00b7ne", "h\u00e4t\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jetzt ist der Teufel los.", "tokens": ["Jetzt", "ist", "der", "Teu\u00b7fel", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Der Advokat spricht: \u00bbHeute", "tokens": ["Der", "Ad\u00b7vo\u00b7kat", "spricht", ":", "\u00bb", "Heu\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sieht man's dem Heinz nicht an,", "tokens": ["Sieht", "man's", "dem", "Heinz", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Welch' ideale Leute", "tokens": ["Welch'", "i\u00b7dea\u00b7le", "Leu\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Der Heinzen lieben kann.", "tokens": ["Der", "Hein\u00b7zen", "lie\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Das war damals Sylvester,", "tokens": ["Das", "war", "da\u00b7mals", "Syl\u00b7ves\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da sa\u00df ich auf dem Land,", "tokens": ["Da", "sa\u00df", "ich", "auf", "dem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo meine Milichschwester", "tokens": ["Wo", "mei\u00b7ne", "Mi\u00b7lich\u00b7schwes\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tief in Prozessen stand.", "tokens": ["Tief", "in", "Pro\u00b7zes\u00b7sen", "stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.27": {"line.1": {"text": "Im Haus war eine Dame,", "tokens": ["Im", "Haus", "war", "ei\u00b7ne", "Da\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie schrieb die Schreibmaschin'.", "tokens": ["Sie", "schrieb", "die", "Schreib\u00b7ma\u00b7schin'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rosalie war ihr Name,", "tokens": ["Ro\u00b7sa\u00b7lie", "war", "ihr", "Na\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie schrieb stets still dahin.", "tokens": ["Sie", "schrieb", "stets", "still", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Rosalie zu Sylvester", "tokens": ["Ro\u00b7sa\u00b7lie", "zu", "Syl\u00b7ves\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Auch sie go\u00df mit uns Blei.\u00ab", "tokens": ["Auch", "sie", "go\u00df", "mit", "uns", "Blei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "PPER", "NN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sprach: \u00bbAdvokat, mein Bester,", "tokens": ["Sprach", ":", "\u00bb", "Ad\u00b7vo\u00b7kat", ",", "mein", "Bes\u00b7ter", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Steht mir 'ne Frage frei?", "tokens": ["Steht", "mir", "'ne", "Fra\u00b7ge", "frei", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Sagt mir doch das Orakel", "tokens": ["Sagt", "mir", "doch", "das", "O\u00b7ra\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hier aus dem Blei heraus!", "tokens": ["Hier", "aus", "dem", "Blei", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Besah mir den Spektakel", "tokens": ["Be\u00b7sah", "mir", "den", "Spek\u00b7ta\u00b7kel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ward nicht klug daraus.", "tokens": ["Und", "ward", "nicht", "klug", "da\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADJD", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Sie fragte mich so eigen,", "tokens": ["Sie", "frag\u00b7te", "mich", "so", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als m\u00fc\u00dft' in diesem Jahr", "tokens": ["Als", "m\u00fc\u00dft'", "in", "die\u00b7sem", "Jahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sich was besondres zeigen,", "tokens": ["Sich", "was", "be\u00b7sond\u00b7res", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PWS", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dran ihr gelegen war.", "tokens": ["Dran", "ihr", "ge\u00b7le\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Und sp\u00e4ter traf ich richtig", "tokens": ["Und", "sp\u00e4\u00b7ter", "traf", "ich", "rich\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Dunkeln sie allein,", "tokens": ["Im", "Dun\u00b7keln", "sie", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dies soll immer wichtig", "tokens": ["Und", "dies", "soll", "im\u00b7mer", "wich\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bei allen Damen sein.", "tokens": ["Bei", "al\u00b7len", "Da\u00b7men", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "La\u00df mir das nicht entgehen,", "tokens": ["La\u00df", "mir", "das", "nicht", "ent\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich habe sie gek\u00fc\u00dft.", "tokens": ["Ich", "ha\u00b7be", "sie", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie lie\u00df es auch geschehen,", "tokens": ["Sie", "lie\u00df", "es", "auch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ich bekam Gel\u00fcst,", "tokens": ["Und", "ich", "be\u00b7kam", "Ge\u00b7l\u00fcst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Das Neujahr zu beginnen,", "tokens": ["Das", "Neu\u00b7jahr", "zu", "be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So gut's am Lande geht.", "tokens": ["So", "gut's", "am", "Lan\u00b7de", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wollt' um mehr K\u00fcsse minnen \u2013", "tokens": ["Wollt'", "um", "mehr", "K\u00fcs\u00b7se", "min\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch Rosa widersteht.\u00ab", "tokens": ["Doch", "Ro\u00b7sa", "wi\u00b7der\u00b7steht", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Die Ohren der Babette,", "tokens": ["Die", "Oh\u00b7ren", "der", "Ba\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Sie sind schon wie ein Fa\u00df.", "tokens": ["Sie", "sind", "schon", "wie", "ein", "Fa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie jetzt keine h\u00e4tte,", "tokens": ["Wenn", "sie", "jetzt", "kei\u00b7ne", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie h\u00f6rte doch etwas.", "tokens": ["Sie", "h\u00f6r\u00b7te", "doch", "et\u00b7was", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "\u00bbich fragt'\u00ab, warum den einen", "tokens": ["\u00bb", "ich", "fragt'", "\u00ab", ",", "wa\u00b7rum", "den", "ei\u00b7nen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$(", "$,", "PWAV", "ART", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ku\u00df sie gelitten hat,", "tokens": ["Ku\u00df", "sie", "ge\u00b7lit\u00b7ten", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie sprach: \u00bbIch war im Reinen", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "war", "im", "Rei\u00b7nen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht ganz, Herr Advokat,", "tokens": ["Nicht", "ganz", ",", "Herr", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Mit mir. Ich dacht voll Lachen", "tokens": ["Mit", "mir", ".", "Ich", "dacht", "voll", "La\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "PPER", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als man den Ku\u00df mir nahm:", "tokens": ["Als", "man", "den", "Ku\u00df", "mir", "nahm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So d\u00fcrfte es sich machen,", "tokens": ["So", "d\u00fcrf\u00b7te", "es", "sich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "W\u00e4r' hier mein Br\u00e4utigam.", "tokens": ["W\u00e4r'", "hier", "mein", "Br\u00e4u\u00b7ti\u00b7gam", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Ich tue ihn erwarten", "tokens": ["Ich", "tue", "ihn", "er\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Jetzt volle zwanzig Jahr.", "tokens": ["Jetzt", "vol\u00b7le", "zwan\u00b7zig", "Jahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Frag' st\u00fcndlich nur die Karten,", "tokens": ["Frag'", "st\u00fcnd\u00b7lich", "nur", "die", "Kar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch dies macht mich nicht klar!\u00ab", "tokens": ["Auch", "dies", "macht", "mich", "nicht", "klar", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PTKNEG", "ADJD", "$.", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.38": {"line.1": {"text": "Ich h\u00f6rte zu allm\u00e4hlich.", "tokens": ["Ich", "h\u00f6r\u00b7te", "zu", "all\u00b7m\u00e4h\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie sprach sich einfach aus:", "tokens": ["Sie", "sprach", "sich", "ein\u00b7fach", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Heinz, er mach' sie selig,", "tokens": ["Herr", "Heinz", ",", "er", "mach'", "sie", "se\u00b7lig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie kenn' ihn von zu Haus.", "tokens": ["Sie", "kenn'", "ihn", "von", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Sie war damals 'ne kleine", "tokens": ["Sie", "war", "da\u00b7mals", "'ne", "klei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Liebliche Kindsperson,", "tokens": ["Lieb\u00b7li\u00b7che", "Kinds\u00b7per\u00b7son", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ein Kinderm\u00e4dchen, reine,", "tokens": ["Ein", "Kin\u00b7der\u00b7m\u00e4d\u00b7chen", ",", "rei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit Sucht nach h\u00f6hrem Ton.", "tokens": ["Mit", "Sucht", "nach", "h\u00f6h\u00b7rem", "Ton", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Sie schob den Kinderwagen", "tokens": ["Sie", "schob", "den", "Kin\u00b7der\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und sagte h\u00f6chstens: \u00bbach!\u00ab", "tokens": ["Und", "sag\u00b7te", "h\u00f6chs\u00b7tens", ":", "\u00bb", "ach", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "$(", "ITJ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz tat um Lieb sie fragen.", "tokens": ["Heinz", "tat", "um", "Lieb", "sie", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sie sprach: \u00bbHeinz, hernach!\u00ab", "tokens": ["Und", "sie", "sprach", ":", "\u00bb", "Heinz", ",", "her\u00b7nach", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NE", "$,", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Denn er ging noch zur Schule", "tokens": ["Denn", "er", "ging", "noch", "zur", "Schu\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mit der Primanerschar,", "tokens": ["Mit", "der", "Pri\u00b7ma\u00b7ner\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Las ihr K\u00f6nig von Thule,", "tokens": ["Las", "ihr", "K\u00f6\u00b7nig", "von", "Thu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wo eine Buhle war.", "tokens": ["Wo", "ei\u00b7ne", "Buh\u00b7le", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Sie traf unter Kastanien", "tokens": ["Sie", "traf", "un\u00b7ter", "Kas\u00b7ta\u00b7ni\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Heinz da jede Nacht,", "tokens": ["Den", "Heinz", "da", "je\u00b7de", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nahm gerne die Geranien,", "tokens": ["Nahm", "ger\u00b7ne", "die", "Ge\u00b7ra\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Die er ihr mitgebracht.", "tokens": ["Die", "er", "ihr", "mit\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Sie hielten sich die H\u00e4nde,", "tokens": ["Sie", "hiel\u00b7ten", "sich", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Doch mehr gab sie ihm nicht.", "tokens": ["Doch", "mehr", "gab", "sie", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Weil es ihr besser st\u00e4nde,", "tokens": ["Weil", "es", "ihr", "bes\u00b7ser", "st\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn sie sich ihm verspricht.", "tokens": ["Wenn", "sie", "sich", "ihm", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Er steckte an den Finger", "tokens": ["Er", "steck\u00b7te", "an", "den", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Ringlein ihr aus Stahl,", "tokens": ["Ein", "Rin\u00b7glein", "ihr", "aus", "Stahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wertvoller als Golddinger,", "tokens": ["Wert\u00b7vol\u00b7ler", "als", "Gold\u00b7din\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KOUS", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die's sonst gibt jedesmal.", "tokens": ["Die's", "sonst", "gibt", "je\u00b7des\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Sie tat sich ihm geloben \u2013", "tokens": ["Sie", "tat", "sich", "ihm", "ge\u00b7lo\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schwur Heinz st\u00e4hlerne Treu,", "tokens": ["Schwur", "Heinz", "st\u00e4h\u00b7ler\u00b7ne", "Treu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Darum hielt sie sich oben.", "tokens": ["Da\u00b7rum", "hielt", "sie", "sich", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Noch heut ist sie ihm neu.", "tokens": ["Noch", "heut", "ist", "sie", "ihm", "neu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PPER", "ADJD", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.46": {"line.1": {"text": "Und treu will sie ihm bleiben", "tokens": ["Und", "treu", "will", "sie", "ihm", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auch in dem neuen Jahr.", "tokens": ["Auch", "in", "dem", "neu\u00b7en", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es ist nicht zu beschreiben,", "tokens": ["Es", "ist", "nicht", "zu", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie Rosa komisch war.", "tokens": ["Wie", "Ro\u00b7sa", "ko\u00b7misch", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Da br\u00fcllten alle Herren,", "tokens": ["Da", "br\u00fcll\u00b7ten", "al\u00b7le", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es br\u00fcllt der Advokat.", "tokens": ["Es", "br\u00fcllt", "der", "Ad\u00b7vo\u00b7kat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Solch Lachen mu\u00df verzerren,", "tokens": ["Solch", "La\u00b7chen", "mu\u00df", "ver\u00b7zer\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er wu\u00dft' nicht, was er tat.", "tokens": ["Er", "wu\u00dft'", "nicht", ",", "was", "er", "tat", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Er hob sein Glas zur H\u00f6he", "tokens": ["Er", "hob", "sein", "Glas", "zur", "H\u00f6\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und rief: \u00bbEs leb' der Ku\u00df!", "tokens": ["Und", "rief", ":", "\u00bb", "Es", "leb'", "der", "Ku\u00df", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Treu bei\u00dfen auch die Fl\u00f6he,", "tokens": ["Treu", "bei\u00b7\u00dfen", "auch", "die", "Fl\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil man sich n\u00e4hren mu\u00df.\u00ab", "tokens": ["Weil", "man", "sich", "n\u00e4h\u00b7ren", "mu\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "Pl\u00f6tzlich ert\u00f6nt ein Poltern \u2013", "tokens": ["Pl\u00f6tz\u00b7lich", "er\u00b7t\u00f6nt", "ein", "Pol\u00b7tern", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Der Schornstein st\u00fcrzt fast ein.", "tokens": ["Der", "Schorn\u00b7stein", "st\u00fcrzt", "fast", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit ihren Liebesfoltern", "tokens": ["Mit", "ih\u00b7ren", "Lie\u00b7bes\u00b7fol\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "F\u00e4llt die Babett herein.", "tokens": ["F\u00e4llt", "die", "Ba\u00b7bett", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.50": {"line.1": {"text": "Sie mu\u00df zuerst sich sch\u00fctteln,", "tokens": ["Sie", "mu\u00df", "zu\u00b7erst", "sich", "sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dann schreit sie hoch in Wut:", "tokens": ["Dann", "schreit", "sie", "hoch", "in", "Wut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdem Anwalt und den B\u00fctteln", "tokens": ["\u00bb", "dem", "An\u00b7walt", "und", "den", "B\u00fct\u00b7teln"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schmeckt das Verschw\u00e4rzen gut!", "tokens": ["Schmeckt", "das", "Ver\u00b7schw\u00e4r\u00b7zen", "gut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.51": {"line.1": {"text": "Herr Advokat, Sie brennen", "tokens": ["Herr", "Ad\u00b7vo\u00b7kat", ",", "Sie", "bren\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sich ganz gemein den Mund,", "tokens": ["Sich", "ganz", "ge\u00b7mein", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Rosa Sie verkennen", "tokens": ["Wenn", "Ro\u00b7sa", "Sie", "ver\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In ihrer besten Stund.", "tokens": ["In", "ih\u00b7rer", "bes\u00b7ten", "Stund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Gleich mu\u00df der Heinz mir her da!", "tokens": ["Gleich", "mu\u00df", "der", "Heinz", "mir", "her", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "ADV", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "\u2013 Wie ihr doch dreckig lacht! \u2013", "tokens": ["\u2013", "Wie", "ihr", "doch", "dre\u00b7ckig", "lacht", "!", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00fc\u00dft ich doch, ob aus Rosa", "tokens": ["W\u00fc\u00dft", "ich", "doch", ",", "ob", "aus", "Ro\u00b7sa"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Heinz sich viel noch macht!\u00ab", "tokens": ["Mein", "Heinz", "sich", "viel", "noch", "macht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "PRF", "ADV", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.53": {"line.1": {"text": "Vor Staub und Ru\u00df konnt niemand", "tokens": ["Vor", "Staub", "und", "Ru\u00df", "konnt", "nie\u00b7mand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VMFIN", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den andern richtig sehn.", "tokens": ["Den", "an\u00b7dern", "rich\u00b7tig", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Lachen schnell dahinschwand,", "tokens": ["Das", "La\u00b7chen", "schnell", "da\u00b7hin\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Der Ru\u00df nur blieb bestehn.", "tokens": ["Der", "Ru\u00df", "nur", "blieb", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Das End vom Herrenessen", "tokens": ["Das", "End", "vom", "Her\u00b7re\u00b7nes\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schien ein Kinnbackenkrampf.", "tokens": ["Schien", "ein", "Kinn\u00b7ba\u00b7cken\u00b7krampf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Weit auf standen zw\u00f6lf Fressen,", "tokens": ["Weit", "auf", "stan\u00b7den", "zw\u00f6lf", "Fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "CARD", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und der Verstand ward Dampf.", "tokens": ["Und", "der", "Ver\u00b7stand", "ward", "Dampf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.55": {"line.1": {"text": "\u00bbder Teufel!\u00ab schrieen alle,", "tokens": ["\u00bb", "der", "Teu\u00b7fel", "!", "\u00ab", "schri\u00b7een", "al\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "$(", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und selbst ein Staatsanwalt", "tokens": ["Und", "selbst", "ein", "Staats\u00b7an\u00b7walt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rief: \u00bbJa, in diesem Falle", "tokens": ["Rief", ":", "\u00bb", "Ja", ",", "in", "die\u00b7sem", "Fal\u00b7le"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "$(", "PTKANT", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kam er in Weibsgestalt.\u00ab", "tokens": ["Kam", "er", "in", "Weibs\u00b7ge\u00b7stalt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.56": {"line.1": {"text": "Babette aber, eiligst,", "tokens": ["Ba\u00b7bet\u00b7te", "a\u00b7ber", ",", "ei\u00b7ligst", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Flog sturmgebl\u00e4ht nach Haus.", "tokens": ["Flog", "sturm\u00b7ge\u00b7bl\u00e4ht", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Heinz \u00fcbt grad kurzweiligst", "tokens": ["Herr", "Heinz", "\u00fcbt", "grad", "kurz\u00b7wei\u00b7ligst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "ADV", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Die Kunst am Waldhorn aus.", "tokens": ["Die", "Kunst", "am", "Wald\u00b7horn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.57": {"line.1": {"text": "Sie h\u00f6rt schon aus drei Stra\u00dfen,", "tokens": ["Sie", "h\u00f6rt", "schon", "aus", "drei", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie sch\u00f6n er tremoliert.", "tokens": ["Wie", "sch\u00f6n", "er", "tre\u00b7mo\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie mu\u00df ans Herz sich fassen,", "tokens": ["Sie", "mu\u00df", "ans", "Herz", "sich", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil sie dort was verliert.", "tokens": ["Weil", "sie", "dort", "was", "ver\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PWS", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.58": {"line.1": {"text": "Sie f\u00fchlt sich wie erstochen:", "tokens": ["Sie", "f\u00fchlt", "sich", "wie", "er\u00b7sto\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Heinz geh\u00f6rt Rosa an!", "tokens": ["Heinz", "ge\u00b7h\u00f6rt", "Ro\u00b7sa", "an", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Rosa ist er versprochen!", "tokens": ["Ro\u00b7sa", "ist", "er", "ver\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Sie hat kein Recht daran!", "tokens": ["Sie", "hat", "kein", "Recht", "da\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "Es zieht die Tr\u00e4n' wie S\u00e4ure", "tokens": ["Es", "zieht", "die", "Tr\u00e4n'", "wie", "S\u00e4u\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Linien durchs Ru\u00dfgesicht.", "tokens": ["Li\u00b7ni\u00b7en", "durchs", "Ru\u00df\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie sch\u00f6n bl\u00e4st Heinz der Teure!", "tokens": ["Wie", "sch\u00f6n", "bl\u00e4st", "Heinz", "der", "Teu\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "NE", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Schw\u00e4rze kennt er nicht.", "tokens": ["Und", "Schw\u00e4r\u00b7ze", "kennt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.60": {"line.1": {"text": "Keine hat er vergessen,", "tokens": ["Kei\u00b7ne", "hat", "er", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Doch auch behalten \u2013 nie.", "tokens": ["Doch", "auch", "be\u00b7hal\u00b7ten", "\u2013", "nie", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$(", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf nichts war er versessen,", "tokens": ["Auf", "nichts", "war", "er", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Nur auf die Rosalie.", "tokens": ["Nur", "auf", "die", "Ro\u00b7sa\u00b7lie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.61": {"line.1": {"text": "So denkt es sich Babette", "tokens": ["So", "denkt", "es", "sich", "Ba\u00b7bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ganz schmierig im Gesicht.", "tokens": ["Ganz", "schmie\u00b7rig", "im", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie nicht Ru\u00df dran h\u00e4tte,", "tokens": ["Wenn", "sie", "nicht", "Ru\u00df", "dran", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "PAV", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "W\u00e4r sie wie ein Gedicht.", "tokens": ["W\u00e4r", "sie", "wie", "ein", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Rosa wollt' er nicht r\u00fchren", "tokens": ["Ro\u00b7sa", "wollt'", "er", "nicht", "r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Der Heinz, wie sonst er's tat,", "tokens": ["Der", "Heinz", ",", "wie", "sonst", "er's", "tat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil er ja zum Verf\u00fchren", "tokens": ["Weil", "er", "ja", "zum", "Ver\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Die andern Alle hat.", "tokens": ["Die", "an\u00b7dern", "Al\u00b7le", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "Auch denkt sich jetzt Babette", "tokens": ["Auch", "denkt", "sich", "jetzt", "Ba\u00b7bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Herz den Hexenschu\u00df:", "tokens": ["Im", "Herz", "den", "He\u00b7xen\u00b7schu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwenn keins gesprochen h\u00e4tte!", "tokens": ["\u00bb", "wenn", "keins", "ge\u00b7spro\u00b7chen", "h\u00e4t\u00b7te", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ich doch horchen mu\u00df!\u00ab", "tokens": ["Da", "ich", "doch", "hor\u00b7chen", "mu\u00df", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "Denn Heinz, er ging zur Stunde,", "tokens": ["Denn", "Heinz", ",", "er", "ging", "zur", "Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nachdem Babette sprach,", "tokens": ["Nach\u00b7dem", "Ba\u00b7bet\u00b7te", "sprach", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Zur Herrentafelrunde", "tokens": ["Zur", "Her\u00b7ren\u00b7ta\u00b7fel\u00b7run\u00b7de"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und machte einen Krach.", "tokens": ["Und", "mach\u00b7te", "ei\u00b7nen", "Krach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "Schlug sich dann ohne Sorgen", "tokens": ["Schlug", "sich", "dann", "oh\u00b7ne", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im W\u00e4ldchen mit dem Herrn.", "tokens": ["Im", "W\u00e4ld\u00b7chen", "mit", "dem", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kaum lag er tot am Morgen,", "tokens": ["Kaum", "lag", "er", "tot", "am", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da h\u00e4tt' ihn Jeder gern.", "tokens": ["Da", "h\u00e4tt'", "ihn", "Je\u00b7der", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Ihm flie\u00dft vom Herz ein F\u00e4dchen", "tokens": ["Ihm", "flie\u00dft", "vom", "Herz", "ein", "F\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Tiefrot und leuchtet sehr,", "tokens": ["Tief\u00b7rot", "und", "leuch\u00b7tet", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil Heinz von seinen M\u00e4dchen", "tokens": ["Weil", "Heinz", "von", "sei\u00b7nen", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verteidigte die Ehr!", "tokens": ["Ver\u00b7tei\u00b7dig\u00b7te", "die", "Ehr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.67": {"line.1": {"text": "Babett, wenn auch gewaschen,", "tokens": ["Ba\u00b7bett", ",", "wenn", "auch", "ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "F\u00fchlt st\u00fcndlich sich nicht rein.", "tokens": ["F\u00fchlt", "st\u00fcnd\u00b7lich", "sich", "nicht", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schuld sitzt in ihren Taschen,", "tokens": ["Schuld", "sitzt", "in", "ih\u00b7ren", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schwarz wie Kamine sein.", "tokens": ["Schwarz", "wie", "Ka\u00b7mi\u00b7ne", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.68": {"line.1": {"text": "Sie m\u00f6cht' am Sarge toben,", "tokens": ["Sie", "m\u00f6cht'", "am", "Sar\u00b7ge", "to\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil sie jetzt nichts mehr hat,", "tokens": ["Weil", "sie", "jetzt", "nichts", "mehr", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als in dem Schornstein oben", "tokens": ["Als", "in", "dem", "Schorn\u00b7stein", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Titel Schornsteinrat.", "tokens": ["Den", "Ti\u00b7tel", "Schorn\u00b7stein\u00b7rat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.69": {"line.1": {"text": "\u00bbnun m\u00f6cht ich\u00ab, sprach die Amme,", "tokens": ["\u00bb", "nun", "m\u00f6cht", "ich", "\u00ab", ",", "sprach", "die", "Am\u00b7me", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "$(", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbeinmal die Tassen schwenken.", "tokens": ["\u00bb", "ein\u00b7mal", "die", "Tas\u00b7sen", "schwen\u00b7ken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Rest schmeckt stets infame.", "tokens": ["Der", "Rest", "schmeckt", "stets", "in\u00b7fa\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Leben tut Gr\u00e4ber schenken\u00ab \u2013", "tokens": ["Le\u00b7ben", "tut", "Gr\u00e4\u00b7ber", "schen\u00b7ken", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "NN", "VVINF", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.70": {"line.1": {"text": "Jemand mu\u00df heut' noch sterben,", "tokens": ["Je\u00b7mand", "mu\u00df", "heut'", "noch", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Hund heult so heut' Nacht!", "tokens": ["Ein", "Hund", "heult", "so", "heut'", "Nacht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die Z\u00e4hn' klappern wie Scherben,", "tokens": ["Die", "Z\u00e4hn'", "klap\u00b7pern", "wie", "Scher\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jed' Amme Kreuze macht.", "tokens": ["Jed'", "Am\u00b7me", "Kreu\u00b7ze", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "In sich geb\u00fcckt wie Kn\u00e4ule", "tokens": ["In", "sich", "ge\u00b7b\u00fcckt", "wie", "Kn\u00e4u\u00b7le"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "VVPP", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zwei Kreuz' noch Jede macht.", "tokens": ["Zwei", "Kreuz'", "noch", "Je\u00b7de", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADV", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Endlos ist's Hundsgeheule,", "tokens": ["End\u00b7los", "ist's", "Hunds\u00b7ge\u00b7heu\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja, Jemand stirbt heut Nacht! \u2013", "tokens": ["Ja", ",", "Je\u00b7mand", "stirbt", "heut", "Nacht", "!", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKANT", "$,", "PIS", "VVFIN", "ADV", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Und eine Amme wieder", "tokens": ["Und", "ei\u00b7ne", "Am\u00b7me", "wie\u00b7der"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach: \u00bbAlles nimmt ein End,", "tokens": ["Sprach", ":", "\u00bb", "Al\u00b7les", "nimmt", "ein", "End", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PIS", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Enden tun alle Lieder,", "tokens": ["En\u00b7den", "tun", "al\u00b7le", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Man ist das schon gew\u00f6hnt.", "tokens": ["Man", "ist", "das", "schon", "ge\u00b7w\u00f6hnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ART", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.73": {"line.1": {"text": "Durch Horchen h\u00f6rt man eben,", "tokens": ["Durch", "Hor\u00b7chen", "h\u00f6rt", "man", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie man beim Reden spricht.", "tokens": ["Wie", "man", "beim", "Re\u00b7den", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz w\u00e4r' heut' noch am Leben,", "tokens": ["Heinz", "w\u00e4r'", "heut'", "noch", "am", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Horchte Babette nicht.", "tokens": ["Horch\u00b7te", "Ba\u00b7bet\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKNEG", "$."], "meter": "+----+", "measure": "dactylic.init"}}, "stanza.74": {"line.1": {"text": "So denk' ich mir das Ganze:", "tokens": ["So", "denk'", "ich", "mir", "das", "Gan\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Teufel war im Spiel.", "tokens": ["Der", "Teu\u00b7fel", "war", "im", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Oft sitzt an einer Wanze", "tokens": ["Oft", "sitzt", "an", "ei\u00b7ner", "Wan\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sein Pech, wann er es will.\u00ab", "tokens": ["Sein", "Pech", ",", "wann", "er", "es", "will", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "$,", "PWAV", "PPER", "PPER", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.75": {"line.1": {"text": "Die sieben andern Ammen", "tokens": ["Die", "sie\u00b7ben", "an\u00b7dern", "Am\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "CARD", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Mu\u00dften ans Herz sich fassen.", "tokens": ["Mu\u00df\u00b7ten", "ans", "Herz", "sich", "fas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie r\u00fcckten eng zusammen", "tokens": ["Sie", "r\u00fcck\u00b7ten", "eng", "zu\u00b7sam\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und stellten fort die Tassen.", "tokens": ["Und", "stell\u00b7ten", "fort", "die", "Tas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.76": {"line.1": {"text": "Babett tut Schornstein fegen,", "tokens": ["Ba\u00b7bett", "tut", "Schorn\u00b7stein", "fe\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wird Schornsteinrat genannt.", "tokens": ["Wird", "Schorn\u00b7stein\u00b7rat", "ge\u00b7nannt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und schwarz ist sie deswegen", "tokens": ["Und", "schwarz", "ist", "sie", "des\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "PAV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und dadurch stadtbekannt.", "tokens": ["Und", "da\u00b7durch", "stadt\u00b7be\u00b7kannt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PAV", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.77": {"line.1": {"text": "Einmal da rutscht sie 'runter,", "tokens": ["Ein\u00b7mal", "da", "rutscht", "sie", "'r\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NE", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Herrn Heinz just in die Arm'.", "tokens": ["Herrn", "Heinz", "just", "in", "die", "Arm'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Vom Dach fiel sie hinunter,", "tokens": ["Vom", "Dach", "fiel", "sie", "hin\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Noch war sie ganz ru\u00dfwarm.", "tokens": ["Noch", "war", "sie", "ganz", "ru\u00df\u00b7warm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.78": {"line.1": {"text": "Er trug sie in sein Zimmer", "tokens": ["Er", "trug", "sie", "in", "sein", "Zim\u00b7mer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und wusch sie etwas klar.", "tokens": ["Und", "wusch", "sie", "et\u00b7was", "klar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und daraus ward was schlimmer,", "tokens": ["Und", "da\u00b7raus", "ward", "was", "schlim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "VAFIN", "PIS", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Etwas, was furchtbar war.", "tokens": ["Et\u00b7was", ",", "was", "furcht\u00b7bar", "war", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.79": {"line.1": {"text": "N\u00e4mlich 'ne Mordgeschichte", "tokens": ["N\u00e4m\u00b7lich", "'ne", "Mord\u00b7ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Entstand aus diesem Akt.", "tokens": ["Ent\u00b7stand", "aus", "die\u00b7sem", "Ak\u00b7t."], "token_info": ["word", "word", "word", "abbreviation"], "pos": ["NN", "APPR", "PDAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Vorher da schlo\u00df im Schornstein", "tokens": ["Vor\u00b7her", "da", "schlo\u00df", "im", "Schorn\u00b7stein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "APPRART", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Der Teufel seinen Pakt.", "tokens": ["Der", "Teu\u00b7fel", "sei\u00b7nen", "Pakt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.80": {"line.1": {"text": "Der Teufel kam gekrochen,", "tokens": ["Der", "Teu\u00b7fel", "kam", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sprach: \u00bbBabett, kriegst 'nen Mann,", "tokens": ["Sprach", ":", "\u00bb", "Ba\u00b7bett", ",", "kriegst", "'nen", "Mann", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NE", "$,", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn nach so'n so viel Wochen", "tokens": ["Wenn", "nach", "so'n", "so", "viel", "Wo\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADV", "ADV", "PIAT", "NN"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Ich mir ihn holen kann.", "tokens": ["Ich", "mir", "ihn", "ho\u00b7len", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.81": {"line.1": {"text": "Du mu\u00dft ihm dann erz\u00e4hlen,", "tokens": ["Du", "mu\u00dft", "ihm", "dann", "er\u00b7z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Was ich Dir sagen tu.", "tokens": ["Was", "ich", "Dir", "sa\u00b7gen", "tu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PPER", "VVFIN", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Denn nur so darfst Du w\u00e4hlen", "tokens": ["Denn", "nur", "so", "darfst", "Du", "w\u00e4h\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "VVFIN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und gibst dem Teufel Ruh.", "tokens": ["Und", "gibst", "dem", "Teu\u00b7fel", "Ruh", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.82": {"line.1": {"text": "Daf\u00fcr darfst Du auch k\u00fcssen,", "tokens": ["Da\u00b7f\u00fcr", "darfst", "Du", "auch", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kriegst einen ganzen Mann.", "tokens": ["Kriegst", "ei\u00b7nen", "gan\u00b7zen", "Mann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Du kannst nichts Be\u00dfres m\u00fcssen.\u00ab", "tokens": ["Du", "kannst", "nichts", "Be\u00df\u00b7res", "m\u00fcs\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PIS", "PIS", "VMFIN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was liegt der Babett d'ran!", "tokens": ["Was", "liegt", "der", "Ba\u00b7bett", "d'\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.83": {"line.1": {"text": "Kaum ist sie einverstanden,", "tokens": ["Kaum", "ist", "sie", "ein\u00b7ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schmei\u00dft Jemand sie vom Dach.", "tokens": ["Schmei\u00dft", "Je\u00b7mand", "sie", "vom", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie tut bei Heinzen landen \u2013", "tokens": ["Sie", "tut", "bei", "Hein\u00b7zen", "lan\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Teufel sieht ihr nach.", "tokens": ["Der", "Teu\u00b7fel", "sieht", "ihr", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.84": {"line.1": {"text": "Der Heinz hat sie gewaschen,", "tokens": ["Der", "Heinz", "hat", "sie", "ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und als sie rein genug,", "tokens": ["Und", "als", "sie", "rein", "ge\u00b7nug", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "L\u00e4\u00dft sie Heinz K\u00fcsse naschen,", "tokens": ["L\u00e4\u00dft", "sie", "Heinz", "K\u00fcs\u00b7se", "na\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NE", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nascht selber zart und klug.", "tokens": ["Nascht", "sel\u00b7ber", "zart", "und", "klug", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "Bald lebten sie wie Tauben,", "tokens": ["Bald", "leb\u00b7ten", "sie", "wie", "Tau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KOKOM", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie liebte selbstbewu\u00dft,", "tokens": ["Sie", "lieb\u00b7te", "selbst\u00b7be\u00b7wu\u00dft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Tat seine Lampen schrauben,", "tokens": ["Tat", "sei\u00b7ne", "Lam\u00b7pen", "schrau\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Wenn eine Lampe ru\u00dft.", "tokens": ["Wenn", "ei\u00b7ne", "Lam\u00b7pe", "ru\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "Des Morgens stieg sie wieder", "tokens": ["Des", "Mor\u00b7gens", "stieg", "sie", "wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zum Schornsteine hinauf,", "tokens": ["Zum", "Schorn\u00b7stei\u00b7ne", "hin\u00b7auf", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,"], "meter": "-+---+", "measure": "dactylic.init"}, "line.3": {"text": "Abends zu Heinz hernieder;", "tokens": ["A\u00b7bends", "zu", "Heinz", "her\u00b7nie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Das war ihr Lebenslauf.", "tokens": ["Das", "war", "ihr", "Le\u00b7bens\u00b7lauf", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.87": {"line.1": {"text": "Doch endlich nach acht Wochen,", "tokens": ["Doch", "end\u00b7lich", "nach", "acht", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da kam dann der Termin.", "tokens": ["Da", "kam", "dann", "der", "Ter\u00b7min", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der Teufel kam gekrochen,", "tokens": ["Der", "Teu\u00b7fel", "kam", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sa\u00df im Kamine drin.", "tokens": ["Sa\u00df", "im", "Ka\u00b7mi\u00b7ne", "drin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.88": {"line.1": {"text": "Babett gleich einem Storchen", "tokens": ["Ba\u00b7bett", "gleich", "ei\u00b7nem", "Stor\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kehrt just beim Advokat.", "tokens": ["Kehrt", "just", "beim", "Ad\u00b7vo\u00b7kat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf einem Bein zu horchen", "tokens": ["Auf", "ei\u00b7nem", "Bein", "zu", "hor\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie die Gewohnheit hat.", "tokens": ["Sie", "die", "Ge\u00b7wohn\u00b7heit", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.89": {"line.1": {"text": "Dort war grad' Herrenessen.", "tokens": ["Dort", "war", "grad'", "Her\u00b7re\u00b7nes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Man renommierte sehr,", "tokens": ["Man", "re\u00b7nom\u00b7mier\u00b7te", "sehr", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und bei dem besten Fressen", "tokens": ["Und", "bei", "dem", "bes\u00b7ten", "Fres\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Fiel \u00fcber Heinz man her.", "tokens": ["Fiel", "\u00fc\u00b7ber", "Heinz", "man", "her", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "PIS", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.90": {"line.1": {"text": "Man sprach, man k\u00f6nnt' nicht z\u00e4hlen,", "tokens": ["Man", "sprach", ",", "man", "k\u00f6nnt'", "nicht", "z\u00e4h\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PIS", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie gro\u00df sein Harem sei.", "tokens": ["Wie", "gro\u00df", "sein", "Ha\u00b7rem", "sei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er t\u00e4t' die M\u00e4dchen sch\u00e4len", "tokens": ["Er", "t\u00e4t'", "die", "M\u00e4d\u00b7chen", "sch\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und liebte sie zu Brei.", "tokens": ["Und", "lieb\u00b7te", "sie", "zu", "Brei", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.91": {"line.1": {"text": "Und alle Frauen w\u00fc\u00dften,", "tokens": ["Und", "al\u00b7le", "Frau\u00b7en", "w\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu hitzig ging er um.", "tokens": ["Zu", "hit\u00b7zig", "ging", "er", "um", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Doch all' ihn lieben m\u00fc\u00dften,", "tokens": ["Doch", "all'", "ihn", "lie\u00b7ben", "m\u00fc\u00df\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nur eine bliebe stumm.", "tokens": ["Nur", "ei\u00b7ne", "blie\u00b7be", "stumm", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "VVFIN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.92": {"line.1": {"text": "\u00bbund diese seltne eine\u00ab,", "tokens": ["\u00bb", "und", "die\u00b7se", "selt\u00b7ne", "ei\u00b7ne", "\u00ab", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "PDS", "VVFIN", "ART", "$(", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Lachte der Advokat,", "tokens": ["Lach\u00b7te", "der", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "\u00bbist eine selten Reine,", "tokens": ["\u00bb", "ist", "ei\u00b7ne", "sel\u00b7ten", "Rei\u00b7ne", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die ich mal k\u00fcssen tat.\u00ab", "tokens": ["Die", "ich", "mal", "k\u00fcs\u00b7sen", "tat", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PPER", "ADV", "VVINF", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.93": {"line.1": {"text": "Die Ohren der Babette,", "tokens": ["Die", "Oh\u00b7ren", "der", "Ba\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Die wuchsen riesengro\u00df.", "tokens": ["Die", "wuch\u00b7sen", "rie\u00b7sen\u00b7gro\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie doch keine h\u00e4tte!", "tokens": ["Wenn", "sie", "doch", "kei\u00b7ne", "h\u00e4t\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Jetzt ist der Teufel los.", "tokens": ["Jetzt", "ist", "der", "Teu\u00b7fel", "los", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.94": {"line.1": {"text": "Der Advokat spricht: \u00bbHeute", "tokens": ["Der", "Ad\u00b7vo\u00b7kat", "spricht", ":", "\u00bb", "Heu\u00b7te"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sieht man's dem Heinz nicht an,", "tokens": ["Sieht", "man's", "dem", "Heinz", "nicht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ART", "NN", "PTKNEG", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Welch' ideale Leute", "tokens": ["Welch'", "i\u00b7dea\u00b7le", "Leu\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Der Heinzen lieben kann.", "tokens": ["Der", "Hein\u00b7zen", "lie\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.95": {"line.1": {"text": "Das war damals Sylvester,", "tokens": ["Das", "war", "da\u00b7mals", "Syl\u00b7ves\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Da sa\u00df ich auf dem Land,", "tokens": ["Da", "sa\u00df", "ich", "auf", "dem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wo meine Milichschwester", "tokens": ["Wo", "mei\u00b7ne", "Mi\u00b7lich\u00b7schwes\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tief in Prozessen stand.", "tokens": ["Tief", "in", "Pro\u00b7zes\u00b7sen", "stand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.96": {"line.1": {"text": "Im Haus war eine Dame,", "tokens": ["Im", "Haus", "war", "ei\u00b7ne", "Da\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie schrieb die Schreibmaschin'.", "tokens": ["Sie", "schrieb", "die", "Schreib\u00b7ma\u00b7schin'", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rosalie war ihr Name,", "tokens": ["Ro\u00b7sa\u00b7lie", "war", "ihr", "Na\u00b7me", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Sie schrieb stets still dahin.", "tokens": ["Sie", "schrieb", "stets", "still", "da\u00b7hin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADJD", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.97": {"line.1": {"text": "Rosalie zu Sylvester", "tokens": ["Ro\u00b7sa\u00b7lie", "zu", "Syl\u00b7ves\u00b7ter"], "token_info": ["word", "word", "word"], "pos": ["NE", "APPR", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Auch sie go\u00df mit uns Blei.\u00ab", "tokens": ["Auch", "sie", "go\u00df", "mit", "uns", "Blei", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPER", "VVFIN", "APPR", "PPER", "NN", "$.", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Sprach: \u00bbAdvokat, mein Bester,", "tokens": ["Sprach", ":", "\u00bb", "Ad\u00b7vo\u00b7kat", ",", "mein", "Bes\u00b7ter", ","], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Steht mir 'ne Frage frei?", "tokens": ["Steht", "mir", "'ne", "Fra\u00b7ge", "frei", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.98": {"line.1": {"text": "Sagt mir doch das Orakel", "tokens": ["Sagt", "mir", "doch", "das", "O\u00b7ra\u00b7kel"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hier aus dem Blei heraus!", "tokens": ["Hier", "aus", "dem", "Blei", "he\u00b7raus", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Besah mir den Spektakel", "tokens": ["Be\u00b7sah", "mir", "den", "Spek\u00b7ta\u00b7kel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ward nicht klug daraus.", "tokens": ["Und", "ward", "nicht", "klug", "da\u00b7raus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "ADJD", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.99": {"line.1": {"text": "Sie fragte mich so eigen,", "tokens": ["Sie", "frag\u00b7te", "mich", "so", "ei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als m\u00fc\u00dft' in diesem Jahr", "tokens": ["Als", "m\u00fc\u00dft'", "in", "die\u00b7sem", "Jahr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "APPR", "PDAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sich was besondres zeigen,", "tokens": ["Sich", "was", "be\u00b7sond\u00b7res", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "PWS", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dran ihr gelegen war.", "tokens": ["Dran", "ihr", "ge\u00b7le\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.100": {"line.1": {"text": "Und sp\u00e4ter traf ich richtig", "tokens": ["Und", "sp\u00e4\u00b7ter", "traf", "ich", "rich\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Dunkeln sie allein,", "tokens": ["Im", "Dun\u00b7keln", "sie", "al\u00b7lein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "PPER", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und dies soll immer wichtig", "tokens": ["Und", "dies", "soll", "im\u00b7mer", "wich\u00b7tig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VMFIN", "ADV", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bei allen Damen sein.", "tokens": ["Bei", "al\u00b7len", "Da\u00b7men", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.101": {"line.1": {"text": "La\u00df mir das nicht entgehen,", "tokens": ["La\u00df", "mir", "das", "nicht", "ent\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PDS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ich habe sie gek\u00fc\u00dft.", "tokens": ["Ich", "ha\u00b7be", "sie", "ge\u00b7k\u00fc\u00dft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie lie\u00df es auch geschehen,", "tokens": ["Sie", "lie\u00df", "es", "auch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ich bekam Gel\u00fcst,", "tokens": ["Und", "ich", "be\u00b7kam", "Ge\u00b7l\u00fcst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.102": {"line.1": {"text": "Das Neujahr zu beginnen,", "tokens": ["Das", "Neu\u00b7jahr", "zu", "be\u00b7gin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So gut's am Lande geht.", "tokens": ["So", "gut's", "am", "Lan\u00b7de", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wollt' um mehr K\u00fcsse minnen \u2013", "tokens": ["Wollt'", "um", "mehr", "K\u00fcs\u00b7se", "min\u00b7nen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch Rosa widersteht.\u00ab", "tokens": ["Doch", "Ro\u00b7sa", "wi\u00b7der\u00b7steht", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.103": {"line.1": {"text": "Die Ohren der Babette,", "tokens": ["Die", "Oh\u00b7ren", "der", "Ba\u00b7bet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Sie sind schon wie ein Fa\u00df.", "tokens": ["Sie", "sind", "schon", "wie", "ein", "Fa\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie jetzt keine h\u00e4tte,", "tokens": ["Wenn", "sie", "jetzt", "kei\u00b7ne", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie h\u00f6rte doch etwas.", "tokens": ["Sie", "h\u00f6r\u00b7te", "doch", "et\u00b7was", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.104": {"line.1": {"text": "\u00bbich fragt'\u00ab, warum den einen", "tokens": ["\u00bb", "ich", "fragt'", "\u00ab", ",", "wa\u00b7rum", "den", "ei\u00b7nen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$(", "$,", "PWAV", "ART", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ku\u00df sie gelitten hat,", "tokens": ["Ku\u00df", "sie", "ge\u00b7lit\u00b7ten", "hat", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VVPP", "VAFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Sie sprach: \u00bbIch war im Reinen", "tokens": ["Sie", "sprach", ":", "\u00bb", "Ich", "war", "im", "Rei\u00b7nen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nicht ganz, Herr Advokat,", "tokens": ["Nicht", "ganz", ",", "Herr", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "$,", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.105": {"line.1": {"text": "Mit mir. Ich dacht voll Lachen", "tokens": ["Mit", "mir", ".", "Ich", "dacht", "voll", "La\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$.", "PPER", "VVFIN", "ADJD", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Als man den Ku\u00df mir nahm:", "tokens": ["Als", "man", "den", "Ku\u00df", "mir", "nahm", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "So d\u00fcrfte es sich machen,", "tokens": ["So", "d\u00fcrf\u00b7te", "es", "sich", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "W\u00e4r' hier mein Br\u00e4utigam.", "tokens": ["W\u00e4r'", "hier", "mein", "Br\u00e4u\u00b7ti\u00b7gam", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.106": {"line.1": {"text": "Ich tue ihn erwarten", "tokens": ["Ich", "tue", "ihn", "er\u00b7war\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "VVINF"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Jetzt volle zwanzig Jahr.", "tokens": ["Jetzt", "vol\u00b7le", "zwan\u00b7zig", "Jahr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "CARD", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Frag' st\u00fcndlich nur die Karten,", "tokens": ["Frag'", "st\u00fcnd\u00b7lich", "nur", "die", "Kar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJD", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch dies macht mich nicht klar!\u00ab", "tokens": ["Auch", "dies", "macht", "mich", "nicht", "klar", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PTKNEG", "ADJD", "$.", "$("], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.107": {"line.1": {"text": "Ich h\u00f6rte zu allm\u00e4hlich.", "tokens": ["Ich", "h\u00f6r\u00b7te", "zu", "all\u00b7m\u00e4h\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sie sprach sich einfach aus:", "tokens": ["Sie", "sprach", "sich", "ein\u00b7fach", "aus", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Heinz, er mach' sie selig,", "tokens": ["Herr", "Heinz", ",", "er", "mach'", "sie", "se\u00b7lig", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie kenn' ihn von zu Haus.", "tokens": ["Sie", "kenn'", "ihn", "von", "zu", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.108": {"line.1": {"text": "Sie war damals 'ne kleine", "tokens": ["Sie", "war", "da\u00b7mals", "'ne", "klei\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Liebliche Kindsperson,", "tokens": ["Lieb\u00b7li\u00b7che", "Kinds\u00b7per\u00b7son", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Ein Kinderm\u00e4dchen, reine,", "tokens": ["Ein", "Kin\u00b7der\u00b7m\u00e4d\u00b7chen", ",", "rei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit Sucht nach h\u00f6hrem Ton.", "tokens": ["Mit", "Sucht", "nach", "h\u00f6h\u00b7rem", "Ton", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.109": {"line.1": {"text": "Sie schob den Kinderwagen", "tokens": ["Sie", "schob", "den", "Kin\u00b7der\u00b7wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und sagte h\u00f6chstens: \u00bbach!\u00ab", "tokens": ["Und", "sag\u00b7te", "h\u00f6chs\u00b7tens", ":", "\u00bb", "ach", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "ADV", "$.", "$(", "ITJ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Heinz tat um Lieb sie fragen.", "tokens": ["Heinz", "tat", "um", "Lieb", "sie", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und sie sprach: \u00bbHeinz, hernach!\u00ab", "tokens": ["Und", "sie", "sprach", ":", "\u00bb", "Heinz", ",", "her\u00b7nach", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "$.", "$(", "NE", "$,", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.110": {"line.1": {"text": "Denn er ging noch zur Schule", "tokens": ["Denn", "er", "ging", "noch", "zur", "Schu\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ADV", "APPRART", "NN"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Mit der Primanerschar,", "tokens": ["Mit", "der", "Pri\u00b7ma\u00b7ner\u00b7schar", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Las ihr K\u00f6nig von Thule,", "tokens": ["Las", "ihr", "K\u00f6\u00b7nig", "von", "Thu\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "APPR", "NE", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wo eine Buhle war.", "tokens": ["Wo", "ei\u00b7ne", "Buh\u00b7le", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.111": {"line.1": {"text": "Sie traf unter Kastanien", "tokens": ["Sie", "traf", "un\u00b7ter", "Kas\u00b7ta\u00b7ni\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Den Heinz da jede Nacht,", "tokens": ["Den", "Heinz", "da", "je\u00b7de", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Nahm gerne die Geranien,", "tokens": ["Nahm", "ger\u00b7ne", "die", "Ge\u00b7ra\u00b7ni\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$,"], "meter": "-+-++-+-", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Die er ihr mitgebracht.", "tokens": ["Die", "er", "ihr", "mit\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.112": {"line.1": {"text": "Sie hielten sich die H\u00e4nde,", "tokens": ["Sie", "hiel\u00b7ten", "sich", "die", "H\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Doch mehr gab sie ihm nicht.", "tokens": ["Doch", "mehr", "gab", "sie", "ihm", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PPER", "PTKNEG", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Weil es ihr besser st\u00e4nde,", "tokens": ["Weil", "es", "ihr", "bes\u00b7ser", "st\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wenn sie sich ihm verspricht.", "tokens": ["Wenn", "sie", "sich", "ihm", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.113": {"line.1": {"text": "Er steckte an den Finger", "tokens": ["Er", "steck\u00b7te", "an", "den", "Fin\u00b7ger"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ein Ringlein ihr aus Stahl,", "tokens": ["Ein", "Rin\u00b7glein", "ihr", "aus", "Stahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wertvoller als Golddinger,", "tokens": ["Wert\u00b7vol\u00b7ler", "als", "Gold\u00b7din\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KOUS", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Die's sonst gibt jedesmal.", "tokens": ["Die's", "sonst", "gibt", "je\u00b7des\u00b7mal", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.114": {"line.1": {"text": "Sie tat sich ihm geloben \u2013", "tokens": ["Sie", "tat", "sich", "ihm", "ge\u00b7lo\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schwur Heinz st\u00e4hlerne Treu,", "tokens": ["Schwur", "Heinz", "st\u00e4h\u00b7ler\u00b7ne", "Treu", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADJA", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Darum hielt sie sich oben.", "tokens": ["Da\u00b7rum", "hielt", "sie", "sich", "o\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.4": {"text": "Noch heut ist sie ihm neu.", "tokens": ["Noch", "heut", "ist", "sie", "ihm", "neu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "PPER", "ADJD", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.115": {"line.1": {"text": "Und treu will sie ihm bleiben", "tokens": ["Und", "treu", "will", "sie", "ihm", "blei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auch in dem neuen Jahr.", "tokens": ["Auch", "in", "dem", "neu\u00b7en", "Jahr", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es ist nicht zu beschreiben,", "tokens": ["Es", "ist", "nicht", "zu", "be\u00b7schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wie Rosa komisch war.", "tokens": ["Wie", "Ro\u00b7sa", "ko\u00b7misch", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADJD", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.116": {"line.1": {"text": "Da br\u00fcllten alle Herren,", "tokens": ["Da", "br\u00fcll\u00b7ten", "al\u00b7le", "Her\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es br\u00fcllt der Advokat.", "tokens": ["Es", "br\u00fcllt", "der", "Ad\u00b7vo\u00b7kat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Solch Lachen mu\u00df verzerren,", "tokens": ["Solch", "La\u00b7chen", "mu\u00df", "ver\u00b7zer\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er wu\u00dft' nicht, was er tat.", "tokens": ["Er", "wu\u00dft'", "nicht", ",", "was", "er", "tat", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.117": {"line.1": {"text": "Er hob sein Glas zur H\u00f6he", "tokens": ["Er", "hob", "sein", "Glas", "zur", "H\u00f6\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und rief: \u00bbEs leb' der Ku\u00df!", "tokens": ["Und", "rief", ":", "\u00bb", "Es", "leb'", "der", "Ku\u00df", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Treu bei\u00dfen auch die Fl\u00f6he,", "tokens": ["Treu", "bei\u00b7\u00dfen", "auch", "die", "Fl\u00f6\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil man sich n\u00e4hren mu\u00df.\u00ab", "tokens": ["Weil", "man", "sich", "n\u00e4h\u00b7ren", "mu\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PIS", "PRF", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.118": {"line.1": {"text": "Pl\u00f6tzlich ert\u00f6nt ein Poltern \u2013", "tokens": ["Pl\u00f6tz\u00b7lich", "er\u00b7t\u00f6nt", "ein", "Pol\u00b7tern", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.2": {"text": "Der Schornstein st\u00fcrzt fast ein.", "tokens": ["Der", "Schorn\u00b7stein", "st\u00fcrzt", "fast", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Mit ihren Liebesfoltern", "tokens": ["Mit", "ih\u00b7ren", "Lie\u00b7bes\u00b7fol\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "F\u00e4llt die Babett herein.", "tokens": ["F\u00e4llt", "die", "Ba\u00b7bett", "her\u00b7ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.119": {"line.1": {"text": "Sie mu\u00df zuerst sich sch\u00fctteln,", "tokens": ["Sie", "mu\u00df", "zu\u00b7erst", "sich", "sch\u00fct\u00b7teln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dann schreit sie hoch in Wut:", "tokens": ["Dann", "schreit", "sie", "hoch", "in", "Wut", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdem Anwalt und den B\u00fctteln", "tokens": ["\u00bb", "dem", "An\u00b7walt", "und", "den", "B\u00fct\u00b7teln"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schmeckt das Verschw\u00e4rzen gut!", "tokens": ["Schmeckt", "das", "Ver\u00b7schw\u00e4r\u00b7zen", "gut", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.120": {"line.1": {"text": "Herr Advokat, Sie brennen", "tokens": ["Herr", "Ad\u00b7vo\u00b7kat", ",", "Sie", "bren\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$,", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Sich ganz gemein den Mund,", "tokens": ["Sich", "ganz", "ge\u00b7mein", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn Rosa Sie verkennen", "tokens": ["Wenn", "Ro\u00b7sa", "Sie", "ver\u00b7ken\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPER", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "In ihrer besten Stund.", "tokens": ["In", "ih\u00b7rer", "bes\u00b7ten", "Stund", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.121": {"line.1": {"text": "Gleich mu\u00df der Heinz mir her da!", "tokens": ["Gleich", "mu\u00df", "der", "Heinz", "mir", "her", "da", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "PPER", "ADV", "ADV", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "\u2013 Wie ihr doch dreckig lacht! \u2013", "tokens": ["\u2013", "Wie", "ihr", "doch", "dre\u00b7ckig", "lacht", "!", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWAV", "PPER", "ADV", "ADJD", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "W\u00fc\u00dft ich doch, ob aus Rosa", "tokens": ["W\u00fc\u00dft", "ich", "doch", ",", "ob", "aus", "Ro\u00b7sa"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "KOUS", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mein Heinz sich viel noch macht!\u00ab", "tokens": ["Mein", "Heinz", "sich", "viel", "noch", "macht", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "PRF", "ADV", "ADV", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.122": {"line.1": {"text": "Vor Staub und Ru\u00df konnt niemand", "tokens": ["Vor", "Staub", "und", "Ru\u00df", "konnt", "nie\u00b7mand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "VMFIN", "PIS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Den andern richtig sehn.", "tokens": ["Den", "an\u00b7dern", "rich\u00b7tig", "sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJD", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Lachen schnell dahinschwand,", "tokens": ["Das", "La\u00b7chen", "schnell", "da\u00b7hin\u00b7schwand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Der Ru\u00df nur blieb bestehn.", "tokens": ["Der", "Ru\u00df", "nur", "blieb", "be\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.123": {"line.1": {"text": "Das End vom Herrenessen", "tokens": ["Das", "End", "vom", "Her\u00b7re\u00b7nes\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Schien ein Kinnbackenkrampf.", "tokens": ["Schien", "ein", "Kinn\u00b7ba\u00b7cken\u00b7krampf", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Weit auf standen zw\u00f6lf Fressen,", "tokens": ["Weit", "auf", "stan\u00b7den", "zw\u00f6lf", "Fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ADJA", "CARD", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und der Verstand ward Dampf.", "tokens": ["Und", "der", "Ver\u00b7stand", "ward", "Dampf", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.124": {"line.1": {"text": "\u00bbder Teufel!\u00ab schrieen alle,", "tokens": ["\u00bb", "der", "Teu\u00b7fel", "!", "\u00ab", "schri\u00b7een", "al\u00b7le", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$.", "$(", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und selbst ein Staatsanwalt", "tokens": ["Und", "selbst", "ein", "Staats\u00b7an\u00b7walt"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rief: \u00bbJa, in diesem Falle", "tokens": ["Rief", ":", "\u00bb", "Ja", ",", "in", "die\u00b7sem", "Fal\u00b7le"], "token_info": ["word", "punct", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$.", "$(", "PTKANT", "$,", "APPR", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kam er in Weibsgestalt.\u00ab", "tokens": ["Kam", "er", "in", "Weibs\u00b7ge\u00b7stalt", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "PPER", "APPR", "NN", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.125": {"line.1": {"text": "Babette aber, eiligst,", "tokens": ["Ba\u00b7bet\u00b7te", "a\u00b7ber", ",", "ei\u00b7ligst", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["NE", "ADV", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Flog sturmgebl\u00e4ht nach Haus.", "tokens": ["Flog", "sturm\u00b7ge\u00b7bl\u00e4ht", "nach", "Haus", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Heinz \u00fcbt grad kurzweiligst", "tokens": ["Herr", "Heinz", "\u00fcbt", "grad", "kurz\u00b7wei\u00b7ligst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "VVFIN", "ADV", "VVFIN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Die Kunst am Waldhorn aus.", "tokens": ["Die", "Kunst", "am", "Wald\u00b7horn", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.126": {"line.1": {"text": "Sie h\u00f6rt schon aus drei Stra\u00dfen,", "tokens": ["Sie", "h\u00f6rt", "schon", "aus", "drei", "Stra\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Wie sch\u00f6n er tremoliert.", "tokens": ["Wie", "sch\u00f6n", "er", "tre\u00b7mo\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie mu\u00df ans Herz sich fassen,", "tokens": ["Sie", "mu\u00df", "ans", "Herz", "sich", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil sie dort was verliert.", "tokens": ["Weil", "sie", "dort", "was", "ver\u00b7liert", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PWS", "VVFIN", "$."], "meter": "--+--+", "measure": "anapaest.di.plus"}}, "stanza.127": {"line.1": {"text": "Sie f\u00fchlt sich wie erstochen:", "tokens": ["Sie", "f\u00fchlt", "sich", "wie", "er\u00b7sto\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "KOKOM", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Heinz geh\u00f6rt Rosa an!", "tokens": ["Heinz", "ge\u00b7h\u00f6rt", "Ro\u00b7sa", "an", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "NE", "PTKVZ", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Rosa ist er versprochen!", "tokens": ["Ro\u00b7sa", "ist", "er", "ver\u00b7spro\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Sie hat kein Recht daran!", "tokens": ["Sie", "hat", "kein", "Recht", "da\u00b7ran", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.128": {"line.1": {"text": "Es zieht die Tr\u00e4n' wie S\u00e4ure", "tokens": ["Es", "zieht", "die", "Tr\u00e4n'", "wie", "S\u00e4u\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "KOKOM", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Linien durchs Ru\u00dfgesicht.", "tokens": ["Li\u00b7ni\u00b7en", "durchs", "Ru\u00df\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie sch\u00f6n bl\u00e4st Heinz der Teure!", "tokens": ["Wie", "sch\u00f6n", "bl\u00e4st", "Heinz", "der", "Teu\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "NE", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Schw\u00e4rze kennt er nicht.", "tokens": ["Und", "Schw\u00e4r\u00b7ze", "kennt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.129": {"line.1": {"text": "Keine hat er vergessen,", "tokens": ["Kei\u00b7ne", "hat", "er", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Doch auch behalten \u2013 nie.", "tokens": ["Doch", "auch", "be\u00b7hal\u00b7ten", "\u2013", "nie", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "ADV", "VVINF", "$(", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf nichts war er versessen,", "tokens": ["Auf", "nichts", "war", "er", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Nur auf die Rosalie.", "tokens": ["Nur", "auf", "die", "Ro\u00b7sa\u00b7lie", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.130": {"line.1": {"text": "So denkt es sich Babette", "tokens": ["So", "denkt", "es", "sich", "Ba\u00b7bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Ganz schmierig im Gesicht.", "tokens": ["Ganz", "schmie\u00b7rig", "im", "Ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn sie nicht Ru\u00df dran h\u00e4tte,", "tokens": ["Wenn", "sie", "nicht", "Ru\u00df", "dran", "h\u00e4t\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "NN", "PAV", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "W\u00e4r sie wie ein Gedicht.", "tokens": ["W\u00e4r", "sie", "wie", "ein", "Ge\u00b7dicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.131": {"line.1": {"text": "Rosa wollt' er nicht r\u00fchren", "tokens": ["Ro\u00b7sa", "wollt'", "er", "nicht", "r\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "Der Heinz, wie sonst er's tat,", "tokens": ["Der", "Heinz", ",", "wie", "sonst", "er's", "tat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil er ja zum Verf\u00fchren", "tokens": ["Weil", "er", "ja", "zum", "Ver\u00b7f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPRART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Die andern Alle hat.", "tokens": ["Die", "an\u00b7dern", "Al\u00b7le", "hat", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.132": {"line.1": {"text": "Auch denkt sich jetzt Babette", "tokens": ["Auch", "denkt", "sich", "jetzt", "Ba\u00b7bet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im Herz den Hexenschu\u00df:", "tokens": ["Im", "Herz", "den", "He\u00b7xen\u00b7schu\u00df", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbwenn keins gesprochen h\u00e4tte!", "tokens": ["\u00bb", "wenn", "keins", "ge\u00b7spro\u00b7chen", "h\u00e4t\u00b7te", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KOUS", "PIS", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da ich doch horchen mu\u00df!\u00ab", "tokens": ["Da", "ich", "doch", "hor\u00b7chen", "mu\u00df", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.133": {"line.1": {"text": "Denn Heinz, er ging zur Stunde,", "tokens": ["Denn", "Heinz", ",", "er", "ging", "zur", "Stun\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nachdem Babette sprach,", "tokens": ["Nach\u00b7dem", "Ba\u00b7bet\u00b7te", "sprach", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "NE", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Zur Herrentafelrunde", "tokens": ["Zur", "Her\u00b7ren\u00b7ta\u00b7fel\u00b7run\u00b7de"], "token_info": ["word", "word"], "pos": ["APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und machte einen Krach.", "tokens": ["Und", "mach\u00b7te", "ei\u00b7nen", "Krach", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.134": {"line.1": {"text": "Schlug sich dann ohne Sorgen", "tokens": ["Schlug", "sich", "dann", "oh\u00b7ne", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Im W\u00e4ldchen mit dem Herrn.", "tokens": ["Im", "W\u00e4ld\u00b7chen", "mit", "dem", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kaum lag er tot am Morgen,", "tokens": ["Kaum", "lag", "er", "tot", "am", "Mor\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da h\u00e4tt' ihn Jeder gern.", "tokens": ["Da", "h\u00e4tt'", "ihn", "Je\u00b7der", "gern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIS", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.135": {"line.1": {"text": "Ihm flie\u00dft vom Herz ein F\u00e4dchen", "tokens": ["Ihm", "flie\u00dft", "vom", "Herz", "ein", "F\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Tiefrot und leuchtet sehr,", "tokens": ["Tief\u00b7rot", "und", "leuch\u00b7tet", "sehr", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil Heinz von seinen M\u00e4dchen", "tokens": ["Weil", "Heinz", "von", "sei\u00b7nen", "M\u00e4d\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verteidigte die Ehr!", "tokens": ["Ver\u00b7tei\u00b7dig\u00b7te", "die", "Ehr", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.136": {"line.1": {"text": "Babett, wenn auch gewaschen,", "tokens": ["Ba\u00b7bett", ",", "wenn", "auch", "ge\u00b7wa\u00b7schen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "F\u00fchlt st\u00fcndlich sich nicht rein.", "tokens": ["F\u00fchlt", "st\u00fcnd\u00b7lich", "sich", "nicht", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PRF", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Schuld sitzt in ihren Taschen,", "tokens": ["Schuld", "sitzt", "in", "ih\u00b7ren", "Ta\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Schwarz wie Kamine sein.", "tokens": ["Schwarz", "wie", "Ka\u00b7mi\u00b7ne", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VAINF", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.137": {"line.1": {"text": "Sie m\u00f6cht' am Sarge toben,", "tokens": ["Sie", "m\u00f6cht'", "am", "Sar\u00b7ge", "to\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Weil sie jetzt nichts mehr hat,", "tokens": ["Weil", "sie", "jetzt", "nichts", "mehr", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "ADV", "VAFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Als in dem Schornstein oben", "tokens": ["Als", "in", "dem", "Schorn\u00b7stein", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den Titel Schornsteinrat.", "tokens": ["Den", "Ti\u00b7tel", "Schorn\u00b7stein\u00b7rat", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.138": {"line.1": {"text": "\u00bbnun m\u00f6cht ich\u00ab, sprach die Amme,", "tokens": ["\u00bb", "nun", "m\u00f6cht", "ich", "\u00ab", ",", "sprach", "die", "Am\u00b7me", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VMFIN", "PPER", "$(", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbeinmal die Tassen schwenken.", "tokens": ["\u00bb", "ein\u00b7mal", "die", "Tas\u00b7sen", "schwen\u00b7ken", "."], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Rest schmeckt stets infame.", "tokens": ["Der", "Rest", "schmeckt", "stets", "in\u00b7fa\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Leben tut Gr\u00e4ber schenken\u00ab \u2013", "tokens": ["Le\u00b7ben", "tut", "Gr\u00e4\u00b7ber", "schen\u00b7ken", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "NN", "VVINF", "$(", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}}}}