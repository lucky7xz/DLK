{"textgrid.poem.47920": {"metadata": {"author": {"name": "Klaj, Johann", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich wei\u00df/ ich wei\u00df/ wie viel an d\u1ebd verglast\u1ebd Schantzen", "genre": "verse", "period": "N.A.", "pub_year": 1636, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wei\u00df/ ich wei\u00df/ wie viel an d\u1ebd verglast\u1ebd Schantzen", "tokens": ["Ich", "wei\u00df", "/", "ich", "wei\u00df", "/", "wie", "viel", "an", "d\u1ebd", "ver\u00b7glast\u1ebd", "Schant\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "KOKOM", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "goldg\u00fcldne Sternlein tantzen.", "tokens": ["gold\u00b7g\u00fcld\u00b7ne", "Stern\u00b7lein", "tant\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich wei\u00df ein reiches Reich/", "tokens": ["Ich", "wei\u00df", "ein", "rei\u00b7ches", "Reich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "dem unser Reich nicht gleich.", "tokens": ["dem", "un\u00b7ser", "Reich", "nicht", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es hilfft mich nichts. Das n\u00fctzt/ die Stunden \u00fcberschlagen/", "tokens": ["Es", "hilfft", "mich", "nichts", ".", "Das", "n\u00fctzt", "/", "die", "Stun\u00b7den", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$.", "PDS", "VVFIN", "$(", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "die uns das Heil getragen;", "tokens": ["die", "uns", "das", "Heil", "ge\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Es f\u00fchrt uns auf die Spur", "tokens": ["Es", "f\u00fchrt", "uns", "auf", "die", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "der blinden Juden Vhr.", "tokens": ["der", "blin\u00b7den", "Ju\u00b7den", "Vhr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Vm Eins k\u00f6mmt Gottes Sohn", "tokens": ["Vm", "Eins", "k\u00f6mmt", "Got\u00b7tes", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "weint mit uns in die Wette/", "tokens": ["weint", "mit", "uns", "in", "die", "Wet\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "legt an de\u00df Fleisches Kleid/", "tokens": ["legt", "an", "de\u00df", "Flei\u00b7sches", "Kleid", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "und tr\u00e4get Menschenleid.", "tokens": ["und", "tr\u00e4\u00b7get", "Men\u00b7schen\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Vm Drey spielt er mit uns/ es hat jhm viel gestanden/", "tokens": ["Vm", "Drey", "spielt", "er", "mit", "uns", "/", "es", "hat", "jhm", "viel", "ge\u00b7stan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "CARD", "VVFIN", "PPER", "APPR", "PPER", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "viel/ viel stie\u00df jhm zu Handen/", "tokens": ["viel", "/", "viel", "stie\u00df", "jhm", "zu", "Han\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": "Durst/ Hunger/ Hitze/ Frost/", "tokens": ["Durst", "/", "Hun\u00b7ger", "/", "Hit\u00b7ze", "/", "Frost", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$(", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.16": {"text": "am Ende Wermut kost.", "tokens": ["am", "En\u00b7de", "Wer\u00b7mut", "kost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Vm Sechse gieng recht an das Trauerspiel/ das Bluten/", "tokens": ["Vm", "Sech\u00b7se", "gieng", "recht", "an", "das", "Trau\u00b7er\u00b7spiel", "/", "das", "Blu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Creutz/ Ketten/ Geisseln/ Ruten/", "tokens": ["Creutz", "/", "Ket\u00b7ten", "/", "Geis\u00b7seln", "/", "Ru\u00b7ten", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Speer/ N\u00e4gel/ W\u00fcrfel/ Dorn", "tokens": ["Speer", "/", "N\u00e4\u00b7gel", "/", "W\u00fcr\u00b7fel", "/", "Dorn"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "vers\u00f6hnen Gottes Zorn.", "tokens": ["ver\u00b7s\u00f6h\u00b7nen", "Got\u00b7tes", "Zorn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Vm Neune stirbt/ hilf Gott! als wie ein Dieb/ das Leben/", "tokens": ["Vm", "Neu\u00b7ne", "stirbt", "/", "hilf", "Gott", "!", "als", "wie", "ein", "Dieb", "/", "das", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$(", "VVIMP", "NN", "$.", "KOUS", "KOKOM", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "der Vnschuld Zeugni\u00df geben", "tokens": ["der", "Vn\u00b7schuld", "Zeug\u00b7ni\u00df", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "das aufger\u00fchrte Rund/", "tokens": ["das", "auf\u00b7ge\u00b7r\u00fchr\u00b7te", "Rund", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "der dreygeschnautzte Hund.", "tokens": ["der", "drey\u00b7ge\u00b7schnautz\u00b7te", "Hund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Es ist Nacht/ nemet ab/ von der versteinten Eiche", "tokens": ["Es", "ist", "Nacht", "/", "ne\u00b7met", "ab", "/", "von", "der", "ver\u00b7stein\u00b7ten", "Ei\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$(", "VVFIN", "PTKVZ", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.26": {"text": "die grosse Sch\u00e4ferleiche", "tokens": ["die", "gros\u00b7se", "Sch\u00e4\u00b7fer\u00b7lei\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "salbt sie mit Spezerey/", "tokens": ["salbt", "sie", "mit", "Spe\u00b7ze\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.28": {"text": "und setzt sie kostbar bey.", "tokens": ["und", "setzt", "sie", "kost\u00b7bar", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Ach Weh! das Aas steht feil/ nur zwey sind/ die da kauffen/", "tokens": ["Ach", "Weh", "!", "das", "Aas", "steht", "feil", "/", "nur", "zwey", "sind", "/", "die", "da", "kauf\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$(", "ADV", "CARD", "VAFIN", "$(", "ART", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "au\u00df einem solchen Hauffen/", "tokens": ["au\u00df", "ei\u00b7nem", "sol\u00b7chen", "Hauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "ich will der Dritte seyn/", "tokens": ["ich", "will", "der", "Drit\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.32": {"text": "den Kauff mit tretten ein.", "tokens": ["den", "Kauff", "mit", "tret\u00b7ten", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Ich will das heilge Grab mit Rosmarin besetzen/", "tokens": ["Ich", "will", "das", "heil\u00b7ge", "Grab", "mit", "Ros\u00b7ma\u00b7rin", "be\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "mit Augenregnen netzen", "tokens": ["mit", "Au\u00b7gen\u00b7reg\u00b7nen", "net\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "und di\u00df/ was hier gepropfft/", "tokens": ["und", "di\u00df", "/", "was", "hier", "ge\u00b7propfft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$(", "PWS", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "nur Zehrenna\u00df betropfft.", "tokens": ["nur", "Zeh\u00b7ren\u00b7na\u00df", "be\u00b7tropfft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Die liebe Liebe hat ein Abendmal gerahten/", "tokens": ["Die", "lie\u00b7be", "Lie\u00b7be", "hat", "ein", "A\u00b7bend\u00b7mal", "ge\u00b7rah\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die liebe Liebe hat ein Abendmal gebraten/", "tokens": ["die", "lie\u00b7be", "Lie\u00b7be", "hat", "ein", "A\u00b7bend\u00b7mal", "ge\u00b7bra\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die liebe Liebe hat di\u00df Abendmal erdacht/", "tokens": ["die", "lie\u00b7be", "Lie\u00b7be", "hat", "di\u00df", "A\u00b7bend\u00b7mal", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PDS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df liebe Lieb au\u00df Lieb es esse bey der Nacht.", "tokens": ["da\u00df", "lie\u00b7be", "Lieb", "au\u00df", "Lieb", "es", "es\u00b7se", "bey", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "NN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Die Magenleere Hungersnoht", "tokens": ["Die", "Ma\u00b7gen\u00b7lee\u00b7re", "Hun\u00b7gers\u00b7noht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in dieser Welt mich naget/", "tokens": ["in", "die\u00b7ser", "Welt", "mich", "na\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "der Durst/ der \u00e4rger als der Tod/", "tokens": ["der", "Durst", "/", "der", "\u00e4r\u00b7ger", "als", "der", "Tod", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJD", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "im d\u00fcrren Sand mich plaget/", "tokens": ["im", "d\u00fcr\u00b7ren", "Sand", "mich", "pla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "der Hunger qu\u00e4let mich zwar sehr/", "tokens": ["der", "Hun\u00b7ger", "qu\u00e4\u00b7let", "mich", "zwar", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der Durst doch tausendmal vielmehr/", "tokens": ["der", "Durst", "doch", "tau\u00b7send\u00b7mal", "viel\u00b7mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "mein Geist steht auf der Zunge.", "tokens": ["mein", "Geist", "steht", "auf", "der", "Zun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der Erdkrei\u00df l\u00e4det mich zu sich/", "tokens": ["Der", "Erd\u00b7krei\u00df", "l\u00e4\u00b7det", "mich", "zu", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zu sich/ auf sich zu Gaste/", "tokens": ["zu", "sich", "/", "auf", "sich", "zu", "Gas\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "$(", "APPR", "PRF", "APPR", "NN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "er spricht: Komm her und setze dich/", "tokens": ["er", "spricht", ":", "Komm", "her", "und", "set\u00b7ze", "dich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "i\u00df/ was dir schmeckt und raste/", "tokens": ["i\u00df", "/", "was", "dir", "schmeckt", "und", "ras\u00b7te", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "greiff an die Trachten ohne Zahl/", "tokens": ["greiff", "an", "die", "Trach\u00b7ten", "oh\u00b7ne", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "la\u00df dir wol seyn bey meinem Mahl/", "tokens": ["la\u00df", "dir", "wol", "seyn", "bey", "mei\u00b7nem", "Mahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VAINF", "APPR", "PPOSAT", "NN", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "ich hab dich hertzlich gerne.", "tokens": ["ich", "hab", "dich", "hertz\u00b7lich", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Es ruffet mir das Weldmeer zu", "tokens": ["Es", "ruf\u00b7fet", "mir", "das", "Weld\u00b7meer", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "au\u00df glasegr\u00fcnem Sale/", "tokens": ["au\u00df", "gla\u00b7se\u00b7gr\u00fc\u00b7nem", "Sa\u00b7le", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "es rufft/ es trinckt sich selbst mir zu", "tokens": ["es", "rufft", "/", "es", "trinckt", "sich", "selbst", "mir", "zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PRF", "ADV", "PPER", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in einer g\u00fcldnen Schale/", "tokens": ["in", "ei\u00b7ner", "g\u00fcld\u00b7nen", "Scha\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "das nasse Wellensch\u00e4umen fleust/", "tokens": ["das", "nas\u00b7se", "Wel\u00b7len\u00b7sch\u00e4u\u00b7men", "fleust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der Strudel Wasserberge geust/", "tokens": ["der", "Stru\u00b7del", "Was\u00b7ser\u00b7ber\u00b7ge", "geust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "als wolt es alls ertr\u00e4ncken.", "tokens": ["als", "wolt", "es", "alls", "er\u00b7tr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich mag nicht Erd/ ich mag nicht Flut/", "tokens": ["Ich", "mag", "nicht", "Erd", "/", "ich", "mag", "nicht", "Flut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "$(", "PPER", "VMFIN", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie sehr sie mir auch wincken/", "tokens": ["wie", "sehr", "sie", "mir", "auch", "win\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mein Jesus ist mein liebstes Gut/", "tokens": ["mein", "Je\u00b7sus", "ist", "mein", "liebs\u00b7tes", "Gut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mein Essen und mein Trincken/", "tokens": ["mein", "Es\u00b7sen", "und", "mein", "Trin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "mein Hertz/ mein allerliebstes Hertz/", "tokens": ["mein", "Hertz", "/", "mein", "al\u00b7ler\u00b7liebs\u00b7tes", "Hertz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sein Abseyn bringt dem Hertzen Schmertz/", "tokens": ["sein", "Ab\u00b7seyn", "bringt", "dem", "Hert\u00b7zen", "Schmertz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "bringt Hungern und auch D\u00fcrsten.", "tokens": ["bringt", "Hun\u00b7gern", "und", "auch", "D\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "ADV", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Mein Br\u00e4utigam erh\u00f6ret di\u00df/", "tokens": ["Mein", "Br\u00e4u\u00b7ti\u00b7gam", "er\u00b7h\u00f6\u00b7ret", "di\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PDS", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erkennet meine L\u00fcste/", "tokens": ["er\u00b7ken\u00b7net", "mei\u00b7ne", "L\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "er spricht: komm her/ komm trinck/ komm i\u00df/", "tokens": ["er", "spricht", ":", "komm", "her", "/", "komm", "trinck", "/", "komm", "i\u00df", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PTKVZ", "$(", "VVFIN", "VVFIN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und gibt mir beide Br\u00fcste", "tokens": ["und", "gibt", "mir", "bei\u00b7de", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "mein Br\u00e4utigam/ mein Himmelszier/", "tokens": ["mein", "Br\u00e4u\u00b7ti\u00b7gam", "/", "mein", "Him\u00b7mels\u00b7zier", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mein Weitzenbrod/ mein Malvasir/", "tokens": ["mein", "Weit\u00b7zen\u00b7brod", "/", "mein", "Mal\u00b7va\u00b7sir", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der mich speist/ der mich tr\u00e4ncket.", "tokens": ["der", "mich", "speist", "/", "der", "mich", "tr\u00e4n\u00b7cket", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$(", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.8": {"line.1": {"text": "Erd ich mach nimmer/ was du hast", "tokens": ["Erd", "ich", "mach", "nim\u00b7mer", "/", "was", "du", "hast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "VVFIN", "ADV", "$(", "PWS", "PPER", "VAFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "auf deiner Tafel stehen/", "tokens": ["auf", "dei\u00b7ner", "Ta\u00b7fel", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Meer ich mag nimmer seyn dein Gast/", "tokens": ["Meer", "ich", "mag", "nim\u00b7mer", "seyn", "dein", "Gast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VMFIN", "ADV", "VAINF", "PPOSAT", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "wie sch\u00f6n die Fluten gehen.", "tokens": ["wie", "sch\u00f6n", "die", "Flu\u00b7ten", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mich speist/ mich tr\u00e4nckt mein Jesus Christ/", "tokens": ["Mich", "speist", "/", "mich", "tr\u00e4nckt", "mein", "Je\u00b7sus", "Christ", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPOSAT", "NE", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "auf seinem Tisch/ der fertig ist/", "tokens": ["auf", "sei\u00b7nem", "Tisch", "/", "der", "fer\u00b7tig", "ist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ART", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "zu welchem ich jetzt gehe.", "tokens": ["zu", "wel\u00b7chem", "ich", "jetzt", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wach auf mein Ehr/ auf Seiten", "tokens": ["Wach", "auf", "mein", "Ehr", "/", "auf", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$(", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "der scharfen Harffen-Psalterspiel/", "tokens": ["der", "schar\u00b7fen", "Ha\u00b7rf\u00b7fen\u00b7Psal\u00b7ter\u00b7spiel", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "ich will mit Ruhm au\u00dfbreiten", "tokens": ["ich", "will", "mit", "Ruhm", "au\u00df\u00b7brei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "de\u00df Herren Wunder ohne Ziel/", "tokens": ["de\u00df", "Her\u00b7ren", "Wun\u00b7der", "oh\u00b7ne", "Ziel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sie singen/ wo die Frommen", "tokens": ["sie", "sin\u00b7gen", "/", "wo", "die", "From\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "im Raht beysammen seyn/", "tokens": ["im", "Raht", "bey\u00b7sam\u00b7men", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und wo zusammen kommen", "tokens": ["und", "wo", "zu\u00b7sam\u00b7men", "kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "die V\u00f6lcker ins gemein/", "tokens": ["die", "V\u00f6l\u00b7cker", "ins", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "wer jhre Gr\u00f6\u00df betrachtet/", "tokens": ["wer", "jhre", "Gr\u00f6\u00df", "be\u00b7trach\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "so viel er soll und kan/", "tokens": ["so", "viel", "er", "soll", "und", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VMFIN", "KON", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "sie Himmelh\u00f6her achtet/", "tokens": ["sie", "Him\u00b7mel\u00b7h\u00f6\u00b7her", "ach\u00b7tet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "hat eitel Lust daran.", "tokens": ["hat", "ei\u00b7tel", "Lust", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Gesetz/ das er gesetzet/", "tokens": ["Ge\u00b7setz", "/", "das", "er", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "ist lauter Herrlichkeit und Zier/", "tokens": ["ist", "lau\u00b7ter", "Herr\u00b7lich\u00b7keit", "und", "Zier", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "das Leib und Seel ergetzet/", "tokens": ["das", "Leib", "und", "Seel", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "sein Recht bleibt aufrecht f\u00fcr und f\u00fcr/", "tokens": ["sein", "Recht", "bleibt", "auf\u00b7recht", "f\u00fcr", "und", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "KON", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er hat/ sein zu gedencken/", "tokens": ["er", "hat", "/", "sein", "zu", "ge\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VAINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "ein Wundermahl gestifft/", "tokens": ["ein", "Wun\u00b7der\u00b7mahl", "ge\u00b7stifft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "den Erdkrei\u00df zu beschencken", "tokens": ["den", "Erd\u00b7krei\u00df", "zu", "be\u00b7schen\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "mit Gaben und mit Gifft/", "tokens": ["mit", "Ga\u00b7ben", "und", "mit", "Gifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "er hat sein Volck gespeiset/", "tokens": ["er", "hat", "sein", "Volck", "ge\u00b7spei\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "da\u00df jhn mit F\u00fcrchten ehrt/", "tokens": ["da\u00df", "jhn", "mit", "F\u00fcrch\u00b7ten", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "sich gn\u00e4diglich erweiset/", "tokens": ["sich", "gn\u00e4\u00b7di\u00b7glich", "er\u00b7wei\u00b7set", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "den Bund niemal versehrt.", "tokens": ["den", "Bund", "nie\u00b7mal", "ver\u00b7sehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Es mu\u00df bey d\u00fcstern Zeiten", "tokens": ["Es", "mu\u00df", "bey", "d\u00fcs\u00b7tern", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "der tunckelbraunen Schattennacht", "tokens": ["der", "tun\u00b7ckel\u00b7brau\u00b7nen", "Schat\u00b7ten\u00b7nacht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "das Liecht den Frommen leiten/", "tokens": ["das", "Liecht", "den", "From\u00b7men", "lei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "das Liecht/ das Nacht zum Tage macht/", "tokens": ["das", "Liecht", "/", "das", "Nacht", "zum", "Ta\u00b7ge", "macht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "barmhertzig seyn/ gern leihen/", "tokens": ["barm\u00b7hert\u00b7zig", "seyn", "/", "gern", "lei\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$(", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "bekleiden/ was da blo\u00df/", "tokens": ["be\u00b7klei\u00b7den", "/", "was", "da", "blo\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "$(", "PWS", "ADV", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "de\u00df Nechsten Fehl verzeihen/", "tokens": ["de\u00df", "Nechs\u00b7ten", "Fehl", "ver\u00b7zei\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "macht unverzagt und gro\u00df/", "tokens": ["macht", "un\u00b7ver\u00b7zagt", "und", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "solch Thun mu\u00df fruchtbar gr\u00fcnen/", "tokens": ["solch", "Thun", "mu\u00df", "frucht\u00b7bar", "gr\u00fc\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "so lang die Sonne wacht", "tokens": ["so", "lang", "die", "Son\u00b7ne", "wacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "und an der Himmelb\u00fchnen", "tokens": ["und", "an", "der", "Him\u00b7mel\u00b7b\u00fch\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Mittag und N\u00e4chte macht.", "tokens": ["Mit\u00b7tag", "und", "N\u00e4ch\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Gott hat sich hoch gesetzet", "tokens": ["Gott", "hat", "sich", "hoch", "ge\u00b7set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "und schauet auf de\u00df Vntern Noht/", "tokens": ["und", "schau\u00b7et", "auf", "de\u00df", "Vn\u00b7tern", "Noht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was nidrig wird gesch\u00e4tzet/", "tokens": ["was", "nid\u00b7rig", "wird", "ge\u00b7sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "erh\u00f6het er au\u00df Staub und Koht/", "tokens": ["er\u00b7h\u00f6\u00b7het", "er", "au\u00df", "Staub", "und", "Koht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wei\u00df es hernach zu sch\u00fctzen/", "tokens": ["wei\u00df", "es", "her\u00b7nach", "zu", "sch\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "da\u00df es kein Fall gef\u00e4hrt/", "tokens": ["da\u00df", "es", "kein", "Fall", "ge\u00b7f\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "kan neben F\u00fcrsten sitzen", "tokens": ["kan", "ne\u00b7ben", "F\u00fcrs\u00b7ten", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "VVINF"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "im hohen Ehrenwerth/", "tokens": ["im", "ho\u00b7hen", "Eh\u00b7ren\u00b7werth", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "den M\u00fcttern mu\u00df gelingen", "tokens": ["den", "M\u00fct\u00b7tern", "mu\u00df", "ge\u00b7lin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "jhr W\u00fcnschen au\u00df und au\u00df/", "tokens": ["jhr", "W\u00fcn\u00b7schen", "au\u00df", "und", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "KON", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "da\u00df sie viel Kinder bringen/", "tokens": ["da\u00df", "sie", "viel", "Kin\u00b7der", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "besitzen Tisch und Hau\u00df.", "tokens": ["be\u00b7sit\u00b7zen", "Tisch", "und", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Als Israel dem Lande", "tokens": ["Als", "Is\u00b7rael", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "de\u00df Nils gegeben gute Nacht/", "tokens": ["de\u00df", "Nils", "ge\u00b7ge\u00b7ben", "gu\u00b7te", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und Jacobs Hau\u00df vom Bande", "tokens": ["und", "Ja\u00b7cobs", "Hau\u00df", "vom", "Ban\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "der Dienstbarkeit sich lo\u00df gemacht/", "tokens": ["der", "Dienst\u00b7bar\u00b7keit", "sich", "lo\u00df", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "hat Judas gleich bekommen", "tokens": ["hat", "Ju\u00b7das", "gleich", "be\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NE", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "de\u00df Herren Heiligthum/", "tokens": ["de\u00df", "Her\u00b7ren", "Hei\u00b7lig\u00b7thum", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und Israel genommen", "tokens": ["und", "Is\u00b7rael", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "der Herrschafft hohen Ruhm/", "tokens": ["der", "Herr\u00b7schafft", "ho\u00b7hen", "Ruhm", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "das Meer mu\u00df r\u00fcckwerts dringen/", "tokens": ["das", "Meer", "mu\u00df", "r\u00fcck\u00b7werts", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "der Jordan nimmt die Flucht/", "tokens": ["der", "Jor\u00b7dan", "nimmt", "die", "Flucht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "die Berg wie L\u00e4mmer springen/", "tokens": ["die", "Berg", "wie", "L\u00e4m\u00b7mer", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "die H\u00fcgel wie Schafszucht.", "tokens": ["die", "H\u00fc\u00b7gel", "wie", "Schafs\u00b7zucht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.14": {"line.1": {"text": "Wer hat dich heissen fliessen/", "tokens": ["Wer", "hat", "dich", "heis\u00b7sen", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "dich Meer/ dich Jordan hinter sich?", "tokens": ["dich", "Meer", "/", "dich", "Jor\u00b7dan", "hin\u00b7ter", "sich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$(", "PPER", "NE", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was h\u00fcpfft jhr mit den F\u00fcssen/", "tokens": ["was", "h\u00fcpfft", "jhr", "mit", "den", "F\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "jhr Berg/ jhr H\u00fcgel freudiglich?", "tokens": ["jhr", "Berg", "/", "jhr", "H\u00fc\u00b7gel", "freu\u00b7dig\u00b7lich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wann sich der Herr nur r\u00fchret/", "tokens": ["Wann", "sich", "der", "Herr", "nur", "r\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "so lebt der Erden Fu\u00df/", "tokens": ["so", "lebt", "der", "Er\u00b7den", "Fu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "wird Jacobs Gott gesp\u00fcret/", "tokens": ["wird", "Ja\u00b7cobs", "Gott", "ge\u00b7sp\u00fc\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "di\u00df Gantze weichen mu\u00df/", "tokens": ["di\u00df", "Gant\u00b7ze", "wei\u00b7chen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "es mu\u00df der Fels der Erden", "tokens": ["es", "mu\u00df", "der", "Fels", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "ein s\u00fcsses Wasser seyn/", "tokens": ["ein", "s\u00fcs\u00b7ses", "Was\u00b7ser", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "zu f\u00fchlen Brunnen werden", "tokens": ["zu", "f\u00fch\u00b7len", "Brun\u00b7nen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "NN", "VAINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "ein eisenvester Stein.", "tokens": ["ein", "ei\u00b7sen\u00b7ves\u00b7ter", "Stein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Solte nicht beliebet machen/", "tokens": ["Sol\u00b7te", "nicht", "be\u00b7lie\u00b7bet", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "freundlich seyn/ zun S\u00fcndern lachen/", "tokens": ["freund\u00b7lich", "seyn", "/", "zun", "S\u00fcn\u00b7dern", "la\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$(", "APPRART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sonder Galle/ sonder Trug?", "tokens": ["son\u00b7der", "Gal\u00b7le", "/", "son\u00b7der", "Trug", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhr/ jhr Sternen/ die jhr tantzet", "tokens": ["Ihr", "/", "jhr", "Ster\u00b7nen", "/", "die", "jhr", "tant\u00b7zet"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$(", "PPOSAT", "NN", "$(", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und das Leben eingepflantzet/", "tokens": ["und", "das", "Le\u00b7ben", "ein\u00b7ge\u00b7pflant\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gebet unserm Klagen Fug.", "tokens": ["ge\u00b7bet", "un\u00b7serm", "Kla\u00b7gen", "Fug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "War der Mund nur aufgeschlossen/", "tokens": ["War", "der", "Mund", "nur", "auf\u00b7ge\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Honigworte h\u00e4uffig flossen/", "tokens": ["Ho\u00b7nig\u00b7wor\u00b7te", "h\u00e4uf\u00b7fig", "flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "er gieng selbst auf Bl\u00f6de lo\u00df/", "tokens": ["er", "gieng", "selbst", "auf", "Bl\u00f6\u00b7de", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "keinem kont er nichts versagen/", "tokens": ["kei\u00b7nem", "kont", "er", "nichts", "ver\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "keinem keine Bitt abschlagen/", "tokens": ["kei\u00b7nem", "kei\u00b7ne", "Bitt", "ab\u00b7schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIAT", "NN", "VVINF", "$("], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}, "line.6": {"text": "wer Verbrechen noch so gro\u00df.", "tokens": ["wer", "Ver\u00b7bre\u00b7chen", "noch", "so", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Pilgerfreund und selber Pilger/", "tokens": ["Pil\u00b7ger\u00b7freund", "und", "sel\u00b7ber", "Pil\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bettelarm/ doch Armuttilger/", "tokens": ["Bet\u00b7tel\u00b7arm", "/", "doch", "Ar\u00b7mut\u00b7til\u00b7ger", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "du tr\u00e4gst auf den Achseln zu/", "tokens": ["du", "tr\u00e4gst", "auf", "den", "Ach\u00b7seln", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKZU", "$("], "meter": "+++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "was sich sundlich hat verfangen/", "tokens": ["was", "sich", "sund\u00b7lich", "hat", "ver\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADJD", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ohne Weg den Weg gegangen/", "tokens": ["oh\u00b7ne", "Weg", "den", "Weg", "ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sonder Weide/ sonder Ruh.", "tokens": ["son\u00b7der", "Wei\u00b7de", "/", "son\u00b7der", "Ruh", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Was dein Wille/ was dein Wesen/", "tokens": ["Was", "dein", "Wil\u00b7le", "/", "was", "dein", "We\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "$(", "PWS", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hast du selbsten abgelesen/", "tokens": ["hast", "du", "selbs\u00b7ten", "ab\u00b7ge\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Liechter auf den Weg gesteckt;", "tokens": ["Liech\u00b7ter", "auf", "den", "Weg", "ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "du hast einen Glantz gef\u00fchret/", "tokens": ["du", "hast", "ei\u00b7nen", "Glantz", "ge\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "gleich den Spiegeln au\u00dfpoliret/", "tokens": ["gleich", "den", "Spie\u00b7geln", "au\u00df\u00b7po\u00b7li\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "der den S\u00fcndenwust entdeckt.", "tokens": ["der", "den", "S\u00fcn\u00b7den\u00b7wust", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Die der Sonnenbrand geschw\u00e4rtzet/", "tokens": ["Die", "der", "Son\u00b7nen\u00b7brand", "ge\u00b7schw\u00e4rt\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die die Tageslast enthertzet/", "tokens": ["die", "die", "Ta\u00b7ges\u00b7last", "en\u00b7thert\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die vor Hitze blind und taub", "tokens": ["die", "vor", "Hit\u00b7ze", "blind", "und", "taub"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ADJD", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "au\u00dfgemergelt/ abgemattet/", "tokens": ["au\u00df\u00b7ge\u00b7mer\u00b7gelt", "/", "ab\u00b7ge\u00b7mat\u00b7tet", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$(", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "deines Creutzes Linde schattet/", "tokens": ["dei\u00b7nes", "Creut\u00b7zes", "Lin\u00b7de", "schat\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "spielend/ k\u00fchlet Lindenlaub.", "tokens": ["spie\u00b7lend", "/", "k\u00fch\u00b7let", "Lin\u00b7den\u00b7laub", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$(", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Dir dem Artzt gehorsam waren", "tokens": ["Dir", "dem", "Artzt", "ge\u00b7hor\u00b7sam", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die verdorrten Fieberscharen/", "tokens": ["die", "ver\u00b7dorr\u00b7ten", "Fie\u00b7ber\u00b7scha\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "es war \u00fcm ein einig Wort/", "tokens": ["es", "war", "\u00fcm", "ein", "ei\u00b7nig", "Wort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJD", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Kr\u00fcppel lieffen ohne Kr\u00fccken/", "tokens": ["Kr\u00fcp\u00b7pel", "lief\u00b7fen", "oh\u00b7ne", "Kr\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "konten sich zu wandern schicken/", "tokens": ["kon\u00b7ten", "sich", "zu", "wan\u00b7dern", "schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKZU", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "lieffen ohne Steltzen fort.", "tokens": ["lief\u00b7fen", "oh\u00b7ne", "Stelt\u00b7zen", "fort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Auch die stockgebornen Blinden", "tokens": ["Auch", "die", "stock\u00b7ge\u00b7bor\u00b7nen", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "konten ohne Leiter finden", "tokens": ["kon\u00b7ten", "oh\u00b7ne", "Lei\u00b7ter", "fin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "den vor niegesehnen Weg/", "tokens": ["den", "vor", "nie\u00b7ge\u00b7seh\u00b7nen", "Weg", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "den Weg/ der da hat gegeben", "tokens": ["den", "Weg", "/", "der", "da", "hat", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "ADV", "VAFIN", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Augen/ Seele/ Leib und Leben/", "tokens": ["Au\u00b7gen", "/", "See\u00b7le", "/", "Leib", "und", "Le\u00b7ben", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "selbsten Leben/ Liecht und Steg.", "tokens": ["selbs\u00b7ten", "Le\u00b7ben", "/", "Liecht", "und", "Steg", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.22": {"line.1": {"text": "Ohren/ die gantz zugedemmet/", "tokens": ["Oh\u00b7ren", "/", "die", "gantz", "zu\u00b7ge\u00b7dem\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "ADV", "VVPP", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Zungen/ fesselvest gehemmet/", "tokens": ["Zun\u00b7gen", "/", "fes\u00b7sel\u00b7vest", "ge\u00b7hem\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sind zu rechte wiederbracht/", "tokens": ["sind", "zu", "rech\u00b7te", "wie\u00b7der\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ja der Taube h\u00f6rt den Stummen/", "tokens": ["ja", "der", "Tau\u00b7be", "h\u00f6rt", "den", "Stum\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stumm und Tauber sich vermummen/", "tokens": ["Stumm", "und", "Tau\u00b7ber", "sich", "ver\u00b7mum\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mit dem Judas bey der Nacht.", "tokens": ["mit", "dem", "Ju\u00b7das", "bey", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ach jhr Narren/ ach jhr Thoren!", "tokens": ["Ach", "jhr", "Nar\u00b7ren", "/", "ach", "jhr", "Tho\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PPOSAT", "NN", "$(", "XY", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der den Finger in die Ohren", "tokens": ["der", "den", "Fin\u00b7ger", "in", "die", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dir du tauber Dieb gelegt/", "tokens": ["dir", "du", "tau\u00b7ber", "Dieb", "ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADJA", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stummer/ der die Zung dir r\u00fchret/", "tokens": ["Stum\u00b7mer", "/", "der", "die", "Zung", "dir", "r\u00fch\u00b7ret", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird von euch hinau\u00dfgef\u00fchret/", "tokens": ["wird", "von", "euch", "hin\u00b7au\u00df\u00b7ge\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vntreu seinen Herren schl\u00e4gt.", "tokens": ["Vntreu", "sei\u00b7nen", "Her\u00b7ren", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Mein Gott war\u00fcm/ war\u00fcm mein Gott", "tokens": ["Mein", "Gott", "wa\u00b7r\u00fcm", "/", "wa\u00b7r\u00fcm", "mein", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "$(", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hast du mich so verlassen/", "tokens": ["hast", "du", "mich", "so", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "VVINF", "$("], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "ich heul in meinem Creutz und Spott/", "tokens": ["ich", "heul", "in", "mei\u00b7nem", "Creutz", "und", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00fclf ist auf keiner Gassen/", "tokens": ["H\u00fclf", "ist", "auf", "kei\u00b7ner", "Gas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "ich ruffe/ wann die Sonne wacht/", "tokens": ["ich", "ruf\u00b7fe", "/", "wann", "die", "Son\u00b7ne", "wacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "kein Antwort will gefallen", "tokens": ["kein", "Ant\u00b7wort", "will", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "noch erschallen/", "tokens": ["noch", "er\u00b7schal\u00b7len", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "ich schweig auch nicht bey Nacht/", "tokens": ["ich", "schweig", "auch", "nicht", "bey", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "wenn alles schweigt in allen.", "tokens": ["wenn", "al\u00b7les", "schweigt", "in", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Gott du bist heilig f\u00fcr und f\u00fcr/", "tokens": ["Gott", "du", "bist", "hei\u00b7lig", "f\u00fcr", "und", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VAFIN", "ADJD", "APPR", "KON", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gantz Israel das preiset/", "tokens": ["gantz", "Is\u00b7rael", "das", "prei\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PDS", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "dein hohes Lob/ mit hoher Zier/", "tokens": ["dein", "ho\u00b7hes", "Lob", "/", "mit", "ho\u00b7her", "Zier", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der V\u00e4ter Schar erweiset;", "tokens": ["der", "V\u00e4\u00b7ter", "Schar", "er\u00b7wei\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "den V\u00e4tern/ die im w\u00fcsten Land", "tokens": ["den", "V\u00e4\u00b7tern", "/", "die", "im", "w\u00fcs\u00b7ten", "Land"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "APPRART", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit Hoffen an dir hiengen/", "tokens": ["mit", "Hof\u00b7fen", "an", "dir", "hien\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "zu dir giengen/", "tokens": ["zu", "dir", "gien\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "dir du in freyen Stand", "tokens": ["dir", "du", "in", "frey\u00b7en", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "gen\u00e4digst wollen bringen.", "tokens": ["ge\u00b7n\u00e4\u00b7digst", "wol\u00b7len", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Sie suchten deine Helferhand", "tokens": ["Sie", "such\u00b7ten", "dei\u00b7ne", "Hel\u00b7fer\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit Hofnung/ die da schreyet/", "tokens": ["mit", "Hof\u00b7nung", "/", "die", "da", "schre\u00b7yet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ART", "ADV", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "drauf hast du jhre Schmach gewandt", "tokens": ["drauf", "hast", "du", "jhre", "Schmach", "ge\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sie vor Schand befreyet:", "tokens": ["und", "sie", "vor", "Schand", "be\u00b7fre\u00b7yet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ich aber bin ein Wurm vor Gott/", "tokens": ["Ich", "a\u00b7ber", "bin", "ein", "Wurm", "vor", "Gott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr Aengsten gar verschmachtet/", "tokens": ["f\u00fcr", "A\u00b7engs\u00b7ten", "gar", "ver\u00b7schmach\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "nichts geachtet/", "tokens": ["nichts", "ge\u00b7ach\u00b7tet", "/"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVPP", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "der Leute Hohn und Spott/", "tokens": ["der", "Leu\u00b7te", "Hohn", "und", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "von m\u00e4nniglich/ verachtet.", "tokens": ["von", "m\u00e4n\u00b7nig\u00b7lich", "/", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJD", "$(", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Wer mich siht/ lacht mich h\u00f6nisch an/", "tokens": ["Wer", "mich", "siht", "/", "lacht", "mich", "h\u00f6\u00b7nisch", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$(", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den Leib spottweise r\u00fcttelt/", "tokens": ["den", "Leib", "spott\u00b7wei\u00b7se", "r\u00fct\u00b7telt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "zerrt sein Maul auf/ so weit er kan/", "tokens": ["zerrt", "sein", "Maul", "auf", "/", "so", "weit", "er", "kan", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "$(", "ADV", "ADJD", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Kopf gantz h\u00f6nisch sch\u00fcttelt;", "tokens": ["den", "Kopf", "gantz", "h\u00f6\u00b7nisch", "sch\u00fct\u00b7telt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "der ist es/ der sich machet gro\u00df:", "tokens": ["der", "ist", "es", "/", "der", "sich", "ma\u00b7chet", "gro\u00df", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "$(", "PRELS", "PRF", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er klag es seinem Herren/", "tokens": ["er", "klag", "es", "sei\u00b7nem", "Her\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "der nicht ferren/", "tokens": ["der", "nicht", "fer\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVINF", "$("], "meter": "--+-", "measure": "anapaest.init"}, "line.8": {"text": "der wird jhn machen lo\u00df/", "tokens": ["der", "wird", "jhn", "ma\u00b7chen", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "was jhm zuwider sperren!", "tokens": ["was", "jhm", "zu\u00b7wi\u00b7der", "sper\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Als ich noch lag in finstrer Nacht/", "tokens": ["Als", "ich", "noch", "lag", "in", "finst\u00b7rer", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "warst du mein Gott im Weibe/", "tokens": ["warst", "du", "mein", "Gott", "im", "Wei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "als du mich an das Liecht gebracht", "tokens": ["als", "du", "mich", "an", "das", "Liecht", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "au\u00df meiner Mutter Leibe/", "tokens": ["au\u00df", "mei\u00b7ner", "Mut\u00b7ter", "Lei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "du warst mein Gott/ mein Zuversicht/", "tokens": ["du", "warst", "mein", "Gott", "/", "mein", "Zu\u00b7ver\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als ich noch unerzogen", "tokens": ["als", "ich", "noch", "un\u00b7er\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Milch gesogen", "tokens": ["Milch", "ge\u00b7so\u00b7gen"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "und meine Mutterpflicht", "tokens": ["und", "mei\u00b7ne", "Mut\u00b7ter\u00b7pflicht"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mit Wartung mich gepflogen.", "tokens": ["mit", "War\u00b7tung", "mich", "ge\u00b7pflo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Zeug deine H\u00fclffe ja nicht ein", "tokens": ["Zeug", "dei\u00b7ne", "H\u00fclf\u00b7fe", "ja", "nicht", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV", "PTKNEG", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "denn Angst ist nimmer ferren", "tokens": ["denn", "Angst", "ist", "nim\u00b7mer", "fer\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "kein Helffer hilfft als du allein/", "tokens": ["kein", "Helf\u00b7fer", "hilfft", "als", "du", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "KOUS", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "h\u00f6r/ wie die Stiere plerren/", "tokens": ["h\u00f6r", "/", "wie", "die", "Stie\u00b7re", "pler\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "schau/ wie der Wammenochsen Schar", "tokens": ["schau", "/", "wie", "der", "Wam\u00b7me\u00b7noch\u00b7sen", "Schar"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKVZ", "$(", "KOKOM", "ART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "mit aller Krafft einspringet/", "tokens": ["mit", "al\u00b7ler", "Krafft", "ein\u00b7sprin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "auf mich dringet", "tokens": ["auf", "mich", "drin\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "mit Seel- und Leibsgefahr/", "tokens": ["mit", "Seel", "und", "Leibs\u00b7ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mich untertritt und zwinget.", "tokens": ["mich", "un\u00b7ter\u00b7tritt", "und", "zwin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Sie sperren jhren Rachen auf", "tokens": ["Sie", "sper\u00b7ren", "jhren", "Ra\u00b7chen", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie L\u00f6wen/ die da br\u00fcllen/", "tokens": ["wie", "L\u00f6\u00b7wen", "/", "die", "da", "br\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$(", "ART", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "ich truckne wie ein Wasserlauf/", "tokens": ["ich", "truck\u00b7ne", "wie", "ein", "Was\u00b7ser\u00b7lauf", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "de\u00df Quell verseugt ohn Quillen/", "tokens": ["de\u00df", "Quell", "ver\u00b7seugt", "ohn", "Quil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "es will Gelenck/ es will Gebein/", "tokens": ["es", "will", "Ge\u00b7lenck", "/", "es", "will", "Ge\u00b7bein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$(", "PPER", "VMFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als wer es au\u00dfgerissen/", "tokens": ["als", "wer", "es", "au\u00df\u00b7ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "sich nicht schliessen/", "tokens": ["sich", "nicht", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "wie Wachs vom Sonnenschein", "tokens": ["wie", "Wachs", "vom", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mu\u00df mein Hertz fliessig fliessen.", "tokens": ["mu\u00df", "mein", "Hertz", "flies\u00b7sig", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Ich bin ein Scherbend\u00fcrrer Mann/", "tokens": ["Ich", "bin", "ein", "Scher\u00b7ben\u00b7d\u00fcr\u00b7rer", "Mann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kein Krafft/ kein Safft sich reget/", "tokens": ["kein", "Krafft", "/", "kein", "Safft", "sich", "re\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIAT", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "die Zung am Gaumen klebet an/", "tokens": ["die", "Zung", "am", "Gau\u00b7men", "kle\u00b7bet", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich werd von dir geleget/", "tokens": ["ich", "werd", "von", "dir", "ge\u00b7le\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "von dir in schwartzen Todensand/", "tokens": ["von", "dir", "in", "schwart\u00b7zen", "To\u00b7den\u00b7sand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "es haben mir die Hunde/", "tokens": ["es", "ha\u00b7ben", "mir", "die", "Hun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "bi\u00df zu Grunde/", "tokens": ["bi\u00df", "zu", "Grun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "durchgraben Fu\u00df und Hand/", "tokens": ["durch\u00b7gra\u00b7ben", "Fu\u00df", "und", "Hand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mein Leib ist eine Wunde.", "tokens": ["mein", "Leib", "ist", "ei\u00b7ne", "Wun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Ich m\u00f6chte alle mein Gebein", "tokens": ["Ich", "m\u00f6ch\u00b7te", "al\u00b7le", "mein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an Fingern abezehlen/", "tokens": ["an", "Fin\u00b7gern", "a\u00b7be\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "sie haben aber Lust allein/", "tokens": ["sie", "ha\u00b7ben", "a\u00b7ber", "Lust", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit W\u00fcrfelspiel mich qu\u00e4len;", "tokens": ["mit", "W\u00fcr\u00b7fel\u00b7spiel", "mich", "qu\u00e4\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wann sie die Schantz (O S\u00fcnd! O Schand!)", "tokens": ["wann", "sie", "die", "Schantz", "(", "O", "S\u00fcnd", "!", "O", "Schand", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$(", "NE", "NN", "$.", "NE", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00fcm meine Kleider schlagen/", "tokens": ["\u00fcm", "mei\u00b7ne", "Klei\u00b7der", "schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nach Behagen", "tokens": ["nach", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Lo\u00df werfen \u00fcm Gewand/", "tokens": ["Lo\u00df", "wer\u00b7fen", "\u00fcm", "Ge\u00b7wand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "das ich am Leib getragen.", "tokens": ["das", "ich", "am", "Leib", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Tritt Helffer/ tritt doch n\u00e4her bey/", "tokens": ["Tritt", "Helf\u00b7fer", "/", "tritt", "doch", "n\u00e4\u00b7her", "bey", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "VVFIN", "ADV", "ADJD", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "was wilt du ferne gehen?", "tokens": ["was", "wilt", "du", "fer\u00b7ne", "ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mach meine Seel vom Schwerte frey/", "tokens": ["mach", "mei\u00b7ne", "Seel", "vom", "Schwer\u00b7te", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPRART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df sie getrost m\u00f6g stehen/", "tokens": ["da\u00df", "sie", "ge\u00b7trost", "m\u00f6g", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "treib ab/ treib ab den Grimmenhund/", "tokens": ["treib", "ab", "/", "treib", "ab", "den", "Grim\u00b7men\u00b7hund", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$(", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "rei\u00df mich au\u00df L\u00f6wenschlunde", "tokens": ["rei\u00df", "mich", "au\u00df", "L\u00f6\u00b7wen\u00b7schlun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.7": {"text": "zu der Stunde/", "tokens": ["zu", "der", "Stun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "da\u00df meine Zung und Mund", "tokens": ["da\u00df", "mei\u00b7ne", "Zung", "und", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "das Hornthier nicht verwunde/", "tokens": ["das", "Horn\u00b7thier", "nicht", "ver\u00b7wun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Ich will die fromme Br\u00fcderschar", "tokens": ["Ich", "will", "die", "from\u00b7me", "Br\u00fc\u00b7der\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zum Lobefest betagen/", "tokens": ["zum", "Lo\u00b7be\u00b7fest", "be\u00b7ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "de\u00df Herren Namen offenbar", "tokens": ["de\u00df", "Her\u00b7ren", "Na\u00b7men", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dem Samen Jacobs sagen/", "tokens": ["dem", "Sa\u00b7men", "Ja\u00b7cobs", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "da\u00df er jhn ehr/ \u00fcm da\u00df er frey", "tokens": ["da\u00df", "er", "jhn", "ehr", "/", "\u00fcm", "da\u00df", "er", "frey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "NN", "$(", "ADV", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sein Antlitz nicht verstecket", "tokens": ["sein", "Ant\u00b7litz", "nicht", "ver\u00b7ste\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "noch bedecket/", "tokens": ["noch", "be\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "und zu dem Angstgeschrey", "tokens": ["und", "zu", "dem", "Angst\u00b7ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "sein leises Ohr gestrecket.", "tokens": ["sein", "lei\u00b7ses", "Ohr", "ge\u00b7stre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Ich will in dieser grossen Stadt", "tokens": ["Ich", "will", "in", "die\u00b7ser", "gros\u00b7sen", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und allen Kirchgemeinen/", "tokens": ["und", "al\u00b7len", "Kirch\u00b7ge\u00b7mei\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wie meine Zung versprochen hat/", "tokens": ["wie", "mei\u00b7ne", "Zung", "ver\u00b7spro\u00b7chen", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Lobedanck erscheinen/", "tokens": ["mit", "Lo\u00b7be\u00b7danck", "er\u00b7schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wer elend ist/ der isst sich satt/", "tokens": ["wer", "e\u00b7lend", "ist", "/", "der", "isst", "sich", "satt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "ART", "VVFIN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sucht Gott und Gott erhebet", "tokens": ["sucht", "Gott", "und", "Gott", "er\u00b7he\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "friedlich lebet/", "tokens": ["fried\u00b7lich", "le\u00b7bet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "so lang das Sonnenrad", "tokens": ["so", "lang", "das", "Son\u00b7nen\u00b7rad"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "am blauen Himmel schwebet.", "tokens": ["am", "blau\u00b7en", "Him\u00b7mel", "schwe\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "De\u00df wird gedacht zu jeder Zeit/", "tokens": ["De\u00df", "wird", "ge\u00b7dacht", "zu", "je\u00b7der", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der sich zu Gott bekehret/", "tokens": ["der", "sich", "zu", "Gott", "be\u00b7keh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "der Heyden Volck jhn weit und breit", "tokens": ["der", "Hey\u00b7den", "Volck", "jhn", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Niderfallen ehret/", "tokens": ["mit", "Ni\u00b7der\u00b7fal\u00b7len", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "es wird der Fetten feiste Rott", "tokens": ["es", "wird", "der", "Fet\u00b7ten", "feis\u00b7te", "Rott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu seinem Fu\u00df sich legen", "tokens": ["zu", "sei\u00b7nem", "Fu\u00df", "sich", "le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "allerwegen/", "tokens": ["al\u00b7ler\u00b7we\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "auch der mit Kummerspott", "tokens": ["auch", "der", "mit", "Kum\u00b7mer\u00b7spott"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "den Lebensrest mu\u00df hegen.", "tokens": ["den", "Le\u00b7bens\u00b7rest", "mu\u00df", "he\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "So lang und wo nur Menschen sind/", "tokens": ["So", "lang", "und", "wo", "nur", "Men\u00b7schen", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PWAV", "ADV", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wird bleiben Gottes Samen/", "tokens": ["wird", "blei\u00b7ben", "Got\u00b7tes", "Sa\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "fortan wird Kindes-Kindes Kind", "tokens": ["for\u00b7tan", "wird", "Kin\u00b7des\u00b7Kin\u00b7des", "Kind"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verk\u00fcnden seinen Namen/", "tokens": ["ver\u00b7k\u00fcn\u00b7den", "sei\u00b7nen", "Na\u00b7men", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "sie werden seine Billichkeit", "tokens": ["sie", "wer\u00b7den", "sei\u00b7ne", "Bil\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der greisen Nachwelt sagen", "tokens": ["der", "grei\u00b7sen", "Nach\u00b7welt", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nach Behagen:", "tokens": ["nach", "Be\u00b7ha\u00b7gen", ":"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Gott/ der ertheilt Bescheid/", "tokens": ["Gott", "/", "der", "er\u00b7theilt", "Be\u00b7scheid", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "VVFIN", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "da\u00df sich nicht zu beklagen.", "tokens": ["da\u00df", "sich", "nicht", "zu", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Auf dich Herr setz ich alle Sachen/", "tokens": ["Auf", "dich", "Herr", "setz", "ich", "al\u00b7le", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "la\u00df mich ja nicht zu Schanden machen/", "tokens": ["la\u00df", "mich", "ja", "nicht", "zu", "Schan\u00b7den", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "errette doch in dieser Zeit", "tokens": ["er\u00b7ret\u00b7te", "doch", "in", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mein Recht durch die Gerechtigkeit.", "tokens": ["mein", "Recht", "durch", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Begleite mich auf meinen Stegen/", "tokens": ["Be\u00b7glei\u00b7te", "mich", "auf", "mei\u00b7nen", "Ste\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und f\u00fchr mich deines Namens wegen/", "tokens": ["und", "f\u00fchr", "mich", "dei\u00b7nes", "Na\u00b7mens", "we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zeuch mich du Hertzog aller Welt", "tokens": ["zeuch", "mich", "du", "Hert\u00b7zog", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "NE", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "au\u00df Netzen/ die sie mir gestellt.", "tokens": ["au\u00df", "Net\u00b7zen", "/", "die", "sie", "mir", "ge\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "PRELS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Neig dein Geh\u00f6r zu meinen Lippen/", "tokens": ["Neig", "dein", "Ge\u00b7h\u00f6r", "zu", "mei\u00b7nen", "Lip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du bist mein Fels auf hohen Klippen/", "tokens": ["du", "bist", "mein", "Fels", "auf", "ho\u00b7hen", "Klip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sey mir ein wolverwahrter Schutz/", "tokens": ["sey", "mir", "ein", "wol\u00b7ver\u00b7wahr\u00b7ter", "Schutz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der hintertreib der Feinde Trutz.", "tokens": ["der", "hin\u00b7ter\u00b7treib", "der", "Fein\u00b7de", "Trutz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Den Geist/ den ich jetzt \u00fcberlasse", "tokens": ["Den", "Geist", "/", "den", "ich", "jetzt", "\u00fc\u00b7ber\u00b7las\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in deine Vaterh\u00e4nde fasse/", "tokens": ["in", "dei\u00b7ne", "Va\u00b7ter\u00b7h\u00e4n\u00b7de", "fas\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du hast mich Herr/ du treuer Gott/", "tokens": ["du", "hast", "mich", "Herr", "/", "du", "treu\u00b7er", "Gott", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "erl\u00f6set au\u00df des Creutzes Spott.", "tokens": ["er\u00b7l\u00f6\u00b7set", "au\u00df", "des", "Creut\u00b7zes", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Jhr Augen wolt jhr euch der Augeng\u00fcsse sch\u00e4men", "tokens": ["Ihr", "Au\u00b7gen", "wolt", "jhr", "euch", "der", "Au\u00b7gen\u00b7g\u00fcs\u00b7se", "sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PRF", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und du/ mein st\u00e4hlern Hertz/ sey doch nicht Stahl unn Stein/", "tokens": ["und", "du", "/", "mein", "st\u00e4h\u00b7lern", "Hertz", "/", "sey", "doch", "nicht", "Stahl", "unn", "Stein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PPOSAT", "ADJA", "NN", "$(", "VAFIN", "ADV", "PTKNEG", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "thrent Augenwinckel/ thrent/ thrent Wimpern/ Augenbr\u00e4men/", "tokens": ["thrent", "Au\u00b7gen\u00b7win\u00b7ckel", "/", "thrent", "/", "thrent", "Wim\u00b7pern", "/", "Au\u00b7gen\u00b7br\u00e4\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "VVFIN", "$(", "VVFIN", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "es mu\u00df im Zehrenbad mein Hertz gebadet seyn.", "tokens": ["es", "mu\u00df", "im", "Zeh\u00b7ren\u00b7bad", "mein", "Hertz", "ge\u00b7ba\u00b7det", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PPOSAT", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Ich hab mein Lebtag nicht ein solches Bild gesehen/", "tokens": ["Ich", "hab", "mein", "Leb\u00b7tag", "nicht", "ein", "sol\u00b7ches", "Bild", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ART", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ach jammervolles Bild! kranck/ elend/ matt und bla\u00df/", "tokens": ["ach", "jam\u00b7mer\u00b7vol\u00b7les", "Bild", "!", "kranck", "/", "e\u00b7lend", "/", "matt", "und", "bla\u00df", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$.", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "seht/ welch ein Mensch ist das! wie mu\u00df jhm seyn geschehen/", "tokens": ["seht", "/", "welch", "ein", "Mensch", "ist", "das", "!", "wie", "mu\u00df", "jhm", "seyn", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAT", "ART", "NN", "VAFIN", "PDS", "$.", "PWAV", "VMFIN", "PPER", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "na\u00df/ matt/ kranck/ sterbekranck/ vom Blute pf\u00fctzena\u00df.", "tokens": ["na\u00df", "/", "matt", "/", "kranck", "/", "ster\u00b7be\u00b7kranck", "/", "vom", "Blu\u00b7te", "pf\u00fct\u00b7ze\u00b7na\u00df", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "VVFIN", "$(", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.44": {"line.1": {"text": "Das jungferreine Lamm wird von den St\u00e4nckerb\u00f6cken", "tokens": ["Das", "jung\u00b7fer\u00b7rei\u00b7ne", "Lamm", "wird", "von", "den", "St\u00e4n\u00b7cker\u00b7b\u00f6\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "gejaget hin und her; das unbefleckte Schaf", "tokens": ["ge\u00b7ja\u00b7get", "hin", "und", "her", ";", "das", "un\u00b7be\u00b7fleck\u00b7te", "Schaf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "PTKVZ", "KON", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ist gelblich/ braun und blau; die Rosen tragen H\u00f6cken/", "tokens": ["ist", "gelb\u00b7lich", "/", "braun", "und", "blau", ";", "die", "Ro\u00b7sen", "tra\u00b7gen", "H\u00f6\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "ADJD", "KON", "ADJD", "$.", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der Honig trincket Gall; der ohne Schlaf wird Schlaf.", "tokens": ["der", "Ho\u00b7nig", "trin\u00b7cket", "Gall", ";", "der", "oh\u00b7ne", "Schlaf", "wird", "Schlaf", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$.", "ART", "APPR", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Was thut das Silber nicht? hier silbert man die H\u00e4nde", "tokens": ["Was", "thut", "das", "Sil\u00b7ber", "nicht", "?", "hier", "sil\u00b7bert", "man", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$.", "ADV", "VVFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "dem eisern Kriegesknecht; der schl\u00e4get Hand und Fu\u00df", "tokens": ["dem", "ei\u00b7sern", "Krie\u00b7ges\u00b7knecht", ";", "der", "schl\u00e4\u00b7get", "Hand", "und", "Fu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "in Stock und Eisen ein; Ach Elend/ Ach Elende!", "tokens": ["in", "Stock", "und", "Ei\u00b7sen", "ein", ";", "Ach", "E\u00b7lend", "/", "Ach", "E\u00b7len\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "ITJ", "NN", "$(", "ITJ", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "mich wundert/ da\u00df er nicht vor Schmertzen sterben mu\u00df.", "tokens": ["mich", "wun\u00b7dert", "/", "da\u00df", "er", "nicht", "vor", "Schmert\u00b7zen", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Er lebt/ er lebet nicht! Er schwebt/ und nicht recht schwebet", "tokens": ["Er", "lebt", "/", "er", "le\u00b7bet", "nicht", "!", "Er", "schwebt", "/", "und", "nicht", "recht", "schwe\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VVFIN", "$(", "KON", "PTKNEG", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Lufftf\u00fcrst in der Lufft; die Last wird jhme Last/", "tokens": ["der", "Luff\u00b7tf\u00fcrst", "in", "der", "Lufft", ";", "die", "Last", "wird", "jh\u00b7me", "Last", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "de\u00df Lebens Leben stirbt; Er lebet nicht/ er lebet!", "tokens": ["de\u00df", "Le\u00b7bens", "Le\u00b7ben", "stirbt", ";", "Er", "le\u00b7bet", "nicht", "/", "er", "le\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das gr\u00fcne Holtz verdorrt/ der Farben Farbe blast.", "tokens": ["das", "gr\u00fc\u00b7ne", "Holtz", "ver\u00b7dorrt", "/", "der", "Far\u00b7ben", "Far\u00b7be", "blast", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.47": {"line.1": {"text": "Ja/ wol er hat gelebt. Der Glieder Glied sich kr\u00fcmmet/", "tokens": ["Ja", "/", "wol", "er", "hat", "ge\u00b7lebt", ".", "Der", "Glie\u00b7der", "Glied", "sich", "kr\u00fcm\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Aufgang au\u00df der H\u00f6h am Abend untergeht/", "tokens": ["der", "Auf\u00b7gang", "au\u00df", "der", "H\u00f6h", "am", "A\u00b7bend", "un\u00b7ter\u00b7geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Augen Sternenpar im toden Meere schwimmet/", "tokens": ["der", "Au\u00b7gen", "Ster\u00b7nen\u00b7par", "im", "to\u00b7den", "Mee\u00b7re", "schwim\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach Sohn/ Ach lieber Sohn/ sihst du/ wer bey dir steht?", "tokens": ["Ach", "Sohn", "/", "Ach", "lie\u00b7ber", "Sohn", "/", "sihst", "du", "/", "wer", "bey", "dir", "steht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$(", "ITJ", "ADV", "NN", "$(", "VVFIN", "PPER", "$(", "PWS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Ach leider/ leider Ach! Ach/ Ach er ist gestorben", "tokens": ["Ach", "lei\u00b7der", "/", "lei\u00b7der", "Ach", "!", "Ach", "/", "Ach", "er", "ist", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$(", "ADV", "ITJ", "$.", "ITJ", "$(", "ITJ", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mein allerliebstes Kind; Ach weinet doch mit mir/", "tokens": ["mein", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ";", "Ach", "wei\u00b7net", "doch", "mit", "mir", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "ITJ", "VVFIN", "ADV", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Tod hat mir mein Lieb/ und meine Lieb verdorben/", "tokens": ["der", "Tod", "hat", "mir", "mein", "Lieb", "/", "und", "mei\u00b7ne", "Lieb", "ver\u00b7dor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach alles weine doch \u00fcm mich/ und meine Zier.", "tokens": ["Ach", "al\u00b7les", "wei\u00b7ne", "doch", "\u00fcm", "mich", "/", "und", "mei\u00b7ne", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PIS", "VVFIN", "ADV", "VVFIN", "PPER", "$(", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Der F\u00fcrhang ist zerzerret/", "tokens": ["Der", "F\u00fcr\u00b7hang", "ist", "zer\u00b7zer\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "der Himmel aufgesperret.", "tokens": ["der", "Him\u00b7mel", "auf\u00b7ge\u00b7sper\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "Den solten alle Teufel fassen/", "tokens": ["Den", "sol\u00b7ten", "al\u00b7le", "Teu\u00b7fel", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der sich zuerst hinabgelassen/", "tokens": ["der", "sich", "zu\u00b7erst", "hin\u00b7ab\u00b7ge\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durch nasse Tufft/ durch Schwefelrauch", "tokens": ["durch", "nas\u00b7se", "Tufft", "/", "durch", "Schwe\u00b7fel\u00b7rauch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sehr tief hinein in Erdenbauch.", "tokens": ["sehr", "tief", "hin\u00b7ein", "in", "Er\u00b7den\u00b7bauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Da\u00df der doch alle Teufel leide/", "tokens": ["Da\u00df", "der", "doch", "al\u00b7le", "Teu\u00b7fel", "lei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der/ der der Berge Eingeweide", "tokens": ["der", "/", "der", "der", "Ber\u00b7ge", "Ein\u00b7ge\u00b7wei\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$(", "ART", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durchkrochen und daselbst gesucht", "tokens": ["durch\u00b7kro\u00b7chen", "und", "da\u00b7selbst", "ge\u00b7sucht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Teuffels-Stahl/ de\u00df Eisens Zucht.", "tokens": ["den", "Teuf\u00b7fels\u00b7Stahl", "/", "de\u00df", "Ei\u00b7sens", "Zucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Den solten alle Teuffel haschen/", "tokens": ["Den", "sol\u00b7ten", "al\u00b7le", "Teuf\u00b7fel", "ha\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Gruben-Ertz gepocht/ gewaschen/", "tokens": ["der", "Gru\u00b7ben\u00b7Ertz", "ge\u00b7pocht", "/", "ge\u00b7wa\u00b7schen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "verflucht sey/ der es hat geschmeltzt", "tokens": ["ver\u00b7flucht", "sey", "/", "der", "es", "hat", "ge\u00b7schmeltzt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$(", "PRELS", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und offt im Feuer \u00fcmgeweltzt.", "tokens": ["und", "offt", "im", "Feu\u00b7er", "\u00fcm\u00b7ge\u00b7weltzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "Es solten alle Teuffel plagen", "tokens": ["Es", "sol\u00b7ten", "al\u00b7le", "Teuf\u00b7fel", "pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "den Schmidt/ de\u00df Schmidte zugeschlagen", "tokens": ["den", "Schmidt", "/", "de\u00df", "Schmid\u00b7te", "zu\u00b7ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "$(", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "das Eisen spitzig zugericht/", "tokens": ["das", "Ei\u00b7sen", "spit\u00b7zig", "zu\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df es ein hartes Holtz zerbricht.", "tokens": ["da\u00df", "es", "ein", "har\u00b7tes", "Holtz", "zer\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Es m\u00fcssen alle Teuffel holen", "tokens": ["Es", "m\u00fcs\u00b7sen", "al\u00b7le", "Teuf\u00b7fel", "ho\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die N\u00e4gel/ die der F\u00fcsse Solen", "tokens": ["die", "N\u00e4\u00b7gel", "/", "die", "der", "F\u00fcs\u00b7se", "So\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durchboret und der H\u00e4nde Band.", "tokens": ["durch\u00b7bo\u00b7ret", "und", "der", "H\u00e4n\u00b7de", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pfuy/ pfuy der S\u00fcnd/ pfuy/ pfuy der Schand!", "tokens": ["Pfuy", "/", "pfuy", "der", "S\u00fcnd", "/", "pfuy", "/", "pfuy", "der", "Schand", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "ART", "NN", "$(", "NE", "$(", "NE", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.55": {"line.1": {"text": "Vater geh nicht ins Gericht", "tokens": ["Va\u00b7ter", "geh", "nicht", "ins", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PTKNEG", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "mit uns S\u00fcndenknechten/", "tokens": ["mit", "uns", "S\u00fcn\u00b7den\u00b7knech\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "weil dein Sohn uns selbst verspricht/", "tokens": ["weil", "dein", "Sohn", "uns", "selbst", "ver\u00b7spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wilt du mit uns rechten?", "tokens": ["wilt", "du", "mit", "uns", "rech\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Wir sind Stechdorn seiner Kron/", "tokens": ["Wir", "sind", "Stech\u00b7dorn", "sei\u00b7ner", "Kron", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "seine Kn\u00f6tengeissel/", "tokens": ["sei\u00b7ne", "Kn\u00f6\u00b7ten\u00b7geis\u00b7sel", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Ruten/ Peitschen/ Scorpion/", "tokens": ["Ru\u00b7ten", "/", "Peit\u00b7schen", "/", "Scor\u00b7pi\u00b7on", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$(", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Hammer/ N\u00e4gel/ Meissel.", "tokens": ["Ham\u00b7mer", "/", "N\u00e4\u00b7gel", "/", "Meis\u00b7sel", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$(", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "Vater halt den Donner an/", "tokens": ["Va\u00b7ter", "halt", "den", "Don\u00b7ner", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "la\u00df jhn ja nicht haglen/", "tokens": ["la\u00df", "jhn", "ja", "nicht", "hag\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "schlage keinen Zimmermann/", "tokens": ["schla\u00b7ge", "kei\u00b7nen", "Zim\u00b7mer\u00b7mann", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "die das Creutz noch naglen/", "tokens": ["die", "das", "Creutz", "noch", "nag\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "wir/ wir sind de\u00df Speeres Stahl/", "tokens": ["wir", "/", "wir", "sind", "de\u00df", "Spee\u00b7res", "Stahl", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der sein Hertz durchstochen/", "tokens": ["der", "sein", "Hertz", "durch\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "worau\u00df unsers Heiles Mahl", "tokens": ["wo\u00b7rau\u00df", "un\u00b7sers", "Hei\u00b7les", "Mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "wei\u00df und rot gebrochen.", "tokens": ["wei\u00df", "und", "rot", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Rote B\u00e4che wie Corall", "tokens": ["Ro\u00b7te", "B\u00e4\u00b7che", "wie", "Co\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KOKOM", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "springen au\u00df der Seiten/", "tokens": ["sprin\u00b7gen", "au\u00df", "der", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "reine B\u00e4che wie Crystall", "tokens": ["rei\u00b7ne", "B\u00e4\u00b7che", "wie", "Crys\u00b7tall"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KOKOM", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "silberhell sich breiten;", "tokens": ["sil\u00b7ber\u00b7hell", "sich", "brei\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "di\u00df Corall und dieses Gla\u00df", "tokens": ["di\u00df", "Co\u00b7rall", "und", "die\u00b7ses", "Gla\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "KON", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "allen Vnflat waschen/", "tokens": ["al\u00b7len", "Vn\u00b7flat", "wa\u00b7schen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "di\u00df Rubin- di\u00df Perlen-Na\u00df", "tokens": ["di\u00df", "Ru\u00b7bin", "di\u00df", "Per\u00b7len\u00b7Na\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "TRUNC", "PDS", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "s\u00e4ubern S\u00fcnden-Aschen.", "tokens": ["s\u00e4u\u00b7bern", "S\u00fcn\u00b7den\u00b7A\u00b7schen", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.58": {"line.1": {"text": "Gleichen wir gleich einem Mohr/", "tokens": ["Glei\u00b7chen", "wir", "gleich", "ei\u00b7nem", "Mohr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ru\u00dfschwartz angef\u00e4rbet/", "tokens": ["ru\u00df\u00b7schwartz", "an\u00b7ge\u00b7f\u00e4r\u00b7bet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "waschet uns das Seiten-Thor", "tokens": ["wa\u00b7schet", "uns", "das", "Sei\u00b7ten\u00b7Thor"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dessen/ der gesterbet.", "tokens": ["des\u00b7sen", "/", "der", "ge\u00b7ster\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PDS", "$(", "ART", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Alles Wissens Wissenschafft", "tokens": ["Al\u00b7les", "Wis\u00b7sens", "Wis\u00b7sen\u00b7schafft"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan ein Christ fort missen/", "tokens": ["kan", "ein", "Christ", "fort", "mis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKVZ", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "h\u00e4lt er dieses Creutzes Krafft", "tokens": ["h\u00e4lt", "er", "die\u00b7ses", "Creut\u00b7zes", "Krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "vor sein bestes Wissen.", "tokens": ["vor", "sein", "bes\u00b7tes", "Wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.59": {"line.1": {"text": "Aller Zeug der Gottes-Sohn", "tokens": ["Al\u00b7ler", "Zeug", "der", "Got\u00b7tes\u00b7Sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00fcbel zugerichtet/", "tokens": ["\u00fc\u00b7bel", "zu\u00b7ge\u00b7rich\u00b7tet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "aller Spott und aller Hohn", "tokens": ["al\u00b7ler", "Spott", "und", "al\u00b7ler", "Hohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und was jhn vernichtet/", "tokens": ["und", "was", "jhn", "ver\u00b7nich\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Staupseul/ Besen von dem Meer/", "tokens": ["Stau\u00b7pseul", "/", "Be\u00b7sen", "von", "dem", "Meer", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schl\u00e4ge/ Wunden/ Striemen/", "tokens": ["Schl\u00e4\u00b7ge", "/", "Wun\u00b7den", "/", "Strie\u00b7men", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Creutzbaum/ Isop/ Schwamm und Speer", "tokens": ["Creutz\u00b7baum", "/", "I\u00b7sop", "/", "Schwamm", "und", "Speer"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "NE", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "sind nun unser R\u00fchmen.", "tokens": ["sind", "nun", "un\u00b7ser", "R\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "Ich wei\u00df/ ich wei\u00df/ wie viel an d\u1ebd verglast\u1ebd Schantzen", "tokens": ["Ich", "wei\u00df", "/", "ich", "wei\u00df", "/", "wie", "viel", "an", "d\u1ebd", "ver\u00b7glast\u1ebd", "Schant\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "$(", "KOKOM", "ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "goldg\u00fcldne Sternlein tantzen.", "tokens": ["gold\u00b7g\u00fcld\u00b7ne", "Stern\u00b7lein", "tant\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich wei\u00df ein reiches Reich/", "tokens": ["Ich", "wei\u00df", "ein", "rei\u00b7ches", "Reich", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "dem unser Reich nicht gleich.", "tokens": ["dem", "un\u00b7ser", "Reich", "nicht", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Es hilfft mich nichts. Das n\u00fctzt/ die Stunden \u00fcberschlagen/", "tokens": ["Es", "hilfft", "mich", "nichts", ".", "Das", "n\u00fctzt", "/", "die", "Stun\u00b7den", "\u00fc\u00b7bersc\u00b7hla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "$.", "PDS", "VVFIN", "$(", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "die uns das Heil getragen;", "tokens": ["die", "uns", "das", "Heil", "ge\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Es f\u00fchrt uns auf die Spur", "tokens": ["Es", "f\u00fchrt", "uns", "auf", "die", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "der blinden Juden Vhr.", "tokens": ["der", "blin\u00b7den", "Ju\u00b7den", "Vhr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Vm Eins k\u00f6mmt Gottes Sohn", "tokens": ["Vm", "Eins", "k\u00f6mmt", "Got\u00b7tes", "Sohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "NN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "weint mit uns in die Wette/", "tokens": ["weint", "mit", "uns", "in", "die", "Wet\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "APPR", "ART", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "legt an de\u00df Fleisches Kleid/", "tokens": ["legt", "an", "de\u00df", "Flei\u00b7sches", "Kleid", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "und tr\u00e4get Menschenleid.", "tokens": ["und", "tr\u00e4\u00b7get", "Men\u00b7schen\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.13": {"text": "Vm Drey spielt er mit uns/ es hat jhm viel gestanden/", "tokens": ["Vm", "Drey", "spielt", "er", "mit", "uns", "/", "es", "hat", "jhm", "viel", "ge\u00b7stan\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["XY", "CARD", "VVFIN", "PPER", "APPR", "PPER", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "viel/ viel stie\u00df jhm zu Handen/", "tokens": ["viel", "/", "viel", "stie\u00df", "jhm", "zu", "Han\u00b7den", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "ADV", "VVFIN", "PPER", "APPR", "NN", "$("], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.15": {"text": "Durst/ Hunger/ Hitze/ Frost/", "tokens": ["Durst", "/", "Hun\u00b7ger", "/", "Hit\u00b7ze", "/", "Frost", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$(", "NN", "$(", "NN", "$(", "NN", "$("], "meter": "++-+-+", "measure": "iambic.tri"}, "line.16": {"text": "am Ende Wermut kost.", "tokens": ["am", "En\u00b7de", "Wer\u00b7mut", "kost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.17": {"text": "Vm Sechse gieng recht an das Trauerspiel/ das Bluten/", "tokens": ["Vm", "Sech\u00b7se", "gieng", "recht", "an", "das", "Trau\u00b7er\u00b7spiel", "/", "das", "Blu\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Creutz/ Ketten/ Geisseln/ Ruten/", "tokens": ["Creutz", "/", "Ket\u00b7ten", "/", "Geis\u00b7seln", "/", "Ru\u00b7ten", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.19": {"text": "Speer/ N\u00e4gel/ W\u00fcrfel/ Dorn", "tokens": ["Speer", "/", "N\u00e4\u00b7gel", "/", "W\u00fcr\u00b7fel", "/", "Dorn"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word"], "pos": ["NN", "$(", "NN", "$(", "NN", "$(", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "vers\u00f6hnen Gottes Zorn.", "tokens": ["ver\u00b7s\u00f6h\u00b7nen", "Got\u00b7tes", "Zorn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Vm Neune stirbt/ hilf Gott! als wie ein Dieb/ das Leben/", "tokens": ["Vm", "Neu\u00b7ne", "stirbt", "/", "hilf", "Gott", "!", "als", "wie", "ein", "Dieb", "/", "das", "Le\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$(", "VVIMP", "NN", "$.", "KOUS", "KOKOM", "ART", "NN", "$(", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "der Vnschuld Zeugni\u00df geben", "tokens": ["der", "Vn\u00b7schuld", "Zeug\u00b7ni\u00df", "ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "das aufger\u00fchrte Rund/", "tokens": ["das", "auf\u00b7ge\u00b7r\u00fchr\u00b7te", "Rund", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "der dreygeschnautzte Hund.", "tokens": ["der", "drey\u00b7ge\u00b7schnautz\u00b7te", "Hund", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Es ist Nacht/ nemet ab/ von der versteinten Eiche", "tokens": ["Es", "ist", "Nacht", "/", "ne\u00b7met", "ab", "/", "von", "der", "ver\u00b7stein\u00b7ten", "Ei\u00b7che"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "NN", "$(", "VVFIN", "PTKVZ", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "--+--+-+-+-+-", "measure": "anapaest.di.plus"}, "line.26": {"text": "die grosse Sch\u00e4ferleiche", "tokens": ["die", "gros\u00b7se", "Sch\u00e4\u00b7fer\u00b7lei\u00b7che"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.27": {"text": "salbt sie mit Spezerey/", "tokens": ["salbt", "sie", "mit", "Spe\u00b7ze\u00b7rey", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.28": {"text": "und setzt sie kostbar bey.", "tokens": ["und", "setzt", "sie", "kost\u00b7bar", "bey", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Ach Weh! das Aas steht feil/ nur zwey sind/ die da kauffen/", "tokens": ["Ach", "Weh", "!", "das", "Aas", "steht", "feil", "/", "nur", "zwey", "sind", "/", "die", "da", "kauf\u00b7fen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$(", "ADV", "CARD", "VAFIN", "$(", "ART", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "au\u00df einem solchen Hauffen/", "tokens": ["au\u00df", "ei\u00b7nem", "sol\u00b7chen", "Hauf\u00b7fen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "ich will der Dritte seyn/", "tokens": ["ich", "will", "der", "Drit\u00b7te", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.32": {"text": "den Kauff mit tretten ein.", "tokens": ["den", "Kauff", "mit", "tret\u00b7ten", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "Ich will das heilge Grab mit Rosmarin besetzen/", "tokens": ["Ich", "will", "das", "heil\u00b7ge", "Grab", "mit", "Ros\u00b7ma\u00b7rin", "be\u00b7set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "mit Augenregnen netzen", "tokens": ["mit", "Au\u00b7gen\u00b7reg\u00b7nen", "net\u00b7zen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.35": {"text": "und di\u00df/ was hier gepropfft/", "tokens": ["und", "di\u00df", "/", "was", "hier", "ge\u00b7propfft", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "$(", "PWS", "ADV", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.36": {"text": "nur Zehrenna\u00df betropfft.", "tokens": ["nur", "Zeh\u00b7ren\u00b7na\u00df", "be\u00b7tropfft", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.61": {"line.1": {"text": "Die liebe Liebe hat ein Abendmal gerahten/", "tokens": ["Die", "lie\u00b7be", "Lie\u00b7be", "hat", "ein", "A\u00b7bend\u00b7mal", "ge\u00b7rah\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "die liebe Liebe hat ein Abendmal gebraten/", "tokens": ["die", "lie\u00b7be", "Lie\u00b7be", "hat", "ein", "A\u00b7bend\u00b7mal", "ge\u00b7bra\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "die liebe Liebe hat di\u00df Abendmal erdacht/", "tokens": ["die", "lie\u00b7be", "Lie\u00b7be", "hat", "di\u00df", "A\u00b7bend\u00b7mal", "er\u00b7dacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PDS", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "da\u00df liebe Lieb au\u00df Lieb es esse bey der Nacht.", "tokens": ["da\u00df", "lie\u00b7be", "Lieb", "au\u00df", "Lieb", "es", "es\u00b7se", "bey", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "NN", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.62": {"line.1": {"text": "Die Magenleere Hungersnoht", "tokens": ["Die", "Ma\u00b7gen\u00b7lee\u00b7re", "Hun\u00b7gers\u00b7noht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "in dieser Welt mich naget/", "tokens": ["in", "die\u00b7ser", "Welt", "mich", "na\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "der Durst/ der \u00e4rger als der Tod/", "tokens": ["der", "Durst", "/", "der", "\u00e4r\u00b7ger", "als", "der", "Tod", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "ADJD", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "im d\u00fcrren Sand mich plaget/", "tokens": ["im", "d\u00fcr\u00b7ren", "Sand", "mich", "pla\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "der Hunger qu\u00e4let mich zwar sehr/", "tokens": ["der", "Hun\u00b7ger", "qu\u00e4\u00b7let", "mich", "zwar", "sehr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der Durst doch tausendmal vielmehr/", "tokens": ["der", "Durst", "doch", "tau\u00b7send\u00b7mal", "viel\u00b7mehr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "mein Geist steht auf der Zunge.", "tokens": ["mein", "Geist", "steht", "auf", "der", "Zun\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "Der Erdkrei\u00df l\u00e4det mich zu sich/", "tokens": ["Der", "Erd\u00b7krei\u00df", "l\u00e4\u00b7det", "mich", "zu", "sich", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "APPR", "PRF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zu sich/ auf sich zu Gaste/", "tokens": ["zu", "sich", "/", "auf", "sich", "zu", "Gas\u00b7te", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "$(", "APPR", "PRF", "APPR", "NN", "$("], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "er spricht: Komm her und setze dich/", "tokens": ["er", "spricht", ":", "Komm", "her", "und", "set\u00b7ze", "dich", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "i\u00df/ was dir schmeckt und raste/", "tokens": ["i\u00df", "/", "was", "dir", "schmeckt", "und", "ras\u00b7te", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWS", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "greiff an die Trachten ohne Zahl/", "tokens": ["greiff", "an", "die", "Trach\u00b7ten", "oh\u00b7ne", "Zahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "la\u00df dir wol seyn bey meinem Mahl/", "tokens": ["la\u00df", "dir", "wol", "seyn", "bey", "mei\u00b7nem", "Mahl", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "VAINF", "APPR", "PPOSAT", "NN", "$("], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.7": {"text": "ich hab dich hertzlich gerne.", "tokens": ["ich", "hab", "dich", "hertz\u00b7lich", "ger\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "Es ruffet mir das Weldmeer zu", "tokens": ["Es", "ruf\u00b7fet", "mir", "das", "Weld\u00b7meer", "zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "au\u00df glasegr\u00fcnem Sale/", "tokens": ["au\u00df", "gla\u00b7se\u00b7gr\u00fc\u00b7nem", "Sa\u00b7le", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "es rufft/ es trinckt sich selbst mir zu", "tokens": ["es", "rufft", "/", "es", "trinckt", "sich", "selbst", "mir", "zu"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PRF", "ADV", "PPER", "PTKZU"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in einer g\u00fcldnen Schale/", "tokens": ["in", "ei\u00b7ner", "g\u00fcld\u00b7nen", "Scha\u00b7le", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "das nasse Wellensch\u00e4umen fleust/", "tokens": ["das", "nas\u00b7se", "Wel\u00b7len\u00b7sch\u00e4u\u00b7men", "fleust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der Strudel Wasserberge geust/", "tokens": ["der", "Stru\u00b7del", "Was\u00b7ser\u00b7ber\u00b7ge", "geust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "als wolt es alls ertr\u00e4ncken.", "tokens": ["als", "wolt", "es", "alls", "er\u00b7tr\u00e4n\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "Ich mag nicht Erd/ ich mag nicht Flut/", "tokens": ["Ich", "mag", "nicht", "Erd", "/", "ich", "mag", "nicht", "Flut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "NN", "$(", "PPER", "VMFIN", "PTKNEG", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wie sehr sie mir auch wincken/", "tokens": ["wie", "sehr", "sie", "mir", "auch", "win\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "PPER", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mein Jesus ist mein liebstes Gut/", "tokens": ["mein", "Je\u00b7sus", "ist", "mein", "liebs\u00b7tes", "Gut", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mein Essen und mein Trincken/", "tokens": ["mein", "Es\u00b7sen", "und", "mein", "Trin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "mein Hertz/ mein allerliebstes Hertz/", "tokens": ["mein", "Hertz", "/", "mein", "al\u00b7ler\u00b7liebs\u00b7tes", "Hertz", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sein Abseyn bringt dem Hertzen Schmertz/", "tokens": ["sein", "Ab\u00b7seyn", "bringt", "dem", "Hert\u00b7zen", "Schmertz", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "bringt Hungern und auch D\u00fcrsten.", "tokens": ["bringt", "Hun\u00b7gern", "und", "auch", "D\u00fcrs\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "ADV", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.66": {"line.1": {"text": "Mein Br\u00e4utigam erh\u00f6ret di\u00df/", "tokens": ["Mein", "Br\u00e4u\u00b7ti\u00b7gam", "er\u00b7h\u00f6\u00b7ret", "di\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PDS", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "erkennet meine L\u00fcste/", "tokens": ["er\u00b7ken\u00b7net", "mei\u00b7ne", "L\u00fcs\u00b7te", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "er spricht: komm her/ komm trinck/ komm i\u00df/", "tokens": ["er", "spricht", ":", "komm", "her", "/", "komm", "trinck", "/", "komm", "i\u00df", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "VVFIN", "PTKVZ", "$(", "VVFIN", "VVFIN", "$(", "VVFIN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und gibt mir beide Br\u00fcste", "tokens": ["und", "gibt", "mir", "bei\u00b7de", "Br\u00fcs\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "mein Br\u00e4utigam/ mein Himmelszier/", "tokens": ["mein", "Br\u00e4u\u00b7ti\u00b7gam", "/", "mein", "Him\u00b7mels\u00b7zier", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mein Weitzenbrod/ mein Malvasir/", "tokens": ["mein", "Weit\u00b7zen\u00b7brod", "/", "mein", "Mal\u00b7va\u00b7sir", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der mich speist/ der mich tr\u00e4ncket.", "tokens": ["der", "mich", "speist", "/", "der", "mich", "tr\u00e4n\u00b7cket", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$(", "PRELS", "PPER", "VVFIN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.67": {"line.1": {"text": "Erd ich mach nimmer/ was du hast", "tokens": ["Erd", "ich", "mach", "nim\u00b7mer", "/", "was", "du", "hast"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPER", "VVFIN", "ADV", "$(", "PWS", "PPER", "VAFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "auf deiner Tafel stehen/", "tokens": ["auf", "dei\u00b7ner", "Ta\u00b7fel", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Meer ich mag nimmer seyn dein Gast/", "tokens": ["Meer", "ich", "mag", "nim\u00b7mer", "seyn", "dein", "Gast", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VMFIN", "ADV", "VAINF", "PPOSAT", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "wie sch\u00f6n die Fluten gehen.", "tokens": ["wie", "sch\u00f6n", "die", "Flu\u00b7ten", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mich speist/ mich tr\u00e4nckt mein Jesus Christ/", "tokens": ["Mich", "speist", "/", "mich", "tr\u00e4nckt", "mein", "Je\u00b7sus", "Christ", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PPOSAT", "NE", "NE", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "auf seinem Tisch/ der fertig ist/", "tokens": ["auf", "sei\u00b7nem", "Tisch", "/", "der", "fer\u00b7tig", "ist", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ART", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "zu welchem ich jetzt gehe.", "tokens": ["zu", "wel\u00b7chem", "ich", "jetzt", "ge\u00b7he", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Wach auf mein Ehr/ auf Seiten", "tokens": ["Wach", "auf", "mein", "Ehr", "/", "auf", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$(", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "der scharfen Harffen-Psalterspiel/", "tokens": ["der", "schar\u00b7fen", "Ha\u00b7rf\u00b7fen\u00b7Psal\u00b7ter\u00b7spiel", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "ich will mit Ruhm au\u00dfbreiten", "tokens": ["ich", "will", "mit", "Ruhm", "au\u00df\u00b7brei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "de\u00df Herren Wunder ohne Ziel/", "tokens": ["de\u00df", "Her\u00b7ren", "Wun\u00b7der", "oh\u00b7ne", "Ziel", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sie singen/ wo die Frommen", "tokens": ["sie", "sin\u00b7gen", "/", "wo", "die", "From\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVINF", "$(", "PWAV", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "im Raht beysammen seyn/", "tokens": ["im", "Raht", "bey\u00b7sam\u00b7men", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und wo zusammen kommen", "tokens": ["und", "wo", "zu\u00b7sam\u00b7men", "kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PWAV", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "die V\u00f6lcker ins gemein/", "tokens": ["die", "V\u00f6l\u00b7cker", "ins", "ge\u00b7mein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "wer jhre Gr\u00f6\u00df betrachtet/", "tokens": ["wer", "jhre", "Gr\u00f6\u00df", "be\u00b7trach\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "so viel er soll und kan/", "tokens": ["so", "viel", "er", "soll", "und", "kan", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "VMFIN", "KON", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "sie Himmelh\u00f6her achtet/", "tokens": ["sie", "Him\u00b7mel\u00b7h\u00f6\u00b7her", "ach\u00b7tet", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "hat eitel Lust daran.", "tokens": ["hat", "ei\u00b7tel", "Lust", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "NN", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.69": {"line.1": {"text": "Gesetz/ das er gesetzet/", "tokens": ["Ge\u00b7setz", "/", "das", "er", "ge\u00b7set\u00b7zet", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "PRELS", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "ist lauter Herrlichkeit und Zier/", "tokens": ["ist", "lau\u00b7ter", "Herr\u00b7lich\u00b7keit", "und", "Zier", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "das Leib und Seel ergetzet/", "tokens": ["das", "Leib", "und", "Seel", "er\u00b7get\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "sein Recht bleibt aufrecht f\u00fcr und f\u00fcr/", "tokens": ["sein", "Recht", "bleibt", "auf\u00b7recht", "f\u00fcr", "und", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "KON", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "er hat/ sein zu gedencken/", "tokens": ["er", "hat", "/", "sein", "zu", "ge\u00b7den\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$(", "VAINF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "ein Wundermahl gestifft/", "tokens": ["ein", "Wun\u00b7der\u00b7mahl", "ge\u00b7stifft", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "den Erdkrei\u00df zu beschencken", "tokens": ["den", "Erd\u00b7krei\u00df", "zu", "be\u00b7schen\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "mit Gaben und mit Gifft/", "tokens": ["mit", "Ga\u00b7ben", "und", "mit", "Gifft", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "er hat sein Volck gespeiset/", "tokens": ["er", "hat", "sein", "Volck", "ge\u00b7spei\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "da\u00df jhn mit F\u00fcrchten ehrt/", "tokens": ["da\u00df", "jhn", "mit", "F\u00fcrch\u00b7ten", "ehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "sich gn\u00e4diglich erweiset/", "tokens": ["sich", "gn\u00e4\u00b7di\u00b7glich", "er\u00b7wei\u00b7set", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "den Bund niemal versehrt.", "tokens": ["den", "Bund", "nie\u00b7mal", "ver\u00b7sehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.70": {"line.1": {"text": "Es mu\u00df bey d\u00fcstern Zeiten", "tokens": ["Es", "mu\u00df", "bey", "d\u00fcs\u00b7tern", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "der tunckelbraunen Schattennacht", "tokens": ["der", "tun\u00b7ckel\u00b7brau\u00b7nen", "Schat\u00b7ten\u00b7nacht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "das Liecht den Frommen leiten/", "tokens": ["das", "Liecht", "den", "From\u00b7men", "lei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "das Liecht/ das Nacht zum Tage macht/", "tokens": ["das", "Liecht", "/", "das", "Nacht", "zum", "Ta\u00b7ge", "macht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "barmhertzig seyn/ gern leihen/", "tokens": ["barm\u00b7hert\u00b7zig", "seyn", "/", "gern", "lei\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$(", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "bekleiden/ was da blo\u00df/", "tokens": ["be\u00b7klei\u00b7den", "/", "was", "da", "blo\u00df", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VVINF", "$(", "PWS", "ADV", "ADV", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "de\u00df Nechsten Fehl verzeihen/", "tokens": ["de\u00df", "Nechs\u00b7ten", "Fehl", "ver\u00b7zei\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "macht unverzagt und gro\u00df/", "tokens": ["macht", "un\u00b7ver\u00b7zagt", "und", "gro\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "solch Thun mu\u00df fruchtbar gr\u00fcnen/", "tokens": ["solch", "Thun", "mu\u00df", "frucht\u00b7bar", "gr\u00fc\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "so lang die Sonne wacht", "tokens": ["so", "lang", "die", "Son\u00b7ne", "wacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "und an der Himmelb\u00fchnen", "tokens": ["und", "an", "der", "Him\u00b7mel\u00b7b\u00fch\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Mittag und N\u00e4chte macht.", "tokens": ["Mit\u00b7tag", "und", "N\u00e4ch\u00b7te", "macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Gott hat sich hoch gesetzet", "tokens": ["Gott", "hat", "sich", "hoch", "ge\u00b7set\u00b7zet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "PRF", "ADJD", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "und schauet auf de\u00df Vntern Noht/", "tokens": ["und", "schau\u00b7et", "auf", "de\u00df", "Vn\u00b7tern", "Noht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was nidrig wird gesch\u00e4tzet/", "tokens": ["was", "nid\u00b7rig", "wird", "ge\u00b7sch\u00e4t\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "erh\u00f6het er au\u00df Staub und Koht/", "tokens": ["er\u00b7h\u00f6\u00b7het", "er", "au\u00df", "Staub", "und", "Koht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "wei\u00df es hernach zu sch\u00fctzen/", "tokens": ["wei\u00df", "es", "her\u00b7nach", "zu", "sch\u00fct\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.6": {"text": "da\u00df es kein Fall gef\u00e4hrt/", "tokens": ["da\u00df", "es", "kein", "Fall", "ge\u00b7f\u00e4hrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "kan neben F\u00fcrsten sitzen", "tokens": ["kan", "ne\u00b7ben", "F\u00fcrs\u00b7ten", "sit\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "VVINF"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.8": {"text": "im hohen Ehrenwerth/", "tokens": ["im", "ho\u00b7hen", "Eh\u00b7ren\u00b7werth", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "den M\u00fcttern mu\u00df gelingen", "tokens": ["den", "M\u00fct\u00b7tern", "mu\u00df", "ge\u00b7lin\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "jhr W\u00fcnschen au\u00df und au\u00df/", "tokens": ["jhr", "W\u00fcn\u00b7schen", "au\u00df", "und", "au\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKVZ", "KON", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "da\u00df sie viel Kinder bringen/", "tokens": ["da\u00df", "sie", "viel", "Kin\u00b7der", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "besitzen Tisch und Hau\u00df.", "tokens": ["be\u00b7sit\u00b7zen", "Tisch", "und", "Hau\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Als Israel dem Lande", "tokens": ["Als", "Is\u00b7rael", "dem", "Lan\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "de\u00df Nils gegeben gute Nacht/", "tokens": ["de\u00df", "Nils", "ge\u00b7ge\u00b7ben", "gu\u00b7te", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "und Jacobs Hau\u00df vom Bande", "tokens": ["und", "Ja\u00b7cobs", "Hau\u00df", "vom", "Ban\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NE", "NN", "APPRART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "der Dienstbarkeit sich lo\u00df gemacht/", "tokens": ["der", "Dienst\u00b7bar\u00b7keit", "sich", "lo\u00df", "ge\u00b7macht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "hat Judas gleich bekommen", "tokens": ["hat", "Ju\u00b7das", "gleich", "be\u00b7kom\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "NE", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "de\u00df Herren Heiligthum/", "tokens": ["de\u00df", "Her\u00b7ren", "Hei\u00b7lig\u00b7thum", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "und Israel genommen", "tokens": ["und", "Is\u00b7rael", "ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "VVPP"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.8": {"text": "der Herrschafft hohen Ruhm/", "tokens": ["der", "Herr\u00b7schafft", "ho\u00b7hen", "Ruhm", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "das Meer mu\u00df r\u00fcckwerts dringen/", "tokens": ["das", "Meer", "mu\u00df", "r\u00fcck\u00b7werts", "drin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "der Jordan nimmt die Flucht/", "tokens": ["der", "Jor\u00b7dan", "nimmt", "die", "Flucht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "die Berg wie L\u00e4mmer springen/", "tokens": ["die", "Berg", "wie", "L\u00e4m\u00b7mer", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "die H\u00fcgel wie Schafszucht.", "tokens": ["die", "H\u00fc\u00b7gel", "wie", "Schafs\u00b7zucht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.73": {"line.1": {"text": "Wer hat dich heissen fliessen/", "tokens": ["Wer", "hat", "dich", "heis\u00b7sen", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVINF", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "dich Meer/ dich Jordan hinter sich?", "tokens": ["dich", "Meer", "/", "dich", "Jor\u00b7dan", "hin\u00b7ter", "sich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$(", "PPER", "NE", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "was h\u00fcpfft jhr mit den F\u00fcssen/", "tokens": ["was", "h\u00fcpfft", "jhr", "mit", "den", "F\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "jhr Berg/ jhr H\u00fcgel freudiglich?", "tokens": ["jhr", "Berg", "/", "jhr", "H\u00fc\u00b7gel", "freu\u00b7dig\u00b7lich", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$(", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wann sich der Herr nur r\u00fchret/", "tokens": ["Wann", "sich", "der", "Herr", "nur", "r\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "so lebt der Erden Fu\u00df/", "tokens": ["so", "lebt", "der", "Er\u00b7den", "Fu\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "wird Jacobs Gott gesp\u00fcret/", "tokens": ["wird", "Ja\u00b7cobs", "Gott", "ge\u00b7sp\u00fc\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NE", "NN", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "di\u00df Gantze weichen mu\u00df/", "tokens": ["di\u00df", "Gant\u00b7ze", "wei\u00b7chen", "mu\u00df", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVINF", "VMFIN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "es mu\u00df der Fels der Erden", "tokens": ["es", "mu\u00df", "der", "Fels", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "ein s\u00fcsses Wasser seyn/", "tokens": ["ein", "s\u00fcs\u00b7ses", "Was\u00b7ser", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "zu f\u00fchlen Brunnen werden", "tokens": ["zu", "f\u00fch\u00b7len", "Brun\u00b7nen", "wer\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "NN", "VAINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "ein eisenvester Stein.", "tokens": ["ein", "ei\u00b7sen\u00b7ves\u00b7ter", "Stein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.74": {"line.1": {"text": "Solte nicht beliebet machen/", "tokens": ["Sol\u00b7te", "nicht", "be\u00b7lie\u00b7bet", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PTKNEG", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "freundlich seyn/ zun S\u00fcndern lachen/", "tokens": ["freund\u00b7lich", "seyn", "/", "zun", "S\u00fcn\u00b7dern", "la\u00b7chen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "VAINF", "$(", "APPRART", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sonder Galle/ sonder Trug?", "tokens": ["son\u00b7der", "Gal\u00b7le", "/", "son\u00b7der", "Trug", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Jhr/ jhr Sternen/ die jhr tantzet", "tokens": ["Ihr", "/", "jhr", "Ster\u00b7nen", "/", "die", "jhr", "tant\u00b7zet"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "$(", "PPOSAT", "NN", "$(", "PRELS", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "und das Leben eingepflantzet/", "tokens": ["und", "das", "Le\u00b7ben", "ein\u00b7ge\u00b7pflant\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "gebet unserm Klagen Fug.", "tokens": ["ge\u00b7bet", "un\u00b7serm", "Kla\u00b7gen", "Fug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.75": {"line.1": {"text": "War der Mund nur aufgeschlossen/", "tokens": ["War", "der", "Mund", "nur", "auf\u00b7ge\u00b7schlos\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Honigworte h\u00e4uffig flossen/", "tokens": ["Ho\u00b7nig\u00b7wor\u00b7te", "h\u00e4uf\u00b7fig", "flos\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "er gieng selbst auf Bl\u00f6de lo\u00df/", "tokens": ["er", "gieng", "selbst", "auf", "Bl\u00f6\u00b7de", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$("], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.4": {"text": "keinem kont er nichts versagen/", "tokens": ["kei\u00b7nem", "kont", "er", "nichts", "ver\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "PIS", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "keinem keine Bitt abschlagen/", "tokens": ["kei\u00b7nem", "kei\u00b7ne", "Bitt", "ab\u00b7schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "PIAT", "NN", "VVINF", "$("], "meter": "+-+-+++-", "measure": "unknown.measure.penta"}, "line.6": {"text": "wer Verbrechen noch so gro\u00df.", "tokens": ["wer", "Ver\u00b7bre\u00b7chen", "noch", "so", "gro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.76": {"line.1": {"text": "Pilgerfreund und selber Pilger/", "tokens": ["Pil\u00b7ger\u00b7freund", "und", "sel\u00b7ber", "Pil\u00b7ger", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Bettelarm/ doch Armuttilger/", "tokens": ["Bet\u00b7tel\u00b7arm", "/", "doch", "Ar\u00b7mut\u00b7til\u00b7ger", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADV", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "du tr\u00e4gst auf den Achseln zu/", "tokens": ["du", "tr\u00e4gst", "auf", "den", "Ach\u00b7seln", "zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKZU", "$("], "meter": "+++-+-+", "measure": "unknown.measure.penta"}, "line.4": {"text": "was sich sundlich hat verfangen/", "tokens": ["was", "sich", "sund\u00b7lich", "hat", "ver\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PRF", "ADJD", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "ohne Weg den Weg gegangen/", "tokens": ["oh\u00b7ne", "Weg", "den", "Weg", "ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "sonder Weide/ sonder Ruh.", "tokens": ["son\u00b7der", "Wei\u00b7de", "/", "son\u00b7der", "Ruh", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.77": {"line.1": {"text": "Was dein Wille/ was dein Wesen/", "tokens": ["Was", "dein", "Wil\u00b7le", "/", "was", "dein", "We\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "$(", "PWS", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "hast du selbsten abgelesen/", "tokens": ["hast", "du", "selbs\u00b7ten", "ab\u00b7ge\u00b7le\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Liechter auf den Weg gesteckt;", "tokens": ["Liech\u00b7ter", "auf", "den", "Weg", "ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "du hast einen Glantz gef\u00fchret/", "tokens": ["du", "hast", "ei\u00b7nen", "Glantz", "ge\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "gleich den Spiegeln au\u00dfpoliret/", "tokens": ["gleich", "den", "Spie\u00b7geln", "au\u00df\u00b7po\u00b7li\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "der den S\u00fcndenwust entdeckt.", "tokens": ["der", "den", "S\u00fcn\u00b7den\u00b7wust", "ent\u00b7deckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.78": {"line.1": {"text": "Die der Sonnenbrand geschw\u00e4rtzet/", "tokens": ["Die", "der", "Son\u00b7nen\u00b7brand", "ge\u00b7schw\u00e4rt\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die die Tageslast enthertzet/", "tokens": ["die", "die", "Ta\u00b7ges\u00b7last", "en\u00b7thert\u00b7zet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "die vor Hitze blind und taub", "tokens": ["die", "vor", "Hit\u00b7ze", "blind", "und", "taub"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "ADJD", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "au\u00dfgemergelt/ abgemattet/", "tokens": ["au\u00df\u00b7ge\u00b7mer\u00b7gelt", "/", "ab\u00b7ge\u00b7mat\u00b7tet", "/"], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$(", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "deines Creutzes Linde schattet/", "tokens": ["dei\u00b7nes", "Creut\u00b7zes", "Lin\u00b7de", "schat\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NE", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "spielend/ k\u00fchlet Lindenlaub.", "tokens": ["spie\u00b7lend", "/", "k\u00fch\u00b7let", "Lin\u00b7den\u00b7laub", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ADJD", "$(", "VVFIN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.79": {"line.1": {"text": "Dir dem Artzt gehorsam waren", "tokens": ["Dir", "dem", "Artzt", "ge\u00b7hor\u00b7sam", "wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "ADJD", "VAFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "die verdorrten Fieberscharen/", "tokens": ["die", "ver\u00b7dorr\u00b7ten", "Fie\u00b7ber\u00b7scha\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "es war \u00fcm ein einig Wort/", "tokens": ["es", "war", "\u00fcm", "ein", "ei\u00b7nig", "Wort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "ADJD", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Kr\u00fcppel lieffen ohne Kr\u00fccken/", "tokens": ["Kr\u00fcp\u00b7pel", "lief\u00b7fen", "oh\u00b7ne", "Kr\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "konten sich zu wandern schicken/", "tokens": ["kon\u00b7ten", "sich", "zu", "wan\u00b7dern", "schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PRF", "PTKZU", "VVINF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "lieffen ohne Steltzen fort.", "tokens": ["lief\u00b7fen", "oh\u00b7ne", "Stelt\u00b7zen", "fort", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.80": {"line.1": {"text": "Auch die stockgebornen Blinden", "tokens": ["Auch", "die", "stock\u00b7ge\u00b7bor\u00b7nen", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "konten ohne Leiter finden", "tokens": ["kon\u00b7ten", "oh\u00b7ne", "Lei\u00b7ter", "fin\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "APPR", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "den vor niegesehnen Weg/", "tokens": ["den", "vor", "nie\u00b7ge\u00b7seh\u00b7nen", "Weg", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "den Weg/ der da hat gegeben", "tokens": ["den", "Weg", "/", "der", "da", "hat", "ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "ADV", "VAFIN", "VVPP"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Augen/ Seele/ Leib und Leben/", "tokens": ["Au\u00b7gen", "/", "See\u00b7le", "/", "Leib", "und", "Le\u00b7ben", "/"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "selbsten Leben/ Liecht und Steg.", "tokens": ["selbs\u00b7ten", "Le\u00b7ben", "/", "Liecht", "und", "Steg", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$(", "NN", "KON", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.81": {"line.1": {"text": "Ohren/ die gantz zugedemmet/", "tokens": ["Oh\u00b7ren", "/", "die", "gantz", "zu\u00b7ge\u00b7dem\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "ADV", "VVPP", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Zungen/ fesselvest gehemmet/", "tokens": ["Zun\u00b7gen", "/", "fes\u00b7sel\u00b7vest", "ge\u00b7hem\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$(", "ADJD", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "sind zu rechte wiederbracht/", "tokens": ["sind", "zu", "rech\u00b7te", "wie\u00b7der\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "ja der Taube h\u00f6rt den Stummen/", "tokens": ["ja", "der", "Tau\u00b7be", "h\u00f6rt", "den", "Stum\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Stumm und Tauber sich vermummen/", "tokens": ["Stumm", "und", "Tau\u00b7ber", "sich", "ver\u00b7mum\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KON", "NN", "PRF", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "mit dem Judas bey der Nacht.", "tokens": ["mit", "dem", "Ju\u00b7das", "bey", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.82": {"line.1": {"text": "Ach jhr Narren/ ach jhr Thoren!", "tokens": ["Ach", "jhr", "Nar\u00b7ren", "/", "ach", "jhr", "Tho\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PPOSAT", "NN", "$(", "XY", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "der den Finger in die Ohren", "tokens": ["der", "den", "Fin\u00b7ger", "in", "die", "Oh\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "dir du tauber Dieb gelegt/", "tokens": ["dir", "du", "tau\u00b7ber", "Dieb", "ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPER", "ADJA", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Stummer/ der die Zung dir r\u00fchret/", "tokens": ["Stum\u00b7mer", "/", "der", "die", "Zung", "dir", "r\u00fch\u00b7ret", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "ART", "NN", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "wird von euch hinau\u00dfgef\u00fchret/", "tokens": ["wird", "von", "euch", "hin\u00b7au\u00df\u00b7ge\u00b7f\u00fch\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Vntreu seinen Herren schl\u00e4gt.", "tokens": ["Vntreu", "sei\u00b7nen", "Her\u00b7ren", "schl\u00e4gt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.83": {"line.1": {"text": "Mein Gott war\u00fcm/ war\u00fcm mein Gott", "tokens": ["Mein", "Gott", "wa\u00b7r\u00fcm", "/", "wa\u00b7r\u00fcm", "mein", "Gott"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "$(", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "hast du mich so verlassen/", "tokens": ["hast", "du", "mich", "so", "ver\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PRF", "ADV", "VVINF", "$("], "meter": "---+-+-", "measure": "unknown.measure.di"}, "line.3": {"text": "ich heul in meinem Creutz und Spott/", "tokens": ["ich", "heul", "in", "mei\u00b7nem", "Creutz", "und", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00fclf ist auf keiner Gassen/", "tokens": ["H\u00fclf", "ist", "auf", "kei\u00b7ner", "Gas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "ich ruffe/ wann die Sonne wacht/", "tokens": ["ich", "ruf\u00b7fe", "/", "wann", "die", "Son\u00b7ne", "wacht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PWAV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "kein Antwort will gefallen", "tokens": ["kein", "Ant\u00b7wort", "will", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "VMFIN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "noch erschallen/", "tokens": ["noch", "er\u00b7schal\u00b7len", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "ich schweig auch nicht bey Nacht/", "tokens": ["ich", "schweig", "auch", "nicht", "bey", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "APPR", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "wenn alles schweigt in allen.", "tokens": ["wenn", "al\u00b7les", "schweigt", "in", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "APPR", "PIAT", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.84": {"line.1": {"text": "Gott du bist heilig f\u00fcr und f\u00fcr/", "tokens": ["Gott", "du", "bist", "hei\u00b7lig", "f\u00fcr", "und", "f\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "VAFIN", "ADJD", "APPR", "KON", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "gantz Israel das preiset/", "tokens": ["gantz", "Is\u00b7rael", "das", "prei\u00b7set", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "PDS", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "dein hohes Lob/ mit hoher Zier/", "tokens": ["dein", "ho\u00b7hes", "Lob", "/", "mit", "ho\u00b7her", "Zier", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$(", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der V\u00e4ter Schar erweiset;", "tokens": ["der", "V\u00e4\u00b7ter", "Schar", "er\u00b7wei\u00b7set", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "den V\u00e4tern/ die im w\u00fcsten Land", "tokens": ["den", "V\u00e4\u00b7tern", "/", "die", "im", "w\u00fcs\u00b7ten", "Land"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "ART", "APPRART", "VVFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "mit Hoffen an dir hiengen/", "tokens": ["mit", "Hof\u00b7fen", "an", "dir", "hien\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "zu dir giengen/", "tokens": ["zu", "dir", "gien\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "dir du in freyen Stand", "tokens": ["dir", "du", "in", "frey\u00b7en", "Stand"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "PPER", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "gen\u00e4digst wollen bringen.", "tokens": ["ge\u00b7n\u00e4\u00b7digst", "wol\u00b7len", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "Sie suchten deine Helferhand", "tokens": ["Sie", "such\u00b7ten", "dei\u00b7ne", "Hel\u00b7fer\u00b7hand"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "mit Hofnung/ die da schreyet/", "tokens": ["mit", "Hof\u00b7nung", "/", "die", "da", "schre\u00b7yet", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "ART", "ADV", "VVFIN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "drauf hast du jhre Schmach gewandt", "tokens": ["drauf", "hast", "du", "jhre", "Schmach", "ge\u00b7wandt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "PPER", "PPOSAT", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und sie vor Schand befreyet:", "tokens": ["und", "sie", "vor", "Schand", "be\u00b7fre\u00b7yet", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Ich aber bin ein Wurm vor Gott/", "tokens": ["Ich", "a\u00b7ber", "bin", "ein", "Wurm", "vor", "Gott", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "f\u00fcr Aengsten gar verschmachtet/", "tokens": ["f\u00fcr", "A\u00b7engs\u00b7ten", "gar", "ver\u00b7schmach\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.7": {"text": "nichts geachtet/", "tokens": ["nichts", "ge\u00b7ach\u00b7tet", "/"], "token_info": ["word", "word", "punct"], "pos": ["PIS", "VVPP", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "der Leute Hohn und Spott/", "tokens": ["der", "Leu\u00b7te", "Hohn", "und", "Spott", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "von m\u00e4nniglich/ verachtet.", "tokens": ["von", "m\u00e4n\u00b7nig\u00b7lich", "/", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJD", "$(", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "Wer mich siht/ lacht mich h\u00f6nisch an/", "tokens": ["Wer", "mich", "siht", "/", "lacht", "mich", "h\u00f6\u00b7nisch", "an", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVFIN", "$(", "VVFIN", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den Leib spottweise r\u00fcttelt/", "tokens": ["den", "Leib", "spott\u00b7wei\u00b7se", "r\u00fct\u00b7telt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "zerrt sein Maul auf/ so weit er kan/", "tokens": ["zerrt", "sein", "Maul", "auf", "/", "so", "weit", "er", "kan", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPR", "$(", "ADV", "ADJD", "PPER", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Kopf gantz h\u00f6nisch sch\u00fcttelt;", "tokens": ["den", "Kopf", "gantz", "h\u00f6\u00b7nisch", "sch\u00fct\u00b7telt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "der ist es/ der sich machet gro\u00df:", "tokens": ["der", "ist", "es", "/", "der", "sich", "ma\u00b7chet", "gro\u00df", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "$(", "PRELS", "PRF", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "er klag es seinem Herren/", "tokens": ["er", "klag", "es", "sei\u00b7nem", "Her\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "der nicht ferren/", "tokens": ["der", "nicht", "fer\u00b7ren", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PTKNEG", "VVINF", "$("], "meter": "--+-", "measure": "anapaest.init"}, "line.8": {"text": "der wird jhn machen lo\u00df/", "tokens": ["der", "wird", "jhn", "ma\u00b7chen", "lo\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "was jhm zuwider sperren!", "tokens": ["was", "jhm", "zu\u00b7wi\u00b7der", "sper\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.87": {"line.1": {"text": "Als ich noch lag in finstrer Nacht/", "tokens": ["Als", "ich", "noch", "lag", "in", "finst\u00b7rer", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "warst du mein Gott im Weibe/", "tokens": ["warst", "du", "mein", "Gott", "im", "Wei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "als du mich an das Liecht gebracht", "tokens": ["als", "du", "mich", "an", "das", "Liecht", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "au\u00df meiner Mutter Leibe/", "tokens": ["au\u00df", "mei\u00b7ner", "Mut\u00b7ter", "Lei\u00b7be", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "du warst mein Gott/ mein Zuversicht/", "tokens": ["du", "warst", "mein", "Gott", "/", "mein", "Zu\u00b7ver\u00b7sicht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als ich noch unerzogen", "tokens": ["als", "ich", "noch", "un\u00b7er\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Milch gesogen", "tokens": ["Milch", "ge\u00b7so\u00b7gen"], "token_info": ["word", "word"], "pos": ["NN", "VVPP"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "und meine Mutterpflicht", "tokens": ["und", "mei\u00b7ne", "Mut\u00b7ter\u00b7pflicht"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mit Wartung mich gepflogen.", "tokens": ["mit", "War\u00b7tung", "mich", "ge\u00b7pflo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.88": {"line.1": {"text": "Zeug deine H\u00fclffe ja nicht ein", "tokens": ["Zeug", "dei\u00b7ne", "H\u00fclf\u00b7fe", "ja", "nicht", "ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "ADV", "PTKNEG", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "denn Angst ist nimmer ferren", "tokens": ["denn", "Angst", "ist", "nim\u00b7mer", "fer\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "NN", "VAFIN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "kein Helffer hilfft als du allein/", "tokens": ["kein", "Helf\u00b7fer", "hilfft", "als", "du", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "KOUS", "PPER", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "h\u00f6r/ wie die Stiere plerren/", "tokens": ["h\u00f6r", "/", "wie", "die", "Stie\u00b7re", "pler\u00b7ren", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "schau/ wie der Wammenochsen Schar", "tokens": ["schau", "/", "wie", "der", "Wam\u00b7me\u00b7noch\u00b7sen", "Schar"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["PTKVZ", "$(", "KOKOM", "ART", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "mit aller Krafft einspringet/", "tokens": ["mit", "al\u00b7ler", "Krafft", "ein\u00b7sprin\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "auf mich dringet", "tokens": ["auf", "mich", "drin\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPER", "VVFIN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "mit Seel- und Leibsgefahr/", "tokens": ["mit", "Seel", "und", "Leibs\u00b7ge\u00b7fahr", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "TRUNC", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mich untertritt und zwinget.", "tokens": ["mich", "un\u00b7ter\u00b7tritt", "und", "zwin\u00b7get", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.89": {"line.1": {"text": "Sie sperren jhren Rachen auf", "tokens": ["Sie", "sper\u00b7ren", "jhren", "Ra\u00b7chen", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie L\u00f6wen/ die da br\u00fcllen/", "tokens": ["wie", "L\u00f6\u00b7wen", "/", "die", "da", "br\u00fcl\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$(", "ART", "ADV", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "ich truckne wie ein Wasserlauf/", "tokens": ["ich", "truck\u00b7ne", "wie", "ein", "Was\u00b7ser\u00b7lauf", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "de\u00df Quell verseugt ohn Quillen/", "tokens": ["de\u00df", "Quell", "ver\u00b7seugt", "ohn", "Quil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "es will Gelenck/ es will Gebein/", "tokens": ["es", "will", "Ge\u00b7lenck", "/", "es", "will", "Ge\u00b7bein", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$(", "PPER", "VMFIN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als wer es au\u00dfgerissen/", "tokens": ["als", "wer", "es", "au\u00df\u00b7ge\u00b7ris\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PWS", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "sich nicht schliessen/", "tokens": ["sich", "nicht", "schlies\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVINF", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "wie Wachs vom Sonnenschein", "tokens": ["wie", "Wachs", "vom", "Son\u00b7nen\u00b7schein"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "APPRART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mu\u00df mein Hertz fliessig fliessen.", "tokens": ["mu\u00df", "mein", "Hertz", "flies\u00b7sig", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.90": {"line.1": {"text": "Ich bin ein Scherbend\u00fcrrer Mann/", "tokens": ["Ich", "bin", "ein", "Scher\u00b7ben\u00b7d\u00fcr\u00b7rer", "Mann", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "kein Krafft/ kein Safft sich reget/", "tokens": ["kein", "Krafft", "/", "kein", "Safft", "sich", "re\u00b7get", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$(", "PIAT", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "die Zung am Gaumen klebet an/", "tokens": ["die", "Zung", "am", "Gau\u00b7men", "kle\u00b7bet", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "ich werd von dir geleget/", "tokens": ["ich", "werd", "von", "dir", "ge\u00b7le\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "VVPP", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "von dir in schwartzen Todensand/", "tokens": ["von", "dir", "in", "schwart\u00b7zen", "To\u00b7den\u00b7sand", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "es haben mir die Hunde/", "tokens": ["es", "ha\u00b7ben", "mir", "die", "Hun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "bi\u00df zu Grunde/", "tokens": ["bi\u00df", "zu", "Grun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "durchgraben Fu\u00df und Hand/", "tokens": ["durch\u00b7gra\u00b7ben", "Fu\u00df", "und", "Hand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "KON", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "mein Leib ist eine Wunde.", "tokens": ["mein", "Leib", "ist", "ei\u00b7ne", "Wun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.91": {"line.1": {"text": "Ich m\u00f6chte alle mein Gebein", "tokens": ["Ich", "m\u00f6ch\u00b7te", "al\u00b7le", "mein", "Ge\u00b7bein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "an Fingern abezehlen/", "tokens": ["an", "Fin\u00b7gern", "a\u00b7be\u00b7zeh\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "sie haben aber Lust allein/", "tokens": ["sie", "ha\u00b7ben", "a\u00b7ber", "Lust", "al\u00b7lein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit W\u00fcrfelspiel mich qu\u00e4len;", "tokens": ["mit", "W\u00fcr\u00b7fel\u00b7spiel", "mich", "qu\u00e4\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wann sie die Schantz (O S\u00fcnd! O Schand!)", "tokens": ["wann", "sie", "die", "Schantz", "(", "O", "S\u00fcnd", "!", "O", "Schand", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "$(", "NE", "NN", "$.", "NE", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00fcm meine Kleider schlagen/", "tokens": ["\u00fcm", "mei\u00b7ne", "Klei\u00b7der", "schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nach Behagen", "tokens": ["nach", "Be\u00b7ha\u00b7gen"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Lo\u00df werfen \u00fcm Gewand/", "tokens": ["Lo\u00df", "wer\u00b7fen", "\u00fcm", "Ge\u00b7wand", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "das ich am Leib getragen.", "tokens": ["das", "ich", "am", "Leib", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.92": {"line.1": {"text": "Tritt Helffer/ tritt doch n\u00e4her bey/", "tokens": ["Tritt", "Helf\u00b7fer", "/", "tritt", "doch", "n\u00e4\u00b7her", "bey", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "$(", "VVFIN", "ADV", "ADJD", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "was wilt du ferne gehen?", "tokens": ["was", "wilt", "du", "fer\u00b7ne", "ge\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "mach meine Seel vom Schwerte frey/", "tokens": ["mach", "mei\u00b7ne", "Seel", "vom", "Schwer\u00b7te", "frey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "APPRART", "NN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df sie getrost m\u00f6g stehen/", "tokens": ["da\u00df", "sie", "ge\u00b7trost", "m\u00f6g", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "treib ab/ treib ab den Grimmenhund/", "tokens": ["treib", "ab", "/", "treib", "ab", "den", "Grim\u00b7men\u00b7hund", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$(", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "rei\u00df mich au\u00df L\u00f6wenschlunde", "tokens": ["rei\u00df", "mich", "au\u00df", "L\u00f6\u00b7wen\u00b7schlun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "NN"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.7": {"text": "zu der Stunde/", "tokens": ["zu", "der", "Stun\u00b7de", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "da\u00df meine Zung und Mund", "tokens": ["da\u00df", "mei\u00b7ne", "Zung", "und", "Mund"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "das Hornthier nicht verwunde/", "tokens": ["das", "Horn\u00b7thier", "nicht", "ver\u00b7wun\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.93": {"line.1": {"text": "Ich will die fromme Br\u00fcderschar", "tokens": ["Ich", "will", "die", "from\u00b7me", "Br\u00fc\u00b7der\u00b7schar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "zum Lobefest betagen/", "tokens": ["zum", "Lo\u00b7be\u00b7fest", "be\u00b7ta\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "de\u00df Herren Namen offenbar", "tokens": ["de\u00df", "Her\u00b7ren", "Na\u00b7men", "of\u00b7fen\u00b7bar"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dem Samen Jacobs sagen/", "tokens": ["dem", "Sa\u00b7men", "Ja\u00b7cobs", "sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "da\u00df er jhn ehr/ \u00fcm da\u00df er frey", "tokens": ["da\u00df", "er", "jhn", "ehr", "/", "\u00fcm", "da\u00df", "er", "frey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "NN", "$(", "ADV", "KOUS", "PPER", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sein Antlitz nicht verstecket", "tokens": ["sein", "Ant\u00b7litz", "nicht", "ver\u00b7ste\u00b7cket"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "noch bedecket/", "tokens": ["noch", "be\u00b7de\u00b7cket", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "und zu dem Angstgeschrey", "tokens": ["und", "zu", "dem", "Angst\u00b7ge\u00b7schrey"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "sein leises Ohr gestrecket.", "tokens": ["sein", "lei\u00b7ses", "Ohr", "ge\u00b7stre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.94": {"line.1": {"text": "Ich will in dieser grossen Stadt", "tokens": ["Ich", "will", "in", "die\u00b7ser", "gros\u00b7sen", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und allen Kirchgemeinen/", "tokens": ["und", "al\u00b7len", "Kirch\u00b7ge\u00b7mei\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "wie meine Zung versprochen hat/", "tokens": ["wie", "mei\u00b7ne", "Zung", "ver\u00b7spro\u00b7chen", "hat", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Lobedanck erscheinen/", "tokens": ["mit", "Lo\u00b7be\u00b7danck", "er\u00b7schei\u00b7nen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "wer elend ist/ der isst sich satt/", "tokens": ["wer", "e\u00b7lend", "ist", "/", "der", "isst", "sich", "satt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "VAFIN", "$(", "ART", "VVFIN", "PRF", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "sucht Gott und Gott erhebet", "tokens": ["sucht", "Gott", "und", "Gott", "er\u00b7he\u00b7bet"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "friedlich lebet/", "tokens": ["fried\u00b7lich", "le\u00b7bet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVFIN", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "so lang das Sonnenrad", "tokens": ["so", "lang", "das", "Son\u00b7nen\u00b7rad"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "am blauen Himmel schwebet.", "tokens": ["am", "blau\u00b7en", "Him\u00b7mel", "schwe\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.95": {"line.1": {"text": "De\u00df wird gedacht zu jeder Zeit/", "tokens": ["De\u00df", "wird", "ge\u00b7dacht", "zu", "je\u00b7der", "Zeit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "VVPP", "APPR", "PIAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der sich zu Gott bekehret/", "tokens": ["der", "sich", "zu", "Gott", "be\u00b7keh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "der Heyden Volck jhn weit und breit", "tokens": ["der", "Hey\u00b7den", "Volck", "jhn", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "PPER", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mit Niderfallen ehret/", "tokens": ["mit", "Ni\u00b7der\u00b7fal\u00b7len", "eh\u00b7ret", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "es wird der Fetten feiste Rott", "tokens": ["es", "wird", "der", "Fet\u00b7ten", "feis\u00b7te", "Rott"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu seinem Fu\u00df sich legen", "tokens": ["zu", "sei\u00b7nem", "Fu\u00df", "sich", "le\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "allerwegen/", "tokens": ["al\u00b7ler\u00b7we\u00b7gen", "/"], "token_info": ["word", "punct"], "pos": ["ADV", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "auch der mit Kummerspott", "tokens": ["auch", "der", "mit", "Kum\u00b7mer\u00b7spott"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "APPR", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "den Lebensrest mu\u00df hegen.", "tokens": ["den", "Le\u00b7bens\u00b7rest", "mu\u00df", "he\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.96": {"line.1": {"text": "So lang und wo nur Menschen sind/", "tokens": ["So", "lang", "und", "wo", "nur", "Men\u00b7schen", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PWAV", "ADV", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wird bleiben Gottes Samen/", "tokens": ["wird", "blei\u00b7ben", "Got\u00b7tes", "Sa\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVINF", "NN", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "fortan wird Kindes-Kindes Kind", "tokens": ["for\u00b7tan", "wird", "Kin\u00b7des\u00b7Kin\u00b7des", "Kind"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "verk\u00fcnden seinen Namen/", "tokens": ["ver\u00b7k\u00fcn\u00b7den", "sei\u00b7nen", "Na\u00b7men", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "sie werden seine Billichkeit", "tokens": ["sie", "wer\u00b7den", "sei\u00b7ne", "Bil\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "der greisen Nachwelt sagen", "tokens": ["der", "grei\u00b7sen", "Nach\u00b7welt", "sa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "nach Behagen:", "tokens": ["nach", "Be\u00b7ha\u00b7gen", ":"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Gott/ der ertheilt Bescheid/", "tokens": ["Gott", "/", "der", "er\u00b7theilt", "Be\u00b7scheid", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "ART", "VVFIN", "NN", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.9": {"text": "da\u00df sich nicht zu beklagen.", "tokens": ["da\u00df", "sich", "nicht", "zu", "be\u00b7kla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.97": {"line.1": {"text": "Auf dich Herr setz ich alle Sachen/", "tokens": ["Auf", "dich", "Herr", "setz", "ich", "al\u00b7le", "Sa\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "VVFIN", "PPER", "PIAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "la\u00df mich ja nicht zu Schanden machen/", "tokens": ["la\u00df", "mich", "ja", "nicht", "zu", "Schan\u00b7den", "ma\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "errette doch in dieser Zeit", "tokens": ["er\u00b7ret\u00b7te", "doch", "in", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "mein Recht durch die Gerechtigkeit.", "tokens": ["mein", "Recht", "durch", "die", "Ge\u00b7rech\u00b7tig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Begleite mich auf meinen Stegen/", "tokens": ["Be\u00b7glei\u00b7te", "mich", "auf", "mei\u00b7nen", "Ste\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und f\u00fchr mich deines Namens wegen/", "tokens": ["und", "f\u00fchr", "mich", "dei\u00b7nes", "Na\u00b7mens", "we\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "APPR", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "zeuch mich du Hertzog aller Welt", "tokens": ["zeuch", "mich", "du", "Hert\u00b7zog", "al\u00b7ler", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "PPER", "PPER", "NE", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "au\u00df Netzen/ die sie mir gestellt.", "tokens": ["au\u00df", "Net\u00b7zen", "/", "die", "sie", "mir", "ge\u00b7stellt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "PRELS", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.99": {"line.1": {"text": "Neig dein Geh\u00f6r zu meinen Lippen/", "tokens": ["Neig", "dein", "Ge\u00b7h\u00f6r", "zu", "mei\u00b7nen", "Lip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du bist mein Fels auf hohen Klippen/", "tokens": ["du", "bist", "mein", "Fels", "auf", "ho\u00b7hen", "Klip\u00b7pen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "sey mir ein wolverwahrter Schutz/", "tokens": ["sey", "mir", "ein", "wol\u00b7ver\u00b7wahr\u00b7ter", "Schutz", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "der hintertreib der Feinde Trutz.", "tokens": ["der", "hin\u00b7ter\u00b7treib", "der", "Fein\u00b7de", "Trutz", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.100": {"line.1": {"text": "Den Geist/ den ich jetzt \u00fcberlasse", "tokens": ["Den", "Geist", "/", "den", "ich", "jetzt", "\u00fc\u00b7ber\u00b7las\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "PPER", "ADV", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in deine Vaterh\u00e4nde fasse/", "tokens": ["in", "dei\u00b7ne", "Va\u00b7ter\u00b7h\u00e4n\u00b7de", "fas\u00b7se", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "du hast mich Herr/ du treuer Gott/", "tokens": ["du", "hast", "mich", "Herr", "/", "du", "treu\u00b7er", "Gott", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "NN", "$(", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "erl\u00f6set au\u00df des Creutzes Spott.", "tokens": ["er\u00b7l\u00f6\u00b7set", "au\u00df", "des", "Creut\u00b7zes", "Spott", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.101": {"line.1": {"text": "Jhr Augen wolt jhr euch der Augeng\u00fcsse sch\u00e4men", "tokens": ["Ihr", "Au\u00b7gen", "wolt", "jhr", "euch", "der", "Au\u00b7gen\u00b7g\u00fcs\u00b7se", "sch\u00e4\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "PRF", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "und du/ mein st\u00e4hlern Hertz/ sey doch nicht Stahl unn Stein/", "tokens": ["und", "du", "/", "mein", "st\u00e4h\u00b7lern", "Hertz", "/", "sey", "doch", "nicht", "Stahl", "unn", "Stein", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "$(", "PPOSAT", "ADJA", "NN", "$(", "VAFIN", "ADV", "PTKNEG", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "thrent Augenwinckel/ thrent/ thrent Wimpern/ Augenbr\u00e4men/", "tokens": ["thrent", "Au\u00b7gen\u00b7win\u00b7ckel", "/", "thrent", "/", "thrent", "Wim\u00b7pern", "/", "Au\u00b7gen\u00b7br\u00e4\u00b7men", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "NN", "$(", "VVFIN", "$(", "VVFIN", "NN", "$(", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "es mu\u00df im Zehrenbad mein Hertz gebadet seyn.", "tokens": ["es", "mu\u00df", "im", "Zeh\u00b7ren\u00b7bad", "mein", "Hertz", "ge\u00b7ba\u00b7det", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPRART", "NN", "PPOSAT", "NN", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.102": {"line.1": {"text": "Ich hab mein Lebtag nicht ein solches Bild gesehen/", "tokens": ["Ich", "hab", "mein", "Leb\u00b7tag", "nicht", "ein", "sol\u00b7ches", "Bild", "ge\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PTKNEG", "ART", "PIAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "ach jammervolles Bild! kranck/ elend/ matt und bla\u00df/", "tokens": ["ach", "jam\u00b7mer\u00b7vol\u00b7les", "Bild", "!", "kranck", "/", "e\u00b7lend", "/", "matt", "und", "bla\u00df", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$.", "ADJD", "$(", "ADJD", "$(", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "seht/ welch ein Mensch ist das! wie mu\u00df jhm seyn geschehen/", "tokens": ["seht", "/", "welch", "ein", "Mensch", "ist", "das", "!", "wie", "mu\u00df", "jhm", "seyn", "ge\u00b7sche\u00b7hen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAT", "ART", "NN", "VAFIN", "PDS", "$.", "PWAV", "VMFIN", "PPER", "PPOSAT", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "na\u00df/ matt/ kranck/ sterbekranck/ vom Blute pf\u00fctzena\u00df.", "tokens": ["na\u00df", "/", "matt", "/", "kranck", "/", "ster\u00b7be\u00b7kranck", "/", "vom", "Blu\u00b7te", "pf\u00fct\u00b7ze\u00b7na\u00df", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$(", "ADJD", "$(", "ADJD", "$(", "VVFIN", "$(", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.103": {"line.1": {"text": "Das jungferreine Lamm wird von den St\u00e4nckerb\u00f6cken", "tokens": ["Das", "jung\u00b7fer\u00b7rei\u00b7ne", "Lamm", "wird", "von", "den", "St\u00e4n\u00b7cker\u00b7b\u00f6\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "gejaget hin und her; das unbefleckte Schaf", "tokens": ["ge\u00b7ja\u00b7get", "hin", "und", "her", ";", "das", "un\u00b7be\u00b7fleck\u00b7te", "Schaf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "PTKVZ", "KON", "PTKVZ", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "ist gelblich/ braun und blau; die Rosen tragen H\u00f6cken/", "tokens": ["ist", "gelb\u00b7lich", "/", "braun", "und", "blau", ";", "die", "Ro\u00b7sen", "tra\u00b7gen", "H\u00f6\u00b7cken", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$(", "ADJD", "KON", "ADJD", "$.", "ART", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "der Honig trincket Gall; der ohne Schlaf wird Schlaf.", "tokens": ["der", "Ho\u00b7nig", "trin\u00b7cket", "Gall", ";", "der", "oh\u00b7ne", "Schlaf", "wird", "Schlaf", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NE", "$.", "ART", "APPR", "NN", "VAFIN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.104": {"line.1": {"text": "Was thut das Silber nicht? hier silbert man die H\u00e4nde", "tokens": ["Was", "thut", "das", "Sil\u00b7ber", "nicht", "?", "hier", "sil\u00b7bert", "man", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$.", "ADV", "VVFIN", "PIS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "dem eisern Kriegesknecht; der schl\u00e4get Hand und Fu\u00df", "tokens": ["dem", "ei\u00b7sern", "Krie\u00b7ges\u00b7knecht", ";", "der", "schl\u00e4\u00b7get", "Hand", "und", "Fu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$.", "ART", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "in Stock und Eisen ein; Ach Elend/ Ach Elende!", "tokens": ["in", "Stock", "und", "Ei\u00b7sen", "ein", ";", "Ach", "E\u00b7lend", "/", "Ach", "E\u00b7len\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "PTKVZ", "$.", "ITJ", "NN", "$(", "ITJ", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "mich wundert/ da\u00df er nicht vor Schmertzen sterben mu\u00df.", "tokens": ["mich", "wun\u00b7dert", "/", "da\u00df", "er", "nicht", "vor", "Schmert\u00b7zen", "ster\u00b7ben", "mu\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PPER", "PTKNEG", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.105": {"line.1": {"text": "Er lebt/ er lebet nicht! Er schwebt/ und nicht recht schwebet", "tokens": ["Er", "lebt", "/", "er", "le\u00b7bet", "nicht", "!", "Er", "schwebt", "/", "und", "nicht", "recht", "schwe\u00b7bet"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "PTKNEG", "$.", "PPER", "VVFIN", "$(", "KON", "PTKNEG", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Lufftf\u00fcrst in der Lufft; die Last wird jhme Last/", "tokens": ["der", "Luff\u00b7tf\u00fcrst", "in", "der", "Lufft", ";", "die", "Last", "wird", "jh\u00b7me", "Last", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "de\u00df Lebens Leben stirbt; Er lebet nicht/ er lebet!", "tokens": ["de\u00df", "Le\u00b7bens", "Le\u00b7ben", "stirbt", ";", "Er", "le\u00b7bet", "nicht", "/", "er", "le\u00b7bet", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PTKNEG", "$(", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "das gr\u00fcne Holtz verdorrt/ der Farben Farbe blast.", "tokens": ["das", "gr\u00fc\u00b7ne", "Holtz", "ver\u00b7dorrt", "/", "der", "Far\u00b7ben", "Far\u00b7be", "blast", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$(", "ART", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.106": {"line.1": {"text": "Ja/ wol er hat gelebt. Der Glieder Glied sich kr\u00fcmmet/", "tokens": ["Ja", "/", "wol", "er", "hat", "ge\u00b7lebt", ".", "Der", "Glie\u00b7der", "Glied", "sich", "kr\u00fcm\u00b7met", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "ADV", "PPER", "VAFIN", "VVPP", "$.", "ART", "NN", "NN", "PRF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "der Aufgang au\u00df der H\u00f6h am Abend untergeht/", "tokens": ["der", "Auf\u00b7gang", "au\u00df", "der", "H\u00f6h", "am", "A\u00b7bend", "un\u00b7ter\u00b7geht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Augen Sternenpar im toden Meere schwimmet/", "tokens": ["der", "Au\u00b7gen", "Ster\u00b7nen\u00b7par", "im", "to\u00b7den", "Mee\u00b7re", "schwim\u00b7met", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPRART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach Sohn/ Ach lieber Sohn/ sihst du/ wer bey dir steht?", "tokens": ["Ach", "Sohn", "/", "Ach", "lie\u00b7ber", "Sohn", "/", "sihst", "du", "/", "wer", "bey", "dir", "steht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "$(", "ITJ", "ADV", "NN", "$(", "VVFIN", "PPER", "$(", "PWS", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.107": {"line.1": {"text": "Ach leider/ leider Ach! Ach/ Ach er ist gestorben", "tokens": ["Ach", "lei\u00b7der", "/", "lei\u00b7der", "Ach", "!", "Ach", "/", "Ach", "er", "ist", "ge\u00b7stor\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "ADV", "$(", "ADV", "ITJ", "$.", "ITJ", "$(", "ITJ", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "mein allerliebstes Kind; Ach weinet doch mit mir/", "tokens": ["mein", "al\u00b7ler\u00b7liebs\u00b7tes", "Kind", ";", "Ach", "wei\u00b7net", "doch", "mit", "mir", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$.", "ITJ", "VVFIN", "ADV", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "der Tod hat mir mein Lieb/ und meine Lieb verdorben/", "tokens": ["der", "Tod", "hat", "mir", "mein", "Lieb", "/", "und", "mei\u00b7ne", "Lieb", "ver\u00b7dor\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "$(", "KON", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ach alles weine doch \u00fcm mich/ und meine Zier.", "tokens": ["Ach", "al\u00b7les", "wei\u00b7ne", "doch", "\u00fcm", "mich", "/", "und", "mei\u00b7ne", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "PIS", "VVFIN", "ADV", "VVFIN", "PPER", "$(", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.108": {"line.1": {"text": "Der F\u00fcrhang ist zerzerret/", "tokens": ["Der", "F\u00fcr\u00b7hang", "ist", "zer\u00b7zer\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "der Himmel aufgesperret.", "tokens": ["der", "Him\u00b7mel", "auf\u00b7ge\u00b7sper\u00b7ret", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.109": {"line.1": {"text": "Den solten alle Teufel fassen/", "tokens": ["Den", "sol\u00b7ten", "al\u00b7le", "Teu\u00b7fel", "fas\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der sich zuerst hinabgelassen/", "tokens": ["der", "sich", "zu\u00b7erst", "hin\u00b7ab\u00b7ge\u00b7las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durch nasse Tufft/ durch Schwefelrauch", "tokens": ["durch", "nas\u00b7se", "Tufft", "/", "durch", "Schwe\u00b7fel\u00b7rauch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$(", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "sehr tief hinein in Erdenbauch.", "tokens": ["sehr", "tief", "hin\u00b7ein", "in", "Er\u00b7den\u00b7bauch", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.110": {"line.1": {"text": "Da\u00df der doch alle Teufel leide/", "tokens": ["Da\u00df", "der", "doch", "al\u00b7le", "Teu\u00b7fel", "lei\u00b7de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "PIAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der/ der der Berge Eingeweide", "tokens": ["der", "/", "der", "der", "Ber\u00b7ge", "Ein\u00b7ge\u00b7wei\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$(", "ART", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durchkrochen und daselbst gesucht", "tokens": ["durch\u00b7kro\u00b7chen", "und", "da\u00b7selbst", "ge\u00b7sucht"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "KON", "PAV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "den Teuffels-Stahl/ de\u00df Eisens Zucht.", "tokens": ["den", "Teuf\u00b7fels\u00b7Stahl", "/", "de\u00df", "Ei\u00b7sens", "Zucht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$(", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.111": {"line.1": {"text": "Den solten alle Teuffel haschen/", "tokens": ["Den", "sol\u00b7ten", "al\u00b7le", "Teuf\u00b7fel", "ha\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der Gruben-Ertz gepocht/ gewaschen/", "tokens": ["der", "Gru\u00b7ben\u00b7Ertz", "ge\u00b7pocht", "/", "ge\u00b7wa\u00b7schen", "/"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$(", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "verflucht sey/ der es hat geschmeltzt", "tokens": ["ver\u00b7flucht", "sey", "/", "der", "es", "hat", "ge\u00b7schmeltzt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "$(", "PRELS", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und offt im Feuer \u00fcmgeweltzt.", "tokens": ["und", "offt", "im", "Feu\u00b7er", "\u00fcm\u00b7ge\u00b7weltzt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.112": {"line.1": {"text": "Es solten alle Teuffel plagen", "tokens": ["Es", "sol\u00b7ten", "al\u00b7le", "Teuf\u00b7fel", "pla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "den Schmidt/ de\u00df Schmidte zugeschlagen", "tokens": ["den", "Schmidt", "/", "de\u00df", "Schmid\u00b7te", "zu\u00b7ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NE", "$(", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "das Eisen spitzig zugericht/", "tokens": ["das", "Ei\u00b7sen", "spit\u00b7zig", "zu\u00b7ge\u00b7richt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df es ein hartes Holtz zerbricht.", "tokens": ["da\u00df", "es", "ein", "har\u00b7tes", "Holtz", "zer\u00b7bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.113": {"line.1": {"text": "Es m\u00fcssen alle Teuffel holen", "tokens": ["Es", "m\u00fcs\u00b7sen", "al\u00b7le", "Teuf\u00b7fel", "ho\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die N\u00e4gel/ die der F\u00fcsse Solen", "tokens": ["die", "N\u00e4\u00b7gel", "/", "die", "der", "F\u00fcs\u00b7se", "So\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "durchboret und der H\u00e4nde Band.", "tokens": ["durch\u00b7bo\u00b7ret", "und", "der", "H\u00e4n\u00b7de", "Band", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Pfuy/ pfuy der S\u00fcnd/ pfuy/ pfuy der Schand!", "tokens": ["Pfuy", "/", "pfuy", "der", "S\u00fcnd", "/", "pfuy", "/", "pfuy", "der", "Schand", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$(", "NE", "ART", "NN", "$(", "NE", "$(", "NE", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.114": {"line.1": {"text": "Vater geh nicht ins Gericht", "tokens": ["Va\u00b7ter", "geh", "nicht", "ins", "Ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PTKNEG", "APPRART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "mit uns S\u00fcndenknechten/", "tokens": ["mit", "uns", "S\u00fcn\u00b7den\u00b7knech\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "weil dein Sohn uns selbst verspricht/", "tokens": ["weil", "dein", "Sohn", "uns", "selbst", "ver\u00b7spricht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "wilt du mit uns rechten?", "tokens": ["wilt", "du", "mit", "uns", "rech\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Wir sind Stechdorn seiner Kron/", "tokens": ["Wir", "sind", "Stech\u00b7dorn", "sei\u00b7ner", "Kron", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "seine Kn\u00f6tengeissel/", "tokens": ["sei\u00b7ne", "Kn\u00f6\u00b7ten\u00b7geis\u00b7sel", "/"], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$("], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "Ruten/ Peitschen/ Scorpion/", "tokens": ["Ru\u00b7ten", "/", "Peit\u00b7schen", "/", "Scor\u00b7pi\u00b7on", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$(", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Hammer/ N\u00e4gel/ Meissel.", "tokens": ["Ham\u00b7mer", "/", "N\u00e4\u00b7gel", "/", "Meis\u00b7sel", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$(", "NN", "$(", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.115": {"line.1": {"text": "Vater halt den Donner an/", "tokens": ["Va\u00b7ter", "halt", "den", "Don\u00b7ner", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "la\u00df jhn ja nicht haglen/", "tokens": ["la\u00df", "jhn", "ja", "nicht", "hag\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "PTKNEG", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "schlage keinen Zimmermann/", "tokens": ["schla\u00b7ge", "kei\u00b7nen", "Zim\u00b7mer\u00b7mann", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "die das Creutz noch naglen/", "tokens": ["die", "das", "Creutz", "noch", "nag\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "wir/ wir sind de\u00df Speeres Stahl/", "tokens": ["wir", "/", "wir", "sind", "de\u00df", "Spee\u00b7res", "Stahl", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$(", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "der sein Hertz durchstochen/", "tokens": ["der", "sein", "Hertz", "durch\u00b7sto\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "worau\u00df unsers Heiles Mahl", "tokens": ["wo\u00b7rau\u00df", "un\u00b7sers", "Hei\u00b7les", "Mahl"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "wei\u00df und rot gebrochen.", "tokens": ["wei\u00df", "und", "rot", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.116": {"line.1": {"text": "Rote B\u00e4che wie Corall", "tokens": ["Ro\u00b7te", "B\u00e4\u00b7che", "wie", "Co\u00b7rall"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KOKOM", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "springen au\u00df der Seiten/", "tokens": ["sprin\u00b7gen", "au\u00df", "der", "Sei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "reine B\u00e4che wie Crystall", "tokens": ["rei\u00b7ne", "B\u00e4\u00b7che", "wie", "Crys\u00b7tall"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "KOKOM", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "silberhell sich breiten;", "tokens": ["sil\u00b7ber\u00b7hell", "sich", "brei\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "di\u00df Corall und dieses Gla\u00df", "tokens": ["di\u00df", "Co\u00b7rall", "und", "die\u00b7ses", "Gla\u00df"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "KON", "PDAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "allen Vnflat waschen/", "tokens": ["al\u00b7len", "Vn\u00b7flat", "wa\u00b7schen", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "di\u00df Rubin- di\u00df Perlen-Na\u00df", "tokens": ["di\u00df", "Ru\u00b7bin", "di\u00df", "Per\u00b7len\u00b7Na\u00df"], "token_info": ["word", "word", "word", "word"], "pos": ["PDS", "TRUNC", "PDS", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "s\u00e4ubern S\u00fcnden-Aschen.", "tokens": ["s\u00e4u\u00b7bern", "S\u00fcn\u00b7den\u00b7A\u00b7schen", "."], "token_info": ["word", "word", "punct"], "pos": ["KON", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.117": {"line.1": {"text": "Gleichen wir gleich einem Mohr/", "tokens": ["Glei\u00b7chen", "wir", "gleich", "ei\u00b7nem", "Mohr", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "ru\u00dfschwartz angef\u00e4rbet/", "tokens": ["ru\u00df\u00b7schwartz", "an\u00b7ge\u00b7f\u00e4r\u00b7bet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "waschet uns das Seiten-Thor", "tokens": ["wa\u00b7schet", "uns", "das", "Sei\u00b7ten\u00b7Thor"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "dessen/ der gesterbet.", "tokens": ["des\u00b7sen", "/", "der", "ge\u00b7ster\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PDS", "$(", "ART", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Alles Wissens Wissenschafft", "tokens": ["Al\u00b7les", "Wis\u00b7sens", "Wis\u00b7sen\u00b7schafft"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "kan ein Christ fort missen/", "tokens": ["kan", "ein", "Christ", "fort", "mis\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "PTKVZ", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "h\u00e4lt er dieses Creutzes Krafft", "tokens": ["h\u00e4lt", "er", "die\u00b7ses", "Creut\u00b7zes", "Krafft"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PDAT", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "vor sein bestes Wissen.", "tokens": ["vor", "sein", "bes\u00b7tes", "Wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.118": {"line.1": {"text": "Aller Zeug der Gottes-Sohn", "tokens": ["Al\u00b7ler", "Zeug", "der", "Got\u00b7tes\u00b7Sohn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "\u00fcbel zugerichtet/", "tokens": ["\u00fc\u00b7bel", "zu\u00b7ge\u00b7rich\u00b7tet", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "aller Spott und aller Hohn", "tokens": ["al\u00b7ler", "Spott", "und", "al\u00b7ler", "Hohn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "und was jhn vernichtet/", "tokens": ["und", "was", "jhn", "ver\u00b7nich\u00b7tet", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVPP", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Staupseul/ Besen von dem Meer/", "tokens": ["Stau\u00b7pseul", "/", "Be\u00b7sen", "von", "dem", "Meer", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Schl\u00e4ge/ Wunden/ Striemen/", "tokens": ["Schl\u00e4\u00b7ge", "/", "Wun\u00b7den", "/", "Strie\u00b7men", "/"], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$(", "NN", "$(", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Creutzbaum/ Isop/ Schwamm und Speer", "tokens": ["Creutz\u00b7baum", "/", "I\u00b7sop", "/", "Schwamm", "und", "Speer"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "NE", "$(", "NN", "KON", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "sind nun unser R\u00fchmen.", "tokens": ["sind", "nun", "un\u00b7ser", "R\u00fch\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}