{"textgrid.poem.50797": {"metadata": {"author": {"name": "Keller, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich bin befreit, mein Weh hat sich gewendet,", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich bin befreit, mein Weh hat sich gewendet,", "tokens": ["Ich", "bin", "be\u00b7freit", ",", "mein", "Weh", "hat", "sich", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "VAFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich empfind es: ", "tokens": ["Und", "ich", "emp\u00b7find", "es", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der seine Strahlen durch das Weltall sendet,", "tokens": ["Der", "sei\u00b7ne", "Strah\u00b7len", "durch", "das", "Wel\u00b7tall", "sen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er strahlt mich an durch diesen Totenschrein.", "tokens": ["Er", "strahlt", "mich", "an", "durch", "die\u00b7sen", "To\u00b7ten\u00b7schrein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Getrennt bin ich von meinem herben Leiden,", "tokens": ["Ge\u00b7trennt", "bin", "ich", "von", "mei\u00b7nem", "her\u00b7ben", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich b\u00e4ndige den Leib mit starkem Mut;", "tokens": ["Ich", "b\u00e4n\u00b7di\u00b7ge", "den", "Leib", "mit", "star\u00b7kem", "Mut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie wildes Meer, von dem ich mich will scheiden,", "tokens": ["Wie", "wil\u00b7des", "Meer", ",", "von", "dem", "ich", "mich", "will", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "La\u00df brausen ich mein krank und siedend Blut.", "tokens": ["La\u00df", "brau\u00b7sen", "ich", "mein", "krank", "und", "sie\u00b7dend", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PPER", "PPOSAT", "ADJD", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Ja, toset nur, ihr ungetreuen Wogen!", "tokens": ["Ja", ",", "to\u00b7set", "nur", ",", "ihr", "un\u00b7ge\u00b7treu\u00b7en", "Wo\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich \u00fcbersing euch, wie ein Ferg am Strand!", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7sing", "euch", ",", "wie", "ein", "Ferg", "am", "Strand", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Lange genug bin ich mit euch gezogen:", "tokens": ["Lan\u00b7ge", "ge\u00b7nug", "bin", "ich", "mit", "euch", "ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Nun tausch ich euch an festes Bl\u00fctenland.", "tokens": ["Nun", "tausch", "ich", "euch", "an", "fes\u00b7tes", "Bl\u00fc\u00b7ten\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Es ist noch gut geworden, und geschlagen", "tokens": ["Es", "ist", "noch", "gut", "ge\u00b7wor\u00b7den", ",", "und", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$,", "KON", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hat mich der Herr mit einem Rosenstab;", "tokens": ["Hat", "mich", "der", "Herr", "mit", "ei\u00b7nem", "Ro\u00b7sen\u00b7stab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gel\u00e4utert will ich meine Seele tragen", "tokens": ["Ge\u00b7l\u00e4u\u00b7tert", "will", "ich", "mei\u00b7ne", "See\u00b7le", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu ihm empor aus diesem Erdengrab.", "tokens": ["Zu", "ihm", "em\u00b7por", "aus", "die\u00b7sem", "Er\u00b7den\u00b7grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Weil ich so sehr geliebt die gr\u00fcne Erde,", "tokens": ["Weil", "ich", "so", "sehr", "ge\u00b7liebt", "die", "gr\u00fc\u00b7ne", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lebt ich so bang und tief in sie hinein; \u2013", "tokens": ["Lebt", "ich", "so", "bang", "und", "tief", "in", "sie", "hin\u00b7ein", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "APPR", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie ich in ihrem Scho\u00df noch leiden werde:", "tokens": ["Wie", "ich", "in", "ih\u00b7rem", "Scho\u00df", "noch", "lei\u00b7den", "wer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "ADV", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie soll mein lieblichstes Gedenken sein!", "tokens": ["Sie", "soll", "mein", "lieb\u00b7lichs\u00b7tes", "Ge\u00b7den\u00b7ken", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Ich bin befreit, mein Weh hat sich gewendet,", "tokens": ["Ich", "bin", "be\u00b7freit", ",", "mein", "Weh", "hat", "sich", "ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$,", "PPOSAT", "NN", "VAFIN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ich empfind es: ", "tokens": ["Und", "ich", "emp\u00b7find", "es", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Der seine Strahlen durch das Weltall sendet,", "tokens": ["Der", "sei\u00b7ne", "Strah\u00b7len", "durch", "das", "Wel\u00b7tall", "sen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Er strahlt mich an durch diesen Totenschrein.", "tokens": ["Er", "strahlt", "mich", "an", "durch", "die\u00b7sen", "To\u00b7ten\u00b7schrein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Getrennt bin ich von meinem herben Leiden,", "tokens": ["Ge\u00b7trennt", "bin", "ich", "von", "mei\u00b7nem", "her\u00b7ben", "Lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich b\u00e4ndige den Leib mit starkem Mut;", "tokens": ["Ich", "b\u00e4n\u00b7di\u00b7ge", "den", "Leib", "mit", "star\u00b7kem", "Mut", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie wildes Meer, von dem ich mich will scheiden,", "tokens": ["Wie", "wil\u00b7des", "Meer", ",", "von", "dem", "ich", "mich", "will", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "$,", "APPR", "PRELS", "PPER", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "La\u00df brausen ich mein krank und siedend Blut.", "tokens": ["La\u00df", "brau\u00b7sen", "ich", "mein", "krank", "und", "sie\u00b7dend", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "VVFIN", "PPER", "PPOSAT", "ADJD", "KON", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Ja, toset nur, ihr ungetreuen Wogen!", "tokens": ["Ja", ",", "to\u00b7set", "nur", ",", "ihr", "un\u00b7ge\u00b7treu\u00b7en", "Wo\u00b7gen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ich \u00fcbersing euch, wie ein Ferg am Strand!", "tokens": ["Ich", "\u00fc\u00b7ber\u00b7sing", "euch", ",", "wie", "ein", "Ferg", "am", "Strand", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Lange genug bin ich mit euch gezogen:", "tokens": ["Lan\u00b7ge", "ge\u00b7nug", "bin", "ich", "mit", "euch", "ge\u00b7zo\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPER", "APPR", "PPER", "VVPP", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.4": {"text": "Nun tausch ich euch an festes Bl\u00fctenland.", "tokens": ["Nun", "tausch", "ich", "euch", "an", "fes\u00b7tes", "Bl\u00fc\u00b7ten\u00b7land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.9": {"line.1": {"text": "Es ist noch gut geworden, und geschlagen", "tokens": ["Es", "ist", "noch", "gut", "ge\u00b7wor\u00b7den", ",", "und", "ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "VAPP", "$,", "KON", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Hat mich der Herr mit einem Rosenstab;", "tokens": ["Hat", "mich", "der", "Herr", "mit", "ei\u00b7nem", "Ro\u00b7sen\u00b7stab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gel\u00e4utert will ich meine Seele tragen", "tokens": ["Ge\u00b7l\u00e4u\u00b7tert", "will", "ich", "mei\u00b7ne", "See\u00b7le", "tra\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Zu ihm empor aus diesem Erdengrab.", "tokens": ["Zu", "ihm", "em\u00b7por", "aus", "die\u00b7sem", "Er\u00b7den\u00b7grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "PTKVZ", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Weil ich so sehr geliebt die gr\u00fcne Erde,", "tokens": ["Weil", "ich", "so", "sehr", "ge\u00b7liebt", "die", "gr\u00fc\u00b7ne", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Lebt ich so bang und tief in sie hinein; \u2013", "tokens": ["Lebt", "ich", "so", "bang", "und", "tief", "in", "sie", "hin\u00b7ein", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "KON", "ADJD", "APPR", "PPER", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Wie ich in ihrem Scho\u00df noch leiden werde:", "tokens": ["Wie", "ich", "in", "ih\u00b7rem", "Scho\u00df", "noch", "lei\u00b7den", "wer\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "ADV", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Sie soll mein lieblichstes Gedenken sein!", "tokens": ["Sie", "soll", "mein", "lieb\u00b7lichs\u00b7tes", "Ge\u00b7den\u00b7ken", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}