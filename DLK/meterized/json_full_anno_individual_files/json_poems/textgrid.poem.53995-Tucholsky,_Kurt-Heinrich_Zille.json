{"textgrid.poem.53995": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Heinrich Zille", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zweeter Uffjang, vierta Hof", "tokens": ["Zwee\u00b7ter", "Uff\u00b7jang", ",", "vier\u00b7ta", "Hof"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wohnen deine Leute;", "tokens": ["woh\u00b7nen", "dei\u00b7ne", "Leu\u00b7te", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kinder quieken: \u00bbNa, so doof!\u00ab", "tokens": ["Kin\u00b7der", "qui\u00b7e\u00b7ken", ":", "\u00bb", "Na", ",", "so", "doof", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "$.", "$(", "ITJ", "$,", "ADV", "NE", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "jestern, morjn, heute.", "tokens": ["jes\u00b7tern", ",", "morjn", ",", "heu\u00b7te", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Liebe, Krach, Jeburt und Schi\u00df . . .", "tokens": ["Lie\u00b7be", ",", "Krach", ",", "Je\u00b7burt", "und", "Schi\u00df", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "$.", "$.", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Kleene J\u00f6hren mit Pipi", "tokens": ["Klee\u00b7ne", "J\u00f6h\u00b7ren", "mit", "Pi\u00b7pi"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "un vabogne Fie\u00dfe;", "tokens": ["un", "va\u00b7bog\u00b7ne", "Fie\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tanz mit durchjedrickte Knie,", "tokens": ["Tanz", "mit", "durch\u00b7je\u00b7drick\u00b7te", "Knie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "---+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "er sacht: \u00bbMeine Sie\u00dfe!\u00ab", "tokens": ["er", "sacht", ":", "\u00bb", "Mei\u00b7ne", "Sie\u00b7\u00dfe", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Stank und Stunk, berliner Schmi\u00df . . .", "tokens": ["Stank", "und", "Stunk", ",", "ber\u00b7li\u00b7ner", "Sch\u00b7mi\u00df", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "KON", "NN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Jrimmich wahste eijntlich nich \u2013", "tokens": ["Jrim\u00b7mich", "wahs\u00b7te", "ei\u00b7jnt\u00b7lich", "nich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "ADJD", "PTKNEG", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "mal traurich un mal munta.", "tokens": ["mal", "trau\u00b7rich", "un", "mal", "mun\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "FM", "FM", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir war det jahnich l\u00e4chalich:", "tokens": ["Dir", "war", "det", "jah\u00b7nich", "l\u00e4c\u00b7ha\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbmutta, schmei\u00df Stulle runta \u2013!\u00ab", "tokens": ["\u00bb", "mut\u00b7ta", ",", "schmei\u00df", "Stul\u00b7le", "run\u00b7ta", "\u2013", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "$(", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Leierkastenmelodien . . .", "tokens": ["Lei\u00b7er\u00b7kas\u00b7ten\u00b7me\u00b7lo\u00b7di\u00b7en", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Menschen in Berlin.", "tokens": ["Men\u00b7schen", "in", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.4": {"line.1": {"text": "Int Alter beinah ein Schenie \u2013", "tokens": ["Int", "Al\u00b7ter", "bei\u00b7nah", "ein", "Sche\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Bleistift; na, von wejn . . . !", "tokens": ["Dein", "Blei\u00b7stift", ";", "na", ",", "von", "wejn", ".", ".", ".", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "ITJ", "$,", "APPR", "NE", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Janz richtich vastandn ham se dir nie \u2013", "tokens": ["Janz", "rich\u00b7tich", "vas\u00b7tandn", "ham", "se", "dir", "nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "PPER", "ADV", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "die lachtn so \u00fcbalejn.", "tokens": ["die", "lachtn", "so", "\u00fc\u00b7ba\u00b7lejn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die fanden dir riehrend un komisch zujleich.", "tokens": ["Die", "fan\u00b7den", "dir", "ri\u00b7eh\u00b7rend", "un", "ko\u00b7misch", "zu\u00b7jleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "FM", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im \u00fcbrijen: Hoch det Deutsche Reich!", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7jen", ":", "Hoch", "det", "Deut\u00b7sche", "Reich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "ADJD", "VVFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Malen kannste.", "tokens": ["Ma\u00b7len", "kanns\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Zeichnen kannste.", "tokens": ["Zeich\u00b7nen", "kanns\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Witze machen sollste.", "tokens": ["Wit\u00b7ze", "ma\u00b7chen", "solls\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Aba Ernst machen d\u00fcrfste nich.", "tokens": ["A\u00b7ba", "Ernst", "ma\u00b7chen", "d\u00fcrfs\u00b7te", "nich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVINF", "VMFIN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "Du kennst den janzen Kleista \u2013", "tokens": ["Du", "kennst", "den", "jan\u00b7zen", "Kleis\u00b7ta", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "den ihr Schicksal: Stirb oda fri\u00df!", "tokens": ["den", "ihr", "Schick\u00b7sal", ":", "Stirb", "o\u00b7da", "fri\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$.", "FM.la", "FM.la", "FM.la", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Du wahst ein jro\u00dfa Meista.", "tokens": ["Du", "wahst", "ein", "jro\u00b7\u00dfa", "Meis\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "FM", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Zweeter Uffjang, vierta Hof", "tokens": ["Zwee\u00b7ter", "Uff\u00b7jang", ",", "vier\u00b7ta", "Hof"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "wohnen deine Leute;", "tokens": ["woh\u00b7nen", "dei\u00b7ne", "Leu\u00b7te", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Kinder quieken: \u00bbNa, so doof!\u00ab", "tokens": ["Kin\u00b7der", "qui\u00b7e\u00b7ken", ":", "\u00bb", "Na", ",", "so", "doof", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "VVINF", "$.", "$(", "ITJ", "$,", "ADV", "NE", "$.", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "jestern, morjn, heute.", "tokens": ["jes\u00b7tern", ",", "morjn", ",", "heu\u00b7te", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "$,", "ADV", "$,", "ADV", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.5": {"text": "Liebe, Krach, Jeburt und Schi\u00df . . .", "tokens": ["Lie\u00b7be", ",", "Krach", ",", "Je\u00b7burt", "und", "Schi\u00df", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "$,", "NN", "$,", "NE", "KON", "NN", "$.", "$.", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Kleene J\u00f6hren mit Pipi", "tokens": ["Klee\u00b7ne", "J\u00f6h\u00b7ren", "mit", "Pi\u00b7pi"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJA", "NN", "APPR", "NE"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "un vabogne Fie\u00dfe;", "tokens": ["un", "va\u00b7bog\u00b7ne", "Fie\u00b7\u00dfe", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["FM", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Tanz mit durchjedrickte Knie,", "tokens": ["Tanz", "mit", "durch\u00b7je\u00b7drick\u00b7te", "Knie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$,"], "meter": "---+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "er sacht: \u00bbMeine Sie\u00dfe!\u00ab", "tokens": ["er", "sacht", ":", "\u00bb", "Mei\u00b7ne", "Sie\u00b7\u00dfe", "!", "\u00ab"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPOSAT", "NN", "$.", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "Stank und Stunk, berliner Schmi\u00df . . .", "tokens": ["Stank", "und", "Stunk", ",", "ber\u00b7li\u00b7ner", "Sch\u00b7mi\u00df", ".", ".", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["NN", "KON", "NN", "$,", "ADJA", "NN", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Jrimmich wahste eijntlich nich \u2013", "tokens": ["Jrim\u00b7mich", "wahs\u00b7te", "ei\u00b7jnt\u00b7lich", "nich", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "ADJD", "PTKNEG", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.2": {"text": "mal traurich un mal munta.", "tokens": ["mal", "trau\u00b7rich", "un", "mal", "mun\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "FM", "FM", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dir war det jahnich l\u00e4chalich:", "tokens": ["Dir", "war", "det", "jah\u00b7nich", "l\u00e4c\u00b7ha\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PDS", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "\u00bbmutta, schmei\u00df Stulle runta \u2013!\u00ab", "tokens": ["\u00bb", "mut\u00b7ta", ",", "schmei\u00df", "Stul\u00b7le", "run\u00b7ta", "\u2013", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "FM.la", "$,", "FM.la", "FM.la", "FM.la", "$(", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Leierkastenmelodien . . .", "tokens": ["Lei\u00b7er\u00b7kas\u00b7ten\u00b7me\u00b7lo\u00b7di\u00b7en", ".", ".", "."], "token_info": ["word", "punct", "punct", "punct"], "pos": ["NE", "$.", "$.", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Menschen in Berlin.", "tokens": ["Men\u00b7schen", "in", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.8": {"line.1": {"text": "Int Alter beinah ein Schenie \u2013", "tokens": ["Int", "Al\u00b7ter", "bei\u00b7nah", "ein", "Sche\u00b7nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dein Bleistift; na, von wejn . . . !", "tokens": ["Dein", "Blei\u00b7stift", ";", "na", ",", "von", "wejn", ".", ".", ".", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["PPOSAT", "NN", "$.", "ITJ", "$,", "APPR", "NE", "$.", "$.", "$.", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Janz richtich vastandn ham se dir nie \u2013", "tokens": ["Janz", "rich\u00b7tich", "vas\u00b7tandn", "ham", "se", "dir", "nie", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "PPER", "ADV", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "die lachtn so \u00fcbalejn.", "tokens": ["die", "lachtn", "so", "\u00fc\u00b7ba\u00b7lejn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Die fanden dir riehrend un komisch zujleich.", "tokens": ["Die", "fan\u00b7den", "dir", "ri\u00b7eh\u00b7rend", "un", "ko\u00b7misch", "zu\u00b7jleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "FM", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Im \u00fcbrijen: Hoch det Deutsche Reich!", "tokens": ["Im", "\u00fcb\u00b7ri\u00b7jen", ":", "Hoch", "det", "Deut\u00b7sche", "Reich", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "$.", "ADJD", "VVFIN", "ADJA", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Malen kannste.", "tokens": ["Ma\u00b7len", "kanns\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Zeichnen kannste.", "tokens": ["Zeich\u00b7nen", "kanns\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVFIN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.9": {"text": "Witze machen sollste.", "tokens": ["Wit\u00b7ze", "ma\u00b7chen", "solls\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.10": {"text": "Aba Ernst machen d\u00fcrfste nich.", "tokens": ["A\u00b7ba", "Ernst", "ma\u00b7chen", "d\u00fcrfs\u00b7te", "nich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVINF", "VMFIN", "PTKNEG", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "Du kennst den janzen Kleista \u2013", "tokens": ["Du", "kennst", "den", "jan\u00b7zen", "Kleis\u00b7ta", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NE", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "den ihr Schicksal: Stirb oda fri\u00df!", "tokens": ["den", "ihr", "Schick\u00b7sal", ":", "Stirb", "o\u00b7da", "fri\u00df", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "$.", "FM.la", "FM.la", "FM.la", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.13": {"text": "Du wahst ein jro\u00dfa Meista.", "tokens": ["Du", "wahst", "ein", "jro\u00b7\u00dfa", "Meis\u00b7ta", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "FM", "FM", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Du hast jesacht, wies is.", "tokens": ["Du", "hast", "je\u00b7sacht", ",", "wies", "is", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "VVFIN", "FM", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}