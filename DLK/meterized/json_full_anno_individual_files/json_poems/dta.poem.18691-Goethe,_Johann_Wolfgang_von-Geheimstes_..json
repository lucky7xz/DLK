{"dta.poem.18691": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang von", "birth": "N.A.", "death": "N.A."}, "title": "Geheimstes .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1819", "urn": "urn:nbn:de:kobv:b4-200905191692", "language": ["de:0.99"], "booktitle": "Goethe, Johann Wolfgang von: West-\u00f6stlicher Divan. Stuttgart, 1819."}, "poem": {"stanza.1": {"line.1": {"text": "\u201ewir sind emsig nachzusp\u00fcren,", "tokens": ["\u201e", "wir", "sind", "em\u00b7sig", "nach\u00b7zu\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADJD", "VVIZU", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wir, die Anecdotenj\u00e4ger,", "tokens": ["Wir", ",", "die", "A\u00b7nec\u00b7do\u00b7ten\u00b7j\u00e4\u00b7ger", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer dein Liebchen sey und ob du", "tokens": ["Wer", "dein", "Lieb\u00b7chen", "sey", "und", "ob", "du"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "PPOSAT", "NN", "VAFIN", "KON", "KOUS", "PPER"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht auch habest viele Schw\u00e4ger.", "tokens": ["Nicht", "auch", "ha\u00b7best", "vie\u00b7le", "Schw\u00e4\u00b7ger", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Denn dass du verliebt bist sehn wir,", "tokens": ["Denn", "dass", "du", "ver\u00b7liebt", "bist", "sehn", "wir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVPP", "VAFIN", "VVFIN", "PPER", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "M\u00f6gen dir es gerne g\u00f6nnen;", "tokens": ["M\u00f6\u00b7gen", "dir", "es", "ger\u00b7ne", "g\u00f6n\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch dass Liebchen so dich liebe", "tokens": ["Doch", "dass", "Lieb\u00b7chen", "so", "dich", "lie\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "NN", "ADV", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Werden wir nicht glauben k\u00f6nnen.\u201c", "tokens": ["Wer\u00b7den", "wir", "nicht", "glau\u00b7ben", "k\u00f6n\u00b7nen", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "VVINF", "VMINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Ungehindert, liebe Herren,", "tokens": ["Un\u00b7ge\u00b7hin\u00b7dert", ",", "lie\u00b7be", "Her\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sucht sie auf, nur h\u00f6rt das Eine:", "tokens": ["Sucht", "sie", "auf", ",", "nur", "h\u00f6rt", "das", "Ei\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ihr erschrecket wenn sie dasteht,", "tokens": ["Ihr", "er\u00b7schre\u00b7cket", "wenn", "sie", "das\u00b7teht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Ist sie fort, ihr koost dem Scheine.", "tokens": ["Ist", "sie", "fort", ",", "ihr", "ko\u00b7ost", "dem", "Schei\u00b7ne", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Wisst ihr wie ", "tokens": ["Wisst", "ihr", "wie"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPER", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Sich auf ", "tokens": ["Sich", "auf"], "token_info": ["word", "word"], "pos": ["PRF", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.3": {"text": "Niemand haltet ihr f\u00fcr th\u00f6rig", "tokens": ["Nie\u00b7mand", "hal\u00b7tet", "ihr", "f\u00fcr", "th\u00f6\u00b7rig"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "APPR", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Der in seinem Sinne handelt.", "tokens": ["Der", "in", "sei\u00b7nem", "Sin\u00b7ne", "han\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Wenn vor deines Kaysers Throne,", "tokens": ["Wenn", "vor", "dei\u00b7nes", "Kay\u00b7sers", "Thro\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Oder vor der Vielgeliebten", "tokens": ["O\u00b7der", "vor", "der", "Viel\u00b7ge\u00b7lieb\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Je dein Name wird gesprochen", "tokens": ["Je", "dein", "Na\u00b7me", "wird", "ge\u00b7spro\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN", "VAFIN", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Sey es dir zu h\u00f6chstem Lohne.", "tokens": ["Sey", "es", "dir", "zu", "h\u00f6chs\u00b7tem", "Loh\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Darum war\u2019s der h\u00f6chste Jammer", "tokens": ["Da\u00b7rum", "wa\u00b7r's", "der", "h\u00f6chs\u00b7te", "Jam\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Als einst ", "tokens": ["Als", "einst"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.3": {"text": "Dass vor ", "tokens": ["Dass", "vor"], "token_info": ["word", "word"], "pos": ["KOUS", "APPR"], "meter": "-+", "measure": "iambic.single"}, "line.4": {"text": "Man forthin nicht nennen sollte.", "tokens": ["Man", "for\u00b7thin", "nicht", "nen\u00b7nen", "soll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "ADV", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}