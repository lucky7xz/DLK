{"textgrid.poem.53968": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "Start", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "m\u00e4 \u2013! b\u00e4 \u2013!", "tokens": ["m\u00e4", "\u2013", "!", "b\u00e4", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["FM.la", "$(", "$.", "XY", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Dann h\u00e4ngt dir vorne ein Bauch von Schmeer", "tokens": ["Dann", "h\u00e4ngt", "dir", "vor\u00b7ne", "ein", "Bauch", "von", "Schmeer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und Briefmarken sammelst du nebenher,", "tokens": ["und", "Brief\u00b7mar\u00b7ken", "sam\u00b7melst", "du", "ne\u00b7ben\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und du liebst die Autorit\u00e4t und das Heer \u2013", "tokens": ["und", "du", "liebst", "die", "Au\u00b7to\u00b7ri\u00b7t\u00e4t", "und", "das", "Heer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "In der R\u00f6hre stehn Kl\u00f6\u00dfe,", "tokens": ["In", "der", "R\u00f6h\u00b7re", "stehn", "Kl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "du siehst sie blo\u00df nicht! \u2013", "tokens": ["du", "siehst", "sie", "blo\u00df", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.2": {"line.1": {"text": "m\u00e4 \u2013! b\u00e4 \u2013!", "tokens": ["m\u00e4", "\u2013", "!", "b\u00e4", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["FM.la", "$(", "$.", "XY", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Untenrum dick und obenrum kahl,", "tokens": ["Un\u00b7ten\u00b7rum", "dick", "und", "o\u00b7ben\u00b7rum", "kahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "mit dem Maulwerk egalweg sozial,", "tokens": ["mit", "dem", "Maul\u00b7werk", "e\u00b7gal\u00b7weg", "so\u00b7zi\u00b7al", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "und im Herzen nat\u00fcrlich deutsch-national \u2013", "tokens": ["und", "im", "Her\u00b7zen", "na\u00b7t\u00fcr\u00b7lich", "deut\u00b7schna\u00b7ti\u00b7o\u00b7nal", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "ADJD", "$("], "meter": "--+---+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Kille-kille!", "tokens": ["Kil\u00b7le\u00b7kil\u00b7le", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Einer, der die Gesetzb\u00fccher kennt,", "tokens": ["Ei\u00b7ner", ",", "der", "die", "Ge\u00b7setz\u00b7b\u00fc\u00b7cher", "kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "einer, der in den Sitzungen pennt,", "tokens": ["ei\u00b7ner", ",", "der", "in", "den", "Sit\u00b7zun\u00b7gen", "pennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "und die Fresse zerhackt wie ein Korpsstudent \u2013", "tokens": ["und", "die", "Fres\u00b7se", "zer\u00b7hackt", "wie", "ein", "Korps\u00b7stu\u00b7dent", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "KOKOM", "ART", "NN", "$("], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "kille . . . kille . . . kille . . . !", "tokens": ["kil\u00b7le", ".", ".", ".", "kil\u00b7le", ".", ".", ".", "kil\u00b7le", ".", ".", ".", "!"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "$.", "$.", "$.", "VVFIN", "$.", "$.", "$.", "VVFIN", "$.", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "hopla-hopp!", "tokens": ["ho\u00b7pla\u00b7hopp", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Du liebst, wenn er zahlt. Und l\u00e4chelst dazu.", "tokens": ["Du", "liebst", ",", "wenn", "er", "zahlt", ".", "Und", "l\u00e4\u00b7chelst", "da\u00b7zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$.", "KON", "VVFIN", "PAV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und gehts mal schief, verlier nicht die Ruh.", "tokens": ["Und", "gehts", "mal", "schief", ",", "ver\u00b7lier", "nicht", "die", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVFIN", "$,", "ADV", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Du hast ja Geld \u2013 ", "tokens": ["Du", "hast", "ja", "Geld", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "hopla-hopp!", "tokens": ["ho\u00b7pla\u00b7hopp", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+--", "measure": "dactylic.init"}}, "stanza.5": {"line.1": {"text": "na, nu weine man nicht \u2013!", "tokens": ["na", ",", "nu", "wei\u00b7ne", "man", "nicht", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$(", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Zun\u00e4chst gehst du klein und bescheiden einher;", "tokens": ["Zu\u00b7n\u00e4chst", "gehst", "du", "klein", "und", "be\u00b7schei\u00b7den", "ein\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "doch hast du erst den feinen Verkehr,", "tokens": ["doch", "hast", "du", "erst", "den", "fei\u00b7nen", "Ver\u00b7kehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "dann kennst du deine Genossen nicht mehr \u2013", "tokens": ["dann", "kennst", "du", "dei\u00b7ne", "Ge\u00b7nos\u00b7sen", "nicht", "mehr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "in der R\u00f6hre stehn Kl\u00f6\u00dfe,", "tokens": ["in", "der", "R\u00f6h\u00b7re", "stehn", "Kl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "du siehst sie blo\u00df nicht \u2013!", "tokens": ["du", "siehst", "sie", "blo\u00df", "nicht", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$(", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Su \u2013 su \u2013", "tokens": ["Su", "\u2013", "su", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$("], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Na, und du \u2013?", "tokens": ["Na", ",", "und", "du", "\u2013", "?"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "KON", "PPER", "$(", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.6": {"line.1": {"text": "ein anst\u00e4ndiger Proletarier werden,", "tokens": ["ein", "an\u00b7st\u00e4n\u00b7di\u00b7ger", "Pro\u00b7le\u00b7ta\u00b7rier", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "der ein Herz hat f\u00fcr seiner Klasse Beschwerden \u2013!", "tokens": ["der", "ein", "Herz", "hat", "f\u00fcr", "sei\u00b7ner", "Klas\u00b7se", "Be\u00b7schwer\u00b7den", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "NN", "$(", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ein ganzer Mann.", "tokens": ["Ein", "gan\u00b7zer", "Mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Feste, geh ran \u2013!", "tokens": ["Fes\u00b7te", ",", "geh", "ran", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKVZ", "$(", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Das wirst du lernen, bist du einmal gro\u00df \u2013:", "tokens": ["Das", "wirst", "du", "ler\u00b7nen", ",", "bist", "du", "ein\u00b7mal", "gro\u00df", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVINF", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "m\u00e4 \u2013! b\u00e4 \u2013!", "tokens": ["m\u00e4", "\u2013", "!", "b\u00e4", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["FM.la", "$(", "$.", "XY", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Dann h\u00e4ngt dir vorne ein Bauch von Schmeer", "tokens": ["Dann", "h\u00e4ngt", "dir", "vor\u00b7ne", "ein", "Bauch", "von", "Schmeer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "APPR", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "und Briefmarken sammelst du nebenher,", "tokens": ["und", "Brief\u00b7mar\u00b7ken", "sam\u00b7melst", "du", "ne\u00b7ben\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-++--+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "und du liebst die Autorit\u00e4t und das Heer \u2013", "tokens": ["und", "du", "liebst", "die", "Au\u00b7to\u00b7ri\u00b7t\u00e4t", "und", "das", "Heer", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "--+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.7": {"text": "In der R\u00f6hre stehn Kl\u00f6\u00dfe,", "tokens": ["In", "der", "R\u00f6h\u00b7re", "stehn", "Kl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.8": {"text": "du siehst sie blo\u00df nicht! \u2013", "tokens": ["du", "siehst", "sie", "blo\u00df", "nicht", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$.", "$("], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.8": {"line.1": {"text": "m\u00e4 \u2013! b\u00e4 \u2013!", "tokens": ["m\u00e4", "\u2013", "!", "b\u00e4", "\u2013", "!"], "token_info": ["word", "punct", "punct", "word", "punct", "punct"], "pos": ["FM.la", "$(", "$.", "XY", "$(", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.2": {"text": "Untenrum dick und obenrum kahl,", "tokens": ["Un\u00b7ten\u00b7rum", "dick", "und", "o\u00b7ben\u00b7rum", "kahl", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADV", "ADJD", "$,"], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "mit dem Maulwerk egalweg sozial,", "tokens": ["mit", "dem", "Maul\u00b7werk", "e\u00b7gal\u00b7weg", "so\u00b7zi\u00b7al", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "--+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "und im Herzen nat\u00fcrlich deutsch-national \u2013", "tokens": ["und", "im", "Her\u00b7zen", "na\u00b7t\u00fcr\u00b7lich", "deut\u00b7schna\u00b7ti\u00b7o\u00b7nal", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADV", "ADJD", "$("], "meter": "--+---+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Na, nu weine man nicht!", "tokens": ["Na", ",", "nu", "wei\u00b7ne", "man", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Kille-kille!", "tokens": ["Kil\u00b7le\u00b7kil\u00b7le", "!"], "token_info": ["word", "punct"], "pos": ["NE", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Einer, der die Gesetzb\u00fccher kennt,", "tokens": ["Ei\u00b7ner", ",", "der", "die", "Ge\u00b7setz\u00b7b\u00fc\u00b7cher", "kennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "einer, der in den Sitzungen pennt,", "tokens": ["ei\u00b7ner", ",", "der", "in", "den", "Sit\u00b7zun\u00b7gen", "pennt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+--+--+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "und die Fresse zerhackt wie ein Korpsstudent \u2013", "tokens": ["und", "die", "Fres\u00b7se", "zer\u00b7hackt", "wie", "ein", "Korps\u00b7stu\u00b7dent", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "KOKOM", "ART", "NN", "$("], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "kille . . . kille . . . kille . . . !", "tokens": ["kil\u00b7le", ".", ".", ".", "kil\u00b7le", ".", ".", ".", "kil\u00b7le", ".", ".", ".", "!"], "token_info": ["word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "word", "punct", "punct", "punct", "punct"], "pos": ["VVFIN", "$.", "$.", "$.", "VVFIN", "$.", "$.", "$.", "VVFIN", "$.", "$.", "$.", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "hopla-hopp!", "tokens": ["ho\u00b7pla\u00b7hopp", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Du liebst, wenn er zahlt. Und l\u00e4chelst dazu.", "tokens": ["Du", "liebst", ",", "wenn", "er", "zahlt", ".", "Und", "l\u00e4\u00b7chelst", "da\u00b7zu", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$.", "KON", "VVFIN", "PAV", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und gehts mal schief, verlier nicht die Ruh.", "tokens": ["Und", "gehts", "mal", "schief", ",", "ver\u00b7lier", "nicht", "die", "Ruh", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "VVFIN", "$,", "ADV", "PTKNEG", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Du hast ja Geld \u2013 ", "tokens": ["Du", "hast", "ja", "Geld", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "NN", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "hopla-hopp!", "tokens": ["ho\u00b7pla\u00b7hopp", "!"], "token_info": ["word", "punct"], "pos": ["ADJD", "$."], "meter": "+--", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "na, nu weine man nicht \u2013!", "tokens": ["na", ",", "nu", "wei\u00b7ne", "man", "nicht", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "ADV", "VVFIN", "PIS", "PTKNEG", "$(", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Zun\u00e4chst gehst du klein und bescheiden einher;", "tokens": ["Zu\u00b7n\u00e4chst", "gehst", "du", "klein", "und", "be\u00b7schei\u00b7den", "ein\u00b7her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.3": {"text": "doch hast du erst den feinen Verkehr,", "tokens": ["doch", "hast", "du", "erst", "den", "fei\u00b7nen", "Ver\u00b7kehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "dann kennst du deine Genossen nicht mehr \u2013", "tokens": ["dann", "kennst", "du", "dei\u00b7ne", "Ge\u00b7nos\u00b7sen", "nicht", "mehr", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "PTKNEG", "ADV", "$("], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "in der R\u00f6hre stehn Kl\u00f6\u00dfe,", "tokens": ["in", "der", "R\u00f6h\u00b7re", "stehn", "Kl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "du siehst sie blo\u00df nicht \u2013!", "tokens": ["du", "siehst", "sie", "blo\u00df", "nicht", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$(", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Su \u2013 su \u2013", "tokens": ["Su", "\u2013", "su", "\u2013"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$(", "NE", "$("], "meter": "-+", "measure": "iambic.single"}, "line.8": {"text": "Na, und du \u2013?", "tokens": ["Na", ",", "und", "du", "\u2013", "?"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["ITJ", "$,", "KON", "PPER", "$(", "$."], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.12": {"line.1": {"text": "ein anst\u00e4ndiger Proletarier werden,", "tokens": ["ein", "an\u00b7st\u00e4n\u00b7di\u00b7ger", "Pro\u00b7le\u00b7ta\u00b7rier", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAINF", "$,"], "meter": "--+--+-+-+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "der ein Herz hat f\u00fcr seiner Klasse Beschwerden \u2013!", "tokens": ["der", "ein", "Herz", "hat", "f\u00fcr", "sei\u00b7ner", "Klas\u00b7se", "Be\u00b7schwer\u00b7den", "\u2013", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "NN", "$(", "$."], "meter": "--+--+-+--+-", "measure": "anapaest.di.plus"}, "line.3": {"text": "Ein ganzer Mann.", "tokens": ["Ein", "gan\u00b7zer", "Mann", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Feste, geh ran \u2013!", "tokens": ["Fes\u00b7te", ",", "geh", "ran", "\u2013", "!"], "token_info": ["word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVFIN", "PTKVZ", "$(", "$."], "meter": "+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Das wirst du lernen, bist du einmal gro\u00df \u2013:", "tokens": ["Das", "wirst", "du", "ler\u00b7nen", ",", "bist", "du", "ein\u00b7mal", "gro\u00df", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "VVINF", "$,", "VAFIN", "PPER", "ADV", "ADJD", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}