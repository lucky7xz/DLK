{"dta.poem.5350": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Erinnerung.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Sind denn vielleicht nicht auf der Welt", "tokens": ["Sind", "denn", "viel\u00b7leicht", "nicht", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "PTKNEG", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Wunder, die man sieht, uns w\u00fcrcklich vorgestellt?", "tokens": ["Die", "Wun\u00b7der", ",", "die", "man", "sieht", ",", "uns", "w\u00fcrck\u00b7lich", "vor\u00b7ge\u00b7stellt", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VVFIN", "$,", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Beb\u00fcschte H\u00fcgel? gr\u00fcne Felder?", "tokens": ["Be\u00b7b\u00fcschte", "H\u00fc\u00b7gel", "?", "gr\u00fc\u00b7ne", "Fel\u00b7der", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Bebl\u00fchmte Wiesen? k\u00fchle W\u00e4lder?", "tokens": ["Be\u00b7bl\u00fchm\u00b7te", "Wie\u00b7sen", "?", "k\u00fch\u00b7le", "W\u00e4l\u00b7der", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Gesunde Kr\u00e4uter? s\u00fcsse Fr\u00fcchte?", "tokens": ["Ge\u00b7sun\u00b7de", "Kr\u00e4u\u00b7ter", "?", "s\u00fcs\u00b7se", "Fr\u00fcch\u00b7te", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den n\u00e4hrenden Geschmack vergn\u00fcgende Gerichte?", "tokens": ["Den", "n\u00e4h\u00b7ren\u00b7den", "Ge\u00b7schmack", "ver\u00b7gn\u00fc\u00b7gen\u00b7de", "Ge\u00b7rich\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Christallen-gleiche reine B\u00e4che?", "tokens": ["Chris\u00b7tal\u00b7len\u00b7glei\u00b7che", "rei\u00b7ne", "B\u00e4\u00b7che", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "So mancher Berg? so manche Fl\u00e4che?", "tokens": ["So", "man\u00b7cher", "Berg", "?", "so", "man\u00b7che", "Fl\u00e4\u00b7che", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$.", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Es sind vielleicht, in s\u00fcssen Ch\u00f6ren,", "tokens": ["Es", "sind", "viel\u00b7leicht", ",", "in", "s\u00fcs\u00b7sen", "Ch\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Die bunten V\u00f6gel nicht zu h\u00f6ren;", "tokens": ["Die", "bun\u00b7ten", "V\u00f6\u00b7gel", "nicht", "zu", "h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Ist es vielleicht nicht wahr, da\u00df Blumen uns erqvicken?", "tokens": ["Ist", "es", "viel\u00b7leicht", "nicht", "wahr", ",", "da\u00df", "Blu\u00b7men", "uns", "er\u00b7qvi\u00b7cken", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$,", "KOUS", "NN", "PPER", "VVINF", "$."], "meter": "---+-+-+-+-+-", "measure": "unknown.measure.penta"}, "line.12": {"text": "Da\u00df sie, f\u00fcr uns, die Erde schm\u00fccken?", "tokens": ["Da\u00df", "sie", ",", "f\u00fcr", "uns", ",", "die", "Er\u00b7de", "schm\u00fc\u00b7cken", "?"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPER", "$,", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Sieht man, nebst tausend Seltenheiten,", "tokens": ["Sieht", "man", ",", "nebst", "tau\u00b7send", "Sel\u00b7ten\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und ungezehlten Herrlichkeiten,", "tokens": ["Und", "un\u00b7ge\u00b7zehl\u00b7ten", "Herr\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Das all-erfreu\u2019nde Sonnen-Licht", "tokens": ["Das", "all\u00b7er\u00b7freu'n\u00b7de", "Son\u00b7nen\u00b7Licht"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Vielleicht mit unsern Augen nicht?", "tokens": ["Viel\u00b7leicht", "mit", "un\u00b7sern", "Au\u00b7gen", "nicht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Ist etwann alles die\u00df nicht w\u00fcrcklich da?", "tokens": ["Ist", "et\u00b7wann", "al\u00b7les", "die\u00df", "nicht", "w\u00fcrck\u00b7lich", "da", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "PDS", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "O ja!", "tokens": ["O", "ja", "!"], "token_info": ["word", "word", "punct"], "pos": ["ITJ", "ITJ", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.19": {"text": "Ist alles denn nun w\u00fcrcklich da; wie man", "tokens": ["Ist", "al\u00b7les", "denn", "nun", "w\u00fcrck\u00b7lich", "da", ";", "wie", "man"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "ADJD", "PTKVZ", "$.", "PWAV", "PIS"], "meter": "-+-+-+-++-", "measure": "unknown.measure.penta"}, "line.20": {"text": "Unm\u00f6glich leugnen kann;", "tokens": ["Un\u00b7m\u00f6g\u00b7lich", "leug\u00b7nen", "kann", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Warum denn sieht man es nicht an?", "tokens": ["Wa\u00b7rum", "denn", "sieht", "man", "es", "nicht", "an", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VVFIN", "PIS", "PPER", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Warum will man an aller Pracht,", "tokens": ["Wa\u00b7rum", "will", "man", "an", "al\u00b7ler", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PIS", "APPR", "PIAT", "NN", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.23": {"text": "Warum will man an allen Sch\u00e4tzen", "tokens": ["Wa\u00b7rum", "will", "man", "an", "al\u00b7len", "Sch\u00e4t\u00b7zen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VMFIN", "PIS", "APPR", "PIAT", "NN"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "Sich nicht ergetzen;", "tokens": ["Sich", "nicht", "er\u00b7get\u00b7zen", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.25": {"text": "Noch loben den, der sie gemacht?", "tokens": ["Noch", "lo\u00b7ben", "den", ",", "der", "sie", "ge\u00b7macht", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "Es scheint wir wollen, blos um GOtt nur nicht zu ehren,", "tokens": ["Es", "scheint", "wir", "wol\u00b7len", ",", "blos", "um", "Gott", "nur", "nicht", "zu", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VMFIN", "$,", "ADV", "APPR", "NN", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Nicht schmecken, riechen, sehn und h\u00f6ren.", "tokens": ["Nicht", "schme\u00b7cken", ",", "rie\u00b7chen", ",", "sehn", "und", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "$,", "VVFIN", "$,", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Wir sehn ja \u00fcberall die Spur", "tokens": ["Wir", "sehn", "ja", "\u00fc\u00b7be\u00b7rall", "die", "Spur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Von einer g\u00fctigen Natur,", "tokens": ["Von", "ei\u00b7ner", "g\u00fc\u00b7ti\u00b7gen", "Na\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}