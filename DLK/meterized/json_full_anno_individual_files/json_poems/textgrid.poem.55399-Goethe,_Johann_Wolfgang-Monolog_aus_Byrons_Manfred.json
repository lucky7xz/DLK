{"textgrid.poem.55399": {"metadata": {"author": {"name": "Goethe, Johann Wolfgang", "birth": "N.A.", "death": "N.A."}, "title": "Monolog aus Byrons Manfred", "genre": "verse", "period": "N.A.", "pub_year": 1819, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Zeit, des Schreckens Narren sind wir! Tage,", "tokens": ["Der", "Zeit", ",", "des", "Schre\u00b7ckens", "Nar\u00b7ren", "sind", "wir", "!", "Ta\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "VAFIN", "PPER", "$.", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bestehlend stehlen sie sich weg. Wir leben", "tokens": ["Be\u00b7steh\u00b7lend", "steh\u00b7len", "sie", "sich", "weg", ".", "Wir", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "VVFIN", "PPER", "PRF", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In Lebens \u00dcberdru\u00df, in Scheu des Todes.", "tokens": ["In", "Le\u00b7bens", "\u00dc\u00b7berd\u00b7ru\u00df", ",", "in", "Scheu", "des", "To\u00b7des", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In all den Tagen der verw\u00fcnschten Posse \u2013", "tokens": ["In", "all", "den", "Ta\u00b7gen", "der", "ver\u00b7w\u00fcnschten", "Pos\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Lebendige Last auf widerstrebendem Herzen,", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Last", "auf", "wi\u00b7der\u00b7stre\u00b7ben\u00b7dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+---+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "In Sorgen stockt es, heftig schl\u00e4gt's in Pein,", "tokens": ["In", "Sor\u00b7gen", "stockt", "es", ",", "hef\u00b7tig", "schl\u00e4gt's", "in", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "ADJD", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Freud ein End ist Todeskampf und Ohnmacht \u2013,", "tokens": ["Der", "Freud", "ein", "End", "ist", "To\u00b7des\u00b7kampf", "und", "Ohn\u00b7macht", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "NN", "KON", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In all den Tagen, den vergangnen, k\u00fcnftigen \u2013", "tokens": ["In", "all", "den", "Ta\u00b7gen", ",", "den", "ver\u00b7gang\u00b7nen", ",", "k\u00fcnf\u00b7ti\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im Leben ist nichts Gegenwart \u2013 du z\u00e4hlst", "tokens": ["Im", "Le\u00b7ben", "ist", "nichts", "Ge\u00b7gen\u00b7wart", "\u2013", "du", "z\u00e4hlst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PIS", "NN", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wie wenig: weniger als wenig, wo die Seele", "tokens": ["Wie", "we\u00b7nig", ":", "we\u00b7ni\u00b7ger", "als", "we\u00b7nig", ",", "wo", "die", "See\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "$.", "PIS", "KOKOM", "PIS", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nicht nach dem Tod verlangt und doch zur\u00fcck", "tokens": ["Nicht", "nach", "dem", "Tod", "ver\u00b7langt", "und", "doch", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVPP", "KON", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wie vor dem Winterstrome schreckt. Das Fr\u00f6stlen", "tokens": ["Wie", "vor", "dem", "Win\u00b7ter\u00b7stro\u00b7me", "schreckt", ".", "Das", "Fr\u00f6st\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "W\u00e4r nur ein Augenblick. \u2013 Ich hab ein Mittel", "tokens": ["W\u00e4r", "nur", "ein", "Au\u00b7gen\u00b7blick", ".", "\u2013", "Ich", "hab", "ein", "Mit\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "In meiner Wissenskraft: die Toten ruf ich", "tokens": ["In", "mei\u00b7ner", "Wis\u00b7sen\u00b7skraft", ":", "die", "To\u00b7ten", "ruf", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und frage sie: Was ist denn, das wir f\u00fcrchten?", "tokens": ["Und", "fra\u00b7ge", "sie", ":", "Was", "ist", "denn", ",", "das", "wir", "f\u00fcrch\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PWS", "VAFIN", "ADV", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Der Antwort ernsteste ist doch das Grab.", "tokens": ["Der", "Ant\u00b7wort", "erns\u00b7tes\u00b7te", "ist", "doch", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und das ist nichts, antworten sie mir nicht \u2013", "tokens": ["Und", "das", "ist", "nichts", ",", "ant\u00b7wor\u00b7ten", "sie", "mir", "nicht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PIS", "$,", "VVFIN", "PPER", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Antwortete begrabner Priester Gottes", "tokens": ["Ant\u00b7wor\u00b7te\u00b7te", "be\u00b7grab\u00b7ner", "Pries\u00b7ter", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "NN"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Dem Weib zu Endor! Spartas K\u00f6nig zog", "tokens": ["Dem", "Weib", "zu", "En\u00b7dor", "!", "Spar\u00b7tas", "K\u00f6\u00b7nig", "zog"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "$.", "NE", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus griech'scher Jungfrau nie entschlafnem Geist", "tokens": ["Aus", "griech'\u00b7scher", "Jung\u00b7frau", "nie", "ent\u00b7schlaf\u00b7nem", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Antwort und Schicksal. Das Geliebteste", "tokens": ["Ant\u00b7wort", "und", "Schick\u00b7sal", ".", "Das", "Ge\u00b7lieb\u00b7tes\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "ART", "NN"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.5": {"text": "Hatt er gemordet, wu\u00dfte nicht, wen er traf;", "tokens": ["Hatt", "er", "ge\u00b7mor\u00b7det", ",", "wu\u00df\u00b7te", "nicht", ",", "wen", "er", "traf", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Starb unges\u00fchnt. Wenn er auch schon zu H\u00fclfe", "tokens": ["Starb", "un\u00b7ge\u00b7s\u00fchnt", ".", "Wenn", "er", "auch", "schon", "zu", "H\u00fcl\u00b7fe"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$.", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den milden Zeus berief, Phigaliens", "tokens": ["Den", "mil\u00b7den", "Zeus", "be\u00b7rief", ",", "Phi\u00b7ga\u00b7li\u00b7ens"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "$,", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Arkadische Beschw\u00f6rer aufrief, zu gewinnen", "tokens": ["Ar\u00b7ka\u00b7di\u00b7sche", "Be\u00b7schw\u00f6\u00b7rer", "auf\u00b7rief", ",", "zu", "ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vom aufgebrachten Schatten sein Verzeihen,", "tokens": ["Vom", "auf\u00b7ge\u00b7brach\u00b7ten", "Schat\u00b7ten", "sein", "Ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Auch eine Grenze nur des R\u00e4chens. Die versetzte", "tokens": ["Auch", "ei\u00b7ne", "Gren\u00b7ze", "nur", "des", "R\u00e4\u00b7chens", ".", "Die", "ver\u00b7setz\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "ART", "NN", "$.", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit zweifelhaftem Wortsinn; doch erf\u00fcllt ward's.", "tokens": ["Mit", "zwei\u00b7fel\u00b7haf\u00b7tem", "Wort\u00b7sinn", ";", "doch", "er\u00b7f\u00fcllt", "ward'", "s."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["APPR", "ADJA", "NN", "$.", "ADV", "VVPP", "VAFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und h\u00e4tt ich nie gelebt! das, was ich liebe,", "tokens": ["Und", "h\u00e4tt", "ich", "nie", "ge\u00b7lebt", "!", "das", ",", "was", "ich", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00e4re noch lebendig; h\u00e4tt ich nie geliebt!", "tokens": ["W\u00e4\u00b7re", "noch", "le\u00b7ben\u00b7dig", ";", "h\u00e4tt", "ich", "nie", "ge\u00b7liebt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$.", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Das, was ich liebe, w\u00e4r noch immer sch\u00f6n", "tokens": ["Das", ",", "was", "ich", "lie\u00b7be", ",", "w\u00e4r", "noch", "im\u00b7mer", "sch\u00f6n"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und gl\u00fccklich, gl\u00fcckverspendend. Und was aber,", "tokens": ["Und", "gl\u00fcck\u00b7lich", ",", "gl\u00fcck\u00b7ver\u00b7spen\u00b7dend", ".", "Und", "was", "a\u00b7ber", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADJD", "$.", "KON", "PWS", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was ist sie jetzt? F\u00fcr meine S\u00fcnden b\u00fc\u00dfte sie \u2013", "tokens": ["Was", "ist", "sie", "jetzt", "?", "F\u00fcr", "mei\u00b7ne", "S\u00fcn\u00b7den", "b\u00fc\u00df\u00b7te", "sie", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$.", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Wesen? Denk es nicht \u2013 vielleicht ein Nichts.", "tokens": ["Ein", "We\u00b7sen", "?", "Denk", "es", "nicht", "\u2013", "viel\u00b7leicht", "ein", "Nichts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVIMP", "PPER", "PTKNEG", "$(", "ADV", "ART", "PIS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In wenig Stunden frag ich nicht umsonst,", "tokens": ["In", "we\u00b7nig", "Stun\u00b7den", "frag", "ich", "nicht", "um\u00b7sonst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "In dieser Stunde f\u00fcrcht ich, wie ich trotze,", "tokens": ["In", "die\u00b7ser", "Stun\u00b7de", "f\u00fcrcht", "ich", ",", "wie", "ich", "trot\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Bis diese Stunde schreckte mich kein Schauen", "tokens": ["Bis", "die\u00b7se", "Stun\u00b7de", "schreck\u00b7te", "mich", "kein", "Schau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Der Geister, guter, b\u00f6ser. Zittr' ich nun?", "tokens": ["Der", "Geis\u00b7ter", ",", "gu\u00b7ter", ",", "b\u00f6\u00b7ser", ".", "Zit\u00b7tr'", "ich", "nun", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "$,", "ADJD", "$.", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.11": {"text": "Und f\u00fchl am Herzen fremden, kalten Tau!", "tokens": ["Und", "f\u00fchl", "am", "Her\u00b7zen", "frem\u00b7den", ",", "kal\u00b7ten", "Tau", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Doch kann ich tun, was mich im Tiefsten widert,", "tokens": ["Doch", "kann", "ich", "tun", ",", "was", "mich", "im", "Tiefs\u00b7ten", "wi\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der Erde Schrecken ruf ich auf. \u2013 Eis nachtet!", "tokens": ["Der", "Er\u00b7de", "Schre\u00b7cken", "ruf", "ich", "auf", ".", "\u2013", "Eis", "nach\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "NN", "VVPP", "$."], "meter": "-+-+-+-+++-", "measure": "unknown.measure.hexa"}}, "stanza.4": {"line.1": {"text": "Der Zeit, des Schreckens Narren sind wir! Tage,", "tokens": ["Der", "Zeit", ",", "des", "Schre\u00b7ckens", "Nar\u00b7ren", "sind", "wir", "!", "Ta\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NN", "VAFIN", "PPER", "$.", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Bestehlend stehlen sie sich weg. Wir leben", "tokens": ["Be\u00b7steh\u00b7lend", "steh\u00b7len", "sie", "sich", "weg", ".", "Wir", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVPP", "VVFIN", "PPER", "PRF", "PTKVZ", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In Lebens \u00dcberdru\u00df, in Scheu des Todes.", "tokens": ["In", "Le\u00b7bens", "\u00dc\u00b7berd\u00b7ru\u00df", ",", "in", "Scheu", "des", "To\u00b7des", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$,", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In all den Tagen der verw\u00fcnschten Posse \u2013", "tokens": ["In", "all", "den", "Ta\u00b7gen", "der", "ver\u00b7w\u00fcnschten", "Pos\u00b7se", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Lebendige Last auf widerstrebendem Herzen,", "tokens": ["Le\u00b7ben\u00b7di\u00b7ge", "Last", "auf", "wi\u00b7der\u00b7stre\u00b7ben\u00b7dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "+---+-+-+--+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "In Sorgen stockt es, heftig schl\u00e4gt's in Pein,", "tokens": ["In", "Sor\u00b7gen", "stockt", "es", ",", "hef\u00b7tig", "schl\u00e4gt's", "in", "Pein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "$,", "ADJD", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Der Freud ein End ist Todeskampf und Ohnmacht \u2013,", "tokens": ["Der", "Freud", "ein", "End", "ist", "To\u00b7des\u00b7kampf", "und", "Ohn\u00b7macht", "\u2013", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "NN", "KON", "NN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In all den Tagen, den vergangnen, k\u00fcnftigen \u2013", "tokens": ["In", "all", "den", "Ta\u00b7gen", ",", "den", "ver\u00b7gang\u00b7nen", ",", "k\u00fcnf\u00b7ti\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "ART", "ADJA", "$,", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im Leben ist nichts Gegenwart \u2013 du z\u00e4hlst", "tokens": ["Im", "Le\u00b7ben", "ist", "nichts", "Ge\u00b7gen\u00b7wart", "\u2013", "du", "z\u00e4hlst"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "VAFIN", "PIS", "NN", "$(", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wie wenig: weniger als wenig, wo die Seele", "tokens": ["Wie", "we\u00b7nig", ":", "we\u00b7ni\u00b7ger", "als", "we\u00b7nig", ",", "wo", "die", "See\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIS", "$.", "PIS", "KOKOM", "PIS", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nicht nach dem Tod verlangt und doch zur\u00fcck", "tokens": ["Nicht", "nach", "dem", "Tod", "ver\u00b7langt", "und", "doch", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "APPR", "ART", "NN", "VVPP", "KON", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wie vor dem Winterstrome schreckt. Das Fr\u00f6stlen", "tokens": ["Wie", "vor", "dem", "Win\u00b7ter\u00b7stro\u00b7me", "schreckt", ".", "Das", "Fr\u00f6st\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "APPR", "ART", "NN", "VVFIN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "W\u00e4r nur ein Augenblick. \u2013 Ich hab ein Mittel", "tokens": ["W\u00e4r", "nur", "ein", "Au\u00b7gen\u00b7blick", ".", "\u2013", "Ich", "hab", "ein", "Mit\u00b7tel"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "$(", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "In meiner Wissenskraft: die Toten ruf ich", "tokens": ["In", "mei\u00b7ner", "Wis\u00b7sen\u00b7skraft", ":", "die", "To\u00b7ten", "ruf", "ich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$.", "ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und frage sie: Was ist denn, das wir f\u00fcrchten?", "tokens": ["Und", "fra\u00b7ge", "sie", ":", "Was", "ist", "denn", ",", "das", "wir", "f\u00fcrch\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "PWS", "VAFIN", "ADV", "$,", "PRELS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Der Antwort ernsteste ist doch das Grab.", "tokens": ["Der", "Ant\u00b7wort", "erns\u00b7tes\u00b7te", "ist", "doch", "das", "Grab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.17": {"text": "Und das ist nichts, antworten sie mir nicht \u2013", "tokens": ["Und", "das", "ist", "nichts", ",", "ant\u00b7wor\u00b7ten", "sie", "mir", "nicht", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VAFIN", "PIS", "$,", "VVFIN", "PPER", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Antwortete begrabner Priester Gottes", "tokens": ["Ant\u00b7wor\u00b7te\u00b7te", "be\u00b7grab\u00b7ner", "Pries\u00b7ter", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "NN"], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.2": {"text": "Dem Weib zu Endor! Spartas K\u00f6nig zog", "tokens": ["Dem", "Weib", "zu", "En\u00b7dor", "!", "Spar\u00b7tas", "K\u00f6\u00b7nig", "zog"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "NE", "$.", "NE", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aus griech'scher Jungfrau nie entschlafnem Geist", "tokens": ["Aus", "griech'\u00b7scher", "Jung\u00b7frau", "nie", "ent\u00b7schlaf\u00b7nem", "Geist"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Antwort und Schicksal. Das Geliebteste", "tokens": ["Ant\u00b7wort", "und", "Schick\u00b7sal", ".", "Das", "Ge\u00b7lieb\u00b7tes\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "KON", "NN", "$.", "ART", "NN"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.5": {"text": "Hatt er gemordet, wu\u00dfte nicht, wen er traf;", "tokens": ["Hatt", "er", "ge\u00b7mor\u00b7det", ",", "wu\u00df\u00b7te", "nicht", ",", "wen", "er", "traf", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "VVFIN", "PTKNEG", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "Starb unges\u00fchnt. Wenn er auch schon zu H\u00fclfe", "tokens": ["Starb", "un\u00b7ge\u00b7s\u00fchnt", ".", "Wenn", "er", "auch", "schon", "zu", "H\u00fcl\u00b7fe"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADJD", "$.", "KOUS", "PPER", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Den milden Zeus berief, Phigaliens", "tokens": ["Den", "mil\u00b7den", "Zeus", "be\u00b7rief", ",", "Phi\u00b7ga\u00b7li\u00b7ens"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NE", "VVFIN", "$,", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Arkadische Beschw\u00f6rer aufrief, zu gewinnen", "tokens": ["Ar\u00b7ka\u00b7di\u00b7sche", "Be\u00b7schw\u00f6\u00b7rer", "auf\u00b7rief", ",", "zu", "ge\u00b7win\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "VVFIN", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Vom aufgebrachten Schatten sein Verzeihen,", "tokens": ["Vom", "auf\u00b7ge\u00b7brach\u00b7ten", "Schat\u00b7ten", "sein", "Ver\u00b7zei\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Auch eine Grenze nur des R\u00e4chens. Die versetzte", "tokens": ["Auch", "ei\u00b7ne", "Gren\u00b7ze", "nur", "des", "R\u00e4\u00b7chens", ".", "Die", "ver\u00b7setz\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "ART", "NN", "$.", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit zweifelhaftem Wortsinn; doch erf\u00fcllt ward's.", "tokens": ["Mit", "zwei\u00b7fel\u00b7haf\u00b7tem", "Wort\u00b7sinn", ";", "doch", "er\u00b7f\u00fcllt", "ward'", "s."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "abbreviation"], "pos": ["APPR", "ADJA", "NN", "$.", "ADV", "VVPP", "VAFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Und h\u00e4tt ich nie gelebt! das, was ich liebe,", "tokens": ["Und", "h\u00e4tt", "ich", "nie", "ge\u00b7lebt", "!", "das", ",", "was", "ich", "lie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$.", "PDS", "$,", "PWS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "W\u00e4re noch lebendig; h\u00e4tt ich nie geliebt!", "tokens": ["W\u00e4\u00b7re", "noch", "le\u00b7ben\u00b7dig", ";", "h\u00e4tt", "ich", "nie", "ge\u00b7liebt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADJD", "$.", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.3": {"text": "Das, was ich liebe, w\u00e4r noch immer sch\u00f6n", "tokens": ["Das", ",", "was", "ich", "lie\u00b7be", ",", "w\u00e4r", "noch", "im\u00b7mer", "sch\u00f6n"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "$,", "PWS", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und gl\u00fccklich, gl\u00fcckverspendend. Und was aber,", "tokens": ["Und", "gl\u00fcck\u00b7lich", ",", "gl\u00fcck\u00b7ver\u00b7spen\u00b7dend", ".", "Und", "was", "a\u00b7ber", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ADJD", "$.", "KON", "PWS", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Was ist sie jetzt? F\u00fcr meine S\u00fcnden b\u00fc\u00dfte sie \u2013", "tokens": ["Was", "ist", "sie", "jetzt", "?", "F\u00fcr", "mei\u00b7ne", "S\u00fcn\u00b7den", "b\u00fc\u00df\u00b7te", "sie", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$.", "APPR", "PPOSAT", "NN", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ein Wesen? Denk es nicht \u2013 vielleicht ein Nichts.", "tokens": ["Ein", "We\u00b7sen", "?", "Denk", "es", "nicht", "\u2013", "viel\u00b7leicht", "ein", "Nichts", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "VVIMP", "PPER", "PTKNEG", "$(", "ADV", "ART", "PIS", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "In wenig Stunden frag ich nicht umsonst,", "tokens": ["In", "we\u00b7nig", "Stun\u00b7den", "frag", "ich", "nicht", "um\u00b7sonst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "In dieser Stunde f\u00fcrcht ich, wie ich trotze,", "tokens": ["In", "die\u00b7ser", "Stun\u00b7de", "f\u00fcrcht", "ich", ",", "wie", "ich", "trot\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Bis diese Stunde schreckte mich kein Schauen", "tokens": ["Bis", "die\u00b7se", "Stun\u00b7de", "schreck\u00b7te", "mich", "kein", "Schau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Der Geister, guter, b\u00f6ser. Zittr' ich nun?", "tokens": ["Der", "Geis\u00b7ter", ",", "gu\u00b7ter", ",", "b\u00f6\u00b7ser", ".", "Zit\u00b7tr'", "ich", "nun", "?"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJA", "$,", "ADJD", "$.", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-++-+", "measure": "unknown.measure.hexa"}, "line.11": {"text": "Und f\u00fchl am Herzen fremden, kalten Tau!", "tokens": ["Und", "f\u00fchl", "am", "Her\u00b7zen", "frem\u00b7den", ",", "kal\u00b7ten", "Tau", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Doch kann ich tun, was mich im Tiefsten widert,", "tokens": ["Doch", "kann", "ich", "tun", ",", "was", "mich", "im", "Tiefs\u00b7ten", "wi\u00b7dert", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "VVINF", "$,", "PWS", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Der Erde Schrecken ruf ich auf. \u2013 Eis nachtet!", "tokens": ["Der", "Er\u00b7de", "Schre\u00b7cken", "ruf", "ich", "auf", ".", "\u2013", "Eis", "nach\u00b7tet", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "NN", "VVPP", "$."], "meter": "-+-+-+-+++-", "measure": "unknown.measure.hexa"}}}}}