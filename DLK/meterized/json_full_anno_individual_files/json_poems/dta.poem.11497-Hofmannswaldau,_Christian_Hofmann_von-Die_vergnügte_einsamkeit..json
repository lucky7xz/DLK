{"dta.poem.11497": {"metadata": {"author": {"name": "Hofmannswaldau, Christian Hofmann von", "birth": "N.A.", "death": "N.A."}, "title": "Die vergn\u00fcgte einsamkeit.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1709", "urn": "urn:nbn:de:kobv:b4-20283-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Ausb\u00fcndiges revier, wo nichts verbotnes w\u00e4chst!", "tokens": ["Aus\u00b7b\u00fcn\u00b7di\u00b7ges", "re\u00b7vier", ",", "wo", "nichts", "ver\u00b7bot\u00b7nes", "w\u00e4chst", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PWAV", "PIS", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier ist die einsamkeit, der himmel stiller hertzen!", "tokens": ["Hier", "ist", "die", "ein\u00b7sam\u00b7keit", ",", "der", "him\u00b7mel", "stil\u00b7ler", "hert\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wornach der matte geist wohl hundertmahl gelechst,", "tokens": ["Wor\u00b7nach", "der", "mat\u00b7te", "geist", "wohl", "hun\u00b7dert\u00b7mahl", "ge\u00b7lechst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn der verruchte neid, der stets die unschuld schw\u00e4rtzen", "tokens": ["Wenn", "der", "ver\u00b7ruch\u00b7te", "neid", ",", "der", "stets", "die", "un\u00b7schuld", "schw\u00e4rt\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und unterdrucken will, mir manchen tag und nacht", "tokens": ["Und", "un\u00b7ter\u00b7dru\u00b7cken", "will", ",", "mir", "man\u00b7chen", "tag", "und", "nacht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "VMFIN", "$,", "PPER", "PIAT", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Des lebens s\u00fc\u00dfigkeit zu gall und gifft gemacht.", "tokens": ["Des", "le\u00b7bens", "s\u00fc\u00b7\u00dfig\u00b7keit", "zu", "gall", "und", "gifft", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "O angenehmer ort! den mir des himmels schlu\u00df", "tokens": ["O", "an\u00b7ge\u00b7neh\u00b7mer", "ort", "!", "den", "mir", "des", "him\u00b7mels", "schlu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "ADJA", "NN", "$.", "ART", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zum aufenthalt bestimmt! Wie kommst du mir so s\u00fcsse", "tokens": ["Zum", "auf\u00b7ent\u00b7halt", "be\u00b7stimmt", "!", "Wie", "kommst", "du", "mir", "so", "s\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$.", "PWAV", "VVFIN", "PPER", "PPER", "ADV", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und so vergn\u00fcglich vor! Crystallen-klarer flu\u00df!", "tokens": ["Und", "so", "ver\u00b7gn\u00fcg\u00b7lich", "vor", "!", "Cry\u00b7stal\u00b7len\u00b7kla\u00b7rer", "flu\u00df", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "PTKVZ", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der du die gegend zierst, und durch die schnellen g\u00fcsse", "tokens": ["Der", "du", "die", "ge\u00b7gend", "zierst", ",", "und", "durch", "die", "schnel\u00b7len", "g\u00fcs\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ART", "NN", "VVFIN", "$,", "KON", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ein sanfftes rauschen machst! Du stehst mir trefflich an,", "tokens": ["Ein", "sanff\u00b7tes", "rau\u00b7schen", "machst", "!", "Du", "stehst", "mir", "treff\u00b7lich", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Weil sich geh\u00f6r und geist an dir ergetzen kan.", "tokens": ["Weil", "sich", "ge\u00b7h\u00f6r", "und", "geist", "an", "dir", "er\u00b7get\u00b7zen", "kan", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ADJD", "KON", "NN", "APPR", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ticht\u2019 ich ein kurtzes lied zu meiner eignen lust,", "tokens": ["Ticht'", "ich", "ein", "kurt\u00b7zes", "lied", "zu", "mei\u00b7ner", "eig\u00b7nen", "lust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So dient dein silber-strohm mir statt der Hypocrene:", "tokens": ["So", "dient", "dein", "sil\u00b7ber\u00b7strohm", "mir", "statt", "der", "Hy\u00b7po\u00b7cre\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und wenn die sonne sticht, so labst du mund und brust:", "tokens": ["Und", "wenn", "die", "son\u00b7ne", "sticht", ",", "so", "labst", "du", "mund", "und", "brust", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dein ufer ist mein sitz, dein rieselndes geth\u00f6ne", "tokens": ["Dein", "u\u00b7fer", "ist", "mein", "sitz", ",", "dein", "rie\u00b7seln\u00b7des", "ge\u00b7th\u00f6\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Mein s\u00fcsses lautenspiel, das keine lufft verstimmt,", "tokens": ["Mein", "s\u00fcs\u00b7ses", "lau\u00b7ten\u00b7spiel", ",", "das", "kei\u00b7ne", "lufft", "ver\u00b7stimmt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und alle traurigkeit aus den gedancken nimmt.", "tokens": ["Und", "al\u00b7le", "trau\u00b7rig\u00b7keit", "aus", "den", "ge\u00b7dan\u00b7cken", "nimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}}, "stanza.4": {"line.1": {"text": "Werff ich den angel aus, so fang\u2019 ich manchesmahl", "tokens": ["Werff", "ich", "den", "an\u00b7gel", "aus", ",", "so", "fang'", "ich", "man\u00b7ches\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWS", "PPER", "ART", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In deiner kalten fluth die k\u00f6stlichsten forellen,", "tokens": ["In", "dei\u00b7ner", "kal\u00b7ten", "fluth", "die", "k\u00f6st\u00b7lichs\u00b7ten", "fo\u00b7rel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+---+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Denn diese streichen hier in ungemeiner zahl;", "tokens": ["Denn", "die\u00b7se", "strei\u00b7chen", "hier", "in", "un\u00b7ge\u00b7mei\u00b7ner", "zahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ja die vergn\u00fcgung will aus allen orten quellen.", "tokens": ["Ja", "die", "ver\u00b7gn\u00fc\u00b7gung", "will", "aus", "al\u00b7len", "or\u00b7ten", "quel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "VMFIN", "APPR", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Kurtz: Wie dem Araber kein balsam je gebricht;", "tokens": ["Kurtz", ":", "Wie", "dem", "A\u00b7ra\u00b7ber", "kein", "bal\u00b7sam", "je", "ge\u00b7bricht", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PWAV", "ART", "NN", "PIAT", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So fehlt es mir allhier auch an ergetzung nicht.", "tokens": ["So", "fehlt", "es", "mir", "all\u00b7hier", "auch", "an", "er\u00b7get\u00b7zung", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ADV", "ADV", "APPR", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "La\u00dft der poeten kunst den ehmahls grossen berg", "tokens": ["La\u00dft", "der", "po\u00b7e\u00b7ten", "kunst", "den", "eh\u00b7mahls", "gros\u00b7sen", "berg"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "ART", "ADJA", "NN", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der Musen an den kreis der g\u00f6ldnen sonne f\u00fchren!", "tokens": ["Der", "Mu\u00b7sen", "an", "den", "kreis", "der", "g\u00f6ld\u00b7nen", "son\u00b7ne", "f\u00fch\u00b7ren", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Er ist, ich sag es frey, vor denen nur ein zwerg,", "tokens": ["Er", "ist", ",", "ich", "sag", "es", "frey", ",", "vor", "de\u00b7nen", "nur", "ein", "zwerg", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,", "APPR", "PRELS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So dieses paradies mit ihrem schatten zieren;", "tokens": ["So", "die\u00b7ses", "pa\u00b7ra\u00b7dies", "mit", "ih\u00b7rem", "schat\u00b7ten", "zie\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDAT", "NN", "APPR", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Obgleich kein lorber-baum, nach dem der ehrgeitz lechst", "tokens": ["Ob\u00b7gleich", "kein", "lor\u00b7ber\u00b7baum", ",", "nach", "dem", "der", "ehr\u00b7geitz", "lechst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "$,", "APPR", "ART", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und tolle spr\u00fcnge macht, auf ihrem r\u00fccken w\u00e4chst.", "tokens": ["Und", "tol\u00b7le", "spr\u00fcn\u00b7ge", "macht", ",", "auf", "ih\u00b7rem", "r\u00fc\u00b7cken", "w\u00e4chst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Verkehrt Thessaliens ber\u00fchmter felder schos", "tokens": ["Ver\u00b7kehrt", "Thes\u00b7sa\u00b7li\u00b7ens", "be\u00b7r\u00fchm\u00b7ter", "fel\u00b7der", "schos"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["FM.la", "FM.la", "FM.la", "FM.la", "FM.la"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Jhr tichter in ein grab der allerschwersten sorgen!", "tokens": ["Ihr", "tich\u00b7ter", "in", "ein", "grab", "der", "al\u00b7ler\u00b7schwers\u00b7ten", "sor\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier macht der eigne schmuck die gr\u00fcnen th\u00e4ler gros,", "tokens": ["Hier", "macht", "der", "eig\u00b7ne", "schmuck", "die", "gr\u00fc\u00b7nen", "th\u00e4\u00b7ler", "gros", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "VVFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihre zierde darff nicht fremden beysatz borgen.", "tokens": ["Und", "ih\u00b7re", "zier\u00b7de", "darff", "nicht", "frem\u00b7den", "bey\u00b7satz", "bor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ich wei\u00df, Semiramis lie\u00df\u2019 ihre g\u00e4rte stehn,", "tokens": ["Ich", "wei\u00df", ",", "Se\u00b7mi\u00b7ra\u00b7mis", "lie\u00df'", "ih\u00b7re", "g\u00e4r\u00b7te", "stehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "VVFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und w\u00fcrde gantz vergn\u00fcgt allhier spatzieren gehn.", "tokens": ["Und", "w\u00fcr\u00b7de", "gantz", "ver\u00b7gn\u00fcgt", "all\u00b7hier", "spat\u00b7zie\u00b7ren", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "VVFIN", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Weg, falsche Venus! weg! lauff in dein Cypern hin!", "tokens": ["Weg", ",", "fal\u00b7sche", "Ve\u00b7nus", "!", "weg", "!", "lauff", "in", "dein", "Cy\u00b7pern", "hin", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$.", "PTKVZ", "$.", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und decke dich daselbst mit den erkiesten myrthen!", "tokens": ["Und", "de\u00b7cke", "dich", "da\u00b7selbst", "mit", "den", "er\u00b7kies\u00b7ten", "myr\u00b7then", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PAV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ob gleich auf unsrer au nicht geile blumen bl\u00fchn;", "tokens": ["Ob", "gleich", "auf", "uns\u00b7rer", "au", "nicht", "gei\u00b7le", "blu\u00b7men", "bl\u00fchn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "PPOSAT", "NN", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So kan mich dennoch wohl die lieblichkeit bewirthen.", "tokens": ["So", "kan", "mich", "den\u00b7noch", "wohl", "die", "lieb\u00b7lich\u00b7keit", "be\u00b7wirt\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Prahlt dieser wiesen schmeltz mit tulp- und rosen nicht;", "tokens": ["Prahlt", "die\u00b7ser", "wie\u00b7sen", "schmeltz", "mit", "tul\u00b7p", "und", "ro\u00b7sen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PDS", "VVFIN", "ADJD", "APPR", "TRUNC", "KON", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+----+-+", "measure": "unknown.measure.penta"}, "line.6": {"text": "Genung: Da\u00df unsre hand klee und violen bricht.", "tokens": ["Ge\u00b7nung", ":", "Da\u00df", "uns\u00b7re", "hand", "klee", "und", "vi\u00b7o\u00b7len", "bricht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "KOUS", "PPOSAT", "NN", "ADJA", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Steigt aus der reinen bach kein s\u00fcsses zucker-rohr;", "tokens": ["Steigt", "aus", "der", "rei\u00b7nen", "bach", "kein", "s\u00fcs\u00b7ses", "zu\u00b7cke\u00b7rrohr", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "ADJA", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So l\u00e4\u00dft die biene doch gesundes honig fliessen.", "tokens": ["So", "l\u00e4\u00dft", "die", "bie\u00b7ne", "doch", "ge\u00b7sun\u00b7des", "ho\u00b7nig", "flies\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "ADV", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Thut kein Amphion sich um diese fluth hervor;", "tokens": ["Thut", "kein", "Am\u00b7phi\u00b7on", "sich", "um", "die\u00b7se", "fluth", "her\u00b7vor", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PRF", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die ohren k\u00f6nnen hier viel rein\u2019re lust geniessen,", "tokens": ["Die", "oh\u00b7ren", "k\u00f6n\u00b7nen", "hier", "viel", "rein'\u00b7re", "lust", "ge\u00b7nies\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "PIAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wenn finck und nachtigall von denen \u00e4sten singt,", "tokens": ["Wenn", "finck", "und", "nach\u00b7ti\u00b7gall", "von", "de\u00b7nen", "\u00e4s\u00b7ten", "singt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "APPR", "PRELS", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und echo den gesang wohl doppelt wiederbringt.", "tokens": ["Und", "ec\u00b7ho", "den", "ge\u00b7sang", "wohl", "dop\u00b7pelt", "wie\u00b7der\u00b7bringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ART", "ADJD", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Beliebte w\u00fcsteney! vergn\u00fcgungs-volle nacht!", "tokens": ["Be\u00b7lieb\u00b7te", "w\u00fcs\u00b7te\u00b7ney", "!", "ver\u00b7gn\u00fc\u00b7gungs\u00b7vol\u00b7le", "nacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Geht hin, Arcadier! und r\u00fchmet eure w\u00e4lder!", "tokens": ["Geht", "hin", ",", "Ar\u00b7ca\u00b7dier", "!", "und", "r\u00fch\u00b7met", "eu\u00b7re", "w\u00e4l\u00b7der", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "NN", "$.", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Kommt aber auch und schaut, was diese herrlich macht:", "tokens": ["Kommt", "a\u00b7ber", "auch", "und", "schaut", ",", "was", "die\u00b7se", "herr\u00b7lich", "macht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "KON", "VVFIN", "$,", "PWS", "PDAT", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und wie der b\u00e4ume stoltz bi\u00df an die sternen-felder", "tokens": ["Und", "wie", "der", "b\u00e4u\u00b7me", "stoltz", "bi\u00df", "an", "die", "ster\u00b7nen\u00b7fel\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "APPR", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die hohen gipffel treibt. Ach! auserlesner wald!", "tokens": ["Die", "ho\u00b7hen", "gipf\u00b7fel", "treibt", ".", "Ach", "!", "au\u00b7ser\u00b7les\u00b7ner", "wald", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "ITJ", "$.", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Du bist mein lust-revier! du bist mein aufenthalt!", "tokens": ["Du", "bist", "mein", "lust\u00b7re\u00b7vier", "!", "du", "bist", "mein", "auf\u00b7ent\u00b7halt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Gelassner Seladon! Hier bl\u00fcht die s\u00fcsse ruh,", "tokens": ["Ge\u00b7lass\u00b7ner", "Se\u00b7la\u00b7don", "!", "Hier", "bl\u00fcht", "die", "s\u00fcs\u00b7se", "ruh", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So deinen geist entz\u00fcckt, und aus sich selber f\u00fchret:", "tokens": ["So", "dei\u00b7nen", "geist", "ent\u00b7z\u00fcckt", ",", "und", "aus", "sich", "sel\u00b7ber", "f\u00fch\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "$,", "KON", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier schliesst der anmuth krafft der sorgen brunnquell zu:", "tokens": ["Hier", "schliesst", "der", "an\u00b7muth", "krafft", "der", "sor\u00b7gen", "brunn\u00b7quell", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVFIN", "ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier, wo gelinder west die schlancken pappeln r\u00fchret:", "tokens": ["Hier", ",", "wo", "ge\u00b7lin\u00b7der", "west", "die", "schlan\u00b7cken", "pap\u00b7peln", "r\u00fch\u00b7ret", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJD", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da sich der m\u00fcde hirsch an reiche linden streckt,", "tokens": ["Da", "sich", "der", "m\u00fc\u00b7de", "hirsch", "an", "rei\u00b7che", "lin\u00b7den", "streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "APPR", "ADJA", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und ein geheimer trieb die matten sinnen weckt.", "tokens": ["Und", "ein", "ge\u00b7hei\u00b7mer", "trieb", "die", "mat\u00b7ten", "sin\u00b7nen", "weckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "VVFIN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Schreib, kluger Plinius", "tokens": ["Schreib", ",", "klu\u00b7ger", "Pli\u00b7nius"], "token_info": ["word", "punct", "word", "word"], "pos": ["NN", "$,", "ADJA", "NE"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Es kan mein schlechter kiel so viel als deiner sagen.", "tokens": ["Es", "kan", "mein", "schlech\u00b7ter", "kiel", "so", "viel", "als", "dei\u00b7ner", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "ADJA", "NN", "ADV", "PIAT", "KOKOM", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich h\u00f6r\u2019 und schaue nichts, als was mein heetz erfreut:", "tokens": ["Ich", "h\u00f6r'", "und", "schau\u00b7e", "nichts", ",", "als", "was", "mein", "heetz", "er\u00b7freut", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PIS", "$,", "KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es st\u00f6ret kein tumult mein ruhiges behagen.", "tokens": ["Es", "st\u00f6\u00b7ret", "kein", "tu\u00b7mult", "mein", "ru\u00b7hi\u00b7ges", "be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+--+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Der tempel, den ihm einst Harpocrates erkiest,", "tokens": ["Der", "tem\u00b7pel", ",", "den", "ihm", "einst", "Har\u00b7po\u00b7cra\u00b7tes", "er\u00b7kiest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "NE", "VVFIN", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.6": {"text": "Wird kaum so stille seyn, als mein beh\u00e4ltni\u00df ist.", "tokens": ["Wird", "kaum", "so", "stil\u00b7le", "seyn", ",", "als", "mein", "be\u00b7h\u00e4lt\u00b7ni\u00df", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJA", "VAINF", "$,", "KOUS", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Mein zimmer kennt zwar nichts von ungemeiner pracht:", "tokens": ["Mein", "zim\u00b7mer", "kennt", "zwar", "nichts", "von", "un\u00b7ge\u00b7mei\u00b7ner", "pracht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "PIS", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es scheint die armuth sey in selbigem zu hause;", "tokens": ["Es", "scheint", "die", "ar\u00b7muth", "sey", "in", "sel\u00b7bi\u00b7gem", "zu", "hau\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "VAFIN", "APPR", "ADJA", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jedoch mit prahlen ist auch wenig ausgemacht:", "tokens": ["Je\u00b7doch", "mit", "prah\u00b7len", "ist", "auch", "we\u00b7nig", "aus\u00b7ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "VAFIN", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der pr\u00e4chtigste pallast", "tokens": ["Der", "pr\u00e4ch\u00b7tigs\u00b7te", "pal\u00b7last"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Schliest einen Socrates", "tokens": ["Schliest", "ei\u00b7nen", "So\u00b7cra\u00b7tes"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.6": {"text": "So kan er denn so gut, als manches rath-haus seyn.", "tokens": ["So", "kan", "er", "denn", "so", "gut", ",", "als", "man\u00b7ches", "ra\u00b7th\u00b7haus", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "KOUS", "PIAT", "NN", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Ist meine wohnung schlecht? bin ich doch auch nicht gros:", "tokens": ["Ist", "mei\u00b7ne", "woh\u00b7nung", "schlecht", "?", "bin", "ich", "doch", "auch", "nicht", "gros", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVFIN", "$.", "VAFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein zimmer, wo gesund und sauber ist zu wohnen,", "tokens": ["Ein", "zim\u00b7mer", ",", "wo", "ge\u00b7sund", "und", "sau\u00b7ber", "ist", "zu", "woh\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ADJD", "KON", "ADJD", "VAFIN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ist gut genung vor uns: Und bricht der donner los?", "tokens": ["Ist", "gut", "ge\u00b7nung", "vor", "uns", ":", "Und", "bricht", "der", "don\u00b7ner", "los", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "ADV", "APPR", "PPER", "$.", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So w\u00fcnsch ich mich ohndem mit schl\u00f6ssern zu verschonen,", "tokens": ["So", "w\u00fcnsch", "ich", "mich", "ohn\u00b7dem", "mit", "schl\u00f6s\u00b7sern", "zu", "ver\u00b7scho\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "PAV", "APPR", "VVINF", "PTKZU", "VVINF", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Weil meistentheils der schlag ", "tokens": ["Weil", "meis\u00b7ten\u00b7theils", "der", "schlag"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wenn ein geringes dach in sicherm friede steht.", "tokens": ["Wenn", "ein", "ge\u00b7rin\u00b7ges", "dach", "in", "si\u00b7cherm", "frie\u00b7de", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "PAV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Jhr, die beruff und stand zu etwas grossem treibt!", "tokens": ["Ihr", ",", "die", "be\u00b7ruff", "und", "stand", "zu", "et\u00b7was", "gros\u00b7sem", "treibt", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADJD", "KON", "VVFIN", "APPR", "PIAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Folgt eurem triebe nach! ich such\u2019 euch nicht zu tadeln:", "tokens": ["Folgt", "eu\u00b7rem", "trie\u00b7be", "nach", "!", "ich", "such'", "euch", "nicht", "zu", "ta\u00b7deln", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "VVFIN", "PTKVZ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich wei\u00df, was Curtius von Alexandern schreibt", "tokens": ["Ich", "wei\u00df", ",", "was", "Cur\u00b7tius", "von", "A\u00b7lex\u00b7an\u00b7dern", "schreibt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PRELS", "NE", "APPR", "NE", "VVFIN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Und wieviel andre mehr ber\u00fchmte thaten adeln.", "tokens": ["Und", "wie\u00b7viel", "and\u00b7re", "mehr", "be\u00b7r\u00fchm\u00b7te", "tha\u00b7ten", "a\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PIS", "ADV", "VVFIN", "VVFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Geht! sucht den gr\u00f6sten hof, wo die erfahrung gilt,", "tokens": ["Geht", "!", "sucht", "den", "gr\u00f6s\u00b7ten", "hof", ",", "wo", "die", "er\u00b7fah\u00b7rung", "gilt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "VVFIN", "ART", "ADJA", "NN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und man durch klugheit offt viel ungewitter stillt.", "tokens": ["Und", "man", "durch", "klug\u00b7heit", "offt", "viel", "un\u00b7ge\u00b7wit\u00b7ter", "stillt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "ADV", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Rennt! die ihr waffen liebt, und la\u00dft den scharffen stahl", "tokens": ["Rennt", "!", "die", "ihr", "waf\u00b7fen", "liebt", ",", "und", "la\u00dft", "den", "scharf\u00b7fen", "stahl"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "ART", "PPOSAT", "NN", "VVFIN", "$,", "KON", "VVIMP", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In der bezwungnen feind\u2019 erschrockne br\u00fcste gleiten!", "tokens": ["In", "der", "be\u00b7zwung\u00b7nen", "feind'", "er\u00b7schrock\u00b7ne", "br\u00fcs\u00b7te", "glei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Jhr steigt durch tapfferkeit auf einen ehren-saal;", "tokens": ["Ihr", "steigt", "durch", "tapf\u00b7fer\u00b7keit", "auf", "ei\u00b7nen", "eh\u00b7ren\u00b7saal", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mich will der wei\u00dfheits-stern in jene l\u00e4nder leiten,", "tokens": ["Mich", "will", "der", "wei\u00df\u00b7heits\u00b7stern", "in", "je\u00b7ne", "l\u00e4n\u00b7der", "lei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "ADJA", "APPR", "PDAT", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo liebe kayser ist, wo lauter friede wohnt,", "tokens": ["Wo", "lie\u00b7be", "kay\u00b7ser", "ist", ",", "wo", "lau\u00b7ter", "frie\u00b7de", "wohnt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADJD", "VAFIN", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und GOtt zwar der geduld, doch keiner rache lohnt.", "tokens": ["Und", "Gott", "zwar", "der", "ge\u00b7duld", ",", "doch", "kei\u00b7ner", "ra\u00b7che", "lohnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "ART", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Ein andrer suche sich in einer grossen stadt", "tokens": ["Ein", "an\u00b7drer", "su\u00b7che", "sich", "in", "ei\u00b7ner", "gros\u00b7sen", "stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Durch geld und wissenschafft hoch an das bret zu bringen!", "tokens": ["Durch", "geld", "und", "wis\u00b7sen\u00b7schafft", "hoch", "an", "das", "bret", "zu", "brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "VVFIN", "ADJD", "APPR", "PDS", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer seine saiten schon zu hoch gespannet hat,", "tokens": ["Wer", "sei\u00b7ne", "sai\u00b7ten", "schon", "zu", "hoch", "ge\u00b7span\u00b7net", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "VVFIN", "ADV", "PTKA", "ADJD", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem pflegen sie gewi\u00df gar bald entzwey zu springen:", "tokens": ["Dem", "pfle\u00b7gen", "sie", "ge\u00b7wi\u00df", "gar", "bald", "ent\u00b7zwey", "zu", "sprin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Man darff es schlecht versehn, so ist der titel hin;", "tokens": ["Man", "darff", "es", "schlecht", "ver\u00b7sehn", ",", "so", "ist", "der", "ti\u00b7tel", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADJD", "VVINF", "$,", "ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich bin vergn\u00fcgt genung", "tokens": ["Ich", "bin", "ver\u00b7gn\u00fcgt", "ge\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Gepriesnes einsam-seyn! wo ruh und friede wacht!", "tokens": ["Ge\u00b7pri\u00b7es\u00b7nes", "ein\u00b7sam\u00b7seyn", "!", "wo", "ruh", "und", "frie\u00b7de", "wacht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "PWAV", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Hier hab ich weder feind ", "tokens": ["Hier", "hab", "ich", "we\u00b7der", "feind"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Es giebt kein h\u00f6nisch aug auf meine thaten acht:", "tokens": ["Es", "giebt", "kein", "h\u00f6\u00b7nisch", "aug", "auf", "mei\u00b7ne", "tha\u00b7ten", "acht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJD", "NN", "APPR", "PPOSAT", "VVFIN", "CARD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Auf einen stillen schlaf folgt ein gew\u00fcnschter morgen.", "tokens": ["Auf", "ei\u00b7nen", "stil\u00b7len", "schlaf", "folgt", "ein", "ge\u00b7w\u00fcnschter", "mor\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--", "measure": "unknown.measure.penta"}, "line.5": {"text": "Ja, wenn man es bedenckt, wo ist bequemre zeit,", "tokens": ["Ja", ",", "wenn", "man", "es", "be\u00b7denckt", ",", "wo", "ist", "be\u00b7quem\u00b7re", "zeit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "PWAV", "VAFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Recht in sich selbst zu gehn", "tokens": ["Recht", "in", "sich", "selbst", "zu", "gehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PRF", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Drum kreucht Democritus ", "tokens": ["Drum", "kreucht", "De\u00b7mo\u00b7cri\u00b7tus"], "token_info": ["word", "word", "word"], "pos": ["PAV", "VVFIN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der weisheit amber steigt auch aus verfaulten s\u00e4rgen:", "tokens": ["Der", "weis\u00b7heit", "am\u00b7ber", "steigt", "auch", "aus", "ver\u00b7faul\u00b7ten", "s\u00e4r\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "ADV", "APPR", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da\u00df Heraclitus ", "tokens": ["Da\u00df", "Her\u00b7a\u00b7cli\u00b7tus"], "token_info": ["word", "word"], "pos": ["KOUS", "NE"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Wie Timon sich so gern in g\u00e4rten will verbergen,", "tokens": ["Wie", "Ti\u00b7mon", "sich", "so", "gern", "in", "g\u00e4r\u00b7ten", "will", "ver\u00b7ber\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PRF", "ADV", "ADV", "APPR", "ADJA", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ist, wenn man es erwegt, viel eher eine that,", "tokens": ["Ist", ",", "wenn", "man", "es", "er\u00b7wegt", ",", "viel", "e\u00b7her", "ei\u00b7ne", "that", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$,", "ADV", "ADV", "ART", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die menschen-lieb\u2019, als ha\u00df zu ihrer absicht hat.", "tokens": ["Die", "men\u00b7schen\u00b7lieb'", ",", "als", "ha\u00df", "zu", "ih\u00b7rer", "ab\u00b7sicht", "hat", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUS", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Mit andern umzugehn", "tokens": ["Mit", "an\u00b7dern", "um\u00b7zu\u00b7gehn"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIS", "VVIZU"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Noch schwerer aber ist, mit sich zu reden wissen:", "tokens": ["Noch", "schwe\u00b7rer", "a\u00b7ber", "ist", ",", "mit", "sich", "zu", "re\u00b7den", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VAFIN", "$,", "APPR", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und diese wissenschafft hei\u00dft kein gemahlter dunst:", "tokens": ["Und", "die\u00b7se", "wis\u00b7sen\u00b7schafft", "hei\u00dft", "kein", "ge\u00b7mahl\u00b7ter", "dunst", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "VVFIN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie l\u00e4utert den verstand von allen finsternissen,", "tokens": ["Sie", "l\u00e4u\u00b7tert", "den", "ver\u00b7stand", "von", "al\u00b7len", "fins\u00b7ter\u00b7nis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "VVFIN", "APPR", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und s\u00fchret unser hertz in wahre sicherheit;", "tokens": ["Und", "s\u00fch\u00b7ret", "un\u00b7ser", "hertz", "in", "wah\u00b7re", "si\u00b7cher\u00b7heit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Allein, wo lernt man sie, als in der einsamkeit?", "tokens": ["Al\u00b7lein", ",", "wo", "lernt", "man", "sie", ",", "als", "in", "der", "ein\u00b7sam\u00b7keit", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VVFIN", "PIS", "PPER", "$,", "KOUS", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.20": {"line.1": {"text": "Die gr\u00f6sten geister zieht der einsamkeit magnet:", "tokens": ["Die", "gr\u00f6s\u00b7ten", "geis\u00b7ter", "zieht", "der", "ein\u00b7sam\u00b7keit", "mag\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Adonis sucht in ihr", "tokens": ["A\u00b7do\u00b7nis", "sucht", "in", "ihr"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Der gro\u00df Ariovist", "tokens": ["Der", "gro\u00df", "A\u00b7rio\u00b7vist"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJD", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Fand endlich ruh und grab in einer d\u00fcstren h\u00f6le.", "tokens": ["Fand", "end\u00b7lich", "ruh", "und", "grab", "in", "ei\u00b7ner", "d\u00fcst\u00b7ren", "h\u00f6\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "KON", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Was macht\u2019, o Salomo", "tokens": ["Was", "macht'", ",", "o", "Sa\u00b7lo\u00b7mo"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "$,", "FM", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Dir die verg\u00e4nglichkeit der eitlen lust bekannt?", "tokens": ["Dir", "die", "ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "der", "eit\u00b7len", "lust", "be\u00b7kannt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Wo sch\u00f6pfft Alcinous ", "tokens": ["Wo", "sch\u00f6pfft", "Al\u00b7ci\u00b7nous"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "NE"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Wo hieng Semiramis die sorgen an den nagel?", "tokens": ["Wo", "hieng", "Se\u00b7mi\u00b7ra\u00b7mis", "die", "sor\u00b7gen", "an", "den", "na\u00b7gel", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "NE", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wo legt\u2019 ihm Seneca ", "tokens": ["Wo", "legt'", "ihm", "Se\u00b7ne\u00b7ca"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Wo lehret\u2019 Epicur ", "tokens": ["Wo", "leh\u00b7ret'", "E\u00b7pi\u00b7cur"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Der seele wollust nahm? Und wo hat Statius ", "tokens": ["Der", "see\u00b7le", "wol\u00b7lust", "nahm", "?", "Und", "wo", "hat", "Sta\u00b7tius"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "VVFIN", "$.", "KON", "PWAV", "VAFIN", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Es fast dahin gebracht ", "tokens": ["Es", "fast", "da\u00b7hin", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "PAV", "VVPP"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "In stillen g\u00e4rten steckt ein sonderbahrer zug.", "tokens": ["In", "stil\u00b7len", "g\u00e4r\u00b7ten", "steckt", "ein", "son\u00b7der\u00b7bah\u00b7rer", "zug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer wei\u00df nicht, was August ", "tokens": ["Wer", "wei\u00df", "nicht", ",", "was", "Au\u00b7gust"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PTKNEG", "$,", "PWS", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu dieser lebens-art vor grosse neigung trug?", "tokens": ["Zu", "die\u00b7ser", "le\u00b7bens\u00b7art", "vor", "gros\u00b7se", "nei\u00b7gung", "trug", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Zog Diocletian ", "tokens": ["Zog", "Dio\u00b7cle\u00b7ti\u00b7an"], "token_info": ["word", "word"], "pos": ["VVFIN", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Schon um die stirne trug, nicht seinen purpur aus,", "tokens": ["Schon", "um", "die", "stir\u00b7ne", "trug", ",", "nicht", "sei\u00b7nen", "pur\u00b7pur", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "VVFIN", "$,", "PTKNEG", "PPOSAT", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und nahm vor hof und stadt ", "tokens": ["Und", "nahm", "vor", "hof", "und", "stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "M\u00e4cenas ", "tokens": ["M\u00e4\u00b7ce\u00b7nas"], "token_info": ["word"], "pos": ["NE"], "meter": "+--", "measure": "dactylic.init"}, "line.2": {"text": "Weil sein geschickter kopff so wohl zu rathen wuste,", "tokens": ["Weil", "sein", "ge\u00b7schick\u00b7ter", "kopff", "so", "wohl", "zu", "ra\u00b7then", "wus\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hielt offt die einsamkeit vor seinen besten schild,", "tokens": ["Hielt", "offt", "die", "ein\u00b7sam\u00b7keit", "vor", "sei\u00b7nen", "bes\u00b7ten", "schild", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wenn er mit eyfersucht und sorgen k\u00e4mpffen muste.", "tokens": ["Wenn", "er", "mit", "ey\u00b7fer\u00b7sucht", "und", "sor\u00b7gen", "k\u00e4mpf\u00b7fen", "mus\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "KON", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Der tapffre Scipio ", "tokens": ["Der", "tapf\u00b7fre", "Sci\u00b7pio"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.6": {"text": "Jhm nach der ehre grieff, den schutz der einsamkeit.", "tokens": ["Jhm", "nach", "der", "eh\u00b7re", "grieff", ",", "den", "schutz", "der", "ein\u00b7sam\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Da\u00df Cartes ", "tokens": ["Da\u00df", "Car\u00b7tes"], "token_info": ["word", "word"], "pos": ["KOUS", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Das hatt\u2019 er grossen theils der einsamkeit zu dancken:", "tokens": ["Das", "hatt'", "er", "gros\u00b7sen", "theils", "der", "ein\u00b7sam\u00b7keit", "zu", "dan\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "ADV", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie nutzt versichert mehr, als mantel stock und bart:", "tokens": ["Sie", "nutzt", "ver\u00b7si\u00b7chert", "mehr", ",", "als", "man\u00b7tel", "stock", "und", "bart", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "$,", "KOUS", "NN", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie bringt den stillen geist auf hurtige gedancken:", "tokens": ["Sie", "bringt", "den", "stil\u00b7len", "geist", "auf", "hur\u00b7ti\u00b7ge", "ge\u00b7dan\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie ist das vaterland, so keine b\u00fcrger kennt,", "tokens": ["Sie", "ist", "das", "va\u00b7ter\u00b7land", ",", "so", "kei\u00b7ne", "b\u00fcr\u00b7ger", "kennt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADV", "PIAT", "ADJA", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Als die der wahrheit mund gelehrt und heilig nennt.", "tokens": ["Als", "die", "der", "wahr\u00b7heit", "mund", "ge\u00b7lehrt", "und", "hei\u00b7lig", "nennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ART", "NN", "NN", "VVPP", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}