{"textgrid.poem.49730": {"metadata": {"author": {"name": "Thoma, Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "Er\u00f6ffnungshymne", "genre": "verse", "period": "N.A.", "pub_year": 1894, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist schw\u00e4rzer als die Kohle?", "tokens": ["Was", "ist", "schw\u00e4r\u00b7zer", "als", "die", "Koh\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die Tinte? Als der Ru\u00df?", "tokens": ["Als", "die", "Tin\u00b7te", "?", "Als", "der", "Ru\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$.", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schw\u00e4rzer noch als Rab' und Dohle", "tokens": ["Schw\u00e4r\u00b7zer", "noch", "als", "Rab'", "und", "Doh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und des Negers Vorderfu\u00df?", "tokens": ["Und", "des", "Ne\u00b7gers", "Vor\u00b7der\u00b7fu\u00df", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag mir doch, wer dieses kennt!", "tokens": ["Sag", "mir", "doch", ",", "wer", "die\u00b7ses", "kennt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "PWS", "PDS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u2013 Bayerns neues Parlament.", "tokens": ["\u2013", "Bay\u00b7erns", "neu\u00b7es", "Par\u00b7la\u00b7ment", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und wo sind die dicksten K\u00f6pfe?", "tokens": ["Und", "wo", "sind", "die", "dicks\u00b7ten", "K\u00f6p\u00b7fe", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dicke K\u00f6pfe gibt es viel,", "tokens": ["Di\u00b7cke", "K\u00f6p\u00b7fe", "gibt", "es", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denken wir nur an Gesch\u00f6pfe", "tokens": ["Den\u00b7ken", "wir", "nur", "an", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie Rhinozeross' im Nil.", "tokens": ["Wie", "Rhi\u00b7no\u00b7ze\u00b7ross'", "im", "Nil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dick're hat \u2013 o Sakrament!", "tokens": ["Dick'\u00b7re", "hat", "\u2013", "o", "Sak\u00b7ra\u00b7ment", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "FM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u2013 Bayerns neues Parlament.", "tokens": ["\u2013", "Bay\u00b7erns", "neu\u00b7es", "Par\u00b7la\u00b7ment", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Wer ist fr\u00f6mmer als die Taube?", "tokens": ["Wer", "ist", "fr\u00f6m\u00b7mer", "als", "die", "Tau\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die milchgef\u00fcllte Kuh?", "tokens": ["Als", "die", "milch\u00b7ge\u00b7f\u00fcll\u00b7te", "Kuh", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als der Kapuzinerglaube", "tokens": ["Als", "der", "Ka\u00b7pu\u00b7zi\u00b7ner\u00b7glau\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das fromme Lamm dazu?", "tokens": ["Und", "das", "from\u00b7me", "Lamm", "da\u00b7zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fr\u00f6mmer ist das Regiment", "tokens": ["Fr\u00f6m\u00b7mer", "ist", "das", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In dem neuen Parlament.", "tokens": ["In", "dem", "neu\u00b7en", "Par\u00b7la\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Und was ist das Allerd\u00fcmmste?", "tokens": ["Und", "was", "ist", "das", "Al\u00b7ler\u00b7d\u00fcmms\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon noch d\u00fcmmer als wie dumm?", "tokens": ["Schon", "noch", "d\u00fcm\u00b7mer", "als", "wie", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KOKOM", "KOKOM", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sagt mir gleich das Allerschlimmste,", "tokens": ["Sagt", "mir", "gleich", "das", "Al\u00b7ler\u00b7schlimms\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber ratet nicht herum!", "tokens": ["A\u00b7ber", "ra\u00b7tet", "nicht", "he\u00b7rum", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag' mir endlich, wer es kennt!", "tokens": ["Sag'", "mir", "end\u00b7lich", ",", "wer", "es", "kennt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Himmelherrgottsakrament!!", "tokens": ["Him\u00b7mel\u00b7herr\u00b7gott\u00b7sa\u00b7kra\u00b7ment", "!!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Was ist schw\u00e4rzer als die Kohle?", "tokens": ["Was", "ist", "schw\u00e4r\u00b7zer", "als", "die", "Koh\u00b7le", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die Tinte? Als der Ru\u00df?", "tokens": ["Als", "die", "Tin\u00b7te", "?", "Als", "der", "Ru\u00df", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$.", "KOUS", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Schw\u00e4rzer noch als Rab' und Dohle", "tokens": ["Schw\u00e4r\u00b7zer", "noch", "als", "Rab'", "und", "Doh\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "KOUS", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und des Negers Vorderfu\u00df?", "tokens": ["Und", "des", "Ne\u00b7gers", "Vor\u00b7der\u00b7fu\u00df", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag mir doch, wer dieses kennt!", "tokens": ["Sag", "mir", "doch", ",", "wer", "die\u00b7ses", "kennt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "PWS", "PDS", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u2013 Bayerns neues Parlament.", "tokens": ["\u2013", "Bay\u00b7erns", "neu\u00b7es", "Par\u00b7la\u00b7ment", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Und wo sind die dicksten K\u00f6pfe?", "tokens": ["Und", "wo", "sind", "die", "dicks\u00b7ten", "K\u00f6p\u00b7fe", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Dicke K\u00f6pfe gibt es viel,", "tokens": ["Di\u00b7cke", "K\u00f6p\u00b7fe", "gibt", "es", "viel", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denken wir nur an Gesch\u00f6pfe", "tokens": ["Den\u00b7ken", "wir", "nur", "an", "Ge\u00b7sch\u00f6p\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "APPR", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wie Rhinozeross' im Nil.", "tokens": ["Wie", "Rhi\u00b7no\u00b7ze\u00b7ross'", "im", "Nil", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dick're hat \u2013 o Sakrament!", "tokens": ["Dick'\u00b7re", "hat", "\u2013", "o", "Sak\u00b7ra\u00b7ment", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$(", "FM", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "\u2013 Bayerns neues Parlament.", "tokens": ["\u2013", "Bay\u00b7erns", "neu\u00b7es", "Par\u00b7la\u00b7ment", "."], "token_info": ["punct", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Wer ist fr\u00f6mmer als die Taube?", "tokens": ["Wer", "ist", "fr\u00f6m\u00b7mer", "als", "die", "Tau\u00b7be", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Als die milchgef\u00fcllte Kuh?", "tokens": ["Als", "die", "milch\u00b7ge\u00b7f\u00fcll\u00b7te", "Kuh", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Als der Kapuzinerglaube", "tokens": ["Als", "der", "Ka\u00b7pu\u00b7zi\u00b7ner\u00b7glau\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und das fromme Lamm dazu?", "tokens": ["Und", "das", "from\u00b7me", "Lamm", "da\u00b7zu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Fr\u00f6mmer ist das Regiment", "tokens": ["Fr\u00f6m\u00b7mer", "ist", "das", "Re\u00b7gi\u00b7ment"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "In dem neuen Parlament.", "tokens": ["In", "dem", "neu\u00b7en", "Par\u00b7la\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und was ist das Allerd\u00fcmmste?", "tokens": ["Und", "was", "ist", "das", "Al\u00b7ler\u00b7d\u00fcmms\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VAFIN", "ART", "ADJA", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Schon noch d\u00fcmmer als wie dumm?", "tokens": ["Schon", "noch", "d\u00fcm\u00b7mer", "als", "wie", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "KOKOM", "KOKOM", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sagt mir gleich das Allerschlimmste,", "tokens": ["Sagt", "mir", "gleich", "das", "Al\u00b7ler\u00b7schlimms\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Aber ratet nicht herum!", "tokens": ["A\u00b7ber", "ra\u00b7tet", "nicht", "he\u00b7rum", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sag' mir endlich, wer es kennt!", "tokens": ["Sag'", "mir", "end\u00b7lich", ",", "wer", "es", "kennt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Himmelherrgottsakrament!!", "tokens": ["Him\u00b7mel\u00b7herr\u00b7gott\u00b7sa\u00b7kra\u00b7ment", "!!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}