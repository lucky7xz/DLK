{"textgrid.poem.35328": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "1L: Emma Moreland, das freundliche Kind,", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Emma Moreland, das freundliche Kind,", "tokens": ["Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "das", "freund\u00b7li\u00b7che", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Traf mich drau\u00dfen und kam auf mich zu:", "tokens": ["Traf", "mich", "drau\u00b7\u00dfen", "und", "kam", "auf", "mich", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbhast dein Herz verloren?\u00ab frug sie geschwind,", "tokens": ["\u00bb", "hast", "dein", "Herz", "ver\u00b7lo\u00b7ren", "?", "\u00ab", "frug", "sie", "ge\u00b7schwind", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "\u00bbedward Gray, wann heiratest du?\u00ab", "tokens": ["\u00bb", "ed\u00b7ward", "Gray", ",", "wann", "hei\u00b7ra\u00b7test", "du", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "$,", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.2": {"line.1": {"text": "Als sie mich so zur Beichte gekriegt,", "tokens": ["Als", "sie", "mich", "so", "zur", "Beich\u00b7te", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "O da weinte ich bitterlich:", "tokens": ["O", "da", "wein\u00b7te", "ich", "bit\u00b7ter\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbs\u00fc\u00dfe Emma Moreland, ewig versiegt", "tokens": ["\u00bb", "s\u00fc\u00b7\u00dfe", "Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "e\u00b7wig", "ver\u00b7siegt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "NE", "NE", "$,", "ADJD", "VVPP"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ist der Liebe Born f\u00fcr mich!", "tokens": ["Ist", "der", "Lie\u00b7be", "Born", "f\u00fcr", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NE", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Inniglich liebte mich Ellen Adair;", "tokens": ["In\u00b7nig\u00b7lich", "lieb\u00b7te", "mich", "El\u00b7len", "A\u00b7dair", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NE", "$."], "meter": "---+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vater und Mutter wurden ihr gram \u2013", "tokens": ["Va\u00b7ter", "und", "Mut\u00b7ter", "wur\u00b7den", "ihr", "gram", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADJD", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Dort liegt sie begraben, \u2013 frage nicht mehr,", "tokens": ["Dort", "liegt", "sie", "be\u00b7gra\u00b7ben", ",", "\u2013", "fra\u00b7ge", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,", "$(", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von wannen ich eben kam.", "tokens": ["Von", "wan\u00b7nen", "ich", "e\u00b7ben", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "Scheu war sie, nicht kalt, \u2013 ich wu\u00dft' es zu sp\u00e4t;", "tokens": ["Scheu", "war", "sie", ",", "nicht", "kalt", ",", "\u2013", "ich", "wu\u00dft'", "es", "zu", "sp\u00e4t", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PTKNEG", "ADJD", "$,", "$(", "PPER", "VVFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn ich mied, ja ich mied sie lang',", "tokens": ["Denn", "ich", "mied", ",", "ja", "ich", "mied", "sie", "lang'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "ADV", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Strich durch die Meere, von Hochmut gebl\u00e4ht,", "tokens": ["Strich", "durch", "die", "Mee\u00b7re", ",", "von", "Hoch\u00b7mut", "ge\u00b7bl\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Als sie mit dem Tode rang.", "tokens": ["Als", "sie", "mit", "dem", "To\u00b7de", "rang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Grausame Worte, die sie geh\u00f6rt,", "tokens": ["Grau\u00b7sa\u00b7me", "Wor\u00b7te", ",", "die", "sie", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "O wie thun sie mir jetzt so weh!", "tokens": ["O", "wie", "thun", "sie", "mir", "jetzt", "so", "weh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bist ein eitles Ding, so sprach ich beth\u00f6rt,", "tokens": ["Bist", "ein", "eit\u00b7les", "Ding", ",", "so", "sprach", "ich", "be\u00b7th\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Gar zu leicht f\u00fcr Edward Gray.", "tokens": ["Gar", "zu", "leicht", "f\u00fcr", "Ed\u00b7ward", "Gray", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "APPR", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Dort barg ich mein Antlitz im feuchten Gras", "tokens": ["Dort", "barg", "ich", "mein", "Ant\u00b7litz", "im", "feuch\u00b7ten", "Gras"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und rief: Meine Zeit ist um;", "tokens": ["Und", "rief", ":", "Mei\u00b7ne", "Zeit", "ist", "um", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "APPR", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mich reut, was ich that \u2013 und dies und das;", "tokens": ["Mich", "reut", ",", "was", "ich", "that", "\u2013", "und", "dies", "und", "das", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$(", "KON", "PDS", "KON", "PDS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch ihr armes Grab blieb stumm.", "tokens": ["Doch", "ihr", "ar\u00b7mes", "Grab", "blieb", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Da schrieb ich auf den bemoosten Stein,", "tokens": ["Da", "schrieb", "ich", "auf", "den", "be\u00b7moos\u00b7ten", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun ihres Grabes sch\u00f6nste Zier:", "tokens": ["Nun", "ih\u00b7res", "Gra\u00b7bes", "sch\u00f6ns\u00b7te", "Zier", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier liegt Ellen Adairs Gebein,", "tokens": ["Hier", "liegt", "El\u00b7len", "A\u00b7dairs", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und auch Edwards Herz liegt hier.", "tokens": ["Und", "auch", "Ed\u00b7wards", "Herz", "liegt", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie V\u00f6gel flattern von Baum zu Baum,", "tokens": ["Wie", "V\u00f6\u00b7gel", "flat\u00b7tern", "von", "Baum", "zu", "Baum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVINF", "APPR", "NE", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So mag Liebe kommen und gehn.", "tokens": ["So", "mag", "Lie\u00b7be", "kom\u00b7men", "und", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "S\u00fc\u00dfe Emma Moreland, mein einziger Traum", "tokens": ["S\u00fc\u00b7\u00dfe", "Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "mein", "ein\u00b7zi\u00b7ger", "Traum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "NE", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Ist, Ellen wiederzusehn.", "tokens": ["Ist", ",", "El\u00b7len", "wie\u00b7der\u00b7zu\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.9": {"line.1": {"text": "Bitterlich weinte ich \u00fcber den Stein,", "tokens": ["Bit\u00b7ter\u00b7lich", "wein\u00b7te", "ich", "\u00fc\u00b7ber", "den", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Bitterlich weinend geh' ich fort:", "tokens": ["Bit\u00b7ter\u00b7lich", "wei\u00b7nend", "geh'", "ich", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Dort liegt Ellen Adairs Gebein,", "tokens": ["Dort", "liegt", "El\u00b7len", "A\u00b7dairs", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch auch Edwards Herz liegt dort!\u00ab", "tokens": ["Doch", "auch", "Ed\u00b7wards", "Herz", "liegt", "dort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "NE", "NN", "VVFIN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Emma Moreland, das freundliche Kind,", "tokens": ["Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "das", "freund\u00b7li\u00b7che", "Kind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Traf mich drau\u00dfen und kam auf mich zu:", "tokens": ["Traf", "mich", "drau\u00b7\u00dfen", "und", "kam", "auf", "mich", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "KON", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "\u00bbhast dein Herz verloren?\u00ab frug sie geschwind,", "tokens": ["\u00bb", "hast", "dein", "Herz", "ver\u00b7lo\u00b7ren", "?", "\u00ab", "frug", "sie", "ge\u00b7schwind", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VAFIN", "PPOSAT", "NN", "VVPP", "$.", "$(", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "\u00bbedward Gray, wann heiratest du?\u00ab", "tokens": ["\u00bb", "ed\u00b7ward", "Gray", ",", "wann", "hei\u00b7ra\u00b7test", "du", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "NE", "$,", "PWAV", "VVFIN", "PPER", "$.", "$("], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.11": {"line.1": {"text": "Als sie mich so zur Beichte gekriegt,", "tokens": ["Als", "sie", "mich", "so", "zur", "Beich\u00b7te", "ge\u00b7kriegt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "O da weinte ich bitterlich:", "tokens": ["O", "da", "wein\u00b7te", "ich", "bit\u00b7ter\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "PPER", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "\u00bbs\u00fc\u00dfe Emma Moreland, ewig versiegt", "tokens": ["\u00bb", "s\u00fc\u00b7\u00dfe", "Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "e\u00b7wig", "ver\u00b7siegt"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word"], "pos": ["$(", "VVFIN", "NE", "NE", "$,", "ADJD", "VVPP"], "meter": "+-+-+--+--+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Ist der Liebe Born f\u00fcr mich!", "tokens": ["Ist", "der", "Lie\u00b7be", "Born", "f\u00fcr", "mich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "NE", "APPR", "PPER", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Inniglich liebte mich Ellen Adair;", "tokens": ["In\u00b7nig\u00b7lich", "lieb\u00b7te", "mich", "El\u00b7len", "A\u00b7dair", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "NE", "$."], "meter": "---+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Vater und Mutter wurden ihr gram \u2013", "tokens": ["Va\u00b7ter", "und", "Mut\u00b7ter", "wur\u00b7den", "ihr", "gram", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "PPER", "ADJD", "$("], "meter": "+--+-+--+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Dort liegt sie begraben, \u2013 frage nicht mehr,", "tokens": ["Dort", "liegt", "sie", "be\u00b7gra\u00b7ben", ",", "\u2013", "fra\u00b7ge", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVPP", "$,", "$(", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Von wannen ich eben kam.", "tokens": ["Von", "wan\u00b7nen", "ich", "e\u00b7ben", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.13": {"line.1": {"text": "Scheu war sie, nicht kalt, \u2013 ich wu\u00dft' es zu sp\u00e4t;", "tokens": ["Scheu", "war", "sie", ",", "nicht", "kalt", ",", "\u2013", "ich", "wu\u00dft'", "es", "zu", "sp\u00e4t", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "PTKNEG", "ADJD", "$,", "$(", "PPER", "VVFIN", "PPER", "PTKA", "ADJD", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Denn ich mied, ja ich mied sie lang',", "tokens": ["Denn", "ich", "mied", ",", "ja", "ich", "mied", "sie", "lang'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "ADV", "PPER", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Strich durch die Meere, von Hochmut gebl\u00e4ht,", "tokens": ["Strich", "durch", "die", "Mee\u00b7re", ",", "von", "Hoch\u00b7mut", "ge\u00b7bl\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Als sie mit dem Tode rang.", "tokens": ["Als", "sie", "mit", "dem", "To\u00b7de", "rang", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Grausame Worte, die sie geh\u00f6rt,", "tokens": ["Grau\u00b7sa\u00b7me", "Wor\u00b7te", ",", "die", "sie", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "O wie thun sie mir jetzt so weh!", "tokens": ["O", "wie", "thun", "sie", "mir", "jetzt", "so", "weh", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KOKOM", "VVFIN", "PPER", "PPER", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bist ein eitles Ding, so sprach ich beth\u00f6rt,", "tokens": ["Bist", "ein", "eit\u00b7les", "Ding", ",", "so", "sprach", "ich", "be\u00b7th\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "ADV", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.4": {"text": "Gar zu leicht f\u00fcr Edward Gray.", "tokens": ["Gar", "zu", "leicht", "f\u00fcr", "Ed\u00b7ward", "Gray", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKA", "ADJD", "APPR", "NE", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Dort barg ich mein Antlitz im feuchten Gras", "tokens": ["Dort", "barg", "ich", "mein", "Ant\u00b7litz", "im", "feuch\u00b7ten", "Gras"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADJA", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Und rief: Meine Zeit ist um;", "tokens": ["Und", "rief", ":", "Mei\u00b7ne", "Zeit", "ist", "um", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "PPOSAT", "NN", "VAFIN", "APPR", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Mich reut, was ich that \u2013 und dies und das;", "tokens": ["Mich", "reut", ",", "was", "ich", "that", "\u2013", "und", "dies", "und", "das", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "PPER", "VVFIN", "$(", "KON", "PDS", "KON", "PDS", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Doch ihr armes Grab blieb stumm.", "tokens": ["Doch", "ihr", "ar\u00b7mes", "Grab", "blieb", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Da schrieb ich auf den bemoosten Stein,", "tokens": ["Da", "schrieb", "ich", "auf", "den", "be\u00b7moos\u00b7ten", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Nun ihres Grabes sch\u00f6nste Zier:", "tokens": ["Nun", "ih\u00b7res", "Gra\u00b7bes", "sch\u00f6ns\u00b7te", "Zier", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hier liegt Ellen Adairs Gebein,", "tokens": ["Hier", "liegt", "El\u00b7len", "A\u00b7dairs", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Und auch Edwards Herz liegt hier.", "tokens": ["Und", "auch", "Ed\u00b7wards", "Herz", "liegt", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NE", "NN", "VVFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Wie V\u00f6gel flattern von Baum zu Baum,", "tokens": ["Wie", "V\u00f6\u00b7gel", "flat\u00b7tern", "von", "Baum", "zu", "Baum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVINF", "APPR", "NE", "APPR", "NE", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "So mag Liebe kommen und gehn.", "tokens": ["So", "mag", "Lie\u00b7be", "kom\u00b7men", "und", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "NN", "VVINF", "KON", "VVINF", "$."], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "S\u00fc\u00dfe Emma Moreland, mein einziger Traum", "tokens": ["S\u00fc\u00b7\u00dfe", "Em\u00b7ma", "Mo\u00b7re\u00b7land", ",", "mein", "ein\u00b7zi\u00b7ger", "Traum"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "NE", "NE", "$,", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.4": {"text": "Ist, Ellen wiederzusehn.", "tokens": ["Ist", ",", "El\u00b7len", "wie\u00b7der\u00b7zu\u00b7sehn", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "$,", "NN", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}}, "stanza.18": {"line.1": {"text": "Bitterlich weinte ich \u00fcber den Stein,", "tokens": ["Bit\u00b7ter\u00b7lich", "wein\u00b7te", "ich", "\u00fc\u00b7ber", "den", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.2": {"text": "Bitterlich weinend geh' ich fort:", "tokens": ["Bit\u00b7ter\u00b7lich", "wei\u00b7nend", "geh'", "ich", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Dort liegt Ellen Adairs Gebein,", "tokens": ["Dort", "liegt", "El\u00b7len", "A\u00b7dairs", "Ge\u00b7bein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "NE", "NN", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Doch auch Edwards Herz liegt dort!\u00ab", "tokens": ["Doch", "auch", "Ed\u00b7wards", "Herz", "liegt", "dort", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "NE", "NN", "VVFIN", "ADV", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}