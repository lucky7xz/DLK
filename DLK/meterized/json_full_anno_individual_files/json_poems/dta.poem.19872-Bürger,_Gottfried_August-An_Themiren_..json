{"dta.poem.19872": {"metadata": {"author": {"name": "B\u00fcrger, Gottfried August", "birth": "N.A.", "death": "N.A."}, "title": "An Themiren .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1778", "urn": "urn:nbn:de:kobv:b4-20090519672", "language": ["de:0.99"], "booktitle": "B\u00fcrger, Gottfried August: Gedichte. G\u00f6ttingen, 1778."}, "poem": {"stanza.1": {"line.1": {"text": "Ach, w\u00fcrden falsche Schw\u00fcre               ", "tokens": ["Ach", ",", "w\u00fcr\u00b7den", "fal\u00b7sche", "Schw\u00fc\u00b7re"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "VAFIN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Durch Zeichen an dir kund!", "tokens": ["Durch", "Zei\u00b7chen", "an", "dir", "kund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Verf\u00e4rbte sich, Themire,", "tokens": ["Ver\u00b7f\u00e4rb\u00b7te", "sich", ",", "The\u00b7mi\u00b7re", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dein frevelhafter Mund!", "tokens": ["Dein", "fre\u00b7vel\u00b7haf\u00b7ter", "Mund", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O, da\u00df ein Zahn sich schw\u00e4rzte,", "tokens": ["O", ",", "da\u00df", "ein", "Zahn", "sich", "schw\u00e4rz\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KOUS", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Meineidige! da\u00df nur", "tokens": ["Mei\u00b7nei\u00b7di\u00b7ge", "!", "da\u00df", "nur"], "token_info": ["word", "punct", "word", "word"], "pos": ["PIS", "$.", "KOUS", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Fingerchen dir schmerzte,", "tokens": ["Ein", "Fin\u00b7ge\u00b7rchen", "dir", "schmerz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das sich erhob zum Schwur!", "tokens": ["Das", "sich", "er\u00b7hob", "zum", "Schwur", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "VVFIN", "APPRART", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "So glaubt\u2019 ich, G\u00f6tter hielten", "tokens": ["So", "glaubt'", "ich", ",", "G\u00f6t\u00b7ter", "hiel\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Noch was auf Treu\u2019 und Pflicht,", "tokens": ["Noch", "was", "auf", "Treu'", "und", "Pflicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und falsche M\u00e4dchen spielten", "tokens": ["Und", "fal\u00b7sche", "M\u00e4d\u00b7chen", "spiel\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit theuren Eiden nicht. \u2014", "tokens": ["Mit", "theu\u00b7ren", "Ei\u00b7den", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKNEG", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch deine Reize heben", "tokens": ["Doch", "dei\u00b7ne", "Rei\u00b7ze", "he\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Verbrechen nur noch mehr;", "tokens": ["Ver\u00b7bre\u00b7chen", "nur", "noch", "mehr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und immer dichter schweben", "tokens": ["Und", "im\u00b7mer", "dich\u00b7ter", "schwe\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Verehrer um dich her.", "tokens": ["Ver\u00b7eh\u00b7rer", "um", "dich", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Frau Venus und ihr V\u00f6lkchen", "tokens": ["Frau", "Ve\u00b7nus", "und", "ihr", "V\u00f6lk\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NE", "KON", "PPOSAT", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "L\u00e4st f\u00fcnf gerade seyn.", "tokens": ["L\u00e4st", "f\u00fcnf", "ge\u00b7ra\u00b7de", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "CARD", "ADV", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Unmut nicht ein W\u00f6lkchen", "tokens": ["Von", "Un\u00b7mut", "nicht", "ein", "W\u00f6lk\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKNEG", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "H\u00fclt ihre Stirnen ein.", "tokens": ["H\u00fclt", "ih\u00b7re", "Stir\u00b7nen", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Per Dio! was noch schlimmer,", "tokens": ["Per", "Dio", "!", "was", "noch", "schlim\u00b7mer", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PWS", "ADV", "ADJD", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Dein Flattersin erg\u00f6zt", "tokens": ["Dein", "Flat\u00b7ter\u00b7sin", "er\u00b7g\u00f6zt"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Den Schadenfroh, der immer", "tokens": ["Den", "Scha\u00b7den\u00b7froh", ",", "der", "im\u00b7mer"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "An heissen Pfeilen wezt.", "tokens": ["An", "heis\u00b7sen", "Pfei\u00b7len", "wezt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Daher in allen Schulen", "tokens": ["Da\u00b7her", "in", "al\u00b7len", "Schu\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Befiedert t\u00e4glich sich", "tokens": ["Be\u00b7fie\u00b7dert", "t\u00e4g\u00b7lich", "sich"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "ADJD", "PRF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Heer von jungen Bulen,", "tokens": ["Ein", "Heer", "von", "jun\u00b7gen", "Bu\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und insgesamt f\u00fcr dich.", "tokens": ["Und", "ins\u00b7ge\u00b7samt", "f\u00fcr", "dich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Die kommen dann, und zollen", "tokens": ["Die", "kom\u00b7men", "dann", ",", "und", "zol\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VVFIN", "ADV", "$,", "KON", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Dir Huldigung und Pflicht.", "tokens": ["Dir", "Hul\u00b7di\u00b7gung", "und", "Pflicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Die Alten aber trollen", "tokens": ["Die", "Al\u00b7ten", "a\u00b7ber", "trol\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Deswegen sich noch nicht.", "tokens": ["Des\u00b7we\u00b7gen", "sich", "noch", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "PRF", "ADV", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und Alt und Jung umschw\u00e4rmet", "tokens": ["Und", "Alt", "und", "Jung", "um\u00b7schw\u00e4r\u00b7met"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "KON", "NN", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nun, wie behext, dein Haus.", "tokens": ["Nun", ",", "wie", "be\u00b7hext", ",", "dein", "Haus", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "ADJD", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Man baxet sich, man l\u00e4rmet \u2012 \u2012 \u2012", "tokens": ["Man", "ba\u00b7xet", "sich", ",", "man", "l\u00e4r\u00b7met", "\u2012", "\u2012", "\u2012"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "$,", "PIS", "VVFIN", "$(", "$(", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ach! wo wil das hinaus? \u2014", "tokens": ["Ach", "!", "wo", "wil", "das", "hin\u00b7aus", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ITJ", "$.", "PWAV", "VMFIN", "PDS", "PTKVZ", "$.", "$("], "meter": "+-+---", "measure": "unknown.measure.di"}}, "stanza.10": {"line.1": {"text": "Dich scheut, des S\u00f6hnchens wegen,", "tokens": ["Dich", "scheut", ",", "des", "S\u00f6hn\u00b7chens", "we\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die z\u00e4rtliche Mama;", "tokens": ["Die", "z\u00e4rt\u00b7li\u00b7che", "Ma\u00b7ma", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und, seines Beutels wegen,", "tokens": ["Und", ",", "sei\u00b7nes", "Beu\u00b7tels", "we\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PPOSAT", "NN", "APPR", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der geizige Papa.", "tokens": ["Der", "gei\u00b7zi\u00b7ge", "Pa\u00b7pa", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Du \u00e4ngstigst junge Frauen:", "tokens": ["Du", "\u00e4ngs\u00b7tigst", "jun\u00b7ge", "Frau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es m\u00f6chte deinen Wehrt", "tokens": ["Es", "m\u00f6ch\u00b7te", "dei\u00b7nen", "Wehrt"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Tr\u00f6pfchen Gunst bethauen,", "tokens": ["Ein", "Tr\u00f6pf\u00b7chen", "Gunst", "be\u00b7thau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Das ihnen zugeh\u00f6rt.", "tokens": ["Das", "ih\u00b7nen", "zu\u00b7ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "PPER", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}