{"textgrid.poem.32836": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was f\u00e4llt doch meiner Mutter ein!", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was f\u00e4llt doch meiner Mutter ein!", "tokens": ["Was", "f\u00e4llt", "doch", "mei\u00b7ner", "Mut\u00b7ter", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vorzeiten lie\u00df sie mich allein:", "tokens": ["Vor\u00b7zei\u00b7ten", "lie\u00df", "sie", "mich", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt keinen Augenblick.", "tokens": ["Jetzt", "kei\u00b7nen", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich geh ins Feld, ich geh in Hayn,", "tokens": ["Ich", "geh", "ins", "Feld", ",", "ich", "geh", "in", "Hayn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gleich h\u00f6r ich sie von weiten schreyn:", "tokens": ["Gleich", "h\u00f6r", "ich", "sie", "von", "wei\u00b7ten", "schreyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbheh, M\u00e4dchen, komm zur\u00fcck!\u00ab", "tokens": ["\u00bb", "heh", ",", "M\u00e4d\u00b7chen", ",", "komm", "zu\u00b7r\u00fcck", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Wie ist der guten Mutter bang,", "tokens": ["Wie", "ist", "der", "gu\u00b7ten", "Mut\u00b7ter", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00fcrde mir die Zeit zu lang?", "tokens": ["Als", "w\u00fcr\u00b7de", "mir", "die", "Zeit", "zu", "lang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja, daf\u00fcr steh ich ihr.", "tokens": ["Ja", ",", "da\u00b7f\u00fcr", "steh", "ich", "ihr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich geh da, oder dorten hin,", "tokens": ["Ich", "geh", "da", ",", "o\u00b7der", "dor\u00b7ten", "hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Thyrsis wei\u00df schon, wo ich bin,", "tokens": ["Mein", "Thyr\u00b7sis", "wei\u00df", "schon", ",", "wo", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und alsdann \u2013 \u2013 spielen wir.", "tokens": ["Und", "als\u00b7dann", "\u2013", "\u2013", "spie\u00b7len", "wir", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Denkt sie, wenn sie nicht bey mir ist,", "tokens": ["Denkt", "sie", ",", "wenn", "sie", "nicht", "bey", "mir", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mir der Wolf mein Sch\u00e4fgen fri\u00dft?", "tokens": ["Da\u00df", "mir", "der", "Wolf", "mein", "Sch\u00e4f\u00b7gen", "fri\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn nie verl\u00e4\u00dft es mich.", "tokens": ["Denn", "nie", "ver\u00b7l\u00e4\u00dft", "es", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ey, ja doch, das hat gro\u00dfe Noth:", "tokens": ["Ey", ",", "ja", "doch", ",", "das", "hat", "gro\u00b7\u00dfe", "Noth", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "$,", "PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich glaube, Thyrsis schl\u00fcg ihn todt:", "tokens": ["Ich", "glau\u00b7be", ",", "Thyr\u00b7sis", "schl\u00fcg", "ihn", "todt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er liebt es mehr als ich!", "tokens": ["Er", "liebt", "es", "mehr", "als", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was f\u00e4llt doch meiner Mutter ein!", "tokens": ["Was", "f\u00e4llt", "doch", "mei\u00b7ner", "Mut\u00b7ter", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vorzeiten lie\u00df sie mich allein:", "tokens": ["Vor\u00b7zei\u00b7ten", "lie\u00df", "sie", "mich", "al\u00b7lein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Jetzt keinen Augenblick.", "tokens": ["Jetzt", "kei\u00b7nen", "Au\u00b7gen\u00b7blick", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich geh ins Feld, ich geh in Hayn,", "tokens": ["Ich", "geh", "ins", "Feld", ",", "ich", "geh", "in", "Hayn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "PPER", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gleich h\u00f6r ich sie von weiten schreyn:", "tokens": ["Gleich", "h\u00f6r", "ich", "sie", "von", "wei\u00b7ten", "schreyn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "APPR", "ADJA", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "\u00bbheh, M\u00e4dchen, komm zur\u00fcck!\u00ab", "tokens": ["\u00bb", "heh", ",", "M\u00e4d\u00b7chen", ",", "komm", "zu\u00b7r\u00fcck", "!", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "VVFIN", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Wie ist der guten Mutter bang,", "tokens": ["Wie", "ist", "der", "gu\u00b7ten", "Mut\u00b7ter", "bang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als w\u00fcrde mir die Zeit zu lang?", "tokens": ["Als", "w\u00fcr\u00b7de", "mir", "die", "Zeit", "zu", "lang", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ART", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ja, daf\u00fcr steh ich ihr.", "tokens": ["Ja", ",", "da\u00b7f\u00fcr", "steh", "ich", "ihr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PAV", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ich geh da, oder dorten hin,", "tokens": ["Ich", "geh", "da", ",", "o\u00b7der", "dor\u00b7ten", "hin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mein Thyrsis wei\u00df schon, wo ich bin,", "tokens": ["Mein", "Thyr\u00b7sis", "wei\u00df", "schon", ",", "wo", "ich", "bin", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "$,", "PWAV", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und alsdann \u2013 \u2013 spielen wir.", "tokens": ["Und", "als\u00b7dann", "\u2013", "\u2013", "spie\u00b7len", "wir", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "$(", "VVFIN", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Denkt sie, wenn sie nicht bey mir ist,", "tokens": ["Denkt", "sie", ",", "wenn", "sie", "nicht", "bey", "mir", "ist", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "PTKNEG", "APPR", "PPER", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df mir der Wolf mein Sch\u00e4fgen fri\u00dft?", "tokens": ["Da\u00df", "mir", "der", "Wolf", "mein", "Sch\u00e4f\u00b7gen", "fri\u00dft", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NE", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Denn nie verl\u00e4\u00dft es mich.", "tokens": ["Denn", "nie", "ver\u00b7l\u00e4\u00dft", "es", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ey, ja doch, das hat gro\u00dfe Noth:", "tokens": ["Ey", ",", "ja", "doch", ",", "das", "hat", "gro\u00b7\u00dfe", "Noth", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADV", "$,", "PDS", "VAFIN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich glaube, Thyrsis schl\u00fcg ihn todt:", "tokens": ["Ich", "glau\u00b7be", ",", "Thyr\u00b7sis", "schl\u00fcg", "ihn", "todt", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NE", "VVFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er liebt es mehr als ich!", "tokens": ["Er", "liebt", "es", "mehr", "als", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}