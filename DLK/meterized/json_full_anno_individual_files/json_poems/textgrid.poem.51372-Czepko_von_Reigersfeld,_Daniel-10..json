{"textgrid.poem.51372": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "10.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "G\u00f6ttin, ist das Recht gethan", "tokens": ["G\u00f6t\u00b7tin", ",", "ist", "das", "Recht", "ge\u00b7than"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil ich auf und nieder gehe,", "tokens": ["Weil", "ich", "auf", "und", "nie\u00b7der", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKVZ", "KON", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am Fenster stille stehe,", "tokens": ["Und", "am", "Fens\u00b7ter", "stil\u00b7le", "ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stellest du dich Seiten an.", "tokens": ["Stel\u00b7lest", "du", "dich", "Sei\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "H\u00f6fflich redest du mit mir,", "tokens": ["H\u00f6ff\u00b7lich", "re\u00b7dest", "du", "mit", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als ich mich zu dir wil b\u00fccken,", "tokens": ["Als", "ich", "mich", "zu", "dir", "wil", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reicht dein Knabe hinterm R\u00fccken", "tokens": ["Reicht", "dein", "Kna\u00b7be", "hin\u00b7term", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein gespanntes Hand Rohr dir.", "tokens": ["Ein", "ge\u00b7spann\u00b7tes", "Hand", "Rohr", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PPER", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.3": {"line.1": {"text": "Eh, als ich nehm es in acht,", "tokens": ["Eh", ",", "als", "ich", "nehm", "es", "in", "acht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVFIN", "PPER", "APPR", "CARD", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Giebst du Feuer. Ach! Der Laugen!", "tokens": ["Giebst", "du", "Feu\u00b7er", ".", "Ach", "!", "Der", "Lau\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$.", "ITJ", "$.", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fenster aus vor meinen Augen,", "tokens": ["Fens\u00b7ter", "aus", "vor", "mei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es auf dem Marckte kracht.", "tokens": ["Da\u00df", "es", "auf", "dem", "Marck\u00b7te", "kracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Aber, was ist dieser Schu\u00df?", "tokens": ["A\u00b7ber", ",", "was", "ist", "die\u00b7ser", "Schu\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VAFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Augen Blicke machen,", "tokens": ["Dei\u00b7ner", "Au\u00b7gen", "Bli\u00b7cke", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich st\u00fcndlich sonder Krachen", "tokens": ["Da\u00df", "ich", "st\u00fcnd\u00b7lich", "son\u00b7der", "Kra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hundertmal vergehen mu\u00df.", "tokens": ["Hun\u00b7dert\u00b7mal", "ver\u00b7ge\u00b7hen", "mu\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Kan dein Liedermacherlein", "tokens": ["Kan", "dein", "Lie\u00b7der\u00b7ma\u00b7cher\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "G\u00f6ttin, eine Gnad erwerben:", "tokens": ["G\u00f6t\u00b7tin", ",", "ei\u00b7ne", "Gnad", "er\u00b7wer\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df mich ungemartert sterben,", "tokens": ["La\u00df", "mich", "un\u00b7ge\u00b7mar\u00b7tert", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Her Rohr. Weg der Augen Schein.", "tokens": ["Her", "Rohr", ".", "Weg", "der", "Au\u00b7gen", "Schein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "NN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "G\u00f6ttin, ist das Recht gethan", "tokens": ["G\u00f6t\u00b7tin", ",", "ist", "das", "Recht", "ge\u00b7than"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "VAFIN", "ART", "NN", "VVPP"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Weil ich auf und nieder gehe,", "tokens": ["Weil", "ich", "auf", "und", "nie\u00b7der", "ge\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKVZ", "KON", "PTKVZ", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und am Fenster stille stehe,", "tokens": ["Und", "am", "Fens\u00b7ter", "stil\u00b7le", "ste\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "ADJA", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Stellest du dich Seiten an.", "tokens": ["Stel\u00b7lest", "du", "dich", "Sei\u00b7ten", "an", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "H\u00f6fflich redest du mit mir,", "tokens": ["H\u00f6ff\u00b7lich", "re\u00b7dest", "du", "mit", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Als ich mich zu dir wil b\u00fccken,", "tokens": ["Als", "ich", "mich", "zu", "dir", "wil", "b\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "APPR", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reicht dein Knabe hinterm R\u00fccken", "tokens": ["Reicht", "dein", "Kna\u00b7be", "hin\u00b7term", "R\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ein gespanntes Hand Rohr dir.", "tokens": ["Ein", "ge\u00b7spann\u00b7tes", "Hand", "Rohr", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "PPER", "$."], "meter": "+-+-+--", "measure": "unknown.measure.tri"}}, "stanza.8": {"line.1": {"text": "Eh, als ich nehm es in acht,", "tokens": ["Eh", ",", "als", "ich", "nehm", "es", "in", "acht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "VVFIN", "PPER", "APPR", "CARD", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Giebst du Feuer. Ach! Der Laugen!", "tokens": ["Giebst", "du", "Feu\u00b7er", ".", "Ach", "!", "Der", "Lau\u00b7gen", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "$.", "ITJ", "$.", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Fenster aus vor meinen Augen,", "tokens": ["Fens\u00b7ter", "aus", "vor", "mei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Da\u00df es auf dem Marckte kracht.", "tokens": ["Da\u00df", "es", "auf", "dem", "Marck\u00b7te", "kracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Aber, was ist dieser Schu\u00df?", "tokens": ["A\u00b7ber", ",", "was", "ist", "die\u00b7ser", "Schu\u00df", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "VAFIN", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Deiner Augen Blicke machen,", "tokens": ["Dei\u00b7ner", "Au\u00b7gen", "Bli\u00b7cke", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "NN", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df ich st\u00fcndlich sonder Krachen", "tokens": ["Da\u00df", "ich", "st\u00fcnd\u00b7lich", "son\u00b7der", "Kra\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hundertmal vergehen mu\u00df.", "tokens": ["Hun\u00b7dert\u00b7mal", "ver\u00b7ge\u00b7hen", "mu\u00df", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Kan dein Liedermacherlein", "tokens": ["Kan", "dein", "Lie\u00b7der\u00b7ma\u00b7cher\u00b7lein"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "G\u00f6ttin, eine Gnad erwerben:", "tokens": ["G\u00f6t\u00b7tin", ",", "ei\u00b7ne", "Gnad", "er\u00b7wer\u00b7ben", ":"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00df mich ungemartert sterben,", "tokens": ["La\u00df", "mich", "un\u00b7ge\u00b7mar\u00b7tert", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Her Rohr. Weg der Augen Schein.", "tokens": ["Her", "Rohr", ".", "Weg", "der", "Au\u00b7gen", "Schein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "NN", "ART", "NN", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}