{"textgrid.poem.64131": {"metadata": {"author": {"name": "Dahn, Felix", "birth": "N.A.", "death": "N.A."}, "title": "Die rote Erde", "genre": "verse", "period": "N.A.", "pub_year": 1873, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Herrn Kaiser Karl zu Aachen", "tokens": ["Herrn", "Kai\u00b7ser", "Karl", "zu", "Aa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "NE", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kam's \u00fcber die Augen schwer:", "tokens": ["Kam's", "\u00fc\u00b7ber", "die", "Au\u00b7gen", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbich f\u00fchl's, nicht wird mich w\u00e4rmen", "tokens": ["\u00bb", "ich", "f\u00fchl's", ",", "nicht", "wird", "mich", "w\u00e4r\u00b7men"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "PTKNEG", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Fr\u00fchlingssonne mehr.", "tokens": ["Die", "Fr\u00fch\u00b7lings\u00b7son\u00b7ne", "mehr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Noch einmal mu\u00df ich umschaun,", "tokens": ["Noch", "ein\u00b7mal", "mu\u00df", "ich", "um\u00b7schaun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Wie's steht in meinem Reich:", "tokens": ["Wie's", "steht", "in", "mei\u00b7nem", "Reich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O w\u00e4r' ich bei Awaren", "tokens": ["O", "w\u00e4r'", "ich", "bei", "A\u00b7wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Arabern zugleich!", "tokens": ["Und", "A\u00b7ra\u00b7bern", "zu\u00b7gleich", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Zugleich am gelben Tiber,", "tokens": ["Zu\u00b7gleich", "am", "gel\u00b7ben", "Ti\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zugleich am gr\u00fcnen Rhein:", "tokens": ["Zu\u00b7gleich", "am", "gr\u00fc\u00b7nen", "Rhein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu gro\u00df ist ach! das Erbe,", "tokens": ["Zu", "gro\u00df", "ist", "ach", "!", "das", "Er\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "ADV", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Erbe, weh! zu klein. \u2013 \u2013", "tokens": ["Der", "Er\u00b7be", ",", "weh", "!", "zu", "klein", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "$,", "PTKVZ", "$.", "PTKA", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Die N\u00e4chsten sind die Sachsen:", "tokens": ["Die", "N\u00e4chs\u00b7ten", "sind", "die", "Sach\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bis dorthin reicht's wohl noch;", "tokens": ["Bis", "dor\u00b7thin", "reicht's", "wohl", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie k\u00e4mpften drei\u00dfig Jahre,", "tokens": ["Sie", "k\u00e4mpf\u00b7ten", "drei\u00b7\u00dfig", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ich bezwang sie doch!\u00ab \u2013", "tokens": ["Und", "ich", "be\u00b7zwang", "sie", "doch", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er zieht mit Graf und Bischof", "tokens": ["Er", "zieht", "mit", "Graf", "und", "Bi\u00b7schof"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nochmal durch Sachsenland:", "tokens": ["Noch\u00b7mal", "durch", "Sach\u00b7sen\u00b7land", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der M\u00e4nner sieht man wenig: \u2013", "tokens": ["Der", "M\u00e4n\u00b7ner", "sieht", "man", "we\u00b7nig", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PIS", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tot sind sie, landverbannt.", "tokens": ["Tot", "sind", "sie", ",", "land\u00b7ver\u00b7bannt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Auf \u00f6der, brauner Heide,", "tokens": ["Auf", "\u00f6\u00b7der", ",", "brau\u00b7ner", "Hei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Eichbaum \u00fcberragt,", "tokens": ["Vom", "Eich\u00b7baum", "\u00fc\u00b7berr\u00b7agt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Liegt ein Geh\u00f6ft, den Dachfirst", "tokens": ["Liegt", "ein", "Ge\u00b7h\u00f6ft", ",", "den", "Dach\u00b7first"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Ro\u00dfkopf \u00fcberschragt.", "tokens": ["Vom", "Ro\u00df\u00b7kopf", "\u00fc\u00b7bersc\u00b7hragt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Welk \u00fcber'n tiefen Ziehbrunn", "tokens": ["Welk", "\u00fc\u00b7ber'n", "tie\u00b7fen", "Zieh\u00b7brunn"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nickt der Holunder schwer:", "tokens": ["Nickt", "der", "Ho\u00b7lun\u00b7der", "schwer", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und frische H\u00fcgelgr\u00e4ber, \u2013", "tokens": ["Und", "fri\u00b7sche", "H\u00fc\u00b7gel\u00b7gr\u00e4\u00b7ber", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sehr viele! \u2013 rings umher. \u2013", "tokens": ["Sehr", "vie\u00b7le", "!", "\u2013", "rings", "um\u00b7her", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "PIS", "$.", "$(", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ein Weib tritt auf die Schwelle:", "tokens": ["Ein", "Weib", "tritt", "auf", "die", "Schwel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es zerren an ihrem Rock", "tokens": ["Es", "zer\u00b7ren", "an", "ih\u00b7rem", "Rock"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die Knaben mit dem Trutzblick,", "tokens": ["Die", "Kna\u00b7ben", "mit", "dem", "Trutz\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die M\u00e4dchen im Flachsgelock.", "tokens": ["Die", "M\u00e4d\u00b7chen", "im", "Flachs\u00b7ge\u00b7lock", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Sie gaffen auf die Fremden,", "tokens": ["Sie", "gaf\u00b7fen", "auf", "die", "Frem\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf die bunte Reiterschar:", "tokens": ["Auf", "die", "bun\u00b7te", "Rei\u00b7ter\u00b7schar", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Es beugt sich aus der S\u00e4nfte", "tokens": ["Es", "beugt", "sich", "aus", "der", "S\u00e4nf\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Mann in wei\u00dfem Haar.", "tokens": ["Ein", "Mann", "in", "wei\u00b7\u00dfem", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Er streicht den Kopf dem J\u00fcngsten:", "tokens": ["Er", "streicht", "den", "Kopf", "dem", "J\u00fcng\u00b7sten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der greift nach der Spange licht:", "tokens": ["Der", "greift", "nach", "der", "Span\u00b7ge", "licht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwer ist's?\u00ab forscht scheu die Mutter.", "tokens": ["\u00bb", "wer", "ist's", "?", "\u00ab", "forscht", "scheu", "die", "Mut\u00b7ter", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "$.", "$(", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbherr Karl! \u2013 Kennst du ihn nicht?\u00ab", "tokens": ["\u00bb", "herr", "Karl", "!", "\u2013", "Kennst", "du", "ihn", "nicht", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "NE", "$.", "$(", "VVFIN", "PPER", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Laut auf kreischt die Entsetzte", "tokens": ["Laut", "auf", "kreischt", "die", "Ent\u00b7setz\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und rei\u00dft die Kinder fort:", "tokens": ["Und", "rei\u00dft", "die", "Kin\u00b7der", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.4": {"text": "Im nahen Buschwald dort. \u2013", "tokens": ["Im", "na\u00b7hen", "Busc\u00b7hwald", "dort", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Der Kaiser n\u00e4chtet im Kloster.", "tokens": ["Der", "Kai\u00b7ser", "n\u00e4ch\u00b7tet", "im", "Klos\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Leer ist's um den Altar:", "tokens": ["Leer", "ist's", "um", "den", "Al\u00b7tar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Laie, \u2013 nur die M\u00f6nche. \u2013", "tokens": ["Kein", "Lai\u00b7e", ",", "\u2013", "nur", "die", "M\u00f6n\u00b7che", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "$,", "$(", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbwas scheint dort fern so klar?", "tokens": ["\u00bb", "was", "scheint", "dort", "fern", "so", "klar", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Was leuchtet durch das Fenster?\u00ab", "tokens": ["Was", "leuch\u00b7tet", "durch", "das", "Fens\u00b7ter", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbo Herr \u2013 's ist nicht geheuer:", "tokens": ["\u00bb", "o", "Herr", "\u2013", "'s", "ist", "nicht", "ge\u00b7heu\u00b7er", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$(", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Sachsen sind's im Walde", "tokens": ["Die", "Sach\u00b7sen", "sin\u00b7d's", "im", "Wal\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bei Wodans Opferfeuer.\u00ab \u2013 \u2013", "tokens": ["Bei", "Wo\u00b7dans", "Op\u00b7fer\u00b7feu\u00b7er", ".", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$(", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Am andern Morgen rheinw\u00e4rts", "tokens": ["Am", "an\u00b7dern", "Mor\u00b7gen", "rhein\u00b7w\u00e4rts"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Kaiser kehrt die Fahrt;", "tokens": ["Der", "Kai\u00b7ser", "kehrt", "die", "Fahrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er schweigt. \u2013 Er betet manchmal;", "tokens": ["Er", "schweigt", ".", "\u2013", "Er", "be\u00b7tet", "manch\u00b7mal", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er streicht den wei\u00dfen Bart.", "tokens": ["Er", "streicht", "den", "wei\u00b7\u00dfen", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Das Ro\u00df f\u00fchrt ihm ein Sachse,", "tokens": ["Das", "Ro\u00df", "f\u00fchrt", "ihm", "ein", "Sach\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der alle Steige kennt.", "tokens": ["Der", "al\u00b7le", "Stei\u00b7ge", "kennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Erdreich steht zutage,", "tokens": ["Das", "Er\u00b7dreich", "steht", "zu\u00b7ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo der Pfad die H\u00fcgel trennt.", "tokens": ["Wo", "der", "Pfad", "die", "H\u00fc\u00b7gel", "trennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Warm dampft es aus den Schollen, \u2013", "tokens": ["Warm", "dampft", "es", "aus", "den", "Schol\u00b7len", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Karl beugt vom Sattel sich:", "tokens": ["Karl", "beugt", "vom", "Sat\u00b7tel", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbrot ist hier rings die Erde,", "tokens": ["\u00bb", "rot", "ist", "hier", "rings", "die", "Er\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Seit wann? Woher das? \u2013 Sprich!\u00ab", "tokens": ["Seit", "wann", "?", "Wo\u00b7her", "das", "?", "\u2013", "Sprich", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "PWAV", "$.", "PWAV", "PDS", "$.", "$(", "VVIMP", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.17": {"line.1": {"text": "Da hob der graue F\u00fchrer", "tokens": ["Da", "hob", "der", "grau\u00b7e", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu ihm den Blick empor:", "tokens": ["Zu", "ihm", "den", "Blick", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbgr\u00fcn war der Wiesenanger,", "tokens": ["\u00bb", "gr\u00fcn", "war", "der", "Wie\u00b7sen\u00b7an\u00b7ger", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die Heide braun zuvor;", "tokens": ["Die", "Hei\u00b7de", "braun", "zu\u00b7vor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Zweihunderttausend Sachsen,", "tokens": ["Zwei\u00b7hun\u00b7dert\u00b7tau\u00b7send", "Sach\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die starben blut'gen Tod: \u2013", "tokens": ["Die", "star\u00b7ben", "blut'\u00b7gen", "Tod", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Davon ist in Westfalen", "tokens": ["Da\u00b7von", "ist", "in", "West\u00b7fa\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "APPR", "NN"], "meter": "--+-+--", "measure": "anapaest.init"}, "line.4": {"text": "Die Erde worden rot.\u00ab", "tokens": ["Die", "Er\u00b7de", "wor\u00b7den", "rot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAPP", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Da sch\u00fcttelt Frost den Kaiser:", "tokens": ["Da", "sch\u00fct\u00b7telt", "Frost", "den", "Kai\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbso tief \u2013 die Erde rot?", "tokens": ["\u00bb", "so", "tief", "\u2013", "die", "Er\u00b7de", "rot", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$(", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Christus, l\u00f6sche die Farbe:", "tokens": ["Herr", "Chris\u00b7tus", ",", "l\u00f6\u00b7sche", "die", "Far\u00b7be", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ich tat's auf dein Gebot.\u00ab", "tokens": ["Ich", "tat's", "auf", "dein", "Ge\u00b7bot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Starr hat er in die Wolken, \u2013", "tokens": ["Starr", "hat", "er", "in", "die", "Wol\u00b7ken", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "PPER", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf den Boden starr gesehn:", "tokens": ["Auf", "den", "Bo\u00b7den", "starr", "ge\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Boden blieb derselbe: \u2013", "tokens": ["Der", "Bo\u00b7den", "blieb", "der\u00b7sel\u00b7be", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein Wunder ist geschehn. \u2013", "tokens": ["Kein", "Wun\u00b7der", "ist", "ge\u00b7schehn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Schwer krank kam er nach Aachen", "tokens": ["Schwer", "krank", "kam", "er", "nach", "Aa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VVFIN", "PPER", "APPR", "NE"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "In seinen goldnen Saal:", "tokens": ["In", "sei\u00b7nen", "gold\u00b7nen", "Saal", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er raunte mit sich selber,", "tokens": ["Er", "raun\u00b7te", "mit", "sich", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hauptsch\u00fcttelnd, manchesmal.", "tokens": ["Haupt\u00b7sch\u00fct\u00b7telnd", ",", "man\u00b7ches\u00b7mal", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Er fragte: \u00bbIst's ", "tokens": ["Er", "frag\u00b7te", ":", "\u00bb", "Ist's"], "token_info": ["word", "word", "punct", "punct", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Als er im Sterben lag. \u2013", "tokens": ["Als", "er", "im", "Ster\u00b7ben", "lag", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rot blieb Westfalens Erde", "tokens": ["Rot", "blieb", "West\u00b7fa\u00b7lens", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Bis auf den heut'gen Tag.", "tokens": ["Bis", "auf", "den", "heut'\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Herrn Kaiser Karl zu Aachen", "tokens": ["Herrn", "Kai\u00b7ser", "Karl", "zu", "Aa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "NN", "NE", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Kam's \u00fcber die Augen schwer:", "tokens": ["Kam's", "\u00fc\u00b7ber", "die", "Au\u00b7gen", "schwer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbich f\u00fchl's, nicht wird mich w\u00e4rmen", "tokens": ["\u00bb", "ich", "f\u00fchl's", ",", "nicht", "wird", "mich", "w\u00e4r\u00b7men"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "$,", "PTKNEG", "VAFIN", "PPER", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Fr\u00fchlingssonne mehr.", "tokens": ["Die", "Fr\u00fch\u00b7lings\u00b7son\u00b7ne", "mehr", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Noch einmal mu\u00df ich umschaun,", "tokens": ["Noch", "ein\u00b7mal", "mu\u00df", "ich", "um\u00b7schaun", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Wie's steht in meinem Reich:", "tokens": ["Wie's", "steht", "in", "mei\u00b7nem", "Reich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "O w\u00e4r' ich bei Awaren", "tokens": ["O", "w\u00e4r'", "ich", "bei", "A\u00b7wa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und Arabern zugleich!", "tokens": ["Und", "A\u00b7ra\u00b7bern", "zu\u00b7gleich", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Zugleich am gelben Tiber,", "tokens": ["Zu\u00b7gleich", "am", "gel\u00b7ben", "Ti\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zugleich am gr\u00fcnen Rhein:", "tokens": ["Zu\u00b7gleich", "am", "gr\u00fc\u00b7nen", "Rhein", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "ADJA", "NE", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu gro\u00df ist ach! das Erbe,", "tokens": ["Zu", "gro\u00df", "ist", "ach", "!", "das", "Er\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "VAFIN", "ADV", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Erbe, weh! zu klein. \u2013 \u2013", "tokens": ["Der", "Er\u00b7be", ",", "weh", "!", "zu", "klein", ".", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "punct"], "pos": ["ART", "NN", "$,", "PTKVZ", "$.", "PTKA", "ADJD", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Die N\u00e4chsten sind die Sachsen:", "tokens": ["Die", "N\u00e4chs\u00b7ten", "sind", "die", "Sach\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Bis dorthin reicht's wohl noch;", "tokens": ["Bis", "dor\u00b7thin", "reicht's", "wohl", "noch", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie k\u00e4mpften drei\u00dfig Jahre,", "tokens": ["Sie", "k\u00e4mpf\u00b7ten", "drei\u00b7\u00dfig", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ich bezwang sie doch!\u00ab \u2013", "tokens": ["Und", "ich", "be\u00b7zwang", "sie", "doch", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "$.", "$(", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Er zieht mit Graf und Bischof", "tokens": ["Er", "zieht", "mit", "Graf", "und", "Bi\u00b7schof"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NE", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nochmal durch Sachsenland:", "tokens": ["Noch\u00b7mal", "durch", "Sach\u00b7sen\u00b7land", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Der M\u00e4nner sieht man wenig: \u2013", "tokens": ["Der", "M\u00e4n\u00b7ner", "sieht", "man", "we\u00b7nig", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PIS", "PIS", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Tot sind sie, landverbannt.", "tokens": ["Tot", "sind", "sie", ",", "land\u00b7ver\u00b7bannt", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "PPER", "$,", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Auf \u00f6der, brauner Heide,", "tokens": ["Auf", "\u00f6\u00b7der", ",", "brau\u00b7ner", "Hei\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Vom Eichbaum \u00fcberragt,", "tokens": ["Vom", "Eich\u00b7baum", "\u00fc\u00b7berr\u00b7agt", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Liegt ein Geh\u00f6ft, den Dachfirst", "tokens": ["Liegt", "ein", "Ge\u00b7h\u00f6ft", ",", "den", "Dach\u00b7first"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Vom Ro\u00dfkopf \u00fcberschragt.", "tokens": ["Vom", "Ro\u00df\u00b7kopf", "\u00fc\u00b7bersc\u00b7hragt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Welk \u00fcber'n tiefen Ziehbrunn", "tokens": ["Welk", "\u00fc\u00b7ber'n", "tie\u00b7fen", "Zieh\u00b7brunn"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Nickt der Holunder schwer:", "tokens": ["Nickt", "der", "Ho\u00b7lun\u00b7der", "schwer", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.3": {"text": "Und frische H\u00fcgelgr\u00e4ber, \u2013", "tokens": ["Und", "fri\u00b7sche", "H\u00fc\u00b7gel\u00b7gr\u00e4\u00b7ber", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sehr viele! \u2013 rings umher. \u2013", "tokens": ["Sehr", "vie\u00b7le", "!", "\u2013", "rings", "um\u00b7her", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "PIS", "$.", "$(", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Ein Weib tritt auf die Schwelle:", "tokens": ["Ein", "Weib", "tritt", "auf", "die", "Schwel\u00b7le", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Es zerren an ihrem Rock", "tokens": ["Es", "zer\u00b7ren", "an", "ih\u00b7rem", "Rock"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Die Knaben mit dem Trutzblick,", "tokens": ["Die", "Kna\u00b7ben", "mit", "dem", "Trutz\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die M\u00e4dchen im Flachsgelock.", "tokens": ["Die", "M\u00e4d\u00b7chen", "im", "Flachs\u00b7ge\u00b7lock", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.31": {"line.1": {"text": "Sie gaffen auf die Fremden,", "tokens": ["Sie", "gaf\u00b7fen", "auf", "die", "Frem\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf die bunte Reiterschar:", "tokens": ["Auf", "die", "bun\u00b7te", "Rei\u00b7ter\u00b7schar", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Es beugt sich aus der S\u00e4nfte", "tokens": ["Es", "beugt", "sich", "aus", "der", "S\u00e4nf\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Mann in wei\u00dfem Haar.", "tokens": ["Ein", "Mann", "in", "wei\u00b7\u00dfem", "Haar", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Er streicht den Kopf dem J\u00fcngsten:", "tokens": ["Er", "streicht", "den", "Kopf", "dem", "J\u00fcng\u00b7sten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der greift nach der Spange licht:", "tokens": ["Der", "greift", "nach", "der", "Span\u00b7ge", "licht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "\u00bbwer ist's?\u00ab forscht scheu die Mutter.", "tokens": ["\u00bb", "wer", "ist's", "?", "\u00ab", "forscht", "scheu", "die", "Mut\u00b7ter", "."], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VAFIN", "$.", "$(", "VVFIN", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbherr Karl! \u2013 Kennst du ihn nicht?\u00ab", "tokens": ["\u00bb", "herr", "Karl", "!", "\u2013", "Kennst", "du", "ihn", "nicht", "?", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "NE", "$.", "$(", "VVFIN", "PPER", "PPER", "PTKNEG", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Laut auf kreischt die Entsetzte", "tokens": ["Laut", "auf", "kreischt", "die", "Ent\u00b7setz\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "VVFIN", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und rei\u00dft die Kinder fort:", "tokens": ["Und", "rei\u00dft", "die", "Kin\u00b7der", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.4": {"text": "Im nahen Buschwald dort. \u2013", "tokens": ["Im", "na\u00b7hen", "Busc\u00b7hwald", "dort", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADV", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Der Kaiser n\u00e4chtet im Kloster.", "tokens": ["Der", "Kai\u00b7ser", "n\u00e4ch\u00b7tet", "im", "Klos\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Leer ist's um den Altar:", "tokens": ["Leer", "ist's", "um", "den", "Al\u00b7tar", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Laie, \u2013 nur die M\u00f6nche. \u2013", "tokens": ["Kein", "Lai\u00b7e", ",", "\u2013", "nur", "die", "M\u00f6n\u00b7che", ".", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "$,", "$(", "ADV", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbwas scheint dort fern so klar?", "tokens": ["\u00bb", "was", "scheint", "dort", "fern", "so", "klar", "?"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ADJD", "ADV", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Was leuchtet durch das Fenster?\u00ab", "tokens": ["Was", "leuch\u00b7tet", "durch", "das", "Fens\u00b7ter", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VVFIN", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbo Herr \u2013 's ist nicht geheuer:", "tokens": ["\u00bb", "o", "Herr", "\u2013", "'s", "ist", "nicht", "ge\u00b7heu\u00b7er", ":"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "NN", "$(", "PPER", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Die Sachsen sind's im Walde", "tokens": ["Die", "Sach\u00b7sen", "sin\u00b7d's", "im", "Wal\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Bei Wodans Opferfeuer.\u00ab \u2013 \u2013", "tokens": ["Bei", "Wo\u00b7dans", "Op\u00b7fer\u00b7feu\u00b7er", ".", "\u00ab", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$(", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Am andern Morgen rheinw\u00e4rts", "tokens": ["Am", "an\u00b7dern", "Mor\u00b7gen", "rhein\u00b7w\u00e4rts"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der Kaiser kehrt die Fahrt;", "tokens": ["Der", "Kai\u00b7ser", "kehrt", "die", "Fahrt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er schweigt. \u2013 Er betet manchmal;", "tokens": ["Er", "schweigt", ".", "\u2013", "Er", "be\u00b7tet", "manch\u00b7mal", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er streicht den wei\u00dfen Bart.", "tokens": ["Er", "streicht", "den", "wei\u00b7\u00dfen", "Bart", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Das Ro\u00df f\u00fchrt ihm ein Sachse,", "tokens": ["Das", "Ro\u00df", "f\u00fchrt", "ihm", "ein", "Sach\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der alle Steige kennt.", "tokens": ["Der", "al\u00b7le", "Stei\u00b7ge", "kennt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Das Erdreich steht zutage,", "tokens": ["Das", "Er\u00b7dreich", "steht", "zu\u00b7ta\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wo der Pfad die H\u00fcgel trennt.", "tokens": ["Wo", "der", "Pfad", "die", "H\u00fc\u00b7gel", "trennt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.38": {"line.1": {"text": "Warm dampft es aus den Schollen, \u2013", "tokens": ["Warm", "dampft", "es", "aus", "den", "Schol\u00b7len", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Karl beugt vom Sattel sich:", "tokens": ["Karl", "beugt", "vom", "Sat\u00b7tel", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPRART", "NN", "PRF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbrot ist hier rings die Erde,", "tokens": ["\u00bb", "rot", "ist", "hier", "rings", "die", "Er\u00b7de", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ADV", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Seit wann? Woher das? \u2013 Sprich!\u00ab", "tokens": ["Seit", "wann", "?", "Wo\u00b7her", "das", "?", "\u2013", "Sprich", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "punct", "punct"], "pos": ["APPR", "PWAV", "$.", "PWAV", "PDS", "$.", "$(", "VVIMP", "$.", "$("], "meter": "+--+-+", "measure": "iambic.tri.invert"}}, "stanza.39": {"line.1": {"text": "Da hob der graue F\u00fchrer", "tokens": ["Da", "hob", "der", "grau\u00b7e", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Zu ihm den Blick empor:", "tokens": ["Zu", "ihm", "den", "Blick", "em\u00b7por", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbgr\u00fcn war der Wiesenanger,", "tokens": ["\u00bb", "gr\u00fcn", "war", "der", "Wie\u00b7sen\u00b7an\u00b7ger", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "VAFIN", "ART", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Die Heide braun zuvor;", "tokens": ["Die", "Hei\u00b7de", "braun", "zu\u00b7vor", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "Zweihunderttausend Sachsen,", "tokens": ["Zwei\u00b7hun\u00b7dert\u00b7tau\u00b7send", "Sach\u00b7sen", ","], "token_info": ["word", "word", "punct"], "pos": ["CARD", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die starben blut'gen Tod: \u2013", "tokens": ["Die", "star\u00b7ben", "blut'\u00b7gen", "Tod", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Davon ist in Westfalen", "tokens": ["Da\u00b7von", "ist", "in", "West\u00b7fa\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "APPR", "NN"], "meter": "--+-+--", "measure": "anapaest.init"}, "line.4": {"text": "Die Erde worden rot.\u00ab", "tokens": ["Die", "Er\u00b7de", "wor\u00b7den", "rot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAPP", "ADJD", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Da sch\u00fcttelt Frost den Kaiser:", "tokens": ["Da", "sch\u00fct\u00b7telt", "Frost", "den", "Kai\u00b7ser", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "\u00bbso tief \u2013 die Erde rot?", "tokens": ["\u00bb", "so", "tief", "\u2013", "die", "Er\u00b7de", "rot", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJD", "$(", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Herr Christus, l\u00f6sche die Farbe:", "tokens": ["Herr", "Chris\u00b7tus", ",", "l\u00f6\u00b7sche", "die", "Far\u00b7be", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NE", "$,", "VVFIN", "ART", "NN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Ich tat's auf dein Gebot.\u00ab", "tokens": ["Ich", "tat's", "auf", "dein", "Ge\u00b7bot", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Starr hat er in die Wolken, \u2013", "tokens": ["Starr", "hat", "er", "in", "die", "Wol\u00b7ken", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "PPER", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Auf den Boden starr gesehn:", "tokens": ["Auf", "den", "Bo\u00b7den", "starr", "ge\u00b7sehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Der Boden blieb derselbe: \u2013", "tokens": ["Der", "Bo\u00b7den", "blieb", "der\u00b7sel\u00b7be", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kein Wunder ist geschehn. \u2013", "tokens": ["Kein", "Wun\u00b7der", "ist", "ge\u00b7schehn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PIAT", "NN", "VAFIN", "VVPP", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Schwer krank kam er nach Aachen", "tokens": ["Schwer", "krank", "kam", "er", "nach", "Aa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VVFIN", "PPER", "APPR", "NE"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.2": {"text": "In seinen goldnen Saal:", "tokens": ["In", "sei\u00b7nen", "gold\u00b7nen", "Saal", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Er raunte mit sich selber,", "tokens": ["Er", "raun\u00b7te", "mit", "sich", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PRF", "ADV", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hauptsch\u00fcttelnd, manchesmal.", "tokens": ["Haupt\u00b7sch\u00fct\u00b7telnd", ",", "man\u00b7ches\u00b7mal", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["VVPP", "$,", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Er fragte: \u00bbIst's ", "tokens": ["Er", "frag\u00b7te", ":", "\u00bb", "Ist's"], "token_info": ["word", "word", "punct", "punct", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Als er im Sterben lag. \u2013", "tokens": ["Als", "er", "im", "Ster\u00b7ben", "lag", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Rot blieb Westfalens Erde", "tokens": ["Rot", "blieb", "West\u00b7fa\u00b7lens", "Er\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Bis auf den heut'gen Tag.", "tokens": ["Bis", "auf", "den", "heut'\u00b7gen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}