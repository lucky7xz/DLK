{"textgrid.poem.32825": {"metadata": {"author": {"name": "Wei\u00dfe, Christian Felix", "birth": "N.A.", "death": "N.A."}, "title": "1L: O sollt ich es doch noch erleben,", "genre": "verse", "period": "N.A.", "pub_year": 1765, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O sollt ich es doch noch erleben,", "tokens": ["O", "sollt", "ich", "es", "doch", "noch", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Stax, da\u00df man das Aergerni\u00df", "tokens": ["Sprach", "Stax", ",", "da\u00df", "man", "das", "A\u00b7er\u00b7ger\u00b7ni\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "KOUS", "PIS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hahnreyzunft ins Wasser schmi\u00df!", "tokens": ["Der", "Hahn\u00b7rey\u00b7zunft", "ins", "Was\u00b7ser", "schmi\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zehn Thaler wollt ich geben.", "tokens": ["Zehn", "Tha\u00b7ler", "wollt", "ich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Sein Nachbar schien ihm beyzustimmen:", "tokens": ["Sein", "Nach\u00b7bar", "schien", "ihm", "bey\u00b7zu\u00b7stim\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kam sich Stax nicht witzig vor!", "tokens": ["Wie", "kam", "sich", "Stax", "nicht", "wit\u00b7zig", "vor", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "NE", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch seine Frau zischt ihm ins Ohr!", "tokens": ["Doch", "sei\u00b7ne", "Frau", "zischt", "ihm", "ins", "Ohr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Heh, M\u00e4nngen, kannst du schwimmen?", "tokens": ["Heh", ",", "M\u00e4nn\u00b7gen", ",", "kannst", "du", "schwim\u00b7men", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "O sollt ich es doch noch erleben,", "tokens": ["O", "sollt", "ich", "es", "doch", "noch", "er\u00b7le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sprach Stax, da\u00df man das Aergerni\u00df", "tokens": ["Sprach", "Stax", ",", "da\u00df", "man", "das", "A\u00b7er\u00b7ger\u00b7ni\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NE", "$,", "KOUS", "PIS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Hahnreyzunft ins Wasser schmi\u00df!", "tokens": ["Der", "Hahn\u00b7rey\u00b7zunft", "ins", "Was\u00b7ser", "schmi\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zehn Thaler wollt ich geben.", "tokens": ["Zehn", "Tha\u00b7ler", "wollt", "ich", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Sein Nachbar schien ihm beyzustimmen:", "tokens": ["Sein", "Nach\u00b7bar", "schien", "ihm", "bey\u00b7zu\u00b7stim\u00b7men", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie kam sich Stax nicht witzig vor!", "tokens": ["Wie", "kam", "sich", "Stax", "nicht", "wit\u00b7zig", "vor", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PRF", "NE", "PTKNEG", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Doch seine Frau zischt ihm ins Ohr!", "tokens": ["Doch", "sei\u00b7ne", "Frau", "zischt", "ihm", "ins", "Ohr", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Heh, M\u00e4nngen, kannst du schwimmen?", "tokens": ["Heh", ",", "M\u00e4nn\u00b7gen", ",", "kannst", "du", "schwim\u00b7men", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}