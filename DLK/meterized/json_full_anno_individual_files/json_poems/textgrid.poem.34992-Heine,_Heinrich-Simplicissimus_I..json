{"textgrid.poem.34992": {"metadata": {"author": {"name": "Heine, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Simplicissimus I.", "genre": "verse", "period": "N.A.", "pub_year": 1852, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der eine kann das Ungl\u00fcck nicht,", "tokens": ["Der", "ei\u00b7ne", "kann", "das", "Un\u00b7gl\u00fcck", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der andre nicht das Gl\u00fcck verdauen.", "tokens": ["Der", "and\u00b7re", "nicht", "das", "Gl\u00fcck", "ver\u00b7dau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch M\u00e4nnerha\u00df verdirbt der eine,", "tokens": ["Durch", "M\u00e4n\u00b7ner\u00b7ha\u00df", "ver\u00b7dirbt", "der", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der andre durch die Gunst der Frauen.", "tokens": ["Der", "and\u00b7re", "durch", "die", "Gunst", "der", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Als ich dich sah zum erstenmal,", "tokens": ["Als", "ich", "dich", "sah", "zum", "ers\u00b7ten\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPRART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War fremd dir alles galante Geh\u00f6fel;", "tokens": ["War", "fremd", "dir", "al\u00b7les", "ga\u00b7lan\u00b7te", "Ge\u00b7h\u00f6\u00b7fel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es deckten die plebejischen H\u00e4nde", "tokens": ["Es", "deck\u00b7ten", "die", "ple\u00b7be\u00b7ji\u00b7schen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch nicht Glac\u00e9handschuhe von Rehfell.", "tokens": ["Noch", "nicht", "Glac\u00e9hand\u00b7schu\u00b7he", "von", "Reh\u00b7fell", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.3": {"line.1": {"text": "Das R\u00f6cklein, das du trugest, war gr\u00fcn", "tokens": ["Das", "R\u00f6ck\u00b7lein", ",", "das", "du", "tru\u00b7gest", ",", "war", "gr\u00fcn"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und z\u00e4hlte schon sehr viele Lenze;", "tokens": ["Und", "z\u00e4hl\u00b7te", "schon", "sehr", "vie\u00b7le", "Len\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Die \u00c4rmel zu kurz, zu lang die Sch\u00f6\u00dfe,", "tokens": ["Die", "\u00c4r\u00b7mel", "zu", "kurz", ",", "zu", "lang", "die", "Sch\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Erinnernd an Bachstelzenschw\u00e4nze.", "tokens": ["E\u00b7rin\u00b7nernd", "an", "Bach\u00b7stel\u00b7zen\u00b7schw\u00e4n\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.4": {"line.1": {"text": "Du trugest ein Halstuch, das der Mama", "tokens": ["Du", "tru\u00b7gest", "ein", "Hal\u00b7stuch", ",", "das", "der", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als Serviette gedienet hatte;", "tokens": ["Als", "Ser\u00b7viet\u00b7te", "ge\u00b7die\u00b7net", "hat\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "VAFIN", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch wiegte sich nicht dein Kinn so vornehm", "tokens": ["Noch", "wieg\u00b7te", "sich", "nicht", "dein", "Kinn", "so", "vor\u00b7nehm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In einer gestickten Atlaskrawatte.", "tokens": ["In", "ei\u00b7ner", "ge\u00b7stick\u00b7ten", "At\u00b7las\u00b7kra\u00b7wat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.5": {"line.1": {"text": "Die Stiefel sahen so ehrlich aus,", "tokens": ["Die", "Stie\u00b7fel", "sa\u00b7hen", "so", "ehr\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als habe Hans Sachs sie fabrizieret;", "tokens": ["Als", "ha\u00b7be", "Hans", "Sachs", "sie", "fab\u00b7ri\u00b7zie\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NE", "NE", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch nicht mit glei\u00dfend franz\u00f6sischem Firnis,", "tokens": ["Noch", "nicht", "mit", "glei\u00b7\u00dfend", "fran\u00b7z\u00f6\u00b7si\u00b7schem", "Fir\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie waren mit deutschem Tran geschmieret.", "tokens": ["Sie", "wa\u00b7ren", "mit", "deut\u00b7schem", "Tran", "ge\u00b7schmie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Nach Bisam und Moschus rochest du nicht,", "tokens": ["Nach", "Bi\u00b7sam", "und", "Mo\u00b7schus", "ro\u00b7chest", "du", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Am Halse hing noch keine Lorgnette,", "tokens": ["Am", "Hal\u00b7se", "hing", "noch", "kei\u00b7ne", "Lorg\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du hattest noch keine Weste von Sammet", "tokens": ["Du", "hat\u00b7test", "noch", "kei\u00b7ne", "Wes\u00b7te", "von", "Sam\u00b7met"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und keine Frau und goldne Kette.", "tokens": ["Und", "kei\u00b7ne", "Frau", "und", "gold\u00b7ne", "Ket\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Du trugest dich zu jener Zeit", "tokens": ["Du", "tru\u00b7gest", "dich", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz nach der allerneusten Mode", "tokens": ["Ganz", "nach", "der", "al\u00b7ler\u00b7neus\u00b7ten", "Mo\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von Schw\u00e4bisch Hall \u2013 Und dennoch, damals", "tokens": ["Von", "Schw\u00e4\u00b7bisch", "Hall", "\u2013", "Und", "den\u00b7noch", ",", "da\u00b7mals"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "NE", "NE", "$(", "KON", "ADV", "$,", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War deines Lebens Glanzperiode.", "tokens": ["War", "dei\u00b7nes", "Le\u00b7bens", "Glanz\u00b7pe\u00b7ri\u00b7o\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Du hattest Haare auf dem Kopf,", "tokens": ["Du", "hat\u00b7test", "Haa\u00b7re", "auf", "dem", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unter den Haaren, gro\u00df und edel,", "tokens": ["Und", "un\u00b7ter", "den", "Haa\u00b7ren", ",", "gro\u00df", "und", "e\u00b7del", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wuchsen Gedanken \u2013 aber jetzo", "tokens": ["Wuch\u00b7sen", "Ge\u00b7dan\u00b7ken", "\u2013", "a\u00b7ber", "jet\u00b7zo"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$(", "ADV", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ist kahl und leer dein armer Sch\u00e4del.", "tokens": ["Ist", "kahl", "und", "leer", "dein", "ar\u00b7mer", "Sch\u00e4\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Verschwunden ist auch der Lorbeerkranz,", "tokens": ["Ver\u00b7schwun\u00b7den", "ist", "auch", "der", "Lor\u00b7beer\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der dir bedecken k\u00f6nnte die Glatze \u2013", "tokens": ["Der", "dir", "be\u00b7de\u00b7cken", "k\u00f6nn\u00b7te", "die", "Glat\u00b7ze", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "ART", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wer hat dich so gerauft? Wahrhaftig,", "tokens": ["Wer", "hat", "dich", "so", "ger\u00b7auft", "?", "Wahr\u00b7haf\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "ADJD", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Siehst aus wie eine geschorene Katze!", "tokens": ["Siehst", "aus", "wie", "ei\u00b7ne", "ge\u00b7scho\u00b7re\u00b7ne", "Kat\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Die goldnen Dukaten des Schwiegerpapas,", "tokens": ["Die", "gold\u00b7nen", "Du\u00b7ka\u00b7ten", "des", "Schwie\u00b7ger\u00b7pa\u00b7pas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Des Seidenh\u00e4ndlers, sind auch zerronnen \u2013", "tokens": ["Des", "Sei\u00b7den\u00b7h\u00e4nd\u00b7lers", ",", "sind", "auch", "zer\u00b7ron\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Alte klagt: bei der deutschen Dichtkunst", "tokens": ["Der", "Al\u00b7te", "klagt", ":", "bei", "der", "deut\u00b7schen", "Dicht\u00b7kunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Habe er keine Seide gesponnen.", "tokens": ["Ha\u00b7be", "er", "kei\u00b7ne", "Sei\u00b7de", "ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.11": {"line.1": {"text": "Ist das der Lebendige, der die Welt", "tokens": ["Ist", "das", "der", "Le\u00b7ben\u00b7di\u00b7ge", ",", "der", "die", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit all ihren Kn\u00f6deln, Dampfnudeln und W\u00fcrsten", "tokens": ["Mit", "all", "ih\u00b7ren", "Kn\u00f6\u00b7deln", ",", "Dampf\u00b7nu\u00b7deln", "und", "W\u00fcrs\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Verschlingen wollte, und in den Hades", "tokens": ["Ver\u00b7schlin\u00b7gen", "woll\u00b7te", ",", "und", "in", "den", "Ha\u00b7des"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Verwies den P\u00fcckler-Muskau, den F\u00fcrsten?", "tokens": ["Ver\u00b7wies", "den", "P\u00fc\u00b7ck\u00b7ler\u00b7Mus\u00b7kau", ",", "den", "F\u00fcrs\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Ist das der irrende Ritter, der einst,", "tokens": ["Ist", "das", "der", "ir\u00b7ren\u00b7de", "Rit\u00b7ter", ",", "der", "einst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie jener andre, der Manchaner,", "tokens": ["Wie", "je\u00b7ner", "and\u00b7re", ",", "der", "Man\u00b7cha\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PIS", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Absagebriefe schrieb an Tyrannen,", "tokens": ["Ab\u00b7sa\u00b7ge\u00b7brie\u00b7fe", "schrieb", "an", "Ty\u00b7ran\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Im Stile der kecksten Tertianer?", "tokens": ["Im", "Sti\u00b7le", "der", "kecks\u00b7ten", "Ter\u00b7ti\u00b7a\u00b7ner", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.13": {"line.1": {"text": "Ist das der Generalissimus", "tokens": ["Ist", "das", "der", "Ge\u00b7ne\u00b7ra\u00b7lis\u00b7si\u00b7mus"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der deutschen Freiheit, der Gonfaloniere", "tokens": ["Der", "deut\u00b7schen", "Frei\u00b7heit", ",", "der", "Gon\u00b7fa\u00b7lo\u00b7nie\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Emanzipation, der hoch zu Rosse", "tokens": ["Der", "E\u00b7man\u00b7zi\u00b7pa\u00b7ti\u00b7on", ",", "der", "hoch", "zu", "Ros\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "APPR", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Einherritt vor seinem Freischarenheere?", "tokens": ["Ein\u00b7her\u00b7ritt", "vor", "sei\u00b7nem", "Frei\u00b7scha\u00b7ren\u00b7hee\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "Der Schimmel, den er ritt, war wei\u00df,", "tokens": ["Der", "Schim\u00b7mel", ",", "den", "er", "ritt", ",", "war", "wei\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie alle Schimmel, worauf die G\u00f6tter", "tokens": ["Wie", "al\u00b7le", "Schim\u00b7mel", ",", "wo\u00b7rauf", "die", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und Helden geritten, die l\u00e4ngst verschimmelt;", "tokens": ["Und", "Hel\u00b7den", "ge\u00b7rit\u00b7ten", ",", "die", "l\u00e4ngst", "ver\u00b7schim\u00b7melt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Begeistrung jauchzte dem Vaterlandsretter.", "tokens": ["Be\u00b7geis\u00b7trung", "jauchz\u00b7te", "dem", "Va\u00b7ter\u00b7lands\u00b7ret\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Er war ein reitender Virtuos,", "tokens": ["Er", "war", "ein", "rei\u00b7ten\u00b7der", "Vir\u00b7tu\u00b7os", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Liszt zu Pferde, ein somnamb\u00fcler", "tokens": ["Ein", "Liszt", "zu", "Pfer\u00b7de", ",", "ein", "som\u00b7nam\u00b7b\u00fc\u00b7ler"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Marktschreier, Hansnarr, Philisterg\u00fcnstling,", "tokens": ["Markt\u00b7schrei\u00b7er", ",", "Hans\u00b7narr", ",", "Phi\u00b7lis\u00b7ter\u00b7g\u00fcnst\u00b7ling", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+---+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein miserabler Heldenspieler!", "tokens": ["Ein", "mi\u00b7se\u00b7rab\u00b7ler", "Hel\u00b7den\u00b7spie\u00b7ler", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.16": {"line.1": {"text": "Als Amazone ritt neben ihm", "tokens": ["Als", "A\u00b7ma\u00b7zo\u00b7ne", "ritt", "ne\u00b7ben", "ihm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gattin mit der langen Nase;", "tokens": ["Die", "Gat\u00b7tin", "mit", "der", "lan\u00b7gen", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie trug auf dem Hut eine kecke Feder,", "tokens": ["Sie", "trug", "auf", "dem", "Hut", "ei\u00b7ne", "ke\u00b7cke", "Fe\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Im sch\u00f6nen Auge blitzte Ekstase.", "tokens": ["Im", "sch\u00f6\u00b7nen", "Au\u00b7ge", "blitz\u00b7te", "Eks\u00b7ta\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}}, "stanza.17": {"line.1": {"text": "Die Sage geht, es habe die Frau", "tokens": ["Die", "Sa\u00b7ge", "geht", ",", "es", "ha\u00b7be", "die", "Frau"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vergebens bek\u00e4mpft den Kleinmut des Gatten,", "tokens": ["Ver\u00b7ge\u00b7bens", "be\u00b7k\u00e4mpft", "den", "Klein\u00b7mut", "des", "Gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Als Flintensch\u00fcsse seine zarten", "tokens": ["Als", "Flin\u00b7ten\u00b7sch\u00fcs\u00b7se", "sei\u00b7ne", "zar\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unterleibsnerven ersch\u00fcttert hatten.", "tokens": ["Un\u00b7ter\u00b7leibs\u00b7ner\u00b7ven", "er\u00b7sch\u00fct\u00b7tert", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.18": {"line.1": {"text": "Sie sprach zu ihm: \u00bbSei jetzt kein Has',", "tokens": ["Sie", "sprach", "zu", "ihm", ":", "\u00bb", "Sei", "jetzt", "kein", "Has'", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "$(", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Entmemme dich deiner verzagten Gef\u00fchle.", "tokens": ["Ent\u00b7mem\u00b7me", "dich", "dei\u00b7ner", "ver\u00b7zag\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Jetzt gilt es zu siegen oder zu sterben \u2013", "tokens": ["Jetzt", "gilt", "es", "zu", "sie\u00b7gen", "o\u00b7der", "zu", "ster\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Die Kaiserkrone steht auf dem Spiele.", "tokens": ["Die", "Kai\u00b7ser\u00b7kro\u00b7ne", "steht", "auf", "dem", "Spie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Denk an die Not des Vaterlands", "tokens": ["Denk", "an", "die", "Not", "des", "Va\u00b7ter\u00b7lands"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und an die eignen Schulden und N\u00f6ten.", "tokens": ["Und", "an", "die", "eig\u00b7nen", "Schul\u00b7den", "und", "N\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In Frankfurt la\u00df ich dich kr\u00f6nen, und Rothschild", "tokens": ["In", "Frank\u00b7furt", "la\u00df", "ich", "dich", "kr\u00f6\u00b7nen", ",", "und", "Roth\u00b7schild"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "VVIMP", "PPER", "PRF", "VVINF", "$,", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Borgt dir wie andren Majest\u00e4ten.", "tokens": ["Borgt", "dir", "wie", "an\u00b7dren", "Ma\u00b7jes\u00b7t\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Wie sch\u00f6n der Mantel von Hermelin", "tokens": ["Wie", "sch\u00f6n", "der", "Man\u00b7tel", "von", "Her\u00b7me\u00b7lin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dich kleiden wird! Das Vivatschreien,", "tokens": ["Dich", "klei\u00b7den", "wird", "!", "Das", "Vi\u00b7vat\u00b7schrei\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VAFIN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich h\u00f6r es schon; ich seh auch die M\u00e4dchen,", "tokens": ["Ich", "h\u00f6r", "es", "schon", ";", "ich", "seh", "auch", "die", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die wei\u00dfgekleidet dir Blumen streuen\u00ab \u2013", "tokens": ["Die", "wei\u00df\u00b7ge\u00b7klei\u00b7det", "dir", "Blu\u00b7men", "streu\u00b7en", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "VVINF", "$(", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.21": {"line.1": {"text": "Vergebliches Mahnen! Antipathien", "tokens": ["Ver\u00b7geb\u00b7li\u00b7ches", "Mah\u00b7nen", "!", "An\u00b7ti\u00b7pa\u00b7thi\u00b7en"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$.", "NE"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gibt es, woran die Besten siechen,", "tokens": ["Gibt", "es", ",", "wo\u00b7ran", "die", "Bes\u00b7ten", "sie\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Goethe nicht den Rauch des Tabaks,", "tokens": ["Wie", "Goe\u00b7the", "nicht", "den", "Rauch", "des", "Ta\u00b7baks", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kann unser Held kein Pulver riechen.", "tokens": ["Kann", "un\u00b7ser", "Held", "kein", "Pul\u00b7ver", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Die Sch\u00fcsse knallen \u2013 der Held erbla\u00dft,", "tokens": ["Die", "Sch\u00fcs\u00b7se", "knal\u00b7len", "\u2013", "der", "Held", "er\u00b7bla\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$(", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er stottert manche unsinnige Phrase,", "tokens": ["Er", "stot\u00b7tert", "man\u00b7che", "un\u00b7sin\u00b7ni\u00b7ge", "Phra\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+++-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Er phantasieret gelb \u2013 die Gattin", "tokens": ["Er", "phan\u00b7ta\u00b7sie\u00b7ret", "gelb", "\u2013", "die", "Gat\u00b7tin"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00e4lt sich das Tuch vor der langen Nase.", "tokens": ["H\u00e4lt", "sich", "das", "Tuch", "vor", "der", "lan\u00b7gen", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.23": {"line.1": {"text": "So geht die Sage \u2013 Ist sie wahr?", "tokens": ["So", "geht", "die", "Sa\u00b7ge", "\u2013", "Ist", "sie", "wahr", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer wei\u00df es? Wir Menschen sind nicht vollkommen.", "tokens": ["Wer", "wei\u00df", "es", "?", "Wir", "Men\u00b7schen", "sind", "nicht", "voll\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Sogar der gro\u00dfe Horatius Flaccus", "tokens": ["So\u00b7gar", "der", "gro\u00b7\u00dfe", "Ho\u00b7ra\u00b7ti\u00b7us", "Flac\u00b7cus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hat in der Schlacht Rei\u00dfaus genommen.", "tokens": ["Hat", "in", "der", "Schlacht", "Rei\u00df\u00b7aus", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Das ist auf Erden des Sch\u00f6nen Los!", "tokens": ["Das", "ist", "auf", "Er\u00b7den", "des", "Sch\u00f6\u00b7nen", "Los", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Feinen gehn unter, ganz wie die Plumpen;", "tokens": ["Die", "Fei\u00b7nen", "gehn", "un\u00b7ter", ",", "ganz", "wie", "die", "Plum\u00b7pen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "$,", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ihr Lied wird Makulatur, sie selber,", "tokens": ["Ihr", "Lied", "wird", "Ma\u00b7ku\u00b7la\u00b7tur", ",", "sie", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,", "PPER", "ADV", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Dichter, werden am Ende Lumpen.", "tokens": ["Die", "Dich\u00b7ter", ",", "wer\u00b7den", "am", "En\u00b7de", "Lum\u00b7pen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "APPRART", "NN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.25": {"line.1": {"text": "Der eine kann das Ungl\u00fcck nicht,", "tokens": ["Der", "ei\u00b7ne", "kann", "das", "Un\u00b7gl\u00fcck", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VMFIN", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der andre nicht das Gl\u00fcck verdauen.", "tokens": ["Der", "and\u00b7re", "nicht", "das", "Gl\u00fcck", "ver\u00b7dau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Durch M\u00e4nnerha\u00df verdirbt der eine,", "tokens": ["Durch", "M\u00e4n\u00b7ner\u00b7ha\u00df", "ver\u00b7dirbt", "der", "ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der andre durch die Gunst der Frauen.", "tokens": ["Der", "and\u00b7re", "durch", "die", "Gunst", "der", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Als ich dich sah zum erstenmal,", "tokens": ["Als", "ich", "dich", "sah", "zum", "ers\u00b7ten\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPRART", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War fremd dir alles galante Geh\u00f6fel;", "tokens": ["War", "fremd", "dir", "al\u00b7les", "ga\u00b7lan\u00b7te", "Ge\u00b7h\u00f6\u00b7fel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Es deckten die plebejischen H\u00e4nde", "tokens": ["Es", "deck\u00b7ten", "die", "ple\u00b7be\u00b7ji\u00b7schen", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Noch nicht Glac\u00e9handschuhe von Rehfell.", "tokens": ["Noch", "nicht", "Glac\u00e9hand\u00b7schu\u00b7he", "von", "Reh\u00b7fell", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.27": {"line.1": {"text": "Das R\u00f6cklein, das du trugest, war gr\u00fcn", "tokens": ["Das", "R\u00f6ck\u00b7lein", ",", "das", "du", "tru\u00b7gest", ",", "war", "gr\u00fcn"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "ADJD"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und z\u00e4hlte schon sehr viele Lenze;", "tokens": ["Und", "z\u00e4hl\u00b7te", "schon", "sehr", "vie\u00b7le", "Len\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+++-+-", "measure": "unknown.measure.penta"}, "line.3": {"text": "Die \u00c4rmel zu kurz, zu lang die Sch\u00f6\u00dfe,", "tokens": ["Die", "\u00c4r\u00b7mel", "zu", "kurz", ",", "zu", "lang", "die", "Sch\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKA", "ADJD", "$,", "PTKA", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Erinnernd an Bachstelzenschw\u00e4nze.", "tokens": ["E\u00b7rin\u00b7nernd", "an", "Bach\u00b7stel\u00b7zen\u00b7schw\u00e4n\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.28": {"line.1": {"text": "Du trugest ein Halstuch, das der Mama", "tokens": ["Du", "tru\u00b7gest", "ein", "Hal\u00b7stuch", ",", "das", "der", "Ma\u00b7ma"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+--+-++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Als Serviette gedienet hatte;", "tokens": ["Als", "Ser\u00b7viet\u00b7te", "ge\u00b7die\u00b7net", "hat\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "VAFIN", "$."], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch wiegte sich nicht dein Kinn so vornehm", "tokens": ["Noch", "wieg\u00b7te", "sich", "nicht", "dein", "Kinn", "so", "vor\u00b7nehm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "PTKNEG", "PPOSAT", "NN", "ADV", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "In einer gestickten Atlaskrawatte.", "tokens": ["In", "ei\u00b7ner", "ge\u00b7stick\u00b7ten", "At\u00b7las\u00b7kra\u00b7wat\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.29": {"line.1": {"text": "Die Stiefel sahen so ehrlich aus,", "tokens": ["Die", "Stie\u00b7fel", "sa\u00b7hen", "so", "ehr\u00b7lich", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Als habe Hans Sachs sie fabrizieret;", "tokens": ["Als", "ha\u00b7be", "Hans", "Sachs", "sie", "fab\u00b7ri\u00b7zie\u00b7ret", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NE", "NE", "PPER", "VVFIN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Noch nicht mit glei\u00dfend franz\u00f6sischem Firnis,", "tokens": ["Noch", "nicht", "mit", "glei\u00b7\u00dfend", "fran\u00b7z\u00f6\u00b7si\u00b7schem", "Fir\u00b7nis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Sie waren mit deutschem Tran geschmieret.", "tokens": ["Sie", "wa\u00b7ren", "mit", "deut\u00b7schem", "Tran", "ge\u00b7schmie\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.30": {"line.1": {"text": "Nach Bisam und Moschus rochest du nicht,", "tokens": ["Nach", "Bi\u00b7sam", "und", "Mo\u00b7schus", "ro\u00b7chest", "du", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "KON", "NE", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Am Halse hing noch keine Lorgnette,", "tokens": ["Am", "Hal\u00b7se", "hing", "noch", "kei\u00b7ne", "Lorg\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Du hattest noch keine Weste von Sammet", "tokens": ["Du", "hat\u00b7test", "noch", "kei\u00b7ne", "Wes\u00b7te", "von", "Sam\u00b7met"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NN"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Und keine Frau und goldne Kette.", "tokens": ["Und", "kei\u00b7ne", "Frau", "und", "gold\u00b7ne", "Ket\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Du trugest dich zu jener Zeit", "tokens": ["Du", "tru\u00b7gest", "dich", "zu", "je\u00b7ner", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ganz nach der allerneusten Mode", "tokens": ["Ganz", "nach", "der", "al\u00b7ler\u00b7neus\u00b7ten", "Mo\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Von Schw\u00e4bisch Hall \u2013 Und dennoch, damals", "tokens": ["Von", "Schw\u00e4\u00b7bisch", "Hall", "\u2013", "Und", "den\u00b7noch", ",", "da\u00b7mals"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["APPR", "NE", "NE", "$(", "KON", "ADV", "$,", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "War deines Lebens Glanzperiode.", "tokens": ["War", "dei\u00b7nes", "Le\u00b7bens", "Glanz\u00b7pe\u00b7ri\u00b7o\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.32": {"line.1": {"text": "Du hattest Haare auf dem Kopf,", "tokens": ["Du", "hat\u00b7test", "Haa\u00b7re", "auf", "dem", "Kopf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und unter den Haaren, gro\u00df und edel,", "tokens": ["Und", "un\u00b7ter", "den", "Haa\u00b7ren", ",", "gro\u00df", "und", "e\u00b7del", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wuchsen Gedanken \u2013 aber jetzo", "tokens": ["Wuch\u00b7sen", "Ge\u00b7dan\u00b7ken", "\u2013", "a\u00b7ber", "jet\u00b7zo"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["NN", "NN", "$(", "ADV", "ADV"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Ist kahl und leer dein armer Sch\u00e4del.", "tokens": ["Ist", "kahl", "und", "leer", "dein", "ar\u00b7mer", "Sch\u00e4\u00b7del", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Verschwunden ist auch der Lorbeerkranz,", "tokens": ["Ver\u00b7schwun\u00b7den", "ist", "auch", "der", "Lor\u00b7beer\u00b7kranz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der dir bedecken k\u00f6nnte die Glatze \u2013", "tokens": ["Der", "dir", "be\u00b7de\u00b7cken", "k\u00f6nn\u00b7te", "die", "Glat\u00b7ze", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VMFIN", "ART", "NN", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wer hat dich so gerauft? Wahrhaftig,", "tokens": ["Wer", "hat", "dich", "so", "ger\u00b7auft", "?", "Wahr\u00b7haf\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "VVPP", "$.", "ADJD", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Siehst aus wie eine geschorene Katze!", "tokens": ["Siehst", "aus", "wie", "ei\u00b7ne", "ge\u00b7scho\u00b7re\u00b7ne", "Kat\u00b7ze", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.34": {"line.1": {"text": "Die goldnen Dukaten des Schwiegerpapas,", "tokens": ["Die", "gold\u00b7nen", "Du\u00b7ka\u00b7ten", "des", "Schwie\u00b7ger\u00b7pa\u00b7pas", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.2": {"text": "Des Seidenh\u00e4ndlers, sind auch zerronnen \u2013", "tokens": ["Des", "Sei\u00b7den\u00b7h\u00e4nd\u00b7lers", ",", "sind", "auch", "zer\u00b7ron\u00b7nen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "ADV", "VVINF", "$("], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Alte klagt: bei der deutschen Dichtkunst", "tokens": ["Der", "Al\u00b7te", "klagt", ":", "bei", "der", "deut\u00b7schen", "Dicht\u00b7kunst"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Habe er keine Seide gesponnen.", "tokens": ["Ha\u00b7be", "er", "kei\u00b7ne", "Sei\u00b7de", "ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIAT", "NN", "VVPP", "$."], "meter": "+--+-+--+-", "measure": "iambic.tetra.invert"}}, "stanza.35": {"line.1": {"text": "Ist das der Lebendige, der die Welt", "tokens": ["Ist", "das", "der", "Le\u00b7ben\u00b7di\u00b7ge", ",", "der", "die", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Mit all ihren Kn\u00f6deln, Dampfnudeln und W\u00fcrsten", "tokens": ["Mit", "all", "ih\u00b7ren", "Kn\u00f6\u00b7deln", ",", "Dampf\u00b7nu\u00b7deln", "und", "W\u00fcrs\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,", "NN", "KON", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.3": {"text": "Verschlingen wollte, und in den Hades", "tokens": ["Ver\u00b7schlin\u00b7gen", "woll\u00b7te", ",", "und", "in", "den", "Ha\u00b7des"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "VMFIN", "$,", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Verwies den P\u00fcckler-Muskau, den F\u00fcrsten?", "tokens": ["Ver\u00b7wies", "den", "P\u00fc\u00b7ck\u00b7ler\u00b7Mus\u00b7kau", ",", "den", "F\u00fcrs\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.36": {"line.1": {"text": "Ist das der irrende Ritter, der einst,", "tokens": ["Ist", "das", "der", "ir\u00b7ren\u00b7de", "Rit\u00b7ter", ",", "der", "einst", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wie jener andre, der Manchaner,", "tokens": ["Wie", "je\u00b7ner", "and\u00b7re", ",", "der", "Man\u00b7cha\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PDS", "PIS", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Absagebriefe schrieb an Tyrannen,", "tokens": ["Ab\u00b7sa\u00b7ge\u00b7brie\u00b7fe", "schrieb", "an", "Ty\u00b7ran\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "NN", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Im Stile der kecksten Tertianer?", "tokens": ["Im", "Sti\u00b7le", "der", "kecks\u00b7ten", "Ter\u00b7ti\u00b7a\u00b7ner", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.37": {"line.1": {"text": "Ist das der Generalissimus", "tokens": ["Ist", "das", "der", "Ge\u00b7ne\u00b7ra\u00b7lis\u00b7si\u00b7mus"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PDS", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Der deutschen Freiheit, der Gonfaloniere", "tokens": ["Der", "deut\u00b7schen", "Frei\u00b7heit", ",", "der", "Gon\u00b7fa\u00b7lo\u00b7nie\u00b7re"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Emanzipation, der hoch zu Rosse", "tokens": ["Der", "E\u00b7man\u00b7zi\u00b7pa\u00b7ti\u00b7on", ",", "der", "hoch", "zu", "Ros\u00b7se"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "APPR", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Einherritt vor seinem Freischarenheere?", "tokens": ["Ein\u00b7her\u00b7ritt", "vor", "sei\u00b7nem", "Frei\u00b7scha\u00b7ren\u00b7hee\u00b7re", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "$."], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.38": {"line.1": {"text": "Der Schimmel, den er ritt, war wei\u00df,", "tokens": ["Der", "Schim\u00b7mel", ",", "den", "er", "ritt", ",", "war", "wei\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie alle Schimmel, worauf die G\u00f6tter", "tokens": ["Wie", "al\u00b7le", "Schim\u00b7mel", ",", "wo\u00b7rauf", "die", "G\u00f6t\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Und Helden geritten, die l\u00e4ngst verschimmelt;", "tokens": ["Und", "Hel\u00b7den", "ge\u00b7rit\u00b7ten", ",", "die", "l\u00e4ngst", "ver\u00b7schim\u00b7melt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVPP", "$,", "PRELS", "ADV", "VVPP", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Begeistrung jauchzte dem Vaterlandsretter.", "tokens": ["Be\u00b7geis\u00b7trung", "jauchz\u00b7te", "dem", "Va\u00b7ter\u00b7lands\u00b7ret\u00b7ter", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.39": {"line.1": {"text": "Er war ein reitender Virtuos,", "tokens": ["Er", "war", "ein", "rei\u00b7ten\u00b7der", "Vir\u00b7tu\u00b7os", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Liszt zu Pferde, ein somnamb\u00fcler", "tokens": ["Ein", "Liszt", "zu", "Pfer\u00b7de", ",", "ein", "som\u00b7nam\u00b7b\u00fc\u00b7ler"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Marktschreier, Hansnarr, Philisterg\u00fcnstling,", "tokens": ["Markt\u00b7schrei\u00b7er", ",", "Hans\u00b7narr", ",", "Phi\u00b7lis\u00b7ter\u00b7g\u00fcnst\u00b7ling", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,"], "meter": "+---+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Ein miserabler Heldenspieler!", "tokens": ["Ein", "mi\u00b7se\u00b7rab\u00b7ler", "Hel\u00b7den\u00b7spie\u00b7ler", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.40": {"line.1": {"text": "Als Amazone ritt neben ihm", "tokens": ["Als", "A\u00b7ma\u00b7zo\u00b7ne", "ritt", "ne\u00b7ben", "ihm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Gattin mit der langen Nase;", "tokens": ["Die", "Gat\u00b7tin", "mit", "der", "lan\u00b7gen", "Na\u00b7se", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Sie trug auf dem Hut eine kecke Feder,", "tokens": ["Sie", "trug", "auf", "dem", "Hut", "ei\u00b7ne", "ke\u00b7cke", "Fe\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Im sch\u00f6nen Auge blitzte Ekstase.", "tokens": ["Im", "sch\u00f6\u00b7nen", "Au\u00b7ge", "blitz\u00b7te", "Eks\u00b7ta\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "NN", "$."], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}}, "stanza.41": {"line.1": {"text": "Die Sage geht, es habe die Frau", "tokens": ["Die", "Sa\u00b7ge", "geht", ",", "es", "ha\u00b7be", "die", "Frau"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VAFIN", "ART", "NN"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Vergebens bek\u00e4mpft den Kleinmut des Gatten,", "tokens": ["Ver\u00b7ge\u00b7bens", "be\u00b7k\u00e4mpft", "den", "Klein\u00b7mut", "des", "Gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Als Flintensch\u00fcsse seine zarten", "tokens": ["Als", "Flin\u00b7ten\u00b7sch\u00fcs\u00b7se", "sei\u00b7ne", "zar\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "PPOSAT", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unterleibsnerven ersch\u00fcttert hatten.", "tokens": ["Un\u00b7ter\u00b7leibs\u00b7ner\u00b7ven", "er\u00b7sch\u00fct\u00b7tert", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAFIN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.42": {"line.1": {"text": "Sie sprach zu ihm: \u00bbSei jetzt kein Has',", "tokens": ["Sie", "sprach", "zu", "ihm", ":", "\u00bb", "Sei", "jetzt", "kein", "Has'", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPER", "$.", "$(", "VAFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Entmemme dich deiner verzagten Gef\u00fchle.", "tokens": ["Ent\u00b7mem\u00b7me", "dich", "dei\u00b7ner", "ver\u00b7zag\u00b7ten", "Ge\u00b7f\u00fch\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.3": {"text": "Jetzt gilt es zu siegen oder zu sterben \u2013", "tokens": ["Jetzt", "gilt", "es", "zu", "sie\u00b7gen", "o\u00b7der", "zu", "ster\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "KON", "PTKZU", "VVINF", "$("], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Die Kaiserkrone steht auf dem Spiele.", "tokens": ["Die", "Kai\u00b7ser\u00b7kro\u00b7ne", "steht", "auf", "dem", "Spie\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.43": {"line.1": {"text": "Denk an die Not des Vaterlands", "tokens": ["Denk", "an", "die", "Not", "des", "Va\u00b7ter\u00b7lands"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und an die eignen Schulden und N\u00f6ten.", "tokens": ["Und", "an", "die", "eig\u00b7nen", "Schul\u00b7den", "und", "N\u00f6\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "In Frankfurt la\u00df ich dich kr\u00f6nen, und Rothschild", "tokens": ["In", "Frank\u00b7furt", "la\u00df", "ich", "dich", "kr\u00f6\u00b7nen", ",", "und", "Roth\u00b7schild"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "NE", "VVIMP", "PPER", "PRF", "VVINF", "$,", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Borgt dir wie andren Majest\u00e4ten.", "tokens": ["Borgt", "dir", "wie", "an\u00b7dren", "Ma\u00b7jes\u00b7t\u00e4\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Wie sch\u00f6n der Mantel von Hermelin", "tokens": ["Wie", "sch\u00f6n", "der", "Man\u00b7tel", "von", "Her\u00b7me\u00b7lin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "NE"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dich kleiden wird! Das Vivatschreien,", "tokens": ["Dich", "klei\u00b7den", "wird", "!", "Das", "Vi\u00b7vat\u00b7schrei\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVINF", "VAFIN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich h\u00f6r es schon; ich seh auch die M\u00e4dchen,", "tokens": ["Ich", "h\u00f6r", "es", "schon", ";", "ich", "seh", "auch", "die", "M\u00e4d\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die wei\u00dfgekleidet dir Blumen streuen\u00ab \u2013", "tokens": ["Die", "wei\u00df\u00b7ge\u00b7klei\u00b7det", "dir", "Blu\u00b7men", "streu\u00b7en", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "PPER", "NN", "VVINF", "$(", "$("], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.45": {"line.1": {"text": "Vergebliches Mahnen! Antipathien", "tokens": ["Ver\u00b7geb\u00b7li\u00b7ches", "Mah\u00b7nen", "!", "An\u00b7ti\u00b7pa\u00b7thi\u00b7en"], "token_info": ["word", "word", "punct", "word"], "pos": ["ADJA", "NN", "$.", "NE"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Gibt es, woran die Besten siechen,", "tokens": ["Gibt", "es", ",", "wo\u00b7ran", "die", "Bes\u00b7ten", "sie\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wie Goethe nicht den Rauch des Tabaks,", "tokens": ["Wie", "Goe\u00b7the", "nicht", "den", "Rauch", "des", "Ta\u00b7baks", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "PTKNEG", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kann unser Held kein Pulver riechen.", "tokens": ["Kann", "un\u00b7ser", "Held", "kein", "Pul\u00b7ver", "rie\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Die Sch\u00fcsse knallen \u2013 der Held erbla\u00dft,", "tokens": ["Die", "Sch\u00fcs\u00b7se", "knal\u00b7len", "\u2013", "der", "Held", "er\u00b7bla\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$(", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er stottert manche unsinnige Phrase,", "tokens": ["Er", "stot\u00b7tert", "man\u00b7che", "un\u00b7sin\u00b7ni\u00b7ge", "Phra\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+++-+-", "measure": "unknown.measure.hexa"}, "line.3": {"text": "Er phantasieret gelb \u2013 die Gattin", "tokens": ["Er", "phan\u00b7ta\u00b7sie\u00b7ret", "gelb", "\u2013", "die", "Gat\u00b7tin"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$(", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00e4lt sich das Tuch vor der langen Nase.", "tokens": ["H\u00e4lt", "sich", "das", "Tuch", "vor", "der", "lan\u00b7gen", "Na\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}}, "stanza.47": {"line.1": {"text": "So geht die Sage \u2013 Ist sie wahr?", "tokens": ["So", "geht", "die", "Sa\u00b7ge", "\u2013", "Ist", "sie", "wahr", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$(", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wer wei\u00df es? Wir Menschen sind nicht vollkommen.", "tokens": ["Wer", "wei\u00df", "es", "?", "Wir", "Men\u00b7schen", "sind", "nicht", "voll\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "NN", "VAFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Sogar der gro\u00dfe Horatius Flaccus", "tokens": ["So\u00b7gar", "der", "gro\u00b7\u00dfe", "Ho\u00b7ra\u00b7ti\u00b7us", "Flac\u00b7cus"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hat in der Schlacht Rei\u00dfaus genommen.", "tokens": ["Hat", "in", "der", "Schlacht", "Rei\u00df\u00b7aus", "ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Das ist auf Erden des Sch\u00f6nen Los!", "tokens": ["Das", "ist", "auf", "Er\u00b7den", "des", "Sch\u00f6\u00b7nen", "Los", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "APPR", "NN", "ART", "NN", "NE", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Die Feinen gehn unter, ganz wie die Plumpen;", "tokens": ["Die", "Fei\u00b7nen", "gehn", "un\u00b7ter", ",", "ganz", "wie", "die", "Plum\u00b7pen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "$,", "ADV", "KOKOM", "ART", "NN", "$."], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.3": {"text": "Ihr Lied wird Makulatur, sie selber,", "tokens": ["Ihr", "Lied", "wird", "Ma\u00b7ku\u00b7la\u00b7tur", ",", "sie", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "$,", "PPER", "ADV", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Die Dichter, werden am Ende Lumpen.", "tokens": ["Die", "Dich\u00b7ter", ",", "wer\u00b7den", "am", "En\u00b7de", "Lum\u00b7pen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VAFIN", "APPRART", "NN", "NN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}}}}}