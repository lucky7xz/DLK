{"dta.poem.18575": {"metadata": {"author": {"name": "Hunold, Christian Friedrich", "birth": "N.A.", "death": "N.A."}, "title": "N.A.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1702", "urn": "urn:nbn:de:kobv:b4-200905197766", "language": ["de:0.99"], "booktitle": "Hunold, Christian Friedrich: Die Edle Bem\u00fchung m\u00fcssiger Stunden. Hamburg, 1702."}, "poem": {"stanza.1": {"line.1": {"text": "Ach s\u00fcsse Stunde brich doch an/", "tokens": ["Ach", "s\u00fcs\u00b7se", "Stun\u00b7de", "brich", "doch", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADJA", "NN", "VVFIN", "ADV", "PTKVZ", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Hoffen zu vergn\u00fcgen.", "tokens": ["Mein", "Hof\u00b7fen", "zu", "ver\u00b7gn\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mein Hertze dencket stets daran", "tokens": ["Mein", "Hert\u00b7ze", "den\u00b7cket", "stets", "da\u00b7ran"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "VVFIN", "VVFIN", "ADV", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Durch ", "tokens": ["Durch"], "token_info": ["word"], "pos": ["APPR"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "Drum Amor komm und sey bereit/", "tokens": ["Drum", "A\u00b7mor", "komm", "und", "sey", "be\u00b7reit", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NE", "VVFIN", "KON", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu kr\u00f6nen die Best\u00e4ndigkeit.", "tokens": ["Zu", "kr\u00f6\u00b7nen", "die", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Was kan wohl ein s\u00fc\u00dfre Lust/", "tokens": ["Was", "kan", "wohl", "ein", "s\u00fc\u00df\u00b7re", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "ART", "ADJA", "NN", "$("], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und frohern Sinn verstatten?", "tokens": ["Und", "fro\u00b7hern", "Sinn", "ver\u00b7stat\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als wenn die allersch\u00f6nste Brust", "tokens": ["Als", "wenn", "die", "al\u00b7ler\u00b7sch\u00f6ns\u00b7te", "Brust"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sich wird mit meiner gatten.", "tokens": ["Sich", "wird", "mit", "mei\u00b7ner", "gat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VAFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Dr\u00fcm Amor/ komm und sey bereit/", "tokens": ["Dr\u00fcm", "A\u00b7mor", "/", "komm", "und", "sey", "be\u00b7reit", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$(", "VVFIN", "KON", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu kr\u00f6nen die Best\u00e4ndigkeit.", "tokens": ["Zu", "kr\u00f6\u00b7nen", "die", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch bist du gantz von Stahl und Stein/", "tokens": ["Doch", "bist", "du", "gantz", "von", "Stahl", "und", "Stein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Soll ich zuletzt verderben?", "tokens": ["Soll", "ich", "zu\u00b7letzt", "ver\u00b7der\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So la\u00df mich nur so gl\u00fccklich seyn/", "tokens": ["So", "la\u00df", "mich", "nur", "so", "gl\u00fcck\u00b7lich", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "ADV", "ADV", "ADJD", "VAINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In deinen Arm zu sterben.", "tokens": ["In", "dei\u00b7nen", "Arm", "zu", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ach! Amor komm/ ich bin bereit/", "tokens": ["Ach", "!", "A\u00b7mor", "komm", "/", "ich", "bin", "be\u00b7reit", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "NE", "VVFIN", "$(", "PPER", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zu k\u00fcssen deine Sterblichkeit.", "tokens": ["Zu", "k\u00fcs\u00b7sen", "dei\u00b7ne", "Sterb\u00b7lich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}