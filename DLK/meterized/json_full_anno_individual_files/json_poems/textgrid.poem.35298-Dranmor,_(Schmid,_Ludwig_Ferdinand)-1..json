{"textgrid.poem.35298": {"metadata": {"author": {"name": "Dranmor, (Schmid, Ludwig Ferdinand)", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In fernen und gewitterschwangern Tagen", "tokens": ["In", "fer\u00b7nen", "und", "ge\u00b7wit\u00b7ter\u00b7schwan\u00b7gern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Floh durch die Pampa hin ein Reisewagen.", "tokens": ["Floh", "durch", "die", "Pam\u00b7pa", "hin", "ein", "Rei\u00b7se\u00b7wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NE", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Ein Gaucho, auf der Stirn das Todesmal,", "tokens": ["Ein", "Gau\u00b7cho", ",", "auf", "der", "Stirn", "das", "To\u00b7des\u00b7mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein H\u00e4uptling sa\u00df darin, ein General,", "tokens": ["Ein", "H\u00e4upt\u00b7ling", "sa\u00df", "da\u00b7rin", ",", "ein", "Ge\u00b7ne\u00b7ral", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Quiroga \u2013 von der heimatlichen Erde", "tokens": ["Qui\u00b7ro\u00b7ga", "\u2013", "von", "der", "hei\u00b7mat\u00b7li\u00b7chen", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Nur eines fordernd: Pferde, frische Pferde!", "tokens": ["Nur", "ei\u00b7nes", "for\u00b7dernd", ":", "Pfer\u00b7de", ",", "fri\u00b7sche", "Pfer\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "$.", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "\u00bbha, ein Gespann!\u00ab \u2013 das war sein steter Ruf \u2013", "tokens": ["\u00bb", "ha", ",", "ein", "Ge\u00b7spann", "!", "\u00ab", "\u2013", "das", "war", "sein", "ste\u00b7ter", "Ruf", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ART", "NN", "$.", "$(", "$(", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbmein Schicksal h\u00e4ngt an eines Rosses Huf.\u00ab", "tokens": ["\u00bb", "mein", "Schick\u00b7sal", "h\u00e4ngt", "an", "ei\u00b7nes", "Ros\u00b7ses", "Huf", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Sein blutgetr\u00e4nktes Banner war zerrissen;", "tokens": ["Sein", "blut\u00b7ge\u00b7tr\u00e4nk\u00b7tes", "Ban\u00b7ner", "war", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch durch die Wildnis trieb ihn sein Gewissen.", "tokens": ["Doch", "durch", "die", "Wild\u00b7nis", "trieb", "ihn", "sein", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Er mu\u00dfte sterben \u2013 und umsonst gewarnt", "tokens": ["Er", "mu\u00df\u00b7te", "ster\u00b7ben", "\u2013", "und", "um\u00b7sonst", "ge\u00b7warnt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$(", "KON", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kam er von C\u00f3rdova, verfolgt, umgarnt.", "tokens": ["Kam", "er", "von", "C\u00f3r\u00b7do\u00b7va", ",", "ver\u00b7folgt", ",", "um\u00b7garnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NE", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.7": {"line.1": {"text": "\u00bbfort, fort!\u00ab \u2013 Ein D\u00e4mon spornte seine Flanken;", "tokens": ["\u00bb", "fort", ",", "fort", "!", "\u00ab", "\u2013", "Ein", "D\u00e4\u00b7mon", "sporn\u00b7te", "sei\u00b7ne", "Flan\u00b7ken", ";"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PTKVZ", "$.", "$(", "$(", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach Buenos-Ayres flogen die Gedanken", "tokens": ["Nach", "Bu\u00b7e\u00b7nos\u00b7Ay\u00b7res", "flo\u00b7gen", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.8": {"line.1": {"text": "Dem Feinde zu, den die Geschichte kennt", "tokens": ["Dem", "Fein\u00b7de", "zu", ",", "den", "die", "Ge\u00b7schich\u00b7te", "kennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Santos Per\u00e9z war dessen Instrument.", "tokens": ["San\u00b7tos", "Per\u00e9z", "war", "des\u00b7sen", "Inst\u00b7ru\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "PDS", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "Ein Sohn der Pampa, grimmig, racheschnaubend,", "tokens": ["Ein", "Sohn", "der", "Pam\u00b7pa", ",", "grim\u00b7mig", ",", "ra\u00b7ch\u00b7e\u00b7schnau\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dabei an eine hohe Sendung glaubend;", "tokens": ["Da\u00b7bei", "an", "ei\u00b7ne", "ho\u00b7he", "Sen\u00b7dung", "glau\u00b7bend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Durchtobt von z\u00fcgelloser Leidenschaft,", "tokens": ["Durch\u00b7tobt", "von", "z\u00fc\u00b7gel\u00b7lo\u00b7ser", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und doch \u2013 ein junger Baum voll edler Kraft.", "tokens": ["Und", "doch", "\u2013", "ein", "jun\u00b7ger", "Baum", "voll", "ed\u00b7ler", "Kraft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ART", "ADJA", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Beritten h\u00e4lt er dort mit Kameraden", "tokens": ["Be\u00b7rit\u00b7ten", "h\u00e4lt", "er", "dort", "mit", "Ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Busche, die Pistolen scharf geladen.", "tokens": ["Im", "Bu\u00b7sche", ",", "die", "Pis\u00b7to\u00b7len", "scharf", "ge\u00b7la\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Quiroga naht \u2013 Galopp und Peitschenknall", "tokens": ["Qui\u00b7ro\u00b7ga", "naht", "\u2013", "Ga\u00b7lopp", "und", "Peit\u00b7schen\u00b7knall"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$(", "NE", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verk\u00fcnden ihn. \u2013 Vorw\u00e4rts! \u2013 Ein Schu\u00df \u2013 ein Fall \u2013 \u2013", "tokens": ["Ver\u00b7k\u00fcn\u00b7den", "ihn", ".", "\u2013", "Vor\u00b7w\u00e4rts", "!", "\u2013", "Ein", "Schu\u00df", "\u2013", "ein", "Fall", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$.", "$(", "ADV", "$.", "$(", "ART", "NN", "$(", "ART", "NN", "$(", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.13": {"line.1": {"text": "Durchs Auge ist die Kugel ihm geflogen,", "tokens": ["Durchs", "Au\u00b7ge", "ist", "die", "Ku\u00b7gel", "ihm", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die schwarze That, der grause Mord vollzogen.", "tokens": ["Die", "schwar\u00b7ze", "That", ",", "der", "grau\u00b7se", "Mord", "voll\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "\u00bbjetzt\u00ab, ruft Per\u00e9z, \u00bbdas andre abgethan:", "tokens": ["\u00bb", "jetzt", "\u00ab", ",", "ruft", "Per\u00e9z", ",", "\u00bb", "das", "and\u00b7re", "ab\u00b7ge\u00b7than", ":"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ART", "ADJA", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Begleiter, Diener \u2013 alle m\u00fcssen dran;", "tokens": ["Be\u00b7glei\u00b7ter", ",", "Die\u00b7ner", "\u2013", "al\u00b7le", "m\u00fcs\u00b7sen", "dran", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$(", "PIS", "VMFIN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.15": {"line.1": {"text": "Die Messer her, die H\u00e4lse abgeschnitten!\u00ab", "tokens": ["Die", "Mes\u00b7ser", "her", ",", "die", "H\u00e4l\u00b7se", "ab\u00b7ge\u00b7schnit\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da kommt er auf den einen losgeschritten", "tokens": ["Da", "kommt", "er", "auf", "den", "ei\u00b7nen", "los\u00b7ge\u00b7schrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.16": {"line.1": {"text": "Und fragt: \u00bbWer ist der kleine Postillon", "tokens": ["Und", "fragt", ":", "\u00bb", "Wer", "ist", "der", "klei\u00b7ne", "Pos\u00b7til\u00b7lon"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dort auf dem Schimmel?\u00ab \u2013 \u00bbMeiner Schwester Sohn,\u00ab", "tokens": ["Dort", "auf", "dem", "Schim\u00b7mel", "?", "\u00ab", "\u2013", "\u00bb", "Mei\u00b7ner", "Schwes\u00b7ter", "Sohn", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$(", "$(", "$(", "PPOSAT", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.17": {"line.1": {"text": "Antwortet jener; \u00bbo es w\u00e4re schade", "tokens": ["Ant\u00b7wor\u00b7tet", "je\u00b7ner", ";", "\u00bb", "o", "es", "w\u00e4\u00b7re", "scha\u00b7de"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "$.", "$(", "FM", "PPER", "VAFIN", "ADJD"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "F\u00fcr diesen Jungen; Gnade, Se\u00f1or, Gnade \u2013!\u00ab", "tokens": ["F\u00fcr", "die\u00b7sen", "Jun\u00b7gen", ";", "Gna\u00b7de", ",", "Se\u00f1or", ",", "Gna\u00b7de", "\u2013", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "NN", "$,", "NE", "$,", "NN", "$(", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.18": {"line.1": {"text": "\u00bbwas Gnade!\u00ab rast der M\u00f6rder; \u00bber wie du! \u2013", "tokens": ["\u00bb", "was", "Gna\u00b7de", "!", "\u00ab", "rast", "der", "M\u00f6r\u00b7der", ";", "\u00bb", "er", "wie", "du", "!", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "NN", "$.", "$(", "VVFIN", "ART", "NN", "$.", "$(", "PPER", "PWAV", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Blut fordert Blut.\u00ab Ein Fluch \u2013 dann st\u00f6\u00dft er zu.", "tokens": ["Blut", "for\u00b7dert", "Blut", ".", "\u00ab", "Ein", "Fluch", "\u2013", "dann", "st\u00f6\u00dft", "er", "zu", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$.", "$(", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.19": {"line.1": {"text": "Und von dem Leichnam wieder aufgesprungen,", "tokens": ["Und", "von", "dem", "Leich\u00b7nam", "wie\u00b7der", "auf\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Fa\u00dft er am Fu\u00df den armen Gauchojungen.", "tokens": ["Fa\u00dft", "er", "am", "Fu\u00df", "den", "ar\u00b7men", "Gauc\u00b7ho\u00b7jun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Ein Knabe ist's \u2013 acht Jahre oder zehn \u2013,", "tokens": ["Ein", "Kna\u00b7be", "ist's", "\u2013", "acht", "Jah\u00b7re", "o\u00b7der", "zehn", "\u2013", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "CARD", "NN", "KON", "CARD", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Mutter hat ihn ungern ziehen sehn.", "tokens": ["Die", "Mut\u00b7ter", "hat", "ihn", "un\u00b7gern", "zie\u00b7hen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Er aber, um den Onkel zu begleiten,", "tokens": ["Er", "a\u00b7ber", ",", "um", "den", "On\u00b7kel", "zu", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "KOUI", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Um einmal recht nach Herzenslust zu reiten,", "tokens": ["Um", "ein\u00b7mal", "recht", "nach", "Her\u00b7zens\u00b7lust", "zu", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADJD", "APPR", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Bat lange, lange \u2013 und sie lie\u00df ihn ziehn.", "tokens": ["Bat", "lan\u00b7ge", ",", "lan\u00b7ge", "\u2013", "und", "sie", "lie\u00df", "ihn", "ziehn", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADV", "$(", "KON", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Jetzt ist's zu sp\u00e4t, zu ihr zur\u00fcckzufliehn.", "tokens": ["Jetzt", "ist's", "zu", "sp\u00e4t", ",", "zu", "ihr", "zu\u00b7r\u00fcck\u00b7zu\u00b7fliehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKA", "ADJD", "$,", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Wohl greift er krampfhaft in des Schimmels M\u00e4hne;", "tokens": ["Wohl", "greift", "er", "krampf\u00b7haft", "in", "des", "Schim\u00b7mels", "M\u00e4h\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umsonst \u2013 zu Boden rei\u00dft ihn die Hy\u00e4ne.", "tokens": ["Um\u00b7sonst", "\u2013", "zu", "Bo\u00b7den", "rei\u00dft", "ihn", "die", "Hy\u00b7\u00e4\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "APPR", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.24": {"line.1": {"text": "Er f\u00e4llt \u2013 des Henkers Messer ist gez\u00fcckt,", "tokens": ["Er", "f\u00e4llt", "\u2013", "des", "Hen\u00b7kers", "Mes\u00b7ser", "ist", "ge\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und auf des Kindes Brust sein Knie gedr\u00fcckt.", "tokens": ["Und", "auf", "des", "Kin\u00b7des", "Brust", "sein", "Knie", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.25": {"line.1": {"text": "Der Knabe windet sich in Todesschrecken;", "tokens": ["Der", "Kna\u00b7be", "win\u00b7det", "sich", "in", "To\u00b7des\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Thr\u00e4nen, ach, die sein Gesicht bedecken,", "tokens": ["Die", "Thr\u00e4\u00b7nen", ",", "ach", ",", "die", "sein", "Ge\u00b7sicht", "be\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Der Schwei\u00df, der seine blonden Locken n\u00e4\u00dft,", "tokens": ["Der", "Schwei\u00df", ",", "der", "sei\u00b7ne", "blon\u00b7den", "Lo\u00b7cken", "n\u00e4\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Angst, die keine Worte finden l\u00e4\u00dft,", "tokens": ["Die", "Angst", ",", "die", "kei\u00b7ne", "Wor\u00b7te", "fin\u00b7den", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Des Kindes Wimmern, seiner Schw\u00e4che Zeichen \u2013", "tokens": ["Des", "Kin\u00b7des", "Wim\u00b7mern", ",", "sei\u00b7ner", "Schw\u00e4\u00b7che", "Zei\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nichts kann des Ungeheuers Herz erweichen,", "tokens": ["Nichts", "kann", "des", "Un\u00b7ge\u00b7heu\u00b7ers", "Herz", "er\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "In seine Seele f\u00e4llt kein Sonnenstrahl \u2013", "tokens": ["In", "sei\u00b7ne", "See\u00b7le", "f\u00e4llt", "kein", "Son\u00b7nen\u00b7strahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und in die Gurgel bohrt er ihm den Stahl.", "tokens": ["Und", "in", "die", "Gur\u00b7gel", "bohrt", "er", "ihm", "den", "Stahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.29": {"line.1": {"text": "Er l\u00e4\u00dft die Leiche unbegraben liegen,", "tokens": ["Er", "l\u00e4\u00dft", "die", "Lei\u00b7che", "un\u00b7be\u00b7gra\u00b7ben", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und sprengt davon \u2013 die Toten sind verschwiegen.", "tokens": ["Und", "sprengt", "da\u00b7von", "\u2013", "die", "To\u00b7ten", "sind", "ver\u00b7schwie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "In fernen und gewitterschwangern Tagen", "tokens": ["In", "fer\u00b7nen", "und", "ge\u00b7wit\u00b7ter\u00b7schwan\u00b7gern", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Floh durch die Pampa hin ein Reisewagen.", "tokens": ["Floh", "durch", "die", "Pam\u00b7pa", "hin", "ein", "Rei\u00b7se\u00b7wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NE", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "Ein Gaucho, auf der Stirn das Todesmal,", "tokens": ["Ein", "Gau\u00b7cho", ",", "auf", "der", "Stirn", "das", "To\u00b7des\u00b7mal", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein H\u00e4uptling sa\u00df darin, ein General,", "tokens": ["Ein", "H\u00e4upt\u00b7ling", "sa\u00df", "da\u00b7rin", ",", "ein", "Ge\u00b7ne\u00b7ral", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Quiroga \u2013 von der heimatlichen Erde", "tokens": ["Qui\u00b7ro\u00b7ga", "\u2013", "von", "der", "hei\u00b7mat\u00b7li\u00b7chen", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "APPR", "ART", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Nur eines fordernd: Pferde, frische Pferde!", "tokens": ["Nur", "ei\u00b7nes", "for\u00b7dernd", ":", "Pfer\u00b7de", ",", "fri\u00b7sche", "Pfer\u00b7de", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVPP", "$.", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "\u00bbha, ein Gespann!\u00ab \u2013 das war sein steter Ruf \u2013", "tokens": ["\u00bb", "ha", ",", "ein", "Ge\u00b7spann", "!", "\u00ab", "\u2013", "das", "war", "sein", "ste\u00b7ter", "Ruf", "\u2013"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ITJ", "$,", "ART", "NN", "$.", "$(", "$(", "PDS", "VAFIN", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbmein Schicksal h\u00e4ngt an eines Rosses Huf.\u00ab", "tokens": ["\u00bb", "mein", "Schick\u00b7sal", "h\u00e4ngt", "an", "ei\u00b7nes", "Ros\u00b7ses", "Huf", ".", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPOSAT", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Sein blutgetr\u00e4nktes Banner war zerrissen;", "tokens": ["Sein", "blut\u00b7ge\u00b7tr\u00e4nk\u00b7tes", "Ban\u00b7ner", "war", "zer\u00b7ris\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch durch die Wildnis trieb ihn sein Gewissen.", "tokens": ["Doch", "durch", "die", "Wild\u00b7nis", "trieb", "ihn", "sein", "Ge\u00b7wis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Er mu\u00dfte sterben \u2013 und umsonst gewarnt", "tokens": ["Er", "mu\u00df\u00b7te", "ster\u00b7ben", "\u2013", "und", "um\u00b7sonst", "ge\u00b7warnt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VMFIN", "VVINF", "$(", "KON", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Kam er von C\u00f3rdova, verfolgt, umgarnt.", "tokens": ["Kam", "er", "von", "C\u00f3r\u00b7do\u00b7va", ",", "ver\u00b7folgt", ",", "um\u00b7garnt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PPER", "APPR", "NE", "$,", "VVPP", "$,", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.36": {"line.1": {"text": "\u00bbfort, fort!\u00ab \u2013 Ein D\u00e4mon spornte seine Flanken;", "tokens": ["\u00bb", "fort", ",", "fort", "!", "\u00ab", "\u2013", "Ein", "D\u00e4\u00b7mon", "sporn\u00b7te", "sei\u00b7ne", "Flan\u00b7ken", ";"], "token_info": ["punct", "word", "punct", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PTKVZ", "$.", "$(", "$(", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nach Buenos-Ayres flogen die Gedanken", "tokens": ["Nach", "Bu\u00b7e\u00b7nos\u00b7Ay\u00b7res", "flo\u00b7gen", "die", "Ge\u00b7dan\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ART", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}, "stanza.37": {"line.1": {"text": "Dem Feinde zu, den die Geschichte kennt", "tokens": ["Dem", "Fein\u00b7de", "zu", ",", "den", "die", "Ge\u00b7schich\u00b7te", "kennt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "PRELS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Santos Per\u00e9z war dessen Instrument.", "tokens": ["San\u00b7tos", "Per\u00e9z", "war", "des\u00b7sen", "Inst\u00b7ru\u00b7ment", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "PDS", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.38": {"line.1": {"text": "Ein Sohn der Pampa, grimmig, racheschnaubend,", "tokens": ["Ein", "Sohn", "der", "Pam\u00b7pa", ",", "grim\u00b7mig", ",", "ra\u00b7ch\u00b7e\u00b7schnau\u00b7bend", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "ART", "NE", "$,", "ADJD", "$,", "VVPP", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Dabei an eine hohe Sendung glaubend;", "tokens": ["Da\u00b7bei", "an", "ei\u00b7ne", "ho\u00b7he", "Sen\u00b7dung", "glau\u00b7bend", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.39": {"line.1": {"text": "Durchtobt von z\u00fcgelloser Leidenschaft,", "tokens": ["Durch\u00b7tobt", "von", "z\u00fc\u00b7gel\u00b7lo\u00b7ser", "Lei\u00b7den\u00b7schaft", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und doch \u2013 ein junger Baum voll edler Kraft.", "tokens": ["Und", "doch", "\u2013", "ein", "jun\u00b7ger", "Baum", "voll", "ed\u00b7ler", "Kraft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$(", "ART", "ADJA", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.40": {"line.1": {"text": "Beritten h\u00e4lt er dort mit Kameraden", "tokens": ["Be\u00b7rit\u00b7ten", "h\u00e4lt", "er", "dort", "mit", "Ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Im Busche, die Pistolen scharf geladen.", "tokens": ["Im", "Bu\u00b7sche", ",", "die", "Pis\u00b7to\u00b7len", "scharf", "ge\u00b7la\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.41": {"line.1": {"text": "Quiroga naht \u2013 Galopp und Peitschenknall", "tokens": ["Qui\u00b7ro\u00b7ga", "naht", "\u2013", "Ga\u00b7lopp", "und", "Peit\u00b7schen\u00b7knall"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "VVFIN", "$(", "NE", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Verk\u00fcnden ihn. \u2013 Vorw\u00e4rts! \u2013 Ein Schu\u00df \u2013 ein Fall \u2013 \u2013", "tokens": ["Ver\u00b7k\u00fcn\u00b7den", "ihn", ".", "\u2013", "Vor\u00b7w\u00e4rts", "!", "\u2013", "Ein", "Schu\u00df", "\u2013", "ein", "Fall", "\u2013", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["NN", "PPER", "$.", "$(", "ADV", "$.", "$(", "ART", "NN", "$(", "ART", "NN", "$(", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.42": {"line.1": {"text": "Durchs Auge ist die Kugel ihm geflogen,", "tokens": ["Durchs", "Au\u00b7ge", "ist", "die", "Ku\u00b7gel", "ihm", "ge\u00b7flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die schwarze That, der grause Mord vollzogen.", "tokens": ["Die", "schwar\u00b7ze", "That", ",", "der", "grau\u00b7se", "Mord", "voll\u00b7zo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "\u00bbjetzt\u00ab, ruft Per\u00e9z, \u00bbdas andre abgethan:", "tokens": ["\u00bb", "jetzt", "\u00ab", ",", "ruft", "Per\u00e9z", ",", "\u00bb", "das", "and\u00b7re", "ab\u00b7ge\u00b7than", ":"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$(", "$,", "VVFIN", "NE", "$,", "$(", "ART", "ADJA", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Begleiter, Diener \u2013 alle m\u00fcssen dran;", "tokens": ["Be\u00b7glei\u00b7ter", ",", "Die\u00b7ner", "\u2013", "al\u00b7le", "m\u00fcs\u00b7sen", "dran", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$(", "PIS", "VMFIN", "PAV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Die Messer her, die H\u00e4lse abgeschnitten!\u00ab", "tokens": ["Die", "Mes\u00b7ser", "her", ",", "die", "H\u00e4l\u00b7se", "ab\u00b7ge\u00b7schnit\u00b7ten", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Da kommt er auf den einen losgeschritten", "tokens": ["Da", "kommt", "er", "auf", "den", "ei\u00b7nen", "los\u00b7ge\u00b7schrit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.45": {"line.1": {"text": "Und fragt: \u00bbWer ist der kleine Postillon", "tokens": ["Und", "fragt", ":", "\u00bb", "Wer", "ist", "der", "klei\u00b7ne", "Pos\u00b7til\u00b7lon"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$.", "$(", "PWS", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Dort auf dem Schimmel?\u00ab \u2013 \u00bbMeiner Schwester Sohn,\u00ab", "tokens": ["Dort", "auf", "dem", "Schim\u00b7mel", "?", "\u00ab", "\u2013", "\u00bb", "Mei\u00b7ner", "Schwes\u00b7ter", "Sohn", ",", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$.", "$(", "$(", "$(", "PPOSAT", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.46": {"line.1": {"text": "Antwortet jener; \u00bbo es w\u00e4re schade", "tokens": ["Ant\u00b7wor\u00b7tet", "je\u00b7ner", ";", "\u00bb", "o", "es", "w\u00e4\u00b7re", "scha\u00b7de"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PDAT", "$.", "$(", "FM", "PPER", "VAFIN", "ADJD"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "F\u00fcr diesen Jungen; Gnade, Se\u00f1or, Gnade \u2013!\u00ab", "tokens": ["F\u00fcr", "die\u00b7sen", "Jun\u00b7gen", ";", "Gna\u00b7de", ",", "Se\u00f1or", ",", "Gna\u00b7de", "\u2013", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "punct", "punct"], "pos": ["APPR", "PDAT", "NN", "$.", "NN", "$,", "NE", "$,", "NN", "$(", "$.", "$("], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.47": {"line.1": {"text": "\u00bbwas Gnade!\u00ab rast der M\u00f6rder; \u00bber wie du! \u2013", "tokens": ["\u00bb", "was", "Gna\u00b7de", "!", "\u00ab", "rast", "der", "M\u00f6r\u00b7der", ";", "\u00bb", "er", "wie", "du", "!", "\u2013"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PWS", "NN", "$.", "$(", "VVFIN", "ART", "NN", "$.", "$(", "PPER", "PWAV", "PPER", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Blut fordert Blut.\u00ab Ein Fluch \u2013 dann st\u00f6\u00dft er zu.", "tokens": ["Blut", "for\u00b7dert", "Blut", ".", "\u00ab", "Ein", "Fluch", "\u2013", "dann", "st\u00f6\u00dft", "er", "zu", "."], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "NN", "$.", "$(", "ART", "NN", "$(", "ADV", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.48": {"line.1": {"text": "Und von dem Leichnam wieder aufgesprungen,", "tokens": ["Und", "von", "dem", "Leich\u00b7nam", "wie\u00b7der", "auf\u00b7ge\u00b7sprun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Fa\u00dft er am Fu\u00df den armen Gauchojungen.", "tokens": ["Fa\u00dft", "er", "am", "Fu\u00df", "den", "ar\u00b7men", "Gauc\u00b7ho\u00b7jun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.49": {"line.1": {"text": "Ein Knabe ist's \u2013 acht Jahre oder zehn \u2013,", "tokens": ["Ein", "Kna\u00b7be", "ist's", "\u2013", "acht", "Jah\u00b7re", "o\u00b7der", "zehn", "\u2013", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "CARD", "NN", "KON", "CARD", "$(", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Mutter hat ihn ungern ziehen sehn.", "tokens": ["Die", "Mut\u00b7ter", "hat", "ihn", "un\u00b7gern", "zie\u00b7hen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.50": {"line.1": {"text": "Er aber, um den Onkel zu begleiten,", "tokens": ["Er", "a\u00b7ber", ",", "um", "den", "On\u00b7kel", "zu", "be\u00b7glei\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "KOUI", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Um einmal recht nach Herzenslust zu reiten,", "tokens": ["Um", "ein\u00b7mal", "recht", "nach", "Her\u00b7zens\u00b7lust", "zu", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "ADJD", "APPR", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.51": {"line.1": {"text": "Bat lange, lange \u2013 und sie lie\u00df ihn ziehn.", "tokens": ["Bat", "lan\u00b7ge", ",", "lan\u00b7ge", "\u2013", "und", "sie", "lie\u00df", "ihn", "ziehn", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ADV", "$(", "KON", "PPER", "VVFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Jetzt ist's zu sp\u00e4t, zu ihr zur\u00fcckzufliehn.", "tokens": ["Jetzt", "ist's", "zu", "sp\u00e4t", ",", "zu", "ihr", "zu\u00b7r\u00fcck\u00b7zu\u00b7fliehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKA", "ADJD", "$,", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.52": {"line.1": {"text": "Wohl greift er krampfhaft in des Schimmels M\u00e4hne;", "tokens": ["Wohl", "greift", "er", "krampf\u00b7haft", "in", "des", "Schim\u00b7mels", "M\u00e4h\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Umsonst \u2013 zu Boden rei\u00dft ihn die Hy\u00e4ne.", "tokens": ["Um\u00b7sonst", "\u2013", "zu", "Bo\u00b7den", "rei\u00dft", "ihn", "die", "Hy\u00b7\u00e4\u00b7ne", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$(", "APPR", "NN", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Er f\u00e4llt \u2013 des Henkers Messer ist gez\u00fcckt,", "tokens": ["Er", "f\u00e4llt", "\u2013", "des", "Hen\u00b7kers", "Mes\u00b7ser", "ist", "ge\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "ART", "NN", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und auf des Kindes Brust sein Knie gedr\u00fcckt.", "tokens": ["Und", "auf", "des", "Kin\u00b7des", "Brust", "sein", "Knie", "ge\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Der Knabe windet sich in Todesschrecken;", "tokens": ["Der", "Kna\u00b7be", "win\u00b7det", "sich", "in", "To\u00b7des\u00b7schre\u00b7cken", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Thr\u00e4nen, ach, die sein Gesicht bedecken,", "tokens": ["Die", "Thr\u00e4\u00b7nen", ",", "ach", ",", "die", "sein", "Ge\u00b7sicht", "be\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ITJ", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Der Schwei\u00df, der seine blonden Locken n\u00e4\u00dft,", "tokens": ["Der", "Schwei\u00df", ",", "der", "sei\u00b7ne", "blon\u00b7den", "Lo\u00b7cken", "n\u00e4\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Angst, die keine Worte finden l\u00e4\u00dft,", "tokens": ["Die", "Angst", ",", "die", "kei\u00b7ne", "Wor\u00b7te", "fin\u00b7den", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "Des Kindes Wimmern, seiner Schw\u00e4che Zeichen \u2013", "tokens": ["Des", "Kin\u00b7des", "Wim\u00b7mern", ",", "sei\u00b7ner", "Schw\u00e4\u00b7che", "Zei\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Nichts kann des Ungeheuers Herz erweichen,", "tokens": ["Nichts", "kann", "des", "Un\u00b7ge\u00b7heu\u00b7ers", "Herz", "er\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "In seine Seele f\u00e4llt kein Sonnenstrahl \u2013", "tokens": ["In", "sei\u00b7ne", "See\u00b7le", "f\u00e4llt", "kein", "Son\u00b7nen\u00b7strahl", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und in die Gurgel bohrt er ihm den Stahl.", "tokens": ["Und", "in", "die", "Gur\u00b7gel", "bohrt", "er", "ihm", "den", "Stahl", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Er l\u00e4\u00dft die Leiche unbegraben liegen,", "tokens": ["Er", "l\u00e4\u00dft", "die", "Lei\u00b7che", "un\u00b7be\u00b7gra\u00b7ben", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und sprengt davon \u2013 die Toten sind verschwiegen.", "tokens": ["Und", "sprengt", "da\u00b7von", "\u2013", "die", "To\u00b7ten", "sind", "ver\u00b7schwie\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "$(", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}