{"textgrid.poem.60718": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ein Mann sah eine Schlange liegen.", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Mann sah eine Schlange liegen.", "tokens": ["Ein", "Mann", "sah", "ei\u00b7ne", "Schlan\u00b7ge", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bbnichtsw\u00fcrdiges Vieh,\u00ab sprach er, \u00bbnun will ich mit Vergn\u00fcgen", "tokens": ["\u00bb", "nichts\u00b7w\u00fcr\u00b7di\u00b7ges", "Vieh", ",", "\u00ab", "sprach", "er", ",", "\u00bb", "nun", "will", "ich", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ADV", "VMFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.3": {"line.1": {"text": "Der Menschheit einen Dienst erweisen.\u00ab", "tokens": ["Der", "Menschheit", "ei\u00b7nen", "Dienst", "er\u00b7wei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bei diesen Worten ward das schlimme Tier \u2013", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "ward", "das", "schlim\u00b7me", "Tier", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gebt acht, ich rede von der Schlange hier,", "tokens": ["Gebt", "acht", ",", "ich", "re\u00b7de", "von", "der", "Schlan\u00b7ge", "hier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn nicht die Menschheit w\u00fcrd ich also preisen \u2013", "tokens": ["Denn", "nicht", "die", "Menschheit", "w\u00fcrd", "ich", "al\u00b7so", "prei\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "VAFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Bei diesen Worten ward das Tier gepackt", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "ward", "das", "Tier", "ge\u00b7packt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ohne weitres eingesackt.", "tokens": ["Und", "oh\u00b7ne", "weit\u00b7res", "ein\u00b7ge\u00b7sackt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Tod war bei dem Mann beschlo\u00dfne Sache,", "tokens": ["Sein", "Tod", "war", "bei", "dem", "Mann", "be\u00b7schlo\u00df\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch hielt er erst ein gro\u00dfes Wortgericht:", "tokens": ["Doch", "hielt", "er", "erst", "ein", "gro\u00b7\u00dfes", "Wort\u00b7ge\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbsinnbild des Undankbaren, f\u00fchle meine Rache!", "tokens": ["\u00bb", "sinn\u00b7bild", "des", "Un\u00b7dank\u00b7ba\u00b7ren", ",", "f\u00fch\u00b7le", "mei\u00b7ne", "Ra\u00b7che", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn B\u00f6sen Gutes zu erweisen,", "tokens": ["Denn", "B\u00f6\u00b7sen", "Gu\u00b7tes", "zu", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Das w\u00e4re gar zu dumm", "tokens": ["Das", "w\u00e4\u00b7re", "gar", "zu", "dumm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Und eine Tat, die schlechten Lohn verspricht.", "tokens": ["Und", "ei\u00b7ne", "Tat", ",", "die", "schlech\u00b7ten", "Lohn", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So sollst du denn zum Hades reisen,", "tokens": ["So", "sollst", "du", "denn", "zum", "Ha\u00b7des", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Dann kannst du nie mehr mir zum Schaden sein.\u00ab", "tokens": ["Dann", "kannst", "du", "nie", "mehr", "mir", "zum", "Scha\u00b7den", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "PPER", "APPRART", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die Schlange blieb darauf nicht stumm.", "tokens": ["Die", "Schlan\u00b7ge", "blieb", "da\u00b7rauf", "nicht", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbwenn man die Undankbaren alle richtet,\u00ab", "tokens": ["\u00bb", "wenn", "man", "die", "Un\u00b7dank\u00b7ba\u00b7ren", "al\u00b7le", "rich\u00b7tet", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PIS", "ART", "NN", "PIS", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Sprach sie, \u00bbwem k\u00f6nnte man denn da verzeihn?", "tokens": ["Sprach", "sie", ",", "\u00bb", "wem", "k\u00f6nn\u00b7te", "man", "denn", "da", "ver\u00b7zeihn", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "$(", "PWS", "VMFIN", "PIS", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Du, dessen Wille mich vernichtet,", "tokens": ["Du", ",", "des\u00b7sen", "Wil\u00b7le", "mich", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Bist dir zur Rechenschaft verpflichtet,", "tokens": ["Bist", "dir", "zur", "Re\u00b7chen\u00b7schaft", "ver\u00b7pflich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Blick in dein eignes Herz hinein,", "tokens": ["Blick", "in", "dein", "eig\u00b7nes", "Herz", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Ob du, was du gerechtes Urteil nennst,", "tokens": ["Ob", "du", ",", "was", "du", "ge\u00b7rech\u00b7tes", "Ur\u00b7teil", "nennst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWS", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Nicht bald als Laune nur erkennst,", "tokens": ["Nicht", "bald", "als", "Lau\u00b7ne", "nur", "er\u00b7kennst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOUS", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Als Willk\u00fcr oder Machtgel\u00fcste.", "tokens": ["Als", "Will\u00b7k\u00fcr", "o\u00b7der", "Macht\u00b7ge\u00b7l\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "Sprich mir das Urteil, wenn du magst,", "tokens": ["Sprich", "mir", "das", "Ur\u00b7teil", ",", "wenn", "du", "magst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Doch da du mich so hart verklagst,", "tokens": ["Doch", "da", "du", "mich", "so", "hart", "ver\u00b7klagst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "So h\u00f6re, da\u00df ich l\u00fcgen m\u00fc\u00dfte,", "tokens": ["So", "h\u00f6\u00b7re", ",", "da\u00df", "ich", "l\u00fc\u00b7gen", "m\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Mich als des Undanks Sinnbild zu bekennen,", "tokens": ["Mich", "als", "des", "Un\u00b7danks", "Sinn\u00b7bild", "zu", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Doch mu\u00df ich dich ein solches Sinnbild nennen.\u00ab", "tokens": ["Doch", "mu\u00df", "ich", "dich", "ein", "sol\u00b7ches", "Sinn\u00b7bild", "nen\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "ART", "PIAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Der andre stutzte, wich zur\u00fcck und sagte:", "tokens": ["Der", "and\u00b7re", "stutz\u00b7te", ",", "wich", "zu\u00b7r\u00fcck", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "\u00bbsehr nichtige Gr\u00fcnde hast du vorgebracht,", "tokens": ["\u00bb", "sehr", "nich\u00b7ti\u00b7ge", "Gr\u00fcn\u00b7de", "hast", "du", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Sie gelten nichts; denn mein ist Recht und Macht.", "tokens": ["Sie", "gel\u00b7ten", "nichts", ";", "denn", "mein", "ist", "Recht", "und", "Macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$.", "KON", "PPOSAT", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Doch w\u00e4r es gut, wenn einen Dritten man befragte.\u00ab", "tokens": ["Doch", "w\u00e4r", "es", "gut", ",", "wenn", "ei\u00b7nen", "Drit\u00b7ten", "man", "be\u00b7frag\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "ART", "ADJA", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "\u00bbso sei es,\u00ab sagte das Reptil.", "tokens": ["\u00bb", "so", "sei", "es", ",", "\u00ab", "sag\u00b7te", "das", "Rep\u00b7til", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "$,", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Da eine Kuh des Weges ging,", "tokens": ["Da", "ei\u00b7ne", "Kuh", "des", "We\u00b7ges", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Ruft man sie an, da\u00df sie das Urteil f\u00e4lle.", "tokens": ["Ruft", "man", "sie", "an", ",", "da\u00df", "sie", "das", "Ur\u00b7teil", "f\u00e4l\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "\u00bbdazu,\u00ab sprach sie, \u00bbgeh\u00f6rt nicht viel.", "tokens": ["\u00bb", "da\u00b7zu", ",", "\u00ab", "sprach", "sie", ",", "\u00bb", "ge\u00b7h\u00f6rt", "nicht", "viel", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.37": {"text": "Der Bauer, der die Schlange fing,", "tokens": ["Der", "Bau\u00b7er", ",", "der", "die", "Schlan\u00b7ge", "fing", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Geb ihr die Freiheit auf der Stelle!", "tokens": ["Geb", "ihr", "die", "Frei\u00b7heit", "auf", "der", "Stel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Sie ist im Recht; weshalb denn immer t\u00f6ten?", "tokens": ["Sie", "ist", "im", "Recht", ";", "we\u00b7shalb", "denn", "im\u00b7mer", "t\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "$.", "PWAV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Seit vielen Jahren n\u00e4hrt sich dieser hier", "tokens": ["Seit", "vie\u00b7len", "Jah\u00b7ren", "n\u00e4hrt", "sich", "die\u00b7ser", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PRF", "PDAT", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Von meiner Milch und w\u00e4r in argen N\u00f6ten,", "tokens": ["Von", "mei\u00b7ner", "Milch", "und", "w\u00e4r", "in", "ar\u00b7gen", "N\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Wenn meine Euter ihm nicht Nahrung b\u00f6ten;", "tokens": ["Wenn", "mei\u00b7ne", "Eu\u00b7ter", "ihm", "nicht", "Nah\u00b7rung", "b\u00f6\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Selbst meine Kinder nimmt er mir.", "tokens": ["Selbst", "mei\u00b7ne", "Kin\u00b7der", "nimmt", "er", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Jetzt bin ich alt und mu\u00df im Winkel stehen,", "tokens": ["Jetzt", "bin", "ich", "alt", "und", "mu\u00df", "im", "Win\u00b7kel", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Und ohne Nahrung l\u00e4\u00dft er mich.", "tokens": ["Und", "oh\u00b7ne", "Nah\u00b7rung", "l\u00e4\u00dft", "er", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Ja, d\u00fcrft ich auf die Weide gehen!", "tokens": ["Ja", ",", "d\u00fcrft", "ich", "auf", "die", "Wei\u00b7de", "ge\u00b7hen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Doch bin ich angekettet. H\u00e4tte ich", "tokens": ["Doch", "bin", "ich", "an\u00b7ge\u00b7ket\u00b7tet", ".", "H\u00e4t\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "VVPP", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Die Schlange doch zum Herrn gehabt,", "tokens": ["Die", "Schlan\u00b7ge", "doch", "zum", "Herrn", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Sie w\u00e4re nicht so undankbar gewesen!", "tokens": ["Sie", "w\u00e4\u00b7re", "nicht", "so", "un\u00b7dank\u00b7bar", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Da ihr in eurem Fall mir Richterw\u00fcrde gabt,", "tokens": ["Da", "ihr", "in", "eu\u00b7rem", "Fall", "mir", "Rich\u00b7ter\u00b7w\u00fcr\u00b7de", "gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "So sagte ich, was ich gedacht,", "tokens": ["So", "sag\u00b7te", "ich", ",", "was", "ich", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Und machte nicht viel Federlesen.\u00ab", "tokens": ["Und", "mach\u00b7te", "nicht", "viel", "Fe\u00b7der\u00b7le\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Der Mann erstaunte ob des Richtspruchs sehr.", "tokens": ["Der", "Mann", "er\u00b7staun\u00b7te", "ob", "des", "Richts\u00b7pruchs", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOUS", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Zur Schlange sprach er aufgebracht:", "tokens": ["Zur", "Schlan\u00b7ge", "sprach", "er", "auf\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "\u00bbmu\u00df man denn glauben, was sie sagt?", "tokens": ["\u00bb", "mu\u00df", "man", "denn", "glau\u00b7ben", ",", "was", "sie", "sagt", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PIS", "ADV", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "'s ist eine Schw\u00e4tzerin, ihr Hirn ist leer;", "tokens": ["'s", "ist", "ei\u00b7ne", "Schw\u00e4t\u00b7ze\u00b7rin", ",", "ihr", "Hirn", "ist", "leer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.57": {"text": "Ich rate, da\u00df man diesen Ochsen fragt.\u00ab", "tokens": ["Ich", "ra\u00b7te", ",", "da\u00df", "man", "die\u00b7sen", "Och\u00b7sen", "fragt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "PDAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "\u00bbsch\u00f6n,\u00ab sprach die Schleicherin. Gesagt, getan.", "tokens": ["\u00bb", "sch\u00f6n", ",", "\u00ab", "sprach", "die", "Schlei\u00b7che\u00b7rin", ".", "Ge\u00b7sagt", ",", "ge\u00b7tan", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "$(", "VVFIN", "ART", "NN", "$.", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Der Ochse w\u00e4lzt den Fall im Kopfe hin und her.", "tokens": ["Der", "O\u00b7chse", "w\u00e4lzt", "den", "Fall", "im", "Kop\u00b7fe", "hin", "und", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Er habe, sprach der Grobian,", "tokens": ["Er", "ha\u00b7be", ",", "sprach", "der", "Gro\u00b7bi\u00b7an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Des Jahres ganze Last zu tragen,", "tokens": ["Des", "Jah\u00b7res", "gan\u00b7ze", "Last", "zu", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.62": {"text": "Den Kreislauf aller M\u00fchn durchlaufe er", "tokens": ["Den", "Kreis\u00b7lauf", "al\u00b7ler", "M\u00fchn", "durch\u00b7lau\u00b7fe", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.63": {"text": "Und m\u00fcsse sich f\u00fcr uns auf unsern Feldern plagen,", "tokens": ["Und", "m\u00fcs\u00b7se", "sich", "f\u00fcr", "uns", "auf", "un\u00b7sern", "Fel\u00b7dern", "pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Da\u00df das, was Ceres Menschen wie auch Tieren sende,", "tokens": ["Da\u00df", "das", ",", "was", "Ce\u00b7res", "Men\u00b7schen", "wie", "auch", "Tie\u00b7ren", "sen\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "NE", "NN", "KOKOM", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Zur Frucht gedeihe und uns Nahrung spende.", "tokens": ["Zur", "Frucht", "ge\u00b7dei\u00b7he", "und", "uns", "Nah\u00b7rung", "spen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "KON", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Viel Schl\u00e4ge, wenig Dank. Und sei er alt,", "tokens": ["Viel", "Schl\u00e4\u00b7ge", ",", "we\u00b7nig", "Dank", ".", "Und", "sei", "er", "alt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$.", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.67": {"text": "So meine man ihm Ehre anzutun,", "tokens": ["So", "mei\u00b7ne", "man", "ihm", "Eh\u00b7re", "an\u00b7zu\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.68": {"text": "Wenn man ihn schlachte wie ein Huhn,", "tokens": ["Wenn", "man", "ihn", "schlach\u00b7te", "wie", "ein", "Huhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Um durch sein Blut der G\u00f6tter Zorngewalt", "tokens": ["Um", "durch", "sein", "Blut", "der", "G\u00f6t\u00b7ter", "Zorn\u00b7ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "PPOSAT", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.70": {"text": "In Nachsicht zu verwandeln.", "tokens": ["In", "Nach\u00b7sicht", "zu", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "So sprach der Ochs. Der Mensch darauf: \u00bbZum Schweigen", "tokens": ["So", "sprach", "der", "Ochs", ".", "Der", "Mensch", "da\u00b7rauf", ":", "\u00bb", "Zum", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "PAV", "$.", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "La\u00df uns den \u00fcblen Redner bringen.", "tokens": ["La\u00df", "uns", "den", "\u00fcb\u00b7len", "Red\u00b7ner", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Statt unsern Streitfall zu verhandeln,", "tokens": ["Statt", "un\u00b7sern", "Streit\u00b7fall", "zu", "ver\u00b7han\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Will er sich selbst als Kl\u00e4ger zeigen", "tokens": ["Will", "er", "sich", "selbst", "als", "Kl\u00e4\u00b7ger", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "KOUS", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, statt zu schlichten, selber Klage singen.", "tokens": ["Und", ",", "statt", "zu", "schlich\u00b7ten", ",", "sel\u00b7ber", "Kla\u00b7ge", "sin\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "PTKZU", "VVINF", "$,", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich weise ihn zur\u00fcck.\u00ab Nun wird der Baum gew\u00e4hlt,", "tokens": ["Ich", "wei\u00b7se", "ihn", "zu\u00b7r\u00fcck", ".", "\u00ab", "Nun", "wird", "der", "Baum", "ge\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um Recht zu sprechen; doch das war noch schlimmer.", "tokens": ["Um", "Recht", "zu", "spre\u00b7chen", ";", "doch", "das", "war", "noch", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "PTKZU", "VVINF", "$.", "KON", "PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es wird von ihm gewichtig aufgez\u00e4hlt,", "tokens": ["Es", "wird", "von", "ihm", "ge\u00b7wich\u00b7tig", "auf\u00b7ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wie er vor Regen, Sturm und Hitze", "tokens": ["Wie", "er", "vor", "Re\u00b7gen", ",", "Sturm", "und", "Hit\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mit seinem Schatten uns besch\u00fctze", "tokens": ["Mit", "sei\u00b7nem", "Schat\u00b7ten", "uns", "be\u00b7sch\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und Feldern, G\u00e4rten, selbst dem Zimmer", "tokens": ["Und", "Fel\u00b7dern", ",", "G\u00e4r\u00b7ten", ",", "selbst", "dem", "Zim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Zum Schmuck gereiche, dabei immer", "tokens": ["Zum", "Schmuck", "ge\u00b7rei\u00b7che", ",", "da\u00b7bei", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "$,", "PAV", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Mit Fr\u00fcchten schwer beladen sei;", "tokens": ["Mit", "Fr\u00fcch\u00b7ten", "schwer", "be\u00b7la\u00b7den", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Den Lohn indes bezahle in der Regel", "tokens": ["Den", "Lohn", "in\u00b7des", "be\u00b7zah\u00b7le", "in", "der", "Re\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Mit scharfer Axt ein grober Bauernflegel.", "tokens": ["Mit", "schar\u00b7fer", "Axt", "ein", "gro\u00b7ber", "Bau\u00b7ern\u00b7fle\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Er aber lasse sich herbei,", "tokens": ["Er", "a\u00b7ber", "las\u00b7se", "sich", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit Bl\u00fcten uns im Fr\u00fchling zu erfreuen,", "tokens": ["Mit", "Bl\u00fc\u00b7ten", "uns", "im", "Fr\u00fch\u00b7ling", "zu", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Im Herbst uns Fr\u00fcchte in den Scho\u00df zu streuen.", "tokens": ["Im", "Herbst", "uns", "Fr\u00fcch\u00b7te", "in", "den", "Scho\u00df", "zu", "streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Man danke ihm doch besser ohne Beil!", "tokens": ["Man", "dan\u00b7ke", "ihm", "doch", "bes\u00b7ser", "oh\u00b7ne", "Beil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Dann st\u00e4nde er noch lange ganz und heil.", "tokens": ["Dann", "st\u00e4n\u00b7de", "er", "noch", "lan\u00b7ge", "ganz", "und", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der Mensch fand diesen Richterspruch recht schlecht", "tokens": ["Der", "Mensch", "fand", "die\u00b7sen", "Rich\u00b7ter\u00b7spruch", "recht", "schlecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PDAT", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und wollte nun um jeden Preis sein Recht.", "tokens": ["Und", "woll\u00b7te", "nun", "um", "je\u00b7den", "Preis", "sein", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "\u00bbich bin ein Narr,\u00ab sprach er, \u00bbdie Leute anzuh\u00f6ren,\u00ab", "tokens": ["\u00bb", "ich", "bin", "ein", "Narr", ",", "\u00ab", "sprach", "er", ",", "\u00bb", "die", "Leu\u00b7te", "an\u00b7zu\u00b7h\u00f6\u00b7ren", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ART", "NN", "VVIZU", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Warf Sack mit Inhalt wuchtig auf den Stein", "tokens": ["Warf", "Sack", "mit", "In\u00b7halt", "wuch\u00b7tig", "auf", "den", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "NN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Und schlug der Schlange so den Sch\u00e4del ein.", "tokens": ["Und", "schlug", "der", "Schlan\u00b7ge", "so", "den", "Sch\u00e4\u00b7del", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Es pflegt die M\u00e4chtigen stets zu st\u00f6ren,", "tokens": ["Es", "pflegt", "die", "M\u00e4ch\u00b7ti\u00b7gen", "stets", "zu", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn andre Rechenschaft verlangen,", "tokens": ["Wenn", "and\u00b7re", "Re\u00b7chen\u00b7schaft", "ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn alles soll f\u00fcr sie geboren sein,", "tokens": ["Denn", "al\u00b7les", "soll", "f\u00fcr", "sie", "ge\u00b7bo\u00b7ren", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So Mensch wie Vieh und selbst die Schlangen.", "tokens": ["So", "Mensch", "wie", "Vieh", "und", "selbst", "die", "Schlan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und zeigt doch einer mal die Z\u00e4hne,", "tokens": ["Und", "zeigt", "doch", "ei\u00b7ner", "mal", "die", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist's ein T\u00f6lpel. Nun, ich r\u00e4um es ein.", "tokens": ["So", "ist's", "ein", "T\u00f6l\u00b7pel", ".", "Nun", ",", "ich", "r\u00e4um", "es", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und da\u00df ich die Moral erw\u00e4hne:", "tokens": ["Und", "da\u00df", "ich", "die", "Mo\u00b7ral", "er\u00b7w\u00e4h\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verklage nur von fern; noch besser, la\u00df es sein!", "tokens": ["Ver\u00b7kla\u00b7ge", "nur", "von", "fern", ";", "noch", "bes\u00b7ser", ",", "la\u00df", "es", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJD", "$.", "ADV", "ADJD", "$,", "VVIMP", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Ein Mann sah eine Schlange liegen.", "tokens": ["Ein", "Mann", "sah", "ei\u00b7ne", "Schlan\u00b7ge", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbnichtsw\u00fcrdiges Vieh,\u00ab sprach er, \u00bbnun will ich mit Vergn\u00fcgen", "tokens": ["\u00bb", "nichts\u00b7w\u00fcr\u00b7di\u00b7ges", "Vieh", ",", "\u00ab", "sprach", "er", ",", "\u00bb", "nun", "will", "ich", "mit", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "ADJA", "NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ADV", "VMFIN", "PPER", "APPR", "NN"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}}, "stanza.9": {"line.1": {"text": "Der Menschheit einen Dienst erweisen.\u00ab", "tokens": ["Der", "Menschheit", "ei\u00b7nen", "Dienst", "er\u00b7wei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Bei diesen Worten ward das schlimme Tier \u2013", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "ward", "das", "schlim\u00b7me", "Tier", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gebt acht, ich rede von der Schlange hier,", "tokens": ["Gebt", "acht", ",", "ich", "re\u00b7de", "von", "der", "Schlan\u00b7ge", "hier", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "CARD", "$,", "PPER", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn nicht die Menschheit w\u00fcrd ich also preisen \u2013", "tokens": ["Denn", "nicht", "die", "Menschheit", "w\u00fcrd", "ich", "al\u00b7so", "prei\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ART", "NN", "VAFIN", "PPER", "ADV", "VVFIN", "$("], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.5": {"text": "Bei diesen Worten ward das Tier gepackt", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "ward", "das", "Tier", "ge\u00b7packt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ohne weitres eingesackt.", "tokens": ["Und", "oh\u00b7ne", "weit\u00b7res", "ein\u00b7ge\u00b7sackt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Sein Tod war bei dem Mann beschlo\u00dfne Sache,", "tokens": ["Sein", "Tod", "war", "bei", "dem", "Mann", "be\u00b7schlo\u00df\u00b7ne", "Sa\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Doch hielt er erst ein gro\u00dfes Wortgericht:", "tokens": ["Doch", "hielt", "er", "erst", "ein", "gro\u00b7\u00dfes", "Wort\u00b7ge\u00b7richt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "\u00bbsinnbild des Undankbaren, f\u00fchle meine Rache!", "tokens": ["\u00bb", "sinn\u00b7bild", "des", "Un\u00b7dank\u00b7ba\u00b7ren", ",", "f\u00fch\u00b7le", "mei\u00b7ne", "Ra\u00b7che", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Denn B\u00f6sen Gutes zu erweisen,", "tokens": ["Denn", "B\u00f6\u00b7sen", "Gu\u00b7tes", "zu", "er\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Das w\u00e4re gar zu dumm", "tokens": ["Das", "w\u00e4\u00b7re", "gar", "zu", "dumm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ADV", "PTKA", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Und eine Tat, die schlechten Lohn verspricht.", "tokens": ["Und", "ei\u00b7ne", "Tat", ",", "die", "schlech\u00b7ten", "Lohn", "ver\u00b7spricht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So sollst du denn zum Hades reisen,", "tokens": ["So", "sollst", "du", "denn", "zum", "Ha\u00b7des", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Dann kannst du nie mehr mir zum Schaden sein.\u00ab", "tokens": ["Dann", "kannst", "du", "nie", "mehr", "mir", "zum", "Scha\u00b7den", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "PPER", "APPRART", "NN", "VAINF", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die Schlange blieb darauf nicht stumm.", "tokens": ["Die", "Schlan\u00b7ge", "blieb", "da\u00b7rauf", "nicht", "stumm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PAV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "\u00bbwenn man die Undankbaren alle richtet,\u00ab", "tokens": ["\u00bb", "wenn", "man", "die", "Un\u00b7dank\u00b7ba\u00b7ren", "al\u00b7le", "rich\u00b7tet", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "PIS", "ART", "NN", "PIS", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Sprach sie, \u00bbwem k\u00f6nnte man denn da verzeihn?", "tokens": ["Sprach", "sie", ",", "\u00bb", "wem", "k\u00f6nn\u00b7te", "man", "denn", "da", "ver\u00b7zeihn", "?"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "$(", "PWS", "VMFIN", "PIS", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Du, dessen Wille mich vernichtet,", "tokens": ["Du", ",", "des\u00b7sen", "Wil\u00b7le", "mich", "ver\u00b7nich\u00b7tet", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Bist dir zur Rechenschaft verpflichtet,", "tokens": ["Bist", "dir", "zur", "Re\u00b7chen\u00b7schaft", "ver\u00b7pflich\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "Blick in dein eignes Herz hinein,", "tokens": ["Blick", "in", "dein", "eig\u00b7nes", "Herz", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "ADJA", "NN", "PTKVZ", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Ob du, was du gerechtes Urteil nennst,", "tokens": ["Ob", "du", ",", "was", "du", "ge\u00b7rech\u00b7tes", "Ur\u00b7teil", "nennst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PWS", "PPER", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Nicht bald als Laune nur erkennst,", "tokens": ["Nicht", "bald", "als", "Lau\u00b7ne", "nur", "er\u00b7kennst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "KOUS", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Als Willk\u00fcr oder Machtgel\u00fcste.", "tokens": ["Als", "Will\u00b7k\u00fcr", "o\u00b7der", "Macht\u00b7ge\u00b7l\u00fcs\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "Sprich mir das Urteil, wenn du magst,", "tokens": ["Sprich", "mir", "das", "Ur\u00b7teil", ",", "wenn", "du", "magst", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "$,", "KOUS", "PPER", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Doch da du mich so hart verklagst,", "tokens": ["Doch", "da", "du", "mich", "so", "hart", "ver\u00b7klagst", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "So h\u00f6re, da\u00df ich l\u00fcgen m\u00fc\u00dfte,", "tokens": ["So", "h\u00f6\u00b7re", ",", "da\u00df", "ich", "l\u00fc\u00b7gen", "m\u00fc\u00df\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Mich als des Undanks Sinnbild zu bekennen,", "tokens": ["Mich", "als", "des", "Un\u00b7danks", "Sinn\u00b7bild", "zu", "be\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KOUS", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Doch mu\u00df ich dich ein solches Sinnbild nennen.\u00ab", "tokens": ["Doch", "mu\u00df", "ich", "dich", "ein", "sol\u00b7ches", "Sinn\u00b7bild", "nen\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "ART", "PIAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Der andre stutzte, wich zur\u00fcck und sagte:", "tokens": ["Der", "and\u00b7re", "stutz\u00b7te", ",", "wich", "zu\u00b7r\u00fcck", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "$,", "VVFIN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "\u00bbsehr nichtige Gr\u00fcnde hast du vorgebracht,", "tokens": ["\u00bb", "sehr", "nich\u00b7ti\u00b7ge", "Gr\u00fcn\u00b7de", "hast", "du", "vor\u00b7ge\u00b7bracht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.31": {"text": "Sie gelten nichts; denn mein ist Recht und Macht.", "tokens": ["Sie", "gel\u00b7ten", "nichts", ";", "denn", "mein", "ist", "Recht", "und", "Macht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$.", "KON", "PPOSAT", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Doch w\u00e4r es gut, wenn einen Dritten man befragte.\u00ab", "tokens": ["Doch", "w\u00e4r", "es", "gut", ",", "wenn", "ei\u00b7nen", "Drit\u00b7ten", "man", "be\u00b7frag\u00b7te", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "KOUS", "ART", "ADJA", "PIS", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "\u00bbso sei es,\u00ab sagte das Reptil.", "tokens": ["\u00bb", "so", "sei", "es", ",", "\u00ab", "sag\u00b7te", "das", "Rep\u00b7til", "."], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "$,", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.34": {"text": "Da eine Kuh des Weges ging,", "tokens": ["Da", "ei\u00b7ne", "Kuh", "des", "We\u00b7ges", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Ruft man sie an, da\u00df sie das Urteil f\u00e4lle.", "tokens": ["Ruft", "man", "sie", "an", ",", "da\u00df", "sie", "das", "Ur\u00b7teil", "f\u00e4l\u00b7le", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "PTKVZ", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "\u00bbdazu,\u00ab sprach sie, \u00bbgeh\u00f6rt nicht viel.", "tokens": ["\u00bb", "da\u00b7zu", ",", "\u00ab", "sprach", "sie", ",", "\u00bb", "ge\u00b7h\u00f6rt", "nicht", "viel", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PAV", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.37": {"text": "Der Bauer, der die Schlange fing,", "tokens": ["Der", "Bau\u00b7er", ",", "der", "die", "Schlan\u00b7ge", "fing", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Geb ihr die Freiheit auf der Stelle!", "tokens": ["Geb", "ihr", "die", "Frei\u00b7heit", "auf", "der", "Stel\u00b7le", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Sie ist im Recht; weshalb denn immer t\u00f6ten?", "tokens": ["Sie", "ist", "im", "Recht", ";", "we\u00b7shalb", "denn", "im\u00b7mer", "t\u00f6\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "$.", "PWAV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.40": {"text": "Seit vielen Jahren n\u00e4hrt sich dieser hier", "tokens": ["Seit", "vie\u00b7len", "Jah\u00b7ren", "n\u00e4hrt", "sich", "die\u00b7ser", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PRF", "PDAT", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Von meiner Milch und w\u00e4r in argen N\u00f6ten,", "tokens": ["Von", "mei\u00b7ner", "Milch", "und", "w\u00e4r", "in", "ar\u00b7gen", "N\u00f6\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "VAFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.42": {"text": "Wenn meine Euter ihm nicht Nahrung b\u00f6ten;", "tokens": ["Wenn", "mei\u00b7ne", "Eu\u00b7ter", "ihm", "nicht", "Nah\u00b7rung", "b\u00f6\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "PTKNEG", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Selbst meine Kinder nimmt er mir.", "tokens": ["Selbst", "mei\u00b7ne", "Kin\u00b7der", "nimmt", "er", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "PPER", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Jetzt bin ich alt und mu\u00df im Winkel stehen,", "tokens": ["Jetzt", "bin", "ich", "alt", "und", "mu\u00df", "im", "Win\u00b7kel", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "KON", "VMFIN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.45": {"text": "Und ohne Nahrung l\u00e4\u00dft er mich.", "tokens": ["Und", "oh\u00b7ne", "Nah\u00b7rung", "l\u00e4\u00dft", "er", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PPER", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Ja, d\u00fcrft ich auf die Weide gehen!", "tokens": ["Ja", ",", "d\u00fcrft", "ich", "auf", "die", "Wei\u00b7de", "ge\u00b7hen", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VMFIN", "PPER", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.47": {"text": "Doch bin ich angekettet. H\u00e4tte ich", "tokens": ["Doch", "bin", "ich", "an\u00b7ge\u00b7ket\u00b7tet", ".", "H\u00e4t\u00b7te", "ich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "VVPP", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Die Schlange doch zum Herrn gehabt,", "tokens": ["Die", "Schlan\u00b7ge", "doch", "zum", "Herrn", "ge\u00b7habt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VAPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.49": {"text": "Sie w\u00e4re nicht so undankbar gewesen!", "tokens": ["Sie", "w\u00e4\u00b7re", "nicht", "so", "un\u00b7dank\u00b7bar", "ge\u00b7we\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "VAPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Da ihr in eurem Fall mir Richterw\u00fcrde gabt,", "tokens": ["Da", "ihr", "in", "eu\u00b7rem", "Fall", "mir", "Rich\u00b7ter\u00b7w\u00fcr\u00b7de", "gabt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPOSAT", "NN", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "So sagte ich, was ich gedacht,", "tokens": ["So", "sag\u00b7te", "ich", ",", "was", "ich", "ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.52": {"text": "Und machte nicht viel Federlesen.\u00ab", "tokens": ["Und", "mach\u00b7te", "nicht", "viel", "Fe\u00b7der\u00b7le\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.53": {"text": "Der Mann erstaunte ob des Richtspruchs sehr.", "tokens": ["Der", "Mann", "er\u00b7staun\u00b7te", "ob", "des", "Richts\u00b7pruchs", "sehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KOUS", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Zur Schlange sprach er aufgebracht:", "tokens": ["Zur", "Schlan\u00b7ge", "sprach", "er", "auf\u00b7ge\u00b7bracht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.55": {"text": "\u00bbmu\u00df man denn glauben, was sie sagt?", "tokens": ["\u00bb", "mu\u00df", "man", "denn", "glau\u00b7ben", ",", "was", "sie", "sagt", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PIS", "ADV", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.56": {"text": "'s ist eine Schw\u00e4tzerin, ihr Hirn ist leer;", "tokens": ["'s", "ist", "ei\u00b7ne", "Schw\u00e4t\u00b7ze\u00b7rin", ",", "ihr", "Hirn", "ist", "leer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.57": {"text": "Ich rate, da\u00df man diesen Ochsen fragt.\u00ab", "tokens": ["Ich", "ra\u00b7te", ",", "da\u00df", "man", "die\u00b7sen", "Och\u00b7sen", "fragt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "PDAT", "NN", "VVFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "\u00bbsch\u00f6n,\u00ab sprach die Schleicherin. Gesagt, getan.", "tokens": ["\u00bb", "sch\u00f6n", ",", "\u00ab", "sprach", "die", "Schlei\u00b7che\u00b7rin", ".", "Ge\u00b7sagt", ",", "ge\u00b7tan", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["$(", "ADJD", "$,", "$(", "VVFIN", "ART", "NN", "$.", "VVPP", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Der Ochse w\u00e4lzt den Fall im Kopfe hin und her.", "tokens": ["Der", "O\u00b7chse", "w\u00e4lzt", "den", "Fall", "im", "Kop\u00b7fe", "hin", "und", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "PTKVZ", "KON", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Er habe, sprach der Grobian,", "tokens": ["Er", "ha\u00b7be", ",", "sprach", "der", "Gro\u00b7bi\u00b7an", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.61": {"text": "Des Jahres ganze Last zu tragen,", "tokens": ["Des", "Jah\u00b7res", "gan\u00b7ze", "Last", "zu", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.62": {"text": "Den Kreislauf aller M\u00fchn durchlaufe er", "tokens": ["Den", "Kreis\u00b7lauf", "al\u00b7ler", "M\u00fchn", "durch\u00b7lau\u00b7fe", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIAT", "NN", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.63": {"text": "Und m\u00fcsse sich f\u00fcr uns auf unsern Feldern plagen,", "tokens": ["Und", "m\u00fcs\u00b7se", "sich", "f\u00fcr", "uns", "auf", "un\u00b7sern", "Fel\u00b7dern", "pla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PRF", "APPR", "PPER", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.64": {"text": "Da\u00df das, was Ceres Menschen wie auch Tieren sende,", "tokens": ["Da\u00df", "das", ",", "was", "Ce\u00b7res", "Men\u00b7schen", "wie", "auch", "Tie\u00b7ren", "sen\u00b7de", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "NE", "NN", "KOKOM", "ADV", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "Zur Frucht gedeihe und uns Nahrung spende.", "tokens": ["Zur", "Frucht", "ge\u00b7dei\u00b7he", "und", "uns", "Nah\u00b7rung", "spen\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "KON", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.66": {"text": "Viel Schl\u00e4ge, wenig Dank. Und sei er alt,", "tokens": ["Viel", "Schl\u00e4\u00b7ge", ",", "we\u00b7nig", "Dank", ".", "Und", "sei", "er", "alt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "$.", "KON", "VAFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.67": {"text": "So meine man ihm Ehre anzutun,", "tokens": ["So", "mei\u00b7ne", "man", "ihm", "Eh\u00b7re", "an\u00b7zu\u00b7tun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.68": {"text": "Wenn man ihn schlachte wie ein Huhn,", "tokens": ["Wenn", "man", "ihn", "schlach\u00b7te", "wie", "ein", "Huhn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Um durch sein Blut der G\u00f6tter Zorngewalt", "tokens": ["Um", "durch", "sein", "Blut", "der", "G\u00f6t\u00b7ter", "Zorn\u00b7ge\u00b7walt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "APPR", "PPOSAT", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.70": {"text": "In Nachsicht zu verwandeln.", "tokens": ["In", "Nach\u00b7sicht", "zu", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "So sprach der Ochs. Der Mensch darauf: \u00bbZum Schweigen", "tokens": ["So", "sprach", "der", "Ochs", ".", "Der", "Mensch", "da\u00b7rauf", ":", "\u00bb", "Zum", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "PAV", "$.", "$(", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "La\u00df uns den \u00fcblen Redner bringen.", "tokens": ["La\u00df", "uns", "den", "\u00fcb\u00b7len", "Red\u00b7ner", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Statt unsern Streitfall zu verhandeln,", "tokens": ["Statt", "un\u00b7sern", "Streit\u00b7fall", "zu", "ver\u00b7han\u00b7deln", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Will er sich selbst als Kl\u00e4ger zeigen", "tokens": ["Will", "er", "sich", "selbst", "als", "Kl\u00e4\u00b7ger", "zei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "KOUS", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und, statt zu schlichten, selber Klage singen.", "tokens": ["Und", ",", "statt", "zu", "schlich\u00b7ten", ",", "sel\u00b7ber", "Kla\u00b7ge", "sin\u00b7gen", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUI", "PTKZU", "VVINF", "$,", "ADV", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich weise ihn zur\u00fcck.\u00ab Nun wird der Baum gew\u00e4hlt,", "tokens": ["Ich", "wei\u00b7se", "ihn", "zu\u00b7r\u00fcck", ".", "\u00ab", "Nun", "wird", "der", "Baum", "ge\u00b7w\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$.", "$(", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um Recht zu sprechen; doch das war noch schlimmer.", "tokens": ["Um", "Recht", "zu", "spre\u00b7chen", ";", "doch", "das", "war", "noch", "schlim\u00b7mer", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "PTKZU", "VVINF", "$.", "KON", "PDS", "VAFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Es wird von ihm gewichtig aufgez\u00e4hlt,", "tokens": ["Es", "wird", "von", "ihm", "ge\u00b7wich\u00b7tig", "auf\u00b7ge\u00b7z\u00e4hlt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPER", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Wie er vor Regen, Sturm und Hitze", "tokens": ["Wie", "er", "vor", "Re\u00b7gen", ",", "Sturm", "und", "Hit\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "PPER", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Mit seinem Schatten uns besch\u00fctze", "tokens": ["Mit", "sei\u00b7nem", "Schat\u00b7ten", "uns", "be\u00b7sch\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und Feldern, G\u00e4rten, selbst dem Zimmer", "tokens": ["Und", "Fel\u00b7dern", ",", "G\u00e4r\u00b7ten", ",", "selbst", "dem", "Zim\u00b7mer"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "NN", "$,", "NN", "$,", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Zum Schmuck gereiche, dabei immer", "tokens": ["Zum", "Schmuck", "ge\u00b7rei\u00b7che", ",", "da\u00b7bei", "im\u00b7mer"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["APPRART", "NN", "ADJA", "$,", "PAV", "ADV"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Mit Fr\u00fcchten schwer beladen sei;", "tokens": ["Mit", "Fr\u00fcch\u00b7ten", "schwer", "be\u00b7la\u00b7den", "sei", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Den Lohn indes bezahle in der Regel", "tokens": ["Den", "Lohn", "in\u00b7des", "be\u00b7zah\u00b7le", "in", "der", "Re\u00b7gel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Mit scharfer Axt ein grober Bauernflegel.", "tokens": ["Mit", "schar\u00b7fer", "Axt", "ein", "gro\u00b7ber", "Bau\u00b7ern\u00b7fle\u00b7gel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Er aber lasse sich herbei,", "tokens": ["Er", "a\u00b7ber", "las\u00b7se", "sich", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Mit Bl\u00fcten uns im Fr\u00fchling zu erfreuen,", "tokens": ["Mit", "Bl\u00fc\u00b7ten", "uns", "im", "Fr\u00fch\u00b7ling", "zu", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Im Herbst uns Fr\u00fcchte in den Scho\u00df zu streuen.", "tokens": ["Im", "Herbst", "uns", "Fr\u00fcch\u00b7te", "in", "den", "Scho\u00df", "zu", "streu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Man danke ihm doch besser ohne Beil!", "tokens": ["Man", "dan\u00b7ke", "ihm", "doch", "bes\u00b7ser", "oh\u00b7ne", "Beil", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Dann st\u00e4nde er noch lange ganz und heil.", "tokens": ["Dann", "st\u00e4n\u00b7de", "er", "noch", "lan\u00b7ge", "ganz", "und", "heil", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADV", "ADV", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Der Mensch fand diesen Richterspruch recht schlecht", "tokens": ["Der", "Mensch", "fand", "die\u00b7sen", "Rich\u00b7ter\u00b7spruch", "recht", "schlecht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PDAT", "NN", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "Und wollte nun um jeden Preis sein Recht.", "tokens": ["Und", "woll\u00b7te", "nun", "um", "je\u00b7den", "Preis", "sein", "Recht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "PIAT", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "\u00bbich bin ein Narr,\u00ab sprach er, \u00bbdie Leute anzuh\u00f6ren,\u00ab", "tokens": ["\u00bb", "ich", "bin", "ein", "Narr", ",", "\u00ab", "sprach", "er", ",", "\u00bb", "die", "Leu\u00b7te", "an\u00b7zu\u00b7h\u00f6\u00b7ren", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$,", "$(", "VVFIN", "PPER", "$,", "$(", "ART", "NN", "VVIZU", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Warf Sack mit Inhalt wuchtig auf den Stein", "tokens": ["Warf", "Sack", "mit", "In\u00b7halt", "wuch\u00b7tig", "auf", "den", "Stein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NN", "APPR", "NN", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Und schlug der Schlange so den Sch\u00e4del ein.", "tokens": ["Und", "schlug", "der", "Schlan\u00b7ge", "so", "den", "Sch\u00e4\u00b7del", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Es pflegt die M\u00e4chtigen stets zu st\u00f6ren,", "tokens": ["Es", "pflegt", "die", "M\u00e4ch\u00b7ti\u00b7gen", "stets", "zu", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wenn andre Rechenschaft verlangen,", "tokens": ["Wenn", "and\u00b7re", "Re\u00b7chen\u00b7schaft", "ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Denn alles soll f\u00fcr sie geboren sein,", "tokens": ["Denn", "al\u00b7les", "soll", "f\u00fcr", "sie", "ge\u00b7bo\u00b7ren", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "APPR", "PPER", "VVPP", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "So Mensch wie Vieh und selbst die Schlangen.", "tokens": ["So", "Mensch", "wie", "Vieh", "und", "selbst", "die", "Schlan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und zeigt doch einer mal die Z\u00e4hne,", "tokens": ["Und", "zeigt", "doch", "ei\u00b7ner", "mal", "die", "Z\u00e4h\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So ist's ein T\u00f6lpel. Nun, ich r\u00e4um es ein.", "tokens": ["So", "ist's", "ein", "T\u00f6l\u00b7pel", ".", "Nun", ",", "ich", "r\u00e4um", "es", "ein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "$.", "ADV", "$,", "PPER", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und da\u00df ich die Moral erw\u00e4hne:", "tokens": ["Und", "da\u00df", "ich", "die", "Mo\u00b7ral", "er\u00b7w\u00e4h\u00b7ne", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Verklage nur von fern; noch besser, la\u00df es sein!", "tokens": ["Ver\u00b7kla\u00b7ge", "nur", "von", "fern", ";", "noch", "bes\u00b7ser", ",", "la\u00df", "es", "sein", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ADJD", "$.", "ADV", "ADJD", "$,", "VVIMP", "PPER", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}