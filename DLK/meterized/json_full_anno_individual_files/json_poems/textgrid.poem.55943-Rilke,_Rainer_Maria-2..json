{"textgrid.poem.55943": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1900, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und wenn uns eines Tages dieses Tun", "tokens": ["Und", "wenn", "uns", "ei\u00b7nes", "Ta\u00b7ges", "die\u00b7ses", "Tun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und was an uns geschieht gering erschiene", "tokens": ["und", "was", "an", "uns", "ge\u00b7schieht", "ge\u00b7ring", "er\u00b7schie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PPER", "VVFIN", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und uns so fremd, als ob es nicht verdiene,", "tokens": ["und", "uns", "so", "fremd", ",", "als", "ob", "es", "nicht", "ver\u00b7die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "$,", "KOKOM", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df wir so m\u00fchsam aus den Kinderschuhn", "tokens": ["da\u00df", "wir", "so", "m\u00fch\u00b7sam", "aus", "den", "Kin\u00b7der\u00b7schuhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "um seinetwillen wachsen \u2013: Ob die Bahn", "tokens": ["um", "sei\u00b7net\u00b7wil\u00b7len", "wach\u00b7sen", "\u2013", ":", "Ob", "die", "Bahn"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUI", "ADV", "VVINF", "$(", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "vergilbter Spitze, diese dichtgef\u00fcgte", "tokens": ["ver\u00b7gilb\u00b7ter", "Spit\u00b7ze", ",", "die\u00b7se", "dicht\u00b7ge\u00b7f\u00fcg\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PDAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "blumige Spitzenbahn, dann nicht gen\u00fcgte,", "tokens": ["blu\u00b7mi\u00b7ge", "Spit\u00b7zen\u00b7bahn", ",", "dann", "nicht", "ge\u00b7n\u00fcg\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "uns hier zu halten? Sieh: sie ward ", "tokens": ["uns", "hier", "zu", "hal\u00b7ten", "?", "Sieh", ":", "sie", "ward"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$.", "NE", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ein Leben ward vielleicht verschm\u00e4ht, wer wei\u00df?", "tokens": ["Ein", "Le\u00b7ben", "ward", "viel\u00b7leicht", "ver\u00b7schm\u00e4ht", ",", "wer", "wei\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Gl\u00fcck war da und wurde hingegeben,", "tokens": ["Ein", "Gl\u00fcck", "war", "da", "und", "wur\u00b7de", "hin\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "KON", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und endlich wurde doch, um jeden Preis,", "tokens": ["und", "end\u00b7lich", "wur\u00b7de", "doch", ",", "um", "je\u00b7den", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dies Ding daraus, nicht leichter als das Leben", "tokens": ["dies", "Ding", "da\u00b7raus", ",", "nicht", "leich\u00b7ter", "als", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "PAV", "$,", "PTKNEG", "ADJD", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und doch vollendet und so sch\u00f6n als sei's", "tokens": ["und", "doch", "voll\u00b7en\u00b7det", "und", "so", "sch\u00f6n", "als", "sei's"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "KON", "ADV", "ADJD", "KOKOM", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "nicht mehr zu fr\u00fch, zu l\u00e4cheln und zu schweben.", "tokens": ["nicht", "mehr", "zu", "fr\u00fch", ",", "zu", "l\u00e4\u00b7cheln", "und", "zu", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKA", "ADJD", "$,", "PTKZU", "VVFIN", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und wenn uns eines Tages dieses Tun", "tokens": ["Und", "wenn", "uns", "ei\u00b7nes", "Ta\u00b7ges", "die\u00b7ses", "Tun"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und was an uns geschieht gering erschiene", "tokens": ["und", "was", "an", "uns", "ge\u00b7schieht", "ge\u00b7ring", "er\u00b7schie\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "APPR", "PPER", "VVFIN", "ADJD", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und uns so fremd, als ob es nicht verdiene,", "tokens": ["und", "uns", "so", "fremd", ",", "als", "ob", "es", "nicht", "ver\u00b7die\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "ADJD", "$,", "KOKOM", "KOUS", "PPER", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "da\u00df wir so m\u00fchsam aus den Kinderschuhn", "tokens": ["da\u00df", "wir", "so", "m\u00fch\u00b7sam", "aus", "den", "Kin\u00b7der\u00b7schuhn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "um seinetwillen wachsen \u2013: Ob die Bahn", "tokens": ["um", "sei\u00b7net\u00b7wil\u00b7len", "wach\u00b7sen", "\u2013", ":", "Ob", "die", "Bahn"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KOUI", "ADV", "VVINF", "$(", "$.", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "vergilbter Spitze, diese dichtgef\u00fcgte", "tokens": ["ver\u00b7gilb\u00b7ter", "Spit\u00b7ze", ",", "die\u00b7se", "dicht\u00b7ge\u00b7f\u00fcg\u00b7te"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ADJA", "NN", "$,", "PDAT", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "blumige Spitzenbahn, dann nicht gen\u00fcgte,", "tokens": ["blu\u00b7mi\u00b7ge", "Spit\u00b7zen\u00b7bahn", ",", "dann", "nicht", "ge\u00b7n\u00fcg\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADV", "PTKNEG", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "uns hier zu halten? Sieh: sie ward ", "tokens": ["uns", "hier", "zu", "hal\u00b7ten", "?", "Sieh", ":", "sie", "ward"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$.", "NE", "$.", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Ein Leben ward vielleicht verschm\u00e4ht, wer wei\u00df?", "tokens": ["Ein", "Le\u00b7ben", "ward", "viel\u00b7leicht", "ver\u00b7schm\u00e4ht", ",", "wer", "wei\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein Gl\u00fcck war da und wurde hingegeben,", "tokens": ["Ein", "Gl\u00fcck", "war", "da", "und", "wur\u00b7de", "hin\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "KON", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und endlich wurde doch, um jeden Preis,", "tokens": ["und", "end\u00b7lich", "wur\u00b7de", "doch", ",", "um", "je\u00b7den", "Preis", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ADV", "$,", "KOUI", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dies Ding daraus, nicht leichter als das Leben", "tokens": ["dies", "Ding", "da\u00b7raus", ",", "nicht", "leich\u00b7ter", "als", "das", "Le\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "PAV", "$,", "PTKNEG", "ADJD", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und doch vollendet und so sch\u00f6n als sei's", "tokens": ["und", "doch", "voll\u00b7en\u00b7det", "und", "so", "sch\u00f6n", "als", "sei's"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "KON", "ADV", "ADJD", "KOKOM", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "nicht mehr zu fr\u00fch, zu l\u00e4cheln und zu schweben.", "tokens": ["nicht", "mehr", "zu", "fr\u00fch", ",", "zu", "l\u00e4\u00b7cheln", "und", "zu", "schwe\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKA", "ADJD", "$,", "PTKZU", "VVFIN", "KON", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}