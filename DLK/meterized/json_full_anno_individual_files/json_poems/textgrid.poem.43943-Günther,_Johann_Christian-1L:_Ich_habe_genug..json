{"textgrid.poem.43943": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ich habe genug.", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich habe genug.", "tokens": ["Ich", "ha\u00b7be", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Lust, Flammen und K\u00fc\u00dfe", "tokens": ["Lust", ",", "Flam\u00b7men", "und", "K\u00fc\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sind giftig und s\u00fc\u00dfe", "tokens": ["Sind", "gif\u00b7tig", "und", "s\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KON", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und machen nicht klug.", "tokens": ["Und", "ma\u00b7chen", "nicht", "klug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Komm, seelige Freyheit und d\u00e4mpfe den Brand,", "tokens": ["Komm", ",", "see\u00b7li\u00b7ge", "Frey\u00b7heit", "und", "d\u00e4mp\u00b7fe", "den", "Brand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Der meinem Gem\u00fcthe die Wei\u00dfheit entwand.", "tokens": ["Der", "mei\u00b7nem", "Ge\u00b7m\u00fc\u00b7the", "die", "Wei\u00df\u00b7heit", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.2": {"line.1": {"text": "Was hab ich gethan!", "tokens": ["Was", "hab", "ich", "ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Jezt seh ich die Triebe", "tokens": ["Jezt", "seh", "ich", "die", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der th\u00f6richten Liebe", "tokens": ["Der", "th\u00f6\u00b7rich\u00b7ten", "Lie\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Vern\u00fcnftiger an;", "tokens": ["Ver\u00b7n\u00fcnf\u00b7ti\u00b7ger", "an", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Ich breche die Fe\u00dfel, ich l\u00f6se mein Herz", "tokens": ["Ich", "bre\u00b7che", "die", "Fe\u00b7\u00dfel", ",", "ich", "l\u00f6\u00b7se", "mein", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Und ha\u00dfe mit Vorsaz den z\u00e4rtlichen Schmerz.", "tokens": ["Und", "ha\u00b7\u00dfe", "mit", "Vor\u00b7saz", "den", "z\u00e4rt\u00b7li\u00b7chen", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.3": {"line.1": {"text": "Was qu\u00e4lt mich vor Reu?", "tokens": ["Was", "qu\u00e4lt", "mich", "vor", "Reu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "NE", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Was st\u00f6rt mir vor Kummer", "tokens": ["Was", "st\u00f6rt", "mir", "vor", "Kum\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Den n\u00e4chtlichen Schlummer?", "tokens": ["Den", "n\u00e4cht\u00b7li\u00b7chen", "Schlum\u00b7mer", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Die Zeit ist vorbey.", "tokens": ["Die", "Zeit", "ist", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "O k\u00f6stliches Kleinod, o theurer Verlust!", "tokens": ["O", "k\u00f6st\u00b7li\u00b7ches", "Klei\u00b7nod", ",", "o", "theu\u00b7rer", "Ver\u00b7lust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "O h\u00e4tt ich die Falschheit nur eher gewust!", "tokens": ["O", "h\u00e4tt", "ich", "die", "Falschheit", "nur", "e\u00b7her", "ge\u00b7wust", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "Geh, Sch\u00f6nheit, und fleuch!", "tokens": ["Geh", ",", "Sch\u00f6n\u00b7heit", ",", "und", "fleuch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "KON", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Die artigsten Blicke", "tokens": ["Die", "ar\u00b7tigs\u00b7ten", "Bli\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sind schmerzliche Stricke;", "tokens": ["Sind", "schmerz\u00b7li\u00b7che", "Stri\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Ich mercke den Streich.", "tokens": ["Ich", "mer\u00b7cke", "den", "Streich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Es lodern die Briefe, der Ring bricht entzwey", "tokens": ["Es", "lo\u00b7dern", "die", "Brie\u00b7fe", ",", "der", "Ring", "bricht", "ent\u00b7zwey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Und zeigt meiner Sch\u00f6nen: Nun leb ich recht frey.", "tokens": ["Und", "zeigt", "mei\u00b7ner", "Sch\u00f6\u00b7nen", ":", "Nun", "leb", "ich", "recht", "frey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+--+-++--+", "measure": "iambic.penta.relaxed"}}, "stanza.5": {"line.1": {"text": "Nun leb ich recht frey", "tokens": ["Nun", "leb", "ich", "recht", "frey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Und schw\u00f6re von Herzen,", "tokens": ["Und", "schw\u00f6\u00b7re", "von", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Da\u00df K\u00fc\u00dfen und Scherzen", "tokens": ["Da\u00df", "K\u00fc\u00b7\u00dfen", "und", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Ein Narrenspiel sey;", "tokens": ["Ein", "Nar\u00b7ren\u00b7spiel", "sey", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Denn wer sich verliebet, der ist wohl nicht klug.", "tokens": ["Denn", "wer", "sich", "ver\u00b7lie\u00b7bet", ",", "der", "ist", "wohl", "nicht", "klug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Geh, falsche Syrene, ich habe genug!", "tokens": ["Geh", ",", "fal\u00b7sche", "Sy\u00b7re\u00b7ne", ",", "ich", "ha\u00b7be", "ge\u00b7nug", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "Ich habe genug.", "tokens": ["Ich", "ha\u00b7be", "ge\u00b7nug", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Lust, Flammen und K\u00fc\u00dfe", "tokens": ["Lust", ",", "Flam\u00b7men", "und", "K\u00fc\u00b7\u00dfe"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sind giftig und s\u00fc\u00dfe", "tokens": ["Sind", "gif\u00b7tig", "und", "s\u00fc\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "KON", "ADJA"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Und machen nicht klug.", "tokens": ["Und", "ma\u00b7chen", "nicht", "klug", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADJD", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Komm, seelige Freyheit und d\u00e4mpfe den Brand,", "tokens": ["Komm", ",", "see\u00b7li\u00b7ge", "Frey\u00b7heit", "und", "d\u00e4mp\u00b7fe", "den", "Brand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Der meinem Gem\u00fcthe die Wei\u00dfheit entwand.", "tokens": ["Der", "mei\u00b7nem", "Ge\u00b7m\u00fc\u00b7the", "die", "Wei\u00df\u00b7heit", "ent\u00b7wand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.7": {"line.1": {"text": "Was hab ich gethan!", "tokens": ["Was", "hab", "ich", "ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Jezt seh ich die Triebe", "tokens": ["Jezt", "seh", "ich", "die", "Trie\u00b7be"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Der th\u00f6richten Liebe", "tokens": ["Der", "th\u00f6\u00b7rich\u00b7ten", "Lie\u00b7be"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Vern\u00fcnftiger an;", "tokens": ["Ver\u00b7n\u00fcnf\u00b7ti\u00b7ger", "an", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "PTKVZ", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Ich breche die Fe\u00dfel, ich l\u00f6se mein Herz", "tokens": ["Ich", "bre\u00b7che", "die", "Fe\u00b7\u00dfel", ",", "ich", "l\u00f6\u00b7se", "mein", "Herz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Und ha\u00dfe mit Vorsaz den z\u00e4rtlichen Schmerz.", "tokens": ["Und", "ha\u00b7\u00dfe", "mit", "Vor\u00b7saz", "den", "z\u00e4rt\u00b7li\u00b7chen", "Schmerz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}}, "stanza.8": {"line.1": {"text": "Was qu\u00e4lt mich vor Reu?", "tokens": ["Was", "qu\u00e4lt", "mich", "vor", "Reu", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "NE", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Was st\u00f6rt mir vor Kummer", "tokens": ["Was", "st\u00f6rt", "mir", "vor", "Kum\u00b7mer"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Den n\u00e4chtlichen Schlummer?", "tokens": ["Den", "n\u00e4cht\u00b7li\u00b7chen", "Schlum\u00b7mer", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Die Zeit ist vorbey.", "tokens": ["Die", "Zeit", "ist", "vor\u00b7bey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "O k\u00f6stliches Kleinod, o theurer Verlust!", "tokens": ["O", "k\u00f6st\u00b7li\u00b7ches", "Klei\u00b7nod", ",", "o", "theu\u00b7rer", "Ver\u00b7lust", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "FM", "ADJA", "NN", "$."], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "O h\u00e4tt ich die Falschheit nur eher gewust!", "tokens": ["O", "h\u00e4tt", "ich", "die", "Falschheit", "nur", "e\u00b7her", "ge\u00b7wust", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ART", "NN", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Geh, Sch\u00f6nheit, und fleuch!", "tokens": ["Geh", ",", "Sch\u00f6n\u00b7heit", ",", "und", "fleuch", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "KON", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Die artigsten Blicke", "tokens": ["Die", "ar\u00b7tigs\u00b7ten", "Bli\u00b7cke"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Sind schmerzliche Stricke;", "tokens": ["Sind", "schmerz\u00b7li\u00b7che", "Stri\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Ich mercke den Streich.", "tokens": ["Ich", "mer\u00b7cke", "den", "Streich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Es lodern die Briefe, der Ring bricht entzwey", "tokens": ["Es", "lo\u00b7dern", "die", "Brie\u00b7fe", ",", "der", "Ring", "bricht", "ent\u00b7zwey"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PTKVZ"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.6": {"text": "Und zeigt meiner Sch\u00f6nen: Nun leb ich recht frey.", "tokens": ["Und", "zeigt", "mei\u00b7ner", "Sch\u00f6\u00b7nen", ":", "Nun", "leb", "ich", "recht", "frey", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+--+-++--+", "measure": "iambic.penta.relaxed"}}, "stanza.10": {"line.1": {"text": "Nun leb ich recht frey", "tokens": ["Nun", "leb", "ich", "recht", "frey"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.2": {"text": "Und schw\u00f6re von Herzen,", "tokens": ["Und", "schw\u00f6\u00b7re", "von", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Da\u00df K\u00fc\u00dfen und Scherzen", "tokens": ["Da\u00df", "K\u00fc\u00b7\u00dfen", "und", "Scher\u00b7zen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "NN", "KON", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Ein Narrenspiel sey;", "tokens": ["Ein", "Nar\u00b7ren\u00b7spiel", "sey", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.5": {"text": "Denn wer sich verliebet, der ist wohl nicht klug.", "tokens": ["Denn", "wer", "sich", "ver\u00b7lie\u00b7bet", ",", "der", "ist", "wohl", "nicht", "klug", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVFIN", "$,", "PRELS", "VAFIN", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Geh, falsche Syrene, ich habe genug!", "tokens": ["Geh", ",", "fal\u00b7sche", "Sy\u00b7re\u00b7ne", ",", "ich", "ha\u00b7be", "ge\u00b7nug", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADJA", "NN", "$,", "PPER", "VAFIN", "ADV", "$."], "meter": "-+-+---+--+", "measure": "iambic.tetra.chol"}}}}}