{"textgrid.poem.48345": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Zeus in Mission", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Und Gott (es war im Sp\u00e4therbst zweiundsechzig)", "tokens": ["Und", "Gott", "(", "es", "war", "im", "Sp\u00e4t\u00b7herbst", "zwei\u00b7und\u00b7sech\u00b7zig", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "PPER", "VAFIN", "APPRART", "NN", "CARD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Trat an sein Himmelsfenster, sah hernieder", "tokens": ["Trat", "an", "sein", "Him\u00b7mels\u00b7fens\u00b7ter", ",", "sah", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sah auf ", "tokens": ["Und", "sah", "auf"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Seit dem Bronzell-Tag und dem Tag von Olm\u00fctz.", "tokens": ["Seit", "dem", "Bron\u00b7zell\u00b7Tag", "und", "dem", "Tag", "von", "Ol\u00b7m\u00fctz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "APPR", "NE", "$."], "meter": "--+-+--+---", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Er sch\u00fcttelte den Kopf. Danach begann er:", "tokens": ["Er", "sch\u00fct\u00b7tel\u00b7te", "den", "Kopf", ".", "Da\u00b7nach", "be\u00b7gann", "er", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbdas geht nicht l\u00e4nger so. Streit und Zerkl\u00fcftung", "tokens": ["\u00bb", "das", "geht", "nicht", "l\u00e4n\u00b7ger", "so", ".", "Streit", "und", "Zer\u00b7kl\u00fcf\u00b7tung"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PTKNEG", "ADJD", "ADV", "$.", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "L\u00e4hmt ihm die Kraft, zehrt ihm an Mark und Leben,", "tokens": ["L\u00e4hmt", "ihm", "die", "Kraft", ",", "zehrt", "ihm", "an", "Mark", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Und jeder dritte, der au fond nicht wert ist,", "tokens": ["Und", "je\u00b7der", "drit\u00b7te", ",", "der", "au", "fond", "nicht", "wert", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "$,", "ART", "NE", "NE", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Dem Michel seine Schuhriem' nur zu l\u00f6sen,", "tokens": ["Dem", "Mi\u00b7chel", "sei\u00b7ne", "Schuhriem'", "nur", "zu", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kr\u00e4ht nicht blo\u00df laut auf seinem eignen Miste,", "tokens": ["Kr\u00e4ht", "nicht", "blo\u00df", "laut", "auf", "sei\u00b7nem", "eig\u00b7nen", "Mis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nein, kr\u00e4ht auch \u00fcbern Rhein und schl\u00e4gt die Fl\u00fcgel", "tokens": ["Nein", ",", "kr\u00e4ht", "auch", "\u00fc\u00b7bern", "Rhein", "und", "schl\u00e4gt", "die", "Fl\u00fc\u00b7gel"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "ADV", "NE", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und wirft den roten Kamm. Ich kenn' die Fahne.", "tokens": ["Und", "wirft", "den", "ro\u00b7ten", "Kamm", ".", "Ich", "kenn'", "die", "Fah\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Das geht nicht l\u00e4nger so. Gewi\u00df, die Deutschen,", "tokens": ["Das", "geht", "nicht", "l\u00e4n\u00b7ger", "so", ".", "Ge\u00b7wi\u00df", ",", "die", "Deut\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADJD", "ADV", "$.", "PTKANT", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sie taugen auch nicht viel, die lieben Schlingel,", "tokens": ["Sie", "tau\u00b7gen", "auch", "nicht", "viel", ",", "die", "lie\u00b7ben", "Schlin\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Sind Besserwisser, knurrn und querulieren", "tokens": ["Sind", "Bes\u00b7ser\u00b7wis\u00b7ser", ",", "knurrn", "und", "que\u00b7ru\u00b7lie\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und schreiben B\u00fccher, drin sie mir beweisen:", "tokens": ["Und", "schrei\u00b7ben", "B\u00fc\u00b7cher", ",", "drin", "sie", "mir", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADV", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Es sei nicht viel mit mir; im letzten Grunde", "tokens": ["Es", "sei", "nicht", "viel", "mit", "mir", ";", "im", "letz\u00b7ten", "Grun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PPER", "$.", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Best\u00fcnd' ich nur durch Kompromi\u00df und Gnade.", "tokens": ["Be\u00b7st\u00fcnd'", "ich", "nur", "durch", "Kom\u00b7pro\u00b7mi\u00df", "und", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Das predigen sie von Tischen und von B\u00e4nken", "tokens": ["Das", "pre\u00b7di\u00b7gen", "sie", "von", "Ti\u00b7schen", "und", "von", "B\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Und f\u00fchlen sich in ihrem Tabakshimmel", "tokens": ["Und", "f\u00fch\u00b7len", "sich", "in", "ih\u00b7rem", "Ta\u00b7baks\u00b7him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Als Ober-Gott, und wird es dann gem\u00fctlich,", "tokens": ["Als", "O\u00b7ber\u00b7Gott", ",", "und", "wird", "es", "dann", "ge\u00b7m\u00fct\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "So rufen sie mir zu: \u203aIch komm' dir einen!\u2039", "tokens": ["So", "ru\u00b7fen", "sie", "mir", "zu", ":", "\u203a", "Ich", "komm'", "dir", "ei\u00b7nen", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "ART", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Ich kenne sie, sie haben was Kneipantes,", "tokens": ["Ich", "ken\u00b7ne", "sie", ",", "sie", "ha\u00b7ben", "was", "Knei\u00b7pan\u00b7tes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Was Buntbem\u00fctztes, r\u00fcplig Burschikoses,", "tokens": ["Was", "Bunt\u00b7be\u00b7m\u00fctz\u00b7tes", ",", "r\u00fcp\u00b7lig", "Bur\u00b7schi\u00b7ko\u00b7ses", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Sind kindisch, eitel, unbequem-gef\u00fchlvoll", "tokens": ["Sind", "kin\u00b7disch", ",", "ei\u00b7tel", ",", "un\u00b7be\u00b7quem\u00b7ge\u00b7f\u00fchl\u00b7voll"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADJD", "$,", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und vieles andre noch, ich wei\u00df, ich wei\u00df es,", "tokens": ["Und", "vie\u00b7les", "and\u00b7re", "noch", ",", "ich", "wei\u00df", ",", "ich", "wei\u00df", "es", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIS", "ADV", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Und doch, wenn eins zum andern ich erw\u00e4ge,", "tokens": ["Und", "doch", ",", "wenn", "eins", "zum", "an\u00b7dern", "ich", "er\u00b7w\u00e4\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PIS", "APPRART", "ADJA", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "So sind sie schlie\u00dflich immer noch die besten,", "tokens": ["So", "sind", "sie", "schlie\u00df\u00b7lich", "im\u00b7mer", "noch", "die", "bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Die besten und nat\u00fcrlichsten vor allem,", "tokens": ["Die", "bes\u00b7ten", "und", "na\u00b7t\u00fcr\u00b7lichs\u00b7ten", "vor", "al\u00b7lem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "APPR", "PIS", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Am meisten frei von Babel und von Sodom.", "tokens": ["Am", "meis\u00b7ten", "frei", "von", "Ba\u00b7bel", "und", "von", "So\u00b7dom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "ADJD", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Sie dauern mich. L\u00e4ngst qu\u00e4lt mich der Gedanke,", "tokens": ["Sie", "dau\u00b7ern", "mich", ".", "L\u00e4ngst", "qu\u00e4lt", "mich", "der", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Wie schaff' ich ihnen Zuspruch, Beistand, Hilfe!", "tokens": ["Wie", "schaff'", "ich", "ih\u00b7nen", "Zu\u00b7spruch", ",", "Bei\u00b7stand", ",", "Hil\u00b7fe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Vielleicht, da\u00df mir im Gehn und Meditieren", "tokens": ["Viel\u00b7leicht", ",", "da\u00df", "mir", "im", "Gehn", "und", "Me\u00b7di\u00b7tie\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Ein Ausweg kommt, ein guter Plan, ein Einfall.\u00ab", "tokens": ["Ein", "Aus\u00b7weg", "kommt", ",", "ein", "gu\u00b7ter", "Plan", ",", "ein", "Ein\u00b7fall", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und solches denkend nahm er Hut und Mantel", "tokens": ["Und", "sol\u00b7ches", "den\u00b7kend", "nahm", "er", "Hut", "und", "Man\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "PDS", "VVFIN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und seinen Stab und schritt hinaus ins Freie.", "tokens": ["Und", "sei\u00b7nen", "Stab", "und", "schritt", "hin\u00b7aus", "ins", "Frei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Der Weg war weit, die Stra\u00dfenflucht ohn' Ende,", "tokens": ["Der", "Weg", "war", "weit", ",", "die", "Stra\u00b7\u00dfen\u00b7flucht", "ohn'", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch endlich kamen G\u00e4rten, Park und Wiese", "tokens": ["Doch", "end\u00b7lich", "ka\u00b7men", "G\u00e4r\u00b7ten", ",", "Park", "und", "Wie\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Silberb\u00e4chen und mit Birkenbr\u00fccken,", "tokens": ["Mit", "Sil\u00b7ber\u00b7b\u00e4\u00b7chen", "und", "mit", "Bir\u00b7ken\u00b7br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und jenseits dieser Wiese, hoch gelegen,", "tokens": ["Und", "jen\u00b7seits", "die\u00b7ser", "Wie\u00b7se", ",", "hoch", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Erhob ein \u00e4ltrer Stadtteil sich, halb Ghetto,", "tokens": ["Er\u00b7hob", "ein", "\u00e4lt\u00b7rer", "Stadt\u00b7teil", "sich", ",", "halb", "Ghet\u00b7to", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "$,", "ADJD", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Halb Kapitol, ein bunt Gemisch von H\u00fctten", "tokens": ["Halb", "Ka\u00b7pi\u00b7tol", ",", "ein", "bunt", "Ge\u00b7misch", "von", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "$,", "ART", "ADJD", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und Tempeln und Pal\u00e4sten. Die Pal\u00e4ste", "tokens": ["Und", "Tem\u00b7peln", "und", "Pa\u00b7l\u00e4s\u00b7ten", ".", "Die", "Pa\u00b7l\u00e4s\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "H\u00f6chst vornehm, alles Porphyr, alles Marmor,", "tokens": ["H\u00f6chst", "vor\u00b7nehm", ",", "al\u00b7les", "Por\u00b7phyr", ",", "al\u00b7les", "Mar\u00b7mor", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und doch mit Holz verschlagen und vergittert,", "tokens": ["Und", "doch", "mit", "Holz", "ver\u00b7schla\u00b7gen", "und", "ver\u00b7git\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Als w\u00e4ren's Kerker.", "tokens": ["Als", "w\u00e4\u00b7ren's", "Ker\u00b7ker", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Und es waren Kerker.", "tokens": ["Und", "es", "wa\u00b7ren", "Ker\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.12": {"text": "Denn hinter diesen Gitterst\u00e4ben sa\u00dfen", "tokens": ["Denn", "hin\u00b7ter", "die\u00b7sen", "Git\u00b7ter\u00b7st\u00e4\u00b7ben", "sa\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbim Altenteil\u00ab, so hie\u00df es euphemistisch,", "tokens": ["\u00bb", "im", "Al\u00b7ten\u00b7teil", "\u00ab", ",", "so", "hie\u00df", "es", "eu\u00b7phe\u00b7mis\u00b7tisch", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "$(", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die guten, alten, abgesetzten G\u00f6tter:", "tokens": ["Die", "gu\u00b7ten", ",", "al\u00b7ten", ",", "ab\u00b7ge\u00b7setz\u00b7ten", "G\u00f6t\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Neptun und Pluto, Mars (nur Bacchus fehlte),", "tokens": ["Nep\u00b7tun", "und", "Plu\u00b7to", ",", "Mars", "(", "nur", "Bac\u00b7chus", "fehl\u00b7te", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "$,", "NE", "$(", "ADV", "NE", "VVFIN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Merkur, Apoll, Vulkan. Und endlich ", "tokens": ["Mer\u00b7kur", ",", "A\u00b7poll", ",", "Vul\u00b7kan", ".", "Und", "end\u00b7lich"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "$.", "KON", "ADV"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Und sieh, an Zeus (er wohnte sichtlich freier", "tokens": ["Und", "sieh", ",", "an", "Zeus", "(", "er", "wohn\u00b7te", "sicht\u00b7lich", "frei\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "NE", "$(", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ward auf Wort und Handschlag hin behandelt),", "tokens": ["Und", "ward", "auf", "Wort", "und", "Hand\u00b7schlag", "hin", "be\u00b7han\u00b7delt", ")", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN", "ADV", "VVPP", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "An Zeus trat jetzt sein Ober-Herr und sagte:", "tokens": ["An", "Zeus", "trat", "jetzt", "sein", "O\u00b7ber\u00b7Herr", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbgr\u00fc\u00df' Gott dich, Alter. Bringe frohe Botschaft.", "tokens": ["\u00bb", "gr\u00fc\u00df'", "Gott", "dich", ",", "Al\u00b7ter", ".", "Brin\u00b7ge", "fro\u00b7he", "Bot\u00b7schaft", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "NN", "PPER", "$,", "NN", "$.", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich hoff' es wenigstens. Wer so wie du", "tokens": ["Ich", "hoff'", "es", "we\u00b7nigs\u00b7tens", ".", "Wer", "so", "wie", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "PWS", "ADV", "KOKOM", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "'ne h\u00fcbsche Weil' geherrscht, herrscht gern auch wieder,", "tokens": ["'", "ne", "h\u00fcb\u00b7sche", "Weil", "'", "ge\u00b7herrscht", ",", "herrscht", "gern", "auch", "wie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$(", "VVPP", "$,", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Still sitzen ist ein Greul. Ich lieb' es auch nicht.", "tokens": ["Still", "sit\u00b7zen", "ist", "ein", "Greul", ".", "Ich", "lieb'", "es", "auch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.6": {"line.1": {"text": "So h\u00f6re denn: ich habe was in petto,", "tokens": ["So", "h\u00f6\u00b7re", "denn", ":", "ich", "ha\u00b7be", "was", "in", "pet\u00b7to", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Pack deine Koffer, nimm dein Inventar", "tokens": ["Pack", "dei\u00b7ne", "Kof\u00b7fer", ",", "nimm", "dein", "In\u00b7ven\u00b7tar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "VVIMP", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "(spezialmission auf unbestimmte Dauer),", "tokens": ["(", "spe\u00b7zi\u00b7al\u00b7mis\u00b7si\u00b7on", "auf", "un\u00b7be\u00b7stimm\u00b7te", "Dau\u00b7er", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "APPR", "ADJA", "NN", "$(", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Nimm Adler, B\u00fcndelblitze, Ganymed auch,", "tokens": ["Nimm", "Ad\u00b7ler", ",", "B\u00fcn\u00b7del\u00b7blit\u00b7ze", ",", "Ga\u00b7ny\u00b7med", "auch", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$,", "NE", "ADV", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und zieh hernieder in mein altes Deutschland,", "tokens": ["Und", "zieh", "her\u00b7nie\u00b7der", "in", "mein", "al\u00b7tes", "Deutschland", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "An einen Ort, den ", "tokens": ["An", "ei\u00b7nen", "Ort", ",", "den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Zum Unterschiede, du verstehst. Du find'st dort", "tokens": ["Zum", "Un\u00b7ter\u00b7schie\u00b7de", ",", "du", "ver\u00b7stehst", ".", "Du", "fin\u00b7d'st", "dort"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bildwerke viel auf Stra\u00dfen und auf Pl\u00e4tzen,", "tokens": ["Bild\u00b7wer\u00b7ke", "viel", "auf", "Stra\u00b7\u00dfen", "und", "auf", "Pl\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Athene nicht, auch Venus nicht von Milo,", "tokens": ["A\u00b7the\u00b7ne", "nicht", ",", "auch", "Ve\u00b7nus", "nicht", "von", "Mi\u00b7lo", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "ADV", "NN", "PTKNEG", "APPR", "NE", "$,"], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Doch Bl\u00fccher, York, Schwerin und Keith und Scharnhorst,", "tokens": ["Doch", "Bl\u00fc\u00b7cher", ",", "Y\u00b7ork", ",", "Schwe\u00b7rin", "und", "Keith", "und", "Scharn\u00b7horst", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "NE", "$,", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Den alten Zieten und den alten Fritzen,", "tokens": ["Den", "al\u00b7ten", "Zie\u00b7ten", "und", "den", "al\u00b7ten", "Frit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Den letztern, denk' ich, kennst du \u2013's ist derselbe,", "tokens": ["Den", "letz\u00b7tern", ",", "denk'", "ich", ",", "kennst", "du", "\u2013", "'s", "ist", "der\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "PDAT", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Der hier am Himmel gl\u00e4nzt als ", "tokens": ["Der", "hier", "am", "Him\u00b7mel", "gl\u00e4nzt", "als"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "KOKOM"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Nach Deutschland also; hier ist die Bestallung.", "tokens": ["Nach", "Deutschland", "al\u00b7so", ";", "hier", "ist", "die", "Be\u00b7stal\u00b7lung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$.", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Du wei\u00dft ja, wie man's macht, r\u00e4um' auf geb\u00fchrlich,", "tokens": ["Du", "wei\u00dft", "ja", ",", "wie", "man's", "macht", ",", "r\u00e4um'", "auf", "ge\u00b7b\u00fchr\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Sieh nach dem Rechten, mehre Macht und Ordnung,", "tokens": ["Sieh", "nach", "dem", "Rech\u00b7ten", ",", "meh\u00b7re", "Macht", "und", "Ord\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Wirf alle Feinde nieder, drau\u00dfen, drinnen,", "tokens": ["Wirf", "al\u00b7le", "Fein\u00b7de", "nie\u00b7der", ",", "drau\u00b7\u00dfen", ",", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "$,", "ADV", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und wenn du das getan hast, komme wieder.", "tokens": ["Und", "wenn", "du", "das", "ge\u00b7tan", "hast", ",", "kom\u00b7me", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "VVPP", "VAFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Dein Schade soll's nicht sein.\u00ab", "tokens": ["Dein", "Scha\u00b7de", "soll's", "nicht", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Und Zeus verneigte", "tokens": ["Und", "Zeus", "ver\u00b7neig\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "Sich dankbar ehrfurchtsvoll, und aller Unmut,", "tokens": ["Sich", "dank\u00b7bar", "ehr\u00b7furchts\u00b7voll", ",", "und", "al\u00b7ler", "Un\u00b7mut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "$,", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Der wegen unfreiwilliger A.D.-schaft", "tokens": ["Der", "we\u00b7gen", "un\u00b7frei\u00b7wil\u00b7li\u00b7ger", "A.", "D."], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "word"], "pos": ["ART", "APPR", "ADJA", "APPRART", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Ihn lang' gequ\u00e4lt, fiel ab von ihm, es wuchsen", "tokens": ["Ihn", "lang'", "ge\u00b7qu\u00e4lt", ",", "fiel", "ab", "von", "ihm", ",", "es", "wuch\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVPP", "$,", "VVFIN", "PTKVZ", "APPR", "PPER", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Ersichtlich ihm die Brau'n zu ganzen B\u00fcscheln", "tokens": ["Er\u00b7sicht\u00b7lich", "ihm", "die", "Brau'n", "zu", "gan\u00b7zen", "B\u00fc\u00b7scheln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PPER", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.25": {"text": "(nur h\u00f6h'r hinauf war Hopf' und Malz verloren),", "tokens": ["(", "nur", "h\u00f6h'r", "hin\u00b7auf", "war", "Hopf'", "und", "Malz", "ver\u00b7lo\u00b7ren", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "ADV", "VAFIN", "NE", "KON", "NN", "VVPP", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und sieh, mit Adler, Blitz und Ganymed auch", "tokens": ["Und", "sieh", ",", "mit", "Ad\u00b7ler", ",", "Blitz", "und", "Ga\u00b7ny\u00b7med", "auch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Zog er hinab, um Gro\u00df und Kleins zu pr\u00fcfen:", "tokens": ["Zog", "er", "hin\u00b7ab", ",", "um", "Gro\u00df", "und", "Kleins", "zu", "pr\u00fc\u00b7fen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "KOUI", "ADJD", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Herz, Nieren, Rotwein, Bock und andre Biere.", "tokens": ["Herz", ",", "Nie\u00b7ren", ",", "Rot\u00b7wein", ",", "Bock", "und", "and\u00b7re", "Bie\u00b7re", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NE", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "\u00bbwer kommt denn da?\u00ab so lautete der Willkomm,", "tokens": ["\u00bb", "wer", "kommt", "denn", "da", "?", "\u00ab", "so", "lau\u00b7te\u00b7te", "der", "Will\u00b7komm", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ADV", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Der ziemlich n\u00fcchtern ihn empfing, fast feindlich.", "tokens": ["Der", "ziem\u00b7lich", "n\u00fcch\u00b7tern", "ihn", "emp\u00b7fing", ",", "fast", "feind\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er aber, seine Vollmacht in der Tasche,", "tokens": ["Er", "a\u00b7ber", ",", "sei\u00b7ne", "Voll\u00b7macht", "in", "der", "Ta\u00b7sche", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verfuhr programmhaft, sch\u00fcttelte die Brauen,", "tokens": ["Ver\u00b7fuhr", "pro\u00b7gramm\u00b7haft", ",", "sch\u00fct\u00b7tel\u00b7te", "die", "Brau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Jovis-Brauen.", "tokens": ["Die", "Jo\u00b7vis\u00b7Brau\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ei, das klang wie Donner.", "tokens": ["Ei", ",", "das", "klang", "wie", "Don\u00b7ner", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "KOKOM", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und war's nicht Donner, waren es Kanonen.", "tokens": ["Und", "wa\u00b7r's", "nicht", "Don\u00b7ner", ",", "wa\u00b7ren", "es", "Ka\u00b7no\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "NN", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Missunde, D\u00fcppel. Hurra, weiter, weiter:", "tokens": ["Mis\u00b7sun\u00b7de", ",", "D\u00fcp\u00b7pel", ".", "Hur\u00b7ra", ",", "wei\u00b7ter", ",", "wei\u00b7ter", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$.", "NN", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nu\u00dfschalen schwimmen auf dem Alsensunde,", "tokens": ["Nu\u00df\u00b7scha\u00b7len", "schwim\u00b7men", "auf", "dem", "Al\u00b7sen\u00b7sun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Hin \u00fcber Lipa st\u00fcrmen die Geschwader,", "tokens": ["Hin", "\u00fc\u00b7ber", "Li\u00b7pa", "st\u00fcr\u00b7men", "die", "Ge\u00b7schwa\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ein Kn\u00e4ul von Freund und Feind. Da seht ihn selber,", "tokens": ["Ein", "Kn\u00e4ul", "von", "Freund", "und", "Feind", ".", "Da", "seht", "ihn", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Der mit dem Helm ist's und dem Schwefelkragen.", "tokens": ["Der", "mit", "dem", "Helm", "ist's", "und", "dem", "Schwe\u00b7fel\u00b7kra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NE", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und Spichern, W\u00f6rth und Sedan. Weiter, weiter,", "tokens": ["Und", "Spi\u00b7chern", ",", "W\u00f6rth", "und", "Se\u00b7dan", ".", "Wei\u00b7ter", ",", "wei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NE", "$.", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und durchs Triumphtor triumphierend f\u00fchrt er", "tokens": ["Und", "durchs", "Tri\u00b7umph\u00b7tor", "tri\u00b7um\u00b7phie\u00b7rend", "f\u00fchrt", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADJD", "VVFIN", "PPER"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.15": {"text": "All Deutschland in das knirschende Paris ...", "tokens": ["All", "Deutschland", "in", "das", "knir\u00b7schen\u00b7de", "Pa\u00b7ris", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "ADJA", "NE", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.8": {"line.1": {"text": "Und Gott (es war im Sp\u00e4therbst zweiundsechzig)", "tokens": ["Und", "Gott", "(", "es", "war", "im", "Sp\u00e4t\u00b7herbst", "zwei\u00b7und\u00b7sech\u00b7zig", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$(", "PPER", "VAFIN", "APPRART", "NN", "CARD", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Trat an sein Himmelsfenster, sah hernieder", "tokens": ["Trat", "an", "sein", "Him\u00b7mels\u00b7fens\u00b7ter", ",", "sah", "her\u00b7nie\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "$,", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und sah auf ", "tokens": ["Und", "sah", "auf"], "token_info": ["word", "word", "word"], "pos": ["KON", "VVFIN", "APPR"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Seit dem Bronzell-Tag und dem Tag von Olm\u00fctz.", "tokens": ["Seit", "dem", "Bron\u00b7zell\u00b7Tag", "und", "dem", "Tag", "von", "Ol\u00b7m\u00fctz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "ART", "NN", "APPR", "NE", "$."], "meter": "--+-+--+---", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Er sch\u00fcttelte den Kopf. Danach begann er:", "tokens": ["Er", "sch\u00fct\u00b7tel\u00b7te", "den", "Kopf", ".", "Da\u00b7nach", "be\u00b7gann", "er", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$.", "PAV", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "\u00bbdas geht nicht l\u00e4nger so. Streit und Zerkl\u00fcftung", "tokens": ["\u00bb", "das", "geht", "nicht", "l\u00e4n\u00b7ger", "so", ".", "Streit", "und", "Zer\u00b7kl\u00fcf\u00b7tung"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PDS", "VVFIN", "PTKNEG", "ADJD", "ADV", "$.", "NN", "KON", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "L\u00e4hmt ihm die Kraft, zehrt ihm an Mark und Leben,", "tokens": ["L\u00e4hmt", "ihm", "die", "Kraft", ",", "zehrt", "ihm", "an", "Mark", "und", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,", "VVFIN", "PPER", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+---+-+-", "measure": "dactylic.di.plus"}, "line.4": {"text": "Und jeder dritte, der au fond nicht wert ist,", "tokens": ["Und", "je\u00b7der", "drit\u00b7te", ",", "der", "au", "fond", "nicht", "wert", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "$,", "ART", "NE", "NE", "PTKNEG", "ADJD", "VAFIN", "$,"], "meter": "-+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Dem Michel seine Schuhriem' nur zu l\u00f6sen,", "tokens": ["Dem", "Mi\u00b7chel", "sei\u00b7ne", "Schuhriem'", "nur", "zu", "l\u00f6\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Kr\u00e4ht nicht blo\u00df laut auf seinem eignen Miste,", "tokens": ["Kr\u00e4ht", "nicht", "blo\u00df", "laut", "auf", "sei\u00b7nem", "eig\u00b7nen", "Mis\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "ADJD", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Nein, kr\u00e4ht auch \u00fcbern Rhein und schl\u00e4gt die Fl\u00fcgel", "tokens": ["Nein", ",", "kr\u00e4ht", "auch", "\u00fc\u00b7bern", "Rhein", "und", "schl\u00e4gt", "die", "Fl\u00fc\u00b7gel"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "VVFIN", "ADV", "ADV", "NE", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und wirft den roten Kamm. Ich kenn' die Fahne.", "tokens": ["Und", "wirft", "den", "ro\u00b7ten", "Kamm", ".", "Ich", "kenn'", "die", "Fah\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Das geht nicht l\u00e4nger so. Gewi\u00df, die Deutschen,", "tokens": ["Das", "geht", "nicht", "l\u00e4n\u00b7ger", "so", ".", "Ge\u00b7wi\u00df", ",", "die", "Deut\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PTKNEG", "ADJD", "ADV", "$.", "PTKANT", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Sie taugen auch nicht viel, die lieben Schlingel,", "tokens": ["Sie", "tau\u00b7gen", "auch", "nicht", "viel", ",", "die", "lie\u00b7ben", "Schlin\u00b7gel", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Sind Besserwisser, knurrn und querulieren", "tokens": ["Sind", "Bes\u00b7ser\u00b7wis\u00b7ser", ",", "knurrn", "und", "que\u00b7ru\u00b7lie\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Und schreiben B\u00fccher, drin sie mir beweisen:", "tokens": ["Und", "schrei\u00b7ben", "B\u00fc\u00b7cher", ",", "drin", "sie", "mir", "be\u00b7wei\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADV", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Es sei nicht viel mit mir; im letzten Grunde", "tokens": ["Es", "sei", "nicht", "viel", "mit", "mir", ";", "im", "letz\u00b7ten", "Grun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "APPR", "PPER", "$.", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Best\u00fcnd' ich nur durch Kompromi\u00df und Gnade.", "tokens": ["Be\u00b7st\u00fcnd'", "ich", "nur", "durch", "Kom\u00b7pro\u00b7mi\u00df", "und", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Das predigen sie von Tischen und von B\u00e4nken", "tokens": ["Das", "pre\u00b7di\u00b7gen", "sie", "von", "Ti\u00b7schen", "und", "von", "B\u00e4n\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Und f\u00fchlen sich in ihrem Tabakshimmel", "tokens": ["Und", "f\u00fch\u00b7len", "sich", "in", "ih\u00b7rem", "Ta\u00b7baks\u00b7him\u00b7mel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Als Ober-Gott, und wird es dann gem\u00fctlich,", "tokens": ["Als", "O\u00b7ber\u00b7Gott", ",", "und", "wird", "es", "dann", "ge\u00b7m\u00fct\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "So rufen sie mir zu: \u203aIch komm' dir einen!\u2039", "tokens": ["So", "ru\u00b7fen", "sie", "mir", "zu", ":", "\u203a", "Ich", "komm'", "dir", "ei\u00b7nen", "!", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "PTKVZ", "$.", "$(", "PPER", "VVFIN", "PPER", "ART", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Ich kenne sie, sie haben was Kneipantes,", "tokens": ["Ich", "ken\u00b7ne", "sie", ",", "sie", "ha\u00b7ben", "was", "Knei\u00b7pan\u00b7tes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "PIS", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "Was Buntbem\u00fctztes, r\u00fcplig Burschikoses,", "tokens": ["Was", "Bunt\u00b7be\u00b7m\u00fctz\u00b7tes", ",", "r\u00fcp\u00b7lig", "Bur\u00b7schi\u00b7ko\u00b7ses", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "NN", "$,", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Sind kindisch, eitel, unbequem-gef\u00fchlvoll", "tokens": ["Sind", "kin\u00b7disch", ",", "ei\u00b7tel", ",", "un\u00b7be\u00b7quem\u00b7ge\u00b7f\u00fchl\u00b7voll"], "token_info": ["word", "word", "punct", "word", "punct", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADJD", "$,", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Und vieles andre noch, ich wei\u00df, ich wei\u00df es,", "tokens": ["Und", "vie\u00b7les", "and\u00b7re", "noch", ",", "ich", "wei\u00df", ",", "ich", "wei\u00df", "es", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PIS", "ADV", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Und doch, wenn eins zum andern ich erw\u00e4ge,", "tokens": ["Und", "doch", ",", "wenn", "eins", "zum", "an\u00b7dern", "ich", "er\u00b7w\u00e4\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PIS", "APPRART", "ADJA", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "So sind sie schlie\u00dflich immer noch die besten,", "tokens": ["So", "sind", "sie", "schlie\u00df\u00b7lich", "im\u00b7mer", "noch", "die", "bes\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Die besten und nat\u00fcrlichsten vor allem,", "tokens": ["Die", "bes\u00b7ten", "und", "na\u00b7t\u00fcr\u00b7lichs\u00b7ten", "vor", "al\u00b7lem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "APPR", "PIS", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.26": {"text": "Am meisten frei von Babel und von Sodom.", "tokens": ["Am", "meis\u00b7ten", "frei", "von", "Ba\u00b7bel", "und", "von", "So\u00b7dom", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "PIS", "ADJD", "APPR", "NE", "KON", "APPR", "NE", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Sie dauern mich. L\u00e4ngst qu\u00e4lt mich der Gedanke,", "tokens": ["Sie", "dau\u00b7ern", "mich", ".", "L\u00e4ngst", "qu\u00e4lt", "mich", "der", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "NN", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.28": {"text": "Wie schaff' ich ihnen Zuspruch, Beistand, Hilfe!", "tokens": ["Wie", "schaff'", "ich", "ih\u00b7nen", "Zu\u00b7spruch", ",", "Bei\u00b7stand", ",", "Hil\u00b7fe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Vielleicht, da\u00df mir im Gehn und Meditieren", "tokens": ["Viel\u00b7leicht", ",", "da\u00df", "mir", "im", "Gehn", "und", "Me\u00b7di\u00b7tie\u00b7ren"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "PPER", "APPRART", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.30": {"text": "Ein Ausweg kommt, ein guter Plan, ein Einfall.\u00ab", "tokens": ["Ein", "Aus\u00b7weg", "kommt", ",", "ein", "gu\u00b7ter", "Plan", ",", "ein", "Ein\u00b7fall", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.10": {"line.1": {"text": "Und solches denkend nahm er Hut und Mantel", "tokens": ["Und", "sol\u00b7ches", "den\u00b7kend", "nahm", "er", "Hut", "und", "Man\u00b7tel"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "PDS", "VVFIN", "PPER", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und seinen Stab und schritt hinaus ins Freie.", "tokens": ["Und", "sei\u00b7nen", "Stab", "und", "schritt", "hin\u00b7aus", "ins", "Frei\u00b7e", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.11": {"line.1": {"text": "Der Weg war weit, die Stra\u00dfenflucht ohn' Ende,", "tokens": ["Der", "Weg", "war", "weit", ",", "die", "Stra\u00b7\u00dfen\u00b7flucht", "ohn'", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch endlich kamen G\u00e4rten, Park und Wiese", "tokens": ["Doch", "end\u00b7lich", "ka\u00b7men", "G\u00e4r\u00b7ten", ",", "Park", "und", "Wie\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit Silberb\u00e4chen und mit Birkenbr\u00fccken,", "tokens": ["Mit", "Sil\u00b7ber\u00b7b\u00e4\u00b7chen", "und", "mit", "Bir\u00b7ken\u00b7br\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und jenseits dieser Wiese, hoch gelegen,", "tokens": ["Und", "jen\u00b7seits", "die\u00b7ser", "Wie\u00b7se", ",", "hoch", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "APPR", "PDAT", "NN", "$,", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Erhob ein \u00e4ltrer Stadtteil sich, halb Ghetto,", "tokens": ["Er\u00b7hob", "ein", "\u00e4lt\u00b7rer", "Stadt\u00b7teil", "sich", ",", "halb", "Ghet\u00b7to", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJA", "NN", "PRF", "$,", "ADJD", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Halb Kapitol, ein bunt Gemisch von H\u00fctten", "tokens": ["Halb", "Ka\u00b7pi\u00b7tol", ",", "ein", "bunt", "Ge\u00b7misch", "von", "H\u00fct\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "$,", "ART", "ADJD", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und Tempeln und Pal\u00e4sten. Die Pal\u00e4ste", "tokens": ["Und", "Tem\u00b7peln", "und", "Pa\u00b7l\u00e4s\u00b7ten", ".", "Die", "Pa\u00b7l\u00e4s\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "NN", "KON", "NN", "$.", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "H\u00f6chst vornehm, alles Porphyr, alles Marmor,", "tokens": ["H\u00f6chst", "vor\u00b7nehm", ",", "al\u00b7les", "Por\u00b7phyr", ",", "al\u00b7les", "Mar\u00b7mor", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "PIAT", "NN", "$,", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Und doch mit Holz verschlagen und vergittert,", "tokens": ["Und", "doch", "mit", "Holz", "ver\u00b7schla\u00b7gen", "und", "ver\u00b7git\u00b7tert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Als w\u00e4ren's Kerker.", "tokens": ["Als", "w\u00e4\u00b7ren's", "Ker\u00b7ker", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.11": {"text": "Und es waren Kerker.", "tokens": ["Und", "es", "wa\u00b7ren", "Ker\u00b7ker", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.12": {"text": "Denn hinter diesen Gitterst\u00e4ben sa\u00dfen", "tokens": ["Denn", "hin\u00b7ter", "die\u00b7sen", "Git\u00b7ter\u00b7st\u00e4\u00b7ben", "sa\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "\u00bbim Altenteil\u00ab, so hie\u00df es euphemistisch,", "tokens": ["\u00bb", "im", "Al\u00b7ten\u00b7teil", "\u00ab", ",", "so", "hie\u00df", "es", "eu\u00b7phe\u00b7mis\u00b7tisch", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPRART", "NN", "$(", "$,", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Die guten, alten, abgesetzten G\u00f6tter:", "tokens": ["Die", "gu\u00b7ten", ",", "al\u00b7ten", ",", "ab\u00b7ge\u00b7setz\u00b7ten", "G\u00f6t\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Neptun und Pluto, Mars (nur Bacchus fehlte),", "tokens": ["Nep\u00b7tun", "und", "Plu\u00b7to", ",", "Mars", "(", "nur", "Bac\u00b7chus", "fehl\u00b7te", ")", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "$,", "NE", "$(", "ADV", "NE", "VVFIN", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Merkur, Apoll, Vulkan. Und endlich ", "tokens": ["Mer\u00b7kur", ",", "A\u00b7poll", ",", "Vul\u00b7kan", ".", "Und", "end\u00b7lich"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$,", "NE", "$,", "NE", "$.", "KON", "ADV"], "meter": "-++--+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.12": {"line.1": {"text": "Und sieh, an Zeus (er wohnte sichtlich freier", "tokens": ["Und", "sieh", ",", "an", "Zeus", "(", "er", "wohn\u00b7te", "sicht\u00b7lich", "frei\u00b7er"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "NE", "$(", "PPER", "VVFIN", "PRF", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und ward auf Wort und Handschlag hin behandelt),", "tokens": ["Und", "ward", "auf", "Wort", "und", "Hand\u00b7schlag", "hin", "be\u00b7han\u00b7delt", ")", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "KON", "NN", "ADV", "VVPP", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "An Zeus trat jetzt sein Ober-Herr und sagte:", "tokens": ["An", "Zeus", "trat", "jetzt", "sein", "O\u00b7ber\u00b7Herr", "und", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "ADV", "PPOSAT", "NN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "\u00bbgr\u00fc\u00df' Gott dich, Alter. Bringe frohe Botschaft.", "tokens": ["\u00bb", "gr\u00fc\u00df'", "Gott", "dich", ",", "Al\u00b7ter", ".", "Brin\u00b7ge", "fro\u00b7he", "Bot\u00b7schaft", "."], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "NN", "PPER", "$,", "NN", "$.", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich hoff' es wenigstens. Wer so wie du", "tokens": ["Ich", "hoff'", "es", "we\u00b7nigs\u00b7tens", ".", "Wer", "so", "wie", "du"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$.", "PWS", "ADV", "KOKOM", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "'ne h\u00fcbsche Weil' geherrscht, herrscht gern auch wieder,", "tokens": ["'", "ne", "h\u00fcb\u00b7sche", "Weil", "'", "ge\u00b7herrscht", ",", "herrscht", "gern", "auch", "wie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "ADJA", "NN", "$(", "VVPP", "$,", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Still sitzen ist ein Greul. Ich lieb' es auch nicht.", "tokens": ["Still", "sit\u00b7zen", "ist", "ein", "Greul", ".", "Ich", "lieb'", "es", "auch", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}}, "stanza.13": {"line.1": {"text": "So h\u00f6re denn: ich habe was in petto,", "tokens": ["So", "h\u00f6\u00b7re", "denn", ":", "ich", "ha\u00b7be", "was", "in", "pet\u00b7to", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$.", "PPER", "VAFIN", "PIS", "APPR", "NE", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Pack deine Koffer, nimm dein Inventar", "tokens": ["Pack", "dei\u00b7ne", "Kof\u00b7fer", ",", "nimm", "dein", "In\u00b7ven\u00b7tar"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "PPOSAT", "NN", "$,", "VVIMP", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "(spezialmission auf unbestimmte Dauer),", "tokens": ["(", "spe\u00b7zi\u00b7al\u00b7mis\u00b7si\u00b7on", "auf", "un\u00b7be\u00b7stimm\u00b7te", "Dau\u00b7er", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "APPR", "ADJA", "NN", "$(", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Nimm Adler, B\u00fcndelblitze, Ganymed auch,", "tokens": ["Nimm", "Ad\u00b7ler", ",", "B\u00fcn\u00b7del\u00b7blit\u00b7ze", ",", "Ga\u00b7ny\u00b7med", "auch", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NE", "NN", "$,", "NN", "$,", "NE", "ADV", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Und zieh hernieder in mein altes Deutschland,", "tokens": ["Und", "zieh", "her\u00b7nie\u00b7der", "in", "mein", "al\u00b7tes", "Deutschland", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "An einen Ort, den ", "tokens": ["An", "ei\u00b7nen", "Ort", ",", "den"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "ART", "NN", "$,", "ART"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Zum Unterschiede, du verstehst. Du find'st dort", "tokens": ["Zum", "Un\u00b7ter\u00b7schie\u00b7de", ",", "du", "ver\u00b7stehst", ".", "Du", "fin\u00b7d'st", "dort"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "PPER", "VVFIN", "$.", "PPER", "VVFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Bildwerke viel auf Stra\u00dfen und auf Pl\u00e4tzen,", "tokens": ["Bild\u00b7wer\u00b7ke", "viel", "auf", "Stra\u00b7\u00dfen", "und", "auf", "Pl\u00e4t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.9": {"text": "Athene nicht, auch Venus nicht von Milo,", "tokens": ["A\u00b7the\u00b7ne", "nicht", ",", "auch", "Ve\u00b7nus", "nicht", "von", "Mi\u00b7lo", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "$,", "ADV", "NN", "PTKNEG", "APPR", "NE", "$,"], "meter": "+---+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Doch Bl\u00fccher, York, Schwerin und Keith und Scharnhorst,", "tokens": ["Doch", "Bl\u00fc\u00b7cher", ",", "Y\u00b7ork", ",", "Schwe\u00b7rin", "und", "Keith", "und", "Scharn\u00b7horst", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "NE", "$,", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Den alten Zieten und den alten Fritzen,", "tokens": ["Den", "al\u00b7ten", "Zie\u00b7ten", "und", "den", "al\u00b7ten", "Frit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Den letztern, denk' ich, kennst du \u2013's ist derselbe,", "tokens": ["Den", "letz\u00b7tern", ",", "denk'", "ich", ",", "kennst", "du", "\u2013", "'s", "ist", "der\u00b7sel\u00b7be", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "PDAT", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Der hier am Himmel gl\u00e4nzt als ", "tokens": ["Der", "hier", "am", "Him\u00b7mel", "gl\u00e4nzt", "als"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPRART", "NN", "VVFIN", "KOKOM"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Nach Deutschland also; hier ist die Bestallung.", "tokens": ["Nach", "Deutschland", "al\u00b7so", ";", "hier", "ist", "die", "Be\u00b7stal\u00b7lung", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "ADV", "$.", "ADV", "VAFIN", "ART", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.15": {"text": "Du wei\u00dft ja, wie man's macht, r\u00e4um' auf geb\u00fchrlich,", "tokens": ["Du", "wei\u00dft", "ja", ",", "wie", "man's", "macht", ",", "r\u00e4um'", "auf", "ge\u00b7b\u00fchr\u00b7lich", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "PIS", "VVFIN", "$,", "VVFIN", "APPR", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Sieh nach dem Rechten, mehre Macht und Ordnung,", "tokens": ["Sieh", "nach", "dem", "Rech\u00b7ten", ",", "meh\u00b7re", "Macht", "und", "Ord\u00b7nung", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$,", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Wirf alle Feinde nieder, drau\u00dfen, drinnen,", "tokens": ["Wirf", "al\u00b7le", "Fein\u00b7de", "nie\u00b7der", ",", "drau\u00b7\u00dfen", ",", "drin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "PIAT", "NN", "PTKVZ", "$,", "ADV", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und wenn du das getan hast, komme wieder.", "tokens": ["Und", "wenn", "du", "das", "ge\u00b7tan", "hast", ",", "kom\u00b7me", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PDS", "VVPP", "VAFIN", "$,", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "Dein Schade soll's nicht sein.\u00ab", "tokens": ["Dein", "Scha\u00b7de", "soll's", "nicht", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PTKNEG", "VAINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Und Zeus verneigte", "tokens": ["Und", "Zeus", "ver\u00b7neig\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["KON", "NE", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "Sich dankbar ehrfurchtsvoll, und aller Unmut,", "tokens": ["Sich", "dank\u00b7bar", "ehr\u00b7furchts\u00b7voll", ",", "und", "al\u00b7ler", "Un\u00b7mut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "$,", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "Der wegen unfreiwilliger A.D.-schaft", "tokens": ["Der", "we\u00b7gen", "un\u00b7frei\u00b7wil\u00b7li\u00b7ger", "A.", "D."], "token_info": ["word", "word", "word", "abbreviation", "abbreviation", "word"], "pos": ["ART", "APPR", "ADJA", "APPRART", "NE", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Ihn lang' gequ\u00e4lt, fiel ab von ihm, es wuchsen", "tokens": ["Ihn", "lang'", "ge\u00b7qu\u00e4lt", ",", "fiel", "ab", "von", "ihm", ",", "es", "wuch\u00b7sen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "ADV", "VVPP", "$,", "VVFIN", "PTKVZ", "APPR", "PPER", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.24": {"text": "Ersichtlich ihm die Brau'n zu ganzen B\u00fcscheln", "tokens": ["Er\u00b7sicht\u00b7lich", "ihm", "die", "Brau'n", "zu", "gan\u00b7zen", "B\u00fc\u00b7scheln"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "PPER", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+---", "measure": "unknown.measure.tetra"}, "line.25": {"text": "(nur h\u00f6h'r hinauf war Hopf' und Malz verloren),", "tokens": ["(", "nur", "h\u00f6h'r", "hin\u00b7auf", "war", "Hopf'", "und", "Malz", "ver\u00b7lo\u00b7ren", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADV", "ADV", "VAFIN", "NE", "KON", "NN", "VVPP", "$(", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Und sieh, mit Adler, Blitz und Ganymed auch", "tokens": ["Und", "sieh", ",", "mit", "Ad\u00b7ler", ",", "Blitz", "und", "Ga\u00b7ny\u00b7med", "auch"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "APPR", "NN", "$,", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.27": {"text": "Zog er hinab, um Gro\u00df und Kleins zu pr\u00fcfen:", "tokens": ["Zog", "er", "hin\u00b7ab", ",", "um", "Gro\u00df", "und", "Kleins", "zu", "pr\u00fc\u00b7fen", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PTKVZ", "$,", "KOUI", "ADJD", "KON", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.28": {"text": "Herz, Nieren, Rotwein, Bock und andre Biere.", "tokens": ["Herz", ",", "Nie\u00b7ren", ",", "Rot\u00b7wein", ",", "Bock", "und", "and\u00b7re", "Bie\u00b7re", "."], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NE", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "\u00bbwer kommt denn da?\u00ab so lautete der Willkomm,", "tokens": ["\u00bb", "wer", "kommt", "denn", "da", "?", "\u00ab", "so", "lau\u00b7te\u00b7te", "der", "Will\u00b7komm", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ADV", "$.", "$(", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Der ziemlich n\u00fcchtern ihn empfing, fast feindlich.", "tokens": ["Der", "ziem\u00b7lich", "n\u00fcch\u00b7tern", "ihn", "emp\u00b7fing", ",", "fast", "feind\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "PPER", "VVFIN", "$,", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er aber, seine Vollmacht in der Tasche,", "tokens": ["Er", "a\u00b7ber", ",", "sei\u00b7ne", "Voll\u00b7macht", "in", "der", "Ta\u00b7sche", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Verfuhr programmhaft, sch\u00fcttelte die Brauen,", "tokens": ["Ver\u00b7fuhr", "pro\u00b7gramm\u00b7haft", ",", "sch\u00fct\u00b7tel\u00b7te", "die", "Brau\u00b7en", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Die Jovis-Brauen.", "tokens": ["Die", "Jo\u00b7vis\u00b7Brau\u00b7en", "."], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Ei, das klang wie Donner.", "tokens": ["Ei", ",", "das", "klang", "wie", "Don\u00b7ner", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PDS", "VVFIN", "KOKOM", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Und war's nicht Donner, waren es Kanonen.", "tokens": ["Und", "wa\u00b7r's", "nicht", "Don\u00b7ner", ",", "wa\u00b7ren", "es", "Ka\u00b7no\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "NN", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Missunde, D\u00fcppel. Hurra, weiter, weiter:", "tokens": ["Mis\u00b7sun\u00b7de", ",", "D\u00fcp\u00b7pel", ".", "Hur\u00b7ra", ",", "wei\u00b7ter", ",", "wei\u00b7ter", ":"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "NE", "$.", "NN", "$,", "ADV", "$,", "ADV", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nu\u00dfschalen schwimmen auf dem Alsensunde,", "tokens": ["Nu\u00df\u00b7scha\u00b7len", "schwim\u00b7men", "auf", "dem", "Al\u00b7sen\u00b7sun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Hin \u00fcber Lipa st\u00fcrmen die Geschwader,", "tokens": ["Hin", "\u00fc\u00b7ber", "Li\u00b7pa", "st\u00fcr\u00b7men", "die", "Ge\u00b7schwa\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Ein Kn\u00e4ul von Freund und Feind. Da seht ihn selber,", "tokens": ["Ein", "Kn\u00e4ul", "von", "Freund", "und", "Feind", ".", "Da", "seht", "ihn", "sel\u00b7ber", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Der mit dem Helm ist's und dem Schwefelkragen.", "tokens": ["Der", "mit", "dem", "Helm", "ist's", "und", "dem", "Schwe\u00b7fel\u00b7kra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NE", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und Spichern, W\u00f6rth und Sedan. Weiter, weiter,", "tokens": ["Und", "Spi\u00b7chern", ",", "W\u00f6rth", "und", "Se\u00b7dan", ".", "Wei\u00b7ter", ",", "wei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NE", "$.", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Und durchs Triumphtor triumphierend f\u00fchrt er", "tokens": ["Und", "durchs", "Tri\u00b7umph\u00b7tor", "tri\u00b7um\u00b7phie\u00b7rend", "f\u00fchrt", "er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "ADJD", "VVFIN", "PPER"], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.15": {"text": "All Deutschland in das knirschende Paris ...", "tokens": ["All", "Deutschland", "in", "das", "knir\u00b7schen\u00b7de", "Pa\u00b7ris", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "APPR", "ART", "ADJA", "NE", "$("], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}}}}}