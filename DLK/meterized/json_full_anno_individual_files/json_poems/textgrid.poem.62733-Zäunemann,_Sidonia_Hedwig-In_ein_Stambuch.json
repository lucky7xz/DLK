{"textgrid.poem.62733": {"metadata": {"author": {"name": "Z\u00e4unemann, Sidonia Hedwig", "birth": "N.A.", "death": "N.A."}, "title": "In ein Stambuch", "genre": "verse", "period": "N.A.", "pub_year": 1727, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ein Bergmann setzt auf seiner Fahrt", "tokens": ["Ein", "Berg\u00b7mann", "setzt", "auf", "sei\u00b7ner", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den einen einen Fu\u00df erst fest,", "tokens": ["Den", "ei\u00b7nen", "ei\u00b7nen", "Fu\u00df", "erst", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh er den andern fahren l\u00e4\u00dft.", "tokens": ["Eh", "er", "den", "an\u00b7dern", "fah\u00b7ren", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Elephant ist auch von gleicher Art,", "tokens": ["Ein", "E\u00b7le\u00b7phant", "ist", "auch", "von", "glei\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er pflegt mit einem Fu\u00df nicht ehnder fort zu gehen,", "tokens": ["Er", "pflegt", "mit", "ei\u00b7nem", "Fu\u00df", "nicht", "ehn\u00b7der", "fort", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es m\u00fcsse denn der andre feste stehen.", "tokens": ["Es", "m\u00fcs\u00b7se", "denn", "der", "and\u00b7re", "fes\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die\u00df Gleichni\u00df trift bey solchen Menschen ein", "tokens": ["Die\u00df", "Gleich\u00b7ni\u00df", "trift", "bey", "sol\u00b7chen", "Men\u00b7schen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VVFIN", "APPR", "PIAT", "NN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die klug und auch bedachtsam seyn.", "tokens": ["Die", "klug", "und", "auch", "be\u00b7dacht\u00b7sam", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die ohne Grund und reifes Uberlegen,", "tokens": ["Die", "oh\u00b7ne", "Grund", "und", "rei\u00b7fes", "U\u00b7ber\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "In gro\u00df und kleinen Sachen", "tokens": ["In", "gro\u00df", "und", "klei\u00b7nen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Nichts schaffen oder machen.", "tokens": ["Nichts", "schaf\u00b7fen", "o\u00b7der", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ein Bergmann setzt auf seiner Fahrt", "tokens": ["Ein", "Berg\u00b7mann", "setzt", "auf", "sei\u00b7ner", "Fahrt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den einen einen Fu\u00df erst fest,", "tokens": ["Den", "ei\u00b7nen", "ei\u00b7nen", "Fu\u00df", "erst", "fest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Eh er den andern fahren l\u00e4\u00dft.", "tokens": ["Eh", "er", "den", "an\u00b7dern", "fah\u00b7ren", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Elephant ist auch von gleicher Art,", "tokens": ["Ein", "E\u00b7le\u00b7phant", "ist", "auch", "von", "glei\u00b7cher", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Er pflegt mit einem Fu\u00df nicht ehnder fort zu gehen,", "tokens": ["Er", "pflegt", "mit", "ei\u00b7nem", "Fu\u00df", "nicht", "ehn\u00b7der", "fort", "zu", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PTKNEG", "ADJD", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es m\u00fcsse denn der andre feste stehen.", "tokens": ["Es", "m\u00fcs\u00b7se", "denn", "der", "and\u00b7re", "fes\u00b7te", "ste\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "ADJA", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die\u00df Gleichni\u00df trift bey solchen Menschen ein", "tokens": ["Die\u00df", "Gleich\u00b7ni\u00df", "trift", "bey", "sol\u00b7chen", "Men\u00b7schen", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VVFIN", "APPR", "PIAT", "NN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Die klug und auch bedachtsam seyn.", "tokens": ["Die", "klug", "und", "auch", "be\u00b7dacht\u00b7sam", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "KON", "ADV", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die ohne Grund und reifes Uberlegen,", "tokens": ["Die", "oh\u00b7ne", "Grund", "und", "rei\u00b7fes", "U\u00b7ber\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "In gro\u00df und kleinen Sachen", "tokens": ["In", "gro\u00df", "und", "klei\u00b7nen", "Sa\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJD", "KON", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Nichts schaffen oder machen.", "tokens": ["Nichts", "schaf\u00b7fen", "o\u00b7der", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}