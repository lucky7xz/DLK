{"dta.poem.20103": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "1.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1851", "urn": "urn:nbn:de:kobv:b4-200905191321", "language": ["de:0.99"], "booktitle": "Fontane, Theodor: Gedichte. Berlin, 1851."}, "poem": {"stanza.1": {"line.1": {"text": "Sch\u00f6n-Anne str\u00e4hlt ihr schwarzes Haar,", "tokens": ["Sch\u00f6n\u00b7An\u00b7ne", "str\u00e4hlt", "ihr", "schwar\u00b7zes", "Haar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und h\u00e4ngt den Kopf in Trauer;", "tokens": ["Und", "h\u00e4ngt", "den", "Kopf", "in", "Trau\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie spricht: \u201eheut werd\u2019 ich zwanzig Jahr", "tokens": ["Sie", "spricht", ":", "\u201e", "heut", "werd'", "ich", "zwan\u00b7zig", "Jahr"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADV", "VAFIN", "PPER", "CARD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Jugend hat nicht Dauer;", "tokens": ["Und", "Ju\u00b7gend", "hat", "nicht", "Dau\u00b7er", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PTKNEG", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Wenn ich ein Herz noch finden soll,", "tokens": ["Wenn", "ich", "ein", "Herz", "noch", "fin\u00b7den", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Recht wie mein eignes liebevoll,", "tokens": ["Recht", "wie", "mein", "eig\u00b7nes", "lie\u00b7be\u00b7voll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "PPOSAT", "ADJA", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "So mu\u00df ich\u2019s balde finden.\u201c", "tokens": ["So", "mu\u00df", "ich's", "bal\u00b7de", "fin\u00b7den", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Der Tag ist um; neugierig-bang", "tokens": ["Der", "Tag", "ist", "um", ";", "neu\u00b7gie\u00b7rig\u00b7bang"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "$.", "ADJA"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Legt Anne sich die Karten:", "tokens": ["Legt", "An\u00b7ne", "sich", "die", "Kar\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "PRF", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u201eein Jahr noch!\u201c ach, es ist so lang", "tokens": ["\u201e", "ein", "Jahr", "noch", "!", "\u201c", "ach", ",", "es", "ist", "so", "lang"], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ART", "NN", "ADV", "$.", "$(", "ITJ", "$,", "PPER", "VAFIN", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis \u00fcber\u2019s Jahr zu warten;", "tokens": ["Bis", "\u00fc\u00b7ber's", "Jahr", "zu", "war\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie seufzet: \u201ew\u00e4r\u2019 erst wieder Mai,", "tokens": ["Sie", "seuf\u00b7zet", ":", "\u201e", "w\u00e4r'", "erst", "wie\u00b7der", "Mai", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "VAFIN", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht eher athm\u2019 ich froh und frei,", "tokens": ["Nicht", "e\u00b7her", "athm'", "ich", "froh", "und", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Bis ich ein Herz gefunden.\u201c", "tokens": ["Bis", "ich", "ein", "Herz", "ge\u00b7fun\u00b7den", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das Jahr ist um, der Mai ist da", "tokens": ["Das", "Jahr", "ist", "um", ",", "der", "Mai", "ist", "da"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "APPR", "$,", "ART", "NN", "VAFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seinen Blumen allen,", "tokens": ["Mit", "sei\u00b7nen", "Blu\u00b7men", "al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PIAT", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wohl mochte Manchem, der sie sah,", "tokens": ["Wohl", "moch\u00b7te", "Man\u00b7chem", ",", "der", "sie", "sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die h\u00fcbsche Dirn\u2019 gefallen;", "tokens": ["Die", "h\u00fcb\u00b7sche", "Dirn'", "ge\u00b7fal\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch Anne war ein Waisenkind,", "tokens": ["Doch", "An\u00b7ne", "war", "ein", "Wai\u00b7sen\u00b7kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und wo nicht Hof und Truhe sind,", "tokens": ["Und", "wo", "nicht", "Hof", "und", "Tru\u00b7he", "sind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PTKNEG", "NN", "KON", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Da hat die Lieb\u2019 ein Ende.", "tokens": ["Da", "hat", "die", "Lieb'", "ein", "En\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Das Jahr ist um, und Anne spricht:", "tokens": ["Das", "Jahr", "ist", "um", ",", "und", "An\u00b7ne", "spricht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "$,", "KON", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u201egott, diese Herzensleere", "tokens": ["\u201e", "gott", ",", "die\u00b7se", "Her\u00b7zens\u00b7lee\u00b7re"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "ADJD", "$,", "PDAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Trag ich geduldig l\u00e4nger nicht,", "tokens": ["Trag", "ich", "ge\u00b7dul\u00b7dig", "l\u00e4n\u00b7ger", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADJD", "ADJD", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und kostet\u2019s Ruf und Ehre;", "tokens": ["Und", "kos\u00b7tet's", "Ruf", "und", "Eh\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die Eltern hab ich kaum gekannt,", "tokens": ["Die", "El\u00b7tern", "hab", "ich", "kaum", "ge\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Niemals ein Herze mein genannt, \u2014", "tokens": ["Nie\u00b7mals", "ein", "Her\u00b7ze", "mein", "ge\u00b7nannt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "VVFIN", "PPOSAT", "VVPP", "$,", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Ich ", "tokens": ["Ich"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}}, "stanza.5": {"line.1": {"text": "Und als der Sonntag Abend kam", "tokens": ["Und", "als", "der", "Sonn\u00b7tag", "A\u00b7bend", "kam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da ging sie hin zum Tanze,", "tokens": ["Da", "ging", "sie", "hin", "zum", "Tan\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie fragte nichts nach Schand\u2019 und Scham,", "tokens": ["Sie", "frag\u00b7te", "nichts", "nach", "Schand'", "und", "Scham", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nichts nach ihrem Kranze, \u2014", "tokens": ["Und", "nichts", "nach", "ih\u00b7rem", "Kran\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIS", "APPR", "PPOSAT", "NN", "$,", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Sie suchte sich den H\u00fcbsch\u2019sten aus,", "tokens": ["Sie", "such\u00b7te", "sich", "den", "H\u00fcb\u00b7sch'\u00b7sten", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "Und nahm ihn keck mit sich nach Haus; \u2014", "tokens": ["Und", "nahm", "ihn", "keck", "mit", "sich", "nach", "Haus", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "PRF", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Es war ihr fester Wille.", "tokens": ["Es", "war", "ihr", "fes\u00b7ter", "Wil\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "\u201eich hab ein Recht!\u201c der eitle Wahn", "tokens": ["\u201e", "ich", "hab", "ein", "Recht", "!", "\u201c", "der", "eit\u00b7le", "Wahn"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VAFIN", "ART", "NN", "$.", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df keinen Spott sie scheuen,", "tokens": ["Lie\u00df", "kei\u00b7nen", "Spott", "sie", "scheu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie sprach: \u201eich wei\u00df, was ich gethan,", "tokens": ["Sie", "sprach", ":", "\u201e", "ich", "wei\u00df", ",", "was", "ich", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "PPER", "VVFIN", "$,", "PWS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nimmer soll\u2019s mich reuen;", "tokens": ["Und", "nim\u00b7mer", "soll's", "mich", "reu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Was mir das Leben schuldig ist,", "tokens": ["Was", "mir", "das", "Le\u00b7ben", "schul\u00b7dig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das soll mir nun in kurzer Frist", "tokens": ["Das", "soll", "mir", "nun", "in", "kur\u00b7zer", "Frist"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mein eigen Kind bezahlen.\u201c", "tokens": ["Mein", "ei\u00b7gen", "Kind", "be\u00b7zah\u00b7len", ".", "\u201c"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}