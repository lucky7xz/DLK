{"textgrid.poem.44598": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "In tr\u00fcber Stunde", "genre": "verse", "period": "N.A.", "pub_year": 1855, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Frost und Nacht, wohin ich richte", "tokens": ["Frost", "und", "Nacht", ",", "wo\u00b7hin", "ich", "rich\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine besten Lichtgedanken!", "tokens": ["Mei\u00b7ne", "bes\u00b7ten", "Licht\u00b7ge\u00b7dan\u00b7ken", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich sinne, wie ich dichte,", "tokens": ["Wie", "ich", "sin\u00b7ne", ",", "wie", "ich", "dich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht die Mitwelt will mirs danken.", "tokens": ["Nicht", "die", "Mit\u00b7welt", "will", "mirs", "dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Hab mein Bestes ihr gegeben,", "tokens": ["Hab", "mein", "Bes\u00b7tes", "ihr", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwar nicht reichlich, stets doch Reines,", "tokens": ["Zwar", "nicht", "reich\u00b7lich", ",", "stets", "doch", "Rei\u00b7nes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "$,", "ADV", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reinsten Teil von meinem Leben,", "tokens": ["Reins\u00b7ten", "Teil", "von", "mei\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wohl nicht Schmuck voll falschen Scheines.", "tokens": ["Wohl", "nicht", "Schmuck", "voll", "fal\u00b7schen", "Schei\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Kurze Zeit habt ihr verstanden,", "tokens": ["Kur\u00b7ze", "Zeit", "habt", "ihr", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was die G\u00f6tter mir erz\u00e4hlten;", "tokens": ["Was", "die", "G\u00f6t\u00b7ter", "mir", "er\u00b7z\u00e4hl\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ich galt in unsern Landen", "tokens": ["Und", "ich", "galt", "in", "un\u00b7sern", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu den hohen Auserw\u00e4hlten.", "tokens": ["Zu", "den", "ho\u00b7hen", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch ihr habt mich dann vergessen \u2013", "tokens": ["Doch", "ihr", "habt", "mich", "dann", "ver\u00b7ges\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und vergessen eure W\u00fcrde:", "tokens": ["Und", "ver\u00b7ges\u00b7sen", "eu\u00b7re", "W\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und \u2013 wenn nicht mein Wort vermessen:", "tokens": ["Und", "\u2013", "wenn", "nicht", "mein", "Wort", "ver\u00b7mes\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward mein Geist euch eine B\u00fcrde.", "tokens": ["Ward", "mein", "Geist", "euch", "ei\u00b7ne", "B\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Seis! \u2013 ich opfre meinen G\u00f6ttern \u2013", "tokens": ["Seis", "!", "\u2013", "ich", "opf\u00b7re", "mei\u00b7nen", "G\u00f6t\u00b7tern", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Opfert ihr \u2013 wie lang? \u2013 den G\u00f6tzen!", "tokens": ["Op\u00b7fert", "ihr", "\u2013", "wie", "lang", "?", "\u2013", "den", "G\u00f6t\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "PWAV", "ADJD", "$.", "$(", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zukunft wird mit andern Lettern", "tokens": ["Zu\u00b7kunft", "wird", "mit", "an\u00b7dern", "Let\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch und mir das Urteil setzen!", "tokens": ["Euch", "und", "mir", "das", "Ur\u00b7teil", "set\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Zwar, wenn tot einst, werd ich leben,", "tokens": ["Zwar", ",", "wenn", "tot", "einst", ",", "werd", "ich", "le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJD", "ADV", "$,", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ihr flechtet mir noch Kr\u00e4nze,", "tokens": ["Und", "ihr", "flech\u00b7tet", "mir", "noch", "Kr\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denkt ihr auch nicht schmerzlich eben", "tokens": ["Denkt", "ihr", "auch", "nicht", "schmerz\u00b7lich", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner tr\u00fcben Lebenslenze.", "tokens": ["Mei\u00b7ner", "tr\u00fc\u00b7ben", "Le\u00b7bens\u00b7len\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Doch \u2013 was klag ich? \u2013 wo im Innern", "tokens": ["Doch", "\u2013", "was", "klag", "ich", "?", "\u2013", "wo", "im", "In\u00b7nern"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "$(", "PWS", "VVFIN", "PPER", "$.", "$(", "PWAV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heilge Stimmen stets erklangen!", "tokens": ["Heil\u00b7ge", "Stim\u00b7men", "stets", "er\u00b7klan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ists doch \u2013 zwar kein Trost-Erinnern! \u2013", "tokens": ["Ists", "doch", "\u2013", "zwar", "kein", "Trost\u00b7\u00b7Erin\u00b7nern", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "$(", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Manchem ", "tokens": ["Man\u00b7chem"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}, "stanza.8": {"line.1": {"text": "Frost und Nacht, wohin ich richte", "tokens": ["Frost", "und", "Nacht", ",", "wo\u00b7hin", "ich", "rich\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["NN", "KON", "NN", "$,", "PWAV", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Meine besten Lichtgedanken!", "tokens": ["Mei\u00b7ne", "bes\u00b7ten", "Licht\u00b7ge\u00b7dan\u00b7ken", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wie ich sinne, wie ich dichte,", "tokens": ["Wie", "ich", "sin\u00b7ne", ",", "wie", "ich", "dich\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht die Mitwelt will mirs danken.", "tokens": ["Nicht", "die", "Mit\u00b7welt", "will", "mirs", "dan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "VMFIN", "NE", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Hab mein Bestes ihr gegeben,", "tokens": ["Hab", "mein", "Bes\u00b7tes", "ihr", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Zwar nicht reichlich, stets doch Reines,", "tokens": ["Zwar", "nicht", "reich\u00b7lich", ",", "stets", "doch", "Rei\u00b7nes", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJD", "$,", "ADV", "ADV", "NE", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Reinsten Teil von meinem Leben,", "tokens": ["Reins\u00b7ten", "Teil", "von", "mei\u00b7nem", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wohl nicht Schmuck voll falschen Scheines.", "tokens": ["Wohl", "nicht", "Schmuck", "voll", "fal\u00b7schen", "Schei\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Kurze Zeit habt ihr verstanden,", "tokens": ["Kur\u00b7ze", "Zeit", "habt", "ihr", "ver\u00b7stan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VAFIN", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Was die G\u00f6tter mir erz\u00e4hlten;", "tokens": ["Was", "die", "G\u00f6t\u00b7ter", "mir", "er\u00b7z\u00e4hl\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und ich galt in unsern Landen", "tokens": ["Und", "ich", "galt", "in", "un\u00b7sern", "Lan\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Zu den hohen Auserw\u00e4hlten.", "tokens": ["Zu", "den", "ho\u00b7hen", "Au\u00b7ser\u00b7w\u00e4hl\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Doch ihr habt mich dann vergessen \u2013", "tokens": ["Doch", "ihr", "habt", "mich", "dann", "ver\u00b7ges\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und vergessen eure W\u00fcrde:", "tokens": ["Und", "ver\u00b7ges\u00b7sen", "eu\u00b7re", "W\u00fcr\u00b7de", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und \u2013 wenn nicht mein Wort vermessen:", "tokens": ["Und", "\u2013", "wenn", "nicht", "mein", "Wort", "ver\u00b7mes\u00b7sen", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "KOUS", "PTKNEG", "PPOSAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward mein Geist euch eine B\u00fcrde.", "tokens": ["Ward", "mein", "Geist", "euch", "ei\u00b7ne", "B\u00fcr\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Seis! \u2013 ich opfre meinen G\u00f6ttern \u2013", "tokens": ["Seis", "!", "\u2013", "ich", "opf\u00b7re", "mei\u00b7nen", "G\u00f6t\u00b7tern", "\u2013"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Opfert ihr \u2013 wie lang? \u2013 den G\u00f6tzen!", "tokens": ["Op\u00b7fert", "ihr", "\u2013", "wie", "lang", "?", "\u2013", "den", "G\u00f6t\u00b7zen", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$(", "PWAV", "ADJD", "$.", "$(", "ART", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Zukunft wird mit andern Lettern", "tokens": ["Zu\u00b7kunft", "wird", "mit", "an\u00b7dern", "Let\u00b7tern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Euch und mir das Urteil setzen!", "tokens": ["Euch", "und", "mir", "das", "Ur\u00b7teil", "set\u00b7zen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPER", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Zwar, wenn tot einst, werd ich leben,", "tokens": ["Zwar", ",", "wenn", "tot", "einst", ",", "werd", "ich", "le\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "ADJD", "ADV", "$,", "VAFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und ihr flechtet mir noch Kr\u00e4nze,", "tokens": ["Und", "ihr", "flech\u00b7tet", "mir", "noch", "Kr\u00e4n\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADV", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denkt ihr auch nicht schmerzlich eben", "tokens": ["Denkt", "ihr", "auch", "nicht", "schmerz\u00b7lich", "e\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "ADV"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Meiner tr\u00fcben Lebenslenze.", "tokens": ["Mei\u00b7ner", "tr\u00fc\u00b7ben", "Le\u00b7bens\u00b7len\u00b7ze", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Doch \u2013 was klag ich? \u2013 wo im Innern", "tokens": ["Doch", "\u2013", "was", "klag", "ich", "?", "\u2013", "wo", "im", "In\u00b7nern"], "token_info": ["word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["KON", "$(", "PWS", "VVFIN", "PPER", "$.", "$(", "PWAV", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Heilge Stimmen stets erklangen!", "tokens": ["Heil\u00b7ge", "Stim\u00b7men", "stets", "er\u00b7klan\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ists doch \u2013 zwar kein Trost-Erinnern! \u2013", "tokens": ["Ists", "doch", "\u2013", "zwar", "kein", "Trost\u00b7\u00b7Erin\u00b7nern", "!", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NE", "ADV", "$(", "ADV", "PIAT", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Manchem ", "tokens": ["Man\u00b7chem"], "token_info": ["word"], "pos": ["NN"], "meter": "+-", "measure": "trochaic.single"}}}}}