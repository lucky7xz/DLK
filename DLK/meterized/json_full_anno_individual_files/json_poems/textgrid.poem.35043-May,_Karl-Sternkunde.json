{"textgrid.poem.35043": {"metadata": {"author": {"name": "May, Karl", "birth": "N.A.", "death": "N.A."}, "title": "Sternkunde", "genre": "verse", "period": "N.A.", "pub_year": 1877, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich sah dich oft in stiller Nacht.", "tokens": ["Ich", "sah", "dich", "oft", "in", "stil\u00b7ler", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du nahmst ins Rohr des Himmels Sterne", "tokens": ["Du", "nahmst", "ins", "Rohr", "des", "Him\u00b7mels", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und hast dar\u00fcber nachgedacht,", "tokens": ["Und", "hast", "da\u00b7r\u00fc\u00b7ber", "nach\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie man sie wohl ergr\u00fcnden lerne.", "tokens": ["Wie", "man", "sie", "wohl", "er\u00b7gr\u00fcn\u00b7den", "ler\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Ists um die K\u00f6rper dir zu thun,", "tokens": ["Ists", "um", "die", "K\u00f6r\u00b7per", "dir", "zu", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So magst du deiner Forschung leben.", "tokens": ["So", "magst", "du", "dei\u00b7ner", "For\u00b7schung", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wissenschaft darf nimmer ruhn;", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "darf", "nim\u00b7mer", "ruhn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist ihr Schweres aufgegeben.", "tokens": ["Es", "ist", "ihr", "Schwe\u00b7res", "auf\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Doch weiter, weiter trachte nicht;", "tokens": ["Doch", "wei\u00b7ter", ",", "wei\u00b7ter", "trach\u00b7te", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Allmacht l\u00e4\u00dft sich nicht bestehlen.", "tokens": ["Die", "All\u00b7macht", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gott gab den Sternen zwar das Licht,", "tokens": ["Gott", "gab", "den", "Ster\u00b7nen", "zwar", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie zu ergr\u00fcnden, wird dirs fehlen.", "tokens": ["Sie", "zu", "er\u00b7gr\u00fcn\u00b7den", ",", "wird", "dirs", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Weg zum rechten, wahren Schaun", "tokens": ["Der", "Weg", "zum", "rech\u00b7ten", ",", "wah\u00b7ren", "Schaun"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt nicht empor auf Prismenstrahlen.", "tokens": ["Steigt", "nicht", "em\u00b7por", "auf", "Pris\u00b7mens\u00b7trah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist da Andres aufzubaun", "tokens": ["Es", "ist", "da", "And\u00b7res", "auf\u00b7zu\u00b7baun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Logarithmen-Dezimalen.", "tokens": ["Als", "Lo\u00b7ga\u00b7rith\u00b7men\u00b7De\u00b7zi\u00b7ma\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Den gro\u00dfen Weltzusammenhang", "tokens": ["Den", "gro\u00b7\u00dfen", "Welt\u00b7zu\u00b7sam\u00b7men\u00b7hang"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Regiert allein die Hand des Einen,", "tokens": ["Re\u00b7giert", "al\u00b7lein", "die", "Hand", "des", "Ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Durch die sich wie ein Lobgesang", "tokens": ["Durch", "die", "sich", "wie", "ein", "Lob\u00b7ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PRF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sph\u00e4rent\u00f6ne hell vereinen.", "tokens": ["Die", "Sph\u00e4\u00b7ren\u00b7t\u00f6\u00b7ne", "hell", "ver\u00b7ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "In seiner Wunder ewgem Reich", "tokens": ["In", "sei\u00b7ner", "Wun\u00b7der", "ew\u00b7gem", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist keines seiner Sch\u00f6pfungsworte", "tokens": ["Ist", "kei\u00b7nes", "sei\u00b7ner", "Sch\u00f6p\u00b7fungs\u00b7wor\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und nie ein Ton dem andern gleich", "tokens": ["Und", "nie", "ein", "Ton", "dem", "an\u00b7dern", "gleich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch harmonisch im Akkorde.", "tokens": ["Und", "doch", "har\u00b7mo\u00b7nisch", "im", "Ak\u00b7kor\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.7": {"line.1": {"text": "Willst du ein Intervall verstehn", "tokens": ["Willst", "du", "ein", "In\u00b7ter\u00b7vall", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von deinem Standpunkt aus, der Erde,", "tokens": ["Von", "dei\u00b7nem", "Stand\u00b7punkt", "aus", ",", "der", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "ART", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So mu\u00dft du bittend zu ihm gehn,", "tokens": ["So", "mu\u00dft", "du", "bit\u00b7tend", "zu", "ihm", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob er es dir erlauben werde.", "tokens": ["Ob", "er", "es", "dir", "er\u00b7lau\u00b7ben", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Dann lausche demuthsvoll und still,", "tokens": ["Dann", "lau\u00b7sche", "de\u00b7muths\u00b7voll", "und", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dein ganzes Sein ihm zugewendet,", "tokens": ["Dein", "gan\u00b7zes", "Sein", "ihm", "zu\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis er dein Flehn erh\u00f6ren will", "tokens": ["Bis", "er", "dein", "Flehn", "er\u00b7h\u00f6\u00b7ren", "will"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und einen seiner Boten sendet.", "tokens": ["Und", "ei\u00b7nen", "sei\u00b7ner", "Bo\u00b7ten", "sen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Der nimmt und tr\u00e4gt dich hoch empor,", "tokens": ["Der", "nimmt", "und", "tr\u00e4gt", "dich", "hoch", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo keine Gegenkl\u00e4nge st\u00f6ren,", "tokens": ["Wo", "kei\u00b7ne", "Ge\u00b7gen\u00b7kl\u00e4n\u00b7ge", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und dann wirst du im Weltenchor", "tokens": ["Und", "dann", "wirst", "du", "im", "Wel\u00b7ten\u00b7chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Stimme deines Sternes h\u00f6ren.", "tokens": ["Die", "Stim\u00b7me", "dei\u00b7nes", "Ster\u00b7nes", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich sah dich oft in stiller Nacht.", "tokens": ["Ich", "sah", "dich", "oft", "in", "stil\u00b7ler", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Du nahmst ins Rohr des Himmels Sterne", "tokens": ["Du", "nahmst", "ins", "Rohr", "des", "Him\u00b7mels", "Ster\u00b7ne"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und hast dar\u00fcber nachgedacht,", "tokens": ["Und", "hast", "da\u00b7r\u00fc\u00b7ber", "nach\u00b7ge\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wie man sie wohl ergr\u00fcnden lerne.", "tokens": ["Wie", "man", "sie", "wohl", "er\u00b7gr\u00fcn\u00b7den", "ler\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPER", "ADV", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ists um die K\u00f6rper dir zu thun,", "tokens": ["Ists", "um", "die", "K\u00f6r\u00b7per", "dir", "zu", "thun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So magst du deiner Forschung leben.", "tokens": ["So", "magst", "du", "dei\u00b7ner", "For\u00b7schung", "le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Wissenschaft darf nimmer ruhn;", "tokens": ["Die", "Wis\u00b7sen\u00b7schaft", "darf", "nim\u00b7mer", "ruhn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es ist ihr Schweres aufgegeben.", "tokens": ["Es", "ist", "ihr", "Schwe\u00b7res", "auf\u00b7ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Doch weiter, weiter trachte nicht;", "tokens": ["Doch", "wei\u00b7ter", ",", "wei\u00b7ter", "trach\u00b7te", "nicht", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ADV", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Allmacht l\u00e4\u00dft sich nicht bestehlen.", "tokens": ["Die", "All\u00b7macht", "l\u00e4\u00dft", "sich", "nicht", "be\u00b7steh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Gott gab den Sternen zwar das Licht,", "tokens": ["Gott", "gab", "den", "Ster\u00b7nen", "zwar", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sie zu ergr\u00fcnden, wird dirs fehlen.", "tokens": ["Sie", "zu", "er\u00b7gr\u00fcn\u00b7den", ",", "wird", "dirs", "feh\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PTKZU", "VVINF", "$,", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Der Weg zum rechten, wahren Schaun", "tokens": ["Der", "Weg", "zum", "rech\u00b7ten", ",", "wah\u00b7ren", "Schaun"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "APPRART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Steigt nicht empor auf Prismenstrahlen.", "tokens": ["Steigt", "nicht", "em\u00b7por", "auf", "Pris\u00b7mens\u00b7trah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PTKVZ", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ist da Andres aufzubaun", "tokens": ["Es", "ist", "da", "And\u00b7res", "auf\u00b7zu\u00b7baun"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Logarithmen-Dezimalen.", "tokens": ["Als", "Lo\u00b7ga\u00b7rith\u00b7men\u00b7De\u00b7zi\u00b7ma\u00b7len", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Den gro\u00dfen Weltzusammenhang", "tokens": ["Den", "gro\u00b7\u00dfen", "Welt\u00b7zu\u00b7sam\u00b7men\u00b7hang"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Regiert allein die Hand des Einen,", "tokens": ["Re\u00b7giert", "al\u00b7lein", "die", "Hand", "des", "Ei\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Durch die sich wie ein Lobgesang", "tokens": ["Durch", "die", "sich", "wie", "ein", "Lob\u00b7ge\u00b7sang"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PRF", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Sph\u00e4rent\u00f6ne hell vereinen.", "tokens": ["Die", "Sph\u00e4\u00b7ren\u00b7t\u00f6\u00b7ne", "hell", "ver\u00b7ei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "In seiner Wunder ewgem Reich", "tokens": ["In", "sei\u00b7ner", "Wun\u00b7der", "ew\u00b7gem", "Reich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist keines seiner Sch\u00f6pfungsworte", "tokens": ["Ist", "kei\u00b7nes", "sei\u00b7ner", "Sch\u00f6p\u00b7fungs\u00b7wor\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und nie ein Ton dem andern gleich", "tokens": ["Und", "nie", "ein", "Ton", "dem", "an\u00b7dern", "gleich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "ART", "ADJA", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und doch harmonisch im Akkorde.", "tokens": ["Und", "doch", "har\u00b7mo\u00b7nisch", "im", "Ak\u00b7kor\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPRART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.16": {"line.1": {"text": "Willst du ein Intervall verstehn", "tokens": ["Willst", "du", "ein", "In\u00b7ter\u00b7vall", "ver\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ART", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von deinem Standpunkt aus, der Erde,", "tokens": ["Von", "dei\u00b7nem", "Stand\u00b7punkt", "aus", ",", "der", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,", "ART", "NN", "$,"], "meter": "-+-++--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "So mu\u00dft du bittend zu ihm gehn,", "tokens": ["So", "mu\u00dft", "du", "bit\u00b7tend", "zu", "ihm", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ob er es dir erlauben werde.", "tokens": ["Ob", "er", "es", "dir", "er\u00b7lau\u00b7ben", "wer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Dann lausche demuthsvoll und still,", "tokens": ["Dann", "lau\u00b7sche", "de\u00b7muths\u00b7voll", "und", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dein ganzes Sein ihm zugewendet,", "tokens": ["Dein", "gan\u00b7zes", "Sein", "ihm", "zu\u00b7ge\u00b7wen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Bis er dein Flehn erh\u00f6ren will", "tokens": ["Bis", "er", "dein", "Flehn", "er\u00b7h\u00f6\u00b7ren", "will"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und einen seiner Boten sendet.", "tokens": ["Und", "ei\u00b7nen", "sei\u00b7ner", "Bo\u00b7ten", "sen\u00b7det", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Der nimmt und tr\u00e4gt dich hoch empor,", "tokens": ["Der", "nimmt", "und", "tr\u00e4gt", "dich", "hoch", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wo keine Gegenkl\u00e4nge st\u00f6ren,", "tokens": ["Wo", "kei\u00b7ne", "Ge\u00b7gen\u00b7kl\u00e4n\u00b7ge", "st\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und dann wirst du im Weltenchor", "tokens": ["Und", "dann", "wirst", "du", "im", "Wel\u00b7ten\u00b7chor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Stimme deines Sternes h\u00f6ren.", "tokens": ["Die", "Stim\u00b7me", "dei\u00b7nes", "Ster\u00b7nes", "h\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}