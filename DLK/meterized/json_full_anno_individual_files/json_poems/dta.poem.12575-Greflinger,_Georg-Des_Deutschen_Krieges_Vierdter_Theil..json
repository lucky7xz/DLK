{"dta.poem.12575": {"metadata": {"author": {"name": "Greflinger, Georg", "birth": "N.A.", "death": "N.A."}, "title": "Des  \n Deutschen Krieges  \n Vierdter Theil.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1657", "urn": "urn:nbn:de:kobv:b4-200905199036", "language": ["de:0.99"], "booktitle": "Celadon von der Donau [i. e. Greflinger, Georg]: Der Deutschen Drey\u00dfig-J\u00e4hriger Krjeg. [s. l.], 1657."}, "poem": {"stanza.1": {"line.1": {"text": "Eh aber Magdeburg zu solchem Blut und Bran-\nde/", "tokens": ["Eh", "a\u00b7ber", "Mag\u00b7de\u00b7burg", "zu", "sol\u00b7chem", "Blut", "und", "Bran", "de", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NE", "APPR", "PIAT", "NN", "KON", "TRUNC", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Zu solcher Schand und Schmach/ zu solchem Jam-", "tokens": ["Zu", "sol\u00b7cher", "Schand", "und", "Schmach", "/", "zu", "sol\u00b7chem", "Jam"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "NN", "$(", "APPR", "PIAT", "TRUNC"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Als kaum in einer Schrifft von Brand und Blut bekannt/", "tokens": ["Als", "kaum", "in", "ei\u00b7ner", "Schrifft", "von", "Brand", "und", "Blut", "be\u00b7kannt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "(gOtt tr\u00f6ste) kommen war/ war K\u00e4yser Ferdinand", "tokens": ["(", "gOtt", "tr\u00f6s\u00b7te", ")", "kom\u00b7men", "war", "/", "war", "K\u00e4y\u00b7ser", "Fer\u00b7di\u00b7nand"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "FM.la", "FM.la", "$(", "VVINF", "VAFIN", "$(", "VAFIN", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wie auch das gantze Reich/ die jenen au\u00dfgenommen", "tokens": ["Wie", "auch", "das", "gant\u00b7ze", "Reich", "/", "die", "je\u00b7nen", "au\u00df\u00b7ge\u00b7nom\u00b7men"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "ADJA", "NN", "$(", "ART", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Evangelisch sind/ gen Regenspurg gekommen/", "tokens": ["Die", "E\u00b7van\u00b7ge\u00b7lisch", "sind", "/", "gen", "Re\u00b7gen\u00b7spurg", "ge\u00b7kom\u00b7men", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zu rathen/ auf was Art die Lutherische Lehr", "tokens": ["Zu", "ra\u00b7then", "/", "auf", "was", "Art", "die", "Lu\u00b7the\u00b7ri\u00b7sche", "Lehr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "APPR", "PRELS", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "und dero Josua mit seinem tapfren Heer", "tokens": ["und", "de\u00b7ro", "Jo\u00b7sua", "mit", "sei\u00b7nem", "tapf\u00b7ren", "Heer"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "NE", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.9": {"text": "Zu d\u00e4mpfen (dann sie war dem Pabste viel vergiffter", "tokens": ["Zu", "d\u00e4mp\u00b7fen", "(", "dann", "sie", "war", "dem", "Pabs\u00b7te", "viel", "ver\u00b7giff\u00b7ter"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "ADV", "PPER", "VAFIN", "ART", "NN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Als Saracenen Gifft) auch die begehrten Stiffter", "tokens": ["Als", "Sa\u00b7ra\u00b7ce\u00b7nen", "Gifft", ")", "auch", "die", "be\u00b7gehr\u00b7ten", "Stiff\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "NN", "$(", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Zu kriegen m\u00f6chten seyn. Mit Augspurg wars gethan/", "tokens": ["Zu", "krie\u00b7gen", "m\u00f6ch\u00b7ten", "seyn", ".", "Mit", "Augs\u00b7purg", "wars", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VMFIN", "VAINF", "$.", "APPR", "NN", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Mit der ber\u00fchmten Stadt. Nun solten mehr daran.", "tokens": ["Mit", "der", "be\u00b7r\u00fchm\u00b7ten", "Stadt", ".", "Nun", "sol\u00b7ten", "mehr", "da\u00b7ran", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "ADV", "VMFIN", "ADV", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Als nun die anderen/ die solches solten f\u00fchlen/", "tokens": ["Als", "nun", "die", "an\u00b7de\u00b7ren", "/", "die", "sol\u00b7ches", "sol\u00b7ten", "f\u00fch\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "$(", "ART", "PIS", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vermerckten/ wie der Pabst mit jhnen wolte spielen/", "tokens": ["Ver\u00b7merck\u00b7ten", "/", "wie", "der", "Pabst", "mit", "jh\u00b7nen", "wol\u00b7te", "spie\u00b7len", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "KOKOM", "ART", "NN", "APPR", "PPER", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Versamleten sie sich gen Leipzig/ hielten Raht", "tokens": ["Ver\u00b7sam\u00b7le\u00b7ten", "sie", "sich", "gen", "Leip\u00b7zig", "/", "hiel\u00b7ten", "Raht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PPER", "PRF", "APPR", "NE", "$(", "VVFIN", "NN"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.16": {"text": "Was hier zu machen w\u00e4r\u2019. Es war nunmehr zu spat", "tokens": ["Was", "hier", "zu", "ma\u00b7chen", "w\u00e4r'", ".", "Es", "war", "nun\u00b7mehr", "zu", "spat"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "PTKZU", "VVINF", "VAFIN", "$.", "PPER", "VAFIN", "ADV", "APPR", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Mit Federn viel zu thun/ man muste zu den Waffen", "tokens": ["Mit", "Fe\u00b7dern", "viel", "zu", "thun", "/", "man", "mus\u00b7te", "zu", "den", "Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "PTKZU", "VVINF", "$(", "PIS", "VMFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "und mit gesamter Hand der Freyheit Schutz verschaffen.", "tokens": ["und", "mit", "ge\u00b7sam\u00b7ter", "Hand", "der", "Frey\u00b7heit", "Schutz", "ver\u00b7schaf\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Es kam dem K\u00e4yser vor/ der bald daewider schrieb.", "tokens": ["Es", "kam", "dem", "K\u00e4y\u00b7ser", "vor", "/", "der", "bald", "dae\u00b7wi\u00b7der", "schrieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$(", "ART", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Weil aber jederman bey seiner Meynung blieb/", "tokens": ["Weil", "a\u00b7ber", "je\u00b7der\u00b7man", "bey", "sei\u00b7ner", "Mey\u00b7nung", "blieb", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Der an der Forderung/ die-am- gar-nichts-zu-geben/", "tokens": ["Der", "an", "der", "For\u00b7de\u00b7rung", "/", "die\u00b7am", "ga\u00b7rnichts\u00b7zu\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "$(", "TRUNC", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Als sah man \u00fcberall die Lantzen hoch erheben.", "tokens": ["Als", "sah", "man", "\u00fc\u00b7be\u00b7rall", "die", "Lant\u00b7zen", "hoch", "er\u00b7he\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PIS", "ADV", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Chur Sachsen h\u00e4uffte Volck/ Chur Brandenburg nahm an/", "tokens": ["Chur", "Sach\u00b7sen", "h\u00e4uff\u00b7te", "Volck", "/", "Chur", "Bran\u00b7den\u00b7burg", "nahm", "an", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$(", "NE", "NE", "VVFIN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zur Folge sammlete bey achtmal tausend Mann", "tokens": ["Zur", "Fol\u00b7ge", "samm\u00b7le\u00b7te", "bey", "acht\u00b7mal", "tau\u00b7send", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "APPR", "ADV", "CARD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Der tapfre Weymar-F\u00fcrst Bernhardus f\u00fcr die Hessen/", "tokens": ["Der", "tapf\u00b7re", "Wey\u00b7ma\u00b7rF\u00fcrst", "Bern\u00b7har\u00b7dus", "f\u00fcr", "die", "Hes\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Auch andre wolten sich in diesem nicht vergessen.", "tokens": ["Auch", "and\u00b7re", "wol\u00b7ten", "sich", "in", "die\u00b7sem", "nicht", "ver\u00b7ges\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VMFIN", "PRF", "APPR", "PDAT", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Als K\u00e4yser Ferdinand dergleichen R\u00fcstung sah", "tokens": ["Als", "K\u00e4y\u00b7ser", "Fer\u00b7di\u00b7nand", "derg\u00b7lei\u00b7chen", "R\u00fcs\u00b7tung", "sah"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "NE", "PIS", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Gieng/ wie man sch\u00e4tzen kan/ jhm das nicht wenig nah.", "tokens": ["Gieng", "/", "wie", "man", "sch\u00e4t\u00b7zen", "kan", "/", "jhm", "das", "nicht", "we\u00b7nig", "nah", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAV", "PIS", "VVINF", "VMFIN", "$(", "PPER", "PDS", "PTKNEG", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Er schrieb/ vermahnte/ trieb/ und doch war kein Geh\u00f6re/", "tokens": ["Er", "schrieb", "/", "ver\u00b7mahn\u00b7te", "/", "trieb", "/", "und", "doch", "war", "kein", "Ge\u00b7h\u00f6\u00b7re", "/"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "VVFIN", "$(", "VVFIN", "$(", "KON", "ADV", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Hierauf begab er sich sehr starck zur Gegenwehre/", "tokens": ["Hier\u00b7auf", "be\u00b7gab", "er", "sich", "sehr", "starck", "zur", "Ge\u00b7gen\u00b7weh\u00b7re", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Des Gegentheils Gewalt gewaltig abzuthun/", "tokens": ["Des", "Ge\u00b7gen\u00b7theils", "Ge\u00b7walt", "ge\u00b7wal\u00b7tig", "ab\u00b7zu\u00b7thun", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADJD", "VVIZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Worzu jhm Magdeburgs-Eroberung/ die nun", "tokens": ["Wor\u00b7zu", "jhm", "Mag\u00b7de\u00b7burgs\u00b7Erobe\u00b7rung", "/", "die", "nun"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PPER", "NN", "$(", "PRELS", "ADV"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.33": {"text": "Jm Blut und Asche lag/ nicht wenig Hertzens machte.", "tokens": ["Jm", "Blut", "und", "A\u00b7sche", "lag", "/", "nicht", "we\u00b7nig", "Hert\u00b7zens", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KON", "NN", "VVFIN", "$(", "PTKNEG", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Es gieng auch wie es jhm des K\u00e4ysers Hertz gedachte", "tokens": ["Es", "gieng", "auch", "wie", "es", "jhm", "des", "K\u00e4y\u00b7sers", "Hertz", "ge\u00b7dach\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "PPER", "PPER", "ART", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Bey vielen gl\u00fccklich an. Dann da kam F\u00fcrstenberg", "tokens": ["Bey", "vie\u00b7len", "gl\u00fcck\u00b7lich", "an", ".", "Dann", "da", "kam", "F\u00fcrs\u00b7ten\u00b7berg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJD", "PTKVZ", "$.", "ADV", "ADV", "VVFIN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "und bracht aus W\u00e4lischland nicht eine schlechte St\u00e4rck", "tokens": ["und", "bracht", "aus", "W\u00e4\u00b7li\u00b7schland", "nicht", "ei\u00b7ne", "schlech\u00b7te", "St\u00e4rck"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "An wolversuchtem Volck auf W\u00fcrtenberg und Schwaben/", "tokens": ["An", "wol\u00b7ver\u00b7such\u00b7tem", "Volck", "auf", "W\u00fcr\u00b7ten\u00b7berg", "und", "Schwa\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NE", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "und zwung sie unges\u00e4umt/ da\u00df sie den Bund begaben/", "tokens": ["und", "zwung", "sie", "un\u00b7ge\u00b7s\u00e4umt", "/", "da\u00df", "sie", "den", "Bund", "be\u00b7ga\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPER", "ADJD", "$(", "KOUS", "PPER", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.39": {"text": "und jhr geworben Volck erliessen. Di\u00df gethan/", "tokens": ["und", "jhr", "ge\u00b7wor\u00b7ben", "Volck", "er\u00b7lies\u00b7sen", ".", "Di\u00df", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$.", "PDS", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Kam er mit seiner Macht im Lande Francken an/", "tokens": ["Kam", "er", "mit", "sei\u00b7ner", "Macht", "im", "Lan\u00b7de", "Fran\u00b7cken", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "PPOSAT", "NN", "APPRART", "NN", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "und stillet\u2019 auch daselbst was sich im Bunde fundte/", "tokens": ["und", "stil\u00b7let'", "auch", "da\u00b7selbst", "was", "sich", "im", "Bun\u00b7de", "fund\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "PRELS", "PRF", "APPRART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "Da\u00df also dieses Orts sich nichts emp\u00f6ren kundte.", "tokens": ["Da\u00df", "al\u00b7so", "die\u00b7ses", "Orts", "sich", "nichts", "em\u00b7p\u00f6\u00b7ren", "kund\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDAT", "NN", "PRF", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Hierauf begab er sich zum Tylli/ der schon lang", "tokens": ["Hier\u00b7auf", "be\u00b7gab", "er", "sich", "zum", "Tyl\u00b7li", "/", "der", "schon", "lang"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "APPRART", "NE", "$(", "ART", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Von Wien beordert war/ Chur Sachsen in den Zwang", "tokens": ["Von", "Wi\u00b7en", "be\u00b7or\u00b7dert", "war", "/", "Chur", "Sach\u00b7sen", "in", "den", "Zwang"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "$(", "NE", "NE", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "und Hessen in den Sturtz mit seiner Macht zu bringen/", "tokens": ["und", "Hes\u00b7sen", "in", "den", "Sturtz", "mit", "sei\u00b7ner", "Macht", "zu", "brin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.46": {"text": "Weil sie die Feder nicht vermochte zu bezwingen", "tokens": ["Weil", "sie", "die", "Fe\u00b7der", "nicht", "ver\u00b7moch\u00b7te", "zu", "be\u00b7zwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVFIN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "So solt\u2019 es Tylli thun/ dann diesem war getrant", "tokens": ["So", "solt'", "es", "Tyl\u00b7li", "thun", "/", "dann", "die\u00b7sem", "war", "ge\u00b7trant"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "NE", "VVINF", "$(", "ADV", "PDS", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "Da\u00df er nicht f\u00e4hlen k\u00f6nnt. Er hat auch seine Haut", "tokens": ["Da\u00df", "er", "nicht", "f\u00e4h\u00b7len", "k\u00f6nnt", ".", "Er", "hat", "auch", "sei\u00b7ne", "Haut"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "VVINF", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Gewaltig angesetzt/ und gro\u00dfe Sieg\u2019 erworben/", "tokens": ["Ge\u00b7wal\u00b7tig", "an\u00b7ge\u00b7setzt", "/", "und", "gro\u00b7\u00dfe", "Sieg'", "er\u00b7wor\u00b7ben", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVPP", "$(", "KON", "ADJA", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.50": {"text": "Nun aber war sein Gl\u00fcck mit Magdeburg gestorben.", "tokens": ["Nun", "a\u00b7ber", "war", "sein", "Gl\u00fcck", "mit", "Mag\u00b7de\u00b7burg", "ge\u00b7stor\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "PPOSAT", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Dann bald darauf gerieth sein Lager in den Brand/", "tokens": ["Dann", "bald", "da\u00b7rauf", "ge\u00b7rieth", "sein", "La\u00b7ger", "in", "den", "Brand", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PAV", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "und niemand wuste wie. Wodurch so manches Band/", "tokens": ["und", "nie\u00b7mand", "wus\u00b7te", "wie", ".", "Wo\u00b7durch", "so", "man\u00b7ches", "Band", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "KOKOM", "$.", "PWAV", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Das viel aus Magdeburg beschlo\u00df/ ist aufgegangen/", "tokens": ["Das", "viel", "aus", "Mag\u00b7de\u00b7burg", "be\u00b7schlo\u00df", "/", "ist", "auf\u00b7ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "APPR", "NE", "VVFIN", "$(", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Dann Magdeburg wurd halb erw\u00fcrgt und halb gefangen.", "tokens": ["Dann", "Mag\u00b7de\u00b7burg", "wurd", "halb", "er\u00b7w\u00fcrgt", "und", "halb", "ge\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NE", "VAFIN", "ADJD", "VVPP", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Nach diesem zog er auf und fiel in Hessen ein/", "tokens": ["Nach", "die\u00b7sem", "zog", "er", "auf", "und", "fiel", "in", "Hes\u00b7sen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "APPR", "NE", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.56": {"text": "Was sein verrichten war/ sol dann berichtet seyn/", "tokens": ["Was", "sein", "ver\u00b7rich\u00b7ten", "war", "/", "sol", "dann", "be\u00b7rich\u00b7tet", "seyn", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "ADJA", "VAFIN", "$(", "VMFIN", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.57": {"text": "Wann wir die Schwedischen vorher besuchet haben/", "tokens": ["Wann", "wir", "die", "Schwe\u00b7di\u00b7schen", "vor\u00b7her", "be\u00b7su\u00b7chet", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADV", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.58": {"text": "Die allem Lande nun genug zu schaffen gaben.", "tokens": ["Die", "al\u00b7lem", "Lan\u00b7de", "nun", "ge\u00b7nug", "zu", "schaf\u00b7fen", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "NN", "ADV", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.59": {"text": "Es wurd\u2019 auch dort und da denselben Hilf gethan/", "tokens": ["Es", "wurd'", "auch", "dort", "und", "da", "den\u00b7sel\u00b7ben", "Hilf", "ge\u00b7than", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "KON", "ADV", "PDAT", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.60": {"text": "Da kam Graf Hamilthon mit etlich tausend Mann", "tokens": ["Da", "kam", "Graf", "Ha\u00b7mil\u00b7thon", "mit", "et\u00b7lich", "tau\u00b7send", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "NE", "APPR", "ADJD", "CARD", "NN"], "meter": "-+-++--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.61": {"text": "In vielen Schiffen an aus Engelland geschicket/", "tokens": ["In", "vie\u00b7len", "Schif\u00b7fen", "an", "aus", "En\u00b7gel\u00b7land", "ge\u00b7schi\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "APPR", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.62": {"text": "Er war auch trefflich starck bethalert und best\u00fccket/", "tokens": ["Er", "war", "auch", "treff\u00b7lich", "starck", "be\u00b7tha\u00b7lert", "und", "be\u00b7st\u00fc\u00b7cket", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "ADJD", "VVPP", "KON", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Nechst dem auch Franckreich sich zu gro\u00dfer Hilf erbot", "tokens": ["Nechst", "dem", "auch", "Fran\u00b7ck\u00b7reich", "sich", "zu", "gro\u00b7\u00dfer", "Hilf", "er\u00b7bot"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "NE", "PRF", "APPR", "ADJA", "NN", "VVFIN"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.64": {"text": "Mit Volck und anderm mehr/ das der Soldaten Noth", "tokens": ["Mit", "Volck", "und", "an\u00b7derm", "mehr", "/", "das", "der", "Sol\u00b7da\u00b7ten", "Noth"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "PIS", "ADV", "$(", "PRELS", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.65": {"text": "In eine Freude kehrt. Des Geldes war kein schonen/", "tokens": ["In", "ei\u00b7ne", "Freu\u00b7de", "kehrt", ".", "Des", "Gel\u00b7des", "war", "kein", "scho\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$.", "ART", "NN", "VAFIN", "PIAT", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Es kam zu Tonnen an/ und auch zu Millionen/", "tokens": ["Es", "kam", "zu", "Ton\u00b7nen", "an", "/", "und", "auch", "zu", "Mil\u00b7lion\u00b7en", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "PTKVZ", "$(", "KON", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.67": {"text": "Dann Geldt erh\u00e4lt den Krieg. De\u00dfgleichen that der Zaar", "tokens": ["Dann", "Geldt", "er\u00b7h\u00e4lt", "den", "Krieg", ".", "De\u00df\u00b7glei\u00b7chen", "that", "der", "Zaar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "ART", "NN", "$.", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.68": {"text": "Aus Mo\u00dfkow/ der nunmehr mit Schweden einig war/", "tokens": ["Aus", "Mo\u00df\u00b7kow", "/", "der", "nun\u00b7mehr", "mit", "Schwe\u00b7den", "ei\u00b7nig", "war", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$(", "ART", "ADV", "APPR", "NE", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.69": {"text": "Entbote Volck und Korn/ durch einen seiner Gro\u00dfen", "tokens": ["Ent\u00b7bo\u00b7te", "Volck", "und", "Korn", "/", "durch", "ei\u00b7nen", "sei\u00b7ner", "Gro\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN", "$(", "APPR", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.70": {"text": "Aus F\u00fcrstlichem Geschlecht iu seinem Reich entspro\u00dfen/", "tokens": ["Aus", "F\u00fcrst\u00b7li\u00b7chem", "Ge\u00b7schlecht", "i\u00b7u", "sei\u00b7nem", "Reich", "ent\u00b7spro\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "NE", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.71": {"text": "Der gro\u00df nach jhrer Art von Pracht in Pommern kam/", "tokens": ["Der", "gro\u00df", "nach", "jhrer", "Art", "von", "Pracht", "in", "Pom\u00b7mern", "kam", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "APPR", "PPOSAT", "NN", "APPR", "NN", "APPR", "NE", "VVFIN", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.72": {"text": "Den der Stettiner Volck mit grosser Ehr\u2019 annahm.", "tokens": ["Den", "der", "Stet\u00b7ti\u00b7ner", "Volck", "mit", "gros\u00b7ser", "Ehr'", "an\u00b7nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.73": {"text": "Der K\u00f6nig kam auch selbst dahin jhn zu empfangen/", "tokens": ["Der", "K\u00f6\u00b7nig", "kam", "auch", "selbst", "da\u00b7hin", "jhn", "zu", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "PAV", "PPER", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.74": {"text": "Wobey es trefflich hoch von Pracht ist zugegangen.", "tokens": ["Wo\u00b7bey", "es", "treff\u00b7lich", "hoch", "von", "Pracht", "ist", "zu\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "ADJD", "APPR", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.75": {"text": "Der K\u00f6nig h\u00f6rete was sein Verrichten war", "tokens": ["Der", "K\u00f6\u00b7nig", "h\u00f6\u00b7re\u00b7te", "was", "sein", "Ver\u00b7rich\u00b7ten", "war"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PIS", "PPOSAT", "NN", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "In freyen Feldern an/ vernehmend/ was der Zaar", "tokens": ["In", "frey\u00b7en", "Fel\u00b7dern", "an", "/", "ver\u00b7neh\u00b7mend", "/", "was", "der", "Zaar"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$(", "VVPP", "$(", "PWS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.77": {"text": "Aus Moskow s\u00e4gen lie\u00df/ bedanckt er dessen Willen/", "tokens": ["Aus", "Mos\u00b7kow", "s\u00e4\u00b7gen", "lie\u00df", "/", "be\u00b7danckt", "er", "des\u00b7sen", "Wil\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVINF", "VVFIN", "$(", "VVFIN", "PPER", "PDS", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "und wolte Deutschland nicht mit solchem Volck\u2019 anf\u00fcllen", "tokens": ["und", "wol\u00b7te", "Deutschland", "nicht", "mit", "sol\u00b7chem", "Volck'", "an\u00b7f\u00fcl\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "NE", "PTKNEG", "APPR", "PIAT", "NN", "VVINF"], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.79": {"text": "Das seines Glaubens Feind. Es war wol andrer Raht", "tokens": ["Das", "sei\u00b7nes", "Glau\u00b7bens", "Feind", ".", "Es", "war", "wol", "an\u00b7drer", "Raht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "PPOSAT", "NN", "NN", "$.", "PPER", "VAFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.80": {"text": "Wann Volck gebrechen solt\u2019/ als man auch in der That", "tokens": ["Wann", "Volck", "ge\u00b7bre\u00b7chen", "solt'", "/", "als", "man", "auch", "in", "der", "That"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NN", "VVINF", "VMFIN", "$(", "KOUS", "PIS", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.81": {"text": "Hernach gesehen hat. In dem der kluge K\u00f6nig", "tokens": ["Her\u00b7nach", "ge\u00b7se\u00b7hen", "hat", ".", "In", "dem", "der", "klu\u00b7ge", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVPP", "VAFIN", "$.", "APPR", "ART", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Dem Russen Antwort gab und \u00fcber das nicht wenig", "tokens": ["Dem", "Rus\u00b7sen", "Ant\u00b7wort", "gab", "und", "\u00fc\u00b7ber", "das", "nicht", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "APPR", "PRELS", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.83": {"text": "Jhm Lust und Ehr\u2019 anthat/ nahm Baudis Werben ein/", "tokens": ["Jhm", "Lust", "und", "Ehr'", "an\u00b7that", "/", "nahm", "Bau\u00b7dis", "Wer\u00b7ben", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVFIN", "$(", "VVFIN", "NE", "VAFIN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.84": {"text": "Woselbst viel Tyllische verw\u00e4llt gewesen seyn.", "tokens": ["Wo\u00b7selbst", "viel", "Tyl\u00b7li\u00b7sche", "ver\u00b7w\u00e4llt", "ge\u00b7we\u00b7sen", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "VVPP", "VAPP", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.85": {"text": "Viel wurden fest gemacht/ die meisten musten sterben/", "tokens": ["Viel", "wur\u00b7den", "fest", "ge\u00b7macht", "/", "die", "meis\u00b7ten", "mus\u00b7ten", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "VVPP", "$(", "ART", "PIS", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.86": {"text": "Als es im Kriege geht. Als Baudis di\u00df mit Werben", "tokens": ["Als", "es", "im", "Krie\u00b7ge", "geht", ".", "Als", "Bau\u00b7dis", "di\u00df", "mit", "Wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$.", "KOUS", "NE", "PDS", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.87": {"text": "Beging/ fiel Banners Volck den Dohm zur Havel an/", "tokens": ["Be\u00b7ging", "/", "fiel", "Ban\u00b7ners", "Volck", "den", "Dohm", "zur", "Ha\u00b7vel", "an", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "VVFIN", "NE", "NN", "ART", "NN", "APPRART", "NE", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Gewann jhn und erschlug auch etlich hundert Mann", "tokens": ["Ge\u00b7wann", "jhn", "und", "er\u00b7schlug", "auch", "et\u00b7lich", "hun\u00b7dert", "Mann"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "KON", "VVFIN", "ADV", "ADJD", "CARD", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.89": {"text": "Jm St\u00e4dtlein Havelberg/ (ein wolverwahrtes Wesen/", "tokens": ["Jm", "St\u00e4dt\u00b7lein", "Ha\u00b7vel\u00b7berg", "/", "(", "ein", "wol\u00b7ver\u00b7wahr\u00b7tes", "We\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$(", "$(", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.90": {"text": "Ist jetzo sehr verschw\u00e4cht/ und wird nicht bald genesen.)", "tokens": ["Ist", "jet\u00b7zo", "sehr", "ver\u00b7schw\u00e4cht", "/", "und", "wird", "nicht", "bald", "ge\u00b7ne\u00b7sen", ".", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$(", "KON", "VAFIN", "PTKNEG", "ADV", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Hierauf gieng Banner selbst zum festen Platz Gripswald/", "tokens": ["Hier\u00b7auf", "gieng", "Ban\u00b7ner", "selbst", "zum", "fes\u00b7ten", "Platz", "Grips\u00b7wald", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "NN", "ADV", "APPRART", "ADJA", "NN", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "(di\u00df war der K\u00e4ysrischen jhr letzter Aufenthalt", "tokens": ["(", "di\u00df", "war", "der", "K\u00e4y\u00b7sri\u00b7schen", "jhr", "letz\u00b7ter", "Auf\u00b7ent\u00b7halt"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "PDS", "VAFIN", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.93": {"text": "Durch alles Pommerland) begehrt es aufzugeben.", "tokens": ["Durch", "al\u00b7les", "Pom\u00b7mer\u00b7land", ")", "be\u00b7gehrt", "es", "auf\u00b7zu\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$(", "VVPP", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Perusi/ der es hielt/ begehrte da sein Leben", "tokens": ["Pe\u00b7ru\u00b7si", "/", "der", "es", "hielt", "/", "be\u00b7gehr\u00b7te", "da", "sein", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$(", "PRELS", "PPER", "VVFIN", "$(", "ADJA", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.95": {"text": "Zu enden/ oder dann den wolverschantzten Ort", "tokens": ["Zu", "en\u00b7den", "/", "o\u00b7der", "dann", "den", "wol\u00b7ver\u00b7schantz\u00b7ten", "Ort"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$(", "KON", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.96": {"text": "Zu halten. Di\u00df gesagt/ fuhr Banner etwas fort", "tokens": ["Zu", "hal\u00b7ten", ".", "Di\u00df", "ge\u00b7sagt", "/", "fuhr", "Ban\u00b7ner", "et\u00b7was", "fort"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "PDS", "VVPP", "$(", "VVFIN", "NN", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Jhn mit Gesch\u00fctze/ Schwerdt und Brand heraus zu treiben.", "tokens": ["Jhn", "mit", "Ge\u00b7sch\u00fct\u00b7ze", "/", "Schwerdt", "und", "Brand", "he\u00b7raus", "zu", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "$(", "NE", "KON", "NN", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.98": {"text": "Perusi/ dessen Hertz hier Lebenslang zu bleiben", "tokens": ["Pe\u00b7ru\u00b7si", "/", "des\u00b7sen", "Hertz", "hier", "Le\u00b7bens\u00b7lang", "zu", "blei\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$(", "PRELAT", "NN", "ADV", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.99": {"text": "Vielleicht gewillet war/ besch\u00fctzete die Stadt/", "tokens": ["Viel\u00b7leicht", "ge\u00b7wil\u00b7let", "war", "/", "be\u00b7sch\u00fct\u00b7ze\u00b7te", "die", "Stadt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "$(", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.100": {"text": "Wie sichs geziemet/ als ein Ritter und Soldat/", "tokens": ["Wie", "sichs", "ge\u00b7zie\u00b7met", "/", "als", "ein", "Rit\u00b7ter", "und", "Sol\u00b7dat", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVPP", "$(", "KOUS", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Wie er dann beydes war. Man lebe was zu loben.", "tokens": ["Wie", "er", "dann", "bey\u00b7des", "war", ".", "Man", "le\u00b7be", "was", "zu", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PIS", "VAFIN", "$.", "PIS", "VVFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.102": {"text": "Es trug sich aber zu/ da\u00df dieser Held von oben", "tokens": ["Es", "trug", "sich", "a\u00b7ber", "zu", "/", "da\u00df", "die\u00b7ser", "Held", "von", "o\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKZU", "$(", "KOUS", "PDAT", "NN", "APPR", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.103": {"text": "Ein Schwedisch H\u00e4uflein sah/ das seiner Mauern Vieh", "tokens": ["Ein", "Schwe\u00b7disch", "H\u00e4uf\u00b7lein", "sah", "/", "das", "sei\u00b7ner", "Mau\u00b7ern", "Vieh"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "$(", "PDS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.104": {"text": "Zu nehmen kommen war/ da fiel er unter sie/", "tokens": ["Zu", "neh\u00b7men", "kom\u00b7men", "war", "/", "da", "fiel", "er", "un\u00b7ter", "sie", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVINF", "VAFIN", "$(", "ADV", "VVFIN", "PPER", "APPR", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.105": {"text": "Wust\u2019 aber nicht davon da\u00df in dem Grund\u2019 und B\u00fcschen/", "tokens": ["Wust'", "a\u00b7ber", "nicht", "da\u00b7von", "da\u00df", "in", "dem", "Grund'", "und", "B\u00fc\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKNEG", "PAV", "KOUS", "APPR", "ART", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.106": {"text": "Ein gro\u00dfer Hauffe war/ auf jhn herf\u00fcr zu wischen", "tokens": ["Ein", "gro\u00b7\u00dfer", "Hauf\u00b7fe", "war", "/", "auf", "jhn", "her\u00b7f\u00fcr", "zu", "wi\u00b7schen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$(", "APPR", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.107": {"text": "Wann er die andern trieb. Eh\u2019 als er sichs versah/", "tokens": ["Wann", "er", "die", "an\u00b7dern", "trieb", ".", "Eh'", "als", "er", "sichs", "ver\u00b7sah", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "VVFIN", "$.", "NN", "KOUS", "PPER", "PIS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "War rings um ihn herum ein gro\u00dfer Hauffen da/", "tokens": ["War", "rings", "um", "ihn", "he\u00b7rum", "ein", "gro\u00b7\u00dfer", "Hauf\u00b7fen", "da", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PPER", "APZR", "ART", "ADJA", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.109": {"text": "Die ihm den Pa\u00df zu r\u00fcck und auch das Leben nahmen/", "tokens": ["Die", "ihm", "den", "Pa\u00df", "zu", "r\u00fcck", "und", "auch", "das", "Le\u00b7ben", "nah\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "PTKZU", "PTKVZ", "KON", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Worauf sie bald hernach auch in die Vestung kahmen/", "tokens": ["Wo\u00b7rauf", "sie", "bald", "her\u00b7nach", "auch", "in", "die", "Ves\u00b7tung", "kah\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "ADV", "ADV", "ADV", "APPR", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.111": {"text": "Damit war Pommern frey. In dem es war gethan", "tokens": ["Da\u00b7mit", "war", "Pom\u00b7mern", "frey", ".", "In", "dem", "es", "war", "ge\u00b7than"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "NN", "PTKVZ", "$.", "APPR", "PRELS", "PPER", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.112": {"text": "Kam der Gustavus selbst/ in Meynung/ diesen Plan", "tokens": ["Kam", "der", "Gus\u00b7ta\u00b7vus", "selbst", "/", "in", "Mey\u00b7nung", "/", "die\u00b7sen", "Plan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NE", "ART", "NN", "ADV", "$(", "APPR", "NN", "$(", "PDAT", "NN"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.113": {"text": "Zu st\u00fcrmen. Als er sah/ da\u00df solcher seinen Leuthen", "tokens": ["Zu", "st\u00fcr\u00b7men", ".", "Als", "er", "sah", "/", "da\u00df", "sol\u00b7cher", "sei\u00b7nen", "Leu\u00b7then"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "KOUS", "PPER", "VVFIN", "$(", "KOUS", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.114": {"text": "Schon in den H\u00e4nden war/ belobt\u2019 er solcher streiten", "tokens": ["Schon", "in", "den", "H\u00e4n\u00b7den", "war", "/", "be\u00b7lobt'", "er", "sol\u00b7cher", "strei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN", "VAFIN", "$(", "VVFIN", "PPER", "PIAT", "ADJA"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.115": {"text": "Sehr K\u00f6niglich/ und gieng darauf nach Gustrau zu/", "tokens": ["Sehr", "K\u00f6\u00b7nig\u00b7lich", "/", "und", "gieng", "da\u00b7rauf", "nach", "Gus\u00b7trau", "zu", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$(", "KON", "VVFIN", "PAV", "APPR", "NN", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.116": {"text": "Die F\u00fcrstenj Mecklenburgs zur alten Ehr und Ruh/", "tokens": ["Die", "F\u00fcrs\u00b7tenj", "Meck\u00b7len\u00b7burgs", "zur", "al\u00b7ten", "Ehr", "und", "Ruh", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "APPRART", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.117": {"text": "Aus jhrem ", "tokens": ["Aus", "jhrem"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "-+", "measure": "iambic.single"}, "line.118": {"text": "Wie es dann auch geschah mit mancherley ergetzen.", "tokens": ["Wie", "es", "dann", "auch", "ge\u00b7schah", "mit", "man\u00b7cher\u00b7ley", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVFIN", "APPR", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.119": {"text": "Dann nun war Mecklenburg fast alles wieder rein", "tokens": ["Dann", "nun", "war", "Meck\u00b7len\u00b7burg", "fast", "al\u00b7les", "wie\u00b7der", "rein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN", "NE", "ADV", "PIS", "ADV", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.120": {"text": "Bi\u00df auf die Wi\u00dfmar-Stadt und Rostock. Die allein", "tokens": ["Bi\u00df", "auf", "die", "Wi\u00df\u00b7ma\u00b7rStadt", "und", "Ros\u00b7tock", ".", "Die", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "APPR", "ART", "NN", "KON", "NN", "$.", "ART", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.121": {"text": "Bezeigten noch Gewalt/ die doch nach wenig Zeiten", "tokens": ["Be\u00b7zeig\u00b7ten", "noch", "Ge\u00b7walt", "/", "die", "doch", "nach", "we\u00b7nig", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "NN", "$(", "PRELS", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Sich auch zerbr\u00e4chen lie\u00df/ dieweil der Schweden Streiten", "tokens": ["Sich", "auch", "zer\u00b7br\u00e4\u00b7chen", "lie\u00df", "/", "die\u00b7weil", "der", "Schwe\u00b7den", "Strei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PRF", "ADV", "VVINF", "VVFIN", "$(", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.123": {"text": "Ein stetes Siegen wurd\u2019. Es bracht auch eben nu", "tokens": ["Ein", "ste\u00b7tes", "Sie\u00b7gen", "wurd'", ".", "Es", "bracht", "auch", "e\u00b7ben", "nu"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$.", "PPER", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.124": {"text": "Des K\u00f6nigs Ehgemal acht tausend Mann herzu/", "tokens": ["Des", "K\u00f6\u00b7nigs", "Eh\u00b7ge\u00b7mal", "acht", "tau\u00b7send", "Mann", "her\u00b7zu", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "CARD", "CARD", "NN", "ADV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.125": {"text": "Wovon vier tausend Mann besagte St\u00e4dt\u2019 umfingen/", "tokens": ["Wo\u00b7von", "vier", "tau\u00b7send", "Mann", "be\u00b7sag\u00b7te", "St\u00e4dt'", "um\u00b7fin\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "CARD", "NN", "ADJA", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Vier tausend aber fort jns K\u00f6nigs Lager giengen/", "tokens": ["Vier", "tau\u00b7send", "a\u00b7ber", "fort", "jns", "K\u00f6\u00b7nigs", "La\u00b7ger", "gien\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "ADV", "PTKVZ", "ADJA", "NN", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Das um alt Brandenburg herum geschlagen war.", "tokens": ["Das", "um", "alt", "Bran\u00b7den\u00b7burg", "he\u00b7rum", "ge\u00b7schla\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADJD", "NE", "APZR", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.128": {"text": "Nach dem der Schweden Held das fromme F\u00fcrsten Paar", "tokens": ["Nach", "dem", "der", "Schwe\u00b7den", "Held", "das", "from\u00b7me", "F\u00fcrs\u00b7ten", "Paar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.129": {"text": "Vom Lande Mecklenburg von neuen hatt\u2019 erfreuet", "tokens": ["Vom", "Lan\u00b7de", "Meck\u00b7len\u00b7burg", "von", "neu\u00b7en", "hatt'", "er\u00b7freu\u00b7et"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "NE", "APPR", "ADJA", "VAFIN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.130": {"text": "und heim gebracht/ darzu jhr Volck/ das wie zerstreuet", "tokens": ["und", "heim", "ge\u00b7bracht", "/", "dar\u00b7zu", "jhr", "Volck", "/", "das", "wie", "zer\u00b7streu\u00b7et"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PTKVZ", "VVPP", "$(", "PAV", "PPOSAT", "NN", "$(", "PDS", "KOKOM", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.131": {"text": "In gro\u00dfer Jrre gieng/ gesamlet/ schied er ab/", "tokens": ["In", "gro\u00b7\u00dfer", "Jr\u00b7re", "gieng", "/", "ge\u00b7sam\u00b7let", "/", "schied", "er", "ab", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$(", "VVPP", "$(", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.132": {"text": "Worauf er alsobald sich nach dem Lager gab/", "tokens": ["Wo\u00b7rauf", "er", "al\u00b7so\u00b7bald", "sich", "nach", "dem", "La\u00b7ger", "gab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "KOUS", "PRF", "APPR", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.133": {"text": "Mit seiner Gegenwart sein Kriegs-Heer zu ergetzen.", "tokens": ["Mit", "sei\u00b7ner", "Ge\u00b7gen\u00b7wart", "sein", "Kriegs\u00b7Heer", "zu", "er\u00b7get\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.134": {"text": "Bald lie\u00df er durch die Elb an Tangerm\u00fcnde setzen/", "tokens": ["Bald", "lie\u00df", "er", "durch", "die", "Elb", "an", "Tan\u00b7ger\u00b7m\u00fcn\u00b7de", "set\u00b7zen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NE", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.135": {"text": "Das bald besieget wurd\u2019 und alles im Gewehr", "tokens": ["Das", "bald", "be\u00b7sie\u00b7get", "wurd'", "und", "al\u00b7les", "im", "Ge\u00b7wehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVPP", "VAFIN", "KON", "PIS", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.136": {"text": "Erw\u00fcrget/ diesem nach nahm er das gantze Heer", "tokens": ["Er\u00b7w\u00fcr\u00b7get", "/", "die\u00b7sem", "nach", "nahm", "er", "das", "gant\u00b7ze", "Heer"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "$(", "PDAT", "APPR", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.137": {"text": "Mit sich nach Werben zu/ hier zwischen zweyen Fl\u00fcssen", "tokens": ["Mit", "sich", "nach", "Wer\u00b7ben", "zu", "/", "hier", "zwi\u00b7schen", "zwe\u00b7yen", "Fl\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PRF", "APPR", "NN", "PTKZU", "$(", "ADV", "VVINF", "VVFIN", "NN"], "meter": "+--+--+--+-+-", "measure": "dactylic.tri.plus"}, "line.138": {"text": "Der Havel und der Elb\u2019 ein Lager zu beschl\u00fcssen/", "tokens": ["Der", "Ha\u00b7vel", "und", "der", "Elb'", "ein", "La\u00b7ger", "zu", "be\u00b7schl\u00fcs\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "KON", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.139": {"text": "Da\u00df auch sehr bald geschah. In dem man dieses that", "tokens": ["Da\u00df", "auch", "sehr", "bald", "ge\u00b7schah", ".", "In", "dem", "man", "die\u00b7ses", "that"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "ADV", "VVFIN", "$.", "APPR", "ART", "PIS", "PDAT", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.140": {"text": "Befiel der tapfre Horn zu Gr\u00fcnberg in der Stadt", "tokens": ["Be\u00b7fiel", "der", "tapf\u00b7re", "Horn", "zu", "Gr\u00fcn\u00b7berg", "in", "der", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.141": {"text": "Achthundert K\u00e4ysrische/ die meisten musten sterben.", "tokens": ["Acht\u00b7hun\u00b7dert", "K\u00e4y\u00b7sri\u00b7sche", "/", "die", "meis\u00b7ten", "mus\u00b7ten", "ster\u00b7ben", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "$(", "ART", "PIS", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.142": {"text": "Wir lassen nun das Heer der Schwedischen zu Werben", "tokens": ["Wir", "las\u00b7sen", "nun", "das", "Heer", "der", "Schwe\u00b7di\u00b7schen", "zu", "Wer\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.143": {"text": "In festen Schantzen stehn/ und gehn dem Tylli zu/", "tokens": ["In", "fes\u00b7ten", "Schant\u00b7zen", "stehn", "/", "und", "gehn", "dem", "Tyl\u00b7li", "zu", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$(", "KON", "VVFIN", "ART", "NE", "PTKZU", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.144": {"text": "Zu sehen was er doch dem Cassel-Hessen thu.", "tokens": ["Zu", "se\u00b7hen", "was", "er", "doch", "dem", "Cas\u00b7sel\u00b7Hes\u00b7sen", "thu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PWS", "PPER", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.145": {"text": "Wirhaben vor gedacht/ da\u00df Hessen/ gleich wie Sachsen/", "tokens": ["Wir\u00b7ha\u00b7ben", "vor", "ge\u00b7dacht", "/", "da\u00df", "Hes\u00b7sen", "/", "gleich", "wie", "Sach\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "VVPP", "$(", "KOUS", "NE", "$(", "ADV", "KOKOM", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.146": {"text": "Cur-Brandenburg und mehr/ der Feinds Gewalt gewach-", "tokens": ["Cur\u00b7Bran\u00b7den\u00b7burg", "und", "mehr", "/", "der", "Feinds", "Ge\u00b7walt", "ge\u00b7wach"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "KON", "ADV", "$(", "ART", "NN", "NN", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "und unverzagt zu seyn/ viel Volcks geworben hab/", "tokens": ["und", "un\u00b7ver\u00b7zagt", "zu", "seyn", "/", "viel", "Volcks", "ge\u00b7wor\u00b7ben", "hab", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PTKZU", "VAINF", "$(", "PIAT", "NN", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Und weil dann keiner nicht dasselbige begab/", "tokens": ["Und", "weil", "dann", "kei\u00b7ner", "nicht", "das\u00b7sel\u00b7bi\u00b7ge", "be\u00b7gab", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIS", "PTKNEG", "PDS", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.149": {"text": "Wieviel vom K\u00e4yser wurd\u2019 an sie darum geschrieben/", "tokens": ["Wie\u00b7viel", "vom", "K\u00e4y\u00b7ser", "wurd'", "an", "sie", "da\u00b7rum", "ge\u00b7schrie\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NN", "VAFIN", "APPR", "PPER", "PAV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.150": {"text": "So solten sie mit Macht zu solchem seyn getrieben.", "tokens": ["So", "sol\u00b7ten", "sie", "mit", "Macht", "zu", "sol\u00b7chem", "seyn", "ge\u00b7trie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "NN", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.151": {"text": "Di\u00df war die ", "tokens": ["Di\u00df", "war", "die"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.152": {"text": "Nach diesem Hessen trieb. Was hier wurd\u2019 umgebracht", "tokens": ["Nach", "die\u00b7sem", "Hes\u00b7sen", "trieb", ".", "Was", "hier", "wurd'", "um\u00b7ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "$.", "PWS", "ADV", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.153": {"text": "An G\u00fctern/ Menschen/ Vieh/ durch Th\u00fcringen und Meis-", "tokens": ["An", "G\u00fc\u00b7tern", "/", "Men\u00b7schen", "/", "Vieh", "/", "durch", "Th\u00fc\u00b7rin\u00b7gen", "und", "Meis"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$(", "NN", "$(", "NN", "$(", "APPR", "NN", "KON", "TRUNC"], "meter": "-+-+-+-+---+", "measure": "unknown.measure.penta"}, "line.154": {"text": "Eh er an Hessen kam/ wird niemand l\u00f6blich heissen.", "tokens": ["Eh", "er", "an", "Hes\u00b7sen", "kam", "/", "wird", "nie\u00b7mand", "l\u00f6b\u00b7lich", "heis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "$(", "VAFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.155": {"text": "Und eben dieses bracht am Hartzwald einen Schwarm", "tokens": ["Und", "e\u00b7ben", "die\u00b7ses", "bracht", "am", "Hart\u00b7zwald", "ei\u00b7nen", "Schwarm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "PDS", "VVFIN", "APPRART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.156": {"text": "Von b\u00f6sen Bauren auf/ der grausam im alarm", "tokens": ["Von", "b\u00f6\u00b7sen", "Bau\u00b7ren", "auf", "/", "der", "grau\u00b7sam", "im", "a\u00b7larm"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "APPR", "$(", "ART", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.157": {"text": "Viel hundert niederschlug/ da\u00df auch die Todten lagen/", "tokens": ["Viel", "hun\u00b7dert", "nie\u00b7der\u00b7schlug", "/", "da\u00df", "auch", "die", "Tod\u00b7ten", "la\u00b7gen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "VVFIN", "$(", "KOUS", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Als h\u00e4tte Tylli sich mit Schweden r\u00fcm geschlagen/", "tokens": ["Als", "h\u00e4t\u00b7te", "Tyl\u00b7li", "sich", "mit", "Schwe\u00b7den", "r\u00fcm", "ge\u00b7schla\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NE", "PRF", "APPR", "NE", "NE", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.159": {"text": "und eine Schlacht verlohrn. Als er an Hessen stie\u00df", "tokens": ["und", "ei\u00b7ne", "Schlacht", "ver\u00b7lohrn", ".", "Als", "er", "an", "Hes\u00b7sen", "stie\u00df"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF", "$.", "KOUS", "PPER", "APPR", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "und dessen Oberherrn durch einen sagen lie\u00df:", "tokens": ["und", "des\u00b7sen", "O\u00b7ber\u00b7herrn", "durch", "ei\u00b7nen", "sa\u00b7gen", "lie\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "APPR", "ART", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.161": {"text": "Freund oder Feind zu seyn/ die Waffen abzulegen/", "tokens": ["Freund", "o\u00b7der", "Feind", "zu", "seyn", "/", "die", "Waf\u00b7fen", "ab\u00b7zu\u00b7le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKZU", "VAINF", "$(", "ART", "NN", "VVIZU", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.162": {"text": "F\u00fcnff tausend K\u00e4ysrische im Lande zu verpflegen/", "tokens": ["F\u00fcnff", "tau\u00b7send", "K\u00e4y\u00b7sri\u00b7sche", "im", "Lan\u00b7de", "zu", "ver\u00b7pfle\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.163": {"text": "Zur Contribution sehr bald bereit zu seyn/", "tokens": ["Zur", "Con\u00b7tri\u00b7bu\u00b7ti\u00b7on", "sehr", "bald", "be\u00b7reit", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "ADJD", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "und was noch anders war. Da war die Antwort: Nein.", "tokens": ["und", "was", "noch", "an\u00b7ders", "war", ".", "Da", "war", "die", "Ant\u00b7wort", ":", "Nein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PWS", "ADV", "ADV", "VAFIN", "$.", "ADV", "VAFIN", "ART", "NN", "$.", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.165": {"text": "Wir gehen keines ein. Wird jemand uns belasten/", "tokens": ["Wir", "ge\u00b7hen", "kei\u00b7nes", "ein", ".", "Wird", "je\u00b7mand", "uns", "be\u00b7las\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PTKVZ", "$.", "VAFIN", "PIS", "PPER", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.166": {"text": "So stehen wir gefast jhn wieder anzutasten.", "tokens": ["So", "ste\u00b7hen", "wir", "ge\u00b7fast", "jhn", "wie\u00b7der", "an\u00b7zu\u00b7tas\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "VVFIN", "PPER", "ADV", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.167": {"text": "Was war dem Tylli mehr befremdt als dieses Wort?", "tokens": ["Was", "war", "dem", "Tyl\u00b7li", "mehr", "be\u00b7fremdt", "als", "die\u00b7ses", "Wort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NE", "ADV", "ADJD", "KOKOM", "PDAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.168": {"text": "Auf welches er auch bald ergrimmt durch Hessen fort", "tokens": ["Auf", "wel\u00b7ches", "er", "auch", "bald", "er\u00b7grimmt", "durch", "Hes\u00b7sen", "fort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELS", "PPER", "ADV", "ADV", "VVPP", "APPR", "NE", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.169": {"text": "und \u00fcber Cassel wolt\u2019. In dem er in Bereitung/", "tokens": ["und", "\u00fc\u00b7ber", "Cas\u00b7sel", "wolt'", ".", "In", "dem", "er", "in", "Be\u00b7rei\u00b7tung", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VMFIN", "$.", "APPR", "PRELS", "PPER", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.170": {"text": "Das Land zu st\u00fcrmen/ war/ bekam er b\u00f6se Zeitung/", "tokens": ["Das", "Land", "zu", "st\u00fcr\u00b7men", "/", "war", "/", "be\u00b7kam", "er", "b\u00f6\u00b7se", "Zei\u00b7tung", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$(", "VAFIN", "$(", "VVFIN", "PPER", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "Wie sein verlassen Volck zur Elbe durch die Macht", "tokens": ["Wie", "sein", "ver\u00b7las\u00b7sen", "Volck", "zur", "El\u00b7be", "durch", "die", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "ADJA", "NN", "APPRART", "NE", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.172": {"text": "Der Schweden meistentheils w\u00e4r um den Hals gebracht/", "tokens": ["Der", "Schwe\u00b7den", "meis\u00b7ten\u00b7theils", "w\u00e4r", "um", "den", "Hals", "ge\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ADV", "VAFIN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Wie sich Gustavus h\u00e4tt\u2019 um Werben starck bew\u00e4llet/", "tokens": ["Wie", "sich", "Gus\u00b7ta\u00b7vus", "h\u00e4tt'", "um", "Wer\u00b7ben", "starck", "be\u00b7w\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NE", "VAFIN", "APPR", "NN", "ADJD", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.174": {"text": "Wie schlecht es Rostock gieng/ wie Wi\u00dfmar w\u00e4r \u00fcmst\u00e4llet/", "tokens": ["Wie", "schlecht", "es", "Ros\u00b7tock", "gieng", "/", "wie", "Wi\u00df\u00b7mar", "w\u00e4r", "\u00fcm\u00b7st\u00e4l\u00b7let", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "NE", "VVFIN", "$(", "KOKOM", "NE", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.175": {"text": "Gripswald schon gar besiegt/ und wie die jene Schar/", "tokens": ["Grips\u00b7wald", "schon", "gar", "be\u00b7siegt", "/", "und", "wie", "die", "je\u00b7ne", "Schar", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADV", "VVPP", "$(", "KON", "PWAV", "ART", "PDAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Die mit Perusi hier in der Besatzung war/", "tokens": ["Die", "mit", "Pe\u00b7ru\u00b7si", "hier", "in", "der", "Be\u00b7sat\u00b7zung", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "ADV", "APPR", "ART", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.177": {"text": "Durch eine Schwedische Verfolgung/ weil ihr reisen", "tokens": ["Durch", "ei\u00b7ne", "Schwe\u00b7di\u00b7sche", "Ver\u00b7fol\u00b7gung", "/", "weil", "ihr", "rei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "$(", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.178": {"text": "Der Abred\u2019 ungleich war/ w\u00e4r alle durch das Eisen", "tokens": ["Der", "Ab\u00b7red'", "un\u00b7gleich", "war", "/", "w\u00e4r", "al\u00b7le", "durch", "das", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VAFIN", "$(", "VAFIN", "PIS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.179": {"text": "Gefallen. Di\u00df und mehr bewog des Tylli Sinn/", "tokens": ["Ge\u00b7fal\u00b7len", ".", "Di\u00df", "und", "mehr", "be\u00b7wog", "des", "Tyl\u00b7li", "Sinn", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PDS", "KON", "ADV", "VVFIN", "ART", "NE", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.180": {"text": "Da\u00df er von Hessen lie\u00df und nach der Elbe hin", "tokens": ["Da\u00df", "er", "von", "Hes\u00b7sen", "lie\u00df", "und", "nach", "der", "El\u00b7be", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NE", "VVFIN", "KON", "APPR", "ART", "NE", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Mit grossem Eifer gieng/ am Schweden sich zu r\u00e4chen/", "tokens": ["Mit", "gros\u00b7sem", "Ei\u00b7fer", "gieng", "/", "am", "Schwe\u00b7den", "sich", "zu", "r\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$(", "APPRART", "NE", "PRF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.182": {"text": "Eh er noch weiter m\u00f6cht ins Deutsche Reich einbr\u00e4chen.", "tokens": ["Eh", "er", "noch", "wei\u00b7ter", "m\u00f6cht", "ins", "Deut\u00b7sche", "Reich", "ein\u00b7br\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "VMFIN", "APPRART", "ADJA", "NN", "VVINF", "$."], "meter": "++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.183": {"text": "Ach welche Freude kam nunmehr ins Hessen-Land/", "tokens": ["Ach", "wel\u00b7che", "Freu\u00b7de", "kam", "nun\u00b7mehr", "ins", "Hes\u00b7sen\u00b7Land", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "PWAT", "NN", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.184": {"text": "Als dieses Wetter war von jhnen abgewandt!", "tokens": ["Als", "die\u00b7ses", "Wet\u00b7ter", "war", "von", "jh\u00b7nen", "ab\u00b7ge\u00b7wandt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.185": {"text": "Man stellte Danckfest an/ es jauchtzten gro\u00df und kleine.", "tokens": ["Man", "stell\u00b7te", "Dan\u00b7ck\u00b7fest", "an", "/", "es", "jauchtz\u00b7ten", "gro\u00df", "und", "klei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "PTKVZ", "$(", "PPER", "VVFIN", "ADJD", "KON", "ADJA", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.186": {"text": "Ein Theil der jagte nach und machte schnelle Beine/", "tokens": ["Ein", "Theil", "der", "jag\u00b7te", "nach", "und", "mach\u00b7te", "schnel\u00b7le", "Bei\u00b7ne", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "VVFIN", "APPR", "KON", "VVFIN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.187": {"text": "Da gab es Schl\u00e4g\u2019 und Beuth\u2019. Als durch das gantze", "tokens": ["Da", "gab", "es", "Schl\u00e4g'", "und", "Beuth'", ".", "Als", "durch", "das", "gant\u00b7ze"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "KON", "NN", "$.", "KOUS", "APPR", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.188": {"text": "Land", "tokens": ["Land"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.189": {"text": "Das Danckfest war gethan fiel man mit starcker Hand", "tokens": ["Das", "Dan\u00b7ck\u00b7fest", "war", "ge\u00b7than", "fiel", "man", "mit", "star\u00b7cker", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "VVPP", "VVFIN", "PIS", "APPR", "ADJA", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.190": {"text": "An Hirschfeld/ nahm es ein und machte gro\u00dfe Beuthen.", "tokens": ["An", "Hirschfeld", "/", "nahm", "es", "ein", "und", "mach\u00b7te", "gro\u00b7\u00dfe", "Beu\u00b7then", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.191": {"text": "Nach diesem fieng man an auch Fulda zu bestreiten/", "tokens": ["Nach", "die\u00b7sem", "fi\u00b7eng", "man", "an", "auch", "Ful\u00b7da", "zu", "be\u00b7strei\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PIS", "APPR", "ADV", "NE", "PTKZU", "VVINF", "$("], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.192": {"text": "Das auch erobert wurd\u2019/ und muste solche Stadt", "tokens": ["Das", "auch", "er\u00b7o\u00b7bert", "wurd'", "/", "und", "mus\u00b7te", "sol\u00b7che", "Stadt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVPP", "VAFIN", "$(", "KON", "VMFIN", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.193": {"text": "Ein trefflich gro\u00dfes Geld/ das es versprochen hatt\u2019", "tokens": ["Ein", "treff\u00b7lich", "gro\u00b7\u00dfes", "Geld", "/", "das", "es", "ver\u00b7spro\u00b7chen", "hatt'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN", "$(", "PRELS", "PPER", "VVINF", "VAFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Als Hertzog Christian \u00fcm solche war gelegen/", "tokens": ["Als", "Hert\u00b7zog", "Chris\u00b7ti\u00b7an", "\u00fcm", "sol\u00b7che", "war", "ge\u00b7le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "APPRART", "PIS", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Erlegen/ dieses war der Anfang von dem Segen", "tokens": ["Er\u00b7le\u00b7gen", "/", "die\u00b7ses", "war", "der", "An\u00b7fang", "von", "dem", "Se\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "PDS", "VAFIN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Des Cassel-Hessen-Kriegs. Auf/ auf und la\u00df uns nach", "tokens": ["Des", "Cas\u00b7sel\u00b7Hes\u00b7sen\u00b7Kriegs", ".", "Auf", "/", "auf", "und", "la\u00df", "uns", "nach"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$.", "APPR", "$(", "PTKVZ", "KON", "VVIMP", "PPER", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.197": {"text": "Zu sehen wie der Held Graff Tylli seine Rach", "tokens": ["Zu", "se\u00b7hen", "wie", "der", "Held", "Graff", "Tyl\u00b7li", "sei\u00b7ne", "Rach"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "KOKOM", "ART", "NN", "NE", "NE", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.198": {"text": "Ver\u00fcbe. Seine Reis\u2019 ist schnell/ er wil sich r\u00e4chen/", "tokens": ["Ver\u00b7\u00fc\u00b7be", ".", "Sei\u00b7ne", "Reis'", "ist", "schnell", "/", "er", "wil", "sich", "r\u00e4\u00b7chen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$(", "PPER", "VMFIN", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.199": {"text": "Sich oder seinen Feind darob an Kr\u00e4fften schw\u00e4chen/", "tokens": ["Sich", "o\u00b7der", "sei\u00b7nen", "Feind", "da\u00b7rob", "an", "Kr\u00e4ff\u00b7ten", "schw\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "KON", "PPOSAT", "NN", "PAV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.200": {"text": "Es traff jhn aber selbst. Er kam so bald nicht an", "tokens": ["Es", "traff", "jhn", "a\u00b7ber", "selbst", ".", "Er", "kam", "so", "bald", "nicht", "an"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "$.", "PPER", "VVFIN", "ADV", "ADV", "PTKNEG", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "und hielt bey Stendel Stand/ der tapfre Schweden-Mann", "tokens": ["und", "hielt", "bey", "Sten\u00b7del", "Stand", "/", "der", "tapf\u00b7re", "Schwe\u00b7den\u00b7Mann"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "NN", "$(", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.202": {"text": "Fiel in der Nacht auf jhn und schlug jhm seiner Reiter", "tokens": ["Fiel", "in", "der", "Nacht", "auf", "jhn", "und", "schlug", "jhm", "sei\u00b7ner", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "PPER", "KON", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.203": {"text": "Bey sieben hundert Mann/ h\u00e4tt\u2019 jhn die Nacht noch weiter", "tokens": ["Bey", "sie\u00b7ben", "hun\u00b7dert", "Mann", "/", "h\u00e4tt'", "jhn", "die", "Nacht", "noch", "wei\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "CARD", "NN", "$(", "VAFIN", "PPER", "ART", "NN", "ADV", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.204": {"text": "Zu gehen nicht gehemmt/ er h\u00e4tte die\u00df allein", "tokens": ["Zu", "ge\u00b7hen", "nicht", "ge\u00b7hemmt", "/", "er", "h\u00e4t\u00b7te", "die\u00df", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "PTKNEG", "VVPP", "$(", "PPER", "VAFIN", "PDS", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.205": {"text": "Jhm viel zu wenig noch zum Siege lassen seyn/", "tokens": ["Jhm", "viel", "zu", "we\u00b7nig", "noch", "zum", "Sie\u00b7ge", "las\u00b7sen", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKA", "PIS", "ADV", "APPRART", "NN", "VVINF", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.206": {"text": "Es h\u00e4tten jhm noch mehr vom Feinde m\u00fcssen sterben.", "tokens": ["Es", "h\u00e4t\u00b7ten", "jhm", "noch", "mehr", "vom", "Fein\u00b7de", "m\u00fcs\u00b7sen", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Mit diesem zog er sich nun wiederum nach Werben/", "tokens": ["Mit", "die\u00b7sem", "zog", "er", "sich", "nun", "wie\u00b7de\u00b7rum", "nach", "Wer\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.208": {"text": "In seinen festen Platz/ und hielt sich da gantz still.", "tokens": ["In", "sei\u00b7nen", "fes\u00b7ten", "Platz", "/", "und", "hielt", "sich", "da", "gantz", "still", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "KON", "VVFIN", "PRF", "ADV", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.209": {"text": "Wie b\u00f6\u00df auf diesen Schlag des gro\u00dfen Tylli Will", "tokens": ["Wie", "b\u00f6\u00df", "auf", "die\u00b7sen", "Schlag", "des", "gro\u00b7\u00dfen", "Tyl\u00b7li", "Will"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "APPR", "PDAT", "NN", "ART", "ADJA", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.210": {"text": "und Hertze sich erwie\u00df/ ist schwerlich au\u00dfzusagen/", "tokens": ["und", "Hert\u00b7ze", "sich", "er\u00b7wie\u00df", "/", "ist", "schwer\u00b7lich", "au\u00df\u00b7zu\u00b7sa\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "VVFIN", "$(", "VAFIN", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.211": {"text": "Nun wolt er nichts als nur sich mit dem K\u00f6nig schlagen.", "tokens": ["Nun", "wolt", "er", "nichts", "als", "nur", "sich", "mit", "dem", "K\u00f6\u00b7nig", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PIS", "KOKOM", "ADV", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.212": {"text": "Er kam/ uud schickte doch vorher ins K\u00f6nigs Heer", "tokens": ["Er", "kam", "/", "u\u00b7ud", "schick\u00b7te", "doch", "vor\u00b7her", "ins", "K\u00f6\u00b7nigs", "Heer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$(", "KON", "VVFIN", "ADV", "ADV", "APPRART", "NN", "NN"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.213": {"text": "Ein abgef\u00e4umtes Paar/ die solten seiner Ehr", "tokens": ["Ein", "ab\u00b7ge\u00b7f\u00e4um\u00b7tes", "Paar", "/", "die", "sol\u00b7ten", "sei\u00b7ner", "Ehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "PIAT", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.214": {"text": "und Siege Schmiede seyn und das Gesch\u00fctz vernageln/", "tokens": ["und", "Sie\u00b7ge", "Schmie\u00b7de", "seyn", "und", "das", "Ge\u00b7sch\u00fctz", "ver\u00b7na\u00b7geln", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VAINF", "KON", "ART", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.215": {"text": "Damit der tapfre Goth im Zorn nicht k\u00f6nnte hageln", "tokens": ["Da\u00b7mit", "der", "tapf\u00b7re", "Goth", "im", "Zorn", "nicht", "k\u00f6nn\u00b7te", "ha\u00b7geln"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "ADJA", "NN", "APPRART", "NN", "PTKNEG", "VMFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.216": {"text": "und jhm zum Schaden seyn. Das au\u00dfgeschickte Paar", "tokens": ["und", "jhm", "zum", "Scha\u00b7den", "seyn", ".", "Das", "au\u00df\u00b7ge\u00b7schick\u00b7te", "Paar"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPER", "APPRART", "NN", "VAINF", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.217": {"text": "Kam an/ und sagt\u2019 es aus/ worum es kommen war.", "tokens": ["Kam", "an", "/", "und", "sagt'", "es", "aus", "/", "wo\u00b7rum", "es", "kom\u00b7men", "war", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKVZ", "$(", "KON", "VVFIN", "PPER", "PTKVZ", "$(", "PWAV", "PPER", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.218": {"text": "Um einen gr\u00f6\u00dfern Lohn vom K\u00f6nig zu empfangen/", "tokens": ["Um", "ei\u00b7nen", "gr\u00f6\u00b7\u00dfern", "Lohn", "vom", "K\u00f6\u00b7nig", "zu", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.219": {"text": "Als Tylli selbst verhie\u00df/ da es war au\u00dfgegangen/", "tokens": ["Als", "Tyl\u00b7li", "selbst", "ver\u00b7hie\u00df", "/", "da", "es", "war", "au\u00df\u00b7ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "VVFIN", "$(", "KOUS", "PPER", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.220": {"text": "Da war die List entdeckt. Der K\u00f6nig s\u00e4umte nicht", "tokens": ["Da", "war", "die", "List", "ent\u00b7deckt", ".", "Der", "K\u00f6\u00b7nig", "s\u00e4um\u00b7te", "nicht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "VVPP", "$.", "ART", "NN", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.221": {"text": "und hielte das Gesch\u00fctz dem Feinde zu gericht", "tokens": ["und", "hiel\u00b7te", "das", "Ge\u00b7sch\u00fctz", "dem", "Fein\u00b7de", "zu", "ge\u00b7richt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.222": {"text": "Nach Creutz-art lo\u00df zu gehn. Das gantze Heer war r\u00fcstig", "tokens": ["Nach", "Creutz\u00b7art", "lo\u00df", "zu", "gehn", ".", "Das", "gant\u00b7ze", "Heer", "war", "r\u00fcs\u00b7tig"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "PTKVZ", "PTKZU", "VVINF", "$.", "ART", "ADJA", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.223": {"text": "und hielte dennoch sich wie schlaffend. O wie listig/", "tokens": ["und", "hiel\u00b7te", "den\u00b7noch", "sich", "wie", "schlaf\u00b7fend", ".", "O", "wie", "lis\u00b7tig", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PRF", "KOKOM", "ADJD", "$.", "NE", "KOKOM", "ADJD", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.224": {"text": "Des Feindes seine List zu schimpfen! Tylli kam", "tokens": ["Des", "Fein\u00b7des", "sei\u00b7ne", "List", "zu", "schimp\u00b7fen", "!", "Tyl\u00b7li", "kam"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$.", "NE", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.225": {"text": "und fiel das Lager an. Als er kein St\u00fcck vernahm", "tokens": ["und", "fiel", "das", "La\u00b7ger", "an", ".", "Als", "er", "kein", "St\u00fcck", "ver\u00b7nahm"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKVZ", "$.", "KOUS", "PPER", "PIAT", "NN", "VVFIN"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.226": {"text": "Gedacht er/ seine List die w\u00e4re sieghafft worden", "tokens": ["Ge\u00b7dacht", "er", "/", "sei\u00b7ne", "List", "die", "w\u00e4\u00b7re", "sieg\u00b7hafft", "wor\u00b7den"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$(", "PPOSAT", "NN", "ART", "VAFIN", "VVPP", "VAPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.227": {"text": "und r\u00fcckte ba\u00df darauf. Da gieng der Knall von Norden/", "tokens": ["und", "r\u00fcck\u00b7te", "ba\u00df", "da\u00b7rauf", ".", "Da", "gieng", "der", "Knall", "von", "Nor\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PAV", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.228": {"text": "Da giengen alle St\u00fcck um jhn erschrecklich her/", "tokens": ["Da", "gien\u00b7gen", "al\u00b7le", "St\u00fcck", "um", "jhn", "er\u00b7schreck\u00b7lich", "her", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "NN", "APPR", "PPER", "ADJD", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.229": {"text": "Als wie der Hagel tobt/ und wie das wilde Meer/", "tokens": ["Als", "wie", "der", "Ha\u00b7gel", "tobt", "/", "und", "wie", "das", "wil\u00b7de", "Meer", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "VVFIN", "$(", "KON", "PWAV", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.230": {"text": "Wann es der Nord erregt. Da flogen Pferd und Reiter", "tokens": ["Wann", "es", "der", "Nord", "er\u00b7regt", ".", "Da", "flo\u00b7gen", "Pferd", "und", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "NN", "VVPP", "$.", "ADV", "VVFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "In freyer Lufft herum. Da sah der tapfre Streiter/", "tokens": ["In", "frey\u00b7er", "Lufft", "he\u00b7rum", ".", "Da", "sah", "der", "tapf\u00b7re", "Strei\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "$.", "ADV", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.232": {"text": "Graff Tylli/ wie sein Gl\u00fcck so sch\u00e4ndlich jhn verlie\u00df", "tokens": ["Graff", "Tyl\u00b7li", "/", "wie", "sein", "Gl\u00fcck", "so", "sch\u00e4nd\u00b7lich", "jhn", "ver\u00b7lie\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$(", "KOKOM", "PPOSAT", "NN", "ADV", "ADJD", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.233": {"text": "und in die gro\u00dfe Zahl der ", "tokens": ["und", "in", "die", "gro\u00b7\u00dfe", "Zahl", "der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.234": {"text": "Bey diesem Hauptgefecht hat Bernhard wol erwiesen/", "tokens": ["Bey", "die\u00b7sem", "Haupt\u00b7ge\u00b7fecht", "hat", "Bern\u00b7hard", "wol", "er\u00b7wie\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "NE", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Der tapfre Weymar-F\u00fcrst und Held/ was er nach diesen", "tokens": ["Der", "tapf\u00b7re", "Wey\u00b7ma\u00b7rF\u00fcrst", "und", "Held", "/", "was", "er", "nach", "die\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "$(", "PWS", "PPER", "APPR", "PDAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.236": {"text": "F\u00fcr Thaten w\u00fcrde thun/ er kam aufs dritte Pferd/", "tokens": ["F\u00fcr", "Tha\u00b7ten", "w\u00fcr\u00b7de", "thun", "/", "er", "kam", "aufs", "drit\u00b7te", "Pferd", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVINF", "$(", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Kam doch gesund davon/ als langes Lebens werth.", "tokens": ["Kam", "doch", "ge\u00b7sund", "da\u00b7von", "/", "als", "lan\u00b7ges", "Le\u00b7bens", "werth", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "PAV", "$(", "KOUS", "ADJA", "NN", "ADJD", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.238": {"text": "Di\u00df war der erste Ritt und Dienst/ den er dem K\u00f6nig", "tokens": ["Di\u00df", "war", "der", "ers\u00b7te", "Ritt", "und", "Dienst", "/", "den", "er", "dem", "K\u00f6\u00b7nig"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "KON", "NN", "$(", "PRELS", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.239": {"text": "Aus Schweden hatt\u2019 erzeigt/ der jhn dann auch nicht wenig", "tokens": ["Aus", "Schwe\u00b7den", "hatt'", "er\u00b7zeigt", "/", "der", "jhn", "dann", "auch", "nicht", "we\u00b7nig"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VAFIN", "VVPP", "$(", "PRELS", "PPER", "ADV", "ADV", "PTKNEG", "ADV"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.240": {"text": "In Ansehn hat gebracht. Nach diesem neuen Sieg", "tokens": ["In", "An\u00b7sehn", "hat", "ge\u00b7bracht", ".", "Nach", "die\u00b7sem", "neu\u00b7en", "Sieg"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "$.", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.241": {"text": "Zog er den Hessen zu/ derselben neuen Krieg", "tokens": ["Zog", "er", "den", "Hes\u00b7sen", "zu", "/", "der\u00b7sel\u00b7ben", "neu\u00b7en", "Krieg"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKZU", "$(", "PDAT", "ADJA", "NN"], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.242": {"text": "Zu f\u00f6rdern. Jetzund gieng Graf Tylli recht in Mei\u00dfen/", "tokens": ["Zu", "f\u00f6r\u00b7dern", ".", "Je\u00b7tzund", "gieng", "Graf", "Tyl\u00b7li", "recht", "in", "Mei\u00b7\u00dfen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "ADV", "VVFIN", "NE", "NE", "ADJD", "APPR", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.243": {"text": "Di\u00df hatt\u2019 jhn Wien nunmehr zum andernmahl gehei\u00dfen/", "tokens": ["Di\u00df", "hatt'", "jhn", "Wi\u00b7en", "nun\u00b7mehr", "zum", "an\u00b7dern\u00b7mahl", "ge\u00b7hei\u00b7\u00dfen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "NE", "ADV", "APPRART", "ADV", "VVPP", "$("], "meter": "-+----+-+-+-+-", "measure": "dactylic.init"}, "line.244": {"text": "und plagte Leuth und Land. Weil aber dieser Zeit", "tokens": ["und", "plag\u00b7te", "Leuth", "und", "Land", ".", "Weil", "a\u00b7ber", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "NN", "$.", "KOUS", "ADV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.245": {"text": "Der Cur-F\u00fcrst noch nichts that/ sich auch in keinen", "tokens": ["Der", "Cur\u00b7F\u00fcrst", "noch", "nichts", "that", "/", "sich", "auch", "in", "kei\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PIS", "VVFIN", "$(", "PRF", "ADV", "APPR", "PIAT"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.246": {"text": "Streit", "tokens": ["Streit"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.247": {"text": "Zu lassen/ sehen lie\u00df/ als lie\u00df jhn Tylli fragen:", "tokens": ["Zu", "las\u00b7sen", "/", "se\u00b7hen", "lie\u00df", "/", "als", "lie\u00df", "jhn", "Tyl\u00b7li", "fra\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$(", "VVINF", "VVFIN", "$(", "KOKOM", "VVFIN", "PPER", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.248": {"text": "Was endlich seiner Macht noch w\u00e4re nachzusagen?", "tokens": ["Was", "end\u00b7lich", "sei\u00b7ner", "Macht", "noch", "w\u00e4\u00b7re", "nach\u00b7zu\u00b7sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PPOSAT", "NN", "ADV", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.249": {"text": "Db er des K\u00e4ysers Feind/ wo nicht/ ob er sein Heer", "tokens": ["Db", "er", "des", "K\u00e4y\u00b7sers", "Feind", "/", "wo", "nicht", "/", "ob", "er", "sein", "Heer"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "$(", "PWAV", "PTKNEG", "$(", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.250": {"text": "Dem K\u00e4yser lassen wolt\u2019/ auf da\u00df der Friedenst\u00f6r/", "tokens": ["Dem", "K\u00e4y\u00b7ser", "las\u00b7sen", "wolt'", "/", "auf", "da\u00df", "der", "Frie\u00b7den\u00b7st\u00f6r", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "VMFIN", "$(", "APPR", "KOUS", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.251": {"text": "(wie er den K\u00f6nig nannt\u2019) eh er der Deutschen Erden", "tokens": ["(", "wie", "er", "den", "K\u00f6\u00b7nig", "nannt'", ")", "eh", "er", "der", "Deut\u00b7schen", "Er\u00b7den"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PWAV", "PPER", "ART", "NN", "VVFIN", "$(", "KOUS", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.252": {"text": "Noch weiter donnderde/ k\u00f6nnt aufgeschlagen werden/", "tokens": ["Noch", "wei\u00b7ter", "donn\u00b7der\u00b7de", "/", "k\u00f6nnt", "auf\u00b7ge\u00b7schla\u00b7gen", "wer\u00b7den", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "NN", "$(", "VVFIN", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "und was er anders mehr von jhm an Proviant", "tokens": ["und", "was", "er", "an\u00b7ders", "mehr", "von", "jhm", "an", "Pro\u00b7vi\u00b7ant"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "ADV", "APPR", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.254": {"text": "und Einnahm seines Volcks in alles Mei\u00dfner-Land", "tokens": ["und", "Ein\u00b7nahm", "sei\u00b7nes", "Volcks", "in", "al\u00b7les", "Mei\u00df\u00b7ner\u00b7Land"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "PPOSAT", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.255": {"text": "Bedr\u00f6uend fordern lie\u00df. Hier ist zur Antwort worden:", "tokens": ["Be\u00b7dr\u00f6u\u00b7end", "for\u00b7dern", "lie\u00df", ".", "Hier", "ist", "zur", "Ant\u00b7wort", "wor\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VVFIN", "$.", "ADV", "VAFIN", "APPRART", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.256": {"text": "Wir sehen t\u00e4glich an das Brennen/ Rauben/ Morden", "tokens": ["Wir", "se\u00b7hen", "t\u00e4g\u00b7lich", "an", "das", "Bren\u00b7nen", "/", "Rau\u00b7ben", "/", "Mor\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "ADJD", "APPR", "ART", "NN", "$(", "NN", "$(", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.257": {"text": "und tau/ end ", "tokens": ["und", "tau", "/", "end"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "NE", "$(", "VVPP"], "meter": "-+-", "measure": "amphibrach.single"}, "line.258": {"text": "Die man von T\u00fcrcken nicht und derer Anhang gl\u00e4ubt/", "tokens": ["Die", "man", "von", "T\u00fcr\u00b7cken", "nicht", "und", "de\u00b7rer", "An\u00b7hang", "gl\u00e4ubt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "NN", "PTKNEG", "KON", "PDS", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.259": {"text": "So ligt den Hirten ob die Heerden zn besch\u00fctzen.", "tokens": ["So", "ligt", "den", "Hir\u00b7ten", "ob", "die", "Heer\u00b7den", "zn", "be\u00b7sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KOUS", "ART", "NN", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.260": {"text": "Dieweil nun eure Macht/ die \u00fcberal zu blitzen", "tokens": ["Die\u00b7weil", "nun", "eu\u00b7re", "Macht", "/", "die", "\u00fc\u00b7be\u00b7ral", "zu", "blit\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "$(", "ART", "ADJD", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.261": {"text": "Jhr Fug und Macht ertiche/ gantz Deutschland sehr be-", "tokens": ["Ihr", "Fug", "und", "Macht", "er\u00b7ti\u00b7che", "/", "gantz", "Deutschland", "sehr", "be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "$(", "ADV", "NE", "ADV", "TRUNC"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.262": {"text": "und sonder Zweifel auch auf uns zn kommen denckt/", "tokens": ["und", "son\u00b7der", "Zwei\u00b7fel", "auch", "auf", "uns", "zn", "kom\u00b7men", "denckt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ADV", "APPR", "PPER", "NE", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.263": {"text": "Als haben wir befugt das Schwerdt zur Faust genommen/", "tokens": ["Als", "ha\u00b7ben", "wir", "be\u00b7fugt", "das", "Schwerdt", "zur", "Faust", "ge\u00b7nom\u00b7men", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVFIN", "ART", "NN", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.264": {"text": "Wann uns ein ", "tokens": ["Wann", "uns", "ein"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PPER", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.265": {"text": "Daf\u00fcr bewehrt zu seyn. Hier ist kein Proviant/", "tokens": ["Da\u00b7f\u00fcr", "be\u00b7wehrt", "zu", "seyn", ".", "Hier", "ist", "kein", "Pro\u00b7vi\u00b7ant", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVPP", "PTKZU", "VAINF", "$.", "ADV", "VAFIN", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.266": {"text": "Hier ist kein Einla\u00df nicht f\u00fcr euch in unser Land.", "tokens": ["Hier", "ist", "kein", "Ein\u00b7la\u00df", "nicht", "f\u00fcr", "euch", "in", "un\u00b7ser", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "PTKNEG", "APPR", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.267": {"text": "Ver\u00fcber jhr Gewalt/ jhr solt Gewalt erfahren.", "tokens": ["Ver\u00b7\u00fc\u00b7ber", "jhr", "Ge\u00b7walt", "/", "jhr", "solt", "Ge\u00b7walt", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "PPER", "VMFIN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.268": {"text": "Es komme nicht drazu. Wir sind von langen Jahren", "tokens": ["Es", "kom\u00b7me", "nicht", "dra\u00b7zu", ".", "Wir", "sind", "von", "lan\u00b7gen", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "PTKVZ", "$.", "PPER", "VAFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.269": {"text": "Dem K\u00e4yser treu gewest/ und hoffen b\u00e4ssern Lohn", "tokens": ["Dem", "K\u00e4y\u00b7ser", "treu", "ge\u00b7west", "/", "und", "hof\u00b7fen", "b\u00e4s\u00b7sern", "Lohn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVPP", "$(", "KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.270": {"text": "Als uns gedrohet wird. Di\u00df war ein solcher Thon", "tokens": ["Als", "uns", "ge\u00b7dro\u00b7het", "wird", ".", "Di\u00df", "war", "ein", "sol\u00b7cher", "Thon"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVPP", "VAFIN", "$.", "PDS", "VAFIN", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Der bey den K\u00e4ysrischen ", "tokens": ["Der", "bey", "den", "K\u00e4y\u00b7sri\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.272": {"text": "Da ", "tokens": ["Da"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.273": {"text": "Zum K\u00e4yser solte thun/ fiel mitten in das Land", "tokens": ["Zum", "K\u00e4y\u00b7ser", "sol\u00b7te", "thun", "/", "fiel", "mit\u00b7ten", "in", "das", "Land"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "VVINF", "$(", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.274": {"text": "und bracht es sch\u00e4ndlich um durch Rauben/ Mord und", "tokens": ["und", "bracht", "es", "sch\u00e4nd\u00b7lich", "um", "durch", "Rau\u00b7ben", "/", "Mord", "und"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "ADJD", "APPR", "APPR", "NN", "$(", "NN", "KON"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.275": {"text": "Brand.", "tokens": ["Brand", "."], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.276": {"text": "Der Cur F\u00fcrst schrieb an jhn dergleichen abzust\u00e4llen/", "tokens": ["Der", "Cur", "F\u00fcrst", "schrieb", "an", "jhn", "derg\u00b7lei\u00b7chen", "ab\u00b7zu\u00b7st\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "PPER", "PIS", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.277": {"text": "Wo nicht/ so m\u00fcst er wol Piq-gegen Piquen f\u00e4llen/", "tokens": ["Wo", "nicht", "/", "so", "m\u00fcst", "er", "wol", "Pi\u00b7qge\u00b7gen", "Pi\u00b7quen", "f\u00e4l\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$(", "ADV", "VMFIN", "PPER", "ADV", "NN", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.278": {"text": "Den Seinen Hilff zu thun. Di\u00df alles ungeacht", "tokens": ["Den", "Sei\u00b7nen", "Hilff", "zu", "thun", ".", "Di\u00df", "al\u00b7les", "un\u00b7ge\u00b7acht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "PTKZU", "VVINF", "$.", "PDS", "PIS", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.279": {"text": "Fuhr Tylli grausam fort/ da\u00df Sachsen seine Macht", "tokens": ["Fuhr", "Tyl\u00b7li", "grau\u00b7sam", "fort", "/", "da\u00df", "Sach\u00b7sen", "sei\u00b7ne", "Macht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "ADJD", "PTKVZ", "$(", "KOUS", "NE", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.280": {"text": "Zusammlen ", "tokens": ["Zu\u00b7samm\u00b7len"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.281": {"text": "Doch allem ", "tokens": ["Doch", "al\u00b7lem"], "token_info": ["word", "word"], "pos": ["KON", "PIS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.282": {"text": "Must\u2019 Arnheimb seines Heers Regent zum K\u00f6nig hin/", "tokens": ["Must'", "Arn\u00b7heimb", "sei\u00b7nes", "Heers", "Re\u00b7gent", "zum", "K\u00f6\u00b7nig", "hin", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "PPOSAT", "NN", "NN", "APPRART", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.283": {"text": "Der noch bey Werben lag/ zu bitten/ da\u00df er jhn", "tokens": ["Der", "noch", "bey", "Wer\u00b7ben", "lag", "/", "zu", "bit\u00b7ten", "/", "da\u00df", "er", "jhn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NN", "VVFIN", "$(", "PTKZU", "VVINF", "$(", "KOUS", "PPER", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.284": {"text": "In dieser Kriegs-Gefahr nicht g\u00e4ntzlich wolte lassen/", "tokens": ["In", "die\u00b7ser", "Kriegs\u00b7Ge\u00b7fahr", "nicht", "g\u00e4ntz\u00b7lich", "wol\u00b7te", "las\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "PTKNEG", "ADJD", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.285": {"text": "Vielmehr im Anzug seyn sich seiner anzumassen.", "tokens": ["Viel\u00b7mehr", "im", "An\u00b7zug", "seyn", "sich", "sei\u00b7ner", "an\u00b7zu\u00b7mas\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PPOSAT", "PRF", "PPOSAT", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Der K\u00f6nig gieng es ein/ und meldete dabey:", "tokens": ["Der", "K\u00f6\u00b7nig", "gieng", "es", "ein", "/", "und", "mel\u00b7de\u00b7te", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "$(", "KON", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.287": {"text": "Das hab\u2019 ich lang gedacht/ da\u00df diese Tyranney", "tokens": ["Das", "hab'", "ich", "lang", "ge\u00b7dacht", "/", "da\u00df", "die\u00b7se", "Ty\u00b7ran\u00b7ney"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PDS", "VAFIN", "PPER", "ADJD", "VVPP", "$(", "KOUS", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.288": {"text": "Auch euch betreffen w\u00fcrd. Ich hab\u2019 es lang garathen", "tokens": ["Auch", "euch", "be\u00b7tref\u00b7fen", "w\u00fcrd", ".", "Ich", "hab'", "es", "lang", "ga\u00b7ra\u00b7then"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVPP", "VAFIN", "$.", "PPER", "VAFIN", "PPER", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.289": {"text": "Sich zeitlich vorzusehn. Man lernet mit dem Schaden.", "tokens": ["Sich", "zeit\u00b7lich", "vor\u00b7zu\u00b7sehn", ".", "Man", "ler\u00b7net", "mit", "dem", "Scha\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$.", "PIS", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.290": {"text": "O h\u00e4tten sich die P\u00e4\u00df uns eher aufgethan!", "tokens": ["O", "h\u00e4t\u00b7ten", "sich", "die", "P\u00e4\u00df", "uns", "e\u00b7her", "auf\u00b7ge\u00b7than", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PRF", "ART", "NN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.291": {"text": "Man s\u00e4he Magdeburg nun nicht so scheu\u00dflich an.", "tokens": ["Man", "s\u00e4\u00b7he", "Mag\u00b7de\u00b7burg", "nun", "nicht", "so", "scheu\u00df\u00b7lich", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NE", "ADV", "PTKNEG", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.292": {"text": "So h\u00e4tten wir nechst GOtt mit unsern Sieges-Waffen", "tokens": ["So", "h\u00e4t\u00b7ten", "wir", "nechst", "Gott", "mit", "un\u00b7sern", "Sie\u00b7ges\u00b7Waf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "VVFIN", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.293": {"text": "Vor jhrem ", "tokens": ["Vor", "jhrem"], "token_info": ["word", "word"], "pos": ["APPR", "PPOSAT"], "meter": "+-", "measure": "trochaic.single"}, "line.294": {"text": "Gott r\u00e4che diesen Mord und wilde Tyranney", "tokens": ["Gott", "r\u00e4\u00b7che", "die\u00b7sen", "Mord", "und", "wil\u00b7de", "Ty\u00b7ran\u00b7ney"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PDAT", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.295": {"text": "und stehe kr\u00e4fftiglich durch uns den andern bey/", "tokens": ["und", "ste\u00b7he", "kr\u00e4ff\u00b7tig\u00b7lich", "durch", "uns", "den", "an\u00b7dern", "bey", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "PPER", "ART", "ADJA", "APPR", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.296": {"text": "Die glelche Noth bedroht. Wir wollen helff- und rathen.", "tokens": ["Die", "glel\u00b7che", "Noth", "be\u00b7droht", ".", "Wir", "wol\u00b7len", "helff", "und", "ra\u00b7then", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "PPER", "VMFIN", "TRUNC", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.297": {"text": "Da samlet\u2019 er den Kern der tapfersten Soldaten", "tokens": ["Da", "sam\u00b7let'", "er", "den", "Kern", "der", "tap\u00b7fers\u00b7ten", "Sol\u00b7da\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN"], "meter": "--+--+-+---+-", "measure": "anapaest.di.plus"}, "line.298": {"text": "Bey funfzehntausend Mann und gieng durch Wittenbergt/", "tokens": ["Bey", "funf\u00b7zehn\u00b7tau\u00b7send", "Mann", "und", "gieng", "durch", "Wit\u00b7ten\u00b7bergt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "KON", "VVFIN", "APPR", "NE", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.299": {"text": "Cur-Sachsen Hilf zu thun/ die durch des Tylli St\u00e4rck", "tokens": ["Cur\u00b7Sach\u00b7sen", "Hilf", "zu", "thun", "/", "die", "durch", "des", "Tyl\u00b7li", "St\u00e4rck"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "PTKZU", "VVINF", "$(", "ART", "APPR", "ART", "NE", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.300": {"text": "In gro\u00dfer Schwachheit war und zimlich aufgerieben.", "tokens": ["In", "gro\u00b7\u00dfer", "Schwach\u00b7heit", "war", "und", "zim\u00b7lich", "auf\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "KON", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.301": {"text": "Es ligt ein St\u00e4dtigen in Meissen/ nahmens T\u00fcben/", "tokens": ["Es", "ligt", "ein", "St\u00e4d\u00b7ti\u00b7gen", "in", "Meis\u00b7sen", "/", "nah\u00b7mens", "T\u00fc\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$(", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.302": {"text": "Hier kam der Chur F\u00fcrst selbst f\u00fcr des Gustavus Mund/", "tokens": ["Hier", "kam", "der", "Chur", "F\u00fcrst", "selbst", "f\u00fcr", "des", "Gus\u00b7ta\u00b7vus", "Mund", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADV", "APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.303": {"text": "Wie auch Cur Brandenburg/ und machten einen Bund/", "tokens": ["Wie", "auch", "Cur", "Bran\u00b7den\u00b7burg", "/", "und", "mach\u00b7ten", "ei\u00b7nen", "Bund", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "NE", "$(", "KON", "VVFIN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Den Feind gesamter Hand von jhnen weg zu schmeissen.", "tokens": ["Den", "Feind", "ge\u00b7sam\u00b7ter", "Hand", "von", "jh\u00b7nen", "weg", "zu", "schmeis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "APPR", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.305": {"text": "Indessen dummlete Graf Tylli sich in Meissen", "tokens": ["In\u00b7des\u00b7sen", "dumm\u00b7le\u00b7te", "Graf", "Tyl\u00b7li", "sich", "in", "Meis\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "NE", "PRF", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.306": {"text": "und zog vor Leipzig hin/ begehrete die Stadt.", "tokens": ["und", "zog", "vor", "Leip\u00b7zig", "hin", "/", "be\u00b7ge\u00b7hre\u00b7te", "die", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NE", "PTKVZ", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.307": {"text": "Was solte solche thun? Die unerh\u00f6rte That", "tokens": ["Was", "sol\u00b7te", "sol\u00b7che", "thun", "?", "Die", "un\u00b7er\u00b7h\u00f6r\u00b7te", "That"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VMFIN", "PIS", "VVINF", "$.", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "An Magdeburg ver\u00fcbt und auch auf sie gedr\u00f6uhet/", "tokens": ["An", "Mag\u00b7de\u00b7burg", "ver\u00b7\u00fcbt", "und", "auch", "auf", "sie", "ge\u00b7dr\u00f6u\u00b7het", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "KON", "ADV", "APPR", "PPER", "VVFIN", "$("], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.309": {"text": "Wer hette solchem Grimm von Menschen nicht gescheuet?", "tokens": ["Wer", "het\u00b7te", "sol\u00b7chem", "Grimm", "von", "Men\u00b7schen", "nicht", "ge\u00b7scheu\u00b7et", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PIAT", "NN", "APPR", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.310": {"text": "Trieb Forcht und Schrecken ein. Zu dem war kein Entsatz", "tokens": ["Trieb", "Forcht", "und", "Schre\u00b7cken", "ein", ".", "Zu", "dem", "war", "kein", "Ent\u00b7satz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "KON", "NN", "PTKVZ", "$.", "APPR", "ART", "VAFIN", "PIAT", "NN"], "meter": "++-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.311": {"text": "So eylends vor der Hand. So stund auch um den Platz", "tokens": ["So", "ey\u00b7lends", "vor", "der", "Hand", ".", "So", "stund", "auch", "um", "den", "Platz"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$.", "ADV", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.312": {"text": "Ein grausam streitbar Heer von drei\u00dfig tausend Seelen/", "tokens": ["Ein", "grau\u00b7sam", "streit\u00b7bar", "Heer", "von", "drei\u00b7\u00dfig", "tau\u00b7send", "See\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJD", "NN", "APPR", "CARD", "CARD", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.313": {"text": "Die kamen allesamt die gute Stadt zu qu\u00e4len.", "tokens": ["Die", "ka\u00b7men", "al\u00b7le\u00b7samt", "die", "gu\u00b7te", "Stadt", "zu", "qu\u00e4\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Und also brachte man die Stadt zur Ubergab.", "tokens": ["Und", "al\u00b7so", "brach\u00b7te", "man", "die", "Stadt", "zur", "U\u00b7berg\u00b7ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PIS", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.315": {"text": "Da zog jhr Feind hinein und jhr Geliebter ab.", "tokens": ["Da", "zog", "jhr", "Feind", "hin\u00b7ein", "und", "jhr", "Ge\u00b7lieb\u00b7ter", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "PTKVZ", "KON", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.316": {"text": "Hier zwischen einigte sich Schweden mit Cur-Sachsen/", "tokens": ["Hier", "zwi\u00b7schen", "ei\u00b7nig\u00b7te", "sich", "Schwe\u00b7den", "mit", "Cur\u00b7Sach\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VVFIN", "PRF", "NE", "APPR", "NE", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.317": {"text": "und weil der Cur F\u00fcrst sich dem Feind also gewachsen", "tokens": ["und", "weil", "der", "Cur", "F\u00fcrst", "sich", "dem", "Feind", "al\u00b7so", "ge\u00b7wach\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "NN", "PRF", "ART", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.318": {"text": "Erachtet/ hielt er an/ der K\u00f6nig m\u00f6chte doch", "tokens": ["E\u00b7rach\u00b7tet", "/", "hielt", "er", "an", "/", "der", "K\u00f6\u00b7nig", "m\u00f6ch\u00b7te", "doch"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVPP", "$(", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "NN", "VMFIN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.319": {"text": "Zur Schlacht gewillet seyn/ weil ohne die das Joch", "tokens": ["Zur", "Schlacht", "ge\u00b7wil\u00b7let", "seyn", "/", "weil", "oh\u00b7ne", "die", "das", "Joch"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "VAINF", "$(", "KOUS", "APPR", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.320": {"text": "Von seinem Lande sich nicht w\u00fcrde lassen br\u00e4chen/", "tokens": ["Von", "sei\u00b7nem", "Lan\u00b7de", "sich", "nicht", "w\u00fcr\u00b7de", "las\u00b7sen", "br\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PRF", "PTKNEG", "VAFIN", "VVINF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.321": {"text": "Er hoffte da\u00df jhn GOtt w\u00fcrd\u2019 an den Feinden r\u00e4chen.", "tokens": ["Er", "hoff\u00b7te", "da\u00df", "jhn", "Gott", "w\u00fcrd'", "an", "den", "Fein\u00b7den", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOUS", "PPER", "NN", "VAFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.322": {"text": "Der K\u00f6nig aber war hier zu von schlechter Lust/", "tokens": ["Der", "K\u00f6\u00b7nig", "a\u00b7ber", "war", "hier", "zu", "von", "schlech\u00b7ter", "Lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "ADV", "APPR", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.323": {"text": "Dann es war jhm des Feinds sein Vorthel wol bewust/", "tokens": ["Dann", "es", "war", "jhm", "des", "Feinds", "sein", "Vor\u00b7thel", "wol", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PPER", "ART", "NN", "PPOSAT", "NN", "ADV", "VVFIN", "$("], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.324": {"text": "Drum hielt er es f\u00fcr gut jhm etwas nachzusehen/", "tokens": ["Drum", "hielt", "er", "es", "f\u00fcr", "gut", "jhm", "et\u00b7was", "nach\u00b7zu\u00b7se\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PPER", "APPR", "ADJD", "PPER", "PIS", "VVIZU", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.325": {"text": "und wann ein Vorthel w\u00e4r auf solchen lo\u00df zu gehen.", "tokens": ["und", "wann", "ein", "Vor\u00b7thel", "w\u00e4r", "auf", "sol\u00b7chen", "lo\u00df", "zu", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VAFIN", "APPR", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.326": {"text": "Di\u00df alles ungeacht lag er dem K\u00f6nig an", "tokens": ["Di\u00df", "al\u00b7les", "un\u00b7ge\u00b7acht", "lag", "er", "dem", "K\u00f6\u00b7nig", "an"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "ADJD", "VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.327": {"text": "Zur Schlacht gewillt zu seyn/ der dann die nechste Bahn", "tokens": ["Zur", "Schlacht", "ge\u00b7willt", "zu", "seyn", "/", "der", "dann", "die", "nechs\u00b7te", "Bahn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "PTKZU", "VAINF", "$(", "ART", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.328": {"text": "Mit jhm auf Leipzig nahm/ des Feindes Macht zu br\u00e4chen", "tokens": ["Mit", "jhm", "auf", "Leip\u00b7zig", "nahm", "/", "des", "Fein\u00b7des", "Macht", "zu", "br\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APPR", "NE", "VVFIN", "$(", "ART", "NN", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.329": {"text": "und das vergo\u00dfne Blut von Magdeburg zu r\u00e4chen.", "tokens": ["und", "das", "ver\u00b7go\u00df\u00b7ne", "Blut", "von", "Mag\u00b7de\u00b7burg", "zu", "r\u00e4\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "APPR", "NE", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.330": {"text": "Graf Tylli merckende/ das Sachsen nicht allein", "tokens": ["Graf", "Tyl\u00b7li", "mer\u00b7cken\u00b7de", "/", "das", "Sach\u00b7sen", "nicht", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NE", "VVFIN", "$(", "ART", "NN", "PTKNEG", "ADV"], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}, "line.331": {"text": "Auf jhn im Anzug war/ dann es war jhm der Schein", "tokens": ["Auf", "jhn", "im", "An\u00b7zug", "war", "/", "dann", "es", "war", "jhm", "der", "Schein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "APPRART", "NN", "VAFIN", "$(", "ADV", "PPER", "VAFIN", "PPER", "ART", "NN"], "meter": "+--+-+--+--+", "measure": "iambic.penta.invert"}, "line.332": {"text": "Von solchem viel zu gro\u00df/ lie\u00df keine Zeit zerrinnen/", "tokens": ["Von", "sol\u00b7chem", "viel", "zu", "gro\u00df", "/", "lie\u00df", "kei\u00b7ne", "Zeit", "zer\u00b7rin\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADV", "PTKA", "ADJD", "$(", "VVFIN", "PIAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.333": {"text": "Wind/ H\u00f6cht und anders mehr zum Vorthel zu gewinnen/", "tokens": ["Wind", "/", "H\u00f6cht", "und", "an\u00b7ders", "mehr", "zum", "Vor\u00b7thel", "zu", "ge\u00b7win\u00b7nen", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "ADV", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.334": {"text": "und dann erst lo\u00df zu gehn. Sein Wollen gieng jhm an/", "tokens": ["und", "dann", "erst", "lo\u00df", "zu", "gehn", ".", "Sein", "Wol\u00b7len", "gieng", "jhm", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADV", "PTKZU", "VVINF", "$.", "PPOSAT", "NN", "VVFIN", "PPER", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.335": {"text": "So da\u00df jhm guter Wind und ein bequemer Plan", "tokens": ["So", "da\u00df", "jhm", "gu\u00b7ter", "Wind", "und", "ein", "be\u00b7que\u00b7mer", "Plan"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADJA", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.336": {"text": "Zu seinem Vorthel wurd. Es stund auch sein Gesch\u00fctze", "tokens": ["Zu", "sei\u00b7nem", "Vor\u00b7thel", "wurd", ".", "Es", "stund", "auch", "sein", "Ge\u00b7sch\u00fct\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VAFIN", "$.", "PPER", "VVFIN", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.337": {"text": "Nach seiner Lust gepflantzt/ mit Donnder und mit Blitze", "tokens": ["Nach", "sei\u00b7ner", "Lust", "ge\u00b7pflantzt", "/", "mit", "Donn\u00b7der", "und", "mit", "Blit\u00b7ze"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVPP", "$(", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.338": {"text": "Den starcken Gegentheil zu gr\u00fc\u00dfen. Welch ein Gru\u00df/", "tokens": ["Den", "star\u00b7cken", "Ge\u00b7gen\u00b7theil", "zu", "gr\u00fc\u00b7\u00dfen", ".", "Welch", "ein", "Gru\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$.", "PIAT", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.339": {"text": "Dar\u00fcber mancher Held sein Leben enden mu\u00df.", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "man\u00b7cher", "Held", "sein", "Le\u00b7ben", "en\u00b7den", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PIAT", "NN", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.340": {"text": "Di\u00df alles war dem H\u00e4upt aus Schweden schwer zu wen-", "tokens": ["Di\u00df", "al\u00b7les", "war", "dem", "H\u00e4upt", "aus", "Schwe\u00b7den", "schwer", "zu", "wen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "PIS", "VAFIN", "ART", "NN", "APPR", "NE", "ADJD", "APPR", "TRUNC"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.341": {"text": "Noch gleichwol traut er GOtt und lie\u00df an allen Enden", "tokens": ["Noch", "gleich\u00b7wol", "traut", "er", "Gott", "und", "lie\u00df", "an", "al\u00b7len", "En\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "NN", "KON", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.342": {"text": "um seine Feinde gehn den Vorthel/ H\u00f6cht und Wind/", "tokens": ["um", "sei\u00b7ne", "Fein\u00b7de", "gehn", "den", "Vor\u00b7thel", "/", "H\u00f6cht", "und", "Wind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "VVFIN", "ART", "NN", "$(", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.343": {"text": "und was f\u00fcr Dinge mehr zum Siege dienlich sind/", "tokens": ["und", "was", "f\u00fcr", "Din\u00b7ge", "mehr", "zum", "Sie\u00b7ge", "dien\u00b7lich", "sind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "NN", "ADV", "APPRART", "NN", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.344": {"text": "Eh es zum Schlagen k\u00e4m\u2019 auf seinen Theil zu haben/", "tokens": ["Eh", "es", "zum", "Schla\u00b7gen", "k\u00e4m'", "auf", "sei\u00b7nen", "Theil", "zu", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "PTKZU", "VAINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.345": {"text": "um welche beyde Theil ihr Hertz zu sehen gaben.", "tokens": ["um", "wel\u00b7che", "bey\u00b7de", "Theil", "ihr", "Hertz", "zu", "se\u00b7hen", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIAT", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.346": {"text": "Nichts minders thaten auch die Sachsen/ derer Macht", "tokens": ["Nichts", "min\u00b7ders", "tha\u00b7ten", "auch", "die", "Sach\u00b7sen", "/", "de\u00b7rer", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PIS", "ADV", "VVFIN", "ADV", "ART", "NN", "$(", "PDS", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.347": {"text": "Den lincken Fl\u00fcgel hielt. Es kam zur gro\u00dfen Schlacht/ ", "tokens": ["Den", "lin\u00b7cken", "Fl\u00fc\u00b7gel", "hielt", ".", "Es", "kam", "zur", "gro\u00b7\u00dfen", "Schlacht", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$.", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.348": {"text": "und zwar mit Sachsen erst. Dann Tylli lie\u00df sich d\u00fcncken", "tokens": ["und", "zwar", "mit", "Sach\u00b7sen", "erst", ".", "Dann", "Tyl\u00b7li", "lie\u00df", "sich", "d\u00fcn\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NE", "ADV", "$.", "ADV", "NE", "VVFIN", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.349": {"text": "Das Hertz der neuen Macht das w\u00fcrde leichtlich sincken/", "tokens": ["Das", "Hertz", "der", "neu\u00b7en", "Macht", "das", "w\u00fcr\u00b7de", "leicht\u00b7lich", "sin\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PDS", "VAFIN", "ADJD", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.350": {"text": "Br\u00e4cht er nur die zur Flucht/ so w\u00e4r es halb gesiegt/", "tokens": ["Br\u00e4cht", "er", "nur", "die", "zur", "Flucht", "/", "so", "w\u00e4r", "es", "halb", "ge\u00b7siegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "APPRART", "NN", "$(", "ADV", "VAFIN", "PPER", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.351": {"text": "So h\u00e4tte Schweden schon mit jhm halb au\u00dfgekriegt.", "tokens": ["So", "h\u00e4t\u00b7te", "Schwe\u00b7den", "schon", "mit", "jhm", "halb", "au\u00df\u00b7ge\u00b7kriegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NE", "ADV", "APPR", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.352": {"text": "Seht/ wie der schlauhe Held sein Gl\u00fcck an Fingern z\u00e4hlte/", "tokens": ["Seht", "/", "wie", "der", "schlau\u00b7he", "Held", "sein", "Gl\u00fcck", "an", "Fin\u00b7gern", "z\u00e4hl\u00b7te", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "KOKOM", "ART", "ADJA", "NN", "PPOSAT", "NN", "APPR", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.353": {"text": "Das erste gieng jhm an/ das ander aber f\u00e4hlte.", "tokens": ["Das", "ers\u00b7te", "gieng", "jhm", "an", "/", "das", "an\u00b7der", "a\u00b7ber", "f\u00e4hl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PTKVZ", "$(", "ART", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.354": {"text": "Damit Chur-Sachsen sich zur Schlacht nicht st\u00e4llen kunt", "tokens": ["Da\u00b7mit", "Chur\u00b7Sach\u00b7sen", "sich", "zur", "Schlacht", "nicht", "st\u00e4l\u00b7len", "kunt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "NN", "PRF", "APPRART", "NN", "PTKNEG", "VVFIN", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.355": {"text": "Hielt Tylli viel Gefechts. Er hielt es f\u00fcr den Grund", "tokens": ["Hielt", "Tyl\u00b7li", "viel", "Ge\u00b7fechts", ".", "Er", "hielt", "es", "f\u00fcr", "den", "Grund"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "PIAT", "NN", "$.", "PPER", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.356": {"text": "und Eckstein seines Siegs sie erst zur Flucht zu bringen.", "tokens": ["und", "E\u00b7ckstein", "sei\u00b7nes", "Siegs", "sie", "erst", "zur", "Flucht", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "PPOSAT", "NN", "PPER", "ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.357": {"text": "Hilf GOtt! was lie\u00df er nicht hier f\u00fcr Granaten springen/", "tokens": ["Hilf", "Gott", "!", "was", "lie\u00df", "er", "nicht", "hier", "f\u00fcr", "Gra\u00b7na\u00b7ten", "sprin\u00b7gen", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PWS", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.358": {"text": "Wie blitzt und donndert er bey zweyen Stunden lang/", "tokens": ["Wie", "blitzt", "und", "donn\u00b7dert", "er", "bey", "zwe\u00b7yen", "Stun\u00b7den", "lang", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "KON", "VVFIN", "PPER", "APPR", "VVFIN", "NN", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.359": {"text": "Da weder di\u00df noch das sie auf die Flucht bezwang", "tokens": ["Da", "we\u00b7der", "di\u00df", "noch", "das", "sie", "auf", "die", "Flucht", "be\u00b7zwang"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "PDS", "ADV", "ART", "PPER", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.360": {"text": "Gieng eine Macht auf sie von gantz geharnschten Reitern/", "tokens": ["Gieng", "ei\u00b7ne", "Macht", "auf", "sie", "von", "gantz", "ge\u00b7harnschten", "Rei\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PPER", "APPR", "ADV", "ADJA", "NN", "$("], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.361": {"text": "Hiemit so sahe man viel tausend sich zerscheitern/", "tokens": ["Hie\u00b7mit", "so", "sa\u00b7he", "man", "viel", "tau\u00b7send", "sich", "zer\u00b7schei\u00b7tern", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "ADV", "CARD", "PRF", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.362": {"text": "Den da den dort hinau\u00df. ", "tokens": ["Den", "da", "den", "dort", "hin\u00b7au\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADV", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.363": {"text": "Viel ruffte: Haltet Fu\u00df/ kehrt um und wehret euch/", "tokens": ["Viel", "ruff\u00b7te", ":", "Hal\u00b7tet", "Fu\u00df", "/", "kehrt", "um", "und", "weh\u00b7ret", "euch", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "VVFIN", "NN", "$(", "VVFIN", "PTKVZ", "KON", "VVFIN", "PPER", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.364": {"text": "Erzeigt euch einen Mann/ thut Thaten ihr Soldaten.", "tokens": ["Er\u00b7zeigt", "euch", "ei\u00b7nen", "Mann", "/", "thut", "Tha\u00b7ten", "ihr", "Sol\u00b7da\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$(", "VVFIN", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.365": {"text": "Umbsonst/ Sie giengen durch/ da folgten die Croaten", "tokens": ["Um\u00b7bsonst", "/", "Sie", "gien\u00b7gen", "durch", "/", "da", "folg\u00b7ten", "die", "Croa\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "$(", "PPER", "VVFIN", "APPR", "$(", "ADV", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.366": {"text": "und hieben unter sie/ da\u00df viel im stiche blieb/", "tokens": ["und", "hie\u00b7ben", "un\u00b7ter", "sie", "/", "da\u00df", "viel", "im", "sti\u00b7che", "blieb", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$(", "KOUS", "ADV", "APPRART", "ADJA", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.367": {"text": "Vier Fahnen/ zwey Gesch\u00fctz: In dem man diese trieb", "tokens": ["Vier", "Fah\u00b7nen", "/", "zwey", "Ge\u00b7sch\u00fctz", ":", "In", "dem", "man", "die\u00b7se", "trieb"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["CARD", "NN", "$(", "CARD", "NN", "$.", "APPR", "ART", "PIS", "PDS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.368": {"text": "Lie\u00df Tylli mit der Post den Sieg nach Wien vetmelden/", "tokens": ["Lie\u00df", "Tyl\u00b7li", "mit", "der", "Post", "den", "Sieg", "nach", "Wi\u00b7en", "vet\u00b7mel\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "APPR", "ART", "NN", "ART", "NN", "APPR", "NE", "VVINF", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.369": {"text": "Es war noch viel zu fr\u00fch. Der Kern der b\u00e4sten Helden", "tokens": ["Es", "war", "noch", "viel", "zu", "fr\u00fch", ".", "Der", "Kern", "der", "b\u00e4s\u00b7ten", "Hel\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKA", "ADJD", "$.", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.370": {"text": "War noch nicht angetast. Es war noch nicht gethan.", "tokens": ["War", "noch", "nicht", "an\u00b7ge\u00b7tast", ".", "Es", "war", "noch", "nicht", "ge\u00b7than", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PTKNEG", "VVPP", "$.", "PPER", "VAFIN", "ADV", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.371": {"text": "Gustavus sahe das mit tr\u00fcben Augen an/", "tokens": ["Gus\u00b7ta\u00b7vus", "sa\u00b7he", "das", "mit", "tr\u00fc\u00b7ben", "Au\u00b7gen", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "APPR", "ADJA", "NN", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.372": {"text": "und ruffte so zu GOtt mit tief-gebeugten Knyen:", "tokens": ["und", "ruff\u00b7te", "so", "zu", "Gott", "mit", "tie\u00b7fge\u00b7beug\u00b7ten", "Kn\u00b7yen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.373": {"text": "Sol dann/ O HErr/ dein Volck vor deinen Feinden fliehen/", "tokens": ["Sol", "dann", "/", "O", "Herr", "/", "dein", "Volck", "vor", "dei\u00b7nen", "Fein\u00b7den", "flie\u00b7hen", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "$(", "NE", "NN", "$(", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.374": {"text": "Gib deinem Namen Ehr\u2019 und Sieg/ GOtt unser Hort/", "tokens": ["Gib", "dei\u00b7nem", "Na\u00b7men", "Ehr'", "und", "Sieg", "/", "Gott", "un\u00b7ser", "Hort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "NN", "KON", "NN", "$(", "NN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.375": {"text": "Wir streiten f\u00fcr dein Volck und f\u00fcr dein heilig Wort/", "tokens": ["Wir", "strei\u00b7ten", "f\u00fcr", "dein", "Volck", "und", "f\u00fcr", "dein", "hei\u00b7lig", "Wort", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "KON", "APPR", "PPOSAT", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.376": {"text": "Beweise deine Macht zu deines Nahmens Ehren.", "tokens": ["Be\u00b7wei\u00b7se", "dei\u00b7ne", "Macht", "zu", "dei\u00b7nes", "Nah\u00b7mens", "Eh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.377": {"text": "Nach diesem lie\u00df er sich vor seinen V\u00f6lckern h\u00f6ren:", "tokens": ["Nach", "die\u00b7sem", "lie\u00df", "er", "sich", "vor", "sei\u00b7nen", "V\u00f6l\u00b7ckern", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.378": {"text": "Jhr Br\u00fcder also stehts/ viel b\u00e4sser in den Tod", "tokens": ["Ihr", "Br\u00fc\u00b7der", "al\u00b7so", "stehts", "/", "viel", "b\u00e4s\u00b7ser", "in", "den", "Tod"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "VVFIN", "$(", "ADV", "ADJD", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.379": {"text": "Als in die schn\u00f6de Flucht. Es hat hier etwas Noth/", "tokens": ["Als", "in", "die", "schn\u00f6\u00b7de", "Flucht", ".", "Es", "hat", "hier", "et\u00b7was", "Noth", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "$.", "PPER", "VAFIN", "ADV", "PIAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.380": {"text": "Der Feind treibt ", "tokens": ["Der", "Feind", "treibt"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "VVFIN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.381": {"text": "Gott hat wol \u00f6ffter viel durch wenig Volck geschlagen.", "tokens": ["Gott", "hat", "wol", "\u00f6ff\u00b7ter", "viel", "durch", "we\u00b7nig", "Volck", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "ADJD", "ADV", "APPR", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.382": {"text": "Hier ist kein ander Heyl als GOtt und unser Schwerdt/", "tokens": ["Hier", "ist", "kein", "an\u00b7der", "Heyl", "als", "Gott", "und", "un\u00b7ser", "Schwerdt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "ADJD", "NN", "KOUS", "NN", "KON", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.383": {"text": "Der seinen K\u00f6nig liebt/ voraus f\u00fcr Kirch und Herd", "tokens": ["Der", "sei\u00b7nen", "K\u00f6\u00b7nig", "liebt", "/", "vo\u00b7raus", "f\u00fcr", "Kirch", "und", "Herd"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "VVFIN", "$(", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.384": {"text": "Zu fechten willens ist/ der folge meinen Thaten.", "tokens": ["Zu", "fech\u00b7ten", "wil\u00b7lens", "ist", "/", "der", "fol\u00b7ge", "mei\u00b7nen", "Tha\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VAFIN", "$(", "ART", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.385": {"text": "Di\u00df Wort kaum au\u00dfgesagt/ befiel er die Croaten", "tokens": ["Di\u00df", "Wort", "kaum", "au\u00df\u00b7ge\u00b7sagt", "/", "be\u00b7fiel", "er", "die", "Croa\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "NN", "ADV", "VVPP", "$(", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.386": {"text": "und schlug sie in die Flucht/ da\u00df viel geblieben seyn/", "tokens": ["und", "schlug", "sie", "in", "die", "Flucht", "/", "da\u00df", "viel", "ge\u00b7blie\u00b7ben", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$(", "KOUS", "PIS", "VVPP", "VAINF", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.387": {"text": "Da brachte man die St\u00fcck und Fahnen wieder ein.", "tokens": ["Da", "brach\u00b7te", "man", "die", "St\u00fcck", "und", "Fah\u00b7nen", "wie\u00b7der", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ART", "NN", "KON", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.388": {"text": "Di\u00df Sieghafft au\u00dfgericht entschlo\u00df der tapfre Streiter", "tokens": ["Di\u00df", "Sieg\u00b7hafft", "au\u00df\u00b7ge\u00b7richt", "ent\u00b7schlo\u00df", "der", "tapf\u00b7re", "Strei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "NN", "VVPP", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.389": {"text": "Samt dem von Arnheimb nun mit aller Macht der Reiter/", "tokens": ["Samt", "dem", "von", "Arn\u00b7heimb", "nun", "mit", "al\u00b7ler", "Macht", "der", "Rei\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "APPR", "NE", "ADV", "APPR", "PIAT", "NN", "ART", "NN", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.390": {"text": "(dann noch der meiste Theil von Sachsens Reuterey", "tokens": ["(", "dann", "noch", "der", "meis\u00b7te", "Theil", "von", "Sach\u00b7sens", "Reu\u00b7te\u00b7rey"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["$(", "ADV", "ADV", "ART", "ADJA", "NN", "APPR", "NE", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.391": {"text": "Dem K\u00f6nig standhaft war und ferner alle Treu", "tokens": ["Dem", "K\u00f6\u00b7nig", "stand\u00b7haft", "war", "und", "fer\u00b7ner", "al\u00b7le", "Treu"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VAFIN", "KON", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.392": {"text": "Zu leisten hoch versprach/) in seinen Feind zu br\u00e4chen/", "tokens": ["Zu", "leis\u00b7ten", "hoch", "ver\u00b7sprach", "/", ")", "in", "sei\u00b7nen", "Feind", "zu", "br\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "ADJD", "VVFIN", "$(", "$(", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.393": {"text": "Weil anders seine Macht und hohes Hertz zu schw\u00e4chen", "tokens": ["Weil", "an\u00b7ders", "sei\u00b7ne", "Macht", "und", "ho\u00b7hes", "Hertz", "zu", "schw\u00e4\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPOSAT", "NN", "KON", "ADJA", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.394": {"text": "Kein ander Mittel war. Merck aber di\u00df dabey:", "tokens": ["Kein", "an\u00b7der", "Mit\u00b7tel", "war", ".", "Merck", "a\u00b7ber", "di\u00df", "da\u00b7bey", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "$.", "NN", "ADV", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.395": {"text": "Es nahm der kluge Held bey solcher Reuterey", "tokens": ["Es", "nahm", "der", "klu\u00b7ge", "Held", "bey", "sol\u00b7cher", "Reu\u00b7te\u00b7rey"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.396": {"text": "Verdeckt viel Fu\u00dfvolck mit/ und nichts dann Musquetirer/", "tokens": ["Ver\u00b7deckt", "viel", "Fu\u00df\u00b7volck", "mit", "/", "und", "nichts", "dann", "Mus\u00b7que\u00b7ti\u00b7rer", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "$(", "KON", "PIS", "ADV", "NN", "$("], "meter": "-+-+-+-+--+--", "measure": "iambic.penta.relaxed"}, "line.397": {"text": "Von diesen allen war er selbst der erst\u2019 und F\u00fchrer", "tokens": ["Von", "die\u00b7sen", "al\u00b7len", "war", "er", "selbst", "der", "er\u00b7st'", "und", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "PIS", "VAFIN", "PPER", "ADV", "ART", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.398": {"text": "Dem Feind ins Hertz zu gehn. Er kam/ der Feind hielt", "tokens": ["Dem", "Feind", "ins", "Hertz", "zu", "gehn", ".", "Er", "kam", "/", "der", "Feind", "hielt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$.", "PPER", "VVFIN", "$(", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.399": {"text": "Stand/", "tokens": ["Stand", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.400": {"text": "That gro\u00dfe Gegenwehr/ bi\u00df sich der K\u00f6nig wand", "tokens": ["That", "gro\u00b7\u00dfe", "Ge\u00b7gen\u00b7wehr", "/", "bi\u00df", "sich", "der", "K\u00f6\u00b7nig", "wand"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "ADJA", "NN", "$(", "APPR", "PRF", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.401": {"text": "Halb da halb dort hinaus/ da giengen die Musqeten/", "tokens": ["Halb", "da", "halb", "dort", "hin\u00b7aus", "/", "da", "gien\u00b7gen", "die", "Mus\u00b7qe\u00b7ten", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "ADJD", "ADV", "APZR", "$(", "ADV", "VVFIN", "ART", "NN", "$("], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.402": {"text": "Da waren alle Feind\u2019 in unverhofften N\u00f6then.", "tokens": ["Da", "wa\u00b7ren", "al\u00b7le", "Feind'", "in", "un\u00b7ver\u00b7hoff\u00b7ten", "N\u00f6\u00b7then", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.403": {"text": "Das erste Glied lag blat/ das ander auf dem Kny/", "tokens": ["Das", "ers\u00b7te", "Glied", "lag", "blat", "/", "das", "an\u00b7der", "auf", "dem", "Kny", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADJD", "$(", "ART", "ADJD", "APPR", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.404": {"text": "Das dritte stund gerad/ und also hatten sie", "tokens": ["Das", "drit\u00b7te", "stund", "ge\u00b7rad", "/", "und", "al\u00b7so", "hat\u00b7ten", "sie"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "KON", "ADV", "VAFIN", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.405": {"text": "Des Tylli Reuterey zum fliehen angestrenget/", "tokens": ["Des", "Tyl\u00b7li", "Reu\u00b7te\u00b7rey", "zum", "flie\u00b7hen", "an\u00b7ge\u00b7stren\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "APPRART", "VVINF", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.406": {"text": "Worauf der K\u00f6nig sie gewaltig hat bedr\u00e4nget/", "tokens": ["Wo\u00b7rauf", "der", "K\u00f6\u00b7nig", "sie", "ge\u00b7wal\u00b7tig", "hat", "be\u00b7dr\u00e4n\u00b7get", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "PPER", "ADJD", "VAFIN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.407": {"text": "umbringet und gew\u00fcrgt. Mit diesem war die Spitz", "tokens": ["um\u00b7brin\u00b7get", "und", "ge\u00b7w\u00fcrgt", ".", "Mit", "die\u00b7sem", "war", "die", "Spitz"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "KON", "VVPP", "$.", "APPR", "PDAT", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.408": {"text": "Vom Degen abgezwickt. Nun galt es das Gesch\u00fctz/", "tokens": ["Vom", "De\u00b7gen", "ab\u00b7ge\u00b7zwickt", ".", "Nun", "galt", "es", "das", "Ge\u00b7sch\u00fctz", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$.", "ADV", "VVFIN", "PPER", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.409": {"text": "Auch dieses fiel jhm heim/ nun sechszehn tausend Seelen", "tokens": ["Auch", "die\u00b7ses", "fiel", "jhm", "heim", "/", "nun", "sechs\u00b7zehn", "tau\u00b7send", "See\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPER", "PTKVZ", "$(", "ADV", "CARD", "CARD", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.410": {"text": "Zu Fu\u00df/ er siegt auch hier und schickte theils den H\u00f6len/", "tokens": ["Zu", "Fu\u00df", "/", "er", "siegt", "auch", "hier", "und", "schick\u00b7te", "theils", "den", "H\u00f6\u00b7len", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "PPER", "VVFIN", "ADV", "ADV", "KON", "VVFIN", "ADV", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.411": {"text": "Theils nach den Banden zu. Der sich hat weg gebracht", "tokens": ["Theils", "nach", "den", "Ban\u00b7den", "zu", ".", "Der", "sich", "hat", "weg", "ge\u00b7bracht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "PTKVZ", "$.", "ART", "PRF", "VAFIN", "ADV", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.412": {"text": "Der that es einig nur durch Hilff der finstern Nacht/", "tokens": ["Der", "that", "es", "ei\u00b7nig", "nur", "durch", "Hilff", "der", "fins\u00b7tern", "Nacht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.413": {"text": "Die endlich dem Gew\u00fcrg\u2019 ein Ende muste geben/", "tokens": ["Die", "end\u00b7lich", "dem", "Ge\u00b7w\u00fcr\u00b7g'", "ein", "En\u00b7de", "mus\u00b7te", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ART", "NN", "VMFIN", "VVINF", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.414": {"text": "Sonst h\u00e4tte niemand sich zu Fu\u00dfe bey dem Leben", "tokens": ["Sonst", "h\u00e4t\u00b7te", "nie\u00b7mand", "sich", "zu", "Fu\u00b7\u00dfe", "bey", "dem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIS", "PRF", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.415": {"text": "Zu halten Zeit gehabt. Auf solches lie\u00df der Held", "tokens": ["Zu", "hal\u00b7ten", "Zeit", "ge\u00b7habt", ".", "Auf", "sol\u00b7ches", "lie\u00df", "der", "Held"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "NN", "VAPP", "$.", "APPR", "PIS", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.416": {"text": "und gro\u00dfe Sieges-F\u00fcrst im Blut-gef\u00e4rbten Feld\u2019", "tokens": ["und", "gro\u00b7\u00dfe", "Sie\u00b7ges\u00b7F\u00fcrst", "im", "Blut\u00b7ge\u00b7f\u00e4rb\u00b7ten", "Feld'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "APPRART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.417": {"text": "Ein Danck-Fest seinem GOTT/ als Siegs-Erhaltern/ hal-", "tokens": ["Ein", "Dan\u00b7ck\u00b7Fest", "sei\u00b7nem", "GoTT", "/", "als", "Siegs\u00b7Er\u00b7hal\u00b7tern", "/", "ha\u00b7l"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word"], "pos": ["ART", "NN", "PPOSAT", "NN", "$(", "KOUS", "NN", "$(", "TRUNC"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.418": {"text": "Man sah jhn selber auch die tapfren H\u00e4nde falten", "tokens": ["Man", "sah", "jhn", "sel\u00b7ber", "auch", "die", "tapf\u00b7ren", "H\u00e4n\u00b7de", "fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.419": {"text": "und mit gebeugtem Kny dem H\u00f6chsten danckbar seyn.", "tokens": ["und", "mit", "ge\u00b7beug\u00b7tem", "Kny", "dem", "H\u00f6chs\u00b7ten", "dan\u00b7ck\u00b7bar", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ADJA", "NN", "ART", "NN", "ADJD", "VAINF", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.420": {"text": "Nach solchem lieferte man jhm die Fahnen ein/", "tokens": ["Nach", "sol\u00b7chem", "lie\u00b7fer\u00b7te", "man", "jhm", "die", "Fah\u00b7nen", "ein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VVFIN", "PIS", "PPER", "ART", "NN", "ART", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.421": {"text": "Gefangene/ Gesch\u00fctz und was aus solchem Streiten", "tokens": ["Ge\u00b7fan\u00b7ge\u00b7ne", "/", "Ge\u00b7sch\u00fctz", "und", "was", "aus", "sol\u00b7chem", "Strei\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "NN", "KON", "PWS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.422": {"text": "Den ", "tokens": ["Den"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}, "line.423": {"text": "Zu sehen lustig macht. Von Fahnen zw\u00f6lfmal zehn", "tokens": ["Zu", "se\u00b7hen", "lus\u00b7tig", "macht", ".", "Von", "Fah\u00b7nen", "zw\u00f6lf\u00b7mal", "zehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "ADJD", "VVFIN", "$.", "APPR", "NN", "ADV", "CARD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.424": {"text": "und dreymal drey darzu. Von Generalen zwen.", "tokens": ["und", "drey\u00b7mal", "drey", "dar\u00b7zu", ".", "Von", "Ge\u00b7ne\u00b7ra\u00b7len", "zwen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "CARD", "PAV", "$.", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.425": {"text": "Von F\u00fcrsten einen/ und von Grafen/ wei\u00df ich/ sieben/", "tokens": ["Von", "F\u00fcrs\u00b7ten", "ei\u00b7nen", "/", "und", "von", "Gra\u00b7fen", "/", "wei\u00df", "ich", "/", "sie\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "ART", "$(", "KON", "APPR", "NN", "$(", "VVFIN", "PPER", "$(", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.426": {"text": "Wobey der Feinde fast in achtmal tausend blieben.", "tokens": ["Wo\u00b7bey", "der", "Fein\u00b7de", "fast", "in", "acht\u00b7mal", "tau\u00b7send", "blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "APPR", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.427": {"text": "Von St\u00fccken f\u00fcnfmal f\u00fcnf mit aller Zubeh\u00f6r.", "tokens": ["Von", "St\u00fc\u00b7cken", "f\u00fcnf\u00b7mal", "f\u00fcnf", "mit", "al\u00b7ler", "Zu\u00b7be\u00b7h\u00f6r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "CARD", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.428": {"text": "Mit welchem L\u00f6uen-Muth und K\u00f6niglicher Ehr\u2019", "tokens": ["Mit", "wel\u00b7chem", "L\u00f6uen\u00b7Muth", "und", "K\u00f6\u00b7nig\u00b7li\u00b7cher", "Ehr'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "KON", "NN", "NN"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.429": {"text": "In dieser Schlacht den Sieg der K\u00f6nig hab\u2019 erfochten", "tokens": ["In", "die\u00b7ser", "Schlacht", "den", "Sieg", "der", "K\u00f6\u00b7nig", "hab'", "er\u00b7foch\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "ART", "NN", "ART", "NN", "VAFIN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.430": {"text": "Wird keiner Zeit genug von Weisen eingeflochten.", "tokens": ["Wird", "kei\u00b7ner", "Zeit", "ge\u00b7nug", "von", "Wei\u00b7sen", "ein\u00b7ge\u00b7floch\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.431": {"text": "Des Feindes Macht war gro\u00df/ versucht/ unabgeschw\u00e4cht/", "tokens": ["Des", "Fein\u00b7des", "Macht", "war", "gro\u00df", "/", "ver\u00b7sucht", "/", "un\u00b7ab\u00b7ge\u00b7schw\u00e4cht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "ADJD", "$(", "VVPP", "$(", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.432": {"text": "Von vielen Siegen keck/ und hatte zum Gefecht\u2019", "tokens": ["Von", "vie\u00b7len", "Sie\u00b7gen", "keck", "/", "und", "hat\u00b7te", "zum", "Ge\u00b7fecht'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "ADJD", "$(", "KON", "VAFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.433": {"text": "Ein vorthelhafftig Ort/ auch Zeit sich zu beschicken/", "tokens": ["Ein", "vor\u00b7thel\u00b7haff\u00b7tig", "Ort", "/", "auch", "Zeit", "sich", "zu", "be\u00b7schi\u00b7cken", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$(", "ADV", "NN", "PRF", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.434": {"text": "Des K\u00f6nigs aber war entbl\u00f6st von b\u00e4sten St\u00fccken/", "tokens": ["Des", "K\u00f6\u00b7nigs", "a\u00b7ber", "war", "ent\u00b7bl\u00f6st", "von", "b\u00e4s\u00b7ten", "St\u00fc\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "VVPP", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.435": {"text": "Vom Reisen abgematt/ darzu denselben Tag", "tokens": ["Vom", "Rei\u00b7sen", "ab\u00b7ge\u00b7matt", "/", "dar\u00b7zu", "den\u00b7sel\u00b7ben", "Tag"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "VVPP", "$(", "PAV", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.436": {"text": "Gantz n\u00fcchtern/ blieb es auch/ bi\u00df da\u00df der gro\u00dfe Schlag", "tokens": ["Gantz", "n\u00fcch\u00b7tern", "/", "blieb", "es", "auch", "/", "bi\u00df", "da\u00df", "der", "gro\u00b7\u00dfe", "Schlag"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$(", "VVFIN", "PPER", "ADV", "$(", "APPR", "KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.437": {"text": "Sein Ende hatt\u2019 erreicht. Der K\u00f6nig selbst im gleichen/", "tokens": ["Sein", "En\u00b7de", "hatt'", "er\u00b7reicht", ".", "Der", "K\u00f6\u00b7nig", "selbst", "im", "glei\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$.", "ART", "NN", "ADV", "APPRART", "ADJA", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.438": {"text": "Der auch nur einen Trunck von Wasser jhm zu reichen", "tokens": ["Der", "auch", "nur", "ei\u00b7nen", "Trunck", "von", "Was\u00b7ser", "jhm", "zu", "rei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "ADV", "ART", "NN", "APPR", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.439": {"text": "Sehr oft geruffen hatt. Hier war nur eitel Blut/", "tokens": ["Sehr", "oft", "ge\u00b7ruf\u00b7fen", "hatt", ".", "Hier", "war", "nur", "ei\u00b7tel", "Blut", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "VAFIN", "$.", "ADV", "VAFIN", "ADV", "ADJD", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.440": {"text": "Seht was ein K\u00f6nig nicht \u00fcm seine Leuthe thut!", "tokens": ["Seht", "was", "ein", "K\u00f6\u00b7nig", "nicht", "\u00fcm", "sei\u00b7ne", "Leu\u00b7the", "thut", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PWS", "ART", "NN", "PTKNEG", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.441": {"text": "Kein Mensch erzehlts genug/ wie gleich und in dem Bogen", "tokens": ["Kein", "Mensch", "er\u00b7zehlts", "ge\u00b7nug", "/", "wie", "gleich", "und", "in", "dem", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN", "ADV", "$(", "KOKOM", "ADV", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.442": {"text": "Viel vieler Kugel Art \u00fcm jhn herum geflogen/", "tokens": ["Viel", "vie\u00b7ler", "Ku\u00b7gel", "Art", "\u00fcm", "jhn", "he\u00b7rum", "ge\u00b7flo\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "NN", "VVFIN", "PPER", "APZR", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.443": {"text": "Dar\u00fcber er sich doch nicht einmal hatt\u2019 entsetzt/", "tokens": ["Da\u00b7r\u00fc\u00b7ber", "er", "sich", "doch", "nicht", "ein\u00b7mal", "hatt'", "ent\u00b7setzt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "ADV", "PTKNEG", "ADV", "VAFIN", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.444": {"text": "und blieb auch/ wie man wei\u00df/ hier g\u00e4ntzlich unverletzt/", "tokens": ["und", "blieb", "auch", "/", "wie", "man", "wei\u00df", "/", "hier", "g\u00e4ntz\u00b7lich", "un\u00b7ver\u00b7letzt", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$(", "PWAV", "PIS", "VVFIN", "$(", "ADV", "ADJD", "ADJD", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.445": {"text": "Da er doch weder Helm noch einen Harnisch f\u00fchrte/", "tokens": ["Da", "er", "doch", "we\u00b7der", "Helm", "noch", "ei\u00b7nen", "Har\u00b7nisch", "f\u00fchr\u00b7te", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "KON", "NN", "ADV", "ART", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.446": {"text": "Wobey man seinen Muht als eines L\u00f6uen sp\u00fcrte.", "tokens": ["Wo\u00b7bey", "man", "sei\u00b7nen", "Muht", "als", "ei\u00b7nes", "L\u00f6u\u00b7en", "sp\u00fcr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPOSAT", "NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.447": {"text": "Was nenn\u2019 ich jhn allein/ der ungeharnischt war/", "tokens": ["Was", "nenn'", "ich", "jhn", "al\u00b7lein", "/", "der", "un\u00b7ge\u00b7har\u00b7nischt", "war", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "ADV", "$(", "ART", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.448": {"text": "Es war es ins gemein auch seine gantze Schaar.", "tokens": ["Es", "war", "es", "ins", "ge\u00b7mein", "auch", "sei\u00b7ne", "gant\u00b7ze", "Schaar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPRART", "ADJD", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.449": {"text": "Dargegen war der Feind vom H\u00e4upte zu den F\u00fcssen", "tokens": ["Dar\u00b7ge\u00b7gen", "war", "der", "Feind", "vom", "H\u00e4up\u00b7te", "zu", "den", "F\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VAFIN", "ART", "NN", "APPRART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.450": {"text": "In Eisen eingepackt. Hierbey ist auch zu wissen/", "tokens": ["In", "Ei\u00b7sen", "ein\u00b7ge\u00b7packt", ".", "Hier\u00b7bey", "ist", "auch", "zu", "wis\u00b7sen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "PAV", "VAFIN", "ADV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.451": {"text": "Da\u00df eben diesen Tag/ an dem di\u00df Blutbald war/", "tokens": ["Da\u00df", "e\u00b7ben", "die\u00b7sen", "Tag", "/", "an", "dem", "di\u00df", "Blut\u00b7bald", "war", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDAT", "NN", "$(", "APPR", "ART", "PDS", "NN", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.452": {"text": "Das arme Basewalck im abgewichnem Jahr", "tokens": ["Das", "ar\u00b7me", "Ba\u00b7se\u00b7walck", "im", "ab\u00b7ge\u00b7wich\u00b7nem", "Jahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.453": {"text": "Erschrecklich leyden must\u2019/ es ist nicht au\u00dfzuspr\u00e4chen/", "tokens": ["Er\u00b7schreck\u00b7lich", "ley\u00b7den", "must'", "/", "es", "ist", "nicht", "au\u00df\u00b7zu\u00b7spr\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVINF", "VMFIN", "$(", "PPER", "VAFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.454": {"text": "Wie man gehauset hat mit Weib- und Kinder schw\u00e4chen/", "tokens": ["Wie", "man", "ge\u00b7hau\u00b7set", "hat", "mit", "Weib", "und", "Kin\u00b7der", "schw\u00e4\u00b7chen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVPP", "VAFIN", "APPR", "TRUNC", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.455": {"text": "Mit Morden und mit Brand. Hier siht man GOttes", "tokens": ["Mit", "Mor\u00b7den", "und", "mit", "Brand", ".", "Hier", "siht", "man", "Got\u00b7tes"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "APPR", "NN", "$.", "ADV", "VVFIN", "PIS", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.456": {"text": "Rach/", "tokens": ["Rach", "/"], "token_info": ["word", "punct"], "pos": ["NN", "$("], "meter": "+", "measure": "single.up"}, "line.457": {"text": "Kommt sie gleich langsam an/ so bleibt sie doch nicht nach.", "tokens": ["Kommt", "sie", "gleich", "lang\u00b7sam", "an", "/", "so", "bleibt", "sie", "doch", "nicht", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "PTKVZ", "$(", "ADV", "VVFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}