{"dta.poem.1215": {"metadata": {"author": {"name": "Abschatz, Hans Assmann von", "birth": "N.A.", "death": "N.A."}, "title": "Jagt der Liebe.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1704", "urn": "urn:nbn:de:kobv:b4-200905199889", "language": ["de:0.99"], "booktitle": "Abschatz, Hans Assmann von: Poetische Ubersetzungen und Gedichte. Leipzig, 1704."}, "poem": {"stanza.1": {"line.1": {"text": "Indem du gehest nach durch Feld und Wald den Thieren/", "tokens": ["In\u00b7dem", "du", "ge\u00b7hest", "nach", "durch", "Feld", "und", "Wald", "den", "Thie\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "APPR", "NN", "KON", "NN", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Schau ich/ ob ich ein Wild der Venus fangen kan.", "tokens": ["Schau", "ich", "/", "ob", "ich", "ein", "Wild", "der", "Ve\u00b7nus", "fan\u00b7gen", "kan", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$(", "KOUS", "PPER", "ART", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Du redest offt was stumm/ und ich was taub ist/ an/", "tokens": ["Du", "re\u00b7dest", "offt", "was", "stumm", "/", "und", "ich", "was", "taub", "ist", "/", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PWS", "ADJD", "$(", "KON", "PPER", "PIS", "ADJD", "VAFIN", "$(", "PTKVZ", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Du l\u00e4st die Grausamkeit/ ich k\u00fchne Freyheit sp\u00fcren.", "tokens": ["Du", "l\u00e4st", "die", "Grau\u00b7sam\u00b7keit", "/", "ich", "k\u00fch\u00b7ne", "Frey\u00b7heit", "sp\u00fc\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PPER", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Du l\u00e4st dich einen Hirsch durch Berg und Th\u00e4ler f\u00fchren/", "tokens": ["Du", "l\u00e4st", "dich", "ei\u00b7nen", "Hirsch", "durch", "Berg", "und", "Th\u00e4\u00b7ler", "f\u00fch\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "APPR", "NN", "KON", "NN", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mich bringt ein sch\u00f6nes Bild auff unbekannte Bahn.", "tokens": ["Mich", "bringt", "ein", "sch\u00f6\u00b7nes", "Bild", "auff", "un\u00b7be\u00b7kann\u00b7te", "Bahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du setzest Strick und Netz/ ich Wort und Reden dran/", "tokens": ["Du", "set\u00b7zest", "Strick", "und", "Netz", "/", "ich", "Wort", "und", "Re\u00b7den", "dran", "/"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$(", "PPER", "NN", "KON", "NN", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Wir m\u00fcssen beyderseits offt M\u00fch und Zeit verlieren.", "tokens": ["Wir", "m\u00fcs\u00b7sen", "bey\u00b7der\u00b7seits", "offt", "M\u00fch", "und", "Zeit", "ver\u00b7lie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ADV", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wir fragen beyde nichts nach Regen oder Wind/", "tokens": ["Wir", "fra\u00b7gen", "bey\u00b7de", "nichts", "nach", "Re\u00b7gen", "o\u00b7der", "Wind", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "PIS", "APPR", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und wie dich offtermahls die falsche Spur betriegt/", "tokens": ["Und", "wie", "dich", "off\u00b7ter\u00b7mahls", "die", "fal\u00b7sche", "Spur", "be\u00b7triegt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So werd\u2019 in eitler Furcht und Hoffnung ich gewiegt.", "tokens": ["So", "werd'", "in", "eit\u00b7ler", "Furcht", "und", "Hoff\u00b7nung", "ich", "ge\u00b7wiegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ADJA", "NN", "KON", "NN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Nur di\u00df ist noch/ in dem wir unterschieden sind:", "tokens": ["Nur", "di\u00df", "ist", "noch", "/", "in", "dem", "wir", "un\u00b7ter\u00b7schie\u00b7den", "sind", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VAFIN", "ADV", "$(", "APPR", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Du hast der M\u00fche Lohn zuweilen schon empfangen/", "tokens": ["Du", "hast", "der", "M\u00fc\u00b7he", "Lohn", "zu\u00b7wei\u00b7len", "schon", "emp\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "NN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Mir aber ist bi\u00dfher kein Wild noch eingegangen.", "tokens": ["Mir", "a\u00b7ber", "ist", "bi\u00df\u00b7her", "kein", "Wild", "noch", "ein\u00b7ge\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VAFIN", "ADV", "PIAT", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}