{"textgrid.poem.48284": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Das Trauerspiel von Afghanistan", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der Schnee leis st\u00e4ubend vom Himmel f\u00e4llt,", "tokens": ["Der", "Schnee", "leis", "st\u00e4u\u00b7bend", "vom", "Him\u00b7mel", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Reiter vor Dschellalabad h\u00e4lt.", "tokens": ["Ein", "Rei\u00b7ter", "vor", "Dschel\u00b7la\u00b7la\u00b7bad", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbwer da!\u00ab \u2013 \u00bbEin britischer Reitersmann,", "tokens": ["\u00bb", "wer", "da", "!", "\u00ab", "\u2013", "\u00bb", "Ein", "bri\u00b7ti\u00b7scher", "Rei\u00b7ters\u00b7mann", ","], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "$.", "$(", "$(", "$(", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Bringe Botschaft aus Afghanistan.\u00ab", "tokens": ["Brin\u00b7ge", "Bot\u00b7schaft", "aus", "Af\u00b7gha\u00b7nis\u00b7tan", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "APPR", "NE", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "\u00bbafghanistan!\u00ab er sprach es so matt;", "tokens": ["\u00bb", "af\u00b7gha\u00b7nis\u00b7tan", "!", "\u00ab", "er", "sprach", "es", "so", "matt", ";"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es umdr\u00e4ngt den Reiter die halbe Stadt,", "tokens": ["Es", "um\u00b7dr\u00e4ngt", "den", "Rei\u00b7ter", "die", "hal\u00b7be", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sir Robert Sale, der Kommandant,", "tokens": ["Sir", "Ro\u00b7bert", "Sa\u00b7le", ",", "der", "Kom\u00b7man\u00b7dant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hebt ihn vom Rosse mit eigener Hand.", "tokens": ["Hebt", "ihn", "vom", "Ros\u00b7se", "mit", "ei\u00b7ge\u00b7ner", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.3": {"line.1": {"text": "Sie f\u00fchren ins steinerne Wachthaus ihn,", "tokens": ["Sie", "f\u00fch\u00b7ren", "ins", "stei\u00b7ner\u00b7ne", "Wacht\u00b7haus", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "PPER", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie setzen ihn nieder an den Kamin,", "tokens": ["Sie", "set\u00b7zen", "ihn", "nie\u00b7der", "an", "den", "Ka\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie w\u00e4rmt ihn das Feuer, wie labt ihn das Licht,", "tokens": ["Wie", "w\u00e4rmt", "ihn", "das", "Feu\u00b7er", ",", "wie", "labt", "ihn", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "NN", "$,", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Er atmet hoch auf und dankt und spricht:", "tokens": ["Er", "at\u00b7met", "hoch", "auf", "und", "dankt", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.4": {"line.1": {"text": "\u00bbwir waren dreizehntausend Mann,", "tokens": ["\u00bb", "wir", "wa\u00b7ren", "drei\u00b7zehn\u00b7tau\u00b7send", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Kabul unser Zug begann,", "tokens": ["Von", "Ka\u00b7bul", "un\u00b7ser", "Zug", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Soldaten, F\u00fchrer, Weib und Kind", "tokens": ["Sol\u00b7da\u00b7ten", ",", "F\u00fch\u00b7rer", ",", "Weib", "und", "Kind"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstarrt, erschlagen, verraten sind.", "tokens": ["Er\u00b7starrt", ",", "er\u00b7schla\u00b7gen", ",", "ver\u00b7ra\u00b7ten", "sind", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.5": {"line.1": {"text": "Zersprengt ist unser ganzes Heer,", "tokens": ["Zer\u00b7sprengt", "ist", "un\u00b7ser", "gan\u00b7zes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was lebt, irrt drau\u00dfen in Nacht umher,", "tokens": ["Was", "lebt", ",", "irrt", "drau\u00b7\u00dfen", "in", "Nacht", "um\u00b7her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mir hat ein Gott die Rettung geg\u00f6nnt,", "tokens": ["Mir", "hat", "ein", "Gott", "die", "Ret\u00b7tung", "ge\u00b7g\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Seht zu, ob den Rest ihr retten k\u00f6nnt.\u00ab", "tokens": ["Seht", "zu", ",", "ob", "den", "Rest", "ihr", "ret\u00b7ten", "k\u00f6nnt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "PPER", "VVINF", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.6": {"line.1": {"text": "Sir Robert stieg auf den Festungswall,", "tokens": ["Sir", "Ro\u00b7bert", "stieg", "auf", "den", "Fes\u00b7tungs\u00b7wall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Offiziere, Soldaten folgten ihm all,", "tokens": ["Of\u00b7fi\u00b7zie\u00b7re", ",", "Sol\u00b7da\u00b7ten", "folg\u00b7ten", "ihm", "all", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "$,", "NN", "VVFIN", "PPER", "PIAT", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Sir Robert sprach: \u00bbDer Schnee f\u00e4llt dicht,", "tokens": ["Sir", "Ro\u00b7bert", "sprach", ":", "\u00bb", "Der", "Schnee", "f\u00e4llt", "dicht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "$.", "$(", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns suchen, sie k\u00f6nnen uns finden nicht.", "tokens": ["Die", "uns", "su\u00b7chen", ",", "sie", "k\u00f6n\u00b7nen", "uns", "fin\u00b7den", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$,", "PPER", "VMFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.7": {"line.1": {"text": "Sie irren wie Blinde und sind uns so nah,", "tokens": ["Sie", "ir\u00b7ren", "wie", "Blin\u00b7de", "und", "sind", "uns", "so", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So la\u00dft sie's ", "tokens": ["So", "la\u00dft", "sie's"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVIMP", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Stimmt an ein Lied von Heimat und Haus,", "tokens": ["Stimmt", "an", "ein", "Lied", "von", "Hei\u00b7mat", "und", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Trompeter, blast in die Nacht hinaus!\u00ab", "tokens": ["Trom\u00b7pe\u00b7ter", ",", "blast", "in", "die", "Nacht", "hin\u00b7aus", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.8": {"line.1": {"text": "Da huben sie an und sie wurden's nicht m\u00fcd',", "tokens": ["Da", "hu\u00b7ben", "sie", "an", "und", "sie", "wur\u00b7den's", "nicht", "m\u00fcd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch die Nacht hin klang es Lied um Lied,", "tokens": ["Durch", "die", "Nacht", "hin", "klang", "es", "Lied", "um", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Erst englische Lieder mit fr\u00f6hlichem Klang,", "tokens": ["Erst", "eng\u00b7li\u00b7sche", "Lie\u00b7der", "mit", "fr\u00f6h\u00b7li\u00b7chem", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Dann Hochlandslieder wie Klagegesang.", "tokens": ["Dann", "Hoch\u00b7lands\u00b7lie\u00b7der", "wie", "Kla\u00b7ge\u00b7ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.9": {"line.1": {"text": "Sie bliesen die Nacht und \u00fcber den Tag,", "tokens": ["Sie", "blie\u00b7sen", "die", "Nacht", "und", "\u00fc\u00b7ber", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Laut, wie nur die Liebe rufen mag,", "tokens": ["Laut", ",", "wie", "nur", "die", "Lie\u00b7be", "ru\u00b7fen", "mag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PWAV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Sie bliesen \u2013 es kam die zweite Nacht,", "tokens": ["Sie", "blie\u00b7sen", "\u2013", "es", "kam", "die", "zwei\u00b7te", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Umsonst, da\u00df ihr ruft, umsonst, da\u00df ihr wacht.", "tokens": ["Um\u00b7sonst", ",", "da\u00df", "ihr", "ruft", ",", "um\u00b7sonst", ",", "da\u00df", "ihr", "wacht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.10": {"line.1": {"text": "Die h\u00f6ren sollen, sie h\u00f6ren nicht mehr,", "tokens": ["Die", "h\u00f6\u00b7ren", "sol\u00b7len", ",", "sie", "h\u00f6\u00b7ren", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "$,", "PPER", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vernichtet ist das ganze Heer,", "tokens": ["Ver\u00b7nich\u00b7tet", "ist", "das", "gan\u00b7ze", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit dreizehntausend der Zug begann,", "tokens": ["Mit", "drei\u00b7zehn\u00b7tau\u00b7send", "der", "Zug", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.11": {"line.1": {"text": "Der Schnee leis st\u00e4ubend vom Himmel f\u00e4llt,", "tokens": ["Der", "Schnee", "leis", "st\u00e4u\u00b7bend", "vom", "Him\u00b7mel", "f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJD", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ein Reiter vor Dschellalabad h\u00e4lt.", "tokens": ["Ein", "Rei\u00b7ter", "vor", "Dschel\u00b7la\u00b7la\u00b7bad", "h\u00e4lt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VVFIN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "\u00bbwer da!\u00ab \u2013 \u00bbEin britischer Reitersmann,", "tokens": ["\u00bb", "wer", "da", "!", "\u00ab", "\u2013", "\u00bb", "Ein", "bri\u00b7ti\u00b7scher", "Rei\u00b7ters\u00b7mann", ","], "token_info": ["punct", "word", "word", "punct", "punct", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "ADV", "$.", "$(", "$(", "$(", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.4": {"text": "Bringe Botschaft aus Afghanistan.\u00ab", "tokens": ["Brin\u00b7ge", "Bot\u00b7schaft", "aus", "Af\u00b7gha\u00b7nis\u00b7tan", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "NN", "APPR", "NE", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "\u00bbafghanistan!\u00ab er sprach es so matt;", "tokens": ["\u00bb", "af\u00b7gha\u00b7nis\u00b7tan", "!", "\u00ab", "er", "sprach", "es", "so", "matt", ";"], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "$(", "PPER", "VVFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Es umdr\u00e4ngt den Reiter die halbe Stadt,", "tokens": ["Es", "um\u00b7dr\u00e4ngt", "den", "Rei\u00b7ter", "die", "hal\u00b7be", "Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sir Robert Sale, der Kommandant,", "tokens": ["Sir", "Ro\u00b7bert", "Sa\u00b7le", ",", "der", "Kom\u00b7man\u00b7dant", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "NE", "NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Hebt ihn vom Rosse mit eigener Hand.", "tokens": ["Hebt", "ihn", "vom", "Ros\u00b7se", "mit", "ei\u00b7ge\u00b7ner", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+--+--+--+", "measure": "dactylic.tetra"}}, "stanza.13": {"line.1": {"text": "Sie f\u00fchren ins steinerne Wachthaus ihn,", "tokens": ["Sie", "f\u00fch\u00b7ren", "ins", "stei\u00b7ner\u00b7ne", "Wacht\u00b7haus", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "PPER", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie setzen ihn nieder an den Kamin,", "tokens": ["Sie", "set\u00b7zen", "ihn", "nie\u00b7der", "an", "den", "Ka\u00b7min", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wie w\u00e4rmt ihn das Feuer, wie labt ihn das Licht,", "tokens": ["Wie", "w\u00e4rmt", "ihn", "das", "Feu\u00b7er", ",", "wie", "labt", "ihn", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ART", "NN", "$,", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Er atmet hoch auf und dankt und spricht:", "tokens": ["Er", "at\u00b7met", "hoch", "auf", "und", "dankt", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.14": {"line.1": {"text": "\u00bbwir waren dreizehntausend Mann,", "tokens": ["\u00bb", "wir", "wa\u00b7ren", "drei\u00b7zehn\u00b7tau\u00b7send", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "CARD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von Kabul unser Zug begann,", "tokens": ["Von", "Ka\u00b7bul", "un\u00b7ser", "Zug", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Soldaten, F\u00fchrer, Weib und Kind", "tokens": ["Sol\u00b7da\u00b7ten", ",", "F\u00fch\u00b7rer", ",", "Weib", "und", "Kind"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Erstarrt, erschlagen, verraten sind.", "tokens": ["Er\u00b7starrt", ",", "er\u00b7schla\u00b7gen", ",", "ver\u00b7ra\u00b7ten", "sind", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVPP", "$,", "VVPP", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Zersprengt ist unser ganzes Heer,", "tokens": ["Zer\u00b7sprengt", "ist", "un\u00b7ser", "gan\u00b7zes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was lebt, irrt drau\u00dfen in Nacht umher,", "tokens": ["Was", "lebt", ",", "irrt", "drau\u00b7\u00dfen", "in", "Nacht", "um\u00b7her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "$,", "VVFIN", "ADV", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Mir hat ein Gott die Rettung geg\u00f6nnt,", "tokens": ["Mir", "hat", "ein", "Gott", "die", "Ret\u00b7tung", "ge\u00b7g\u00f6nnt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Seht zu, ob den Rest ihr retten k\u00f6nnt.\u00ab", "tokens": ["Seht", "zu", ",", "ob", "den", "Rest", "ihr", "ret\u00b7ten", "k\u00f6nnt", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "PPER", "VVINF", "VVFIN", "$.", "$("], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.16": {"line.1": {"text": "Sir Robert stieg auf den Festungswall,", "tokens": ["Sir", "Ro\u00b7bert", "stieg", "auf", "den", "Fes\u00b7tungs\u00b7wall", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Offiziere, Soldaten folgten ihm all,", "tokens": ["Of\u00b7fi\u00b7zie\u00b7re", ",", "Sol\u00b7da\u00b7ten", "folg\u00b7ten", "ihm", "all", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["FM.la", "$,", "NN", "VVFIN", "PPER", "PIAT", "$,"], "meter": "+-+--+-+--+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Sir Robert sprach: \u00bbDer Schnee f\u00e4llt dicht,", "tokens": ["Sir", "Ro\u00b7bert", "sprach", ":", "\u00bb", "Der", "Schnee", "f\u00e4llt", "dicht", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VVFIN", "$.", "$(", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die uns suchen, sie k\u00f6nnen uns finden nicht.", "tokens": ["Die", "uns", "su\u00b7chen", ",", "sie", "k\u00f6n\u00b7nen", "uns", "fin\u00b7den", "nicht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "$,", "PPER", "VMFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}}, "stanza.17": {"line.1": {"text": "Sie irren wie Blinde und sind uns so nah,", "tokens": ["Sie", "ir\u00b7ren", "wie", "Blin\u00b7de", "und", "sind", "uns", "so", "nah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "NN", "KON", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "So la\u00dft sie's ", "tokens": ["So", "la\u00dft", "sie's"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVIMP", "NE"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Stimmt an ein Lied von Heimat und Haus,", "tokens": ["Stimmt", "an", "ein", "Lied", "von", "Hei\u00b7mat", "und", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Trompeter, blast in die Nacht hinaus!\u00ab", "tokens": ["Trom\u00b7pe\u00b7ter", ",", "blast", "in", "die", "Nacht", "hin\u00b7aus", "!", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "ADV", "APPR", "ART", "NN", "PTKVZ", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.18": {"line.1": {"text": "Da huben sie an und sie wurden's nicht m\u00fcd',", "tokens": ["Da", "hu\u00b7ben", "sie", "an", "und", "sie", "wur\u00b7den's", "nicht", "m\u00fcd'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "KON", "PPER", "VAFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+--+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durch die Nacht hin klang es Lied um Lied,", "tokens": ["Durch", "die", "Nacht", "hin", "klang", "es", "Lied", "um", "Lied", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "VVFIN", "PPER", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Erst englische Lieder mit fr\u00f6hlichem Klang,", "tokens": ["Erst", "eng\u00b7li\u00b7sche", "Lie\u00b7der", "mit", "fr\u00f6h\u00b7li\u00b7chem", "Klang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+--+", "measure": "amphibrach.tetra"}, "line.4": {"text": "Dann Hochlandslieder wie Klagegesang.", "tokens": ["Dann", "Hoch\u00b7lands\u00b7lie\u00b7der", "wie", "Kla\u00b7ge\u00b7ge\u00b7sang", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOKOM", "NN", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.19": {"line.1": {"text": "Sie bliesen die Nacht und \u00fcber den Tag,", "tokens": ["Sie", "blie\u00b7sen", "die", "Nacht", "und", "\u00fc\u00b7ber", "den", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Laut, wie nur die Liebe rufen mag,", "tokens": ["Laut", ",", "wie", "nur", "die", "Lie\u00b7be", "ru\u00b7fen", "mag", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "PWAV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Sie bliesen \u2013 es kam die zweite Nacht,", "tokens": ["Sie", "blie\u00b7sen", "\u2013", "es", "kam", "die", "zwei\u00b7te", "Nacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Umsonst, da\u00df ihr ruft, umsonst, da\u00df ihr wacht.", "tokens": ["Um\u00b7sonst", ",", "da\u00df", "ihr", "ruft", ",", "um\u00b7sonst", ",", "da\u00df", "ihr", "wacht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,", "ADV", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}}, "stanza.20": {"line.1": {"text": "Die h\u00f6ren sollen, sie h\u00f6ren nicht mehr,", "tokens": ["Die", "h\u00f6\u00b7ren", "sol\u00b7len", ",", "sie", "h\u00f6\u00b7ren", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "$,", "PPER", "VVFIN", "PTKNEG", "ADV", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vernichtet ist das ganze Heer,", "tokens": ["Ver\u00b7nich\u00b7tet", "ist", "das", "gan\u00b7ze", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit dreizehntausend der Zug begann,", "tokens": ["Mit", "drei\u00b7zehn\u00b7tau\u00b7send", "der", "Zug", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}}}}