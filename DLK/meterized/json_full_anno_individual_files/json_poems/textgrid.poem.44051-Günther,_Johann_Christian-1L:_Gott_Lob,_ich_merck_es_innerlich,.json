{"textgrid.poem.44051": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Gott Lob, ich merck es innerlich,", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Gott Lob, ich merck es innerlich,", "tokens": ["Gott", "Lob", ",", "ich", "merck", "es", "in\u00b7ner\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des H\u00f6chsten Eifer lindert sich,", "tokens": ["Des", "H\u00f6chs\u00b7ten", "Ei\u00b7fer", "lin\u00b7dert", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es raft sich mein bedr\u00e4ngtes Herze;", "tokens": ["Es", "raft", "sich", "mein", "be\u00b7dr\u00e4ng\u00b7tes", "Her\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sieht es gleich noch nicht woher.", "tokens": ["Und", "sieht", "es", "gleich", "noch", "nicht", "wo\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So meint's doch mitten in dem Schmerze,", "tokens": ["So", "meint's", "doch", "mit\u00b7ten", "in", "dem", "Schmer\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als wenn gleichwohl ein Hang zur Hofnung \u00fcbrig w\u00e4r.", "tokens": ["Als", "wenn", "gleich\u00b7wohl", "ein", "Hang", "zur", "Hof\u00b7nung", "\u00fcb\u00b7rig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ADV", "ART", "NN", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was war das nicht vor Bangigkeit!", "tokens": ["Was", "war", "das", "nicht", "vor", "Ban\u00b7gig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meine ganze Lebenszeit", "tokens": ["Durch", "mei\u00b7ne", "gan\u00b7ze", "Le\u00b7bens\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Befind ich nichts von ihres gleichen;", "tokens": ["Be\u00b7find", "ich", "nichts", "von", "ih\u00b7res", "glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "APPR", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Zuspruch konte meinen Gram,", "tokens": ["Kein", "Zu\u00b7spruch", "kon\u00b7te", "mei\u00b7nen", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kein Trost den Eigensinn erweichen,", "tokens": ["Kein", "Trost", "den", "Ei\u00b7gen\u00b7sinn", "er\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der immer von sich selbst mehr Kraft und Nahrung nahm.", "tokens": ["Der", "im\u00b7mer", "von", "sich", "selbst", "mehr", "Kraft", "und", "Nah\u00b7rung", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PRF", "ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ach, allerliebster Herzensfreund,", "tokens": ["Ach", ",", "al\u00b7ler\u00b7liebs\u00b7ter", "Her\u00b7zens\u00b7freund", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey dem mein Elend gr\u00f6\u00dfer scheint,", "tokens": ["Bey", "dem", "mein", "E\u00b7lend", "gr\u00f6\u00b7\u00dfer", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Indem du in Gesellschaft leidest,", "tokens": ["In\u00b7dem", "du", "in", "Ge\u00b7sell\u00b7schaft", "lei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach glaube, da\u00df die gro\u00dfe Treu,", "tokens": ["Ach", "glau\u00b7be", ",", "da\u00df", "die", "gro\u00b7\u00dfe", "Treu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wodurch du dich in Noth bescheidest,", "tokens": ["Wo\u00b7durch", "du", "dich", "in", "Noth", "be\u00b7schei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mir noch die lezte Lust zu diesem Leben sey.", "tokens": ["Mir", "noch", "die", "lez\u00b7te", "Lust", "zu", "die\u00b7sem", "Le\u00b7ben", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "So sehnlich ein noch zartes Kind", "tokens": ["So", "sehn\u00b7lich", "ein", "noch", "zar\u00b7tes", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Br\u00fcste, Milch und Docken sinnt,", "tokens": ["Auf", "Br\u00fcs\u00b7te", ",", "Milch", "und", "Do\u00b7cken", "sinnt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sehnlich brennt auch mein Verlangen,", "tokens": ["So", "sehn\u00b7lich", "brennt", "auch", "mein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich einmahl in vergn\u00fcgter Zeit", "tokens": ["Dich", "ein\u00b7mahl", "in", "ver\u00b7gn\u00fcg\u00b7ter", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und in dem Alter zu umfangen,", "tokens": ["Und", "in", "dem", "Al\u00b7ter", "zu", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wo viel Erinnerung vergangner Noth erfreut.", "tokens": ["Wo", "viel", "E\u00b7rin\u00b7ne\u00b7rung", "ver\u00b7gang\u00b7ner", "Noth", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Die Welt soll kein Exempel sehn,", "tokens": ["Die", "Welt", "soll", "kein", "Ex\u00b7em\u00b7pel", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Das wohl auch so noch nicht geschehn,", "tokens": ["Das", "wohl", "auch", "so", "noch", "nicht", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADV", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das unsrer Treu die Palmen raube.", "tokens": ["Das", "uns\u00b7rer", "Treu", "die", "Pal\u00b7men", "rau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Frauenbrunst w\u00fcrckt sonderlich;", "tokens": ["Die", "Frau\u00b7en\u00b7brunst", "w\u00fcrckt", "son\u00b7der\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bistu Jonathan, so glaube,", "tokens": ["Doch", "bis\u00b7tu", "Jo\u00b7na\u00b7than", ",", "so", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dein David f\u00fchlt sie auch, doch \u00fcberhaupt vor dich.", "tokens": ["Dein", "Da\u00b7vid", "f\u00fchlt", "sie", "auch", ",", "doch", "\u00fc\u00b7ber\u00b7haupt", "vor", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Es mag uns ein Prophetengeist,", "tokens": ["Es", "mag", "uns", "ein", "Pro\u00b7phe\u00b7ten\u00b7geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So klug und weis er immer heist,", "tokens": ["So", "klug", "und", "weis", "er", "im\u00b7mer", "heist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PWS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Erden wenig Guts versprechen,", "tokens": ["Auf", "Er\u00b7den", "we\u00b7nig", "Guts", "ver\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen durch Vernunft und Flei\u00df", "tokens": ["Wir", "wol\u00b7len", "durch", "Ver\u00b7nunft", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Schl\u00fc\u00dfe b\u00f6ser Schickung brechen;", "tokens": ["Die", "Schl\u00fc\u00b7\u00dfe", "b\u00f6\u00b7ser", "Schi\u00b7ckung", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich troze drauf, weil Gott den frommen Vorsaz weis.", "tokens": ["Ich", "tro\u00b7ze", "drauf", ",", "weil", "Gott", "den", "from\u00b7men", "Vor\u00b7saz", "weis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Du siehst allhier, der Abendthau", "tokens": ["Du", "siehst", "all\u00b7hier", ",", "der", "A\u00b7bendt\u00b7hau"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht Gr\u00e4ser, Laub und Kr\u00e4uter grau", "tokens": ["Macht", "Gr\u00e4\u00b7ser", ",", "Laub", "und", "Kr\u00e4u\u00b7ter", "grau"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und st\u00e4rckt sie nach der Mittagshize:", "tokens": ["Und", "st\u00e4rckt", "sie", "nach", "der", "Mit\u00b7tags\u00b7hi\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach, lerne Trost, und klage nicht,", "tokens": ["Ach", ",", "ler\u00b7ne", "Trost", ",", "und", "kla\u00b7ge", "nicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "NN", "$,", "KON", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df unser Herz zu lange schwize;", "tokens": ["Da\u00df", "un\u00b7ser", "Herz", "zu", "lan\u00b7ge", "schwi\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wer weis, wo uns ein Quell auch aus dem Felsen bricht!", "tokens": ["Wer", "weis", ",", "wo", "uns", "ein", "Quell", "auch", "aus", "dem", "Fel\u00b7sen", "bricht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "PWAV", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Das sch\u00f6n- und wundervolle Licht", "tokens": ["Das", "sch\u00f6n", "und", "wun\u00b7der\u00b7vol\u00b7le", "Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entf\u00fchrt uns jezt sein Angesicht", "tokens": ["Ent\u00b7f\u00fchrt", "uns", "jezt", "sein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denckt gleichwohl aufs Wiederkommen;", "tokens": ["Und", "denckt", "gleich\u00b7wohl", "aufs", "Wie\u00b7der\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es bringt auch sein verj\u00fcngter Schritt", "tokens": ["Es", "bringt", "auch", "sein", "ver\u00b7j\u00fcng\u00b7ter", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies, was es uns anjezt genommen,", "tokens": ["Dies", ",", "was", "es", "uns", "an\u00b7jezt", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Glanz, Farben, W\u00e4rm und Lust vielleicht noch reicher mit.", "tokens": ["Glanz", ",", "Far\u00b7ben", ",", "W\u00e4rm", "und", "Lust", "viel\u00b7leicht", "noch", "rei\u00b7cher", "mit", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Es darf dich kein Verlust gereun;", "tokens": ["Es", "darf", "dich", "kein", "Ver\u00b7lust", "ge\u00b7reun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Zukunft wird des Gl\u00fcckes Schein", "tokens": ["Die", "Zu\u00b7kunft", "wird", "des", "Gl\u00fc\u00b7ckes", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit reichem Wucher wiedersenden.", "tokens": ["Mit", "rei\u00b7chem", "Wu\u00b7cher", "wie\u00b7der\u00b7sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir kehren wieder in die Stadt", "tokens": ["Wir", "keh\u00b7ren", "wie\u00b7der", "in", "die", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zur alten Noth mit leeren H\u00e4nden;", "tokens": ["Zur", "al\u00b7ten", "Noth", "mit", "lee\u00b7ren", "H\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jedoch wer weis, wo Gott vor uns gesorget hat!", "tokens": ["Je\u00b7doch", "wer", "weis", ",", "wo", "Gott", "vor", "uns", "ge\u00b7sor\u00b7get", "hat", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PTKVZ", "$,", "PWAV", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Gott Lob, ich merck es innerlich,", "tokens": ["Gott", "Lob", ",", "ich", "merck", "es", "in\u00b7ner\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$,", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des H\u00f6chsten Eifer lindert sich,", "tokens": ["Des", "H\u00f6chs\u00b7ten", "Ei\u00b7fer", "lin\u00b7dert", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es raft sich mein bedr\u00e4ngtes Herze;", "tokens": ["Es", "raft", "sich", "mein", "be\u00b7dr\u00e4ng\u00b7tes", "Her\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "ADJA", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und sieht es gleich noch nicht woher.", "tokens": ["Und", "sieht", "es", "gleich", "noch", "nicht", "wo\u00b7her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So meint's doch mitten in dem Schmerze,", "tokens": ["So", "meint's", "doch", "mit\u00b7ten", "in", "dem", "Schmer\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Als wenn gleichwohl ein Hang zur Hofnung \u00fcbrig w\u00e4r.", "tokens": ["Als", "wenn", "gleich\u00b7wohl", "ein", "Hang", "zur", "Hof\u00b7nung", "\u00fcb\u00b7rig", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "ADV", "ART", "NN", "APPRART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Was war das nicht vor Bangigkeit!", "tokens": ["Was", "war", "das", "nicht", "vor", "Ban\u00b7gig\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "PTKNEG", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Durch meine ganze Lebenszeit", "tokens": ["Durch", "mei\u00b7ne", "gan\u00b7ze", "Le\u00b7bens\u00b7zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Befind ich nichts von ihres gleichen;", "tokens": ["Be\u00b7find", "ich", "nichts", "von", "ih\u00b7res", "glei\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PIS", "APPR", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Kein Zuspruch konte meinen Gram,", "tokens": ["Kein", "Zu\u00b7spruch", "kon\u00b7te", "mei\u00b7nen", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Kein Trost den Eigensinn erweichen,", "tokens": ["Kein", "Trost", "den", "Ei\u00b7gen\u00b7sinn", "er\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Der immer von sich selbst mehr Kraft und Nahrung nahm.", "tokens": ["Der", "im\u00b7mer", "von", "sich", "selbst", "mehr", "Kraft", "und", "Nah\u00b7rung", "nahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "PRF", "ADV", "PIAT", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Ach, allerliebster Herzensfreund,", "tokens": ["Ach", ",", "al\u00b7ler\u00b7liebs\u00b7ter", "Her\u00b7zens\u00b7freund", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["ITJ", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bey dem mein Elend gr\u00f6\u00dfer scheint,", "tokens": ["Bey", "dem", "mein", "E\u00b7lend", "gr\u00f6\u00b7\u00dfer", "scheint", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PPOSAT", "NN", "ADJD", "VVFIN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.3": {"text": "Indem du in Gesellschaft leidest,", "tokens": ["In\u00b7dem", "du", "in", "Ge\u00b7sell\u00b7schaft", "lei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach glaube, da\u00df die gro\u00dfe Treu,", "tokens": ["Ach", "glau\u00b7be", ",", "da\u00df", "die", "gro\u00b7\u00dfe", "Treu", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "VVFIN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wodurch du dich in Noth bescheidest,", "tokens": ["Wo\u00b7durch", "du", "dich", "in", "Noth", "be\u00b7schei\u00b7dest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Mir noch die lezte Lust zu diesem Leben sey.", "tokens": ["Mir", "noch", "die", "lez\u00b7te", "Lust", "zu", "die\u00b7sem", "Le\u00b7ben", "sey", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "ADJA", "NN", "APPR", "PDAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "So sehnlich ein noch zartes Kind", "tokens": ["So", "sehn\u00b7lich", "ein", "noch", "zar\u00b7tes", "Kind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ART", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf Br\u00fcste, Milch und Docken sinnt,", "tokens": ["Auf", "Br\u00fcs\u00b7te", ",", "Milch", "und", "Do\u00b7cken", "sinnt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So sehnlich brennt auch mein Verlangen,", "tokens": ["So", "sehn\u00b7lich", "brennt", "auch", "mein", "Ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dich einmahl in vergn\u00fcgter Zeit", "tokens": ["Dich", "ein\u00b7mahl", "in", "ver\u00b7gn\u00fcg\u00b7ter", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und in dem Alter zu umfangen,", "tokens": ["Und", "in", "dem", "Al\u00b7ter", "zu", "um\u00b7fan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wo viel Erinnerung vergangner Noth erfreut.", "tokens": ["Wo", "viel", "E\u00b7rin\u00b7ne\u00b7rung", "ver\u00b7gang\u00b7ner", "Noth", "er\u00b7freut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Die Welt soll kein Exempel sehn,", "tokens": ["Die", "Welt", "soll", "kein", "Ex\u00b7em\u00b7pel", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Das wohl auch so noch nicht geschehn,", "tokens": ["Das", "wohl", "auch", "so", "noch", "nicht", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADV", "ADV", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das unsrer Treu die Palmen raube.", "tokens": ["Das", "uns\u00b7rer", "Treu", "die", "Pal\u00b7men", "rau\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die Frauenbrunst w\u00fcrckt sonderlich;", "tokens": ["Die", "Frau\u00b7en\u00b7brunst", "w\u00fcrckt", "son\u00b7der\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch bistu Jonathan, so glaube,", "tokens": ["Doch", "bis\u00b7tu", "Jo\u00b7na\u00b7than", ",", "so", "glau\u00b7be", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "$,", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Dein David f\u00fchlt sie auch, doch \u00fcberhaupt vor dich.", "tokens": ["Dein", "Da\u00b7vid", "f\u00fchlt", "sie", "auch", ",", "doch", "\u00fc\u00b7ber\u00b7haupt", "vor", "dich", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NE", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Es mag uns ein Prophetengeist,", "tokens": ["Es", "mag", "uns", "ein", "Pro\u00b7phe\u00b7ten\u00b7geist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So klug und weis er immer heist,", "tokens": ["So", "klug", "und", "weis", "er", "im\u00b7mer", "heist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "PWS", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf Erden wenig Guts versprechen,", "tokens": ["Auf", "Er\u00b7den", "we\u00b7nig", "Guts", "ver\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir wollen durch Vernunft und Flei\u00df", "tokens": ["Wir", "wol\u00b7len", "durch", "Ver\u00b7nunft", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Schl\u00fc\u00dfe b\u00f6ser Schickung brechen;", "tokens": ["Die", "Schl\u00fc\u00b7\u00dfe", "b\u00f6\u00b7ser", "Schi\u00b7ckung", "bre\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ich troze drauf, weil Gott den frommen Vorsaz weis.", "tokens": ["Ich", "tro\u00b7ze", "drauf", ",", "weil", "Gott", "den", "from\u00b7men", "Vor\u00b7saz", "weis", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOUS", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.16": {"line.1": {"text": "Du siehst allhier, der Abendthau", "tokens": ["Du", "siehst", "all\u00b7hier", ",", "der", "A\u00b7bendt\u00b7hau"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Macht Gr\u00e4ser, Laub und Kr\u00e4uter grau", "tokens": ["Macht", "Gr\u00e4\u00b7ser", ",", "Laub", "und", "Kr\u00e4u\u00b7ter", "grau"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$,", "NN", "KON", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und st\u00e4rckt sie nach der Mittagshize:", "tokens": ["Und", "st\u00e4rckt", "sie", "nach", "der", "Mit\u00b7tags\u00b7hi\u00b7ze", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ach, lerne Trost, und klage nicht,", "tokens": ["Ach", ",", "ler\u00b7ne", "Trost", ",", "und", "kla\u00b7ge", "nicht", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVFIN", "NN", "$,", "KON", "VVFIN", "PTKNEG", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df unser Herz zu lange schwize;", "tokens": ["Da\u00df", "un\u00b7ser", "Herz", "zu", "lan\u00b7ge", "schwi\u00b7ze", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wer weis, wo uns ein Quell auch aus dem Felsen bricht!", "tokens": ["Wer", "weis", ",", "wo", "uns", "ein", "Quell", "auch", "aus", "dem", "Fel\u00b7sen", "bricht", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKVZ", "$,", "PWAV", "PPER", "ART", "NN", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.17": {"line.1": {"text": "Das sch\u00f6n- und wundervolle Licht", "tokens": ["Das", "sch\u00f6n", "und", "wun\u00b7der\u00b7vol\u00b7le", "Licht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "TRUNC", "KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entf\u00fchrt uns jezt sein Angesicht", "tokens": ["Ent\u00b7f\u00fchrt", "uns", "jezt", "sein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und denckt gleichwohl aufs Wiederkommen;", "tokens": ["Und", "denckt", "gleich\u00b7wohl", "aufs", "Wie\u00b7der\u00b7kom\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Es bringt auch sein verj\u00fcngter Schritt", "tokens": ["Es", "bringt", "auch", "sein", "ver\u00b7j\u00fcng\u00b7ter", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dies, was es uns anjezt genommen,", "tokens": ["Dies", ",", "was", "es", "uns", "an\u00b7jezt", "ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "PWS", "PPER", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Glanz, Farben, W\u00e4rm und Lust vielleicht noch reicher mit.", "tokens": ["Glanz", ",", "Far\u00b7ben", ",", "W\u00e4rm", "und", "Lust", "viel\u00b7leicht", "noch", "rei\u00b7cher", "mit", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "ADV", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Es darf dich kein Verlust gereun;", "tokens": ["Es", "darf", "dich", "kein", "Ver\u00b7lust", "ge\u00b7reun", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Zukunft wird des Gl\u00fcckes Schein", "tokens": ["Die", "Zu\u00b7kunft", "wird", "des", "Gl\u00fc\u00b7ckes", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit reichem Wucher wiedersenden.", "tokens": ["Mit", "rei\u00b7chem", "Wu\u00b7cher", "wie\u00b7der\u00b7sen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wir kehren wieder in die Stadt", "tokens": ["Wir", "keh\u00b7ren", "wie\u00b7der", "in", "die", "Stadt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zur alten Noth mit leeren H\u00e4nden;", "tokens": ["Zur", "al\u00b7ten", "Noth", "mit", "lee\u00b7ren", "H\u00e4n\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Jedoch wer weis, wo Gott vor uns gesorget hat!", "tokens": ["Je\u00b7doch", "wer", "weis", ",", "wo", "Gott", "vor", "uns", "ge\u00b7sor\u00b7get", "hat", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PWS", "PTKVZ", "$,", "PWAV", "NN", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}