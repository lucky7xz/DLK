{"textgrid.poem.23912": {"metadata": {"author": {"name": "Bierbaum, Otto Julius", "birth": "N.A.", "death": "N.A."}, "title": "Charlotte", "genre": "verse", "period": "N.A.", "pub_year": 1887, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Charlotte, lotte, lotte,", "tokens": ["Char\u00b7lot\u00b7te", ",", "lot\u00b7te", ",", "lot\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hei\u00dft meine W\u00e4scherin,", "tokens": ["Hei\u00dft", "mei\u00b7ne", "W\u00e4\u00b7sche\u00b7rin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie bringt mir selbst die W\u00e4sche,", "tokens": ["Sie", "bringt", "mir", "selbst", "die", "W\u00e4\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil ich ihr Liebster bin.", "tokens": ["Weil", "ich", "ihr", "Liebs\u00b7ter", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und hat sie nichts zu bringen,", "tokens": ["Und", "hat", "sie", "nichts", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So kommt sie ohne was,", "tokens": ["So", "kommt", "sie", "oh\u00b7ne", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PRELS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Tag geht ohne Lotte,", "tokens": ["Kein", "Tag", "geht", "oh\u00b7ne", "Lot\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Lotte ist Verla\u00df.", "tokens": ["Auf", "Lot\u00b7te", "ist", "Ver\u00b7la\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Kommt ohne Hut und Schleier", "tokens": ["Kommt", "oh\u00b7ne", "Hut", "und", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und hat auch kein Korsett;", "tokens": ["Und", "hat", "auch", "kein", "Kor\u00b7sett", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil ich kein Sopha habe,", "tokens": ["Weil", "ich", "kein", "So\u00b7pha", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "So setzt sie sich aufs Bett.", "tokens": ["So", "setzt", "sie", "sich", "aufs", "Bett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ihr ahnt nicht, wie viel Sch\u00f6nes", "tokens": ["Ihr", "ahnt", "nicht", ",", "wie", "viel", "Sch\u00f6\u00b7nes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die kleine Lotte hat;", "tokens": ["Die", "klei\u00b7ne", "Lot\u00b7te", "hat", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich habs schon oft gesehen", "tokens": ["Ich", "habs", "schon", "oft", "ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und seh mich doch nicht satt.", "tokens": ["Und", "seh", "mich", "doch", "nicht", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Charlotte, lotte, lotte,", "tokens": ["Char\u00b7lot\u00b7te", ",", "lot\u00b7te", ",", "lot\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Hei\u00dft meine W\u00e4scherin,", "tokens": ["Hei\u00dft", "mei\u00b7ne", "W\u00e4\u00b7sche\u00b7rin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Sie bringt mir selbst die W\u00e4sche,", "tokens": ["Sie", "bringt", "mir", "selbst", "die", "W\u00e4\u00b7sche", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil ich ihr Liebster bin.", "tokens": ["Weil", "ich", "ihr", "Liebs\u00b7ter", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Und hat sie nichts zu bringen,", "tokens": ["Und", "hat", "sie", "nichts", "zu", "brin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "So kommt sie ohne was,", "tokens": ["So", "kommt", "sie", "oh\u00b7ne", "was", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PRELS", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Kein Tag geht ohne Lotte,", "tokens": ["Kein", "Tag", "geht", "oh\u00b7ne", "Lot\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Lotte ist Verla\u00df.", "tokens": ["Auf", "Lot\u00b7te", "ist", "Ver\u00b7la\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Kommt ohne Hut und Schleier", "tokens": ["Kommt", "oh\u00b7ne", "Hut", "und", "Schlei\u00b7er"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Und hat auch kein Korsett;", "tokens": ["Und", "hat", "auch", "kein", "Kor\u00b7sett", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Weil ich kein Sopha habe,", "tokens": ["Weil", "ich", "kein", "So\u00b7pha", "ha\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PIAT", "NN", "VAFIN", "$,"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "So setzt sie sich aufs Bett.", "tokens": ["So", "setzt", "sie", "sich", "aufs", "Bett", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ihr ahnt nicht, wie viel Sch\u00f6nes", "tokens": ["Ihr", "ahnt", "nicht", ",", "wie", "viel", "Sch\u00f6\u00b7nes"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "PIAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Die kleine Lotte hat;", "tokens": ["Die", "klei\u00b7ne", "Lot\u00b7te", "hat", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ich habs schon oft gesehen", "tokens": ["Ich", "habs", "schon", "oft", "ge\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NE", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und seh mich doch nicht satt.", "tokens": ["Und", "seh", "mich", "doch", "nicht", "satt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}