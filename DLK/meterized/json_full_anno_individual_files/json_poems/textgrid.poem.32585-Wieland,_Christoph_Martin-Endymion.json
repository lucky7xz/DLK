{"textgrid.poem.32585": {"metadata": {"author": {"name": "Wieland, Christoph Martin", "birth": "N.A.", "death": "N.A."}, "title": "Endymion", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "In jener dichterischen Zeit", "tokens": ["In", "je\u00b7ner", "dich\u00b7te\u00b7ri\u00b7schen", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit deren Wundern uns der Amme Freundlichkeit", "tokens": ["Mit", "de\u00b7ren", "Wun\u00b7dern", "uns", "der", "Am\u00b7me", "Freund\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch manches M\u00e4rchen einst in s\u00fc\u00dfen Schlummer wiegte;", "tokens": ["Durch", "man\u00b7ches", "M\u00e4r\u00b7chen", "einst", "in", "s\u00fc\u00b7\u00dfen", "Schlum\u00b7mer", "wieg\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als sorgenfreie M\u00fc\u00dfigkeit", "tokens": ["Als", "sor\u00b7gen\u00b7frei\u00b7e", "M\u00fc\u00b7\u00dfig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich ohne Pflichten, ohne Streit,", "tokens": ["Sich", "oh\u00b7ne", "Pflich\u00b7ten", ",", "oh\u00b7ne", "Streit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit dem was die Natur freiwillig gab, begn\u00fcgte,", "tokens": ["Mit", "dem", "was", "die", "Na\u00b7tur", "frei\u00b7wil\u00b7lig", "gab", ",", "be\u00b7gn\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "PRELS", "ART", "NN", "ADJD", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kein M\u00e4dchen spann, kein J\u00fcngling pfl\u00fcgte,", "tokens": ["Kein", "M\u00e4d\u00b7chen", "spann", ",", "kein", "J\u00fcng\u00b7ling", "pfl\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und manches tunlich war, was Basedow verbeut;", "tokens": ["Und", "man\u00b7ches", "tun\u00b7lich", "war", ",", "was", "Ba\u00b7se\u00b7dow", "ver\u00b7beut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "VAFIN", "$,", "PRELS", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Eh noch der St\u00e4nde Unterscheid", "tokens": ["Eh", "noch", "der", "St\u00e4n\u00b7de", "Un\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Aus Br\u00fcdern Nebenbuhler machte,", "tokens": ["Aus", "Br\u00fc\u00b7dern", "Ne\u00b7ben\u00b7buh\u00b7ler", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und gleisnerische Heiligkeit", "tokens": ["Und", "gleis\u00b7ne\u00b7ri\u00b7sche", "Hei\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das h\u00f6chste Gut der Sterblichkeit,", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "der", "Sterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Lust um ihre Unschuld brachte;", "tokens": ["Die", "Lust", "um", "ih\u00b7re", "Un\u00b7schuld", "brach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und kurz, in jener goldnen Zeit,", "tokens": ["Und", "kurz", ",", "in", "je\u00b7ner", "gold\u00b7nen", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Da die Natur, von keinem Joch entweiht,", "tokens": ["Da", "die", "Na\u00b7tur", ",", "von", "kei\u00b7nem", "Joch", "ent\u00b7weiht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Gesetze gab wodurch sie gl\u00fccklich machte,", "tokens": ["Ge\u00b7set\u00b7ze", "gab", "wo\u00b7durch", "sie", "gl\u00fcck\u00b7lich", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Die Welt noch kindisch war und alles scherzt' und lachte:", "tokens": ["Die", "Welt", "noch", "kin\u00b7disch", "war", "und", "al\u00b7les", "scherzt'", "und", "lach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAFIN", "KON", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "In dieser Zeit lebt' einst auf Latmos H\u00f6hn", "tokens": ["In", "die\u00b7ser", "Zeit", "lebt'", "einst", "auf", "Lat\u00b7mos", "H\u00f6hn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Ein junger Hirt, wie Ganymedes sch\u00f6n,", "tokens": ["Ein", "jun\u00b7ger", "Hirt", ",", "wie", "Ga\u00b7ny\u00b7me\u00b7des", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "NN", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Sch\u00f6n wie Narci\u00df, doch nicht so spr\u00f6de,", "tokens": ["Sch\u00f6n", "wie", "Nar\u00b7ci\u00df", ",", "doch", "nicht", "so", "spr\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NN", "$,", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Wie Ganymed, allein nicht halb so bl\u00f6de.", "tokens": ["Wie", "Ga\u00b7ny\u00b7med", ",", "al\u00b7lein", "nicht", "halb", "so", "bl\u00f6\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "ADV", "PTKNEG", "ADJD", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "So bald man wei\u00df, Endymion", "tokens": ["So", "bald", "man", "wei\u00df", ",", "En\u00b7dy\u00b7mi\u00b7on"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "War sch\u00f6n, so denkt ein jeder schon", "tokens": ["War", "sch\u00f6n", ",", "so", "denkt", "ein", "je\u00b7der", "schon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "VVFIN", "ART", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Da\u00df ihn die M\u00e4dchen gerne sahen;", "tokens": ["Da\u00df", "ihn", "die", "M\u00e4d\u00b7chen", "ger\u00b7ne", "sa\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Zum mindsten liefen sie nie wenn er kam davon,", "tokens": ["Zum", "minds\u00b7ten", "lie\u00b7fen", "sie", "nie", "wenn", "er", "kam", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Das l\u00e4\u00dft sich ohne Scheu bejahen.", "tokens": ["Das", "l\u00e4\u00dft", "sich", "oh\u00b7ne", "Scheu", "be\u00b7ja\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Die Chronik sagt noch mehr als ich", "tokens": ["Die", "Chro\u00b7nik", "sagt", "noch", "mehr", "als", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Den Musen selbst geglaubet h\u00e4tte;", "tokens": ["Den", "Mu\u00b7sen", "selbst", "ge\u00b7glau\u00b7bet", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Sie buhlten, spricht sie, in die Wette", "tokens": ["Sie", "buhl\u00b7ten", ",", "spricht", "sie", ",", "in", "die", "Wet\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Um seine Gunst; sie stellten sich", "tokens": ["Um", "sei\u00b7ne", "Gunst", ";", "sie", "stell\u00b7ten", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ihm wo er ging in Steg' und Wege;", "tokens": ["Ihm", "wo", "er", "ging", "in", "Steg'", "und", "We\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PWAV", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Sie warfen ihm oft Blumen zu;", "tokens": ["Sie", "war\u00b7fen", "ihm", "oft", "Blu\u00b7men", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Und flohn dann hinter ein Geh\u00e4ge;", "tokens": ["Und", "flohn", "dann", "hin\u00b7ter", "ein", "Ge\u00b7h\u00e4\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Belauschten seine Mittags-Ruh", "tokens": ["Be\u00b7lauschten", "sei\u00b7ne", "Mit\u00b7tags\u00b7Ruh"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.35": {"text": "Und guckten, ob er sich nicht rege.", "tokens": ["Und", "guck\u00b7ten", ",", "ob", "er", "sich", "nicht", "re\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.36": {"text": "Man meint, da\u00df er im Bad sogar", "tokens": ["Man", "meint", ",", "da\u00df", "er", "im", "Bad", "so\u00b7gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Nicht immer ohne Zeugen war,", "tokens": ["Nicht", "im\u00b7mer", "oh\u00b7ne", "Zeu\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Doch l\u00e4\u00dft sich das gewi\u00df nicht sagen.", "tokens": ["Doch", "l\u00e4\u00dft", "sich", "das", "ge\u00b7wi\u00df", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PDS", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Genug, kaum fing es an zu tagen", "tokens": ["Ge\u00b7nug", ",", "kaum", "fing", "es", "an", "zu", "ta\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PPER", "APPR", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "So wurde schon von mancher sch\u00f6nen Hand", "tokens": ["So", "wur\u00b7de", "schon", "von", "man\u00b7cher", "sch\u00f6\u00b7nen", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Der Blumen-Flur ihr sch\u00f6nster Schmuck entwandt;", "tokens": ["Der", "Blu\u00b7men\u00b7Flur", "ihr", "sch\u00f6ns\u00b7ter", "Schmuck", "ent\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "So putzt sich schon, dem Sch\u00e4fer zu gefallen,", "tokens": ["So", "putzt", "sich", "schon", ",", "dem", "Sch\u00e4\u00b7fer", "zu", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Im Hain, am Bach, der Nymphen ganze Schar,", "tokens": ["Im", "Hain", ",", "am", "Bach", ",", "der", "Nym\u00b7phen", "gan\u00b7ze", "Schar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Die badet sich, die flicht ihr blondes Haar,", "tokens": ["Die", "ba\u00b7det", "sich", ",", "die", "flicht", "ihr", "blon\u00b7des", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "$,", "PRELS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Die l\u00e4\u00dft es frei um wei\u00dfe Schultern wallen.", "tokens": ["Die", "l\u00e4\u00dft", "es", "frei", "um", "wei\u00b7\u00dfe", "Schul\u00b7tern", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "Herabgeb\u00fcckt auf fl\u00fcssige Cristallen", "tokens": ["Her\u00b7ab\u00b7ge\u00b7b\u00fcckt", "auf", "fl\u00fcs\u00b7si\u00b7ge", "Cris\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.47": {"text": "Bel\u00e4chelt sich die sch\u00f6ne Damalis;", "tokens": ["Be\u00b7l\u00e4\u00b7chelt", "sich", "die", "sch\u00f6\u00b7ne", "Da\u00b7ma\u00b7lis", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Wie vieles macht sie ihres Siegs gewi\u00df!", "tokens": ["Wie", "vie\u00b7les", "macht", "sie", "ih\u00b7res", "Siegs", "ge\u00b7wi\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.49": {"text": "Ein Mund, der K\u00fcssen winkt, ein Lilien-Nacken,", "tokens": ["Ein", "Mund", ",", "der", "K\u00fcs\u00b7sen", "winkt", ",", "ein", "Li\u00b7li\u00b7en\u00b7Nacken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.50": {"text": "Der Augen feuchter Glanz, ein perlengleich Gebi\u00df,", "tokens": ["Der", "Au\u00b7gen", "feuch\u00b7ter", "Glanz", ",", "ein", "per\u00b7len\u00b7gleich", "Ge\u00b7bi\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Die freie Stirn, die Gr\u00fcbchen in den Backen,", "tokens": ["Die", "frei\u00b7e", "Stirn", ",", "die", "Gr\u00fcb\u00b7chen", "in", "den", "Ba\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Ein runder Arm, und o! der Thron der Lust", "tokens": ["Ein", "run\u00b7der", "Arm", ",", "und", "o", "!", "der", "Thron", "der", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "FM", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "Die blendende, die Anmutsvolle Brust!", "tokens": ["Die", "blen\u00b7den\u00b7de", ",", "die", "An\u00b7muts\u00b7vol\u00b7le", "Brust", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Sie sieht noch mehr, nichts zeigt sich ihren Blicken", "tokens": ["Sie", "sieht", "noch", "mehr", ",", "nichts", "zeigt", "sich", "ih\u00b7ren", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PIS", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Das nicht verdient selbst G\u00f6tter zu ber\u00fccken:", "tokens": ["Das", "nicht", "ver\u00b7dient", "selbst", "G\u00f6t\u00b7ter", "zu", "be\u00b7r\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVFIN", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.56": {"text": "Sie sieht's und denkt, ob Leda ihrem Schwan", "tokens": ["Sie", "sieht's", "und", "denkt", ",", "ob", "Le\u00b7da", "ih\u00b7rem", "Schwan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NE", "KON", "VVFIN", "$,", "KOUS", "NE", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Mehr Reizungen gewiesen haben kann,", "tokens": ["Mehr", "Rei\u00b7zun\u00b7gen", "ge\u00b7wie\u00b7sen", "ha\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Und zittert doch und w\u00fcnscht: o! f\u00e4nde mich", "tokens": ["Und", "zit\u00b7tert", "doch", "und", "w\u00fcnscht", ":", "o", "!", "f\u00e4n\u00b7de", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "$.", "FM", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Endymion nur halb so sch\u00f6n als ich!", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "nur", "halb", "so", "sch\u00f6n", "als", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.60": {"text": "Die Sch\u00f6nheit wird mit Wunder angeblickt,", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "wird", "mit", "Wun\u00b7der", "an\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.61": {"text": "Doch nur Gef\u00e4lligkeit entz\u00fcckt.", "tokens": ["Doch", "nur", "Ge\u00b7f\u00e4l\u00b7lig\u00b7keit", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "War Juno nicht, war nicht Minerva sch\u00f6n", "tokens": ["War", "Ju\u00b7no", "nicht", ",", "war", "nicht", "Mi\u00b7ner\u00b7va", "sch\u00f6n"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKNEG", "$,", "VAFIN", "PTKNEG", "NE", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.63": {"text": "Als Zeus den Paris ausersehn", "tokens": ["Als", "Zeus", "den", "Pa\u00b7ris", "au\u00b7ser\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "NE", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Den Streit der Sch\u00f6nheit zu entscheiden'", "tokens": ["Den", "Streit", "der", "Sch\u00f6n\u00b7heit", "zu", "ent\u00b7schei\u00b7den'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "Man wei\u00df, sie lie\u00dfen sich, um b\u00f6sen Schein zu meiden,", "tokens": ["Man", "wei\u00df", ",", "sie", "lie\u00b7\u00dfen", "sich", ",", "um", "b\u00f6\u00b7sen", "Schein", "zu", "mei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "$,", "KOUI", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Dem Richter ohne R\u00f6cke sehn.", "tokens": ["Dem", "Rich\u00b7ter", "oh\u00b7ne", "R\u00f6\u00b7cke", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Lang lie\u00df der Hirt von einem Reiz zum andern", "tokens": ["Lang", "lie\u00df", "der", "Hirt", "von", "ei\u00b7nem", "Reiz", "zum", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Die ungewissen Blicke wandern,", "tokens": ["Die", "un\u00b7ge\u00b7wis\u00b7sen", "Bli\u00b7cke", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Und zehnmal rief ein neuer Blick", "tokens": ["Und", "zehn\u00b7mal", "rief", "ein", "neu\u00b7er", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Den schon gefa\u00dften Schlu\u00df zur\u00fcck:", "tokens": ["Den", "schon", "ge\u00b7fa\u00df\u00b7ten", "Schlu\u00df", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Untadelich ist alles was sie zeigen;", "tokens": ["Un\u00b7ta\u00b7de\u00b7lich", "ist", "al\u00b7les", "was", "sie", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PWS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.72": {"text": "Beisammen sind sie gleich; allein", "tokens": ["Bei\u00b7sam\u00b7men", "sind", "sie", "gleich", ";", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVPP", "VAFIN", "PPER", "ADV", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.73": {"text": "Scheint jede reizender zu sein,", "tokens": ["Scheint", "je\u00b7de", "rei\u00b7zen\u00b7der", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Was wird zuletzt des Sch\u00e4fers Urteil neigen?", "tokens": ["Was", "wird", "zu\u00b7letzt", "des", "Sch\u00e4\u00b7fers", "Ur\u00b7teil", "nei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.75": {"text": "Der Juno Majest\u00e4t! der Pallas W\u00fcrde, \u2013 Nein!", "tokens": ["Der", "Ju\u00b7no", "Ma\u00b7jes\u00b7t\u00e4t", "!", "der", "Pal\u00b7las", "W\u00fcr\u00b7de", ",", "\u2013", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "ART", "NN", "VAFIN", "$,", "$(", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Die fl\u00f6\u00dfen nichts als Ehrfurcht ein,", "tokens": ["Die", "fl\u00f6\u00b7\u00dfen", "nichts", "als", "Ehr\u00b7furcht", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "KOKOM", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "Ein st\u00e4rkrer Reiz wird hier den Ausschlag geben m\u00fcssen:", "tokens": ["Ein", "st\u00e4r\u00b7krer", "Reiz", "wird", "hier", "den", "Aus\u00b7schlag", "ge\u00b7ben", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Sie, die so zaubrisch l\u00e4cheln kann,", "tokens": ["Sie", ",", "die", "so", "zaub\u00b7risch", "l\u00e4\u00b7cheln", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "Die goldne Venus lacht ihn an,", "tokens": ["Die", "gold\u00b7ne", "Ve\u00b7nus", "lacht", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Und Paris f\u00e4llt zu ihren F\u00fc\u00dfen,", "tokens": ["Und", "Pa\u00b7ris", "f\u00e4llt", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.81": {"text": "Und beut (ich t\u00e4t es auch, so wahr ich ehrlich bin)", "tokens": ["Und", "beut", "(", "ich", "t\u00e4t", "es", "auch", ",", "so", "wahr", "ich", "ehr\u00b7lich", "bin", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADJD", "PPER", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Beut um die Freiheit sie zu k\u00fcssen", "tokens": ["Beut", "um", "die", "Frei\u00b7heit", "sie", "zu", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.83": {"text": "Der L\u00e4chelnden den goldnen Apfel hin.", "tokens": ["Der", "L\u00e4\u00b7cheln\u00b7den", "den", "gold\u00b7nen", "Ap\u00b7fel", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "So raubt die Freundlichkeit bei unserm Sch\u00e4fer oft", "tokens": ["So", "raubt", "die", "Freund\u00b7lich\u00b7keit", "bei", "un\u00b7serm", "Sch\u00e4\u00b7fer", "oft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Gunst, worauf die stolze Sch\u00f6nheit hofft.", "tokens": ["Die", "Gunst", ",", "wo\u00b7rauf", "die", "stol\u00b7ze", "Sch\u00f6n\u00b7heit", "hofft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die welke Brust, die Schar der blassen Wangen", "tokens": ["Die", "wel\u00b7ke", "Brust", ",", "die", "Schar", "der", "blas\u00b7sen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erwerben sich durch z\u00e4rtliches Bem\u00fchn,", "tokens": ["Er\u00b7wer\u00b7ben", "sich", "durch", "z\u00e4rt\u00b7li\u00b7ches", "Be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Durch Blicke die an seinen Blicken hangen,", "tokens": ["Durch", "Bli\u00b7cke", "die", "an", "sei\u00b7nen", "Bli\u00b7cken", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und s\u00fc\u00dfen Scherz, manch kleines Recht an ihn.", "tokens": ["Und", "s\u00fc\u00b7\u00dfen", "Scherz", ",", "manch", "klei\u00b7nes", "Recht", "an", "ihn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie eifern sie ihm liebzukosen!", "tokens": ["Wie", "ei\u00b7fern", "sie", "ihm", "lieb\u00b7zu\u00b7ko\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die schm\u00fcckt sein Lamm, die kr\u00e4nzt ihm Hut und Stab;", "tokens": ["Die", "schm\u00fcckt", "sein", "Lamm", ",", "die", "kr\u00e4nzt", "ihm", "Hut", "und", "Stab", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Der Lenz wird arm an Bl\u00fct und Rosen,", "tokens": ["Der", "Lenz", "wird", "arm", "an", "Bl\u00fct", "und", "Ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sie pfl\u00fcckten ganze Haine ab.", "tokens": ["Sie", "pfl\u00fcck\u00b7ten", "gan\u00b7ze", "Hai\u00b7ne", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sie wachten, da\u00df ihn nichts in seinem Schlummer st\u00f6rte,", "tokens": ["Sie", "wach\u00b7ten", ",", "da\u00df", "ihn", "nichts", "in", "sei\u00b7nem", "Schlum\u00b7mer", "st\u00f6r\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie pflanzten Lauben hin, wo er zu weiden pflag,", "tokens": ["Sie", "pflanz\u00b7ten", "Lau\u00b7ben", "hin", ",", "wo", "er", "zu", "wei\u00b7den", "pflag", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$,", "PWAV", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und weil er gerne singen h\u00f6rte", "tokens": ["Und", "weil", "er", "ger\u00b7ne", "sin\u00b7gen", "h\u00f6r\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "So sangen sie den ganzen Tag.", "tokens": ["So", "san\u00b7gen", "sie", "den", "gan\u00b7zen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des Tages Lust schlie\u00dft bis zum Sternen-Glanz", "tokens": ["Des", "Ta\u00b7ges", "Lust", "schlie\u00dft", "bis", "zum", "Ster\u00b7nen\u00b7Glanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Manch munters Spiel und mancher bunte Tanz,", "tokens": ["Manch", "mun\u00b7ters", "Spiel", "und", "man\u00b7cher", "bun\u00b7te", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und trennt zuletzt die Nacht den frohen Reihn", "tokens": ["Und", "trennt", "zu\u00b7letzt", "die", "Nacht", "den", "fro\u00b7hen", "Reihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "So schl\u00e4ft er sanft auf Rosen-Betten ein.", "tokens": ["So", "schl\u00e4ft", "er", "sanft", "auf", "Ro\u00b7sen\u00b7Bet\u00b7ten", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Die Nymphen zwingt der keuschen G\u00f6ttin Schein", "tokens": ["Die", "Nym\u00b7phen", "zwingt", "der", "keu\u00b7schen", "G\u00f6t\u00b7tin", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Sich allgemach hinweg zu stehlen;", "tokens": ["Sich", "all\u00b7ge\u00b7mach", "hin\u00b7weg", "zu", "steh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PAV", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Sie z\u00f6gern zwar, doch mu\u00df es endlich sein.", "tokens": ["Sie", "z\u00f6\u00b7gern", "zwar", ",", "doch", "mu\u00df", "es", "end\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Sie geben ihm die Hand, die angenehmen Seelen!", "tokens": ["Sie", "ge\u00b7ben", "ihm", "die", "Hand", ",", "die", "an\u00b7ge\u00b7neh\u00b7men", "See\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und w\u00fcnschen ihm wohl zehnmal gute Nacht;", "tokens": ["Und", "w\u00fcn\u00b7schen", "ihm", "wohl", "zehn\u00b7mal", "gu\u00b7te", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Doch weil der Schlaf sich oft erwarten macht,", "tokens": ["Doch", "weil", "der", "Schlaf", "sich", "oft", "er\u00b7war\u00b7ten", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Bleibt eine stets zur\u00fcck, ihm M\u00e4rchen zu erz\u00e4hlen.", "tokens": ["Bleibt", "ei\u00b7ne", "stets", "zu\u00b7r\u00fcck", ",", "ihm", "M\u00e4r\u00b7chen", "zu", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "PTKVZ", "$,", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Dem Gl\u00fcck in dieser Unterwelt.", "tokens": ["Dem", "Gl\u00fcck", "in", "die\u00b7ser", "Un\u00b7ter\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat stets Best\u00e4ndigkeit gefehlt.", "tokens": ["Hat", "stets", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Der Sch\u00e4fer war vergn\u00fcgt, das Nymphen-Volk nicht minder,", "tokens": ["Der", "Sch\u00e4\u00b7fer", "war", "ver\u00b7gn\u00fcgt", ",", "das", "Nym\u00b7phen\u00b7Volk", "nicht", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Unschuld lebten sie beisammen wie die Kinder,", "tokens": ["In", "Un\u00b7schuld", "leb\u00b7ten", "sie", "bei\u00b7sam\u00b7men", "wie", "die", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu manchem Spiel, wobei man selten weint", "tokens": ["Zu", "man\u00b7chem", "Spiel", ",", "wo\u00b7bei", "man", "sel\u00b7ten", "weint"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "PIS", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den ganzen Tag, oft auch bei Nacht, vereint.", "tokens": ["Den", "gan\u00b7zen", "Tag", ",", "oft", "auch", "bei", "Nacht", ",", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADV", "APPR", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch, wenn hat Ate je vergessen", "tokens": ["Doch", ",", "wenn", "hat", "A\u00b7te", "je", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "VAFIN", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr jede Lust uns Schmerzen zuzumessen?", "tokens": ["F\u00fcr", "je\u00b7de", "Lust", "uns", "Schmer\u00b7zen", "zu\u00b7zu\u00b7mes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Der Nymphen sch\u00f6ne K\u00f6nigin", "tokens": ["Der", "Nym\u00b7phen", "sch\u00f6\u00b7ne", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erfuhr, man wei\u00df nicht wie? Vielleicht von einem Faun", "tokens": ["Er\u00b7fuhr", ",", "man", "wei\u00df", "nicht", "wie", "?", "Viel\u00b7leicht", "von", "ei\u00b7nem", "Faun"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PIS", "VVFIN", "PTKNEG", "PWAV", "$.", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der sie beschlich, vielleicht auch im Vertraun", "tokens": ["Der", "sie", "be\u00b7schlich", ",", "viel\u00b7leicht", "auch", "im", "Ver\u00b7traun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von einer alten Sch\u00e4ferin,", "tokens": ["Von", "ei\u00b7ner", "al\u00b7ten", "Sch\u00e4\u00b7fe\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der weil sie selbst nicht mehr gefiel", "tokens": ["Der", "weil", "sie", "selbst", "nicht", "mehr", "ge\u00b7fiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Jugend eitles Tun mi\u00dffiel;", "tokens": ["Der", "Ju\u00b7gend", "eit\u00b7les", "Tun", "mi\u00df\u00b7fiel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kurz, sie erfuhr das ganze Sch\u00e4fer-Spiel.", "tokens": ["Kurz", ",", "sie", "er\u00b7fuhr", "das", "gan\u00b7ze", "Sch\u00e4\u00b7fer\u00b7Spiel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Man kennt den strengen Sinn", "tokens": ["Man", "kennt", "den", "stren\u00b7gen", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der sch\u00f6nen J\u00e4gerin", "tokens": ["Der", "sch\u00f6\u00b7nen", "J\u00e4\u00b7ge\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die in der G\u00f6tter-Schar", "tokens": ["Die", "in", "der", "G\u00f6t\u00b7ter\u00b7Schar"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die gr\u00f6\u00dfte Spr\u00f6de war.", "tokens": ["Die", "gr\u00f6\u00df\u00b7te", "Spr\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kein Sterblicher, kein Gott vermochte sie zu r\u00fchren.", "tokens": ["Kein", "Sterb\u00b7li\u00b7cher", ",", "kein", "Gott", "ver\u00b7moch\u00b7te", "sie", "zu", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sonst die Spr\u00f6desten vergn\u00fcgt,", "tokens": ["Was", "sonst", "die", "Spr\u00f6\u00b7des\u00b7ten", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Sogar der Stolz, selbst unbesiegt,", "tokens": ["So\u00b7gar", "der", "Stolz", ",", "selbst", "un\u00b7be\u00b7siegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Herzen im Triumph zu f\u00fchren", "tokens": ["Die", "Her\u00b7zen", "im", "Tri\u00b7umph", "zu", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "War ihrem gr\u00f6\u00dfern Stolz zu klein.", "tokens": ["War", "ih\u00b7rem", "gr\u00f6\u00b7\u00dfern", "Stolz", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie z\u00fcrnte schon, nur angesehn zu sein,", "tokens": ["Sie", "z\u00fcrn\u00b7te", "schon", ",", "nur", "an\u00b7ge\u00b7sehn", "zu", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "VVINF", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Blo\u00df weil er sie vom Wirbel bis zur Nasen", "tokens": ["Blo\u00df", "weil", "er", "sie", "vom", "Wir\u00b7bel", "bis", "zur", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PPER", "APPRART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Im Bad erblickt ward Acton einst zum Hasen.", "tokens": ["Im", "Bad", "er\u00b7blickt", "ward", "Ac\u00b7ton", "einst", "zum", "Ha\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VVPP", "VAFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Dies Beispiel fl\u00f6\u00dfte selbst dem Satyr Ehrfurcht ein.", "tokens": ["Dies", "Bei\u00b7spiel", "fl\u00f6\u00df\u00b7te", "selbst", "dem", "Sa\u00b7tyr", "Ehr\u00b7furcht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ihr schien ein Blick sie schon zu dreiste anzuf\u00fchlen,", "tokens": ["Ihr", "schien", "ein", "Blick", "sie", "schon", "zu", "dreis\u00b7te", "an\u00b7zu\u00b7f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "APPR", "ADJA", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kein Zephyr wagt's sie abzuk\u00fchlen,", "tokens": ["Kein", "Ze\u00b7phyr", "wagt's", "sie", "ab\u00b7zu\u00b7k\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und keine Blume schm\u00fcckt' ihr Haar", "tokens": ["Und", "kei\u00b7ne", "Blu\u00b7me", "schm\u00fcckt'", "ihr", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die einst ein h\u00fcbscher Knabe war;", "tokens": ["Die", "einst", "ein", "h\u00fcb\u00b7scher", "Kna\u00b7be", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Von Liebe nur im Schlaf zu sprechen", "tokens": ["Von", "Lie\u00b7be", "nur", "im", "Schlaf", "zu", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Hie\u00df bei Dianen schon ein strafbares Verbrechen:", "tokens": ["Hie\u00df", "bei", "Di\u00b7a\u00b7nen", "schon", "ein", "straf\u00b7ba\u00b7res", "Ver\u00b7bre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kurz, M\u00e4nner-Ha\u00df und Spr\u00f6digkeit", "tokens": ["Kurz", ",", "M\u00e4n\u00b7ner\u00b7Ha\u00df", "und", "Spr\u00f6\u00b7dig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Trieb selbst Minerva nicht so weit.", "tokens": ["Trieb", "selbst", "Mi\u00b7ner\u00b7va", "nicht", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NE", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.7": {"line.1": {"text": "Man ratet leicht, in welche Wut", "tokens": ["Man", "ra\u00b7tet", "leicht", ",", "in", "wel\u00b7che", "Wut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Nymphen Fall sie setzen mu\u00dfte;", "tokens": ["Der", "Nym\u00b7phen", "Fall", "sie", "set\u00b7zen", "mu\u00df\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es tobt' ihr jungferliches Blut", "tokens": ["Es", "tobt'", "ihr", "jung\u00b7fer\u00b7li\u00b7ches", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da\u00df sie sich kaum zu fassen wu\u00dfte.", "tokens": ["Da\u00df", "sie", "sich", "kaum", "zu", "fas\u00b7sen", "wu\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So zornig sahn die Nymphen sie", "tokens": ["So", "zor\u00b7nig", "sahn", "die", "Nym\u00b7phen", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In keinem andern Falle nie.", "tokens": ["In", "kei\u00b7nem", "an\u00b7dern", "Fal\u00b7le", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kallisto lie\u00df sich doch von einem Gott besiegen,", "tokens": ["Kal\u00b7lis\u00b7to", "lie\u00df", "sich", "doch", "von", "ei\u00b7nem", "Gott", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das milderte die Schn\u00f6digkeit der Tat;", "tokens": ["Das", "mil\u00b7der\u00b7te", "die", "Schn\u00f6\u00b7dig\u00b7keit", "der", "Tat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch einem Hirten unterliegen", "tokens": ["Doch", "ei\u00b7nem", "Hir\u00b7ten", "un\u00b7ter\u00b7lie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wahrhaftig! das war Hochverrat.", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "das", "war", "Hoch\u00b7ver\u00b7rat", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein fliegender Befehl zitiert aus allen Hainen", "tokens": ["Ein", "flie\u00b7gen\u00b7der", "Be\u00b7fehl", "zi\u00b7tiert", "aus", "al\u00b7len", "Hai\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das Nymphen-Volk pers\u00f6nlich zu erscheinen.", "tokens": ["Das", "Nym\u00b7phen\u00b7Volk", "per\u00b7s\u00f6n\u00b7lich", "zu", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie schleichen allgemach herbei,", "tokens": ["Sie", "schlei\u00b7chen", "all\u00b7ge\u00b7mach", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und keine lauft, da\u00df sie die erste sei.", "tokens": ["Und", "kei\u00b7ne", "lauft", ",", "da\u00df", "sie", "die", "ers\u00b7te", "sei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die G\u00f6ttin steht an ihren Spie\u00df gelehnt", "tokens": ["Die", "G\u00f6t\u00b7tin", "steht", "an", "ih\u00b7ren", "Spie\u00df", "ge\u00b7lehnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Und sieht mit ernstem Blick, der ihren Kummer h\u00f6hnt,", "tokens": ["Und", "sieht", "mit", "erns\u00b7tem", "Blick", ",", "der", "ih\u00b7ren", "Kum\u00b7mer", "h\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Im ganzen Kreis nichts als besch\u00e4mte Wangen,", "tokens": ["Im", "gan\u00b7zen", "Kreis", "nichts", "als", "be\u00b7sch\u00e4m\u00b7te", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und Blicke, die zur Erde niederhangen.", "tokens": ["Und", "Bli\u00b7cke", ",", "die", "zur", "Er\u00b7de", "nie\u00b7der\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "\u00bbhofft nicht\u00ab, spricht sie, \u00bbdurch Leugnen zu entgehn,", "tokens": ["\u00bb", "hofft", "nicht", "\u00ab", ",", "spricht", "sie", ",", "\u00bb", "durch", "Leug\u00b7nen", "zu", "ent\u00b7gehn", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Man wird euch bald die Zunge l\u00f6sen k\u00f6nnen,", "tokens": ["Man", "wird", "euch", "bald", "die", "Zun\u00b7ge", "l\u00f6\u00b7sen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und werdet ihr nicht g\u00fctlich eingestehn", "tokens": ["Und", "wer\u00b7det", "ihr", "nicht", "g\u00fct\u00b7lich", "ein\u00b7ge\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ADJD", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "So soll euch mir der Gott zu Delphi nennen.", "tokens": ["So", "soll", "euch", "mir", "der", "Gott", "zu", "Del\u00b7phi", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Durch Zaudern wird die Schuld nicht gut gemacht.", "tokens": ["Durch", "Zau\u00b7dern", "wird", "die", "Schuld", "nicht", "gut", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Nur hurtig! Jede von euch allen", "tokens": ["Nur", "hur\u00b7tig", "!", "Je\u00b7de", "von", "euch", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "PIAT", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die sich verging, la\u00df ihren Schleier fallen.\u00ab", "tokens": ["Die", "sich", "ver\u00b7ging", ",", "la\u00df", "ih\u00b7ren", "Schlei\u00b7er", "fal\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PRF", "VVFIN", "$,", "VVIMP", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Sie spricht's und \u2013 Hem! wer h\u00e4tte das gedacht?", "tokens": ["Sie", "spricht's", "und", "\u2013", "Hem", "!", "wer", "h\u00e4t\u00b7te", "das", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "$(", "NN", "$.", "PWS", "VAFIN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Diana spricht's, und \u2013 alle Schleier fallen.", "tokens": ["Di\u00b7a\u00b7na", "spricht's", ",", "und", "\u2013", "al\u00b7le", "Schlei\u00b7er", "fal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "KON", "$(", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Man stelle sich den Lermen vor", "tokens": ["Man", "stel\u00b7le", "sich", "den", "Ler\u00b7men", "vor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den die besch\u00e4mte G\u00f6ttin machte,", "tokens": ["Den", "die", "be\u00b7sch\u00e4m\u00b7te", "G\u00f6t\u00b7tin", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Indem der lose Cypripor", "tokens": ["In\u00b7dem", "der", "lo\u00b7se", "Cyp\u00b7ri\u00b7por"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus einer Wolke sah und laut herunter lachte.", "tokens": ["Aus", "ei\u00b7ner", "Wol\u00b7ke", "sah", "und", "laut", "her\u00b7un\u00b7ter", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbwie\u00ab, rief sie voller Wut empor,", "tokens": ["\u00bb", "wie", "\u00ab", ",", "rief", "sie", "vol\u00b7ler", "Wut", "em\u00b7por", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$(", "$,", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(doch selbst die Wut versch\u00f6nert ihre Wangen)", "tokens": ["(", "doch", "selbst", "die", "Wut", "ver\u00b7sch\u00f6\u00b7nert", "ih\u00b7re", "Wan\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbdu, Wildfang, hast dies Unheil angestellt,", "tokens": ["\u00bb", "du", ",", "Wild\u00b7fang", ",", "hast", "dies", "Un\u00b7heil", "an\u00b7ge\u00b7stellt", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "NN", "$,", "VAFIN", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und kommst noch gar damit zu prangen!", "tokens": ["Und", "kommst", "noch", "gar", "da\u00b7mit", "zu", "pran\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zwar r\u00fchmst du dich, da\u00df alle Welt", "tokens": ["Zwar", "r\u00fchmst", "du", "dich", ",", "da\u00df", "al\u00b7le", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fcr ihren Sieger dich erkenne", "tokens": ["F\u00fcr", "ih\u00b7ren", "Sie\u00b7ger", "dich", "er\u00b7ken\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df selbst der Vater Zeus so oft es dir gef\u00e4llt", "tokens": ["Da\u00df", "selbst", "der", "Va\u00b7ter", "Zeus", "so", "oft", "es", "dir", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NE", "ADV", "ADV", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von unerlaubten Flammen brenne;", "tokens": ["Von", "un\u00b7er\u00b7laub\u00b7ten", "Flam\u00b7men", "bren\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df, seiner Majest\u00e4t beraubt,", "tokens": ["Da\u00df", ",", "sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "be\u00b7raubt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So oft du willt, der G\u00f6tter Haupt", "tokens": ["So", "oft", "du", "willt", ",", "der", "G\u00f6t\u00b7ter", "Haupt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "VMFIN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Bald als ein Drache, bald als Stier", "tokens": ["Bald", "als", "ein", "Dra\u00b7che", ",", "bald", "als", "Stier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "$,", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Bald als ein b\u00f6ckischer Satyr,", "tokens": ["Bald", "als", "ein", "b\u00f6\u00b7cki\u00b7scher", "Sa\u00b7tyr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Und bald mit Stab und Sch\u00e4fer-Tasche", "tokens": ["Und", "bald", "mit", "Stab", "und", "Sch\u00e4\u00b7fer\u00b7Ta\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Der Nymphen Einfalt \u00fcberrasche.", "tokens": ["Der", "Nym\u00b7phen", "Ein\u00b7falt", "\u00fc\u00b7berr\u00b7a\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Doch trotze nicht zuviel auf deine Macht!", "tokens": ["Doch", "trot\u00b7ze", "nicht", "zu\u00b7viel", "auf", "dei\u00b7ne", "Macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die Siege die dir noch gelungen", "tokens": ["Die", "Sie\u00b7ge", "die", "dir", "noch", "ge\u00b7lun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Hat man dir leicht genug gemacht.", "tokens": ["Hat", "man", "dir", "leicht", "ge\u00b7nug", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wer selbst die Waffen streckt, wird ohne Ruhm bezwungen.", "tokens": ["Wer", "selbst", "die", "Waf\u00b7fen", "streckt", ",", "wird", "oh\u00b7ne", "Ruhm", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Auf mich, auf mich, die deine Macht verlacht,", "tokens": ["Auf", "mich", ",", "auf", "mich", ",", "die", "dei\u00b7ne", "Macht", "ver\u00b7lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "APPR", "PPER", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Auf meine Brust la\u00df deine Pfeile zielen.", "tokens": ["Auf", "mei\u00b7ne", "Brust", "la\u00df", "dei\u00b7ne", "Pfei\u00b7le", "zie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "(ich fordre dich vor tausend Zeugen auf!)", "tokens": ["(", "ich", "ford\u00b7re", "dich", "vor", "tau\u00b7send", "Zeu\u00b7gen", "auf", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "CARD", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Sie werden sich vor halbem Lauf", "tokens": ["Sie", "wer\u00b7den", "sich", "vor", "hal\u00b7bem", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "In meinen feuchten Strahlen k\u00fchlen", "tokens": ["In", "mei\u00b7nen", "feuch\u00b7ten", "Strah\u00b7len", "k\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und stumpf und matt um meinen Busen spielen.", "tokens": ["Und", "stumpf", "und", "matt", "um", "mei\u00b7nen", "Bu\u00b7sen", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Du lachst? Versuch's erst was dein Bogen kann,", "tokens": ["Du", "lachst", "?", "Ver\u00b7such's", "erst", "was", "dein", "Bo\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "ADV", "PWS", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Versuch's an mir und sing und lache dann!", "tokens": ["Ver\u00b7such's", "an", "mir", "und", "sing", "und", "la\u00b7che", "dann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "KON", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Doch st\u00fcnd es dir, versichert! besser an", "tokens": ["Doch", "st\u00fcnd", "es", "dir", ",", "ver\u00b7si\u00b7chert", "!", "bes\u00b7ser", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "VVPP", "$.", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Du k\u00e4mst statt K\u00f6cher, Pfeil und Bogen", "tokens": ["Du", "k\u00e4mst", "statt", "K\u00f6\u00b7cher", ",", "Pfeil", "und", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Mit einem Vogel-Rohr geflogen.", "tokens": ["Mit", "ei\u00b7nem", "Vo\u00b7gel\u00b7Rohr", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Latonens Kindern nur geb\u00fchrt", "tokens": ["La\u00b7to\u00b7nens", "Kin\u00b7dern", "nur", "ge\u00b7b\u00fchrt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Der edle Schmuck der deinen R\u00fccken ziert.", "tokens": ["Der", "ed\u00b7le", "Schmuck", "der", "dei\u00b7nen", "R\u00fc\u00b7cken", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Bald h\u00e4tt ich Lust, dich wehrlos heimzuschicken,", "tokens": ["Bald", "h\u00e4tt", "ich", "Lust", ",", "dich", "wehr\u00b7los", "heim\u00b7zu\u00b7schi\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Und, weil dein Fliegen dich zu Streichen nur verf\u00fchrt,", "tokens": ["Und", ",", "weil", "dein", "Flie\u00b7gen", "dich", "zu", "Strei\u00b7chen", "nur", "ver\u00b7f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "PRF", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Dir noch die Schwingen auszupfl\u00fccken.", "tokens": ["Dir", "noch", "die", "Schwin\u00b7gen", "aus\u00b7zu\u00b7pfl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Doch flieh nur wie du bist; la\u00df meinen Hain in Ruh,", "tokens": ["Doch", "flieh", "nur", "wie", "du", "bist", ";", "la\u00df", "mei\u00b7nen", "Hain", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KOKOM", "PPER", "VAFIN", "$.", "VVIMP", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Auf ewig flieh aus meinen Blicken,", "tokens": ["Auf", "e\u00b7wig", "flieh", "aus", "mei\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Und flattre deinem Paphos zu;", "tokens": ["Und", "flatt\u00b7re", "dei\u00b7nem", "Pa\u00b7phos", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Dort tummle dich auf weichen Rosen-Betten,", "tokens": ["Dort", "tumm\u00b7le", "dich", "auf", "wei\u00b7chen", "Ro\u00b7sen\u00b7Bet\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Mit deinen Grazien, und spiele blinde Kuh", "tokens": ["Mit", "dei\u00b7nen", "Gra\u00b7zi\u00b7en", ",", "und", "spie\u00b7le", "blin\u00b7de", "Kuh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Mit Zephyrn und mit Amoretten.\u00ab", "tokens": ["Mit", "Ze\u00b7phyrn", "und", "mit", "A\u00b7mo\u00b7ret\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Die G\u00f6ttin spricht's. Mit l\u00e4chelndem Gesicht", "tokens": ["Die", "G\u00f6t\u00b7tin", "spricht'", "s.", "Mit", "l\u00e4\u00b7cheln\u00b7dem", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Antwortet ihr der kleine Amor \u2013 nicht.", "tokens": ["Ant\u00b7wor\u00b7tet", "ihr", "der", "klei\u00b7ne", "A\u00b7mor", "\u2013", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NE", "$(", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gelassen langt er nur von ungef\u00e4hr", "tokens": ["Ge\u00b7las\u00b7sen", "langt", "er", "nur", "von", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den sch\u00e4rfsten Pfeil aus seinem K\u00f6cher her;", "tokens": ["Den", "sch\u00e4rfs\u00b7ten", "Pfeil", "aus", "sei\u00b7nem", "K\u00f6\u00b7cher", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch steckt er ihn, als h\u00e4tt er sich bedacht,", "tokens": ["Doch", "steckt", "er", "ihn", ",", "als", "h\u00e4tt", "er", "sich", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "KOKOM", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gleich wieder an, sieht Ph\u00f6ben an und lacht:", "tokens": ["Gleich", "wie\u00b7der", "an", ",", "sieht", "Ph\u00f6\u00b7ben", "an", "und", "lacht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbwie reizend schminkt der Eifer deine Wangen!", "tokens": ["\u00bb", "wie", "rei\u00b7zend", "schminkt", "der", "Ei\u00b7fer", "dei\u00b7ne", "Wan\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "(ruft er, und tut als wollt er sie umfangen)", "tokens": ["(", "ruft", "er", ",", "und", "tut", "als", "wollt", "er", "sie", "um\u00b7fan\u00b7gen", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "KON", "ADJD", "KOKOM", "VMFIN", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ich wollte dir wie Amors Wunde sticht", "tokens": ["Ich", "woll\u00b7te", "dir", "wie", "A\u00b7mors", "Wun\u00b7de", "sticht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "KOKOM", "NE", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein wenig zu versuchen geben;", "tokens": ["Ein", "we\u00b7nig", "zu", "ver\u00b7su\u00b7chen", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Allein, bei meiner Mutter Leben!", "tokens": ["Al\u00b7lein", ",", "bei", "mei\u00b7ner", "Mut\u00b7ter", "Le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Es braucht hier meiner Pfeile nicht.", "tokens": ["Es", "braucht", "hier", "mei\u00b7ner", "Pfei\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "An Spr\u00f6den, die mir Hohn gesprochen,", "tokens": ["An", "Spr\u00f6\u00b7den", ",", "die", "mir", "Hohn", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Hat mich noch stets ihr eignes Herz gerochen:", "tokens": ["Hat", "mich", "noch", "stets", "ihr", "eig\u00b7nes", "Herz", "ge\u00b7ro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und, Schwesterchen, (doch unter dir und mir:)", "tokens": ["Und", ",", "Schwes\u00b7ter\u00b7chen", ",", "(", "doch", "un\u00b7ter", "dir", "und", "mir", ":)"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "emoticon"], "pos": ["KON", "$,", "NN", "$,", "$(", "ADV", "APPR", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Was n\u00fctzt der Lerm? er k\u00f6nnte dich gereuen;", "tokens": ["Was", "n\u00fctzt", "der", "Lerm", "?", "er", "k\u00f6nn\u00b7te", "dich", "ge\u00b7reu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Weit sichrer w\u00e4r's, die kleine Ungeb\u00fchr", "tokens": ["Weit", "sich\u00b7rer", "w\u00e4r's", ",", "die", "klei\u00b7ne", "Un\u00b7ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Den guten Kindern zu verzeihen.\u00ab", "tokens": ["Den", "gu\u00b7ten", "Kin\u00b7dern", "zu", "ver\u00b7zei\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Die Nymphen l\u00e4chelten, und Amor flog davon.", "tokens": ["Die", "Nym\u00b7phen", "l\u00e4\u00b7chel\u00b7ten", ",", "und", "A\u00b7mor", "flog", "da\u00b7von", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "NE", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die G\u00f6ttin z\u00fcrnt, und r\u00e4cht an ihnen", "tokens": ["Die", "G\u00f6t\u00b7tin", "z\u00fcrnt", ",", "und", "r\u00e4cht", "an", "ih\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des losen Sp\u00f6tters Hohn.", "tokens": ["Des", "lo\u00b7sen", "Sp\u00f6t\u00b7ters", "Hohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbunw\u00fcrdige! Dianen mehr zu dienen,", "tokens": ["\u00bb", "un\u00b7w\u00fcr\u00b7di\u00b7ge", "!", "Di\u00b7a\u00b7nen", "mehr", "zu", "die\u00b7nen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$.", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "(spricht sie mit ernstem Angesicht)", "tokens": ["(", "spricht", "sie", "mit", "erns\u00b7tem", "An\u00b7ge\u00b7sicht", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Zur Strafe der verge\u00dfnen Pflicht", "tokens": ["Zur", "Stra\u00b7fe", "der", "ver\u00b7ge\u00df\u00b7nen", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hat euch mein Mond zum letztenmal geschienen.", "tokens": ["Hat", "euch", "mein", "Mond", "zum", "letz\u00b7ten\u00b7mal", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sobald sein Wagen nur den Horizont besteigt,", "tokens": ["So\u00b7bald", "sein", "Wa\u00b7gen", "nur", "den", "Ho\u00b7ri\u00b7zont", "be\u00b7steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sei euch verwehrt im Hain herumzustreichen", "tokens": ["Sei", "euch", "ver\u00b7wehrt", "im", "Hain", "her\u00b7um\u00b7zu\u00b7strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Bis sich des Tages Herold zeigt;", "tokens": ["Bis", "sich", "des", "Ta\u00b7ges", "He\u00b7rold", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Entflieht mit schnellem Fu\u00df, die einen in die Eichen,", "tokens": ["Ent\u00b7flieht", "mit", "schnel\u00b7lem", "Fu\u00df", ",", "die", "ei\u00b7nen", "in", "die", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,", "PRELS", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die \u00fcbrigen zu ihren Urnen hin;", "tokens": ["Die", "\u00fcb\u00b7ri\u00b7gen", "zu", "ih\u00b7ren", "Ur\u00b7nen", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Dort liegt und schlaft so lang ich Luna bin!\u00ab", "tokens": ["Dort", "liegt", "und", "schlaft", "so", "lang", "ich", "Lu\u00b7na", "bin", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADJD", "ADV", "ADJD", "PPER", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Sie spricht's und geht die Drachen anzuspannen", "tokens": ["Sie", "spricht's", "und", "geht", "die", "Dra\u00b7chen", "an\u00b7zu\u00b7span\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "VVIZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die ihren Silber-Wagen ziehn,", "tokens": ["Die", "ih\u00b7ren", "Sil\u00b7ber\u00b7Wa\u00b7gen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und die bestraften Nymphen fliehn", "tokens": ["Und", "die", "be\u00b7straf\u00b7ten", "Nym\u00b7phen", "fliehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Mehr traurig als belehrt von dannen.", "tokens": ["Mehr", "trau\u00b7rig", "als", "be\u00b7lehrt", "von", "dan\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Der Tag zerflie\u00dfet nun", "tokens": ["Der", "Tag", "zer\u00b7flie\u00b7\u00dfet", "nun"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im allgemeinen Schatten,", "tokens": ["Im", "all\u00b7ge\u00b7mei\u00b7nen", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und alle Wesen ruhn", "tokens": ["Und", "al\u00b7le", "We\u00b7sen", "ruhn"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die sich erm\u00fcdet hatten;", "tokens": ["Die", "sich", "er\u00b7m\u00fc\u00b7det", "hat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es schlummert Tal und Hain,", "tokens": ["Es", "schlum\u00b7mert", "Tal", "und", "Hain", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die Weste selbst ermatten", "tokens": ["Die", "Wes\u00b7te", "selbst", "er\u00b7mat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Von ihren Buhlerein,", "tokens": ["Von", "ih\u00b7ren", "Buh\u00b7le\u00b7rein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und schlafen unter K\u00fcssen", "tokens": ["Und", "schla\u00b7fen", "un\u00b7ter", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Im Scho\u00dfe von Narzissen", "tokens": ["Im", "Scho\u00b7\u00dfe", "von", "Nar\u00b7zis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und Rosen g\u00e4hnend ein.", "tokens": ["Und", "Ro\u00b7sen", "g\u00e4h\u00b7nend", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Der junge Satyr nur", "tokens": ["Der", "jun\u00b7ge", "Sa\u00b7tyr", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Verfolgt der Dryas Spur;", "tokens": ["Ver\u00b7folgt", "der", "Dryas", "Spur", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.13": {"text": "Er reckt sein langes Ohr", "tokens": ["Er", "reckt", "sein", "lan\u00b7ges", "Ohr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Bei jedem leisen Zischen", "tokens": ["Bei", "je\u00b7dem", "lei\u00b7sen", "Zi\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Aus dem Gestr\u00e4uch hervor,", "tokens": ["Aus", "dem", "Ge\u00b7str\u00e4uch", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Ein Nymphchen zu erwischen,", "tokens": ["Ein", "Nymph\u00b7chen", "zu", "er\u00b7wi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Das in den finstern B\u00fcschen", "tokens": ["Das", "in", "den", "fins\u00b7tern", "B\u00fc\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Vielleicht den Weg verlor.", "tokens": ["Viel\u00b7leicht", "den", "Weg", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Er sucht im ganzen Hain", "tokens": ["Er", "sucht", "im", "gan\u00b7zen", "Hain"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Mit wohl zerzausten F\u00fc\u00dfen;", "tokens": ["Mit", "wohl", "zer\u00b7zaus\u00b7ten", "F\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Umsonst! Der G\u00f6ttin Dr\u00e4un", "tokens": ["Um\u00b7sonst", "!", "Der", "G\u00f6t\u00b7tin", "Dr\u00e4un"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "ART", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Zwang sie sich einzuschlie\u00dfen;", "tokens": ["Zwang", "sie", "sich", "ein\u00b7zu\u00b7schlie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Die armen M\u00e4dchen m\u00fcssen", "tokens": ["Die", "ar\u00b7men", "M\u00e4d\u00b7chen", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "F\u00fcr k\u00fcrzre N\u00e4chte b\u00fc\u00dfen", "tokens": ["F\u00fcr", "k\u00fcrz\u00b7re", "N\u00e4ch\u00b7te", "b\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Und schlafen itzt allein.", "tokens": ["Und", "schla\u00b7fen", "itzt", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "Dem Faun sinkt Ohr und Mut,", "tokens": ["Dem", "Faun", "sinkt", "Ohr", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Er kehrt mit k\u00fchlerm Blut", "tokens": ["Er", "kehrt", "mit", "k\u00fch\u00b7lerm", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Beim ersten Morgen-Blick", "tokens": ["Beim", "ers\u00b7ten", "Mor\u00b7gen\u00b7Blick"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Zu seinem Schlauch zur\u00fcck.", "tokens": ["Zu", "sei\u00b7nem", "Schlauch", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.30": {"text": "Er denkt, mich zu erhenken", "tokens": ["Er", "denkt", ",", "mich", "zu", "er\u00b7hen\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Da m\u00fc\u00dft ich albern sein!", "tokens": ["Da", "m\u00fc\u00dft", "ich", "al\u00b7bern", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.32": {"text": "Ich will die Liebespein", "tokens": ["Ich", "will", "die", "Lie\u00b7be\u00b7spein"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "In s\u00fc\u00dfem Most ertr\u00e4nken.", "tokens": ["In", "s\u00fc\u00b7\u00dfem", "Most", "er\u00b7tr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Indessen schwebt der G\u00f6ttin Wagen schon", "tokens": ["In\u00b7des\u00b7sen", "schwebt", "der", "G\u00f6t\u00b7tin", "Wa\u00b7gen", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nah \u00fcber jenem Ort wo in des Gei\u00dfblatts Schatten", "tokens": ["Nah", "\u00fc\u00b7ber", "je\u00b7nem", "Ort", "wo", "in", "des", "Gei\u00df\u00b7blatts", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PDAT", "NN", "PWAV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Nymphen dir, Endymion,", "tokens": ["Die", "Nym\u00b7phen", "dir", ",", "En\u00b7dy\u00b7mi\u00b7on", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht auch sich, so sanft gebettet hatten.", "tokens": ["Viel\u00b7leicht", "auch", "sich", ",", "so", "sanft", "ge\u00b7bet\u00b7tet", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "$,", "ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie reizend lag er da! Nicht sch\u00f6ner lag Adon", "tokens": ["Wie", "rei\u00b7zend", "lag", "er", "da", "!", "Nicht", "sch\u00f6\u00b7ner", "lag", "A\u00b7don"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$.", "PTKNEG", "ADJD", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "An seiner G\u00f6ttin Brust, die weil er schlief ihm wachte,", "tokens": ["An", "sei\u00b7ner", "G\u00f6t\u00b7tin", "Brust", ",", "die", "weil", "er", "schlief", "ihm", "wach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PRELS", "KOUS", "PPER", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit Liebestrunknem Blick auf ihren Liebling lachte,", "tokens": ["Mit", "Lie\u00b7be\u00b7strunk\u00b7nem", "Blick", "auf", "ih\u00b7ren", "Lieb\u00b7ling", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und stillentz\u00fcckt auf neue Freuden dachte;", "tokens": ["Und", "stil\u00b7lent\u00b7z\u00fcckt", "auf", "neu\u00b7e", "Freu\u00b7den", "dach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nicht sch\u00f6ner ward der junge Ganymed", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "ward", "der", "jun\u00b7ge", "Ga\u00b7ny\u00b7med"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Vom Vater Zeus, der gro\u00dfe Augen dreht',", "tokens": ["Vom", "Va\u00b7ter", "Zeus", ",", "der", "gro\u00b7\u00dfe", "Au\u00b7gen", "dreht'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "In Junons Armen einst gefunden;", "tokens": ["In", "Ju\u00b7nons", "Ar\u00b7men", "einst", "ge\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht sch\u00f6ner lag, durch doppelte Gewalt", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "lag", ",", "durch", "dop\u00b7pel\u00b7te", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der Feerei und Sch\u00f6nheit \u00fcberwunden,", "tokens": ["Der", "Fee\u00b7rei", "und", "Sch\u00f6n\u00b7heit", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Der Wollust atmende Rinald", "tokens": ["Der", "Wol\u00b7lust", "at\u00b7men\u00b7de", "Ri\u00b7nald"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Von seiner Zauberin umwunden:", "tokens": ["Von", "sei\u00b7ner", "Zau\u00b7be\u00b7rin", "um\u00b7wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Als hier, vom Schlaf gebunden,", "tokens": ["Als", "hier", ",", "vom", "Schlaf", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Endymion \u2013 Gesteht, da\u00df die Gefahr", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "\u2013", "Ge\u00b7steht", ",", "da\u00df", "die", "Ge\u00b7fahr"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.18": {"text": "Nicht allzuklein f\u00fcr eine Spr\u00f6de war.", "tokens": ["Nicht", "all\u00b7zu\u00b7klein", "f\u00fcr", "ei\u00b7ne", "Spr\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Das Sicherste war hier die Augen zuzumachen.", "tokens": ["Das", "Si\u00b7chers\u00b7te", "war", "hier", "die", "Au\u00b7gen", "zu\u00b7zu\u00b7ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sie tat es nicht und warf, jedoch nur obenhin", "tokens": ["Sie", "tat", "es", "nicht", "und", "warf", ",", "je\u00b7doch", "nur", "o\u00b7ben\u00b7hin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "KON", "VVFIN", "$,", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und blinzend, einen Blick auf ihn.", "tokens": ["Und", "blin\u00b7zend", ",", "ei\u00b7nen", "Blick", "auf", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Sie stutzt und hemmt den Flug der schnellen Drachen,", "tokens": ["Sie", "stutzt", "und", "hemmt", "den", "Flug", "der", "schnel\u00b7len", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Schaut wieder hin, err\u00f6tet, bebt zur\u00fcck,", "tokens": ["Schaut", "wie\u00b7der", "hin", ",", "er\u00b7r\u00f6\u00b7tet", ",", "bebt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "VVPP", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Und suchet mit versch\u00e4mtem Blick", "tokens": ["Und", "su\u00b7chet", "mit", "ver\u00b7sch\u00e4m\u00b7tem", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Ob sie vielleicht belauschet werde;", "tokens": ["Ob", "sie", "viel\u00b7leicht", "be\u00b7lau\u00b7schet", "wer\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Doch da sie ganz allein sich sieht,", "tokens": ["Doch", "da", "sie", "ganz", "al\u00b7lein", "sich", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Lenkt sie mit ruhigerm Gem\u00fct", "tokens": ["Lenkt", "sie", "mit", "ru\u00b7hi\u00b7germ", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Den Silber-Wagen sanft zur Erde,", "tokens": ["Den", "Sil\u00b7ber\u00b7Wa\u00b7gen", "sanft", "zur", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "B\u00fcckt sich, auf ihren Arm gest\u00fctzt,", "tokens": ["B\u00fcckt", "sich", ",", "auf", "ih\u00b7ren", "Arm", "ge\u00b7st\u00fctzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Mit halbem Leib heraus und \u00fcberl\u00e4\u00dft sich itzt", "tokens": ["Mit", "hal\u00b7bem", "Leib", "he\u00b7raus", "und", "\u00fc\u00b7berl\u00b7\u00e4\u00dft", "sich", "itzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "KON", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dem Anschaun ganz, womit nach Platons Lehren", "tokens": ["Dem", "An\u00b7schaun", "ganz", ",", "wo\u00b7mit", "nach", "Pla\u00b7tons", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PWAV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Sich im Olymp die reinen Geister n\u00e4hren.", "tokens": ["Sich", "im", "O\u00b7lymp", "die", "rei\u00b7nen", "Geis\u00b7ter", "n\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.13": {"line.1": {"text": "Ein leicht beschattendes Gewand", "tokens": ["Ein", "leicht", "be\u00b7schat\u00b7ten\u00b7des", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erlaubt den ungewohnten Blicken", "tokens": ["Er\u00b7laubt", "den", "un\u00b7ge\u00b7wohn\u00b7ten", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur allzuviel sie zu ber\u00fccken.", "tokens": ["Nur", "all\u00b7zu\u00b7viel", "sie", "zu", "be\u00b7r\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man sagt so gar, sie zog mit leiser Hand", "tokens": ["Man", "sagt", "so", "gar", ",", "sie", "zog", "mit", "lei\u00b7ser", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auch dieses weg, doch wer hat zugesehen?", "tokens": ["Auch", "die\u00b7ses", "weg", ",", "doch", "wer", "hat", "zu\u00b7ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "PTKVZ", "$,", "KON", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und tat sie es, wof\u00fcr wir keinem stehen,", "tokens": ["Und", "tat", "sie", "es", ",", "wo\u00b7f\u00fcr", "wir", "kei\u00b7nem", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So zog sie doch beim ersten Blick", "tokens": ["So", "zog", "sie", "doch", "beim", "ers\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gewi\u00df die Hand so schnell zur\u00fcck", "tokens": ["Ge\u00b7wi\u00df", "die", "Hand", "so", "schnell", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als jenes Kind, das einst im Grase spielte,", "tokens": ["Als", "je\u00b7nes", "Kind", ",", "das", "einst", "im", "Gra\u00b7se", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nach Blumen griff und eine Schlange f\u00fchlte.", "tokens": ["Nach", "Blu\u00b7men", "griff", "und", "ei\u00b7ne", "Schlan\u00b7ge", "f\u00fchl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Indessen klopft vermischt mit banger Lust", "tokens": ["In\u00b7des\u00b7sen", "klopft", "ver\u00b7mischt", "mit", "ban\u00b7ger", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein s\u00fc\u00dfer Schmerz in ihrer hei\u00dfen Brust;", "tokens": ["Ein", "s\u00fc\u00b7\u00dfer", "Schmerz", "in", "ih\u00b7rer", "hei\u00b7\u00dfen", "Brust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein zitterndes, woll\u00fcstiges Verlangen", "tokens": ["Ein", "zit\u00b7tern\u00b7des", ",", "wol\u00b7l\u00fcs\u00b7ti\u00b7ges", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bew\u00f6lkt ihr schwimmend Aug und brennt auf ihren Wangen.", "tokens": ["Be\u00b7w\u00f6lkt", "ihr", "schwim\u00b7mend", "Aug", "und", "brennt", "auf", "ih\u00b7ren", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo, G\u00f6ttin, bleibt dein Stolz, die Spr\u00f6digkeit?", "tokens": ["Wo", ",", "G\u00f6t\u00b7tin", ",", "bleibt", "dein", "Stolz", ",", "die", "Spr\u00f6\u00b7dig\u00b7keit", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "$,", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dein Busen schmilzt wie Schnee in raschen Flammen.", "tokens": ["Dein", "Bu\u00b7sen", "schmilzt", "wie", "Schnee", "in", "ra\u00b7schen", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KOKOM", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Kannst du die Nymphen noch verdammen?", "tokens": ["Kannst", "du", "die", "Nym\u00b7phen", "noch", "ver\u00b7dam\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was ihre Schuld verdient, ist's Tadel oder Neid?", "tokens": ["Was", "ih\u00b7re", "Schuld", "ver\u00b7dient", ",", "ist's", "Ta\u00b7del", "o\u00b7der", "Neid", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$,", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.15": {"line.1": {"text": "Die Neugier hat, wie Zoroaster lehrt,", "tokens": ["Die", "Neu\u00b7gier", "hat", ",", "wie", "Zo\u00b7roas\u00b7ter", "lehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Von Anbeginn der Weiber Herz bet\u00f6rt.", "tokens": ["Von", "An\u00b7be\u00b7ginn", "der", "Wei\u00b7ber", "Herz", "be\u00b7t\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man denkt ein Blick, von Ferne, von der Seiten,", "tokens": ["Man", "denkt", "ein", "Blick", ",", "von", "Fer\u00b7ne", ",", "von", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein blo\u00dfer Blick, hat wenig zu bedeuten.", "tokens": ["Ein", "blo\u00b7\u00dfer", "Blick", ",", "hat", "we\u00b7nig", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "O! glaubet mir, ihr habt schon viel getan,", "tokens": ["O", "!", "glau\u00b7bet", "mir", ",", "ihr", "habt", "schon", "viel", "ge\u00b7tan", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der erste Blick zieht stets den andern an;", "tokens": ["Der", "ers\u00b7te", "Blick", "zieht", "stets", "den", "an\u00b7dern", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das Auge wird (es sagt's ein weiser Mann)", "tokens": ["Das", "Au\u00b7ge", "wird", "(", "es", "sagt's", "ein", "wei\u00b7ser", "Mann", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Nicht satt vom Sehn, und Lunas Beispiel kann,", "tokens": ["Nicht", "satt", "vom", "Sehn", ",", "und", "Lu\u00b7nas", "Bei\u00b7spiel", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPRART", "NN", "$,", "KON", "NE", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Uns hier, wie wahr er sagte, lehren.", "tokens": ["Uns", "hier", ",", "wie", "wahr", "er", "sag\u00b7te", ",", "leh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Ihr M\u00e4dchen, die ihr spr\u00f6de tut,", "tokens": ["Ihr", "M\u00e4d\u00b7chen", ",", "die", "ihr", "spr\u00f6\u00b7de", "tut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hier solltet ihr ein wenig \u00fcberh\u00f6ren;", "tokens": ["Hier", "soll\u00b7tet", "ihr", "ein", "we\u00b7nig", "\u00fc\u00b7ber\u00b7h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin euch diesesmal f\u00fcr kein Err\u00f6ten gut.", "tokens": ["Ich", "bin", "euch", "die\u00b7ses\u00b7mal", "f\u00fcr", "kein", "Er\u00b7r\u00f6\u00b7ten", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die F\u00e4cher vors Gesicht!", "tokens": ["Die", "F\u00e4\u00b7cher", "vors", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Diana \u2013 Nein! um Welten", "tokens": ["Di\u00b7a\u00b7na", "\u2013", "Nein", "!", "um", "Wel\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$(", "PTKANT", "$.", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Verriet' ich dieses nicht,", "tokens": ["Ver\u00b7ri\u00b7et'", "ich", "die\u00b7ses", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Sie lie\u00dfen mich's entgelten.", "tokens": ["Sie", "lie\u00b7\u00dfen", "mich's", "ent\u00b7gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Des jungen L\u00f6wen Grimm,", "tokens": ["Des", "jun\u00b7gen", "L\u00f6\u00b7wen", "Grimm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Des raschen Einhorns Mut,", "tokens": ["Des", "ra\u00b7schen", "Ein\u00b7horns", "Mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Ist nicht so ungest\u00fcm", "tokens": ["Ist", "nicht", "so", "un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Als junger Sch\u00f6nen Wut.", "tokens": ["Als", "jun\u00b7ger", "Sch\u00f6\u00b7nen", "Wut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Sie k\u00f6nnten sich verschw\u00f6ren", "tokens": ["Sie", "k\u00f6nn\u00b7ten", "sich", "ver\u00b7schw\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Mir nimmer zu verzeihn.", "tokens": ["Mir", "nim\u00b7mer", "zu", "ver\u00b7zeihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Nein! Wahrheit, dir zu Ehren", "tokens": ["Nein", "!", "Wahr\u00b7heit", ",", "dir", "zu", "Eh\u00b7ren"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "NN", "$,", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ein M\u00e4rtyrer zu sein,", "tokens": ["Ein", "M\u00e4r\u00b7ty\u00b7rer", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Bei Chloens Busen! Nein!", "tokens": ["Bei", "Chloens", "Bu\u00b7sen", "!", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "NE", "$.", "PTKANT", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.17": {"text": "Das hei\u00dft zuviel begehren.", "tokens": ["Das", "hei\u00dft", "zu\u00b7viel", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Doch, bin ich nicht zu scheu?", "tokens": ["Doch", ",", "bin", "ich", "nicht", "zu", "scheu", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Man wei\u00df, da\u00df uns die Feen", "tokens": ["Man", "wei\u00df", ",", "da\u00df", "uns", "die", "Feen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Oft lieber allzufrei", "tokens": ["Oft", "lie\u00b7ber", "all\u00b7zu\u00b7frei"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Als allzusch\u00fcchtern sehen.", "tokens": ["Als", "all\u00b7zu\u00b7sch\u00fcch\u00b7tern", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "Die Jungen danken mir", "tokens": ["Die", "Jun\u00b7gen", "dan\u00b7ken", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Vielleicht noch gar daf\u00fcr;", "tokens": ["Viel\u00b7leicht", "noch", "gar", "da\u00b7f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Die Weise lacht und spricht,", "tokens": ["Die", "Wei\u00b7se", "lacht", "und", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Mich \u00e4rgern M\u00e4rchen nicht;", "tokens": ["Mich", "\u00e4r\u00b7gern", "M\u00e4r\u00b7chen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "Und Mi\u00df Brigitte \u2013 Nun!", "tokens": ["Und", "Mi\u00df", "Bri\u00b7git\u00b7te", "\u2013", "Nun", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "NE", "$(", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Die l\u00e4\u00dft man b\u00f6se tun!", "tokens": ["Die", "l\u00e4\u00dft", "man", "b\u00f6\u00b7se", "tun", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Der Gegenstand, der Ort, die Zeit,", "tokens": ["Der", "Ge\u00b7gen\u00b7stand", ",", "der", "Ort", ",", "die", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird die Entschuldigung der G\u00f6ttin machen m\u00fcssen.", "tokens": ["Wird", "die", "Ent\u00b7schul\u00b7di\u00b7gung", "der", "G\u00f6t\u00b7tin", "ma\u00b7chen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Selbst ihre Unerfahrenheit", "tokens": ["Selbst", "ih\u00b7re", "Un\u00b7er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vermindert ihre Strafbarkeit.", "tokens": ["Ver\u00b7min\u00b7dert", "ih\u00b7re", "Straf\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So neu sie war, wie kann sie wissen,", "tokens": ["So", "neu", "sie", "war", ",", "wie", "kann", "sie", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie manche wissen's nicht, da\u00df man", "tokens": ["Wie", "man\u00b7che", "wis\u00b7sen's", "nicht", ",", "da\u00df", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "PTKNEG", "$,", "KOUS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vom Sehn sich auch berauschen kann?", "tokens": ["Vom", "Sehn", "sich", "auch", "be\u00b7rau\u00b7schen", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sie schaut, und da sie so wie aus sich selbst gerissen,", "tokens": ["Sie", "schaut", ",", "und", "da", "sie", "so", "wie", "aus", "sich", "selbst", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "ADV", "KOKOM", "APPR", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So uners\u00e4ttlich schaut, kommt ein Gelust sie an", "tokens": ["So", "un\u00b7er\u00b7s\u00e4tt\u00b7lich", "schaut", ",", "kommt", "ein", "Ge\u00b7lust", "sie", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "VVFIN", "ART", "NN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den sch\u00f6nen Schl\u00e4fer gar \u2013 zu k\u00fcssen.", "tokens": ["Den", "sch\u00f6\u00b7nen", "Schl\u00e4\u00b7fer", "gar", "\u2013", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Zu k\u00fcssen? Ja, doch man verstehe mich", "tokens": ["Zu", "k\u00fcs\u00b7sen", "?", "Ja", ",", "doch", "man", "ver\u00b7ste\u00b7he", "mich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "PTKANT", "$,", "KON", "PIS", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So z\u00fcchtig, so unk\u00f6rperlich,", "tokens": ["So", "z\u00fcch\u00b7tig", ",", "so", "un\u00b7k\u00f6r\u00b7per\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So sanft wie junge Zephyrs k\u00fcssen;", "tokens": ["So", "sanft", "wie", "jun\u00b7ge", "Ze\u00b7phyrs", "k\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit den Gedanken nur", "tokens": ["Mit", "den", "Ge\u00b7dan\u00b7ken", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Von einem solchen Ku\u00df,", "tokens": ["Von", "ei\u00b7nem", "sol\u00b7chen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wovon Ovidius", "tokens": ["Wo\u00b7von", "O\u00b7vi\u00b7dius"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Die ungetreue Spur", "tokens": ["Die", "un\u00b7ge\u00b7treu\u00b7e", "Spur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Nach mehr als einer Stunde", "tokens": ["Nach", "mehr", "als", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "(laut seiner eignen Hand)", "tokens": ["(", "laut", "sei\u00b7ner", "eig\u00b7nen", "Hand", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Auf seines M\u00e4dchens Munde", "tokens": ["Auf", "sei\u00b7nes", "M\u00e4d\u00b7chens", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und wei\u00dfen Schultern fand.", "tokens": ["Und", "wei\u00b7\u00dfen", "Schul\u00b7tern", "fand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Es kostet sie den Wunsch sich zu gestehen,", "tokens": ["Es", "kos\u00b7tet", "sie", "den", "Wunsch", "sich", "zu", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie gl\u00fcht von keuscher Scham vom Wirbel bis zum Zehen,", "tokens": ["Sie", "gl\u00fcht", "von", "keu\u00b7scher", "Scham", "vom", "Wir\u00b7bel", "bis", "zum", "Ze\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "APPRART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und lauscht und schaut sich um. Doch allgemeine Ruh", "tokens": ["Und", "lauscht", "und", "schaut", "sich", "um", ".", "Doch", "all\u00b7ge\u00b7mei\u00b7ne", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PRF", "PTKVZ", "$.", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Herrscht weit umher im Tal und auf den H\u00f6hen,", "tokens": ["Herrscht", "weit", "um\u00b7her", "im", "Tal", "und", "auf", "den", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Kein Bl\u00e4ttchen rauscht. Itzt schleicht sie leis hinzu,", "tokens": ["Kein", "Bl\u00e4tt\u00b7chen", "rauscht", ".", "Itzt", "schleicht", "sie", "leis", "hin\u00b7zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Bleibt unentschlossen vor ihm stehen,", "tokens": ["Bleibt", "un\u00b7ent\u00b7schlos\u00b7sen", "vor", "ihm", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Entschlie\u00dft sich, b\u00fcckt sich sanft auf seine Wangen hin,", "tokens": ["Ent\u00b7schlie\u00dft", "sich", ",", "b\u00fcckt", "sich", "sanft", "auf", "sei\u00b7ne", "Wan\u00b7gen", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "VVFIN", "PRF", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die, Rosen gleich, in s\u00fc\u00dfer R\u00f6te gl\u00fchn,", "tokens": ["Die", ",", "Ro\u00b7sen", "gleich", ",", "in", "s\u00fc\u00b7\u00dfer", "R\u00f6\u00b7te", "gl\u00fchn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und spitzt die Lippen schon, und itzt \u2013 itzt war's geschehen,", "tokens": ["Und", "spitzt", "die", "Lip\u00b7pen", "schon", ",", "und", "itzt", "\u2013", "itzt", "wa\u00b7r's", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "$,", "KON", "ADV", "$(", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Als eine neue Furcht (wie leicht", "tokens": ["Als", "ei\u00b7ne", "neu\u00b7e", "Furcht", "(", "wie", "leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "PWAV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wird eine Spr\u00f6de scheu!) sie schnell zur\u00fccke scheucht,", "tokens": ["Wird", "ei\u00b7ne", "Spr\u00f6\u00b7de", "scheu", "!", ")", "sie", "schnell", "zu\u00b7r\u00fc\u00b7cke", "scheucht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$.", "$(", "PPER", "ADJD", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie m\u00f6cht es noch so leise machen,", "tokens": ["Sie", "m\u00f6cht", "es", "noch", "so", "lei\u00b7se", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "So k\u00f6nnte doch der Schl\u00e4fer dran erwachen.", "tokens": ["So", "k\u00f6nn\u00b7te", "doch", "der", "Schl\u00e4\u00b7fer", "dran", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Was folgte drauf' Sie m\u00fc\u00dfte weiter gehn,", "tokens": ["Was", "folg\u00b7te", "drauf'", "Sie", "m\u00fc\u00df\u00b7te", "wei\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VVFIN", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ihm ihre Neigung eingestehn,", "tokens": ["Ihm", "ih\u00b7re", "Nei\u00b7gung", "ein\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Um seine Gegenliebe flehn", "tokens": ["Um", "sei\u00b7ne", "Ge\u00b7gen\u00b7lie\u00b7be", "flehn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und sich vielleicht \u2013 wer k\u00f6nnte das ertragen,", "tokens": ["Und", "sich", "viel\u00b7leicht", "\u2013", "wer", "k\u00f6nn\u00b7te", "das", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "$(", "PWS", "VMFIN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Vielleicht sich abgelesen sehn \u2013", "tokens": ["Viel\u00b7leicht", "sich", "ab\u00b7ge\u00b7le\u00b7sen", "sehn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVPP", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Welch ein Gedank! Kann Luna soviel wagen,", "tokens": ["Welch", "ein", "Ge\u00b7dank", "!", "Kann", "Lu\u00b7na", "so\u00b7viel", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "$.", "VMFIN", "NE", "PIS", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.31": {"text": "Bei einer Venus, ja, da m\u00f6chte so was gehn,", "tokens": ["Bei", "ei\u00b7ner", "Ve\u00b7nus", ",", "ja", ",", "da", "m\u00f6ch\u00b7te", "so", "was", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PTKANT", "$,", "ADV", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die gibt oft ungestraft den G\u00f6ttern was zu spa\u00dfen,", "tokens": ["Die", "gibt", "oft", "un\u00b7ge\u00b7straft", "den", "G\u00f6t\u00b7tern", "was", "zu", "spa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "ART", "NN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und kann sich eh im Netz ertappen lassen", "tokens": ["Und", "kann", "sich", "eh", "im", "Netz", "er\u00b7tap\u00b7pen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PRF", "KOUS", "APPRART", "NN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Als ich, die nun einmal die Spr\u00f6de machen mu\u00df,", "tokens": ["Als", "ich", ",", "die", "nun", "ein\u00b7mal", "die", "Spr\u00f6\u00b7de", "ma\u00b7chen", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Bei einem armen trocknen Ku\u00df.", "tokens": ["Bei", "ei\u00b7nem", "ar\u00b7men", "trock\u00b7nen", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Und wie' er sollte mich zu seinen F\u00fc\u00dfen sehn?", "tokens": ["Und", "wie'", "er", "soll\u00b7te", "mich", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Dianens Ehre sollt in seiner Willk\u00fcr stehn?", "tokens": ["Di\u00b7a\u00b7nens", "Eh\u00b7re", "sollt", "in", "sei\u00b7ner", "Will\u00b7k\u00fcr", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wie, Wenn er dann den Ehrfurchtsvollen machte", "tokens": ["Wie", ",", "Wenn", "er", "dann", "den", "Ehr\u00b7furchts\u00b7vol\u00b7len", "mach\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "(man kennt der Sch\u00e4fer Schelmerei)", "tokens": ["(", "man", "kennt", "der", "Sch\u00e4\u00b7fer", "Schel\u00b7me\u00b7rei", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Und meiner Schwachheit ohne Scheu", "tokens": ["Und", "mei\u00b7ner", "Schwach\u00b7heit", "oh\u00b7ne", "Scheu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "An einer Nymphe Busen lachte?", "tokens": ["An", "ei\u00b7ner", "Nym\u00b7phe", "Bu\u00b7sen", "lach\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Wie w\u00fcrde die der Rache sich erfreun,", "tokens": ["Wie", "w\u00fcr\u00b7de", "die", "der", "Ra\u00b7che", "sich", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Und meine Schmach von Hain zu Hain", "tokens": ["Und", "mei\u00b7ne", "Schmach", "von", "Hain", "zu", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Den Schwestern in die Ohren raunen?", "tokens": ["Den", "Schwes\u00b7tern", "in", "die", "Oh\u00b7ren", "rau\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Die eine spr\u00e4ch's der andern nach,", "tokens": ["Die", "ei\u00b7ne", "spr\u00e4ch's", "der", "an\u00b7dern", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Bald wi\u00dftens auch die Satyrs und die Faunen", "tokens": ["Bald", "wi\u00df\u00b7tens", "auch", "die", "Sa\u00b7tyrs", "und", "die", "Fau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Und s\u00e4ngen's laut beim n\u00e4chtlichen Gelach.", "tokens": ["Und", "s\u00e4n\u00b7gen's", "laut", "beim", "n\u00e4cht\u00b7li\u00b7chen", "Ge\u00b7lach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "In kurzem eilte die Geschichte", "tokens": ["In", "kur\u00b7zem", "eil\u00b7te", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Vermehrt, versch\u00f6nt, gleich einem Stadt-Ger\u00fcchte,", "tokens": ["Ver\u00b7mehrt", ",", "ver\u00b7sch\u00f6nt", ",", "gleich", "ei\u00b7nem", "Stadt\u00b7Ge\u00b7r\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Bis zu der obern G\u00f6tter Sitz;", "tokens": ["Bis", "zu", "der", "o\u00b7bern", "G\u00f6t\u00b7ter", "Sitz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Dem Momus, der beim Saft der Nektar-Reben", "tokens": ["Dem", "Mo\u00b7mus", ",", "der", "beim", "Saft", "der", "Nek\u00b7ta\u00b7r\u00b7Re\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "ART", "NN"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.52": {"text": "Die G\u00f6tter lachen macht, und Junons scharfen Witz", "tokens": ["Die", "G\u00f6t\u00b7ter", "la\u00b7chen", "macht", ",", "und", "Ju\u00b7nons", "schar\u00b7fen", "Witz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,", "KON", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Beim Teetisch neuen Stoff zu geben.", "tokens": ["Beim", "Tee\u00b7tisch", "neu\u00b7en", "Stoff", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Die G\u00f6ttin bebt, erbla\u00dft und gl\u00fcht", "tokens": ["Die", "G\u00f6t\u00b7tin", "bebt", ",", "er\u00b7bla\u00dft", "und", "gl\u00fcht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor so gef\u00e4hrlichen Gedanken,", "tokens": ["Vor", "so", "ge\u00b7f\u00e4hr\u00b7li\u00b7chen", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und wenn sie dort die Neigung zieht,", "tokens": ["Und", "wenn", "sie", "dort", "die", "Nei\u00b7gung", "zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So macht sie hier die Klugheit wanken.", "tokens": ["So", "macht", "sie", "hier", "die", "Klug\u00b7heit", "wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man sagt, bei Spr\u00f6den \u00fcberzieh", "tokens": ["Man", "sagt", ",", "bei", "Spr\u00f6\u00b7den", "\u00fc\u00b7ber\u00b7zieh"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liebe doch die Vorsicht nie.", "tokens": ["Die", "Lie\u00b7be", "doch", "die", "Vor\u00b7sicht", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Ku\u00df mag freilich sehr behagen,", "tokens": ["Ein", "Ku\u00df", "mag", "frei\u00b7lich", "sehr", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch ist's am Ende nur ein Ku\u00df;", "tokens": ["Doch", "ist's", "am", "En\u00b7de", "nur", "ein", "Ku\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Freuden, wo man zittern mu\u00df,", "tokens": ["Und", "Freu\u00b7den", ",", "wo", "man", "zit\u00b7tern", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sind doch (was auch Ovide sagen)", "tokens": ["Sind", "doch", "(", "was", "auch", "O\u00b7vi\u00b7de", "sa\u00b7gen", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$(", "PWS", "ADV", "NE", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "F\u00fcr Damen nicht, die gerne sicher gehn.", "tokens": ["F\u00fcr", "Da\u00b7men", "nicht", ",", "die", "ger\u00b7ne", "si\u00b7cher", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "$,", "PRELS", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sie f\u00e4ngt schon an nach ihrem Drachen-Wagen", "tokens": ["Sie", "f\u00e4ngt", "schon", "an", "nach", "ih\u00b7rem", "Dra\u00b7chen\u00b7Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Den scheuen Blick herumzudrehn,", "tokens": ["Den", "scheu\u00b7en", "Blick", "her\u00b7um\u00b7zu\u00b7drehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Schon weicht ihr scheuer Fu\u00df \u2013 doch bleibt er wieder stehn;", "tokens": ["Schon", "weicht", "ihr", "scheu\u00b7er", "Fu\u00df", "\u2013", "doch", "bleibt", "er", "wie\u00b7der", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Sie kann den Trost sich nicht versagen", "tokens": ["Sie", "kann", "den", "Trost", "sich", "nicht", "ver\u00b7sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PRF", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nur einmal noch (sie hat ja nichts dabei zu wagen)", "tokens": ["Nur", "ein\u00b7mal", "noch", "(", "sie", "hat", "ja", "nichts", "da\u00b7bei", "zu", "wa\u00b7gen", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$(", "PPER", "VAFIN", "ADV", "PIS", "PAV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den sch\u00f6nen Schl\u00e4fer anzusehn.", "tokens": ["Den", "sch\u00f6\u00b7nen", "Schl\u00e4\u00b7fer", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "\u00bbnoch einmal?\u00ab ruft ein Casuist;", "tokens": ["\u00bb", "noch", "ein\u00b7mal", "?", "\u00ab", "ruft", "ein", "Ca\u00b7su\u00b7ist", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund hei\u00dft denn das nicht alles wagen?\u00ab", "tokens": ["\u00bb", "und", "hei\u00dft", "denn", "das", "nicht", "al\u00b7les", "wa\u00b7gen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "KON", "PDS", "PTKNEG", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vielleicht; doch ist es, wie ihr wi\u00dft,", "tokens": ["Viel\u00b7leicht", ";", "doch", "ist", "es", ",", "wie", "ihr", "wi\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Genug, die G\u00f6ttin loszusagen,", "tokens": ["Ge\u00b7nug", ",", "die", "G\u00f6t\u00b7tin", "los\u00b7zu\u00b7sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sie es nicht gemeint; die Frist", "tokens": ["Da\u00df", "sie", "es", "nicht", "ge\u00b7meint", ";", "die", "Frist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVPP", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War allzukurz, euch Rats zu fragen;", "tokens": ["War", "all\u00b7zu\u00b7kurz", ",", "euch", "Rats", "zu", "fra\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcberdem verg\u00f6nnet mir zu sagen,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7dem", "ver\u00b7g\u00f6n\u00b7net", "mir", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df Escobar auf ihrer Seite ist.", "tokens": ["Da\u00df", "E\u00b7sco\u00b7bar", "auf", "ih\u00b7rer", "Sei\u00b7te", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Vorsichtig oder unvorsichtig,", "tokens": ["Vor\u00b7sich\u00b7tig", "o\u00b7der", "un\u00b7vor\u00b7sich\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "(uns gilt es gleich) genug, soviel ist richtig,", "tokens": ["(", "uns", "gilt", "es", "gleich", ")", "ge\u00b7nug", ",", "so\u00b7viel", "ist", "rich\u00b7tig", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "$(", "ADV", "$,", "PIS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Sie b\u00fcckte sich noch einmal hin und sah,", "tokens": ["Sie", "b\u00fcck\u00b7te", "sich", "noch", "ein\u00b7mal", "hin", "und", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "(doch mit dem Vorsatz, ihn auf ewig dann zu fliehen)", "tokens": ["(", "doch", "mit", "dem", "Vor\u00b7satz", ",", "ihn", "auf", "e\u00b7wig", "dann", "zu", "flie\u00b7hen", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "$,", "PPER", "APPR", "ADJD", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Den holden Schl\u00e4fer an. Betrogne Cynthia!", "tokens": ["Den", "hol\u00b7den", "Schl\u00e4\u00b7fer", "an", ".", "Be\u00b7trog\u00b7ne", "Cyn\u00b7thia", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "NN", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Sie sieht, schon kann sie ihm den Blick nicht mehr entziehen,", "tokens": ["Sie", "sieht", ",", "schon", "kann", "sie", "ihm", "den", "Blick", "nicht", "mehr", "ent\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und bald vergi\u00dft sie auch zu fliehen.", "tokens": ["Und", "bald", "ver\u00b7gi\u00dft", "sie", "auch", "zu", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ein fremdes Feuer schleicht durch ihren ganzen Leib,", "tokens": ["Ein", "frem\u00b7des", "Feu\u00b7er", "schleicht", "durch", "ih\u00b7ren", "gan\u00b7zen", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ihr feuchtes Aug erlischt, die runden Kniee beben,", "tokens": ["Ihr", "feuch\u00b7tes", "Aug", "er\u00b7lischt", ",", "die", "run\u00b7den", "Kni\u00b7ee", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sie kennt sich selbst nicht mehr, und f\u00fchlt in ihrem Leben", "tokens": ["Sie", "kennt", "sich", "selbst", "nicht", "mehr", ",", "und", "f\u00fchlt", "in", "ih\u00b7rem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKNEG", "ADV", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sich itzt zum erstenmal ein Weib.", "tokens": ["Sich", "itzt", "zum", "ers\u00b7ten\u00b7mal", "ein", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPRART", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Erst lie\u00df sich ihr Gelust mit einem Kusse b\u00fc\u00dfen,", "tokens": ["Erst", "lie\u00df", "sich", "ihr", "Ge\u00b7lust", "mit", "ei\u00b7nem", "Kus\u00b7se", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Itzt w\u00fcnscht sie schon sich satt an ihm zu k\u00fcssen.", "tokens": ["Itzt", "w\u00fcnscht", "sie", "schon", "sich", "satt", "an", "ihm", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Doch macht sie stets die alte Sorge scheu.", "tokens": ["Doch", "macht", "sie", "stets", "die", "al\u00b7te", "Sor\u00b7ge", "scheu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Diana mu\u00df sich sicher wissen,", "tokens": ["Di\u00b7a\u00b7na", "mu\u00df", "sich", "si\u00b7cher", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "Und wird ein bi\u00dfchen Feerei", "tokens": ["Und", "wird", "ein", "bi\u00df\u00b7chen", "Fee\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-++", "measure": "unknown.measure.tetra"}, "line.25": {"text": "Zu brauchen sich entschlie\u00dfen m\u00fcssen.", "tokens": ["Zu", "brau\u00b7chen", "sich", "ent\u00b7schlie\u00b7\u00dfen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PRF", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Es wallt durch ihre Kunst", "tokens": ["Es", "wallt", "durch", "ih\u00b7re", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ein zauberischer Dunst,", "tokens": ["Ein", "zau\u00b7be\u00b7ri\u00b7scher", "Dunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Schlummer-Kr\u00e4ften schwer,", "tokens": ["Von", "Schlum\u00b7mer\u00b7Kr\u00e4f\u00b7ten", "schwer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Um ihren Liebling her.", "tokens": ["Um", "ih\u00b7ren", "Lieb\u00b7ling", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er dehnt sich, streckt ein Bein", "tokens": ["Er", "dehnt", "sich", ",", "streckt", "ein", "Bein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und schl\u00e4ft bezaubert ein.", "tokens": ["Und", "schl\u00e4ft", "be\u00b7zau\u00b7bert", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sie legt sich neben ihn", "tokens": ["Sie", "legt", "sich", "ne\u00b7ben", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Aufs Rosenlager hin,", "tokens": ["Aufs", "Ro\u00b7sen\u00b7la\u00b7ger", "hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "(es hatte, wie wir wissen,", "tokens": ["(", "es", "hat\u00b7te", ",", "wie", "wir", "wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "F\u00fcr eine Freundin Raum)", "tokens": ["F\u00fcr", "ei\u00b7ne", "Freun\u00b7din", "Raum", ")"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und unter ihren K\u00fcssen", "tokens": ["Und", "un\u00b7ter", "ih\u00b7ren", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Den Schlaf ihm zu vers\u00fc\u00dfen", "tokens": ["Den", "Schlaf", "ihm", "zu", "ver\u00b7s\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Wird jeder Ku\u00df ein Traum.", "tokens": ["Wird", "je\u00b7der", "Ku\u00df", "ein", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Ein Traumgesicht von jener Art,", "tokens": ["Ein", "Traum\u00b7ge\u00b7sicht", "von", "je\u00b7ner", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die oft, trotz Scapulier und Bart,", "tokens": ["Die", "oft", ",", "trotz", "Sca\u00b7pu\u00b7lier", "und", "Bart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sanct Franzens fette Seraphinen", "tokens": ["Sanct", "Fran\u00b7zens", "fet\u00b7te", "Se\u00b7ra\u00b7phi\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In schw\u00fcler Sommer-Nacht bedienen;", "tokens": ["In", "schw\u00fc\u00b7ler", "Som\u00b7mer\u00b7Nacht", "be\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Traum, wovor selbst in der Fasten-Zeit", "tokens": ["Ein", "Traum", ",", "wo\u00b7vor", "selbst", "in", "der", "Fas\u00b7ten\u00b7Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Sich keine junge Nonne scheut,", "tokens": ["Sich", "kei\u00b7ne", "jun\u00b7ge", "Non\u00b7ne", "scheut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der, wie das fromme Ding in seiner Einfalt denket,", "tokens": ["Der", ",", "wie", "das", "from\u00b7me", "Ding", "in", "sei\u00b7ner", "Ein\u00b7falt", "den\u00b7ket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie bis ins Paradies entz\u00fcckt,", "tokens": ["Sie", "bis", "ins", "Pa\u00b7ra\u00b7dies", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit einem Strom von Wollust tr\u00e4nket,", "tokens": ["Mit", "ei\u00b7nem", "Strom", "von", "Wol\u00b7lust", "tr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und f\u00fchlen l\u00e4\u00dft was nie ihr Aug erblickt.", "tokens": ["Und", "f\u00fch\u00b7len", "l\u00e4\u00dft", "was", "nie", "ihr", "Aug", "er\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PWS", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Ob Luna selbst dabei was abgezielet \u2013", "tokens": ["Ob", "Lu\u00b7na", "selbst", "da\u00b7bei", "was", "ab\u00b7ge\u00b7zie\u00b7let", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PAV", "PWS", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob ihr das schelmische Gesicht,", "tokens": ["Ob", "ihr", "das", "schel\u00b7mi\u00b7sche", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Cupido, einen Streich gespielet \u2013", "tokens": ["Cu\u00b7pi\u00b7do", ",", "ei\u00b7nen", "Streich", "ge\u00b7spie\u00b7let", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Entscheidet die Geschichte nicht.", "tokens": ["Ent\u00b7schei\u00b7det", "die", "Ge\u00b7schich\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Genug, wir kennen die und den,", "tokens": ["Ge\u00b7nug", ",", "wir", "ken\u00b7nen", "die", "und", "den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "KON", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die gerne nie erwachen wollten,", "tokens": ["Die", "ger\u00b7ne", "nie", "er\u00b7wa\u00b7chen", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn sie Aeonenlang so sch\u00f6n", "tokens": ["Wenn", "sie", "A\u00b7e\u00b7o\u00b7nen\u00b7lang", "so", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Wie unser Sch\u00e4fer tr\u00e4umen sollten.", "tokens": ["Wie", "un\u00b7ser", "Sch\u00e4\u00b7fer", "tr\u00e4u\u00b7men", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Was Jupiter als Ledas Schwan", "tokens": ["Was", "Ju\u00b7pi\u00b7ter", "als", "Le\u00b7das", "Schwan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KOUS", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als Europens Stier getan,", "tokens": ["Und", "als", "Eu\u00b7ro\u00b7pens", "Stier", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie er Alkmenen hintergangen,", "tokens": ["Wie", "er", "A\u00b7lkme\u00b7nen", "hin\u00b7ter\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie der hinkende Vulcan", "tokens": ["Und", "wie", "der", "hin\u00b7ken\u00b7de", "Vul\u00b7can"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sein Weibchen einst im Garn gefangen;", "tokens": ["Sein", "Weib\u00b7chen", "einst", "im", "Garn", "ge\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie stille Nymphen oft im Hain", "tokens": ["Wie", "stil\u00b7le", "Nym\u00b7phen", "oft", "im", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dem Faun zum Raube werden m\u00fcssen,", "tokens": ["Dem", "Faun", "zum", "Rau\u00b7be", "wer\u00b7den", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie sie sich str\u00e4uben, bitten, dr\u00e4un,", "tokens": ["Wie", "sie", "sich", "str\u00e4u\u00b7ben", ",", "bit\u00b7ten", ",", "dr\u00e4un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Erm\u00fcden, immer schw\u00e4cher schrein,", "tokens": ["Er\u00b7m\u00fc\u00b7den", ",", "im\u00b7mer", "schw\u00e4\u00b7cher", "schrein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und endlich selbst den R\u00e4uber k\u00fcssen;", "tokens": ["Und", "end\u00b7lich", "selbst", "den", "R\u00e4u\u00b7ber", "k\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Des Weingotts Zug, und wie um ihn", "tokens": ["Des", "Wein\u00b7gotts", "Zug", ",", "und", "wie", "um", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "PWAV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die taumelnden Bacchanten schw\u00e4rmen,", "tokens": ["Die", "tau\u00b7meln\u00b7den", "Bac\u00b7chan\u00b7ten", "schw\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wie sie von trunkner Freude gl\u00fchn,", "tokens": ["Wie", "sie", "von", "trunk\u00b7ner", "Freu\u00b7de", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und mit den Klapper-Blechen lermen;", "tokens": ["Und", "mit", "den", "Klap\u00b7per\u00b7Ble\u00b7chen", "ler\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Sie wiehern laut ihr Evoe!", "tokens": ["Sie", "wie\u00b7hern", "laut", "ihr", "E\u00b7voe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Es hallt vom fernen Rhodope", "tokens": ["Es", "hallt", "vom", "fer\u00b7nen", "Rho\u00b7do\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Zur\u00fcck; der Satyr hebt mit rasender Geb\u00e4rde", "tokens": ["Zu\u00b7r\u00fcck", ";", "der", "Sa\u00b7tyr", "hebt", "mit", "ra\u00b7sen\u00b7der", "Ge\u00b7b\u00e4r\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKVZ", "$.", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die nackte Menas in die H\u00f6h,", "tokens": ["Die", "nack\u00b7te", "Me\u00b7nas", "in", "die", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und stampft in wildem Tanz die Erde.", "tokens": ["Und", "stampft", "in", "wil\u00b7dem", "Tanz", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Ein sanftrer Anblick folgt dem rohen Bacchanal.", "tokens": ["Ein", "sanf\u00b7trer", "An\u00b7blick", "folgt", "dem", "ro\u00b7hen", "Bac\u00b7cha\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein stilles, schattenvolles Tal", "tokens": ["Ein", "stil\u00b7les", ",", "schat\u00b7ten\u00b7vol\u00b7les", "Tal"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fchrt ihn der H\u00f6hle zu, wo sich die Nymphen baden;", "tokens": ["F\u00fchrt", "ihn", "der", "H\u00f6h\u00b7le", "zu", ",", "wo", "sich", "die", "Nym\u00b7phen", "ba\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "PWAV", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Diana selbst err\u00f6tet nicht", "tokens": ["Di\u00b7a\u00b7na", "selbst", "er\u00b7r\u00f6\u00b7tet", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "(man merke, nur im Traumgesicht", "tokens": ["(", "man", "mer\u00b7ke", ",", "nur", "im", "Traum\u00b7ge\u00b7sicht"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PIS", "VVFIN", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und von gesch\u00e4ftigen Najaden", "tokens": ["Und", "von", "ge\u00b7sch\u00e4f\u00b7ti\u00b7gen", "Na\u00b7ja\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fast ganz verdeckt) von ihm gesehn zu sein.", "tokens": ["Fast", "ganz", "ver\u00b7deckt", ")", "von", "ihm", "ge\u00b7sehn", "zu", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$(", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Welch reizendes Gew\u00fchl! Es scheint vom Widerschein", "tokens": ["Welch", "rei\u00b7zen\u00b7des", "Ge\u00b7w\u00fchl", "!", "Es", "scheint", "vom", "Wi\u00b7der\u00b7schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So mancher wei\u00dfen Brust die sich im Wasser bildet,", "tokens": ["So", "man\u00b7cher", "wei\u00b7\u00dfen", "Brust", "die", "sich", "im", "Was\u00b7ser", "bil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "ART", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So manches goldnen Haars, die Flut hier \u00fcberg\u00fcldet,", "tokens": ["So", "man\u00b7ches", "gold\u00b7nen", "Haars", ",", "die", "Flut", "hier", "\u00fc\u00b7berg\u00b7\u00fcl\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dort Schnee im Sonnen-Glanz zu sein.", "tokens": ["Dort", "Schnee", "im", "Son\u00b7nen\u00b7Glanz", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPRART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Sein trunknes Auge schlingt mit gierig offnen Blicken", "tokens": ["Sein", "trunk\u00b7nes", "Au\u00b7ge", "schlingt", "mit", "gie\u00b7rig", "off\u00b7nen", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So viele Reizungen hinein,", "tokens": ["So", "vie\u00b7le", "Rei\u00b7zun\u00b7gen", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.14": {"text": "Er schwimmt in l\u00fcsternem Entz\u00fccken", "tokens": ["Er", "schwimmt", "in", "l\u00fcs\u00b7ter\u00b7nem", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und wird vor Wunder fast zum Stein.", "tokens": ["Und", "wird", "vor", "Wun\u00b7der", "fast", "zum", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.26": {"line.1": {"text": "Man glaubt, da\u00df Cynthia hiebei", "tokens": ["Man", "glaubt", ",", "da\u00df", "Cyn\u00b7thia", "hie\u00b7bei"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "NE", "PAV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Nicht unger\u00fchrt geblieben sei;", "tokens": ["Nicht", "un\u00b7ge\u00b7r\u00fchrt", "ge\u00b7blie\u00b7ben", "sei", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So s\u00fc\u00df auch K\u00fcsse sind, wenn wir Tibulle h\u00f6ren,", "tokens": ["So", "s\u00fc\u00df", "auch", "K\u00fcs\u00b7se", "sind", ",", "wenn", "wir", "Ti\u00b7bul\u00b7le", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "NN", "VAFIN", "$,", "KOUS", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ha\u00dft doch die Natur ein ewig Einerlei.", "tokens": ["So", "ha\u00dft", "doch", "die", "Na\u00b7tur", "ein", "e\u00b7wig", "Ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beim Nectartisch und beim Konzert der Sph\u00e4ren", "tokens": ["Beim", "Nec\u00b7tar\u00b7tisch", "und", "beim", "Kon\u00b7zert", "der", "Sph\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Sind G\u00f6tter selbst nicht stets von Langerweile frei.", "tokens": ["Sind", "G\u00f6t\u00b7ter", "selbst", "nicht", "stets", "von", "Lan\u00b7ger\u00b7wei\u00b7le", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "PTKNEG", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zum mindsten sagt's Homer. Wie wird dann, satt von K\u00fcssen,", "tokens": ["Zum", "minds\u00b7ten", "sagt's", "Ho\u00b7mer", ".", "Wie", "wird", "dann", ",", "satt", "von", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "NE", "$.", "PWAV", "VAFIN", "ADV", "$,", "KOUI", "APPR", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Diana sich zu helfen wissen?", "tokens": ["Di\u00b7a\u00b7na", "sich", "zu", "hel\u00b7fen", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbsie tat (so sagt der Faun, der sie beschlichen hat)", "tokens": ["\u00bb", "sie", "tat", "(", "so", "sagt", "der", "Faun", ",", "der", "sie", "be\u00b7schli\u00b7chen", "hat", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$(", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was Platons Penia im G\u00f6tter-Garten tat.\u00ab", "tokens": ["Was", "Pla\u00b7tons", "Pe\u00b7nia", "im", "G\u00f6t\u00b7ter\u00b7Gar\u00b7ten", "tat", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "NE", "NE", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "\u00bbwas tat dann die?\u00ab wird hier ein Neuling fragen?", "tokens": ["\u00bb", "was", "tat", "dann", "die", "?", "\u00ab", "wird", "hier", "ein", "Neu\u00b7ling", "fra\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ART", "$.", "$(", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sie legte \u2013 Ja doch! Nur gemach!", "tokens": ["Sie", "leg\u00b7te", "\u2013", "Ja", "doch", "!", "Nur", "ge\u00b7mach", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PTKANT", "ADV", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Schlagt euern Plato selber nach,", "tokens": ["Schlagt", "eu\u00b7ern", "Pla\u00b7to", "sel\u00b7ber", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das l\u00e4\u00dft sich nur auf Griechisch sagen.", "tokens": ["Das", "l\u00e4\u00dft", "sich", "nur", "auf", "Grie\u00b7chisch", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Verliebt und weise sein, ist, wie ein Alter glaubt,", "tokens": ["Ver\u00b7liebt", "und", "wei\u00b7se", "sein", ",", "ist", ",", "wie", "ein", "Al\u00b7ter", "glaubt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VAINF", "$,", "VAFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den G\u00f6ttern kaum, den Menschen nie erlaubt.", "tokens": ["Den", "G\u00f6t\u00b7tern", "kaum", ",", "den", "Men\u00b7schen", "nie", "er\u00b7laubt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Wer ganz Empfindung ist, kann keine Schl\u00fcsse machen.", "tokens": ["Wer", "ganz", "Emp\u00b7fin\u00b7dung", "ist", ",", "kann", "kei\u00b7ne", "Schl\u00fcs\u00b7se", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "$,", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Gegenstand, der itzt Dianen an sich zieht,", "tokens": ["Der", "Ge\u00b7gen\u00b7stand", ",", "der", "itzt", "Di\u00b7a\u00b7nen", "an", "sich", "zieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Macht, wie Galen bemerkt, nebst Wallung im Gebl\u00fct,", "tokens": ["Macht", ",", "wie", "Ga\u00b7len", "be\u00b7merkt", ",", "nebst", "Wal\u00b7lung", "im", "Ge\u00b7bl\u00fct", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "NN", "VVPP", "$,", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "Die Augen \u00fcbergehn und die Vernunft erschwachen;", "tokens": ["Die", "Au\u00b7gen", "\u00fc\u00b7ber\u00b7gehn", "und", "die", "Ver\u00b7nunft", "er\u00b7schwa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und Martialis mu\u00df gestehn,", "tokens": ["Und", "Mar\u00b7ti\u00b7a\u00b7lis", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "Da\u00df selbst Cornelia, die Mutter beider Gracchen,", "tokens": ["Da\u00df", "selbst", "Cor\u00b7ne\u00b7lia", ",", "die", "Mut\u00b7ter", "bei\u00b7der", "Grac\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "$,", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "Mit kaltem Blut ihn selten angesehn.", "tokens": ["Mit", "kal\u00b7tem", "Blut", "ihn", "sel\u00b7ten", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.27": {"line.1": {"text": "Die Spr\u00f6den m\u00f6gen sich hier ein Exempel nehmen.", "tokens": ["Die", "Spr\u00f6\u00b7den", "m\u00f6\u00b7gen", "sich", "hier", "ein", "Ex\u00b7em\u00b7pel", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das sch\u00f6ne Volk nicht zu besch\u00e4men,", "tokens": ["Das", "sch\u00f6\u00b7ne", "Volk", "nicht", "zu", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verschwieg ich gern, wie tief Diana fiel;", "tokens": ["Ver\u00b7schwieg", "ich", "gern", ",", "wie", "tief", "Di\u00b7a\u00b7na", "fiel", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allein der Faun verriet das ganze Spiel.", "tokens": ["Al\u00b7lein", "der", "Faun", "ver\u00b7riet", "das", "gan\u00b7ze", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zum Ungl\u00fcck war's der schlimmste unter allen.", "tokens": ["Zum", "Un\u00b7gl\u00fcck", "wa\u00b7r's", "der", "schlimms\u00b7te", "un\u00b7ter", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "ADJA", "APPR", "PIAT", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Er hatte, wie gesagt, den Nymphen zu gefallen", "tokens": ["Er", "hat\u00b7te", ",", "wie", "ge\u00b7sagt", ",", "den", "Nym\u00b7phen", "zu", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den ganzen Hain umsonst durchsp\u00fcrt,", "tokens": ["Den", "gan\u00b7zen", "Hain", "um\u00b7sonst", "durch\u00b7sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und dachte gleich zu seinen vollen Schl\u00e4uchen", "tokens": ["Und", "dach\u00b7te", "gleich", "zu", "sei\u00b7nen", "vol\u00b7len", "Schl\u00e4u\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sich unbemerkt zur\u00fcckzuschleichen,", "tokens": ["Sich", "un\u00b7be\u00b7merkt", "zu\u00b7r\u00fcck\u00b7zu\u00b7schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als aus den nahen Myrten-Str\u00e4uchen", "tokens": ["Als", "aus", "den", "na\u00b7hen", "Myr\u00b7ten\u00b7Str\u00e4u\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sein lauschend Ohr ein wollust-atmend Keuchen", "tokens": ["Sein", "lau\u00b7schend", "Ohr", "ein", "wol\u00b7lust\u00b7at\u00b7mend", "Keu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ein liebliches Geseufz und s\u00fc\u00dfes Girren r\u00fchrt.", "tokens": ["Ein", "lieb\u00b7li\u00b7ches", "Ge\u00b7seufz", "und", "s\u00fc\u00b7\u00dfes", "Gir\u00b7ren", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Satyr stutzt und denkt bei sich:", "tokens": ["Der", "Sa\u00b7tyr", "stutzt", "und", "denkt", "bei", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hier ist man gl\u00fccklicher als ich,", "tokens": ["Hier", "ist", "man", "gl\u00fcck\u00b7li\u00b7cher", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dies Seufzen hat was zu bedeuten.", "tokens": ["Dies", "Seuf\u00b7zen", "hat", "was", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So seufzt, beim Styx! trostlose Liebe nicht.", "tokens": ["So", "seufzt", ",", "beim", "Styx", "!", "trost\u00b7lo\u00b7se", "Lie\u00b7be", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPRART", "NN", "$.", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Er schleicht dem Tone nach und sieht ein hellers Licht", "tokens": ["Er", "schleicht", "dem", "To\u00b7ne", "nach", "und", "sieht", "ein", "hel\u00b7lers", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sich \u00fcber das Geb\u00fcsch verbreiten,", "tokens": ["Sich", "\u00fc\u00b7ber", "das", "Ge\u00b7b\u00fcsch", "ver\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Schleicht immer fort, entdeckt das Drachen-Paar,", "tokens": ["Schleicht", "im\u00b7mer", "fort", ",", "ent\u00b7deckt", "das", "Dra\u00b7chen\u00b7Paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die ungeduldig sich am leeren Wagen str\u00e4uben,", "tokens": ["Die", "un\u00b7ge\u00b7dul\u00b7dig", "sich", "am", "lee\u00b7ren", "Wa\u00b7gen", "str\u00e4u\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und stutzt noch mehr. Wie, denkt er, mag wohl gar", "tokens": ["Und", "stutzt", "noch", "mehr", ".", "Wie", ",", "denkt", "er", ",", "mag", "wohl", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$.", "PWAV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Diana, die so spr\u00f6de war,", "tokens": ["Di\u00b7a\u00b7na", ",", "die", "so", "spr\u00f6\u00b7de", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die M\u00e4nner-Hasserin, sich hier die Zeit vertreiben,", "tokens": ["Die", "M\u00e4n\u00b7ner\u00b7Has\u00b7se\u00b7rin", ",", "sich", "hier", "die", "Zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRF", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Kaum denkt er's aus, so zeigt ein neuer Blick", "tokens": ["Kaum", "denkt", "er's", "aus", ",", "so", "zeigt", "ein", "neu\u00b7er", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Ihm Lunas Fall und Amors Meisterst\u00fcck.", "tokens": ["Ihm", "Lu\u00b7nas", "Fall", "und", "A\u00b7mors", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "NN", "KON", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "O! G\u00f6ttin, welch ein Augenblick;", "tokens": ["O", "!", "G\u00f6t\u00b7tin", ",", "welch", "ein", "Au\u00b7gen\u00b7blick", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Wie wird der rohe Faun dich h\u00f6hnen!", "tokens": ["Wie", "wird", "der", "ro\u00b7he", "Faun", "dich", "h\u00f6h\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Ein andrer schliche sich von einer solchen Szenen", "tokens": ["Ein", "an\u00b7drer", "schli\u00b7che", "sich", "von", "ei\u00b7ner", "sol\u00b7chen", "Sze\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "PRF", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Mit abgewandtem Aug aus Gro\u00dfmut still zur\u00fcck;", "tokens": ["Mit", "ab\u00b7ge\u00b7wand\u00b7tem", "Aug", "aus", "Gro\u00df\u00b7mut", "still", "zu\u00b7r\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Er w\u00fcrde sich sogar noch Zweifel machen,", "tokens": ["Er", "w\u00fcr\u00b7de", "sich", "so\u00b7gar", "noch", "Zwei\u00b7fel", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Und hie\u00df es nur ein t\u00e4uschend Nacht-Gesicht:", "tokens": ["Und", "hie\u00df", "es", "nur", "ein", "t\u00e4u\u00b7schend", "Nacht\u00b7Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Allein in Faunen wohnt so viele Tugend nicht.", "tokens": ["Al\u00b7lein", "in", "Fau\u00b7nen", "wohnt", "so", "vie\u00b7le", "Tu\u00b7gend", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "ADV", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Ein wildes \u00fcberlautes Lachen", "tokens": ["Ein", "wil\u00b7des", "\u00fc\u00b7berl\u00b7au\u00b7tes", "La\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weckt sie, und zeigt den Zeugen ihrer Lust.", "tokens": ["Weckt", "sie", ",", "und", "zeigt", "den", "Zeu\u00b7gen", "ih\u00b7rer", "Lust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie hebt ein sterbend Aug und schlie\u00dft es pl\u00f6tzlich wieder,", "tokens": ["Sie", "hebt", "ein", "ster\u00b7bend", "Aug", "und", "schlie\u00dft", "es", "pl\u00f6tz\u00b7lich", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "NN", "KON", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein kalter Schaur durchf\u00e4hrt die aufgel\u00f6sten Glieder,", "tokens": ["Ein", "kal\u00b7ter", "Schaur", "durch\u00b7f\u00e4hrt", "die", "auf\u00b7ge\u00b7l\u00f6s\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor Schrecken starrt die ausgedehnte Brust.", "tokens": ["Vor", "Schre\u00b7cken", "starrt", "die", "aus\u00b7ge\u00b7dehn\u00b7te", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie sinkt bet\u00e4ubt bei ihrem Sch\u00e4fer nieder,", "tokens": ["Sie", "sinkt", "be\u00b7t\u00e4ubt", "bei", "ih\u00b7rem", "Sch\u00e4\u00b7fer", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und seufzt und weint, da\u00df sie nicht sterben kann.", "tokens": ["Und", "seufzt", "und", "weint", ",", "da\u00df", "sie", "nicht", "ster\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ach! k\u00e4m er nur, der d\u00fcrre Knochen-Mann,", "tokens": ["Ach", "!", "k\u00e4m", "er", "nur", ",", "der", "d\u00fcr\u00b7re", "Kno\u00b7chen\u00b7Mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er sollt ihr Liebling sein! Sie wollte mit Entz\u00fccken", "tokens": ["Er", "sollt", "ihr", "Lieb\u00b7ling", "sein", "!", "Sie", "woll\u00b7te", "mit", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VAINF", "$.", "PPER", "VMFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sein faul Geripp an ihren Busen dr\u00fccken!", "tokens": ["Sein", "faul", "Ge\u00b7ripp", "an", "ih\u00b7ren", "Bu\u00b7sen", "dr\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Was kaum so reizend war sieht sie mit Grauen an.", "tokens": ["Was", "kaum", "so", "rei\u00b7zend", "war", "sieht", "sie", "mit", "Grau\u00b7en", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VVPP", "VAFIN", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wie w\u00e4lzt auf Rosen sich als wie auf Kohlen-Feuer,", "tokens": ["Wie", "w\u00e4lzt", "auf", "Ro\u00b7sen", "sich", "als", "wie", "auf", "Koh\u00b7len\u00b7Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "APPR", "NN", "PRF", "KOUS", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Des Zephyrs Atem deucht ihr Pest,", "tokens": ["Des", "Ze\u00b7phyrs", "A\u00b7tem", "deucht", "ihr", "Pest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Endymion ein Ungeheuer,", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "ein", "Un\u00b7ge\u00b7heu\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Die weite Welt ein Drachen-Nest.", "tokens": ["Die", "wei\u00b7te", "Welt", "ein", "Dra\u00b7chen\u00b7Nest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Sie so betr\u00fcbt zu sehn, das schmelzte Tartar-Herzen,", "tokens": ["Sie", "so", "be\u00b7tr\u00fcbt", "zu", "sehn", ",", "das", "schmelz\u00b7te", "Tar\u00b7ta\u00b7rHer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Faun bleibt unger\u00fchrt; er lacht noch ihrer Schmerzen,", "tokens": ["Der", "Faun", "bleibt", "un\u00b7ge\u00b7r\u00fchrt", ";", "er", "lacht", "noch", "ih\u00b7rer", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$.", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und leert den schalen Witz, den er bei manchem Schmaus", "tokens": ["Und", "leert", "den", "scha\u00b7len", "Witz", ",", "den", "er", "bei", "man\u00b7chem", "Schmaus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Gesammelt hat, bei diesem Anla\u00df aus;", "tokens": ["Ge\u00b7sam\u00b7melt", "hat", ",", "bei", "die\u00b7sem", "An\u00b7la\u00df", "aus", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Sieht sie auf ihren Arm sich stumm und trostlos stemmen,", "tokens": ["Sieht", "sie", "auf", "ih\u00b7ren", "Arm", "sich", "stumm", "und", "trost\u00b7los", "stem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PRF", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und eine Tr\u00e4nenflut, die nicht zu stillen war,", "tokens": ["Und", "ei\u00b7ne", "Tr\u00e4\u00b7nen\u00b7flut", ",", "die", "nicht", "zu", "stil\u00b7len", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Den sch\u00f6nsten Busen \u00fcberschwemmen,", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "Bu\u00b7sen", "\u00fc\u00b7bersc\u00b7hwem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Sieht's und erfrecht sich, der Corsar!", "tokens": ["Sieht's", "und", "er\u00b7frecht", "sich", ",", "der", "Cor\u00b7sar", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PRF", "$,", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Durch K\u00fcsse ihren Lauf zu hemmen.", "tokens": ["Durch", "K\u00fcs\u00b7se", "ih\u00b7ren", "Lauf", "zu", "hem\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Sie st\u00f6\u00dft ihn weg, doch nur mit matter Hand.", "tokens": ["Sie", "st\u00f6\u00dft", "ihn", "weg", ",", "doch", "nur", "mit", "mat\u00b7ter", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Was h\u00e4lf ihr gegen einen Zeugen", "tokens": ["Was", "h\u00e4lf", "ihr", "ge\u00b7gen", "ei\u00b7nen", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Von dieser Art ein stolzer Widerstand?", "tokens": ["Von", "die\u00b7ser", "Art", "ein", "stol\u00b7zer", "Wi\u00b7der\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Es liegt zuviel an seinem Schweigen.", "tokens": ["Es", "liegt", "zu\u00b7viel", "an", "sei\u00b7nem", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Der ungeduldige Sylvan", "tokens": ["Der", "un\u00b7ge\u00b7dul\u00b7di\u00b7ge", "Syl\u00b7van"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.30": {"text": "An dem schon alle Adern gl\u00fchen,", "tokens": ["An", "dem", "schon", "al\u00b7le", "A\u00b7dern", "gl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Verspricht und droht zugleich. Sie sieht ihn sch\u00fcchtern an,", "tokens": ["Ver\u00b7spricht", "und", "droht", "zu\u00b7gleich", ".", "Sie", "sieht", "ihn", "sch\u00fcch\u00b7tern", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Err\u00f6tet, staunt, und sucht, was sie nicht hindern kann,", "tokens": ["Er\u00b7r\u00f6\u00b7tet", ",", "staunt", ",", "und", "sucht", ",", "was", "sie", "nicht", "hin\u00b7dern", "kann", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "KON", "VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Zum wenigsten noch aufzuziehen.", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "noch", "auf\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.34": {"text": "Was soll sie tun? Hier ist die Antwort schwer;", "tokens": ["Was", "soll", "sie", "tun", "?", "Hier", "ist", "die", "Ant\u00b7wort", "schwer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "ADV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Dem gr\u00f6\u00dfern zu entgehn ein kleiners \u00dcbel leiden?", "tokens": ["Dem", "gr\u00f6\u00b7\u00dfern", "zu", "ent\u00b7gehn", "ein", "klei\u00b7ners", "\u00dc\u00b7bel", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKZU", "VVINF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Um b\u00f6sen Ruf und \u00c4rgernis zu meiden", "tokens": ["Um", "b\u00f6\u00b7sen", "Ruf", "und", "\u00c4r\u00b7ger\u00b7nis", "zu", "mei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Erlaubt Caramuel wohl mehr.", "tokens": ["Er\u00b7laubt", "Ca\u00b7ra\u00b7mu\u00b7el", "wohl", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "Ein Umstand ist dabei, der ihr sich zu entschlie\u00dfen", "tokens": ["Ein", "Um\u00b7stand", "ist", "da\u00b7bei", ",", "der", "ihr", "sich", "zu", "ent\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PAV", "$,", "PRELS", "PPER", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch leichter macht. Ihr graut vor seinem Bart,", "tokens": ["Noch", "leich\u00b7ter", "macht", ".", "Ihr", "graut", "vor", "sei\u00b7nem", "Bart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem weiten Maul, den rauhen Ziegenf\u00fc\u00dfen,", "tokens": ["Dem", "wei\u00b7ten", "Maul", ",", "den", "rau\u00b7hen", "Zie\u00b7gen\u00b7f\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem H\u00f6rner-Paar, das ihm aus schwarzen Locken starrt.", "tokens": ["Dem", "H\u00f6r\u00b7ner\u00b7Paar", ",", "das", "ihm", "aus", "schwar\u00b7zen", "Lo\u00b7cken", "starrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hofft von ihrer Schuld bei so verha\u00dften K\u00fcssen", "tokens": ["Sie", "hofft", "von", "ih\u00b7rer", "Schuld", "bei", "so", "ver\u00b7ha\u00df\u00b7ten", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zum wenigsten die H\u00e4lfte abzub\u00fc\u00dfen,", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "die", "H\u00e4lf\u00b7te", "ab\u00b7zu\u00b7b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ART", "NN", "VVIZU", "$,"], "meter": "+----+-+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Und ihrem z\u00e4rtlichen Gewissen", "tokens": ["Und", "ih\u00b7rem", "z\u00e4rt\u00b7li\u00b7chen", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Scheint keine Z\u00fcchtigung f\u00fcr ihr Vergehn zu hart.", "tokens": ["Scheint", "kei\u00b7ne", "Z\u00fcch\u00b7ti\u00b7gung", "f\u00fcr", "ihr", "Ver\u00b7gehn", "zu", "hart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Satyr pre\u00dft; es Hilft kein ekles Str\u00e4uben;", "tokens": ["Der", "Sa\u00b7tyr", "pre\u00dft", ";", "es", "Hilft", "kein", "ek\u00b7les", "Str\u00e4u\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbnur gutes Muts, Frau Feen-K\u00f6nigin!", "tokens": ["\u00bb", "nur", "gu\u00b7tes", "Muts", ",", "Frau", "Feen\u00b7K\u00f6\u00b7ni\u00b7gin", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Was schielt ihr so nach euerm Sch\u00e4fer hin?", "tokens": ["Was", "schielt", "ihr", "so", "nach", "eu\u00b7erm", "Sch\u00e4\u00b7fer", "hin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Verge\u00dft ihn itzt! wenn ich so glatt nicht bin,", "tokens": ["Ver\u00b7ge\u00dft", "ihn", "itzt", "!", "wenn", "ich", "so", "glatt", "nicht", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "KOUS", "PPER", "ADV", "ADJD", "PTKNEG", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So soll mir doch ein andrer Vorzug bleiben.\u00ab", "tokens": ["So", "soll", "mir", "doch", "ein", "an\u00b7drer", "Vor\u00b7zug", "blei\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "Die G\u00f6ttin seufzt, der Waldgott schw\u00f6rt", "tokens": ["Die", "G\u00f6t\u00b7tin", "seufzt", ",", "der", "Wald\u00b7gott", "schw\u00f6rt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(doch nicht beim Styx!) die Sache zu verhehlen;", "tokens": ["(", "doch", "nicht", "beim", "Styx", "!", ")", "die", "Sa\u00b7che", "zu", "ver\u00b7heh\u00b7len", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKNEG", "APPRART", "NN", "$.", "$(", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er zeigt sich seines Namens wert,", "tokens": ["Er", "zeigt", "sich", "sei\u00b7nes", "Na\u00b7mens", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und da zuletzt sie mehr zu qu\u00e4len", "tokens": ["Und", "da", "zu\u00b7letzt", "sie", "mehr", "zu", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Aurorens Ankunft ihm verwehrt,", "tokens": ["Au\u00b7ro\u00b7rens", "An\u00b7kunft", "ihm", "ver\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bedankt er sich, wie sich's geh\u00f6rt,", "tokens": ["Be\u00b7dankt", "er", "sich", ",", "wie", "sich's", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und eilt, sein Gl\u00fcck den Br\u00fcdern zu erz\u00e4hlen.", "tokens": ["Und", "eilt", ",", "sein", "Gl\u00fcck", "den", "Br\u00fc\u00b7dern", "zu", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.31": {"line.1": {"text": "In jener dichterischen Zeit", "tokens": ["In", "je\u00b7ner", "dich\u00b7te\u00b7ri\u00b7schen", "Zeit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit deren Wundern uns der Amme Freundlichkeit", "tokens": ["Mit", "de\u00b7ren", "Wun\u00b7dern", "uns", "der", "Am\u00b7me", "Freund\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PRELAT", "NN", "PPER", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Durch manches M\u00e4rchen einst in s\u00fc\u00dfen Schlummer wiegte;", "tokens": ["Durch", "man\u00b7ches", "M\u00e4r\u00b7chen", "einst", "in", "s\u00fc\u00b7\u00dfen", "Schlum\u00b7mer", "wieg\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als sorgenfreie M\u00fc\u00dfigkeit", "tokens": ["Als", "sor\u00b7gen\u00b7frei\u00b7e", "M\u00fc\u00b7\u00dfig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich ohne Pflichten, ohne Streit,", "tokens": ["Sich", "oh\u00b7ne", "Pflich\u00b7ten", ",", "oh\u00b7ne", "Streit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "$,", "KOUI", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit dem was die Natur freiwillig gab, begn\u00fcgte,", "tokens": ["Mit", "dem", "was", "die", "Na\u00b7tur", "frei\u00b7wil\u00b7lig", "gab", ",", "be\u00b7gn\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "PRELS", "ART", "NN", "ADJD", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kein M\u00e4dchen spann, kein J\u00fcngling pfl\u00fcgte,", "tokens": ["Kein", "M\u00e4d\u00b7chen", "spann", ",", "kein", "J\u00fcng\u00b7ling", "pfl\u00fcg\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Und manches tunlich war, was Basedow verbeut;", "tokens": ["Und", "man\u00b7ches", "tun\u00b7lich", "war", ",", "was", "Ba\u00b7se\u00b7dow", "ver\u00b7beut", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "VAFIN", "$,", "PRELS", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Eh noch der St\u00e4nde Unterscheid", "tokens": ["Eh", "noch", "der", "St\u00e4n\u00b7de", "Un\u00b7ter\u00b7scheid"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ADV", "ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.10": {"text": "Aus Br\u00fcdern Nebenbuhler machte,", "tokens": ["Aus", "Br\u00fc\u00b7dern", "Ne\u00b7ben\u00b7buh\u00b7ler", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Und gleisnerische Heiligkeit", "tokens": ["Und", "gleis\u00b7ne\u00b7ri\u00b7sche", "Hei\u00b7lig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Das h\u00f6chste Gut der Sterblichkeit,", "tokens": ["Das", "h\u00f6chs\u00b7te", "Gut", "der", "Sterb\u00b7lich\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die Lust um ihre Unschuld brachte;", "tokens": ["Die", "Lust", "um", "ih\u00b7re", "Un\u00b7schuld", "brach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und kurz, in jener goldnen Zeit,", "tokens": ["Und", "kurz", ",", "in", "je\u00b7ner", "gold\u00b7nen", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Da die Natur, von keinem Joch entweiht,", "tokens": ["Da", "die", "Na\u00b7tur", ",", "von", "kei\u00b7nem", "Joch", "ent\u00b7weiht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Gesetze gab wodurch sie gl\u00fccklich machte,", "tokens": ["Ge\u00b7set\u00b7ze", "gab", "wo\u00b7durch", "sie", "gl\u00fcck\u00b7lich", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PWAV", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Die Welt noch kindisch war und alles scherzt' und lachte:", "tokens": ["Die", "Welt", "noch", "kin\u00b7disch", "war", "und", "al\u00b7les", "scherzt'", "und", "lach\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "VAFIN", "KON", "PIS", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "In dieser Zeit lebt' einst auf Latmos H\u00f6hn", "tokens": ["In", "die\u00b7ser", "Zeit", "lebt'", "einst", "auf", "Lat\u00b7mos", "H\u00f6hn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ADV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Ein junger Hirt, wie Ganymedes sch\u00f6n,", "tokens": ["Ein", "jun\u00b7ger", "Hirt", ",", "wie", "Ga\u00b7ny\u00b7me\u00b7des", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "NN", "ADJD", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.20": {"text": "Sch\u00f6n wie Narci\u00df, doch nicht so spr\u00f6de,", "tokens": ["Sch\u00f6n", "wie", "Nar\u00b7ci\u00df", ",", "doch", "nicht", "so", "spr\u00f6\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "NN", "$,", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.21": {"text": "Wie Ganymed, allein nicht halb so bl\u00f6de.", "tokens": ["Wie", "Ga\u00b7ny\u00b7med", ",", "al\u00b7lein", "nicht", "halb", "so", "bl\u00f6\u00b7de", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "$,", "ADV", "PTKNEG", "ADJD", "ADV", "ADJA", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.22": {"text": "So bald man wei\u00df, Endymion", "tokens": ["So", "bald", "man", "wei\u00df", ",", "En\u00b7dy\u00b7mi\u00b7on"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "PIS", "VVFIN", "$,", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "War sch\u00f6n, so denkt ein jeder schon", "tokens": ["War", "sch\u00f6n", ",", "so", "denkt", "ein", "je\u00b7der", "schon"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADJD", "$,", "ADV", "VVFIN", "ART", "PIS", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.24": {"text": "Da\u00df ihn die M\u00e4dchen gerne sahen;", "tokens": ["Da\u00df", "ihn", "die", "M\u00e4d\u00b7chen", "ger\u00b7ne", "sa\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Zum mindsten liefen sie nie wenn er kam davon,", "tokens": ["Zum", "minds\u00b7ten", "lie\u00b7fen", "sie", "nie", "wenn", "er", "kam", "da\u00b7von", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVFIN", "PPER", "ADV", "KOUS", "PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.26": {"text": "Das l\u00e4\u00dft sich ohne Scheu bejahen.", "tokens": ["Das", "l\u00e4\u00dft", "sich", "oh\u00b7ne", "Scheu", "be\u00b7ja\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Die Chronik sagt noch mehr als ich", "tokens": ["Die", "Chro\u00b7nik", "sagt", "noch", "mehr", "als", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADV", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Den Musen selbst geglaubet h\u00e4tte;", "tokens": ["Den", "Mu\u00b7sen", "selbst", "ge\u00b7glau\u00b7bet", "h\u00e4t\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Sie buhlten, spricht sie, in die Wette", "tokens": ["Sie", "buhl\u00b7ten", ",", "spricht", "sie", ",", "in", "die", "Wet\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Um seine Gunst; sie stellten sich", "tokens": ["Um", "sei\u00b7ne", "Gunst", ";", "sie", "stell\u00b7ten", "sich"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "$.", "PPER", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.31": {"text": "Ihm wo er ging in Steg' und Wege;", "tokens": ["Ihm", "wo", "er", "ging", "in", "Steg'", "und", "We\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PWAV", "PPER", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "Sie warfen ihm oft Blumen zu;", "tokens": ["Sie", "war\u00b7fen", "ihm", "oft", "Blu\u00b7men", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Und flohn dann hinter ein Geh\u00e4ge;", "tokens": ["Und", "flohn", "dann", "hin\u00b7ter", "ein", "Ge\u00b7h\u00e4\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Belauschten seine Mittags-Ruh", "tokens": ["Be\u00b7lauschten", "sei\u00b7ne", "Mit\u00b7tags\u00b7Ruh"], "token_info": ["word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.35": {"text": "Und guckten, ob er sich nicht rege.", "tokens": ["Und", "guck\u00b7ten", ",", "ob", "er", "sich", "nicht", "re\u00b7ge", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "ADJA", "$."], "meter": "-+--+-+--", "measure": "iambic.tri.relaxed"}, "line.36": {"text": "Man meint, da\u00df er im Bad sogar", "tokens": ["Man", "meint", ",", "da\u00df", "er", "im", "Bad", "so\u00b7gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "NE", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.37": {"text": "Nicht immer ohne Zeugen war,", "tokens": ["Nicht", "im\u00b7mer", "oh\u00b7ne", "Zeu\u00b7gen", "war", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.38": {"text": "Doch l\u00e4\u00dft sich das gewi\u00df nicht sagen.", "tokens": ["Doch", "l\u00e4\u00dft", "sich", "das", "ge\u00b7wi\u00df", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "PDS", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Genug, kaum fing es an zu tagen", "tokens": ["Ge\u00b7nug", ",", "kaum", "fing", "es", "an", "zu", "ta\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "ADV", "VVFIN", "PPER", "APPR", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.40": {"text": "So wurde schon von mancher sch\u00f6nen Hand", "tokens": ["So", "wur\u00b7de", "schon", "von", "man\u00b7cher", "sch\u00f6\u00b7nen", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.41": {"text": "Der Blumen-Flur ihr sch\u00f6nster Schmuck entwandt;", "tokens": ["Der", "Blu\u00b7men\u00b7Flur", "ihr", "sch\u00f6ns\u00b7ter", "Schmuck", "ent\u00b7wandt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.42": {"text": "So putzt sich schon, dem Sch\u00e4fer zu gefallen,", "tokens": ["So", "putzt", "sich", "schon", ",", "dem", "Sch\u00e4\u00b7fer", "zu", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Im Hain, am Bach, der Nymphen ganze Schar,", "tokens": ["Im", "Hain", ",", "am", "Bach", ",", "der", "Nym\u00b7phen", "gan\u00b7ze", "Schar", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Die badet sich, die flicht ihr blondes Haar,", "tokens": ["Die", "ba\u00b7det", "sich", ",", "die", "flicht", "ihr", "blon\u00b7des", "Haar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "$,", "PRELS", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "Die l\u00e4\u00dft es frei um wei\u00dfe Schultern wallen.", "tokens": ["Die", "l\u00e4\u00dft", "es", "frei", "um", "wei\u00b7\u00dfe", "Schul\u00b7tern", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.46": {"text": "Herabgeb\u00fcckt auf fl\u00fcssige Cristallen", "tokens": ["Her\u00b7ab\u00b7ge\u00b7b\u00fcckt", "auf", "fl\u00fcs\u00b7si\u00b7ge", "Cris\u00b7tal\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.47": {"text": "Bel\u00e4chelt sich die sch\u00f6ne Damalis;", "tokens": ["Be\u00b7l\u00e4\u00b7chelt", "sich", "die", "sch\u00f6\u00b7ne", "Da\u00b7ma\u00b7lis", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "Wie vieles macht sie ihres Siegs gewi\u00df!", "tokens": ["Wie", "vie\u00b7les", "macht", "sie", "ih\u00b7res", "Siegs", "ge\u00b7wi\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.49": {"text": "Ein Mund, der K\u00fcssen winkt, ein Lilien-Nacken,", "tokens": ["Ein", "Mund", ",", "der", "K\u00fcs\u00b7sen", "winkt", ",", "ein", "Li\u00b7li\u00b7en\u00b7Nacken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.50": {"text": "Der Augen feuchter Glanz, ein perlengleich Gebi\u00df,", "tokens": ["Der", "Au\u00b7gen", "feuch\u00b7ter", "Glanz", ",", "ein", "per\u00b7len\u00b7gleich", "Ge\u00b7bi\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.51": {"text": "Die freie Stirn, die Gr\u00fcbchen in den Backen,", "tokens": ["Die", "frei\u00b7e", "Stirn", ",", "die", "Gr\u00fcb\u00b7chen", "in", "den", "Ba\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.52": {"text": "Ein runder Arm, und o! der Thron der Lust", "tokens": ["Ein", "run\u00b7der", "Arm", ",", "und", "o", "!", "der", "Thron", "der", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "FM", "$.", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.53": {"text": "Die blendende, die Anmutsvolle Brust!", "tokens": ["Die", "blen\u00b7den\u00b7de", ",", "die", "An\u00b7muts\u00b7vol\u00b7le", "Brust", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.54": {"text": "Sie sieht noch mehr, nichts zeigt sich ihren Blicken", "tokens": ["Sie", "sieht", "noch", "mehr", ",", "nichts", "zeigt", "sich", "ih\u00b7ren", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "$,", "PIS", "VVFIN", "PRF", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.55": {"text": "Das nicht verdient selbst G\u00f6tter zu ber\u00fccken:", "tokens": ["Das", "nicht", "ver\u00b7dient", "selbst", "G\u00f6t\u00b7ter", "zu", "be\u00b7r\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PTKNEG", "VVFIN", "ADV", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.56": {"text": "Sie sieht's und denkt, ob Leda ihrem Schwan", "tokens": ["Sie", "sieht's", "und", "denkt", ",", "ob", "Le\u00b7da", "ih\u00b7rem", "Schwan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "NE", "KON", "VVFIN", "$,", "KOUS", "NE", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.57": {"text": "Mehr Reizungen gewiesen haben kann,", "tokens": ["Mehr", "Rei\u00b7zun\u00b7gen", "ge\u00b7wie\u00b7sen", "ha\u00b7ben", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.58": {"text": "Und zittert doch und w\u00fcnscht: o! f\u00e4nde mich", "tokens": ["Und", "zit\u00b7tert", "doch", "und", "w\u00fcnscht", ":", "o", "!", "f\u00e4n\u00b7de", "mich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "KON", "VVFIN", "$.", "FM", "$.", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Endymion nur halb so sch\u00f6n als ich!", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "nur", "halb", "so", "sch\u00f6n", "als", "ich", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ADJD", "ADV", "ADJD", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.60": {"text": "Die Sch\u00f6nheit wird mit Wunder angeblickt,", "tokens": ["Die", "Sch\u00f6n\u00b7heit", "wird", "mit", "Wun\u00b7der", "an\u00b7ge\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.61": {"text": "Doch nur Gef\u00e4lligkeit entz\u00fcckt.", "tokens": ["Doch", "nur", "Ge\u00b7f\u00e4l\u00b7lig\u00b7keit", "ent\u00b7z\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.62": {"text": "War Juno nicht, war nicht Minerva sch\u00f6n", "tokens": ["War", "Ju\u00b7no", "nicht", ",", "war", "nicht", "Mi\u00b7ner\u00b7va", "sch\u00f6n"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "PTKNEG", "$,", "VAFIN", "PTKNEG", "NE", "ADJD"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.63": {"text": "Als Zeus den Paris ausersehn", "tokens": ["Als", "Zeus", "den", "Pa\u00b7ris", "au\u00b7ser\u00b7sehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "NE", "ART", "NE", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Den Streit der Sch\u00f6nheit zu entscheiden'", "tokens": ["Den", "Streit", "der", "Sch\u00f6n\u00b7heit", "zu", "ent\u00b7schei\u00b7den'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "APPR", "NE"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.65": {"text": "Man wei\u00df, sie lie\u00dfen sich, um b\u00f6sen Schein zu meiden,", "tokens": ["Man", "wei\u00df", ",", "sie", "lie\u00b7\u00dfen", "sich", ",", "um", "b\u00f6\u00b7sen", "Schein", "zu", "mei\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "PPER", "VVFIN", "PRF", "$,", "KOUI", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.66": {"text": "Dem Richter ohne R\u00f6cke sehn.", "tokens": ["Dem", "Rich\u00b7ter", "oh\u00b7ne", "R\u00f6\u00b7cke", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.67": {"text": "Lang lie\u00df der Hirt von einem Reiz zum andern", "tokens": ["Lang", "lie\u00df", "der", "Hirt", "von", "ei\u00b7nem", "Reiz", "zum", "an\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "APPRART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.68": {"text": "Die ungewissen Blicke wandern,", "tokens": ["Die", "un\u00b7ge\u00b7wis\u00b7sen", "Bli\u00b7cke", "wan\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.69": {"text": "Und zehnmal rief ein neuer Blick", "tokens": ["Und", "zehn\u00b7mal", "rief", "ein", "neu\u00b7er", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Den schon gefa\u00dften Schlu\u00df zur\u00fcck:", "tokens": ["Den", "schon", "ge\u00b7fa\u00df\u00b7ten", "Schlu\u00df", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Untadelich ist alles was sie zeigen;", "tokens": ["Un\u00b7ta\u00b7de\u00b7lich", "ist", "al\u00b7les", "was", "sie", "zei\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PWS", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.72": {"text": "Beisammen sind sie gleich; allein", "tokens": ["Bei\u00b7sam\u00b7men", "sind", "sie", "gleich", ";", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VVPP", "VAFIN", "PPER", "ADV", "$.", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.73": {"text": "Scheint jede reizender zu sein,", "tokens": ["Scheint", "je\u00b7de", "rei\u00b7zen\u00b7der", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "ADJA", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.74": {"text": "Was wird zuletzt des Sch\u00e4fers Urteil neigen?", "tokens": ["Was", "wird", "zu\u00b7letzt", "des", "Sch\u00e4\u00b7fers", "Ur\u00b7teil", "nei\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ADV", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.75": {"text": "Der Juno Majest\u00e4t! der Pallas W\u00fcrde, \u2013 Nein!", "tokens": ["Der", "Ju\u00b7no", "Ma\u00b7jes\u00b7t\u00e4t", "!", "der", "Pal\u00b7las", "W\u00fcr\u00b7de", ",", "\u2013", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ART", "NN", "NN", "$.", "ART", "NN", "VAFIN", "$,", "$(", "PTKANT", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "Die fl\u00f6\u00dfen nichts als Ehrfurcht ein,", "tokens": ["Die", "fl\u00f6\u00b7\u00dfen", "nichts", "als", "Ehr\u00b7furcht", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "KOKOM", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "Ein st\u00e4rkrer Reiz wird hier den Ausschlag geben m\u00fcssen:", "tokens": ["Ein", "st\u00e4r\u00b7krer", "Reiz", "wird", "hier", "den", "Aus\u00b7schlag", "ge\u00b7ben", "m\u00fcs\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.78": {"text": "Sie, die so zaubrisch l\u00e4cheln kann,", "tokens": ["Sie", ",", "die", "so", "zaub\u00b7risch", "l\u00e4\u00b7cheln", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "ADJD", "VVFIN", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.79": {"text": "Die goldne Venus lacht ihn an,", "tokens": ["Die", "gold\u00b7ne", "Ve\u00b7nus", "lacht", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Und Paris f\u00e4llt zu ihren F\u00fc\u00dfen,", "tokens": ["Und", "Pa\u00b7ris", "f\u00e4llt", "zu", "ih\u00b7ren", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.81": {"text": "Und beut (ich t\u00e4t es auch, so wahr ich ehrlich bin)", "tokens": ["Und", "beut", "(", "ich", "t\u00e4t", "es", "auch", ",", "so", "wahr", "ich", "ehr\u00b7lich", "bin", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$(", "PPER", "VVFIN", "PPER", "ADV", "$,", "ADV", "ADJD", "PPER", "ADJD", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.82": {"text": "Beut um die Freiheit sie zu k\u00fcssen", "tokens": ["Beut", "um", "die", "Frei\u00b7heit", "sie", "zu", "k\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.83": {"text": "Der L\u00e4chelnden den goldnen Apfel hin.", "tokens": ["Der", "L\u00e4\u00b7cheln\u00b7den", "den", "gold\u00b7nen", "Ap\u00b7fel", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "So raubt die Freundlichkeit bei unserm Sch\u00e4fer oft", "tokens": ["So", "raubt", "die", "Freund\u00b7lich\u00b7keit", "bei", "un\u00b7serm", "Sch\u00e4\u00b7fer", "oft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Gunst, worauf die stolze Sch\u00f6nheit hofft.", "tokens": ["Die", "Gunst", ",", "wo\u00b7rauf", "die", "stol\u00b7ze", "Sch\u00f6n\u00b7heit", "hofft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die welke Brust, die Schar der blassen Wangen", "tokens": ["Die", "wel\u00b7ke", "Brust", ",", "die", "Schar", "der", "blas\u00b7sen", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Erwerben sich durch z\u00e4rtliches Bem\u00fchn,", "tokens": ["Er\u00b7wer\u00b7ben", "sich", "durch", "z\u00e4rt\u00b7li\u00b7ches", "Be\u00b7m\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Durch Blicke die an seinen Blicken hangen,", "tokens": ["Durch", "Bli\u00b7cke", "die", "an", "sei\u00b7nen", "Bli\u00b7cken", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und s\u00fc\u00dfen Scherz, manch kleines Recht an ihn.", "tokens": ["Und", "s\u00fc\u00b7\u00dfen", "Scherz", ",", "manch", "klei\u00b7nes", "Recht", "an", "ihn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "PIAT", "ADJA", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Wie eifern sie ihm liebzukosen!", "tokens": ["Wie", "ei\u00b7fern", "sie", "ihm", "lieb\u00b7zu\u00b7ko\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Die schm\u00fcckt sein Lamm, die kr\u00e4nzt ihm Hut und Stab;", "tokens": ["Die", "schm\u00fcckt", "sein", "Lamm", ",", "die", "kr\u00e4nzt", "ihm", "Hut", "und", "Stab", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "$,", "PRELS", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Der Lenz wird arm an Bl\u00fct und Rosen,", "tokens": ["Der", "Lenz", "wird", "arm", "an", "Bl\u00fct", "und", "Ro\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Sie pfl\u00fcckten ganze Haine ab.", "tokens": ["Sie", "pfl\u00fcck\u00b7ten", "gan\u00b7ze", "Hai\u00b7ne", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sie wachten, da\u00df ihn nichts in seinem Schlummer st\u00f6rte,", "tokens": ["Sie", "wach\u00b7ten", ",", "da\u00df", "ihn", "nichts", "in", "sei\u00b7nem", "Schlum\u00b7mer", "st\u00f6r\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PIS", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Sie pflanzten Lauben hin, wo er zu weiden pflag,", "tokens": ["Sie", "pflanz\u00b7ten", "Lau\u00b7ben", "hin", ",", "wo", "er", "zu", "wei\u00b7den", "pflag", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "$,", "PWAV", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und weil er gerne singen h\u00f6rte", "tokens": ["Und", "weil", "er", "ger\u00b7ne", "sin\u00b7gen", "h\u00f6r\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVINF", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "So sangen sie den ganzen Tag.", "tokens": ["So", "san\u00b7gen", "sie", "den", "gan\u00b7zen", "Tag", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des Tages Lust schlie\u00dft bis zum Sternen-Glanz", "tokens": ["Des", "Ta\u00b7ges", "Lust", "schlie\u00dft", "bis", "zum", "Ster\u00b7nen\u00b7Glanz"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Manch munters Spiel und mancher bunte Tanz,", "tokens": ["Manch", "mun\u00b7ters", "Spiel", "und", "man\u00b7cher", "bun\u00b7te", "Tanz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und trennt zuletzt die Nacht den frohen Reihn", "tokens": ["Und", "trennt", "zu\u00b7letzt", "die", "Nacht", "den", "fro\u00b7hen", "Reihn"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "So schl\u00e4ft er sanft auf Rosen-Betten ein.", "tokens": ["So", "schl\u00e4ft", "er", "sanft", "auf", "Ro\u00b7sen\u00b7Bet\u00b7ten", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Die Nymphen zwingt der keuschen G\u00f6ttin Schein", "tokens": ["Die", "Nym\u00b7phen", "zwingt", "der", "keu\u00b7schen", "G\u00f6t\u00b7tin", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Sich allgemach hinweg zu stehlen;", "tokens": ["Sich", "all\u00b7ge\u00b7mach", "hin\u00b7weg", "zu", "steh\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PAV", "APZR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Sie z\u00f6gern zwar, doch mu\u00df es endlich sein.", "tokens": ["Sie", "z\u00f6\u00b7gern", "zwar", ",", "doch", "mu\u00df", "es", "end\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "VMFIN", "PPER", "ADV", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Sie geben ihm die Hand, die angenehmen Seelen!", "tokens": ["Sie", "ge\u00b7ben", "ihm", "die", "Hand", ",", "die", "an\u00b7ge\u00b7neh\u00b7men", "See\u00b7len", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Und w\u00fcnschen ihm wohl zehnmal gute Nacht;", "tokens": ["Und", "w\u00fcn\u00b7schen", "ihm", "wohl", "zehn\u00b7mal", "gu\u00b7te", "Nacht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Doch weil der Schlaf sich oft erwarten macht,", "tokens": ["Doch", "weil", "der", "Schlaf", "sich", "oft", "er\u00b7war\u00b7ten", "macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PRF", "ADV", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Bleibt eine stets zur\u00fcck, ihm M\u00e4rchen zu erz\u00e4hlen.", "tokens": ["Bleibt", "ei\u00b7ne", "stets", "zu\u00b7r\u00fcck", ",", "ihm", "M\u00e4r\u00b7chen", "zu", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADV", "PTKVZ", "$,", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Dem Gl\u00fcck in dieser Unterwelt.", "tokens": ["Dem", "Gl\u00fcck", "in", "die\u00b7ser", "Un\u00b7ter\u00b7welt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat stets Best\u00e4ndigkeit gefehlt.", "tokens": ["Hat", "stets", "Be\u00b7st\u00e4n\u00b7dig\u00b7keit", "ge\u00b7fehlt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Der Sch\u00e4fer war vergn\u00fcgt, das Nymphen-Volk nicht minder,", "tokens": ["Der", "Sch\u00e4\u00b7fer", "war", "ver\u00b7gn\u00fcgt", ",", "das", "Nym\u00b7phen\u00b7Volk", "nicht", "min\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,", "ART", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In Unschuld lebten sie beisammen wie die Kinder,", "tokens": ["In", "Un\u00b7schuld", "leb\u00b7ten", "sie", "bei\u00b7sam\u00b7men", "wie", "die", "Kin\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "PTKVZ", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Zu manchem Spiel, wobei man selten weint", "tokens": ["Zu", "man\u00b7chem", "Spiel", ",", "wo\u00b7bei", "man", "sel\u00b7ten", "weint"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "PWAV", "PIS", "ADJD", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den ganzen Tag, oft auch bei Nacht, vereint.", "tokens": ["Den", "gan\u00b7zen", "Tag", ",", "oft", "auch", "bei", "Nacht", ",", "ver\u00b7eint", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADV", "ADV", "APPR", "NN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch, wenn hat Ate je vergessen", "tokens": ["Doch", ",", "wenn", "hat", "A\u00b7te", "je", "ver\u00b7ges\u00b7sen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "VAFIN", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "F\u00fcr jede Lust uns Schmerzen zuzumessen?", "tokens": ["F\u00fcr", "je\u00b7de", "Lust", "uns", "Schmer\u00b7zen", "zu\u00b7zu\u00b7mes\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPER", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Der Nymphen sch\u00f6ne K\u00f6nigin", "tokens": ["Der", "Nym\u00b7phen", "sch\u00f6\u00b7ne", "K\u00f6\u00b7ni\u00b7gin"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erfuhr, man wei\u00df nicht wie? Vielleicht von einem Faun", "tokens": ["Er\u00b7fuhr", ",", "man", "wei\u00df", "nicht", "wie", "?", "Viel\u00b7leicht", "von", "ei\u00b7nem", "Faun"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PIS", "VVFIN", "PTKNEG", "PWAV", "$.", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der sie beschlich, vielleicht auch im Vertraun", "tokens": ["Der", "sie", "be\u00b7schlich", ",", "viel\u00b7leicht", "auch", "im", "Ver\u00b7traun"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PPER", "ADJD", "$,", "ADV", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Von einer alten Sch\u00e4ferin,", "tokens": ["Von", "ei\u00b7ner", "al\u00b7ten", "Sch\u00e4\u00b7fe\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der weil sie selbst nicht mehr gefiel", "tokens": ["Der", "weil", "sie", "selbst", "nicht", "mehr", "ge\u00b7fiel"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "KOUS", "PPER", "ADV", "PTKNEG", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der Jugend eitles Tun mi\u00dffiel;", "tokens": ["Der", "Ju\u00b7gend", "eit\u00b7les", "Tun", "mi\u00df\u00b7fiel", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kurz, sie erfuhr das ganze Sch\u00e4fer-Spiel.", "tokens": ["Kurz", ",", "sie", "er\u00b7fuhr", "das", "gan\u00b7ze", "Sch\u00e4\u00b7fer\u00b7Spiel", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.36": {"line.1": {"text": "Man kennt den strengen Sinn", "tokens": ["Man", "kennt", "den", "stren\u00b7gen", "Sinn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Der sch\u00f6nen J\u00e4gerin", "tokens": ["Der", "sch\u00f6\u00b7nen", "J\u00e4\u00b7ge\u00b7rin"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Die in der G\u00f6tter-Schar", "tokens": ["Die", "in", "der", "G\u00f6t\u00b7ter\u00b7Schar"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die gr\u00f6\u00dfte Spr\u00f6de war.", "tokens": ["Die", "gr\u00f6\u00df\u00b7te", "Spr\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Kein Sterblicher, kein Gott vermochte sie zu r\u00fchren.", "tokens": ["Kein", "Sterb\u00b7li\u00b7cher", ",", "kein", "Gott", "ver\u00b7moch\u00b7te", "sie", "zu", "r\u00fch\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "PIAT", "NN", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was sonst die Spr\u00f6desten vergn\u00fcgt,", "tokens": ["Was", "sonst", "die", "Spr\u00f6\u00b7des\u00b7ten", "ver\u00b7gn\u00fcgt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Sogar der Stolz, selbst unbesiegt,", "tokens": ["So\u00b7gar", "der", "Stolz", ",", "selbst", "un\u00b7be\u00b7siegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die Herzen im Triumph zu f\u00fchren", "tokens": ["Die", "Her\u00b7zen", "im", "Tri\u00b7umph", "zu", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "War ihrem gr\u00f6\u00dfern Stolz zu klein.", "tokens": ["War", "ih\u00b7rem", "gr\u00f6\u00b7\u00dfern", "Stolz", "zu", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sie z\u00fcrnte schon, nur angesehn zu sein,", "tokens": ["Sie", "z\u00fcrn\u00b7te", "schon", ",", "nur", "an\u00b7ge\u00b7sehn", "zu", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ADV", "VVINF", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Blo\u00df weil er sie vom Wirbel bis zur Nasen", "tokens": ["Blo\u00df", "weil", "er", "sie", "vom", "Wir\u00b7bel", "bis", "zur", "Na\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "PPER", "APPRART", "NN", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Im Bad erblickt ward Acton einst zum Hasen.", "tokens": ["Im", "Bad", "er\u00b7blickt", "ward", "Ac\u00b7ton", "einst", "zum", "Ha\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NE", "VVPP", "VAFIN", "NE", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Dies Beispiel fl\u00f6\u00dfte selbst dem Satyr Ehrfurcht ein.", "tokens": ["Dies", "Bei\u00b7spiel", "fl\u00f6\u00df\u00b7te", "selbst", "dem", "Sa\u00b7tyr", "Ehr\u00b7furcht", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ADV", "ART", "NN", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ihr schien ein Blick sie schon zu dreiste anzuf\u00fchlen,", "tokens": ["Ihr", "schien", "ein", "Blick", "sie", "schon", "zu", "dreis\u00b7te", "an\u00b7zu\u00b7f\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "APPR", "ADJA", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kein Zephyr wagt's sie abzuk\u00fchlen,", "tokens": ["Kein", "Ze\u00b7phyr", "wagt's", "sie", "ab\u00b7zu\u00b7k\u00fch\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Und keine Blume schm\u00fcckt' ihr Haar", "tokens": ["Und", "kei\u00b7ne", "Blu\u00b7me", "schm\u00fcckt'", "ihr", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die einst ein h\u00fcbscher Knabe war;", "tokens": ["Die", "einst", "ein", "h\u00fcb\u00b7scher", "Kna\u00b7be", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "Von Liebe nur im Schlaf zu sprechen", "tokens": ["Von", "Lie\u00b7be", "nur", "im", "Schlaf", "zu", "spre\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "APPRART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Hie\u00df bei Dianen schon ein strafbares Verbrechen:", "tokens": ["Hie\u00df", "bei", "Di\u00b7a\u00b7nen", "schon", "ein", "straf\u00b7ba\u00b7res", "Ver\u00b7bre\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Kurz, M\u00e4nner-Ha\u00df und Spr\u00f6digkeit", "tokens": ["Kurz", ",", "M\u00e4n\u00b7ner\u00b7Ha\u00df", "und", "Spr\u00f6\u00b7dig\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADJD", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "Trieb selbst Minerva nicht so weit.", "tokens": ["Trieb", "selbst", "Mi\u00b7ner\u00b7va", "nicht", "so", "weit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "NE", "PTKNEG", "ADV", "ADJD", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.37": {"line.1": {"text": "Man ratet leicht, in welche Wut", "tokens": ["Man", "ra\u00b7tet", "leicht", ",", "in", "wel\u00b7che", "Wut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADJD", "$,", "APPR", "PWAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Nymphen Fall sie setzen mu\u00dfte;", "tokens": ["Der", "Nym\u00b7phen", "Fall", "sie", "set\u00b7zen", "mu\u00df\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es tobt' ihr jungferliches Blut", "tokens": ["Es", "tobt'", "ihr", "jung\u00b7fer\u00b7li\u00b7ches", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-++--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Da\u00df sie sich kaum zu fassen wu\u00dfte.", "tokens": ["Da\u00df", "sie", "sich", "kaum", "zu", "fas\u00b7sen", "wu\u00df\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "So zornig sahn die Nymphen sie", "tokens": ["So", "zor\u00b7nig", "sahn", "die", "Nym\u00b7phen", "sie"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "In keinem andern Falle nie.", "tokens": ["In", "kei\u00b7nem", "an\u00b7dern", "Fal\u00b7le", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kallisto lie\u00df sich doch von einem Gott besiegen,", "tokens": ["Kal\u00b7lis\u00b7to", "lie\u00df", "sich", "doch", "von", "ei\u00b7nem", "Gott", "be\u00b7sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Das milderte die Schn\u00f6digkeit der Tat;", "tokens": ["Das", "mil\u00b7der\u00b7te", "die", "Schn\u00f6\u00b7dig\u00b7keit", "der", "Tat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Doch einem Hirten unterliegen", "tokens": ["Doch", "ei\u00b7nem", "Hir\u00b7ten", "un\u00b7ter\u00b7lie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Wahrhaftig! das war Hochverrat.", "tokens": ["Wahr\u00b7haf\u00b7tig", "!", "das", "war", "Hoch\u00b7ver\u00b7rat", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "$.", "PDS", "VAFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Ein fliegender Befehl zitiert aus allen Hainen", "tokens": ["Ein", "flie\u00b7gen\u00b7der", "Be\u00b7fehl", "zi\u00b7tiert", "aus", "al\u00b7len", "Hai\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das Nymphen-Volk pers\u00f6nlich zu erscheinen.", "tokens": ["Das", "Nym\u00b7phen\u00b7Volk", "per\u00b7s\u00f6n\u00b7lich", "zu", "er\u00b7schei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie schleichen allgemach herbei,", "tokens": ["Sie", "schlei\u00b7chen", "all\u00b7ge\u00b7mach", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und keine lauft, da\u00df sie die erste sei.", "tokens": ["Und", "kei\u00b7ne", "lauft", ",", "da\u00df", "sie", "die", "ers\u00b7te", "sei", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "VVFIN", "$,", "KOUS", "PPER", "ART", "ADJA", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Die G\u00f6ttin steht an ihren Spie\u00df gelehnt", "tokens": ["Die", "G\u00f6t\u00b7tin", "steht", "an", "ih\u00b7ren", "Spie\u00df", "ge\u00b7lehnt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Und sieht mit ernstem Blick, der ihren Kummer h\u00f6hnt,", "tokens": ["Und", "sieht", "mit", "erns\u00b7tem", "Blick", ",", "der", "ih\u00b7ren", "Kum\u00b7mer", "h\u00f6hnt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Im ganzen Kreis nichts als besch\u00e4mte Wangen,", "tokens": ["Im", "gan\u00b7zen", "Kreis", "nichts", "als", "be\u00b7sch\u00e4m\u00b7te", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PIS", "KOKOM", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "Und Blicke, die zur Erde niederhangen.", "tokens": ["Und", "Bli\u00b7cke", ",", "die", "zur", "Er\u00b7de", "nie\u00b7der\u00b7han\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "\u00bbhofft nicht\u00ab, spricht sie, \u00bbdurch Leugnen zu entgehn,", "tokens": ["\u00bb", "hofft", "nicht", "\u00ab", ",", "spricht", "sie", ",", "\u00bb", "durch", "Leug\u00b7nen", "zu", "ent\u00b7gehn", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PTKNEG", "$(", "$,", "VVFIN", "PPER", "$,", "$(", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.20": {"text": "Man wird euch bald die Zunge l\u00f6sen k\u00f6nnen,", "tokens": ["Man", "wird", "euch", "bald", "die", "Zun\u00b7ge", "l\u00f6\u00b7sen", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Und werdet ihr nicht g\u00fctlich eingestehn", "tokens": ["Und", "wer\u00b7det", "ihr", "nicht", "g\u00fct\u00b7lich", "ein\u00b7ge\u00b7stehn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "PPER", "PTKNEG", "ADJD", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "So soll euch mir der Gott zu Delphi nennen.", "tokens": ["So", "soll", "euch", "mir", "der", "Gott", "zu", "Del\u00b7phi", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ART", "NN", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Durch Zaudern wird die Schuld nicht gut gemacht.", "tokens": ["Durch", "Zau\u00b7dern", "wird", "die", "Schuld", "nicht", "gut", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "ART", "NN", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Nur hurtig! Jede von euch allen", "tokens": ["Nur", "hur\u00b7tig", "!", "Je\u00b7de", "von", "euch", "al\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "PIAT", "APPR", "PPER", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Die sich verging, la\u00df ihren Schleier fallen.\u00ab", "tokens": ["Die", "sich", "ver\u00b7ging", ",", "la\u00df", "ih\u00b7ren", "Schlei\u00b7er", "fal\u00b7len", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "PRF", "VVFIN", "$,", "VVIMP", "PPOSAT", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Sie spricht's und \u2013 Hem! wer h\u00e4tte das gedacht?", "tokens": ["Sie", "spricht's", "und", "\u2013", "Hem", "!", "wer", "h\u00e4t\u00b7te", "das", "ge\u00b7dacht", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "$(", "NN", "$.", "PWS", "VAFIN", "PDS", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.27": {"text": "Diana spricht's, und \u2013 alle Schleier fallen.", "tokens": ["Di\u00b7a\u00b7na", "spricht's", ",", "und", "\u2013", "al\u00b7le", "Schlei\u00b7er", "fal\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$,", "KON", "$(", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.38": {"line.1": {"text": "Man stelle sich den Lermen vor", "tokens": ["Man", "stel\u00b7le", "sich", "den", "Ler\u00b7men", "vor"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PRF", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den die besch\u00e4mte G\u00f6ttin machte,", "tokens": ["Den", "die", "be\u00b7sch\u00e4m\u00b7te", "G\u00f6t\u00b7tin", "mach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Indem der lose Cypripor", "tokens": ["In\u00b7dem", "der", "lo\u00b7se", "Cyp\u00b7ri\u00b7por"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Aus einer Wolke sah und laut herunter lachte.", "tokens": ["Aus", "ei\u00b7ner", "Wol\u00b7ke", "sah", "und", "laut", "her\u00b7un\u00b7ter", "lach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKVZ", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "\u00bbwie\u00ab, rief sie voller Wut empor,", "tokens": ["\u00bb", "wie", "\u00ab", ",", "rief", "sie", "vol\u00b7ler", "Wut", "em\u00b7por", ","], "token_info": ["punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "$(", "$,", "VVFIN", "PPER", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(doch selbst die Wut versch\u00f6nert ihre Wangen)", "tokens": ["(", "doch", "selbst", "die", "Wut", "ver\u00b7sch\u00f6\u00b7nert", "ih\u00b7re", "Wan\u00b7gen", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "ART", "NN", "VVFIN", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbdu, Wildfang, hast dies Unheil angestellt,", "tokens": ["\u00bb", "du", ",", "Wild\u00b7fang", ",", "hast", "dies", "Un\u00b7heil", "an\u00b7ge\u00b7stellt", ","], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "$,", "NN", "$,", "VAFIN", "PDS", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und kommst noch gar damit zu prangen!", "tokens": ["Und", "kommst", "noch", "gar", "da\u00b7mit", "zu", "pran\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Zwar r\u00fchmst du dich, da\u00df alle Welt", "tokens": ["Zwar", "r\u00fchmst", "du", "dich", ",", "da\u00df", "al\u00b7le", "Welt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "KOUS", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "F\u00fcr ihren Sieger dich erkenne", "tokens": ["F\u00fcr", "ih\u00b7ren", "Sie\u00b7ger", "dich", "er\u00b7ken\u00b7ne"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Da\u00df selbst der Vater Zeus so oft es dir gef\u00e4llt", "tokens": ["Da\u00df", "selbst", "der", "Va\u00b7ter", "Zeus", "so", "oft", "es", "dir", "ge\u00b7f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN", "NE", "ADV", "ADV", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Von unerlaubten Flammen brenne;", "tokens": ["Von", "un\u00b7er\u00b7laub\u00b7ten", "Flam\u00b7men", "bren\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Da\u00df, seiner Majest\u00e4t beraubt,", "tokens": ["Da\u00df", ",", "sei\u00b7ner", "Ma\u00b7jes\u00b7t\u00e4t", "be\u00b7raubt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "So oft du willt, der G\u00f6tter Haupt", "tokens": ["So", "oft", "du", "willt", ",", "der", "G\u00f6t\u00b7ter", "Haupt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ADV", "PPER", "VMFIN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Bald als ein Drache, bald als Stier", "tokens": ["Bald", "als", "ein", "Dra\u00b7che", ",", "bald", "als", "Stier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "$,", "ADV", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Bald als ein b\u00f6ckischer Satyr,", "tokens": ["Bald", "als", "ein", "b\u00f6\u00b7cki\u00b7scher", "Sa\u00b7tyr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.17": {"text": "Und bald mit Stab und Sch\u00e4fer-Tasche", "tokens": ["Und", "bald", "mit", "Stab", "und", "Sch\u00e4\u00b7fer\u00b7Ta\u00b7sche"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Der Nymphen Einfalt \u00fcberrasche.", "tokens": ["Der", "Nym\u00b7phen", "Ein\u00b7falt", "\u00fc\u00b7berr\u00b7a\u00b7sche", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Doch trotze nicht zuviel auf deine Macht!", "tokens": ["Doch", "trot\u00b7ze", "nicht", "zu\u00b7viel", "auf", "dei\u00b7ne", "Macht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die Siege die dir noch gelungen", "tokens": ["Die", "Sie\u00b7ge", "die", "dir", "noch", "ge\u00b7lun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "Hat man dir leicht genug gemacht.", "tokens": ["Hat", "man", "dir", "leicht", "ge\u00b7nug", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "ADJD", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wer selbst die Waffen streckt, wird ohne Ruhm bezwungen.", "tokens": ["Wer", "selbst", "die", "Waf\u00b7fen", "streckt", ",", "wird", "oh\u00b7ne", "Ruhm", "be\u00b7zwun\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ART", "NN", "VVFIN", "$,", "VAFIN", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Auf mich, auf mich, die deine Macht verlacht,", "tokens": ["Auf", "mich", ",", "auf", "mich", ",", "die", "dei\u00b7ne", "Macht", "ver\u00b7lacht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "APPR", "PPER", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Auf meine Brust la\u00df deine Pfeile zielen.", "tokens": ["Auf", "mei\u00b7ne", "Brust", "la\u00df", "dei\u00b7ne", "Pfei\u00b7le", "zie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "(ich fordre dich vor tausend Zeugen auf!)", "tokens": ["(", "ich", "ford\u00b7re", "dich", "vor", "tau\u00b7send", "Zeu\u00b7gen", "auf", "!", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VVFIN", "PRF", "APPR", "CARD", "NN", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Sie werden sich vor halbem Lauf", "tokens": ["Sie", "wer\u00b7den", "sich", "vor", "hal\u00b7bem", "Lauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "In meinen feuchten Strahlen k\u00fchlen", "tokens": ["In", "mei\u00b7nen", "feuch\u00b7ten", "Strah\u00b7len", "k\u00fch\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Und stumpf und matt um meinen Busen spielen.", "tokens": ["Und", "stumpf", "und", "matt", "um", "mei\u00b7nen", "Bu\u00b7sen", "spie\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Du lachst? Versuch's erst was dein Bogen kann,", "tokens": ["Du", "lachst", "?", "Ver\u00b7such's", "erst", "was", "dein", "Bo\u00b7gen", "kann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "ADV", "PWS", "PPOSAT", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.30": {"text": "Versuch's an mir und sing und lache dann!", "tokens": ["Ver\u00b7such's", "an", "mir", "und", "sing", "und", "la\u00b7che", "dann", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PPER", "KON", "VVFIN", "KON", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Doch st\u00fcnd es dir, versichert! besser an", "tokens": ["Doch", "st\u00fcnd", "es", "dir", ",", "ver\u00b7si\u00b7chert", "!", "bes\u00b7ser", "an"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "VVPP", "$.", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Du k\u00e4mst statt K\u00f6cher, Pfeil und Bogen", "tokens": ["Du", "k\u00e4mst", "statt", "K\u00f6\u00b7cher", ",", "Pfeil", "und", "Bo\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.33": {"text": "Mit einem Vogel-Rohr geflogen.", "tokens": ["Mit", "ei\u00b7nem", "Vo\u00b7gel\u00b7Rohr", "ge\u00b7flo\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.34": {"text": "Latonens Kindern nur geb\u00fchrt", "tokens": ["La\u00b7to\u00b7nens", "Kin\u00b7dern", "nur", "ge\u00b7b\u00fchrt"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "NN", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Der edle Schmuck der deinen R\u00fccken ziert.", "tokens": ["Der", "ed\u00b7le", "Schmuck", "der", "dei\u00b7nen", "R\u00fc\u00b7cken", "ziert", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.36": {"text": "Bald h\u00e4tt ich Lust, dich wehrlos heimzuschicken,", "tokens": ["Bald", "h\u00e4tt", "ich", "Lust", ",", "dich", "wehr\u00b7los", "heim\u00b7zu\u00b7schi\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Und, weil dein Fliegen dich zu Streichen nur verf\u00fchrt,", "tokens": ["Und", ",", "weil", "dein", "Flie\u00b7gen", "dich", "zu", "Strei\u00b7chen", "nur", "ver\u00b7f\u00fchrt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPOSAT", "NN", "PRF", "APPR", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Dir noch die Schwingen auszupfl\u00fccken.", "tokens": ["Dir", "noch", "die", "Schwin\u00b7gen", "aus\u00b7zu\u00b7pfl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Doch flieh nur wie du bist; la\u00df meinen Hain in Ruh,", "tokens": ["Doch", "flieh", "nur", "wie", "du", "bist", ";", "la\u00df", "mei\u00b7nen", "Hain", "in", "Ruh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "KOKOM", "PPER", "VAFIN", "$.", "VVIMP", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.40": {"text": "Auf ewig flieh aus meinen Blicken,", "tokens": ["Auf", "e\u00b7wig", "flieh", "aus", "mei\u00b7nen", "Bli\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.41": {"text": "Und flattre deinem Paphos zu;", "tokens": ["Und", "flatt\u00b7re", "dei\u00b7nem", "Pa\u00b7phos", "zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Dort tummle dich auf weichen Rosen-Betten,", "tokens": ["Dort", "tumm\u00b7le", "dich", "auf", "wei\u00b7chen", "Ro\u00b7sen\u00b7Bet\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.43": {"text": "Mit deinen Grazien, und spiele blinde Kuh", "tokens": ["Mit", "dei\u00b7nen", "Gra\u00b7zi\u00b7en", ",", "und", "spie\u00b7le", "blin\u00b7de", "Kuh"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.44": {"text": "Mit Zephyrn und mit Amoretten.\u00ab", "tokens": ["Mit", "Ze\u00b7phyrn", "und", "mit", "A\u00b7mo\u00b7ret\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "NE", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.39": {"line.1": {"text": "Die G\u00f6ttin spricht's. Mit l\u00e4chelndem Gesicht", "tokens": ["Die", "G\u00f6t\u00b7tin", "spricht'", "s.", "Mit", "l\u00e4\u00b7cheln\u00b7dem", "Ge\u00b7sicht"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "NE", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Antwortet ihr der kleine Amor \u2013 nicht.", "tokens": ["Ant\u00b7wor\u00b7tet", "ihr", "der", "klei\u00b7ne", "A\u00b7mor", "\u2013", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NE", "$(", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Gelassen langt er nur von ungef\u00e4hr", "tokens": ["Ge\u00b7las\u00b7sen", "langt", "er", "nur", "von", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "APPR", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Den sch\u00e4rfsten Pfeil aus seinem K\u00f6cher her;", "tokens": ["Den", "sch\u00e4rfs\u00b7ten", "Pfeil", "aus", "sei\u00b7nem", "K\u00f6\u00b7cher", "her", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Doch steckt er ihn, als h\u00e4tt er sich bedacht,", "tokens": ["Doch", "steckt", "er", "ihn", ",", "als", "h\u00e4tt", "er", "sich", "be\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "KOKOM", "VAFIN", "PPER", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Gleich wieder an, sieht Ph\u00f6ben an und lacht:", "tokens": ["Gleich", "wie\u00b7der", "an", ",", "sieht", "Ph\u00f6\u00b7ben", "an", "und", "lacht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "VVFIN", "NN", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "\u00bbwie reizend schminkt der Eifer deine Wangen!", "tokens": ["\u00bb", "wie", "rei\u00b7zend", "schminkt", "der", "Ei\u00b7fer", "dei\u00b7ne", "Wan\u00b7gen", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "ADJD", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "(ruft er, und tut als wollt er sie umfangen)", "tokens": ["(", "ruft", "er", ",", "und", "tut", "als", "wollt", "er", "sie", "um\u00b7fan\u00b7gen", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "KON", "ADJD", "KOKOM", "VMFIN", "PPER", "PPER", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Ich wollte dir wie Amors Wunde sticht", "tokens": ["Ich", "woll\u00b7te", "dir", "wie", "A\u00b7mors", "Wun\u00b7de", "sticht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER", "KOKOM", "NE", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ein wenig zu versuchen geben;", "tokens": ["Ein", "we\u00b7nig", "zu", "ver\u00b7su\u00b7chen", "ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Allein, bei meiner Mutter Leben!", "tokens": ["Al\u00b7lein", ",", "bei", "mei\u00b7ner", "Mut\u00b7ter", "Le\u00b7ben", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Es braucht hier meiner Pfeile nicht.", "tokens": ["Es", "braucht", "hier", "mei\u00b7ner", "Pfei\u00b7le", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPOSAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "An Spr\u00f6den, die mir Hohn gesprochen,", "tokens": ["An", "Spr\u00f6\u00b7den", ",", "die", "mir", "Hohn", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Hat mich noch stets ihr eignes Herz gerochen:", "tokens": ["Hat", "mich", "noch", "stets", "ihr", "eig\u00b7nes", "Herz", "ge\u00b7ro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und, Schwesterchen, (doch unter dir und mir:)", "tokens": ["Und", ",", "Schwes\u00b7ter\u00b7chen", ",", "(", "doch", "un\u00b7ter", "dir", "und", "mir", ":)"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "emoticon"], "pos": ["KON", "$,", "NN", "$,", "$(", "ADV", "APPR", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Was n\u00fctzt der Lerm? er k\u00f6nnte dich gereuen;", "tokens": ["Was", "n\u00fctzt", "der", "Lerm", "?", "er", "k\u00f6nn\u00b7te", "dich", "ge\u00b7reu\u00b7en", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Weit sichrer w\u00e4r's, die kleine Ungeb\u00fchr", "tokens": ["Weit", "sich\u00b7rer", "w\u00e4r's", ",", "die", "klei\u00b7ne", "Un\u00b7ge\u00b7b\u00fchr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VAFIN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Den guten Kindern zu verzeihen.\u00ab", "tokens": ["Den", "gu\u00b7ten", "Kin\u00b7dern", "zu", "ver\u00b7zei\u00b7hen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Die Nymphen l\u00e4chelten, und Amor flog davon.", "tokens": ["Die", "Nym\u00b7phen", "l\u00e4\u00b7chel\u00b7ten", ",", "und", "A\u00b7mor", "flog", "da\u00b7von", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "NE", "VVFIN", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die G\u00f6ttin z\u00fcrnt, und r\u00e4cht an ihnen", "tokens": ["Die", "G\u00f6t\u00b7tin", "z\u00fcrnt", ",", "und", "r\u00e4cht", "an", "ih\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KON", "VVFIN", "APPR", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Des losen Sp\u00f6tters Hohn.", "tokens": ["Des", "lo\u00b7sen", "Sp\u00f6t\u00b7ters", "Hohn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "\u00bbunw\u00fcrdige! Dianen mehr zu dienen,", "tokens": ["\u00bb", "un\u00b7w\u00fcr\u00b7di\u00b7ge", "!", "Di\u00b7a\u00b7nen", "mehr", "zu", "die\u00b7nen", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJA", "$.", "NN", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "(spricht sie mit ernstem Angesicht)", "tokens": ["(", "spricht", "sie", "mit", "erns\u00b7tem", "An\u00b7ge\u00b7sicht", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Zur Strafe der verge\u00dfnen Pflicht", "tokens": ["Zur", "Stra\u00b7fe", "der", "ver\u00b7ge\u00df\u00b7nen", "Pflicht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Hat euch mein Mond zum letztenmal geschienen.", "tokens": ["Hat", "euch", "mein", "Mond", "zum", "letz\u00b7ten\u00b7mal", "ge\u00b7schie\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sobald sein Wagen nur den Horizont besteigt,", "tokens": ["So\u00b7bald", "sein", "Wa\u00b7gen", "nur", "den", "Ho\u00b7ri\u00b7zont", "be\u00b7steigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Sei euch verwehrt im Hain herumzustreichen", "tokens": ["Sei", "euch", "ver\u00b7wehrt", "im", "Hain", "her\u00b7um\u00b7zu\u00b7strei\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "VVFIN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Bis sich des Tages Herold zeigt;", "tokens": ["Bis", "sich", "des", "Ta\u00b7ges", "He\u00b7rold", "zeigt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Entflieht mit schnellem Fu\u00df, die einen in die Eichen,", "tokens": ["Ent\u00b7flieht", "mit", "schnel\u00b7lem", "Fu\u00df", ",", "die", "ei\u00b7nen", "in", "die", "Ei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,", "PRELS", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die \u00fcbrigen zu ihren Urnen hin;", "tokens": ["Die", "\u00fcb\u00b7ri\u00b7gen", "zu", "ih\u00b7ren", "Ur\u00b7nen", "hin", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Dort liegt und schlaft so lang ich Luna bin!\u00ab", "tokens": ["Dort", "liegt", "und", "schlaft", "so", "lang", "ich", "Lu\u00b7na", "bin", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "KON", "ADJD", "ADV", "ADJD", "PPER", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Sie spricht's und geht die Drachen anzuspannen", "tokens": ["Sie", "spricht's", "und", "geht", "die", "Dra\u00b7chen", "an\u00b7zu\u00b7span\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "VVIZU"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Die ihren Silber-Wagen ziehn,", "tokens": ["Die", "ih\u00b7ren", "Sil\u00b7ber\u00b7Wa\u00b7gen", "ziehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und die bestraften Nymphen fliehn", "tokens": ["Und", "die", "be\u00b7straf\u00b7ten", "Nym\u00b7phen", "fliehn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Mehr traurig als belehrt von dannen.", "tokens": ["Mehr", "trau\u00b7rig", "als", "be\u00b7lehrt", "von", "dan\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "VVFIN", "APPR", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "Der Tag zerflie\u00dfet nun", "tokens": ["Der", "Tag", "zer\u00b7flie\u00b7\u00dfet", "nun"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Im allgemeinen Schatten,", "tokens": ["Im", "all\u00b7ge\u00b7mei\u00b7nen", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und alle Wesen ruhn", "tokens": ["Und", "al\u00b7le", "We\u00b7sen", "ruhn"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "VVINF"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die sich erm\u00fcdet hatten;", "tokens": ["Die", "sich", "er\u00b7m\u00fc\u00b7det", "hat\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Es schlummert Tal und Hain,", "tokens": ["Es", "schlum\u00b7mert", "Tal", "und", "Hain", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Die Weste selbst ermatten", "tokens": ["Die", "Wes\u00b7te", "selbst", "er\u00b7mat\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Von ihren Buhlerein,", "tokens": ["Von", "ih\u00b7ren", "Buh\u00b7le\u00b7rein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Und schlafen unter K\u00fcssen", "tokens": ["Und", "schla\u00b7fen", "un\u00b7ter", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Im Scho\u00dfe von Narzissen", "tokens": ["Im", "Scho\u00b7\u00dfe", "von", "Nar\u00b7zis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und Rosen g\u00e4hnend ein.", "tokens": ["Und", "Ro\u00b7sen", "g\u00e4h\u00b7nend", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Der junge Satyr nur", "tokens": ["Der", "jun\u00b7ge", "Sa\u00b7tyr", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Verfolgt der Dryas Spur;", "tokens": ["Ver\u00b7folgt", "der", "Dryas", "Spur", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "NN", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.13": {"text": "Er reckt sein langes Ohr", "tokens": ["Er", "reckt", "sein", "lan\u00b7ges", "Ohr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Bei jedem leisen Zischen", "tokens": ["Bei", "je\u00b7dem", "lei\u00b7sen", "Zi\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Aus dem Gestr\u00e4uch hervor,", "tokens": ["Aus", "dem", "Ge\u00b7str\u00e4uch", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Ein Nymphchen zu erwischen,", "tokens": ["Ein", "Nymph\u00b7chen", "zu", "er\u00b7wi\u00b7schen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Das in den finstern B\u00fcschen", "tokens": ["Das", "in", "den", "fins\u00b7tern", "B\u00fc\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Vielleicht den Weg verlor.", "tokens": ["Viel\u00b7leicht", "den", "Weg", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Er sucht im ganzen Hain", "tokens": ["Er", "sucht", "im", "gan\u00b7zen", "Hain"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Mit wohl zerzausten F\u00fc\u00dfen;", "tokens": ["Mit", "wohl", "zer\u00b7zaus\u00b7ten", "F\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.21": {"text": "Umsonst! Der G\u00f6ttin Dr\u00e4un", "tokens": ["Um\u00b7sonst", "!", "Der", "G\u00f6t\u00b7tin", "Dr\u00e4un"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["ADV", "$.", "ART", "NN", "NE"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.22": {"text": "Zwang sie sich einzuschlie\u00dfen;", "tokens": ["Zwang", "sie", "sich", "ein\u00b7zu\u00b7schlie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.23": {"text": "Die armen M\u00e4dchen m\u00fcssen", "tokens": ["Die", "ar\u00b7men", "M\u00e4d\u00b7chen", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VMFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.24": {"text": "F\u00fcr k\u00fcrzre N\u00e4chte b\u00fc\u00dfen", "tokens": ["F\u00fcr", "k\u00fcrz\u00b7re", "N\u00e4ch\u00b7te", "b\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.25": {"text": "Und schlafen itzt allein.", "tokens": ["Und", "schla\u00b7fen", "itzt", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "Dem Faun sinkt Ohr und Mut,", "tokens": ["Dem", "Faun", "sinkt", "Ohr", "und", "Mut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "NN", "KON", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Er kehrt mit k\u00fchlerm Blut", "tokens": ["Er", "kehrt", "mit", "k\u00fch\u00b7lerm", "Blut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.28": {"text": "Beim ersten Morgen-Blick", "tokens": ["Beim", "ers\u00b7ten", "Mor\u00b7gen\u00b7Blick"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.29": {"text": "Zu seinem Schlauch zur\u00fcck.", "tokens": ["Zu", "sei\u00b7nem", "Schlauch", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.30": {"text": "Er denkt, mich zu erhenken", "tokens": ["Er", "denkt", ",", "mich", "zu", "er\u00b7hen\u00b7ken"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.31": {"text": "Da m\u00fc\u00dft ich albern sein!", "tokens": ["Da", "m\u00fc\u00dft", "ich", "al\u00b7bern", "sein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADJD", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.32": {"text": "Ich will die Liebespein", "tokens": ["Ich", "will", "die", "Lie\u00b7be\u00b7spein"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.33": {"text": "In s\u00fc\u00dfem Most ertr\u00e4nken.", "tokens": ["In", "s\u00fc\u00b7\u00dfem", "Most", "er\u00b7tr\u00e4n\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Indessen schwebt der G\u00f6ttin Wagen schon", "tokens": ["In\u00b7des\u00b7sen", "schwebt", "der", "G\u00f6t\u00b7tin", "Wa\u00b7gen", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Nah \u00fcber jenem Ort wo in des Gei\u00dfblatts Schatten", "tokens": ["Nah", "\u00fc\u00b7ber", "je\u00b7nem", "Ort", "wo", "in", "des", "Gei\u00df\u00b7blatts", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "PDAT", "NN", "PWAV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Nymphen dir, Endymion,", "tokens": ["Die", "Nym\u00b7phen", "dir", ",", "En\u00b7dy\u00b7mi\u00b7on", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "PPER", "$,", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vielleicht auch sich, so sanft gebettet hatten.", "tokens": ["Viel\u00b7leicht", "auch", "sich", ",", "so", "sanft", "ge\u00b7bet\u00b7tet", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PRF", "$,", "ADV", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Wie reizend lag er da! Nicht sch\u00f6ner lag Adon", "tokens": ["Wie", "rei\u00b7zend", "lag", "er", "da", "!", "Nicht", "sch\u00f6\u00b7ner", "lag", "A\u00b7don"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVFIN", "PPER", "ADV", "$.", "PTKNEG", "ADJD", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "An seiner G\u00f6ttin Brust, die weil er schlief ihm wachte,", "tokens": ["An", "sei\u00b7ner", "G\u00f6t\u00b7tin", "Brust", ",", "die", "weil", "er", "schlief", "ihm", "wach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PRELS", "KOUS", "PPER", "VVFIN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit Liebestrunknem Blick auf ihren Liebling lachte,", "tokens": ["Mit", "Lie\u00b7be\u00b7strunk\u00b7nem", "Blick", "auf", "ih\u00b7ren", "Lieb\u00b7ling", "lach\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und stillentz\u00fcckt auf neue Freuden dachte;", "tokens": ["Und", "stil\u00b7lent\u00b7z\u00fcckt", "auf", "neu\u00b7e", "Freu\u00b7den", "dach\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nicht sch\u00f6ner ward der junge Ganymed", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "ward", "der", "jun\u00b7ge", "Ga\u00b7ny\u00b7med"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Vom Vater Zeus, der gro\u00dfe Augen dreht',", "tokens": ["Vom", "Va\u00b7ter", "Zeus", ",", "der", "gro\u00b7\u00dfe", "Au\u00b7gen", "dreht'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "NE", "$,", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "In Junons Armen einst gefunden;", "tokens": ["In", "Ju\u00b7nons", "Ar\u00b7men", "einst", "ge\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Nicht sch\u00f6ner lag, durch doppelte Gewalt", "tokens": ["Nicht", "sch\u00f6\u00b7ner", "lag", ",", "durch", "dop\u00b7pel\u00b7te", "Ge\u00b7walt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Der Feerei und Sch\u00f6nheit \u00fcberwunden,", "tokens": ["Der", "Fee\u00b7rei", "und", "Sch\u00f6n\u00b7heit", "\u00fc\u00b7berw\u00b7un\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.14": {"text": "Der Wollust atmende Rinald", "tokens": ["Der", "Wol\u00b7lust", "at\u00b7men\u00b7de", "Ri\u00b7nald"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.15": {"text": "Von seiner Zauberin umwunden:", "tokens": ["Von", "sei\u00b7ner", "Zau\u00b7be\u00b7rin", "um\u00b7wun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Als hier, vom Schlaf gebunden,", "tokens": ["Als", "hier", ",", "vom", "Schlaf", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Endymion \u2013 Gesteht, da\u00df die Gefahr", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "\u2013", "Ge\u00b7steht", ",", "da\u00df", "die", "Ge\u00b7fahr"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["NE", "$(", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "++-+-+-+-+", "measure": "iambic.penta.spondeus"}, "line.18": {"text": "Nicht allzuklein f\u00fcr eine Spr\u00f6de war.", "tokens": ["Nicht", "all\u00b7zu\u00b7klein", "f\u00fcr", "ei\u00b7ne", "Spr\u00f6\u00b7de", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "ART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "Das Sicherste war hier die Augen zuzumachen.", "tokens": ["Das", "Si\u00b7chers\u00b7te", "war", "hier", "die", "Au\u00b7gen", "zu\u00b7zu\u00b7ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "ART", "NN", "VVIZU", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sie tat es nicht und warf, jedoch nur obenhin", "tokens": ["Sie", "tat", "es", "nicht", "und", "warf", ",", "je\u00b7doch", "nur", "o\u00b7ben\u00b7hin"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "KON", "VVFIN", "$,", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und blinzend, einen Blick auf ihn.", "tokens": ["Und", "blin\u00b7zend", ",", "ei\u00b7nen", "Blick", "auf", "ihn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Sie stutzt und hemmt den Flug der schnellen Drachen,", "tokens": ["Sie", "stutzt", "und", "hemmt", "den", "Flug", "der", "schnel\u00b7len", "Dra\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.23": {"text": "Schaut wieder hin, err\u00f6tet, bebt zur\u00fcck,", "tokens": ["Schaut", "wie\u00b7der", "hin", ",", "er\u00b7r\u00f6\u00b7tet", ",", "bebt", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "VVPP", "$,", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Und suchet mit versch\u00e4mtem Blick", "tokens": ["Und", "su\u00b7chet", "mit", "ver\u00b7sch\u00e4m\u00b7tem", "Blick"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Ob sie vielleicht belauschet werde;", "tokens": ["Ob", "sie", "viel\u00b7leicht", "be\u00b7lau\u00b7schet", "wer\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.26": {"text": "Doch da sie ganz allein sich sieht,", "tokens": ["Doch", "da", "sie", "ganz", "al\u00b7lein", "sich", "sieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Lenkt sie mit ruhigerm Gem\u00fct", "tokens": ["Lenkt", "sie", "mit", "ru\u00b7hi\u00b7germ", "Ge\u00b7m\u00fct"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.28": {"text": "Den Silber-Wagen sanft zur Erde,", "tokens": ["Den", "Sil\u00b7ber\u00b7Wa\u00b7gen", "sanft", "zur", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "B\u00fcckt sich, auf ihren Arm gest\u00fctzt,", "tokens": ["B\u00fcckt", "sich", ",", "auf", "ih\u00b7ren", "Arm", "ge\u00b7st\u00fctzt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Mit halbem Leib heraus und \u00fcberl\u00e4\u00dft sich itzt", "tokens": ["Mit", "hal\u00b7bem", "Leib", "he\u00b7raus", "und", "\u00fc\u00b7berl\u00b7\u00e4\u00dft", "sich", "itzt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "PTKVZ", "KON", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Dem Anschaun ganz, womit nach Platons Lehren", "tokens": ["Dem", "An\u00b7schaun", "ganz", ",", "wo\u00b7mit", "nach", "Pla\u00b7tons", "Leh\u00b7ren"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "$,", "PWAV", "APPR", "NE", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.32": {"text": "Sich im Olymp die reinen Geister n\u00e4hren.", "tokens": ["Sich", "im", "O\u00b7lymp", "die", "rei\u00b7nen", "Geis\u00b7ter", "n\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPRART", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.43": {"line.1": {"text": "Ein leicht beschattendes Gewand", "tokens": ["Ein", "leicht", "be\u00b7schat\u00b7ten\u00b7des", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Erlaubt den ungewohnten Blicken", "tokens": ["Er\u00b7laubt", "den", "un\u00b7ge\u00b7wohn\u00b7ten", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Nur allzuviel sie zu ber\u00fccken.", "tokens": ["Nur", "all\u00b7zu\u00b7viel", "sie", "zu", "be\u00b7r\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Man sagt so gar, sie zog mit leiser Hand", "tokens": ["Man", "sagt", "so", "gar", ",", "sie", "zog", "mit", "lei\u00b7ser", "Hand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ADV", "ADV", "$,", "PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auch dieses weg, doch wer hat zugesehen?", "tokens": ["Auch", "die\u00b7ses", "weg", ",", "doch", "wer", "hat", "zu\u00b7ge\u00b7se\u00b7hen", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PDS", "PTKVZ", "$,", "KON", "PWS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und tat sie es, wof\u00fcr wir keinem stehen,", "tokens": ["Und", "tat", "sie", "es", ",", "wo\u00b7f\u00fcr", "wir", "kei\u00b7nem", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$,", "PWAV", "PPER", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "So zog sie doch beim ersten Blick", "tokens": ["So", "zog", "sie", "doch", "beim", "ers\u00b7ten", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gewi\u00df die Hand so schnell zur\u00fcck", "tokens": ["Ge\u00b7wi\u00df", "die", "Hand", "so", "schnell", "zu\u00b7r\u00fcck"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "ADV", "ADJD", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als jenes Kind, das einst im Grase spielte,", "tokens": ["Als", "je\u00b7nes", "Kind", ",", "das", "einst", "im", "Gra\u00b7se", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "$,", "PRELS", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Nach Blumen griff und eine Schlange f\u00fchlte.", "tokens": ["Nach", "Blu\u00b7men", "griff", "und", "ei\u00b7ne", "Schlan\u00b7ge", "f\u00fchl\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "KON", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.44": {"line.1": {"text": "Indessen klopft vermischt mit banger Lust", "tokens": ["In\u00b7des\u00b7sen", "klopft", "ver\u00b7mischt", "mit", "ban\u00b7ger", "Lust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ein s\u00fc\u00dfer Schmerz in ihrer hei\u00dfen Brust;", "tokens": ["Ein", "s\u00fc\u00b7\u00dfer", "Schmerz", "in", "ih\u00b7rer", "hei\u00b7\u00dfen", "Brust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Ein zitterndes, woll\u00fcstiges Verlangen", "tokens": ["Ein", "zit\u00b7tern\u00b7des", ",", "wol\u00b7l\u00fcs\u00b7ti\u00b7ges", "Ver\u00b7lan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Bew\u00f6lkt ihr schwimmend Aug und brennt auf ihren Wangen.", "tokens": ["Be\u00b7w\u00f6lkt", "ihr", "schwim\u00b7mend", "Aug", "und", "brennt", "auf", "ih\u00b7ren", "Wan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo, G\u00f6ttin, bleibt dein Stolz, die Spr\u00f6digkeit?", "tokens": ["Wo", ",", "G\u00f6t\u00b7tin", ",", "bleibt", "dein", "Stolz", ",", "die", "Spr\u00f6\u00b7dig\u00b7keit", "?"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "$,", "NN", "$,", "VVFIN", "PPOSAT", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Dein Busen schmilzt wie Schnee in raschen Flammen.", "tokens": ["Dein", "Bu\u00b7sen", "schmilzt", "wie", "Schnee", "in", "ra\u00b7schen", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "KOKOM", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Kannst du die Nymphen noch verdammen?", "tokens": ["Kannst", "du", "die", "Nym\u00b7phen", "noch", "ver\u00b7dam\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Was ihre Schuld verdient, ist's Tadel oder Neid?", "tokens": ["Was", "ih\u00b7re", "Schuld", "ver\u00b7dient", ",", "ist's", "Ta\u00b7del", "o\u00b7der", "Neid", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "VVPP", "$,", "VAFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Die Neugier hat, wie Zoroaster lehrt,", "tokens": ["Die", "Neu\u00b7gier", "hat", ",", "wie", "Zo\u00b7roas\u00b7ter", "lehrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PWAV", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Von Anbeginn der Weiber Herz bet\u00f6rt.", "tokens": ["Von", "An\u00b7be\u00b7ginn", "der", "Wei\u00b7ber", "Herz", "be\u00b7t\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Man denkt ein Blick, von Ferne, von der Seiten,", "tokens": ["Man", "denkt", "ein", "Blick", ",", "von", "Fer\u00b7ne", ",", "von", "der", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "APPR", "NN", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Ein blo\u00dfer Blick, hat wenig zu bedeuten.", "tokens": ["Ein", "blo\u00b7\u00dfer", "Blick", ",", "hat", "we\u00b7nig", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "O! glaubet mir, ihr habt schon viel getan,", "tokens": ["O", "!", "glau\u00b7bet", "mir", ",", "ihr", "habt", "schon", "viel", "ge\u00b7tan", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "VVFIN", "PPER", "$,", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Der erste Blick zieht stets den andern an;", "tokens": ["Der", "ers\u00b7te", "Blick", "zieht", "stets", "den", "an\u00b7dern", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "ART", "ADJA", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Das Auge wird (es sagt's ein weiser Mann)", "tokens": ["Das", "Au\u00b7ge", "wird", "(", "es", "sagt's", "ein", "wei\u00b7ser", "Mann", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$(", "PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Nicht satt vom Sehn, und Lunas Beispiel kann,", "tokens": ["Nicht", "satt", "vom", "Sehn", ",", "und", "Lu\u00b7nas", "Bei\u00b7spiel", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "APPRART", "NN", "$,", "KON", "NE", "NN", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Uns hier, wie wahr er sagte, lehren.", "tokens": ["Uns", "hier", ",", "wie", "wahr", "er", "sag\u00b7te", ",", "leh\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "ADV", "$,", "PWAV", "ADJD", "PPER", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Ihr M\u00e4dchen, die ihr spr\u00f6de tut,", "tokens": ["Ihr", "M\u00e4d\u00b7chen", ",", "die", "ihr", "spr\u00f6\u00b7de", "tut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hier solltet ihr ein wenig \u00fcberh\u00f6ren;", "tokens": ["Hier", "soll\u00b7tet", "ihr", "ein", "we\u00b7nig", "\u00fc\u00b7ber\u00b7h\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich bin euch diesesmal f\u00fcr kein Err\u00f6ten gut.", "tokens": ["Ich", "bin", "euch", "die\u00b7ses\u00b7mal", "f\u00fcr", "kein", "Er\u00b7r\u00f6\u00b7ten", "gut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "APPR", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die F\u00e4cher vors Gesicht!", "tokens": ["Die", "F\u00e4\u00b7cher", "vors", "Ge\u00b7sicht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Diana \u2013 Nein! um Welten", "tokens": ["Di\u00b7a\u00b7na", "\u2013", "Nein", "!", "um", "Wel\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["NE", "$(", "PTKANT", "$.", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Verriet' ich dieses nicht,", "tokens": ["Ver\u00b7ri\u00b7et'", "ich", "die\u00b7ses", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "PTKNEG", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Sie lie\u00dfen mich's entgelten.", "tokens": ["Sie", "lie\u00b7\u00dfen", "mich's", "ent\u00b7gel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.8": {"text": "Des jungen L\u00f6wen Grimm,", "tokens": ["Des", "jun\u00b7gen", "L\u00f6\u00b7wen", "Grimm", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "Des raschen Einhorns Mut,", "tokens": ["Des", "ra\u00b7schen", "Ein\u00b7horns", "Mut", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Ist nicht so ungest\u00fcm", "tokens": ["Ist", "nicht", "so", "un\u00b7ge\u00b7st\u00fcm"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PTKNEG", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Als junger Sch\u00f6nen Wut.", "tokens": ["Als", "jun\u00b7ger", "Sch\u00f6\u00b7nen", "Wut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Sie k\u00f6nnten sich verschw\u00f6ren", "tokens": ["Sie", "k\u00f6nn\u00b7ten", "sich", "ver\u00b7schw\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PRF", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Mir nimmer zu verzeihn.", "tokens": ["Mir", "nim\u00b7mer", "zu", "ver\u00b7zeihn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.14": {"text": "Nein! Wahrheit, dir zu Ehren", "tokens": ["Nein", "!", "Wahr\u00b7heit", ",", "dir", "zu", "Eh\u00b7ren"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$.", "NN", "$,", "PPER", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Ein M\u00e4rtyrer zu sein,", "tokens": ["Ein", "M\u00e4r\u00b7ty\u00b7rer", "zu", "sein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "Bei Chloens Busen! Nein!", "tokens": ["Bei", "Chloens", "Bu\u00b7sen", "!", "Nein", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NE", "NE", "$.", "PTKANT", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.17": {"text": "Das hei\u00dft zuviel begehren.", "tokens": ["Das", "hei\u00dft", "zu\u00b7viel", "be\u00b7geh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Doch, bin ich nicht zu scheu?", "tokens": ["Doch", ",", "bin", "ich", "nicht", "zu", "scheu", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "VAFIN", "PPER", "PTKNEG", "PTKA", "ADJD", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Man wei\u00df, da\u00df uns die Feen", "tokens": ["Man", "wei\u00df", ",", "da\u00df", "uns", "die", "Feen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.20": {"text": "Oft lieber allzufrei", "tokens": ["Oft", "lie\u00b7ber", "all\u00b7zu\u00b7frei"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.21": {"text": "Als allzusch\u00fcchtern sehen.", "tokens": ["Als", "all\u00b7zu\u00b7sch\u00fcch\u00b7tern", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.22": {"text": "Die Jungen danken mir", "tokens": ["Die", "Jun\u00b7gen", "dan\u00b7ken", "mir"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Vielleicht noch gar daf\u00fcr;", "tokens": ["Viel\u00b7leicht", "noch", "gar", "da\u00b7f\u00fcr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PAV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.24": {"text": "Die Weise lacht und spricht,", "tokens": ["Die", "Wei\u00b7se", "lacht", "und", "spricht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.25": {"text": "Mich \u00e4rgern M\u00e4rchen nicht;", "tokens": ["Mich", "\u00e4r\u00b7gern", "M\u00e4r\u00b7chen", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKNEG", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.26": {"text": "Und Mi\u00df Brigitte \u2013 Nun!", "tokens": ["Und", "Mi\u00df", "Bri\u00b7git\u00b7te", "\u2013", "Nun", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "NE", "$(", "ADV", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.27": {"text": "Die l\u00e4\u00dft man b\u00f6se tun!", "tokens": ["Die", "l\u00e4\u00dft", "man", "b\u00f6\u00b7se", "tun", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADJD", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Der Gegenstand, der Ort, die Zeit,", "tokens": ["Der", "Ge\u00b7gen\u00b7stand", ",", "der", "Ort", ",", "die", "Zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wird die Entschuldigung der G\u00f6ttin machen m\u00fcssen.", "tokens": ["Wird", "die", "Ent\u00b7schul\u00b7di\u00b7gung", "der", "G\u00f6t\u00b7tin", "ma\u00b7chen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ART", "NN", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Selbst ihre Unerfahrenheit", "tokens": ["Selbst", "ih\u00b7re", "Un\u00b7er\u00b7fah\u00b7ren\u00b7heit"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Vermindert ihre Strafbarkeit.", "tokens": ["Ver\u00b7min\u00b7dert", "ih\u00b7re", "Straf\u00b7bar\u00b7keit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So neu sie war, wie kann sie wissen,", "tokens": ["So", "neu", "sie", "war", ",", "wie", "kann", "sie", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "VAFIN", "$,", "PWAV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie manche wissen's nicht, da\u00df man", "tokens": ["Wie", "man\u00b7che", "wis\u00b7sen's", "nicht", ",", "da\u00df", "man"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "PTKNEG", "$,", "KOUS", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Vom Sehn sich auch berauschen kann?", "tokens": ["Vom", "Sehn", "sich", "auch", "be\u00b7rau\u00b7schen", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Sie schaut, und da sie so wie aus sich selbst gerissen,", "tokens": ["Sie", "schaut", ",", "und", "da", "sie", "so", "wie", "aus", "sich", "selbst", "ge\u00b7ris\u00b7sen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "KOUS", "PPER", "ADV", "KOKOM", "APPR", "PRF", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So uners\u00e4ttlich schaut, kommt ein Gelust sie an", "tokens": ["So", "un\u00b7er\u00b7s\u00e4tt\u00b7lich", "schaut", ",", "kommt", "ein", "Ge\u00b7lust", "sie", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "$,", "VVFIN", "ART", "NN", "PPER", "PTKVZ"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den sch\u00f6nen Schl\u00e4fer gar \u2013 zu k\u00fcssen.", "tokens": ["Den", "sch\u00f6\u00b7nen", "Schl\u00e4\u00b7fer", "gar", "\u2013", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "$(", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Zu k\u00fcssen? Ja, doch man verstehe mich", "tokens": ["Zu", "k\u00fcs\u00b7sen", "?", "Ja", ",", "doch", "man", "ver\u00b7ste\u00b7he", "mich"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "$.", "PTKANT", "$,", "KON", "PIS", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "So z\u00fcchtig, so unk\u00f6rperlich,", "tokens": ["So", "z\u00fcch\u00b7tig", ",", "so", "un\u00b7k\u00f6r\u00b7per\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "So sanft wie junge Zephyrs k\u00fcssen;", "tokens": ["So", "sanft", "wie", "jun\u00b7ge", "Ze\u00b7phyrs", "k\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Mit den Gedanken nur", "tokens": ["Mit", "den", "Ge\u00b7dan\u00b7ken", "nur"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "++-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Von einem solchen Ku\u00df,", "tokens": ["Von", "ei\u00b7nem", "sol\u00b7chen", "Ku\u00df", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wovon Ovidius", "tokens": ["Wo\u00b7von", "O\u00b7vi\u00b7dius"], "token_info": ["word", "word"], "pos": ["PWAV", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Die ungetreue Spur", "tokens": ["Die", "un\u00b7ge\u00b7treu\u00b7e", "Spur"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Nach mehr als einer Stunde", "tokens": ["Nach", "mehr", "als", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "KOKOM", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "(laut seiner eignen Hand)", "tokens": ["(", "laut", "sei\u00b7ner", "eig\u00b7nen", "Hand", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Auf seines M\u00e4dchens Munde", "tokens": ["Auf", "sei\u00b7nes", "M\u00e4d\u00b7chens", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Und wei\u00dfen Schultern fand.", "tokens": ["Und", "wei\u00b7\u00dfen", "Schul\u00b7tern", "fand", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Es kostet sie den Wunsch sich zu gestehen,", "tokens": ["Es", "kos\u00b7tet", "sie", "den", "Wunsch", "sich", "zu", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Sie gl\u00fcht von keuscher Scham vom Wirbel bis zum Zehen,", "tokens": ["Sie", "gl\u00fcht", "von", "keu\u00b7scher", "Scham", "vom", "Wir\u00b7bel", "bis", "zum", "Ze\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN", "APPRART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Und lauscht und schaut sich um. Doch allgemeine Ruh", "tokens": ["Und", "lauscht", "und", "schaut", "sich", "um", ".", "Doch", "all\u00b7ge\u00b7mei\u00b7ne", "Ruh"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "PRF", "PTKVZ", "$.", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Herrscht weit umher im Tal und auf den H\u00f6hen,", "tokens": ["Herrscht", "weit", "um\u00b7her", "im", "Tal", "und", "auf", "den", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "PTKVZ", "APPRART", "NN", "KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "Kein Bl\u00e4ttchen rauscht. Itzt schleicht sie leis hinzu,", "tokens": ["Kein", "Bl\u00e4tt\u00b7chen", "rauscht", ".", "Itzt", "schleicht", "sie", "leis", "hin\u00b7zu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Bleibt unentschlossen vor ihm stehen,", "tokens": ["Bleibt", "un\u00b7ent\u00b7schlos\u00b7sen", "vor", "ihm", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Entschlie\u00dft sich, b\u00fcckt sich sanft auf seine Wangen hin,", "tokens": ["Ent\u00b7schlie\u00dft", "sich", ",", "b\u00fcckt", "sich", "sanft", "auf", "sei\u00b7ne", "Wan\u00b7gen", "hin", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "$,", "VVFIN", "PRF", "ADJD", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Die, Rosen gleich, in s\u00fc\u00dfer R\u00f6te gl\u00fchn,", "tokens": ["Die", ",", "Ro\u00b7sen", "gleich", ",", "in", "s\u00fc\u00b7\u00dfer", "R\u00f6\u00b7te", "gl\u00fchn", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "NN", "ADV", "$,", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und spitzt die Lippen schon, und itzt \u2013 itzt war's geschehen,", "tokens": ["Und", "spitzt", "die", "Lip\u00b7pen", "schon", ",", "und", "itzt", "\u2013", "itzt", "wa\u00b7r's", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADV", "$,", "KON", "ADV", "$(", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Als eine neue Furcht (wie leicht", "tokens": ["Als", "ei\u00b7ne", "neu\u00b7e", "Furcht", "(", "wie", "leicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN", "$(", "PWAV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Wird eine Spr\u00f6de scheu!) sie schnell zur\u00fccke scheucht,", "tokens": ["Wird", "ei\u00b7ne", "Spr\u00f6\u00b7de", "scheu", "!", ")", "sie", "schnell", "zu\u00b7r\u00fc\u00b7cke", "scheucht", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADJD", "$.", "$(", "PPER", "ADJD", "PTKVZ", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Sie m\u00f6cht es noch so leise machen,", "tokens": ["Sie", "m\u00f6cht", "es", "noch", "so", "lei\u00b7se", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "So k\u00f6nnte doch der Schl\u00e4fer dran erwachen.", "tokens": ["So", "k\u00f6nn\u00b7te", "doch", "der", "Schl\u00e4\u00b7fer", "dran", "er\u00b7wa\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "ART", "NN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.25": {"text": "Was folgte drauf' Sie m\u00fc\u00dfte weiter gehn,", "tokens": ["Was", "folg\u00b7te", "drauf'", "Sie", "m\u00fc\u00df\u00b7te", "wei\u00b7ter", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VVFIN", "PPER", "VMFIN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Ihm ihre Neigung eingestehn,", "tokens": ["Ihm", "ih\u00b7re", "Nei\u00b7gung", "ein\u00b7ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Um seine Gegenliebe flehn", "tokens": ["Um", "sei\u00b7ne", "Ge\u00b7gen\u00b7lie\u00b7be", "flehn"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUI", "PPOSAT", "NN", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.28": {"text": "Und sich vielleicht \u2013 wer k\u00f6nnte das ertragen,", "tokens": ["Und", "sich", "viel\u00b7leicht", "\u2013", "wer", "k\u00f6nn\u00b7te", "das", "er\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADV", "$(", "PWS", "VMFIN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.29": {"text": "Vielleicht sich abgelesen sehn \u2013", "tokens": ["Viel\u00b7leicht", "sich", "ab\u00b7ge\u00b7le\u00b7sen", "sehn", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVPP", "VVINF", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.30": {"text": "Welch ein Gedank! Kann Luna soviel wagen,", "tokens": ["Welch", "ein", "Ge\u00b7dank", "!", "Kann", "Lu\u00b7na", "so\u00b7viel", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ART", "NN", "$.", "VMFIN", "NE", "PIS", "VVINF", "$,"], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.31": {"text": "Bei einer Venus, ja, da m\u00f6chte so was gehn,", "tokens": ["Bei", "ei\u00b7ner", "Ve\u00b7nus", ",", "ja", ",", "da", "m\u00f6ch\u00b7te", "so", "was", "gehn", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PTKANT", "$,", "ADV", "VMFIN", "ADV", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Die gibt oft ungestraft den G\u00f6ttern was zu spa\u00dfen,", "tokens": ["Die", "gibt", "oft", "un\u00b7ge\u00b7straft", "den", "G\u00f6t\u00b7tern", "was", "zu", "spa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADJD", "ART", "NN", "PIS", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Und kann sich eh im Netz ertappen lassen", "tokens": ["Und", "kann", "sich", "eh", "im", "Netz", "er\u00b7tap\u00b7pen", "las\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PRF", "KOUS", "APPRART", "NN", "VVINF", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.34": {"text": "Als ich, die nun einmal die Spr\u00f6de machen mu\u00df,", "tokens": ["Als", "ich", ",", "die", "nun", "ein\u00b7mal", "die", "Spr\u00f6\u00b7de", "ma\u00b7chen", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "PRELS", "ADV", "ADV", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Bei einem armen trocknen Ku\u00df.", "tokens": ["Bei", "ei\u00b7nem", "ar\u00b7men", "trock\u00b7nen", "Ku\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.36": {"text": "Und wie' er sollte mich zu seinen F\u00fc\u00dfen sehn?", "tokens": ["Und", "wie'", "er", "soll\u00b7te", "mich", "zu", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "sehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VMFIN", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Dianens Ehre sollt in seiner Willk\u00fcr stehn?", "tokens": ["Di\u00b7a\u00b7nens", "Eh\u00b7re", "sollt", "in", "sei\u00b7ner", "Will\u00b7k\u00fcr", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VMFIN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.38": {"text": "Wie, Wenn er dann den Ehrfurchtsvollen machte", "tokens": ["Wie", ",", "Wenn", "er", "dann", "den", "Ehr\u00b7furchts\u00b7vol\u00b7len", "mach\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.39": {"text": "(man kennt der Sch\u00e4fer Schelmerei)", "tokens": ["(", "man", "kennt", "der", "Sch\u00e4\u00b7fer", "Schel\u00b7me\u00b7rei", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PIS", "VVFIN", "ART", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Und meiner Schwachheit ohne Scheu", "tokens": ["Und", "mei\u00b7ner", "Schwach\u00b7heit", "oh\u00b7ne", "Scheu"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.41": {"text": "An einer Nymphe Busen lachte?", "tokens": ["An", "ei\u00b7ner", "Nym\u00b7phe", "Bu\u00b7sen", "lach\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.42": {"text": "Wie w\u00fcrde die der Rache sich erfreun,", "tokens": ["Wie", "w\u00fcr\u00b7de", "die", "der", "Ra\u00b7che", "sich", "er\u00b7freun", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ART", "NN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.43": {"text": "Und meine Schmach von Hain zu Hain", "tokens": ["Und", "mei\u00b7ne", "Schmach", "von", "Hain", "zu", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.44": {"text": "Den Schwestern in die Ohren raunen?", "tokens": ["Den", "Schwes\u00b7tern", "in", "die", "Oh\u00b7ren", "rau\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.45": {"text": "Die eine spr\u00e4ch's der andern nach,", "tokens": ["Die", "ei\u00b7ne", "spr\u00e4ch's", "der", "an\u00b7dern", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVFIN", "ART", "ADJA", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.46": {"text": "Bald wi\u00dftens auch die Satyrs und die Faunen", "tokens": ["Bald", "wi\u00df\u00b7tens", "auch", "die", "Sa\u00b7tyrs", "und", "die", "Fau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Und s\u00e4ngen's laut beim n\u00e4chtlichen Gelach.", "tokens": ["Und", "s\u00e4n\u00b7gen's", "laut", "beim", "n\u00e4cht\u00b7li\u00b7chen", "Ge\u00b7lach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADJD", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.48": {"text": "In kurzem eilte die Geschichte", "tokens": ["In", "kur\u00b7zem", "eil\u00b7te", "die", "Ge\u00b7schich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "Vermehrt, versch\u00f6nt, gleich einem Stadt-Ger\u00fcchte,", "tokens": ["Ver\u00b7mehrt", ",", "ver\u00b7sch\u00f6nt", ",", "gleich", "ei\u00b7nem", "Stadt\u00b7Ge\u00b7r\u00fcch\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.50": {"text": "Bis zu der obern G\u00f6tter Sitz;", "tokens": ["Bis", "zu", "der", "o\u00b7bern", "G\u00f6t\u00b7ter", "Sitz", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.51": {"text": "Dem Momus, der beim Saft der Nektar-Reben", "tokens": ["Dem", "Mo\u00b7mus", ",", "der", "beim", "Saft", "der", "Nek\u00b7ta\u00b7r\u00b7Re\u00b7ben"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "ART", "NN"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.52": {"text": "Die G\u00f6tter lachen macht, und Junons scharfen Witz", "tokens": ["Die", "G\u00f6t\u00b7ter", "la\u00b7chen", "macht", ",", "und", "Ju\u00b7nons", "schar\u00b7fen", "Witz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVFIN", "$,", "KON", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.53": {"text": "Beim Teetisch neuen Stoff zu geben.", "tokens": ["Beim", "Tee\u00b7tisch", "neu\u00b7en", "Stoff", "zu", "ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Die G\u00f6ttin bebt, erbla\u00dft und gl\u00fcht", "tokens": ["Die", "G\u00f6t\u00b7tin", "bebt", ",", "er\u00b7bla\u00dft", "und", "gl\u00fcht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "VVPP", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vor so gef\u00e4hrlichen Gedanken,", "tokens": ["Vor", "so", "ge\u00b7f\u00e4hr\u00b7li\u00b7chen", "Ge\u00b7dan\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.3": {"text": "Und wenn sie dort die Neigung zieht,", "tokens": ["Und", "wenn", "sie", "dort", "die", "Nei\u00b7gung", "zieht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So macht sie hier die Klugheit wanken.", "tokens": ["So", "macht", "sie", "hier", "die", "Klug\u00b7heit", "wan\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Man sagt, bei Spr\u00f6den \u00fcberzieh", "tokens": ["Man", "sagt", ",", "bei", "Spr\u00f6\u00b7den", "\u00fc\u00b7ber\u00b7zieh"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die Liebe doch die Vorsicht nie.", "tokens": ["Die", "Lie\u00b7be", "doch", "die", "Vor\u00b7sicht", "nie", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ein Ku\u00df mag freilich sehr behagen,", "tokens": ["Ein", "Ku\u00df", "mag", "frei\u00b7lich", "sehr", "be\u00b7ha\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Doch ist's am Ende nur ein Ku\u00df;", "tokens": ["Doch", "ist's", "am", "En\u00b7de", "nur", "ein", "Ku\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und Freuden, wo man zittern mu\u00df,", "tokens": ["Und", "Freu\u00b7den", ",", "wo", "man", "zit\u00b7tern", "mu\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "PIS", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Sind doch (was auch Ovide sagen)", "tokens": ["Sind", "doch", "(", "was", "auch", "O\u00b7vi\u00b7de", "sa\u00b7gen", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$(", "PWS", "ADV", "NE", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "F\u00fcr Damen nicht, die gerne sicher gehn.", "tokens": ["F\u00fcr", "Da\u00b7men", "nicht", ",", "die", "ger\u00b7ne", "si\u00b7cher", "gehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKNEG", "$,", "PRELS", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sie f\u00e4ngt schon an nach ihrem Drachen-Wagen", "tokens": ["Sie", "f\u00e4ngt", "schon", "an", "nach", "ih\u00b7rem", "Dra\u00b7chen\u00b7Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Den scheuen Blick herumzudrehn,", "tokens": ["Den", "scheu\u00b7en", "Blick", "her\u00b7um\u00b7zu\u00b7drehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Schon weicht ihr scheuer Fu\u00df \u2013 doch bleibt er wieder stehn;", "tokens": ["Schon", "weicht", "ihr", "scheu\u00b7er", "Fu\u00df", "\u2013", "doch", "bleibt", "er", "wie\u00b7der", "stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPOSAT", "ADJA", "NN", "$(", "ADV", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Sie kann den Trost sich nicht versagen", "tokens": ["Sie", "kann", "den", "Trost", "sich", "nicht", "ver\u00b7sa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "PRF", "PTKNEG", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Nur einmal noch (sie hat ja nichts dabei zu wagen)", "tokens": ["Nur", "ein\u00b7mal", "noch", "(", "sie", "hat", "ja", "nichts", "da\u00b7bei", "zu", "wa\u00b7gen", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "$(", "PPER", "VAFIN", "ADV", "PIS", "PAV", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Den sch\u00f6nen Schl\u00e4fer anzusehn.", "tokens": ["Den", "sch\u00f6\u00b7nen", "Schl\u00e4\u00b7fer", "an\u00b7zu\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVIZU", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "\u00bbnoch einmal?\u00ab ruft ein Casuist;", "tokens": ["\u00bb", "noch", "ein\u00b7mal", "?", "\u00ab", "ruft", "ein", "Ca\u00b7su\u00b7ist", ";"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "ADV", "$.", "$(", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbund hei\u00dft denn das nicht alles wagen?\u00ab", "tokens": ["\u00bb", "und", "hei\u00dft", "denn", "das", "nicht", "al\u00b7les", "wa\u00b7gen", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "VVFIN", "KON", "PDS", "PTKNEG", "PIS", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Vielleicht; doch ist es, wie ihr wi\u00dft,", "tokens": ["Viel\u00b7leicht", ";", "doch", "ist", "es", ",", "wie", "ihr", "wi\u00dft", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "ADV", "VAFIN", "PPER", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Genug, die G\u00f6ttin loszusagen,", "tokens": ["Ge\u00b7nug", ",", "die", "G\u00f6t\u00b7tin", "los\u00b7zu\u00b7sa\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df sie es nicht gemeint; die Frist", "tokens": ["Da\u00df", "sie", "es", "nicht", "ge\u00b7meint", ";", "die", "Frist"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "PTKNEG", "VVPP", "$.", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "War allzukurz, euch Rats zu fragen;", "tokens": ["War", "all\u00b7zu\u00b7kurz", ",", "euch", "Rats", "zu", "fra\u00b7gen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "PPER", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Und \u00fcberdem verg\u00f6nnet mir zu sagen,", "tokens": ["Und", "\u00fc\u00b7ber\u00b7dem", "ver\u00b7g\u00f6n\u00b7net", "mir", "zu", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df Escobar auf ihrer Seite ist.", "tokens": ["Da\u00df", "E\u00b7sco\u00b7bar", "auf", "ih\u00b7rer", "Sei\u00b7te", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Vorsichtig oder unvorsichtig,", "tokens": ["Vor\u00b7sich\u00b7tig", "o\u00b7der", "un\u00b7vor\u00b7sich\u00b7tig", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "(uns gilt es gleich) genug, soviel ist richtig,", "tokens": ["(", "uns", "gilt", "es", "gleich", ")", "ge\u00b7nug", ",", "so\u00b7viel", "ist", "rich\u00b7tig", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "PPER", "ADV", "$(", "ADV", "$,", "PIS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Sie b\u00fcckte sich noch einmal hin und sah,", "tokens": ["Sie", "b\u00fcck\u00b7te", "sich", "noch", "ein\u00b7mal", "hin", "und", "sah", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "ADV", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "(doch mit dem Vorsatz, ihn auf ewig dann zu fliehen)", "tokens": ["(", "doch", "mit", "dem", "Vor\u00b7satz", ",", "ihn", "auf", "e\u00b7wig", "dann", "zu", "flie\u00b7hen", ")"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "APPR", "ART", "NN", "$,", "PPER", "APPR", "ADJD", "ADV", "PTKZU", "VVINF", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.13": {"text": "Den holden Schl\u00e4fer an. Betrogne Cynthia!", "tokens": ["Den", "hol\u00b7den", "Schl\u00e4\u00b7fer", "an", ".", "Be\u00b7trog\u00b7ne", "Cyn\u00b7thia", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$.", "NN", "NE", "$."], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.14": {"text": "Sie sieht, schon kann sie ihm den Blick nicht mehr entziehen,", "tokens": ["Sie", "sieht", ",", "schon", "kann", "sie", "ihm", "den", "Blick", "nicht", "mehr", "ent\u00b7zie\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADV", "VMFIN", "PPER", "PPER", "ART", "NN", "PTKNEG", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und bald vergi\u00dft sie auch zu fliehen.", "tokens": ["Und", "bald", "ver\u00b7gi\u00dft", "sie", "auch", "zu", "flie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "Ein fremdes Feuer schleicht durch ihren ganzen Leib,", "tokens": ["Ein", "frem\u00b7des", "Feu\u00b7er", "schleicht", "durch", "ih\u00b7ren", "gan\u00b7zen", "Leib", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ihr feuchtes Aug erlischt, die runden Kniee beben,", "tokens": ["Ihr", "feuch\u00b7tes", "Aug", "er\u00b7lischt", ",", "die", "run\u00b7den", "Kni\u00b7ee", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sie kennt sich selbst nicht mehr, und f\u00fchlt in ihrem Leben", "tokens": ["Sie", "kennt", "sich", "selbst", "nicht", "mehr", ",", "und", "f\u00fchlt", "in", "ih\u00b7rem", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "PTKNEG", "ADV", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sich itzt zum erstenmal ein Weib.", "tokens": ["Sich", "itzt", "zum", "ers\u00b7ten\u00b7mal", "ein", "Weib", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPRART", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.20": {"text": "Erst lie\u00df sich ihr Gelust mit einem Kusse b\u00fc\u00dfen,", "tokens": ["Erst", "lie\u00df", "sich", "ihr", "Ge\u00b7lust", "mit", "ei\u00b7nem", "Kus\u00b7se", "b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "PPOSAT", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Itzt w\u00fcnscht sie schon sich satt an ihm zu k\u00fcssen.", "tokens": ["Itzt", "w\u00fcnscht", "sie", "schon", "sich", "satt", "an", "ihm", "zu", "k\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PRF", "ADJD", "APPR", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-++--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Doch macht sie stets die alte Sorge scheu.", "tokens": ["Doch", "macht", "sie", "stets", "die", "al\u00b7te", "Sor\u00b7ge", "scheu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.23": {"text": "Diana mu\u00df sich sicher wissen,", "tokens": ["Di\u00b7a\u00b7na", "mu\u00df", "sich", "si\u00b7cher", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PRF", "ADJD", "VVINF", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.24": {"text": "Und wird ein bi\u00dfchen Feerei", "tokens": ["Und", "wird", "ein", "bi\u00df\u00b7chen", "Fee\u00b7rei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-++", "measure": "unknown.measure.tetra"}, "line.25": {"text": "Zu brauchen sich entschlie\u00dfen m\u00fcssen.", "tokens": ["Zu", "brau\u00b7chen", "sich", "ent\u00b7schlie\u00b7\u00dfen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PRF", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Es wallt durch ihre Kunst", "tokens": ["Es", "wallt", "durch", "ih\u00b7re", "Kunst"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Ein zauberischer Dunst,", "tokens": ["Ein", "zau\u00b7be\u00b7ri\u00b7scher", "Dunst", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Von Schlummer-Kr\u00e4ften schwer,", "tokens": ["Von", "Schlum\u00b7mer\u00b7Kr\u00e4f\u00b7ten", "schwer", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Um ihren Liebling her.", "tokens": ["Um", "ih\u00b7ren", "Lieb\u00b7ling", "her", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Er dehnt sich, streckt ein Bein", "tokens": ["Er", "dehnt", "sich", ",", "streckt", "ein", "Bein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Und schl\u00e4ft bezaubert ein.", "tokens": ["Und", "schl\u00e4ft", "be\u00b7zau\u00b7bert", "ein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Sie legt sich neben ihn", "tokens": ["Sie", "legt", "sich", "ne\u00b7ben", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "Aufs Rosenlager hin,", "tokens": ["Aufs", "Ro\u00b7sen\u00b7la\u00b7ger", "hin", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.9": {"text": "(es hatte, wie wir wissen,", "tokens": ["(", "es", "hat\u00b7te", ",", "wie", "wir", "wis\u00b7sen", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "PWAV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "F\u00fcr eine Freundin Raum)", "tokens": ["F\u00fcr", "ei\u00b7ne", "Freun\u00b7din", "Raum", ")"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.11": {"text": "Und unter ihren K\u00fcssen", "tokens": ["Und", "un\u00b7ter", "ih\u00b7ren", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Den Schlaf ihm zu vers\u00fc\u00dfen", "tokens": ["Den", "Schlaf", "ihm", "zu", "ver\u00b7s\u00fc\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "PTKZU", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Wird jeder Ku\u00df ein Traum.", "tokens": ["Wird", "je\u00b7der", "Ku\u00df", "ein", "Traum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Ein Traumgesicht von jener Art,", "tokens": ["Ein", "Traum\u00b7ge\u00b7sicht", "von", "je\u00b7ner", "Art", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die oft, trotz Scapulier und Bart,", "tokens": ["Die", "oft", ",", "trotz", "Sca\u00b7pu\u00b7lier", "und", "Bart", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "APPR", "NE", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sanct Franzens fette Seraphinen", "tokens": ["Sanct", "Fran\u00b7zens", "fet\u00b7te", "Se\u00b7ra\u00b7phi\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "NE", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "In schw\u00fcler Sommer-Nacht bedienen;", "tokens": ["In", "schw\u00fc\u00b7ler", "Som\u00b7mer\u00b7Nacht", "be\u00b7die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Traum, wovor selbst in der Fasten-Zeit", "tokens": ["Ein", "Traum", ",", "wo\u00b7vor", "selbst", "in", "der", "Fas\u00b7ten\u00b7Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PWAV", "ADV", "APPR", "ART", "NN"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Sich keine junge Nonne scheut,", "tokens": ["Sich", "kei\u00b7ne", "jun\u00b7ge", "Non\u00b7ne", "scheut", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Der, wie das fromme Ding in seiner Einfalt denket,", "tokens": ["Der", ",", "wie", "das", "from\u00b7me", "Ding", "in", "sei\u00b7ner", "Ein\u00b7falt", "den\u00b7ket", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PWAV", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie bis ins Paradies entz\u00fcckt,", "tokens": ["Sie", "bis", "ins", "Pa\u00b7ra\u00b7dies", "ent\u00b7z\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mit einem Strom von Wollust tr\u00e4nket,", "tokens": ["Mit", "ei\u00b7nem", "Strom", "von", "Wol\u00b7lust", "tr\u00e4n\u00b7ket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Und f\u00fchlen l\u00e4\u00dft was nie ihr Aug erblickt.", "tokens": ["Und", "f\u00fch\u00b7len", "l\u00e4\u00dft", "was", "nie", "ihr", "Aug", "er\u00b7blickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVFIN", "PWS", "ADV", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Ob Luna selbst dabei was abgezielet \u2013", "tokens": ["Ob", "Lu\u00b7na", "selbst", "da\u00b7bei", "was", "ab\u00b7ge\u00b7zie\u00b7let", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADV", "PAV", "PWS", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Ob ihr das schelmische Gesicht,", "tokens": ["Ob", "ihr", "das", "schel\u00b7mi\u00b7sche", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Cupido, einen Streich gespielet \u2013", "tokens": ["Cu\u00b7pi\u00b7do", ",", "ei\u00b7nen", "Streich", "ge\u00b7spie\u00b7let", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Entscheidet die Geschichte nicht.", "tokens": ["Ent\u00b7schei\u00b7det", "die", "Ge\u00b7schich\u00b7te", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Genug, wir kennen die und den,", "tokens": ["Ge\u00b7nug", ",", "wir", "ken\u00b7nen", "die", "und", "den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PPER", "VVFIN", "ART", "KON", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die gerne nie erwachen wollten,", "tokens": ["Die", "ger\u00b7ne", "nie", "er\u00b7wa\u00b7chen", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Wenn sie Aeonenlang so sch\u00f6n", "tokens": ["Wenn", "sie", "A\u00b7e\u00b7o\u00b7nen\u00b7lang", "so", "sch\u00f6n"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "NN", "ADV", "ADJD"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.8": {"text": "Wie unser Sch\u00e4fer tr\u00e4umen sollten.", "tokens": ["Wie", "un\u00b7ser", "Sch\u00e4\u00b7fer", "tr\u00e4u\u00b7men", "soll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.54": {"line.1": {"text": "Was Jupiter als Ledas Schwan", "tokens": ["Was", "Ju\u00b7pi\u00b7ter", "als", "Le\u00b7das", "Schwan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "NN", "KOUS", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als Europens Stier getan,", "tokens": ["Und", "als", "Eu\u00b7ro\u00b7pens", "Stier", "ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NE", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wie er Alkmenen hintergangen,", "tokens": ["Wie", "er", "A\u00b7lkme\u00b7nen", "hin\u00b7ter\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Und wie der hinkende Vulcan", "tokens": ["Und", "wie", "der", "hin\u00b7ken\u00b7de", "Vul\u00b7can"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Sein Weibchen einst im Garn gefangen;", "tokens": ["Sein", "Weib\u00b7chen", "einst", "im", "Garn", "ge\u00b7fan\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wie stille Nymphen oft im Hain", "tokens": ["Wie", "stil\u00b7le", "Nym\u00b7phen", "oft", "im", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJA", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Dem Faun zum Raube werden m\u00fcssen,", "tokens": ["Dem", "Faun", "zum", "Rau\u00b7be", "wer\u00b7den", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Wie sie sich str\u00e4uben, bitten, dr\u00e4un,", "tokens": ["Wie", "sie", "sich", "str\u00e4u\u00b7ben", ",", "bit\u00b7ten", ",", "dr\u00e4un", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVFIN", "$,", "VVFIN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Erm\u00fcden, immer schw\u00e4cher schrein,", "tokens": ["Er\u00b7m\u00fc\u00b7den", ",", "im\u00b7mer", "schw\u00e4\u00b7cher", "schrein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADV", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Und endlich selbst den R\u00e4uber k\u00fcssen;", "tokens": ["Und", "end\u00b7lich", "selbst", "den", "R\u00e4u\u00b7ber", "k\u00fcs\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Des Weingotts Zug, und wie um ihn", "tokens": ["Des", "Wein\u00b7gotts", "Zug", ",", "und", "wie", "um", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "KON", "PWAV", "APPR", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Die taumelnden Bacchanten schw\u00e4rmen,", "tokens": ["Die", "tau\u00b7meln\u00b7den", "Bac\u00b7chan\u00b7ten", "schw\u00e4r\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wie sie von trunkner Freude gl\u00fchn,", "tokens": ["Wie", "sie", "von", "trunk\u00b7ner", "Freu\u00b7de", "gl\u00fchn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Und mit den Klapper-Blechen lermen;", "tokens": ["Und", "mit", "den", "Klap\u00b7per\u00b7Ble\u00b7chen", "ler\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Sie wiehern laut ihr Evoe!", "tokens": ["Sie", "wie\u00b7hern", "laut", "ihr", "E\u00b7voe", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.16": {"text": "Es hallt vom fernen Rhodope", "tokens": ["Es", "hallt", "vom", "fer\u00b7nen", "Rho\u00b7do\u00b7pe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Zur\u00fcck; der Satyr hebt mit rasender Geb\u00e4rde", "tokens": ["Zu\u00b7r\u00fcck", ";", "der", "Sa\u00b7tyr", "hebt", "mit", "ra\u00b7sen\u00b7der", "Ge\u00b7b\u00e4r\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PTKVZ", "$.", "ART", "NN", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Die nackte Menas in die H\u00f6h,", "tokens": ["Die", "nack\u00b7te", "Me\u00b7nas", "in", "die", "H\u00f6h", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Und stampft in wildem Tanz die Erde.", "tokens": ["Und", "stampft", "in", "wil\u00b7dem", "Tanz", "die", "Er\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Ein sanftrer Anblick folgt dem rohen Bacchanal.", "tokens": ["Ein", "sanf\u00b7trer", "An\u00b7blick", "folgt", "dem", "ro\u00b7hen", "Bac\u00b7cha\u00b7nal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein stilles, schattenvolles Tal", "tokens": ["Ein", "stil\u00b7les", ",", "schat\u00b7ten\u00b7vol\u00b7les", "Tal"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "F\u00fchrt ihn der H\u00f6hle zu, wo sich die Nymphen baden;", "tokens": ["F\u00fchrt", "ihn", "der", "H\u00f6h\u00b7le", "zu", ",", "wo", "sich", "die", "Nym\u00b7phen", "ba\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "PWAV", "PRF", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Diana selbst err\u00f6tet nicht", "tokens": ["Di\u00b7a\u00b7na", "selbst", "er\u00b7r\u00f6\u00b7tet", "nicht"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ADV", "VVFIN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "(man merke, nur im Traumgesicht", "tokens": ["(", "man", "mer\u00b7ke", ",", "nur", "im", "Traum\u00b7ge\u00b7sicht"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PIS", "VVFIN", "$,", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und von gesch\u00e4ftigen Najaden", "tokens": ["Und", "von", "ge\u00b7sch\u00e4f\u00b7ti\u00b7gen", "Na\u00b7ja\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Fast ganz verdeckt) von ihm gesehn zu sein.", "tokens": ["Fast", "ganz", "ver\u00b7deckt", ")", "von", "ihm", "ge\u00b7sehn", "zu", "sein", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$(", "APPR", "PPER", "VVPP", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Welch reizendes Gew\u00fchl! Es scheint vom Widerschein", "tokens": ["Welch", "rei\u00b7zen\u00b7des", "Ge\u00b7w\u00fchl", "!", "Es", "scheint", "vom", "Wi\u00b7der\u00b7schein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So mancher wei\u00dfen Brust die sich im Wasser bildet,", "tokens": ["So", "man\u00b7cher", "wei\u00b7\u00dfen", "Brust", "die", "sich", "im", "Was\u00b7ser", "bil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "ART", "PRF", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So manches goldnen Haars, die Flut hier \u00fcberg\u00fcldet,", "tokens": ["So", "man\u00b7ches", "gold\u00b7nen", "Haars", ",", "die", "Flut", "hier", "\u00fc\u00b7berg\u00b7\u00fcl\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dort Schnee im Sonnen-Glanz zu sein.", "tokens": ["Dort", "Schnee", "im", "Son\u00b7nen\u00b7Glanz", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPRART", "NN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Sein trunknes Auge schlingt mit gierig offnen Blicken", "tokens": ["Sein", "trunk\u00b7nes", "Au\u00b7ge", "schlingt", "mit", "gie\u00b7rig", "off\u00b7nen", "Bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "APPR", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "So viele Reizungen hinein,", "tokens": ["So", "vie\u00b7le", "Rei\u00b7zun\u00b7gen", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.14": {"text": "Er schwimmt in l\u00fcsternem Entz\u00fccken", "tokens": ["Er", "schwimmt", "in", "l\u00fcs\u00b7ter\u00b7nem", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Und wird vor Wunder fast zum Stein.", "tokens": ["Und", "wird", "vor", "Wun\u00b7der", "fast", "zum", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "NN", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.56": {"line.1": {"text": "Man glaubt, da\u00df Cynthia hiebei", "tokens": ["Man", "glaubt", ",", "da\u00df", "Cyn\u00b7thia", "hie\u00b7bei"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "NE", "PAV"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Nicht unger\u00fchrt geblieben sei;", "tokens": ["Nicht", "un\u00b7ge\u00b7r\u00fchrt", "ge\u00b7blie\u00b7ben", "sei", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So s\u00fc\u00df auch K\u00fcsse sind, wenn wir Tibulle h\u00f6ren,", "tokens": ["So", "s\u00fc\u00df", "auch", "K\u00fcs\u00b7se", "sind", ",", "wenn", "wir", "Ti\u00b7bul\u00b7le", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "NN", "VAFIN", "$,", "KOUS", "PPER", "NE", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So ha\u00dft doch die Natur ein ewig Einerlei.", "tokens": ["So", "ha\u00dft", "doch", "die", "Na\u00b7tur", "ein", "e\u00b7wig", "Ei\u00b7ner\u00b7lei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beim Nectartisch und beim Konzert der Sph\u00e4ren", "tokens": ["Beim", "Nec\u00b7tar\u00b7tisch", "und", "beim", "Kon\u00b7zert", "der", "Sph\u00e4\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "KON", "APPRART", "NN", "ART", "NN"], "meter": "+-+--+-+-+-", "measure": "trochaic.penta.relaxed"}, "line.6": {"text": "Sind G\u00f6tter selbst nicht stets von Langerweile frei.", "tokens": ["Sind", "G\u00f6t\u00b7ter", "selbst", "nicht", "stets", "von", "Lan\u00b7ger\u00b7wei\u00b7le", "frei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "PTKNEG", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zum mindsten sagt's Homer. Wie wird dann, satt von K\u00fcssen,", "tokens": ["Zum", "minds\u00b7ten", "sagt's", "Ho\u00b7mer", ".", "Wie", "wird", "dann", ",", "satt", "von", "K\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NE", "NE", "$.", "PWAV", "VAFIN", "ADV", "$,", "KOUI", "APPR", "NN", "$,"], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Diana sich zu helfen wissen?", "tokens": ["Di\u00b7a\u00b7na", "sich", "zu", "hel\u00b7fen", "wis\u00b7sen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "\u00bbsie tat (so sagt der Faun, der sie beschlichen hat)", "tokens": ["\u00bb", "sie", "tat", "(", "so", "sagt", "der", "Faun", ",", "der", "sie", "be\u00b7schli\u00b7chen", "hat", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$(", "ADV", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was Platons Penia im G\u00f6tter-Garten tat.\u00ab", "tokens": ["Was", "Pla\u00b7tons", "Pe\u00b7nia", "im", "G\u00f6t\u00b7ter\u00b7Gar\u00b7ten", "tat", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "NE", "NE", "APPRART", "NN", "VVFIN", "$.", "$("], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "\u00bbwas tat dann die?\u00ab wird hier ein Neuling fragen?", "tokens": ["\u00bb", "was", "tat", "dann", "die", "?", "\u00ab", "wird", "hier", "ein", "Neu\u00b7ling", "fra\u00b7gen", "?"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "ADV", "ART", "$.", "$(", "VAFIN", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Sie legte \u2013 Ja doch! Nur gemach!", "tokens": ["Sie", "leg\u00b7te", "\u2013", "Ja", "doch", "!", "Nur", "ge\u00b7mach", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "PTKANT", "ADV", "$.", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Schlagt euern Plato selber nach,", "tokens": ["Schlagt", "eu\u00b7ern", "Pla\u00b7to", "sel\u00b7ber", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NE", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Das l\u00e4\u00dft sich nur auf Griechisch sagen.", "tokens": ["Das", "l\u00e4\u00dft", "sich", "nur", "auf", "Grie\u00b7chisch", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PRF", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Verliebt und weise sein, ist, wie ein Alter glaubt,", "tokens": ["Ver\u00b7liebt", "und", "wei\u00b7se", "sein", ",", "ist", ",", "wie", "ein", "Al\u00b7ter", "glaubt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "VAINF", "$,", "VAFIN", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Den G\u00f6ttern kaum, den Menschen nie erlaubt.", "tokens": ["Den", "G\u00f6t\u00b7tern", "kaum", ",", "den", "Men\u00b7schen", "nie", "er\u00b7laubt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Wer ganz Empfindung ist, kann keine Schl\u00fcsse machen.", "tokens": ["Wer", "ganz", "Emp\u00b7fin\u00b7dung", "ist", ",", "kann", "kei\u00b7ne", "Schl\u00fcs\u00b7se", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NN", "VAFIN", "$,", "VMFIN", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Der Gegenstand, der itzt Dianen an sich zieht,", "tokens": ["Der", "Ge\u00b7gen\u00b7stand", ",", "der", "itzt", "Di\u00b7a\u00b7nen", "an", "sich", "zieht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADV", "NN", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Macht, wie Galen bemerkt, nebst Wallung im Gebl\u00fct,", "tokens": ["Macht", ",", "wie", "Ga\u00b7len", "be\u00b7merkt", ",", "nebst", "Wal\u00b7lung", "im", "Ge\u00b7bl\u00fct", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PWAV", "NN", "VVPP", "$,", "APPR", "NN", "APPRART", "NN", "$,"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.20": {"text": "Die Augen \u00fcbergehn und die Vernunft erschwachen;", "tokens": ["Die", "Au\u00b7gen", "\u00fc\u00b7ber\u00b7gehn", "und", "die", "Ver\u00b7nunft", "er\u00b7schwa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und Martialis mu\u00df gestehn,", "tokens": ["Und", "Mar\u00b7ti\u00b7a\u00b7lis", "mu\u00df", "ge\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "VMFIN", "VVINF", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.22": {"text": "Da\u00df selbst Cornelia, die Mutter beider Gracchen,", "tokens": ["Da\u00df", "selbst", "Cor\u00b7ne\u00b7lia", ",", "die", "Mut\u00b7ter", "bei\u00b7der", "Grac\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "$,", "ART", "NN", "PIAT", "NN", "$,"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.23": {"text": "Mit kaltem Blut ihn selten angesehn.", "tokens": ["Mit", "kal\u00b7tem", "Blut", "ihn", "sel\u00b7ten", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Die Spr\u00f6den m\u00f6gen sich hier ein Exempel nehmen.", "tokens": ["Die", "Spr\u00f6\u00b7den", "m\u00f6\u00b7gen", "sich", "hier", "ein", "Ex\u00b7em\u00b7pel", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PRF", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Das sch\u00f6ne Volk nicht zu besch\u00e4men,", "tokens": ["Das", "sch\u00f6\u00b7ne", "Volk", "nicht", "zu", "be\u00b7sch\u00e4\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Verschwieg ich gern, wie tief Diana fiel;", "tokens": ["Ver\u00b7schwieg", "ich", "gern", ",", "wie", "tief", "Di\u00b7a\u00b7na", "fiel", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Allein der Faun verriet das ganze Spiel.", "tokens": ["Al\u00b7lein", "der", "Faun", "ver\u00b7riet", "das", "gan\u00b7ze", "Spiel", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Zum Ungl\u00fcck war's der schlimmste unter allen.", "tokens": ["Zum", "Un\u00b7gl\u00fcck", "wa\u00b7r's", "der", "schlimms\u00b7te", "un\u00b7ter", "al\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "ADJA", "APPR", "PIAT", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Er hatte, wie gesagt, den Nymphen zu gefallen", "tokens": ["Er", "hat\u00b7te", ",", "wie", "ge\u00b7sagt", ",", "den", "Nym\u00b7phen", "zu", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "VVPP", "$,", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den ganzen Hain umsonst durchsp\u00fcrt,", "tokens": ["Den", "gan\u00b7zen", "Hain", "um\u00b7sonst", "durch\u00b7sp\u00fcrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und dachte gleich zu seinen vollen Schl\u00e4uchen", "tokens": ["Und", "dach\u00b7te", "gleich", "zu", "sei\u00b7nen", "vol\u00b7len", "Schl\u00e4u\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sich unbemerkt zur\u00fcckzuschleichen,", "tokens": ["Sich", "un\u00b7be\u00b7merkt", "zu\u00b7r\u00fcck\u00b7zu\u00b7schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als aus den nahen Myrten-Str\u00e4uchen", "tokens": ["Als", "aus", "den", "na\u00b7hen", "Myr\u00b7ten\u00b7Str\u00e4u\u00b7chen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sein lauschend Ohr ein wollust-atmend Keuchen", "tokens": ["Sein", "lau\u00b7schend", "Ohr", "ein", "wol\u00b7lust\u00b7at\u00b7mend", "Keu\u00b7chen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPOSAT", "ADJD", "NN", "ART", "ADJD", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Ein liebliches Geseufz und s\u00fc\u00dfes Girren r\u00fchrt.", "tokens": ["Ein", "lieb\u00b7li\u00b7ches", "Ge\u00b7seufz", "und", "s\u00fc\u00b7\u00dfes", "Gir\u00b7ren", "r\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Der Satyr stutzt und denkt bei sich:", "tokens": ["Der", "Sa\u00b7tyr", "stutzt", "und", "denkt", "bei", "sich", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "APPR", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Hier ist man gl\u00fccklicher als ich,", "tokens": ["Hier", "ist", "man", "gl\u00fcck\u00b7li\u00b7cher", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADJD", "KOKOM", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Dies Seufzen hat was zu bedeuten.", "tokens": ["Dies", "Seuf\u00b7zen", "hat", "was", "zu", "be\u00b7deu\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VAFIN", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "So seufzt, beim Styx! trostlose Liebe nicht.", "tokens": ["So", "seufzt", ",", "beim", "Styx", "!", "trost\u00b7lo\u00b7se", "Lie\u00b7be", "nicht", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "APPRART", "NN", "$.", "ADJA", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Er schleicht dem Tone nach und sieht ein hellers Licht", "tokens": ["Er", "schleicht", "dem", "To\u00b7ne", "nach", "und", "sieht", "ein", "hel\u00b7lers", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "KON", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Sich \u00fcber das Geb\u00fcsch verbreiten,", "tokens": ["Sich", "\u00fc\u00b7ber", "das", "Ge\u00b7b\u00fcsch", "ver\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "Schleicht immer fort, entdeckt das Drachen-Paar,", "tokens": ["Schleicht", "im\u00b7mer", "fort", ",", "ent\u00b7deckt", "das", "Dra\u00b7chen\u00b7Paar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKVZ", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Die ungeduldig sich am leeren Wagen str\u00e4uben,", "tokens": ["Die", "un\u00b7ge\u00b7dul\u00b7dig", "sich", "am", "lee\u00b7ren", "Wa\u00b7gen", "str\u00e4u\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und stutzt noch mehr. Wie, denkt er, mag wohl gar", "tokens": ["Und", "stutzt", "noch", "mehr", ".", "Wie", ",", "denkt", "er", ",", "mag", "wohl", "gar"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "ADV", "$.", "PWAV", "$,", "VVFIN", "PPER", "$,", "VMFIN", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Diana, die so spr\u00f6de war,", "tokens": ["Di\u00b7a\u00b7na", ",", "die", "so", "spr\u00f6\u00b7de", "war", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PRELS", "ADV", "VVFIN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Die M\u00e4nner-Hasserin, sich hier die Zeit vertreiben,", "tokens": ["Die", "M\u00e4n\u00b7ner\u00b7Has\u00b7se\u00b7rin", ",", "sich", "hier", "die", "Zeit", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRF", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Kaum denkt er's aus, so zeigt ein neuer Blick", "tokens": ["Kaum", "denkt", "er's", "aus", ",", "so", "zeigt", "ein", "neu\u00b7er", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PTKVZ", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.25": {"text": "Ihm Lunas Fall und Amors Meisterst\u00fcck.", "tokens": ["Ihm", "Lu\u00b7nas", "Fall", "und", "A\u00b7mors", "Meis\u00b7ter\u00b7st\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NE", "NN", "KON", "NE", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "O! G\u00f6ttin, welch ein Augenblick;", "tokens": ["O", "!", "G\u00f6t\u00b7tin", ",", "welch", "ein", "Au\u00b7gen\u00b7blick", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$.", "NN", "$,", "PWAT", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Wie wird der rohe Faun dich h\u00f6hnen!", "tokens": ["Wie", "wird", "der", "ro\u00b7he", "Faun", "dich", "h\u00f6h\u00b7nen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "ADJA", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Ein andrer schliche sich von einer solchen Szenen", "tokens": ["Ein", "an\u00b7drer", "schli\u00b7che", "sich", "von", "ei\u00b7ner", "sol\u00b7chen", "Sze\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "PRF", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Mit abgewandtem Aug aus Gro\u00dfmut still zur\u00fcck;", "tokens": ["Mit", "ab\u00b7ge\u00b7wand\u00b7tem", "Aug", "aus", "Gro\u00df\u00b7mut", "still", "zu\u00b7r\u00fcck", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Er w\u00fcrde sich sogar noch Zweifel machen,", "tokens": ["Er", "w\u00fcr\u00b7de", "sich", "so\u00b7gar", "noch", "Zwei\u00b7fel", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "ADV", "ADV", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.31": {"text": "Und hie\u00df es nur ein t\u00e4uschend Nacht-Gesicht:", "tokens": ["Und", "hie\u00df", "es", "nur", "ein", "t\u00e4u\u00b7schend", "Nacht\u00b7Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Allein in Faunen wohnt so viele Tugend nicht.", "tokens": ["Al\u00b7lein", "in", "Fau\u00b7nen", "wohnt", "so", "vie\u00b7le", "Tu\u00b7gend", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "VVFIN", "ADV", "PIAT", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Ein wildes \u00fcberlautes Lachen", "tokens": ["Ein", "wil\u00b7des", "\u00fc\u00b7berl\u00b7au\u00b7tes", "La\u00b7chen"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Weckt sie, und zeigt den Zeugen ihrer Lust.", "tokens": ["Weckt", "sie", ",", "und", "zeigt", "den", "Zeu\u00b7gen", "ih\u00b7rer", "Lust", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KON", "VVFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie hebt ein sterbend Aug und schlie\u00dft es pl\u00f6tzlich wieder,", "tokens": ["Sie", "hebt", "ein", "ster\u00b7bend", "Aug", "und", "schlie\u00dft", "es", "pl\u00f6tz\u00b7lich", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJD", "NN", "KON", "VVFIN", "PPER", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ein kalter Schaur durchf\u00e4hrt die aufgel\u00f6sten Glieder,", "tokens": ["Ein", "kal\u00b7ter", "Schaur", "durch\u00b7f\u00e4hrt", "die", "auf\u00b7ge\u00b7l\u00f6s\u00b7ten", "Glie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Vor Schrecken starrt die ausgedehnte Brust.", "tokens": ["Vor", "Schre\u00b7cken", "starrt", "die", "aus\u00b7ge\u00b7dehn\u00b7te", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie sinkt bet\u00e4ubt bei ihrem Sch\u00e4fer nieder,", "tokens": ["Sie", "sinkt", "be\u00b7t\u00e4ubt", "bei", "ih\u00b7rem", "Sch\u00e4\u00b7fer", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "VVPP", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und seufzt und weint, da\u00df sie nicht sterben kann.", "tokens": ["Und", "seufzt", "und", "weint", ",", "da\u00df", "sie", "nicht", "ster\u00b7ben", "kann", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Ach! k\u00e4m er nur, der d\u00fcrre Knochen-Mann,", "tokens": ["Ach", "!", "k\u00e4m", "er", "nur", ",", "der", "d\u00fcr\u00b7re", "Kno\u00b7chen\u00b7Mann", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "VVFIN", "PPER", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Er sollt ihr Liebling sein! Sie wollte mit Entz\u00fccken", "tokens": ["Er", "sollt", "ihr", "Lieb\u00b7ling", "sein", "!", "Sie", "woll\u00b7te", "mit", "Ent\u00b7z\u00fc\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VAINF", "$.", "PPER", "VMFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Sein faul Geripp an ihren Busen dr\u00fccken!", "tokens": ["Sein", "faul", "Ge\u00b7ripp", "an", "ih\u00b7ren", "Bu\u00b7sen", "dr\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Was kaum so reizend war sieht sie mit Grauen an.", "tokens": ["Was", "kaum", "so", "rei\u00b7zend", "war", "sieht", "sie", "mit", "Grau\u00b7en", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "VVPP", "VAFIN", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wie w\u00e4lzt auf Rosen sich als wie auf Kohlen-Feuer,", "tokens": ["Wie", "w\u00e4lzt", "auf", "Ro\u00b7sen", "sich", "als", "wie", "auf", "Koh\u00b7len\u00b7Feu\u00b7er", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "APPR", "NN", "PRF", "KOUS", "KOKOM", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Des Zephyrs Atem deucht ihr Pest,", "tokens": ["Des", "Ze\u00b7phyrs", "A\u00b7tem", "deucht", "ihr", "Pest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Endymion ein Ungeheuer,", "tokens": ["En\u00b7dy\u00b7mi\u00b7on", "ein", "Un\u00b7ge\u00b7heu\u00b7er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Die weite Welt ein Drachen-Nest.", "tokens": ["Die", "wei\u00b7te", "Welt", "ein", "Dra\u00b7chen\u00b7Nest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Sie so betr\u00fcbt zu sehn, das schmelzte Tartar-Herzen,", "tokens": ["Sie", "so", "be\u00b7tr\u00fcbt", "zu", "sehn", ",", "das", "schmelz\u00b7te", "Tar\u00b7ta\u00b7rHer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJD", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Der Faun bleibt unger\u00fchrt; er lacht noch ihrer Schmerzen,", "tokens": ["Der", "Faun", "bleibt", "un\u00b7ge\u00b7r\u00fchrt", ";", "er", "lacht", "noch", "ih\u00b7rer", "Schmer\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "$.", "PPER", "VVFIN", "ADV", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Und leert den schalen Witz, den er bei manchem Schmaus", "tokens": ["Und", "leert", "den", "scha\u00b7len", "Witz", ",", "den", "er", "bei", "man\u00b7chem", "Schmaus"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Gesammelt hat, bei diesem Anla\u00df aus;", "tokens": ["Ge\u00b7sam\u00b7melt", "hat", ",", "bei", "die\u00b7sem", "An\u00b7la\u00df", "aus", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "$,", "APPR", "PDAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Sieht sie auf ihren Arm sich stumm und trostlos stemmen,", "tokens": ["Sieht", "sie", "auf", "ih\u00b7ren", "Arm", "sich", "stumm", "und", "trost\u00b7los", "stem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PRF", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und eine Tr\u00e4nenflut, die nicht zu stillen war,", "tokens": ["Und", "ei\u00b7ne", "Tr\u00e4\u00b7nen\u00b7flut", ",", "die", "nicht", "zu", "stil\u00b7len", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "PTKNEG", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Den sch\u00f6nsten Busen \u00fcberschwemmen,", "tokens": ["Den", "sch\u00f6ns\u00b7ten", "Bu\u00b7sen", "\u00fc\u00b7bersc\u00b7hwem\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.23": {"text": "Sieht's und erfrecht sich, der Corsar!", "tokens": ["Sieht's", "und", "er\u00b7frecht", "sich", ",", "der", "Cor\u00b7sar", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "KON", "VVFIN", "PRF", "$,", "ART", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.24": {"text": "Durch K\u00fcsse ihren Lauf zu hemmen.", "tokens": ["Durch", "K\u00fcs\u00b7se", "ih\u00b7ren", "Lauf", "zu", "hem\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.25": {"text": "Sie st\u00f6\u00dft ihn weg, doch nur mit matter Hand.", "tokens": ["Sie", "st\u00f6\u00dft", "ihn", "weg", ",", "doch", "nur", "mit", "mat\u00b7ter", "Hand", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "Was h\u00e4lf ihr gegen einen Zeugen", "tokens": ["Was", "h\u00e4lf", "ihr", "ge\u00b7gen", "ei\u00b7nen", "Zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "Von dieser Art ein stolzer Widerstand?", "tokens": ["Von", "die\u00b7ser", "Art", "ein", "stol\u00b7zer", "Wi\u00b7der\u00b7stand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.28": {"text": "Es liegt zuviel an seinem Schweigen.", "tokens": ["Es", "liegt", "zu\u00b7viel", "an", "sei\u00b7nem", "Schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.29": {"text": "Der ungeduldige Sylvan", "tokens": ["Der", "un\u00b7ge\u00b7dul\u00b7di\u00b7ge", "Syl\u00b7van"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+---+", "measure": "unknown.measure.tri"}, "line.30": {"text": "An dem schon alle Adern gl\u00fchen,", "tokens": ["An", "dem", "schon", "al\u00b7le", "A\u00b7dern", "gl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.31": {"text": "Verspricht und droht zugleich. Sie sieht ihn sch\u00fcchtern an,", "tokens": ["Ver\u00b7spricht", "und", "droht", "zu\u00b7gleich", ".", "Sie", "sieht", "ihn", "sch\u00fcch\u00b7tern", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "$.", "PPER", "VVFIN", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Err\u00f6tet, staunt, und sucht, was sie nicht hindern kann,", "tokens": ["Er\u00b7r\u00f6\u00b7tet", ",", "staunt", ",", "und", "sucht", ",", "was", "sie", "nicht", "hin\u00b7dern", "kann", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "VVFIN", "$,", "KON", "VVFIN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Zum wenigsten noch aufzuziehen.", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "noch", "auf\u00b7zu\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ADV", "VVINF", "$."], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.34": {"text": "Was soll sie tun? Hier ist die Antwort schwer;", "tokens": ["Was", "soll", "sie", "tun", "?", "Hier", "ist", "die", "Ant\u00b7wort", "schwer", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$.", "ADV", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.35": {"text": "Dem gr\u00f6\u00dfern zu entgehn ein kleiners \u00dcbel leiden?", "tokens": ["Dem", "gr\u00f6\u00b7\u00dfern", "zu", "ent\u00b7gehn", "ein", "klei\u00b7ners", "\u00dc\u00b7bel", "lei\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PTKZU", "VVINF", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Um b\u00f6sen Ruf und \u00c4rgernis zu meiden", "tokens": ["Um", "b\u00f6\u00b7sen", "Ruf", "und", "\u00c4r\u00b7ger\u00b7nis", "zu", "mei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUI", "ADJA", "NN", "KON", "NN", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.37": {"text": "Erlaubt Caramuel wohl mehr.", "tokens": ["Er\u00b7laubt", "Ca\u00b7ra\u00b7mu\u00b7el", "wohl", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.59": {"line.1": {"text": "Ein Umstand ist dabei, der ihr sich zu entschlie\u00dfen", "tokens": ["Ein", "Um\u00b7stand", "ist", "da\u00b7bei", ",", "der", "ihr", "sich", "zu", "ent\u00b7schlie\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PAV", "$,", "PRELS", "PPER", "PRF", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch leichter macht. Ihr graut vor seinem Bart,", "tokens": ["Noch", "leich\u00b7ter", "macht", ".", "Ihr", "graut", "vor", "sei\u00b7nem", "Bart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Dem weiten Maul, den rauhen Ziegenf\u00fc\u00dfen,", "tokens": ["Dem", "wei\u00b7ten", "Maul", ",", "den", "rau\u00b7hen", "Zie\u00b7gen\u00b7f\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Dem H\u00f6rner-Paar, das ihm aus schwarzen Locken starrt.", "tokens": ["Dem", "H\u00f6r\u00b7ner\u00b7Paar", ",", "das", "ihm", "aus", "schwar\u00b7zen", "Lo\u00b7cken", "starrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sie hofft von ihrer Schuld bei so verha\u00dften K\u00fcssen", "tokens": ["Sie", "hofft", "von", "ih\u00b7rer", "Schuld", "bei", "so", "ver\u00b7ha\u00df\u00b7ten", "K\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Zum wenigsten die H\u00e4lfte abzub\u00fc\u00dfen,", "tokens": ["Zum", "we\u00b7nigs\u00b7ten", "die", "H\u00e4lf\u00b7te", "ab\u00b7zu\u00b7b\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "VVFIN", "ART", "NN", "VVIZU", "$,"], "meter": "+----+-+-+-", "measure": "dactylic.init"}, "line.7": {"text": "Und ihrem z\u00e4rtlichen Gewissen", "tokens": ["Und", "ih\u00b7rem", "z\u00e4rt\u00b7li\u00b7chen", "Ge\u00b7wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Scheint keine Z\u00fcchtigung f\u00fcr ihr Vergehn zu hart.", "tokens": ["Scheint", "kei\u00b7ne", "Z\u00fcch\u00b7ti\u00b7gung", "f\u00fcr", "ihr", "Ver\u00b7gehn", "zu", "hart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "APPR", "PPOSAT", "NN", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Der Satyr pre\u00dft; es Hilft kein ekles Str\u00e4uben;", "tokens": ["Der", "Sa\u00b7tyr", "pre\u00dft", ";", "es", "Hilft", "kein", "ek\u00b7les", "Str\u00e4u\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "\u00bbnur gutes Muts, Frau Feen-K\u00f6nigin!", "tokens": ["\u00bb", "nur", "gu\u00b7tes", "Muts", ",", "Frau", "Feen\u00b7K\u00f6\u00b7ni\u00b7gin", "!"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADV", "ADJA", "NN", "$,", "NN", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Was schielt ihr so nach euerm Sch\u00e4fer hin?", "tokens": ["Was", "schielt", "ihr", "so", "nach", "eu\u00b7erm", "Sch\u00e4\u00b7fer", "hin", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Verge\u00dft ihn itzt! wenn ich so glatt nicht bin,", "tokens": ["Ver\u00b7ge\u00dft", "ihn", "itzt", "!", "wenn", "ich", "so", "glatt", "nicht", "bin", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "$.", "KOUS", "PPER", "ADV", "ADJD", "PTKNEG", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "So soll mir doch ein andrer Vorzug bleiben.\u00ab", "tokens": ["So", "soll", "mir", "doch", "ein", "an\u00b7drer", "Vor\u00b7zug", "blei\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Die G\u00f6ttin seufzt, der Waldgott schw\u00f6rt", "tokens": ["Die", "G\u00f6t\u00b7tin", "seufzt", ",", "der", "Wald\u00b7gott", "schw\u00f6rt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(doch nicht beim Styx!) die Sache zu verhehlen;", "tokens": ["(", "doch", "nicht", "beim", "Styx", "!", ")", "die", "Sa\u00b7che", "zu", "ver\u00b7heh\u00b7len", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PTKNEG", "APPRART", "NN", "$.", "$(", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er zeigt sich seines Namens wert,", "tokens": ["Er", "zeigt", "sich", "sei\u00b7nes", "Na\u00b7mens", "wert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und da zuletzt sie mehr zu qu\u00e4len", "tokens": ["Und", "da", "zu\u00b7letzt", "sie", "mehr", "zu", "qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADV", "PPER", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Aurorens Ankunft ihm verwehrt,", "tokens": ["Au\u00b7ro\u00b7rens", "An\u00b7kunft", "ihm", "ver\u00b7wehrt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Bedankt er sich, wie sich's geh\u00f6rt,", "tokens": ["Be\u00b7dankt", "er", "sich", ",", "wie", "sich's", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "$,", "PWAV", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und eilt, sein Gl\u00fcck den Br\u00fcdern zu erz\u00e4hlen.", "tokens": ["Und", "eilt", ",", "sein", "Gl\u00fcck", "den", "Br\u00fc\u00b7dern", "zu", "er\u00b7z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PPOSAT", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}