{"textgrid.poem.38368": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Sommerverk\u00fcndigung", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Hanns Vo\u00df hei\u00dft er,", "tokens": ["Hanns", "Vo\u00df", "hei\u00dft", "er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Schelmst\u00fcck weis er,", "tokens": ["Schelm\u00b7st\u00fcck", "weis", "er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "PPER", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die er nicht weis, die will er lehren,", "tokens": ["Die", "er", "nicht", "weis", ",", "die", "will", "er", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "PTKVZ", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Haus und Hof will er verzehren;", "tokens": ["Haus", "und", "Hof", "will", "er", "ver\u00b7zeh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Brod auf die Trage,", "tokens": ["Brod", "auf", "die", "Tra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Speck auf den Wagen,", "tokens": ["Speck", "auf", "den", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Eier ins Nest,", "tokens": ["Ei\u00b7er", "ins", "Nest", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Wer mir was giebt, der ist der Best!", "tokens": ["Wer", "mir", "was", "giebt", ",", "der", "ist", "der", "Best", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PIS", "VVFIN", "$,", "PRELS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Als ich hier vor diesem war,", "tokens": ["Als", "ich", "hier", "vor", "die\u00b7sem", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PDAT", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War hier nichts als Laub und Gras,", "tokens": ["War", "hier", "nichts", "als", "Laub", "und", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da war auch hier kein reicher Mann,", "tokens": ["Da", "war", "auch", "hier", "kein", "rei\u00b7cher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der uns den Beutel f\u00fcllen kann,", "tokens": ["Der", "uns", "den", "Beu\u00b7tel", "f\u00fcl\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit einem Schilling drei, vier oder mehr", "tokens": ["Mit", "ei\u00b7nem", "Schil\u00b7ling", "drei", ",", "vier", "o\u00b7der", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "CARD", "$,", "CARD", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wenns auch ein halber Thaler w\u00e4r.", "tokens": ["Wenns", "auch", "ein", "hal\u00b7ber", "Tha\u00b7ler", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Droben in der Hausfirst", "tokens": ["Dro\u00b7ben", "in", "der", "Haus\u00b7first"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00e4ngen die langen Mettw\u00fcrst,", "tokens": ["H\u00e4n\u00b7gen", "die", "lan\u00b7gen", "Mett\u00b7w\u00fcrst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Gebt uns von den langen,", "tokens": ["Gebt", "uns", "von", "den", "lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "La\u00dft die kurzen hangen,", "tokens": ["La\u00dft", "die", "kur\u00b7zen", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sind sie etwas kleine,", "tokens": ["Sind", "sie", "et\u00b7was", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Gebt uns zwei f\u00fcr eine;", "tokens": ["Gebt", "uns", "zwei", "f\u00fcr", "ei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "CARD", "APPR", "ART", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Sind sie ein wenig zerbrochen,", "tokens": ["Sind", "sie", "ein", "we\u00b7nig", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "PIS", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "So sind sie leichter kochen,", "tokens": ["So", "sind", "sie", "leich\u00b7ter", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Sind sie etwas fett,", "tokens": ["Sind", "sie", "et\u00b7was", "fett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.10": {"text": "Je besser es uns schmeckt.", "tokens": ["Je", "bes\u00b7ser", "es", "uns", "schmeckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Hanns Vo\u00df hei\u00dft er,", "tokens": ["Hanns", "Vo\u00df", "hei\u00dft", "er", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VVFIN", "PPER", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Schelmst\u00fcck weis er,", "tokens": ["Schelm\u00b7st\u00fcck", "weis", "er", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "PPER", "$,"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Die er nicht weis, die will er lehren,", "tokens": ["Die", "er", "nicht", "weis", ",", "die", "will", "er", "leh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "PTKVZ", "$,", "PDS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Haus und Hof will er verzehren;", "tokens": ["Haus", "und", "Hof", "will", "er", "ver\u00b7zeh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Brod auf die Trage,", "tokens": ["Brod", "auf", "die", "Tra\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Speck auf den Wagen,", "tokens": ["Speck", "auf", "den", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.7": {"text": "Eier ins Nest,", "tokens": ["Ei\u00b7er", "ins", "Nest", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$,"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.8": {"text": "Wer mir was giebt, der ist der Best!", "tokens": ["Wer", "mir", "was", "giebt", ",", "der", "ist", "der", "Best", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "PIS", "VVFIN", "$,", "PRELS", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Als ich hier vor diesem war,", "tokens": ["Als", "ich", "hier", "vor", "die\u00b7sem", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "PDAT", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "War hier nichts als Laub und Gras,", "tokens": ["War", "hier", "nichts", "als", "Laub", "und", "Gras", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIS", "KOKOM", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da war auch hier kein reicher Mann,", "tokens": ["Da", "war", "auch", "hier", "kein", "rei\u00b7cher", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der uns den Beutel f\u00fcllen kann,", "tokens": ["Der", "uns", "den", "Beu\u00b7tel", "f\u00fcl\u00b7len", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit einem Schilling drei, vier oder mehr", "tokens": ["Mit", "ei\u00b7nem", "Schil\u00b7ling", "drei", ",", "vier", "o\u00b7der", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "CARD", "$,", "CARD", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Wenns auch ein halber Thaler w\u00e4r.", "tokens": ["Wenns", "auch", "ein", "hal\u00b7ber", "Tha\u00b7ler", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Droben in der Hausfirst", "tokens": ["Dro\u00b7ben", "in", "der", "Haus\u00b7first"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00e4ngen die langen Mettw\u00fcrst,", "tokens": ["H\u00e4n\u00b7gen", "die", "lan\u00b7gen", "Mett\u00b7w\u00fcrst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Gebt uns von den langen,", "tokens": ["Gebt", "uns", "von", "den", "lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "La\u00dft die kurzen hangen,", "tokens": ["La\u00dft", "die", "kur\u00b7zen", "han\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Sind sie etwas kleine,", "tokens": ["Sind", "sie", "et\u00b7was", "klei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Gebt uns zwei f\u00fcr eine;", "tokens": ["Gebt", "uns", "zwei", "f\u00fcr", "ei\u00b7ne", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "CARD", "APPR", "ART", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Sind sie ein wenig zerbrochen,", "tokens": ["Sind", "sie", "ein", "we\u00b7nig", "zer\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "PIS", "VVPP", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "So sind sie leichter kochen,", "tokens": ["So", "sind", "sie", "leich\u00b7ter", "ko\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Sind sie etwas fett,", "tokens": ["Sind", "sie", "et\u00b7was", "fett", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.10": {"text": "Je besser es uns schmeckt.", "tokens": ["Je", "bes\u00b7ser", "es", "uns", "schmeckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}