{"textgrid.poem.36988": {"metadata": {"author": {"name": "Gla\u00dfbrenner, Adolf", "birth": "N.A.", "death": "N.A."}, "title": "Der Pa\u00df-Rath", "genre": "verse", "period": "N.A.", "pub_year": 1843, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Nachdem die Gr\u00e4fin mir versetzt", "tokens": ["Nach\u00b7dem", "die", "Gr\u00e4\u00b7fin", "mir", "ver\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies hohe Lied vom Passe,", "tokens": ["Dies", "ho\u00b7he", "Lied", "vom", "Pas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sprang sie, den eignen in der Hand,", "tokens": ["Sprang", "sie", ",", "den", "eig\u00b7nen", "in", "der", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinunter auf die Gasse,", "tokens": ["Hin\u00b7un\u00b7ter", "auf", "die", "Gas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und schon nach Zehn Minuten stand", "tokens": ["Und", "schon", "nach", "Zehn", "Mi\u00b7nu\u00b7ten", "stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor mir, und artig und galant \u2013", "tokens": ["Vor", "mir", ",", "und", "ar\u00b7tig", "und", "ga\u00b7lant", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KON", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das ist doch ein verkehrtes Land! \u2013", "tokens": ["Das", "ist", "doch", "ein", "ver\u00b7kehr\u00b7tes", "Land", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Pa\u00df-Rath erster Klasse.", "tokens": ["Ein", "Pa\u00df\u00b7Rath", "ers\u00b7ter", "Klas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Bei weitem Katze mehr als Mensch,", "tokens": ["Bei", "wei\u00b7tem", "Kat\u00b7ze", "mehr", "als", "Mensch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War er doch nicht verwildet,", "tokens": ["War", "er", "doch", "nicht", "ver\u00b7wil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Im Gegentheil: ein Gentleman,", "tokens": ["Im", "Ge\u00b7gen\u00b7theil", ":", "ein", "Gent\u00b7le\u00b7man", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Welt- und Salongebildet.", "tokens": ["Welt", "und", "Sa\u00b7lon\u00b7ge\u00b7bil\u00b7det", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Er knickste dreimal, warf sich auf", "tokens": ["Er", "knicks\u00b7te", "drei\u00b7mal", ",", "warf", "sich", "auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Divan, den bequemen,", "tokens": ["Den", "Di\u00b7van", ",", "den", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Und bat auf einer H\u00fctsche mich", "tokens": ["Und", "bat", "auf", "ei\u00b7ner", "H\u00fct\u00b7sche", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gef\u00e4lligst Platz zu nehmen.", "tokens": ["Ge\u00b7f\u00e4l\u00b7ligst", "Platz", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Dann lie\u00df er gn\u00e4dig sich herab", "tokens": ["Dann", "lie\u00df", "er", "gn\u00e4\u00b7dig", "sich", "her\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gr\u00e4fin zuzuwinken,", "tokens": ["Der", "Gr\u00e4\u00b7fin", "zu\u00b7zu\u00b7win\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df sie ein Fr\u00fchst\u00fcck bringe, a\u00df", "tokens": ["Da\u00df", "sie", "ein", "Fr\u00fch\u00b7st\u00fcck", "brin\u00b7ge", ",", "a\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Viertel Pfaffenschinken,", "tokens": ["Ein", "Vier\u00b7tel", "Pfaf\u00b7fen\u00b7schin\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein delikates Herz-Ragout", "tokens": ["Ein", "de\u00b7li\u00b7ka\u00b7tes", "Her\u00b7zRa\u00b7gout"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Von Adlern und Hy\u00e4nen,", "tokens": ["Von", "Ad\u00b7lern", "und", "Hy\u00b7\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und einen Tr\u00fcffel-Cacadu", "tokens": ["Und", "ei\u00b7nen", "Tr\u00fcf\u00b7fel\u00b7Ca\u00b7ca\u00b7du"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und feines Brod und trank dazu", "tokens": ["Und", "fei\u00b7nes", "Brod", "und", "trank", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "F\u00fcnf Gl\u00e4ser Menschenthr\u00e4nen.", "tokens": ["F\u00fcnf", "Gl\u00e4\u00b7ser", "Men\u00b7schen\u00b7thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Und winkte Lotten wiederum,", "tokens": ["Und", "wink\u00b7te", "Lot\u00b7ten", "wie\u00b7de\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sie mit der Serviette", "tokens": ["Da\u00df", "sie", "mit", "der", "Ser\u00b7viet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Ihm schuldigst s\u00e4ubre Kinn und Mund", "tokens": ["Ihm", "schul\u00b7digst", "s\u00e4u\u00b7bre", "Kinn", "und", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Brust vom Fr\u00fchst\u00fccks-Fette,", "tokens": ["Und", "Brust", "vom", "Fr\u00fch\u00b7st\u00fccks\u00b7Fet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und schnitt ihr ein Gesicht dann, ein", "tokens": ["Und", "schnitt", "ihr", "ein", "Ge\u00b7sicht", "dann", ",", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADV", "$,", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Halb l\u00fcsternes, halb frommes,", "tokens": ["Halb", "l\u00fcs\u00b7ter\u00b7nes", ",", "halb", "from\u00b7mes", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "$,", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als sie, den Bauch ihm klopfend, sprach:", "tokens": ["Als", "sie", ",", "den", "Bauch", "ihm", "klop\u00b7fend", ",", "sprach", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbherr Pa\u00df-Rath, wohl bekomm' es!\u00ab", "tokens": ["\u00bb", "herr", "Pa\u00df\u00b7Rath", ",", "wohl", "be\u00b7komm'", "es", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "NN", "$,", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er steckte ihr aus Dankbarkeit", "tokens": ["Er", "steck\u00b7te", "ihr", "aus", "Dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In's M\u00e4ulchen eine Tr\u00fcffel,", "tokens": ["In's", "M\u00e4ul\u00b7chen", "ei\u00b7ne", "Tr\u00fcf\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ging dann an das Pa\u00dfgesch\u00e4ft,", "tokens": ["Und", "ging", "dann", "an", "das", "Pa\u00df\u00b7ge\u00b7sch\u00e4ft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entwerfend mit dem Griffel", "tokens": ["Ent\u00b7wer\u00b7fend", "mit", "dem", "Grif\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein m\u00e4nnlich Brustbild, das jedoch", "tokens": ["Ein", "m\u00e4nn\u00b7lich", "Brust\u00b7bild", ",", "das", "je\u00b7doch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Borsthaar eine Platte,", "tokens": ["Im", "Bors\u00b7thaar", "ei\u00b7ne", "Plat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und eine Nase stumpf und breit,", "tokens": ["Und", "ei\u00b7ne", "Na\u00b7se", "stumpf", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und statt des Munds ein rundes Loch,", "tokens": ["Und", "statt", "des", "Munds", "ein", "run\u00b7des", "Loch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kurz, nicht die kleinste Aehnlichkeit", "tokens": ["Kurz", ",", "nicht", "die", "kleins\u00b7te", "A\u00b7ehn\u00b7lich\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Mit mir, dem Sch\u00f6nen, hatte.", "tokens": ["Mit", "mir", ",", "dem", "Sch\u00f6\u00b7nen", ",", "hat\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ART", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich wollte, als er mein Portr\u00e4t", "tokens": ["Ich", "woll\u00b7te", ",", "als", "er", "mein", "Por\u00b7tr\u00e4t"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir zeigte, mich erfrechen,", "tokens": ["Mir", "zeig\u00b7te", ",", "mich", "er\u00b7fre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihm, hinsichtlich des Kunstwerths, mein", "tokens": ["Ihm", ",", "hin\u00b7sicht\u00b7lich", "des", "Kunst\u00b7werths", ",", "mein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "ADV", "ART", "NN", "$,", "PPOSAT"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bedenken auszusprechen,", "tokens": ["Be\u00b7den\u00b7ken", "aus\u00b7zu\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch lie\u00df sein strenger, ernster Blick", "tokens": ["Doch", "lie\u00df", "sein", "stren\u00b7ger", ",", "erns\u00b7ter", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein T\u00e4delchen mich wagen,", "tokens": ["Kein", "T\u00e4\u00b7del\u00b7chen", "mich", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ganz bescheid'ne Antwort gab", "tokens": ["Und", "ganz", "be\u00b7schei\u00b7d'\u00b7ne", "Ant\u00b7wort", "gab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich jetzt auf seine Fragen:", "tokens": ["Ich", "jetzt", "auf", "sei\u00b7ne", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ja, vom edelsten!", "tokens": ["Ja", ",", "vom", "e\u00b7dels\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPRART", "ADJA", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Es ruht im Grab mein's!", "tokens": ["Es", "ruht", "im", "Grab", "mein's", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Von der Erde!", "tokens": ["Von", "der", "Er\u00b7de", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Ich hab' kein's!", "tokens": ["Ich", "hab'", "kein's", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Aller!", "tokens": ["Al\u00b7ler", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Witz!", "tokens": ["Witz", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Einen biedern!", "tokens": ["Ei\u00b7nen", "bie\u00b7dern", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Ernst Heiter!", "tokens": ["Ernst", "Hei\u00b7ter", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Herr von Humor und Liedern!", "tokens": ["Herr", "von", "Hu\u00b7mor", "und", "Lie\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Narr unter den Verr\u00fcckten!", "tokens": ["Narr", "un\u00b7ter", "den", "Ver\u00b7r\u00fcck\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ja, treu und brav", "tokens": ["Ja", ",", "treu", "und", "brav"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Im Heer der Unterdr\u00fcckten.", "tokens": ["Im", "Heer", "der", "Un\u00b7ter\u00b7dr\u00fcck\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Ist die Freiheit.", "tokens": ["Ist", "die", "Frei\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "Nur oben in dem Haare!", "tokens": ["Nur", "o\u00b7ben", "in", "dem", "Haa\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Kein's, doch hab' ich Geld!", "tokens": ["Kein's", ",", "doch", "hab'", "ich", "Geld", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "So gegen Vierzig Jahre.", "tokens": ["So", "ge\u00b7gen", "Vier\u00b7zig", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "\u00bbjedwede Antwort\u00ab, sprach er jetzt,", "tokens": ["\u00bb", "jed\u00b7we\u00b7de", "Ant\u00b7wort", "\u00ab", ",", "sprach", "er", "jetzt", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "$(", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Pa\u00df mir \u00fcberreichend", "tokens": ["Den", "Pa\u00df", "mir", "\u00fc\u00b7berr\u00b7ei\u00b7chend"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mit Beamtenw\u00fcrde sich", "tokens": ["Und", "mit", "Be\u00b7am\u00b7ten\u00b7w\u00fcr\u00b7de", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Katzen-Schnautzbart streichend,", "tokens": ["Den", "Kat\u00b7zen\u00b7Schnautz\u00b7bart", "strei\u00b7chend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbjedwede Antwort, welche Ihr", "tokens": ["\u00bb", "jed\u00b7we\u00b7de", "Ant\u00b7wort", ",", "wel\u00b7che", "Ihr"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PIAT", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gegeben, ist Beweis mir,", "tokens": ["Ge\u00b7ge\u00b7ben", ",", "ist", "Be\u00b7weis", "mir", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df Ihr ein dummer Kerl seid, dem,", "tokens": ["Da\u00df", "Ihr", "ein", "dum\u00b7mer", "Kerl", "seid", ",", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$,", "PRELS", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "Wenn er mit allem Flei\u00df hier", "tokens": ["Wenn", "er", "mit", "al\u00b7lem", "Flei\u00df", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIS", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die theuern Steuern zahlt und sich", "tokens": ["Die", "theu\u00b7ern", "Steu\u00b7ern", "zahlt", "und", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Fern h\u00e4lt von allem Denken,", "tokens": ["Fern", "h\u00e4lt", "von", "al\u00b7lem", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Sultan Pampel sicherlich", "tokens": ["Der", "Sul\u00b7tan", "Pam\u00b7pel", "si\u00b7cher\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wird seine Gnade schenken,", "tokens": ["Wird", "sei\u00b7ne", "Gna\u00b7de", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "H\u00f6chstselbst, wie's hier zu Land Gebrauch", "tokens": ["H\u00f6chst\u00b7selbst", ",", "wie's", "hier", "zu", "Land", "Ge\u00b7brauch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Auf Euern vielverzeh'rnden Bauch", "tokens": ["Auf", "Eu\u00b7ern", "viel\u00b7ver\u00b7zeh'rn\u00b7den", "Bauch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein Loblied wird verfassen,", "tokens": ["Ein", "Lob\u00b7lied", "wird", "ver\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Und Euch zuletzt das Tragen auch", "tokens": ["Und", "Euch", "zu\u00b7letzt", "das", "Tra\u00b7gen", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Des Ordens wird erlassen!\u00ab", "tokens": ["Des", "Or\u00b7dens", "wird", "er\u00b7las\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Nachdem f\u00fcr sein Vertrauen ich", "tokens": ["Nach\u00b7dem", "f\u00fcr", "sein", "Ver\u00b7trau\u00b7en", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedankt mich, sprach er weiter:", "tokens": ["Be\u00b7dankt", "mich", ",", "sprach", "er", "wei\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbes ist nun meines Amtes Pflicht,", "tokens": ["\u00bb", "es", "ist", "nun", "mei\u00b7nes", "Am\u00b7tes", "Pflicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Herr Unterthan Ernst Heiter\u00ab \u2013", "tokens": ["Herr", "Un\u00b7ter\u00b7than", "Ernst", "Hei\u00b7ter", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NE", "NN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bei diesen Worten zog er aus", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "zog", "er", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die purpurrothen Handschuh' \u2013", "tokens": ["Die", "pur\u00b7pur\u00b7ro\u00b7then", "Hand\u00b7schuh'", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u00bbeuch hier mit diesem allerdickst-", "tokens": ["\u00bb", "euch", "hier", "mit", "die\u00b7sem", "al\u00b7ler\u00b7dickst"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "APPR", "PDAT", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geflocht'nen Sultans-Kantschu", "tokens": ["Ge\u00b7flocht'\u00b7nen", "Sul\u00b7tans\u00b7Kant\u00b7schu"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "So lange durchzuhau'n bis zwei", "tokens": ["So", "lan\u00b7ge", "durch\u00b7zu\u00b7hau'n", "bis", "zwei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVINF", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Pott Blut von Euch geflossen,", "tokens": ["Pott", "Blut", "von", "Euch", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Die Euch dann werden g\u00fcnstigenfalls,", "tokens": ["Die", "Euch", "dann", "wer\u00b7den", "g\u00fcns\u00b7ti\u00b7gen\u00b7falls", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.12": {"text": "Wenn Ihr nicht schreit, notiret als", "tokens": ["Wenn", "Ihr", "nicht", "schreit", ",", "no\u00b7ti\u00b7ret", "als"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "$,", "VVFIN", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "F\u00fcr's Vaterland vergossen.", "tokens": ["F\u00fcr's", "Va\u00b7ter\u00b7land", "ver\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Dies w\u00e4re, sag' ich, meine Pflicht,", "tokens": ["Dies", "w\u00e4\u00b7re", ",", "sag'", "ich", ",", "mei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch la\u00df' ich mit mir sprechen,", "tokens": ["Doch", "la\u00df'", "ich", "mit", "mir", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mich durch landes\u00fcbliche", "tokens": ["Und", "mich", "durch", "lan\u00b7des\u00b7\u00fcb\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "M\u00fcnzsorten gern bestechen.", "tokens": ["M\u00fcnz\u00b7sor\u00b7ten", "gern", "be\u00b7ste\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gesetzt, Ihr f\u00fchltet ", "tokens": ["Ge\u00b7setzt", ",", "Ihr", "f\u00fchl\u00b7tet"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVPP", "$,", "PPER", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Den Kantschu zu genie\u00dfen,", "tokens": ["Den", "Kant\u00b7schu", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und wolltet Euer Blut ", "tokens": ["Und", "woll\u00b7tet", "Eu\u00b7er", "Blut"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "F\u00fcr's Vaterland vergie\u00dfen:", "tokens": ["F\u00fcr's", "Va\u00b7ter\u00b7land", "ver\u00b7gie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Ganz gut! Drei Pampelsd'ore mir,", "tokens": ["Ganz", "gut", "!", "Drei", "Pam\u00b7pels\u00b7d'\u00b7o\u00b7re", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "CARD", "NN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Sechs meinen Vorgesetzten!", "tokens": ["Sechs", "mei\u00b7nen", "Vor\u00b7ge\u00b7setz\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Bewahre Ego uns, da\u00df wir", "tokens": ["Be\u00b7wah\u00b7re", "E\u00b7go", "uns", ",", "da\u00df", "wir"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NE", "PPER", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Den K\u00f6rper Euch verletzten!", "tokens": ["Den", "K\u00f6r\u00b7per", "Euch", "ver\u00b7letz\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Ja gebt Ihr noch ein Goldst\u00fcck mehr", "tokens": ["Ja", "gebt", "Ihr", "noch", "ein", "Gold\u00b7st\u00fcck", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "F\u00fcr unsern Ober-Mufti her,", "tokens": ["F\u00fcr", "un\u00b7sern", "O\u00b7ber\u00b7Muf\u00b7ti", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So preiset die Bestechung Der", "tokens": ["So", "prei\u00b7set", "die", "Be\u00b7ste\u00b7chung", "Der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und giebt Euch ihretwegen,", "tokens": ["Und", "giebt", "Euch", "ih\u00b7ret\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Falls Euch daran gelegen,", "tokens": ["Falls", "Euch", "da\u00b7ran", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Noch seinen heiligen Segen.\u00ab", "tokens": ["Noch", "sei\u00b7nen", "hei\u00b7li\u00b7gen", "Se\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Da er nach diesen Worten schon", "tokens": ["Da", "er", "nach", "die\u00b7sen", "Wor\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rechte Hand sich netzte,", "tokens": ["Die", "rech\u00b7te", "Hand", "sich", "netz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und in die Amtspflicht-Positur,", "tokens": ["Und", "in", "die", "Amts\u00b7pflicht\u00b7Po\u00b7si\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die drohende, sich setzte,", "tokens": ["Die", "dro\u00b7hen\u00b7de", ",", "sich", "setz\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Auch mein unritterlicher Sinn", "tokens": ["Auch", "mein", "un\u00b7rit\u00b7ter\u00b7li\u00b7cher", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Heil nicht konnte fassen,", "tokens": ["Das", "Heil", "nicht", "konn\u00b7te", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sich so Staatsimpfen, Thadden-Trie-", "tokens": ["Sich", "so", "Staat\u00b7simp\u00b7fen", ",", "Thad\u00b7den\u00b7Trie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PRF", "ADV", "NN", "$,", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Glaff-Gerlachen zu lassen:", "tokens": ["Glaff\u00b7Ger\u00b7la\u00b7chen", "zu", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "So nahm ich Abstand schnell von den", "tokens": ["So", "nahm", "ich", "Ab\u00b7stand", "schnell", "von", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJD", "APPR", "ART"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Kantschuigen Staatsstreichen,", "tokens": ["Kant\u00b7schu\u00b7i\u00b7gen", "Staats\u00b7strei\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Bat Lotten, Neun St\u00fcck Pampelsd'or", "tokens": ["Bat", "Lot\u00b7ten", ",", "Neun", "St\u00fcck", "Pam\u00b7pels\u00b7d'\u00b7or"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "CARD", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Dem Pa\u00df-Rath darzureichen,", "tokens": ["Dem", "Pa\u00df\u00b7Rath", "dar\u00b7zu\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Und schwur dabei dem Ehrenmann", "tokens": ["Und", "schwur", "da\u00b7bei", "dem", "Eh\u00b7ren\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Bei allen G\u00f6ttern, da\u00df mir an", "tokens": ["Bei", "al\u00b7len", "G\u00f6t\u00b7tern", ",", "da\u00df", "mir", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "KOUS", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des Ober-Mufti's Segen", "tokens": ["Des", "O\u00b7ber\u00b7Muf\u00b7ti's", "Se\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Durchaus gar Nichts gelegen.", "tokens": ["Durc\u00b7haus", "gar", "Nichts", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Nachdem die Gr\u00e4fin mir versetzt", "tokens": ["Nach\u00b7dem", "die", "Gr\u00e4\u00b7fin", "mir", "ver\u00b7setzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dies hohe Lied vom Passe,", "tokens": ["Dies", "ho\u00b7he", "Lied", "vom", "Pas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sprang sie, den eignen in der Hand,", "tokens": ["Sprang", "sie", ",", "den", "eig\u00b7nen", "in", "der", "Hand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "ART", "ADJA", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hinunter auf die Gasse,", "tokens": ["Hin\u00b7un\u00b7ter", "auf", "die", "Gas\u00b7se", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und schon nach Zehn Minuten stand", "tokens": ["Und", "schon", "nach", "Zehn", "Mi\u00b7nu\u00b7ten", "stand"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "CARD", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Vor mir, und artig und galant \u2013", "tokens": ["Vor", "mir", ",", "und", "ar\u00b7tig", "und", "ga\u00b7lant", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KON", "ADJD", "KON", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Das ist doch ein verkehrtes Land! \u2013", "tokens": ["Das", "ist", "doch", "ein", "ver\u00b7kehr\u00b7tes", "Land", "!", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Pa\u00df-Rath erster Klasse.", "tokens": ["Ein", "Pa\u00df\u00b7Rath", "ers\u00b7ter", "Klas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Bei weitem Katze mehr als Mensch,", "tokens": ["Bei", "wei\u00b7tem", "Kat\u00b7ze", "mehr", "als", "Mensch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "War er doch nicht verwildet,", "tokens": ["War", "er", "doch", "nicht", "ver\u00b7wil\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Im Gegentheil: ein Gentleman,", "tokens": ["Im", "Ge\u00b7gen\u00b7theil", ":", "ein", "Gent\u00b7le\u00b7man", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$.", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Welt- und Salongebildet.", "tokens": ["Welt", "und", "Sa\u00b7lon\u00b7ge\u00b7bil\u00b7det", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["TRUNC", "KON", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.5": {"text": "Er knickste dreimal, warf sich auf", "tokens": ["Er", "knicks\u00b7te", "drei\u00b7mal", ",", "warf", "sich", "auf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "PRF", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den Divan, den bequemen,", "tokens": ["Den", "Di\u00b7van", ",", "den", "be\u00b7que\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Und bat auf einer H\u00fctsche mich", "tokens": ["Und", "bat", "auf", "ei\u00b7ner", "H\u00fct\u00b7sche", "mich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Gef\u00e4lligst Platz zu nehmen.", "tokens": ["Ge\u00b7f\u00e4l\u00b7ligst", "Platz", "zu", "neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Dann lie\u00df er gn\u00e4dig sich herab", "tokens": ["Dann", "lie\u00df", "er", "gn\u00e4\u00b7dig", "sich", "her\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "PRF", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Gr\u00e4fin zuzuwinken,", "tokens": ["Der", "Gr\u00e4\u00b7fin", "zu\u00b7zu\u00b7win\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df sie ein Fr\u00fchst\u00fcck bringe, a\u00df", "tokens": ["Da\u00df", "sie", "ein", "Fr\u00fch\u00b7st\u00fcck", "brin\u00b7ge", ",", "a\u00df"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Viertel Pfaffenschinken,", "tokens": ["Ein", "Vier\u00b7tel", "Pfaf\u00b7fen\u00b7schin\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein delikates Herz-Ragout", "tokens": ["Ein", "de\u00b7li\u00b7ka\u00b7tes", "Her\u00b7zRa\u00b7gout"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Von Adlern und Hy\u00e4nen,", "tokens": ["Von", "Ad\u00b7lern", "und", "Hy\u00b7\u00e4\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und einen Tr\u00fcffel-Cacadu", "tokens": ["Und", "ei\u00b7nen", "Tr\u00fcf\u00b7fel\u00b7Ca\u00b7ca\u00b7du"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und feines Brod und trank dazu", "tokens": ["Und", "fei\u00b7nes", "Brod", "und", "trank", "da\u00b7zu"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "VVFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "F\u00fcnf Gl\u00e4ser Menschenthr\u00e4nen.", "tokens": ["F\u00fcnf", "Gl\u00e4\u00b7ser", "Men\u00b7schen\u00b7thr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Und winkte Lotten wiederum,", "tokens": ["Und", "wink\u00b7te", "Lot\u00b7ten", "wie\u00b7de\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df sie mit der Serviette", "tokens": ["Da\u00df", "sie", "mit", "der", "Ser\u00b7viet\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.3": {"text": "Ihm schuldigst s\u00e4ubre Kinn und Mund", "tokens": ["Ihm", "schul\u00b7digst", "s\u00e4u\u00b7bre", "Kinn", "und", "Mund"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und Brust vom Fr\u00fchst\u00fccks-Fette,", "tokens": ["Und", "Brust", "vom", "Fr\u00fch\u00b7st\u00fccks\u00b7Fet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Und schnitt ihr ein Gesicht dann, ein", "tokens": ["Und", "schnitt", "ihr", "ein", "Ge\u00b7sicht", "dann", ",", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "ADV", "$,", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Halb l\u00fcsternes, halb frommes,", "tokens": ["Halb", "l\u00fcs\u00b7ter\u00b7nes", ",", "halb", "from\u00b7mes", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJD", "ADJA", "$,", "ADJD", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Als sie, den Bauch ihm klopfend, sprach:", "tokens": ["Als", "sie", ",", "den", "Bauch", "ihm", "klop\u00b7fend", ",", "sprach", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "PPER", "VVPP", "$,", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "\u00bbherr Pa\u00df-Rath, wohl bekomm' es!\u00ab", "tokens": ["\u00bb", "herr", "Pa\u00df\u00b7Rath", ",", "wohl", "be\u00b7komm'", "es", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NN", "NN", "$,", "ADV", "VVFIN", "PPER", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Er steckte ihr aus Dankbarkeit", "tokens": ["Er", "steck\u00b7te", "ihr", "aus", "Dank\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In's M\u00e4ulchen eine Tr\u00fcffel,", "tokens": ["In's", "M\u00e4ul\u00b7chen", "ei\u00b7ne", "Tr\u00fcf\u00b7fel", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und ging dann an das Pa\u00dfgesch\u00e4ft,", "tokens": ["Und", "ging", "dann", "an", "das", "Pa\u00df\u00b7ge\u00b7sch\u00e4ft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Entwerfend mit dem Griffel", "tokens": ["Ent\u00b7wer\u00b7fend", "mit", "dem", "Grif\u00b7fel"], "token_info": ["word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ein m\u00e4nnlich Brustbild, das jedoch", "tokens": ["Ein", "m\u00e4nn\u00b7lich", "Brust\u00b7bild", ",", "das", "je\u00b7doch"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJD", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Borsthaar eine Platte,", "tokens": ["Im", "Bors\u00b7thaar", "ei\u00b7ne", "Plat\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und eine Nase stumpf und breit,", "tokens": ["Und", "ei\u00b7ne", "Na\u00b7se", "stumpf", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und statt des Munds ein rundes Loch,", "tokens": ["Und", "statt", "des", "Munds", "ein", "run\u00b7des", "Loch", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kurz, nicht die kleinste Aehnlichkeit", "tokens": ["Kurz", ",", "nicht", "die", "kleins\u00b7te", "A\u00b7ehn\u00b7lich\u00b7keit"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "PTKNEG", "ART", "ADJA", "NN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "Mit mir, dem Sch\u00f6nen, hatte.", "tokens": ["Mit", "mir", ",", "dem", "Sch\u00f6\u00b7nen", ",", "hat\u00b7te", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "ART", "NN", "$,", "VAFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Ich wollte, als er mein Portr\u00e4t", "tokens": ["Ich", "woll\u00b7te", ",", "als", "er", "mein", "Por\u00b7tr\u00e4t"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "$,", "KOUS", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mir zeigte, mich erfrechen,", "tokens": ["Mir", "zeig\u00b7te", ",", "mich", "er\u00b7fre\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihm, hinsichtlich des Kunstwerths, mein", "tokens": ["Ihm", ",", "hin\u00b7sicht\u00b7lich", "des", "Kunst\u00b7werths", ",", "mein"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word"], "pos": ["PPER", "$,", "ADV", "ART", "NN", "$,", "PPOSAT"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Bedenken auszusprechen,", "tokens": ["Be\u00b7den\u00b7ken", "aus\u00b7zu\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVIZU", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Doch lie\u00df sein strenger, ernster Blick", "tokens": ["Doch", "lie\u00df", "sein", "stren\u00b7ger", ",", "erns\u00b7ter", "Blick"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPOSAT", "ADJA", "$,", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Kein T\u00e4delchen mich wagen,", "tokens": ["Kein", "T\u00e4\u00b7del\u00b7chen", "mich", "wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und ganz bescheid'ne Antwort gab", "tokens": ["Und", "ganz", "be\u00b7schei\u00b7d'\u00b7ne", "Ant\u00b7wort", "gab"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Ich jetzt auf seine Fragen:", "tokens": ["Ich", "jetzt", "auf", "sei\u00b7ne", "Fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ja, vom edelsten!", "tokens": ["Ja", ",", "vom", "e\u00b7dels\u00b7ten", "!"], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["PTKANT", "$,", "APPRART", "ADJA", "$."], "meter": "+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Es ruht im Grab mein's!", "tokens": ["Es", "ruht", "im", "Grab", "mein's", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "NE", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Von der Erde!", "tokens": ["Von", "der", "Er\u00b7de", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.4": {"text": "Ich hab' kein's!", "tokens": ["Ich", "hab'", "kein's", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Aller!", "tokens": ["Al\u00b7ler", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Witz!", "tokens": ["Witz", "!"], "token_info": ["word", "punct"], "pos": ["NN", "$."], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Einen biedern!", "tokens": ["Ei\u00b7nen", "bie\u00b7dern", "!"], "token_info": ["word", "word", "punct"], "pos": ["ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.8": {"text": "Ernst Heiter!", "tokens": ["Ernst", "Hei\u00b7ter", "!"], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.9": {"text": "Herr von Humor und Liedern!", "tokens": ["Herr", "von", "Hu\u00b7mor", "und", "Lie\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "KON", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.10": {"text": "Narr unter den Verr\u00fcckten!", "tokens": ["Narr", "un\u00b7ter", "den", "Ver\u00b7r\u00fcck\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ja, treu und brav", "tokens": ["Ja", ",", "treu", "und", "brav"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PTKANT", "$,", "ADJD", "KON", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.12": {"text": "Im Heer der Unterdr\u00fcckten.", "tokens": ["Im", "Heer", "der", "Un\u00b7ter\u00b7dr\u00fcck\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Ist die Freiheit.", "tokens": ["Ist", "die", "Frei\u00b7heit", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}, "line.14": {"text": "Nur oben in dem Haare!", "tokens": ["Nur", "o\u00b7ben", "in", "dem", "Haa\u00b7re", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.15": {"text": "Kein's, doch hab' ich Geld!", "tokens": ["Kein's", ",", "doch", "hab'", "ich", "Geld", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "$,", "ADV", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.16": {"text": "So gegen Vierzig Jahre.", "tokens": ["So", "ge\u00b7gen", "Vier\u00b7zig", "Jah\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "\u00bbjedwede Antwort\u00ab, sprach er jetzt,", "tokens": ["\u00bb", "jed\u00b7we\u00b7de", "Ant\u00b7wort", "\u00ab", ",", "sprach", "er", "jetzt", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["$(", "PIAT", "NN", "$(", "$,", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Pa\u00df mir \u00fcberreichend", "tokens": ["Den", "Pa\u00df", "mir", "\u00fc\u00b7berr\u00b7ei\u00b7chend"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mit Beamtenw\u00fcrde sich", "tokens": ["Und", "mit", "Be\u00b7am\u00b7ten\u00b7w\u00fcr\u00b7de", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Den Katzen-Schnautzbart streichend,", "tokens": ["Den", "Kat\u00b7zen\u00b7Schnautz\u00b7bart", "strei\u00b7chend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "\u00bbjedwede Antwort, welche Ihr", "tokens": ["\u00bb", "jed\u00b7we\u00b7de", "Ant\u00b7wort", ",", "wel\u00b7che", "Ihr"], "token_info": ["punct", "word", "word", "punct", "word", "word"], "pos": ["$(", "PIAT", "NN", "$,", "PRELS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gegeben, ist Beweis mir,", "tokens": ["Ge\u00b7ge\u00b7ben", ",", "ist", "Be\u00b7weis", "mir", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "VAFIN", "NN", "PPER", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Da\u00df Ihr ein dummer Kerl seid, dem,", "tokens": ["Da\u00df", "Ihr", "ein", "dum\u00b7mer", "Kerl", "seid", ",", "dem", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "VAFIN", "$,", "PRELS", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.8": {"text": "Wenn er mit allem Flei\u00df hier", "tokens": ["Wenn", "er", "mit", "al\u00b7lem", "Flei\u00df", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PIS", "NN", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Die theuern Steuern zahlt und sich", "tokens": ["Die", "theu\u00b7ern", "Steu\u00b7ern", "zahlt", "und", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Fern h\u00e4lt von allem Denken,", "tokens": ["Fern", "h\u00e4lt", "von", "al\u00b7lem", "Den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PIS", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Der Sultan Pampel sicherlich", "tokens": ["Der", "Sul\u00b7tan", "Pam\u00b7pel", "si\u00b7cher\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "NE", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Wird seine Gnade schenken,", "tokens": ["Wird", "sei\u00b7ne", "Gna\u00b7de", "schen\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "H\u00f6chstselbst, wie's hier zu Land Gebrauch", "tokens": ["H\u00f6chst\u00b7selbst", ",", "wie's", "hier", "zu", "Land", "Ge\u00b7brauch"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "VVFIN", "ADV", "APPR", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Auf Euern vielverzeh'rnden Bauch", "tokens": ["Auf", "Eu\u00b7ern", "viel\u00b7ver\u00b7zeh'rn\u00b7den", "Bauch"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Ein Loblied wird verfassen,", "tokens": ["Ein", "Lob\u00b7lied", "wird", "ver\u00b7fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Und Euch zuletzt das Tragen auch", "tokens": ["Und", "Euch", "zu\u00b7letzt", "das", "Tra\u00b7gen", "auch"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Des Ordens wird erlassen!\u00ab", "tokens": ["Des", "Or\u00b7dens", "wird", "er\u00b7las\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Nachdem f\u00fcr sein Vertrauen ich", "tokens": ["Nach\u00b7dem", "f\u00fcr", "sein", "Ver\u00b7trau\u00b7en", "ich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPOSAT", "NN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bedankt mich, sprach er weiter:", "tokens": ["Be\u00b7dankt", "mich", ",", "sprach", "er", "wei\u00b7ter", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbes ist nun meines Amtes Pflicht,", "tokens": ["\u00bb", "es", "ist", "nun", "mei\u00b7nes", "Am\u00b7tes", "Pflicht", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Herr Unterthan Ernst Heiter\u00ab \u2013", "tokens": ["Herr", "Un\u00b7ter\u00b7than", "Ernst", "Hei\u00b7ter", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "NE", "NN", "$(", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Bei diesen Worten zog er aus", "tokens": ["Bei", "die\u00b7sen", "Wor\u00b7ten", "zog", "er", "aus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die purpurrothen Handschuh' \u2013", "tokens": ["Die", "pur\u00b7pur\u00b7ro\u00b7then", "Hand\u00b7schuh'", "\u2013"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "\u00bbeuch hier mit diesem allerdickst-", "tokens": ["\u00bb", "euch", "hier", "mit", "die\u00b7sem", "al\u00b7ler\u00b7dickst"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "ADV", "APPR", "PDAT", "TRUNC"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Geflocht'nen Sultans-Kantschu", "tokens": ["Ge\u00b7flocht'\u00b7nen", "Sul\u00b7tans\u00b7Kant\u00b7schu"], "token_info": ["word", "word"], "pos": ["NN", "NE"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.9": {"text": "So lange durchzuhau'n bis zwei", "tokens": ["So", "lan\u00b7ge", "durch\u00b7zu\u00b7hau'n", "bis", "zwei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVINF", "APPR", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Pott Blut von Euch geflossen,", "tokens": ["Pott", "Blut", "von", "Euch", "ge\u00b7flos\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Die Euch dann werden g\u00fcnstigenfalls,", "tokens": ["Die", "Euch", "dann", "wer\u00b7den", "g\u00fcns\u00b7ti\u00b7gen\u00b7falls", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.12": {"text": "Wenn Ihr nicht schreit, notiret als", "tokens": ["Wenn", "Ihr", "nicht", "schreit", ",", "no\u00b7ti\u00b7ret", "als"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "PTKNEG", "ADJD", "$,", "VVFIN", "KOKOM"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "F\u00fcr's Vaterland vergossen.", "tokens": ["F\u00fcr's", "Va\u00b7ter\u00b7land", "ver\u00b7gos\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Dies w\u00e4re, sag' ich, meine Pflicht,", "tokens": ["Dies", "w\u00e4\u00b7re", ",", "sag'", "ich", ",", "mei\u00b7ne", "Pflicht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "$,", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Doch la\u00df' ich mit mir sprechen,", "tokens": ["Doch", "la\u00df'", "ich", "mit", "mir", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIMP", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und mich durch landes\u00fcbliche", "tokens": ["Und", "mich", "durch", "lan\u00b7des\u00b7\u00fcb\u00b7li\u00b7che"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "APPR", "ADJA"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "M\u00fcnzsorten gern bestechen.", "tokens": ["M\u00fcnz\u00b7sor\u00b7ten", "gern", "be\u00b7ste\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Gesetzt, Ihr f\u00fchltet ", "tokens": ["Ge\u00b7setzt", ",", "Ihr", "f\u00fchl\u00b7tet"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVPP", "$,", "PPER", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Den Kantschu zu genie\u00dfen,", "tokens": ["Den", "Kant\u00b7schu", "zu", "ge\u00b7nie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Und wolltet Euer Blut ", "tokens": ["Und", "woll\u00b7tet", "Eu\u00b7er", "Blut"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.8": {"text": "F\u00fcr's Vaterland vergie\u00dfen:", "tokens": ["F\u00fcr's", "Va\u00b7ter\u00b7land", "ver\u00b7gie\u00b7\u00dfen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "Ganz gut! Drei Pampelsd'ore mir,", "tokens": ["Ganz", "gut", "!", "Drei", "Pam\u00b7pels\u00b7d'\u00b7o\u00b7re", "mir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "CARD", "NN", "PPER", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.10": {"text": "Sechs meinen Vorgesetzten!", "tokens": ["Sechs", "mei\u00b7nen", "Vor\u00b7ge\u00b7setz\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["CARD", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Bewahre Ego uns, da\u00df wir", "tokens": ["Be\u00b7wah\u00b7re", "E\u00b7go", "uns", ",", "da\u00df", "wir"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VVFIN", "NE", "PPER", "$,", "KOUS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Den K\u00f6rper Euch verletzten!", "tokens": ["Den", "K\u00f6r\u00b7per", "Euch", "ver\u00b7letz\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Ja gebt Ihr noch ein Goldst\u00fcck mehr", "tokens": ["Ja", "gebt", "Ihr", "noch", "ein", "Gold\u00b7st\u00fcck", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "VVFIN", "PPER", "ADV", "ART", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "F\u00fcr unsern Ober-Mufti her,", "tokens": ["F\u00fcr", "un\u00b7sern", "O\u00b7ber\u00b7Muf\u00b7ti", "her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "So preiset die Bestechung Der", "tokens": ["So", "prei\u00b7set", "die", "Be\u00b7ste\u00b7chung", "Der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Und giebt Euch ihretwegen,", "tokens": ["Und", "giebt", "Euch", "ih\u00b7ret\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.17": {"text": "Falls Euch daran gelegen,", "tokens": ["Falls", "Euch", "da\u00b7ran", "ge\u00b7le\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.18": {"text": "Noch seinen heiligen Segen.\u00ab", "tokens": ["Noch", "sei\u00b7nen", "hei\u00b7li\u00b7gen", "Se\u00b7gen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Da er nach diesen Worten schon", "tokens": ["Da", "er", "nach", "die\u00b7sen", "Wor\u00b7ten", "schon"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "PDAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die rechte Hand sich netzte,", "tokens": ["Die", "rech\u00b7te", "Hand", "sich", "netz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und in die Amtspflicht-Positur,", "tokens": ["Und", "in", "die", "Amts\u00b7pflicht\u00b7Po\u00b7si\u00b7tur", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die drohende, sich setzte,", "tokens": ["Die", "dro\u00b7hen\u00b7de", ",", "sich", "setz\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Auch mein unritterlicher Sinn", "tokens": ["Auch", "mein", "un\u00b7rit\u00b7ter\u00b7li\u00b7cher", "Sinn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Das Heil nicht konnte fassen,", "tokens": ["Das", "Heil", "nicht", "konn\u00b7te", "fas\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Sich so Staatsimpfen, Thadden-Trie-", "tokens": ["Sich", "so", "Staat\u00b7simp\u00b7fen", ",", "Thad\u00b7den\u00b7Trie"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PRF", "ADV", "NN", "$,", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.8": {"text": "Glaff-Gerlachen zu lassen:", "tokens": ["Glaff\u00b7Ger\u00b7la\u00b7chen", "zu", "las\u00b7sen", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.9": {"text": "So nahm ich Abstand schnell von den", "tokens": ["So", "nahm", "ich", "Ab\u00b7stand", "schnell", "von", "den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "NN", "ADJD", "APPR", "ART"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.10": {"text": "Kantschuigen Staatsstreichen,", "tokens": ["Kant\u00b7schu\u00b7i\u00b7gen", "Staats\u00b7strei\u00b7chen", ","], "token_info": ["word", "word", "punct"], "pos": ["VMFIN", "VVINF", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.11": {"text": "Bat Lotten, Neun St\u00fcck Pampelsd'or", "tokens": ["Bat", "Lot\u00b7ten", ",", "Neun", "St\u00fcck", "Pam\u00b7pels\u00b7d'\u00b7or"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "NN", "$,", "CARD", "NN", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.12": {"text": "Dem Pa\u00df-Rath darzureichen,", "tokens": ["Dem", "Pa\u00df\u00b7Rath", "dar\u00b7zu\u00b7rei\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.13": {"text": "Und schwur dabei dem Ehrenmann", "tokens": ["Und", "schwur", "da\u00b7bei", "dem", "Eh\u00b7ren\u00b7mann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PAV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Bei allen G\u00f6ttern, da\u00df mir an", "tokens": ["Bei", "al\u00b7len", "G\u00f6t\u00b7tern", ",", "da\u00df", "mir", "an"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "KOUS", "PPER", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Des Ober-Mufti's Segen", "tokens": ["Des", "O\u00b7ber\u00b7Muf\u00b7ti's", "Se\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.16": {"text": "Durchaus gar Nichts gelegen.", "tokens": ["Durc\u00b7haus", "gar", "Nichts", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}