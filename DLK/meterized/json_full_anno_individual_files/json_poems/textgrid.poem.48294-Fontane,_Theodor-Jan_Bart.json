{"textgrid.poem.48294": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Jan Bart", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Jan Bart geht \u00fcber den Vlissinger Damm.", "tokens": ["Jan", "Bart", "geht", "\u00fc\u00b7ber", "den", "Vlis\u00b7sin\u00b7ger", "Damm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u00bbh\u00fcr', Katrin, wi trecken tosamm;", "tokens": ["\u00bb", "h\u00fcr'", ",", "Kat\u00b7rin", ",", "wi", "tre\u00b7cken", "to\u00b7samm", ";"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PWAV", "VVFIN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "En Huus, en Boot, 'ne Zieg' un 'ne Kuh,", "tokens": ["En", "Huus", ",", "en", "Boot", ",", "'", "ne", "Zieg", "'", "un", "'ne", "Kuh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,", "$(", "NE", "NE", "$(", "FM", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wat mienst, Katrin? Sy miene Fru.\u00ab", "tokens": ["Wat", "mienst", ",", "Kat\u00b7rin", "?", "Sy", "mie\u00b7ne", "Fru", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "$,", "NN", "$.", "NE", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.2": {"line.1": {"text": "Katrin an ihrem Friesrock zog:", "tokens": ["Kat\u00b7rin", "an", "ih\u00b7rem", "Fries\u00b7rock", "zog", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbne, Jan, bist mi nich Mynherr 'noog.\u00ab", "tokens": ["\u00bb", "ne", ",", "Jan", ",", "bist", "mi", "nich", "Myn\u00b7herr", "'n\u00b7oog", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "NE", "$,", "VAFIN", "NE", "PTKNEG", "NN", "VVFIN", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Der nickt und lacht: \u00bbNa, denn Adje.\u00ab", "tokens": ["Der", "nickt", "und", "lacht", ":", "\u00bb", "Na", ",", "denn", "Ad\u00b7je", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "ITJ", "$,", "KON", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nach Frankreich geht er und sticht in See.", "tokens": ["Und", "nach", "Fran\u00b7kreich", "geht", "er", "und", "sticht", "in", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-----+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Matrose, Maat, so f\u00e4ngt er an,", "tokens": ["Mat\u00b7ro\u00b7se", ",", "Maat", ",", "so", "f\u00e4ngt", "er", "an", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf der zweiten Reise: Steuermann,", "tokens": ["Auf", "der", "zwei\u00b7ten", "Rei\u00b7se", ":", "Steu\u00b7er\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Auf der dritten: Leutnant unter Du Quesne,", "tokens": ["Auf", "der", "drit\u00b7ten", ":", "Leut\u00b7nant", "un\u00b7ter", "Du", "Ques\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "APPR", "PPER", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf der vierten: Flottenkapit\u00e4n.", "tokens": ["Auf", "der", "vier\u00b7ten", ":", "Flot\u00b7ten\u00b7ka\u00b7pi\u00b7t\u00e4n", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.4": {"line.1": {"text": "Und als es mit England kommt zum Krieg,", "tokens": ["Und", "als", "es", "mit", "En\u00b7gland", "kommt", "zum", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wo Jan Bart erscheint, erscheint der Sieg,", "tokens": ["Wo", "Jan", "Bart", "er\u00b7scheint", ",", "er\u00b7scheint", "der", "Sieg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Wie stolz das britische Banner auch weh',", "tokens": ["Wie", "stolz", "das", "bri\u00b7ti\u00b7sche", "Ban\u00b7ner", "auch", "weh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jan Bart ist Herr und fegt die See.", "tokens": ["Jan", "Bart", "ist", "Herr", "und", "fegt", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Heut aber tritt er vor seinen Herrn,", "tokens": ["Heut", "a\u00b7ber", "tritt", "er", "vor", "sei\u00b7nen", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor Louis quatorze. Der sieht ihn gern.", "tokens": ["Vor", "Lou\u00b7is", "qua\u00b7tor\u00b7ze", ".", "Der", "sieht", "ihn", "gern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "$.", "ART", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwillkommen, Jan Bart, in diesem Saal,", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", ",", "Jan", "Bart", ",", "in", "die\u00b7sem", "Saal", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NE", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich ernenn' Euch zu meinem Gro\u00df-Admiral.\u00ab", "tokens": ["Ich", "er\u00b7nenn'", "Euch", "zu", "mei\u00b7nem", "Gro\u00df\u00b7Ad\u00b7mi\u00b7ral", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Jan Bart verneigt sich: \u00bbMajest\u00e4t,", "tokens": ["Jan", "Bart", "ver\u00b7neigt", "sich", ":", "\u00bb", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PRF", "$.", "$(", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was klug und recht ist, kommt nie zu sp\u00e4t.\u00ab", "tokens": ["Was", "klug", "und", "recht", "ist", ",", "kommt", "nie", "zu", "sp\u00e4t", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Alles starrt auf den K\u00f6nig, der aber lacht \u2013", "tokens": ["Al\u00b7les", "starrt", "auf", "den", "K\u00f6\u00b7nig", ",", "der", "a\u00b7ber", "lacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Jan Bart hat sich wieder heim gemacht.", "tokens": ["Jan", "Bart", "hat", "sich", "wie\u00b7der", "heim", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "PRF", "ADV", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.7": {"line.1": {"text": "Und am Vlissinger Damm, an alter Stell',", "tokens": ["Und", "am", "Vlis\u00b7sin\u00b7ger", "Damm", ",", "an", "al\u00b7ter", "Stell'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sitzt wieder Katrin auf ihrer Schwell',", "tokens": ["Sitzt", "wie\u00b7der", "Kat\u00b7rin", "auf", "ih\u00b7rer", "Schwell'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ihren \u00c4ltsten h\u00e4lt sie bei der Hand,", "tokens": ["Ih\u00b7ren", "\u00c4lts\u00b7ten", "h\u00e4lt", "sie", "bei", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Der J\u00fcngste liegt und spielt im Sand.", "tokens": ["Der", "J\u00fcngs\u00b7te", "liegt", "und", "spielt", "im", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Er gr\u00fc\u00dft sie lachend und noch einmal:", "tokens": ["Er", "gr\u00fc\u00dft", "sie", "la\u00b7chend", "und", "noch", "ein\u00b7mal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADV", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbkatrin, ich bin nu Gro\u00df-Admiral,", "tokens": ["\u00bb", "kat\u00b7rin", ",", "ich", "bin", "nu", "Gro\u00df\u00b7Ad\u00b7mi\u00b7ral", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Katrin, w'r\u00fcm biste nich mit mi goahn?\u00ab", "tokens": ["Kat\u00b7rin", ",", "w'\u00b7r\u00fcm", "bis\u00b7te", "nich", "mit", "mi", "go\u00b7ahn", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "\u00bbjoa, wenn ick't ", "tokens": ["\u00bb", "joa", ",", "wenn", "ick't"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "PTKANT", "$,", "KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.9": {"line.1": {"text": "Jan Bart geht \u00fcber den Vlissinger Damm.", "tokens": ["Jan", "Bart", "geht", "\u00fc\u00b7ber", "den", "Vlis\u00b7sin\u00b7ger", "Damm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "\u00bbh\u00fcr', Katrin, wi trecken tosamm;", "tokens": ["\u00bb", "h\u00fcr'", ",", "Kat\u00b7rin", ",", "wi", "tre\u00b7cken", "to\u00b7samm", ";"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$,", "NN", "$,", "PWAV", "VVFIN", "ADJD", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "En Huus, en Boot, 'ne Zieg' un 'ne Kuh,", "tokens": ["En", "Huus", ",", "en", "Boot", ",", "'", "ne", "Zieg", "'", "un", "'ne", "Kuh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "ADJA", "NN", "$,", "$(", "NE", "NE", "$(", "FM", "ART", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.4": {"text": "Wat mienst, Katrin? Sy miene Fru.\u00ab", "tokens": ["Wat", "mienst", ",", "Kat\u00b7rin", "?", "Sy", "mie\u00b7ne", "Fru", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["FM.la", "FM.la", "$,", "NN", "$.", "NE", "ADJA", "NN", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Katrin an ihrem Friesrock zog:", "tokens": ["Kat\u00b7rin", "an", "ih\u00b7rem", "Fries\u00b7rock", "zog", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbne, Jan, bist mi nich Mynherr 'noog.\u00ab", "tokens": ["\u00bb", "ne", ",", "Jan", ",", "bist", "mi", "nich", "Myn\u00b7herr", "'n\u00b7oog", ".", "\u00ab"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "NE", "$,", "NE", "$,", "VAFIN", "NE", "PTKNEG", "NN", "VVFIN", "$.", "$("], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Der nickt und lacht: \u00bbNa, denn Adje.\u00ab", "tokens": ["Der", "nickt", "und", "lacht", ":", "\u00bb", "Na", ",", "denn", "Ad\u00b7je", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "$.", "$(", "ITJ", "$,", "KON", "NE", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und nach Frankreich geht er und sticht in See.", "tokens": ["Und", "nach", "Fran\u00b7kreich", "geht", "er", "und", "sticht", "in", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NE", "VVFIN", "PPER", "KON", "VVFIN", "APPR", "NN", "$."], "meter": "-+-----+-+", "measure": "dactylic.init"}}, "stanza.11": {"line.1": {"text": "Matrose, Maat, so f\u00e4ngt er an,", "tokens": ["Mat\u00b7ro\u00b7se", ",", "Maat", ",", "so", "f\u00e4ngt", "er", "an", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auf der zweiten Reise: Steuermann,", "tokens": ["Auf", "der", "zwei\u00b7ten", "Rei\u00b7se", ":", "Steu\u00b7er\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$.", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Auf der dritten: Leutnant unter Du Quesne,", "tokens": ["Auf", "der", "drit\u00b7ten", ":", "Leut\u00b7nant", "un\u00b7ter", "Du", "Ques\u00b7ne", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "APPR", "PPER", "NN", "$,"], "meter": "--+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Auf der vierten: Flottenkapit\u00e4n.", "tokens": ["Auf", "der", "vier\u00b7ten", ":", "Flot\u00b7ten\u00b7ka\u00b7pi\u00b7t\u00e4n", "."], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$.", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.12": {"line.1": {"text": "Und als es mit England kommt zum Krieg,", "tokens": ["Und", "als", "es", "mit", "En\u00b7gland", "kommt", "zum", "Krieg", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "NE", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wo Jan Bart erscheint, erscheint der Sieg,", "tokens": ["Wo", "Jan", "Bart", "er\u00b7scheint", ",", "er\u00b7scheint", "der", "Sieg", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "NN", "VVFIN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Wie stolz das britische Banner auch weh',", "tokens": ["Wie", "stolz", "das", "bri\u00b7ti\u00b7sche", "Ban\u00b7ner", "auch", "weh'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "ADJA", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Jan Bart ist Herr und fegt die See.", "tokens": ["Jan", "Bart", "ist", "Herr", "und", "fegt", "die", "See", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "NN", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Heut aber tritt er vor seinen Herrn,", "tokens": ["Heut", "a\u00b7ber", "tritt", "er", "vor", "sei\u00b7nen", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Vor Louis quatorze. Der sieht ihn gern.", "tokens": ["Vor", "Lou\u00b7is", "qua\u00b7tor\u00b7ze", ".", "Der", "sieht", "ihn", "gern", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "$.", "ART", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "\u00bbwillkommen, Jan Bart, in diesem Saal,", "tokens": ["\u00bb", "will\u00b7kom\u00b7men", ",", "Jan", "Bart", ",", "in", "die\u00b7sem", "Saal", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "NE", "NN", "$,", "APPR", "PDAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ich ernenn' Euch zu meinem Gro\u00df-Admiral.\u00ab", "tokens": ["Ich", "er\u00b7nenn'", "Euch", "zu", "mei\u00b7nem", "Gro\u00df\u00b7Ad\u00b7mi\u00b7ral", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.14": {"line.1": {"text": "Jan Bart verneigt sich: \u00bbMajest\u00e4t,", "tokens": ["Jan", "Bart", "ver\u00b7neigt", "sich", ":", "\u00bb", "Ma\u00b7jes\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["NE", "NN", "VVFIN", "PRF", "$.", "$(", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Was klug und recht ist, kommt nie zu sp\u00e4t.\u00ab", "tokens": ["Was", "klug", "und", "recht", "ist", ",", "kommt", "nie", "zu", "sp\u00e4t", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "ADJD", "KON", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "PTKA", "ADJD", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Alles starrt auf den K\u00f6nig, der aber lacht \u2013", "tokens": ["Al\u00b7les", "starrt", "auf", "den", "K\u00f6\u00b7nig", ",", "der", "a\u00b7ber", "lacht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$("], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "Jan Bart hat sich wieder heim gemacht.", "tokens": ["Jan", "Bart", "hat", "sich", "wie\u00b7der", "heim", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "VAFIN", "PRF", "ADV", "PTKVZ", "VVPP", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.15": {"line.1": {"text": "Und am Vlissinger Damm, an alter Stell',", "tokens": ["Und", "am", "Vlis\u00b7sin\u00b7ger", "Damm", ",", "an", "al\u00b7ter", "Stell'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "ADJA", "NN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sitzt wieder Katrin auf ihrer Schwell',", "tokens": ["Sitzt", "wie\u00b7der", "Kat\u00b7rin", "auf", "ih\u00b7rer", "Schwell'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.3": {"text": "Ihren \u00c4ltsten h\u00e4lt sie bei der Hand,", "tokens": ["Ih\u00b7ren", "\u00c4lts\u00b7ten", "h\u00e4lt", "sie", "bei", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.4": {"text": "Der J\u00fcngste liegt und spielt im Sand.", "tokens": ["Der", "J\u00fcngs\u00b7te", "liegt", "und", "spielt", "im", "Sand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Er gr\u00fc\u00dft sie lachend und noch einmal:", "tokens": ["Er", "gr\u00fc\u00dft", "sie", "la\u00b7chend", "und", "noch", "ein\u00b7mal", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADJD", "KON", "ADV", "ADV", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbkatrin, ich bin nu Gro\u00df-Admiral,", "tokens": ["\u00bb", "kat\u00b7rin", ",", "ich", "bin", "nu", "Gro\u00df\u00b7Ad\u00b7mi\u00b7ral", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "PTKVZ", "$,", "PPER", "VAFIN", "ADV", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Katrin, w'r\u00fcm biste nich mit mi goahn?\u00ab", "tokens": ["Kat\u00b7rin", ",", "w'\u00b7r\u00fcm", "bis\u00b7te", "nich", "mit", "mi", "go\u00b7ahn", "?", "\u00ab"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "FM.la", "$.", "$("], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.4": {"text": "\u00bbjoa, wenn ick't ", "tokens": ["\u00bb", "joa", ",", "wenn", "ick't"], "token_info": ["punct", "word", "punct", "word", "word"], "pos": ["$(", "PTKANT", "$,", "KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}}}}}