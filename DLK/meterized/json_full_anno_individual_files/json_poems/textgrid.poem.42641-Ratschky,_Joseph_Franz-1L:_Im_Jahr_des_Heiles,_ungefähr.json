{"textgrid.poem.42641": {"metadata": {"author": {"name": "Ratschky, Joseph Franz", "birth": "N.A.", "death": "N.A."}, "title": "1L: Im Jahr des Heiles, ungef\u00e4hr", "genre": "verse", "period": "N.A.", "pub_year": 1783, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Im Jahr des Heiles, ungef\u00e4hr", "tokens": ["Im", "Jahr", "des", "Hei\u00b7les", ",", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Achthundert F\u00fcnf und Neunzig,", "tokens": ["Acht\u00b7hun\u00b7dert", "F\u00fcnf", "und", "Neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "KON", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Griff K\u00f6nig Arnulph zum Gewehr:", "tokens": ["Griff", "K\u00f6\u00b7nig", "Ar\u00b7nulph", "zum", "Ge\u00b7wehr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es folgt' ihm nur ein kleines Heer,", "tokens": ["Es", "folgt'", "ihm", "nur", "ein", "klei\u00b7nes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch an Bravur war's einzig.", "tokens": ["Doch", "an", "Bra\u00b7vur", "wa\u00b7r's", "ein\u00b7zig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Fern, sprach er, in der R\u00f6mer Land", "tokens": ["Fern", ",", "sprach", "er", ",", "in", "der", "R\u00f6\u00b7mer", "Land"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Meuterey entstanden:", "tokens": ["Ist", "Meu\u00b7te\u00b7rey", "ent\u00b7stan\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf, Kinder! lasst, in's Kriegsgewand", "tokens": ["Auf", ",", "Kin\u00b7der", "!", "lasst", ",", "in's", "Kriegs\u00b7ge\u00b7wand"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "$,", "NN", "$.", "VVFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00fcllt, uns mit bewehrter Hand,", "tokens": ["Ge\u00b7h\u00fcllt", ",", "uns", "mit", "be\u00b7wehr\u00b7ter", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Walt's Gott! den Unfug ahnden!", "tokens": ["Walt's", "Gott", "!", "den", "Un\u00b7fug", "ahn\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Diess Aufgebot war Gross und Klein", "tokens": ["Diess", "Auf\u00b7ge\u00b7bot", "war", "Gross", "und", "Klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar lieblich zu vernehmen.", "tokens": ["Gar", "lieb\u00b7lich", "zu", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dortorts, rief man, w\u00e4chst s\u00fcsser Wein:", "tokens": ["Dor\u00b7torts", ",", "rief", "man", ",", "w\u00e4chst", "s\u00fcs\u00b7ser", "Wein", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Kommt, lasst uns guter Dinge seyn!", "tokens": ["Kommt", ",", "lasst", "uns", "gu\u00b7ter", "Din\u00b7ge", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den wollen wir schon z\u00e4hmen.", "tokens": ["Den", "wol\u00b7len", "wir", "schon", "z\u00e4h\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Nun f\u00f6rdert Arnulph sich, zu ziehn", "tokens": ["Nun", "f\u00f6r\u00b7dert", "Ar\u00b7nulph", "sich", ",", "zu", "ziehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "PRF", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl gegen W\u00e4lschlands Gr\u00e4nzen.", "tokens": ["Wohl", "ge\u00b7gen", "W\u00e4l\u00b7schlands", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Schon k\u00f6mmt er bis nach Florenz hin,", "tokens": ["Schon", "k\u00f6mmt", "er", "bis", "nach", "Flo\u00b7renz", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und allerw\u00e4rts empf\u00e4ngt man ihn", "tokens": ["Und", "al\u00b7ler\u00b7w\u00e4rts", "emp\u00b7f\u00e4ngt", "man", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit tausend Reverenzen.", "tokens": ["Mit", "tau\u00b7send", "Re\u00b7ve\u00b7ren\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Nur bey den stolzen R\u00f6mern war", "tokens": ["Nur", "bey", "den", "stol\u00b7zen", "R\u00f6\u00b7mern", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm Th\u00fcr' und Thor verriegelt.", "tokens": ["Ihm", "Th\u00fcr'", "und", "Thor", "ver\u00b7rie\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie aufzubieten, sandt' er zwar", "tokens": ["Sie", "auf\u00b7zu\u00b7bie\u00b7ten", ",", "sandt'", "er", "zwar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zween Boten: doch das gute Paar", "tokens": ["Zween", "Bo\u00b7ten", ":", "doch", "das", "gu\u00b7te", "Paar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ward schimpflich fortgepr\u00fcgelt.", "tokens": ["Ward", "schimpf\u00b7lich", "fort\u00b7ge\u00b7pr\u00fc\u00b7gelt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Erbosst rief Arnulph: \u00bbHabt ihr so", "tokens": ["Er\u00b7bosst", "rief", "Ar\u00b7nulph", ":", "\u00bb", "Habt", "ihr", "so"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "$.", "$(", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das V\u00f6lkerrecht in Ehren?", "tokens": ["Das", "V\u00f6l\u00b7ker\u00b7recht", "in", "Eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Lotterbuben! lichterloh", "tokens": ["Ihr", "Lot\u00b7ter\u00b7bu\u00b7ben", "!", "lich\u00b7ter\u00b7loh"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll eure Stadt mir flammen! ... O!", "tokens": ["Soll", "eu\u00b7re", "Stadt", "mir", "flam\u00b7men", "!", "...", "O", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$.", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will euch ", "tokens": ["Ich", "will", "euch"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.7": {"line.1": {"text": "Auf, Br\u00fcder! z\u00e4hmet das Geschmeiss!", "tokens": ["Auf", ",", "Br\u00fc\u00b7der", "!", "z\u00e4h\u00b7met", "das", "Ge\u00b7schmeiss", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lasst uns die Stadt berennen!\u00ab", "tokens": ["Lasst", "uns", "die", "Stadt", "be\u00b7ren\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Potz Blitz! nun ward den R\u00f6mern heiss:", "tokens": ["Potz", "Blitz", "!", "nun", "ward", "den", "R\u00f6\u00b7mern", "heiss", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Stadtrath sprang, als ob der Steiss", "tokens": ["Der", "Stad\u00b7trath", "sprang", ",", "als", "ob", "der", "Steiss"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOKOM", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon anfieng' ihm zu brennen.", "tokens": ["Schon", "an\u00b7fieng'", "ihm", "zu", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "F\u00fcr diessmal galt wohl auch f\u00fcrwahr", "tokens": ["F\u00fcr", "diess\u00b7mal", "galt", "wohl", "auch", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Zaudern und Besinnen;", "tokens": ["Kein", "Zau\u00b7dern", "und", "Be\u00b7sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn sieh! der Deutschen wilde Schaar", "tokens": ["Denn", "sieh", "!", "der", "Deut\u00b7schen", "wil\u00b7de", "Schaar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sucht schon, trotz jeglicher Gefahr", "tokens": ["Sucht", "schon", ",", "trotz", "jeg\u00b7li\u00b7cher", "Ge\u00b7fahr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Die W\u00e4lle zu gewinnen.", "tokens": ["Die", "W\u00e4l\u00b7le", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Wohl sieben Stunden k\u00e4mpfte man", "tokens": ["Wohl", "sie\u00b7ben", "Stun\u00b7den", "k\u00e4mpf\u00b7te", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So derb von beyden Seiten,", "tokens": ["So", "derb", "von", "bey\u00b7den", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dass ringsum Blut wie Wasser rann,", "tokens": ["Dass", "ring\u00b7sum", "Blut", "wie", "Was\u00b7ser", "rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis allgemach die Nacht begann", "tokens": ["Bis", "all\u00b7ge\u00b7mach", "die", "Nacht", "be\u00b7gann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Schleyer auszubreiten.", "tokens": ["Den", "Schle\u00b7yer", "aus\u00b7zu\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Gen\u00f6thigt wendeten nunmehr", "tokens": ["Ge\u00b7n\u00f6t\u00b7higt", "wen\u00b7de\u00b7ten", "nun\u00b7mehr"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Deutschen die Standarten,", "tokens": ["Die", "Deut\u00b7schen", "die", "Stand\u00b7ar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Arnulph, sinnend hin und her,", "tokens": ["Und", "Ar\u00b7nulph", ",", "sin\u00b7nend", "hin", "und", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beschloss, ein gl\u00fccklich Ungef\u00e4hr", "tokens": ["Be\u00b7schloss", ",", "ein", "gl\u00fcck\u00b7lich", "Un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im Lager abzuwarten.", "tokens": ["Im", "La\u00b7ger", "ab\u00b7zu\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Rom, das den Feind schon f\u00fcr verzagt", "tokens": ["Rom", ",", "das", "den", "Feind", "schon", "f\u00fcr", "ver\u00b7zagt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "ADV", "APPR", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und muthlos hielt, verlachte", "tokens": ["Und", "muth\u00b7los", "hielt", ",", "ver\u00b7lach\u00b7te"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ADJD", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des K\u00f6nigs Heer, bis eine Jagd", "tokens": ["Des", "K\u00f6\u00b7nigs", "Heer", ",", "bis", "ei\u00b7ne", "Jagd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Urpl\u00f6tzlich, wie die Chronik sagt,", "tokens": ["Ur\u00b7pl\u00f6tz\u00b7lich", ",", "wie", "die", "Chro\u00b7nik", "sagt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Spott ein Ende machte.", "tokens": ["Dem", "Spott", "ein", "En\u00b7de", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ein Rammler aus dem nahen Hain", "tokens": ["Ein", "Ramm\u00b7ler", "aus", "dem", "na\u00b7hen", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprang sch\u00fcchtern vor den W\u00e4llen", "tokens": ["Sprang", "sch\u00fcch\u00b7tern", "vor", "den", "W\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Stadt umher, und hinterdrein", "tokens": ["Der", "Stadt", "um\u00b7her", ",", "und", "hin\u00b7ter\u00b7drein"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Sp\u00fcrhund und mit derbem Schreyn", "tokens": ["Ein", "Sp\u00fcr\u00b7hund", "und", "mit", "der\u00b7bem", "Schreyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Ein Schwarm von Weidgesellen.", "tokens": ["Ein", "Schwarm", "von", "Weid\u00b7ge\u00b7sel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Halb Rom, vom heftigen Rumor", "tokens": ["Halb", "Rom", ",", "vom", "hef\u00b7ti\u00b7gen", "Ru\u00b7mor"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Jagenden betroffen,", "tokens": ["Der", "Ja\u00b7gen\u00b7den", "be\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Lief, ohne Hut und Roquelaur,", "tokens": ["Lief", ",", "oh\u00b7ne", "Hut", "und", "Ro\u00b7que\u00b7laur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ripsraps beym Tempel aus, und Thor", "tokens": ["Rips\u00b7raps", "beym", "Tem\u00b7pel", "aus", ",", "und", "Thor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "APPRART", "NN", "PTKVZ", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Angel blieben offen.", "tokens": ["Und", "An\u00b7gel", "blie\u00b7ben", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Der K\u00f6nig sah am Horst hinab", "tokens": ["Der", "K\u00f6\u00b7nig", "sah", "am", "Horst", "hin\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Fl\u00fcchtigen Gedr\u00e4nge,", "tokens": ["Der", "Fl\u00fcch\u00b7ti\u00b7gen", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Halt! rief er, lasst vom Hasen ab!", "tokens": ["Halt", "!", "rief", "er", ",", "lasst", "vom", "Ha\u00b7sen", "ab", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "VVFIN", "PPER", "$,", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was soll euch Einer? dort bergab,", "tokens": ["Was", "soll", "euch", "Ei\u00b7ner", "?", "dort", "berg\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PIS", "$.", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dort kriegt ihr eine Menge.", "tokens": ["Dort", "kriegt", "ihr", "ei\u00b7ne", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Nun gieng's aus einem andern Ton.", "tokens": ["Nun", "gieng's", "aus", "ei\u00b7nem", "an\u00b7dern", "Ton", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seht! spornstreichs galoppiren", "tokens": ["Seht", "!", "sporn\u00b7streichs", "ga\u00b7lop\u00b7pi\u00b7ren"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "NE", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die J\u00e4ger nach: doch ferne schon", "tokens": ["Die", "J\u00e4\u00b7ger", "nach", ":", "doch", "fer\u00b7ne", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00f6rt man die Memmen um Pardon", "tokens": ["H\u00f6rt", "man", "die", "Mem\u00b7men", "um", "Par\u00b7don"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "NN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Gnade lamentiren.", "tokens": ["Und", "Gna\u00b7de", "la\u00b7men\u00b7ti\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Bewegt ward Arnulph, frank und frey", "tokens": ["Be\u00b7wegt", "ward", "Ar\u00b7nulph", ",", "frank", "und", "frey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "NE", "$,", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie alle heimzuschicken:", "tokens": ["Sie", "al\u00b7le", "heim\u00b7zu\u00b7schi\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch liess er, Rom zu Schimpf und Scheu,", "tokens": ["Doch", "liess", "er", ",", "Rom", "zu", "Schimpf", "und", "Scheu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "NE", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von F\u00fcnfzigen je Zwey und Zwey", "tokens": ["Von", "F\u00fcnf\u00b7zi\u00b7gen", "je", "Zwey", "und", "Zwey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "CARD", "KON", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Hasenschw\u00e4nzen schm\u00fccken,", "tokens": ["Mit", "Ha\u00b7sen\u00b7schw\u00e4n\u00b7zen", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Wenn solche Ordenszeichen heut", "tokens": ["Wenn", "sol\u00b7che", "Or\u00b7dens\u00b7zei\u00b7chen", "heut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Tag noch Sitte w\u00e4ren,", "tokens": ["Zu", "Tag", "noch", "Sit\u00b7te", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00fcrd' auch wohl zu unsrer Zeit", "tokens": ["So", "w\u00fcrd'", "auch", "wohl", "zu", "uns\u00b7rer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Manch liebes S\u00f6hnchen aus dem Streit", "tokens": ["Manch", "lie\u00b7bes", "S\u00f6hn\u00b7chen", "aus", "dem", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit nach Hause kehren.", "tokens": ["Da\u00b7mit", "nach", "Hau\u00b7se", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Im Jahr des Heiles, ungef\u00e4hr", "tokens": ["Im", "Jahr", "des", "Hei\u00b7les", ",", "un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["APPRART", "NN", "ART", "NN", "$,", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Achthundert F\u00fcnf und Neunzig,", "tokens": ["Acht\u00b7hun\u00b7dert", "F\u00fcnf", "und", "Neun\u00b7zig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "CARD", "KON", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Griff K\u00f6nig Arnulph zum Gewehr:", "tokens": ["Griff", "K\u00f6\u00b7nig", "Ar\u00b7nulph", "zum", "Ge\u00b7wehr", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "NE", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Es folgt' ihm nur ein kleines Heer,", "tokens": ["Es", "folgt'", "ihm", "nur", "ein", "klei\u00b7nes", "Heer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch an Bravur war's einzig.", "tokens": ["Doch", "an", "Bra\u00b7vur", "wa\u00b7r's", "ein\u00b7zig", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VAFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Fern, sprach er, in der R\u00f6mer Land", "tokens": ["Fern", ",", "sprach", "er", ",", "in", "der", "R\u00f6\u00b7mer", "Land"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "PPER", "$,", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist Meuterey entstanden:", "tokens": ["Ist", "Meu\u00b7te\u00b7rey", "ent\u00b7stan\u00b7den", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Auf, Kinder! lasst, in's Kriegsgewand", "tokens": ["Auf", ",", "Kin\u00b7der", "!", "lasst", ",", "in's", "Kriegs\u00b7ge\u00b7wand"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "$,", "NN", "$.", "VVFIN", "$,", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Geh\u00fcllt, uns mit bewehrter Hand,", "tokens": ["Ge\u00b7h\u00fcllt", ",", "uns", "mit", "be\u00b7wehr\u00b7ter", "Hand", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Walt's Gott! den Unfug ahnden!", "tokens": ["Walt's", "Gott", "!", "den", "Un\u00b7fug", "ahn\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Diess Aufgebot war Gross und Klein", "tokens": ["Diess", "Auf\u00b7ge\u00b7bot", "war", "Gross", "und", "Klein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDAT", "NN", "VAFIN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gar lieblich zu vernehmen.", "tokens": ["Gar", "lieb\u00b7lich", "zu", "ver\u00b7neh\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dortorts, rief man, w\u00e4chst s\u00fcsser Wein:", "tokens": ["Dor\u00b7torts", ",", "rief", "man", ",", "w\u00e4chst", "s\u00fcs\u00b7ser", "Wein", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PIS", "$,", "VVFIN", "ADJA", "NN", "$."], "meter": "-----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Kommt, lasst uns guter Dinge seyn!", "tokens": ["Kommt", ",", "lasst", "uns", "gu\u00b7ter", "Din\u00b7ge", "seyn", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PPER", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den wollen wir schon z\u00e4hmen.", "tokens": ["Den", "wol\u00b7len", "wir", "schon", "z\u00e4h\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Nun f\u00f6rdert Arnulph sich, zu ziehn", "tokens": ["Nun", "f\u00f6r\u00b7dert", "Ar\u00b7nulph", "sich", ",", "zu", "ziehn"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "NE", "PRF", "$,", "PTKZU", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wohl gegen W\u00e4lschlands Gr\u00e4nzen.", "tokens": ["Wohl", "ge\u00b7gen", "W\u00e4l\u00b7schlands", "Gr\u00e4n\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.3": {"text": "Schon k\u00f6mmt er bis nach Florenz hin,", "tokens": ["Schon", "k\u00f6mmt", "er", "bis", "nach", "Flo\u00b7renz", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und allerw\u00e4rts empf\u00e4ngt man ihn", "tokens": ["Und", "al\u00b7ler\u00b7w\u00e4rts", "emp\u00b7f\u00e4ngt", "man", "ihn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PIS", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit tausend Reverenzen.", "tokens": ["Mit", "tau\u00b7send", "Re\u00b7ve\u00b7ren\u00b7zen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Nur bey den stolzen R\u00f6mern war", "tokens": ["Nur", "bey", "den", "stol\u00b7zen", "R\u00f6\u00b7mern", "war"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm Th\u00fcr' und Thor verriegelt.", "tokens": ["Ihm", "Th\u00fcr'", "und", "Thor", "ver\u00b7rie\u00b7gelt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Sie aufzubieten, sandt' er zwar", "tokens": ["Sie", "auf\u00b7zu\u00b7bie\u00b7ten", ",", "sandt'", "er", "zwar"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zween Boten: doch das gute Paar", "tokens": ["Zween", "Bo\u00b7ten", ":", "doch", "das", "gu\u00b7te", "Paar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ward schimpflich fortgepr\u00fcgelt.", "tokens": ["Ward", "schimpf\u00b7lich", "fort\u00b7ge\u00b7pr\u00fc\u00b7gelt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Erbosst rief Arnulph: \u00bbHabt ihr so", "tokens": ["Er\u00b7bosst", "rief", "Ar\u00b7nulph", ":", "\u00bb", "Habt", "ihr", "so"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NN", "VVFIN", "NE", "$.", "$(", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das V\u00f6lkerrecht in Ehren?", "tokens": ["Das", "V\u00f6l\u00b7ker\u00b7recht", "in", "Eh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ihr Lotterbuben! lichterloh", "tokens": ["Ihr", "Lot\u00b7ter\u00b7bu\u00b7ben", "!", "lich\u00b7ter\u00b7loh"], "token_info": ["word", "word", "punct", "word"], "pos": ["PPOSAT", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Soll eure Stadt mir flammen! ... O!", "tokens": ["Soll", "eu\u00b7re", "Stadt", "mir", "flam\u00b7men", "!", "...", "O", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$.", "$(", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich will euch ", "tokens": ["Ich", "will", "euch"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VMFIN", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.24": {"line.1": {"text": "Auf, Br\u00fcder! z\u00e4hmet das Geschmeiss!", "tokens": ["Auf", ",", "Br\u00fc\u00b7der", "!", "z\u00e4h\u00b7met", "das", "Ge\u00b7schmeiss", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "$,", "NN", "$.", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lasst uns die Stadt berennen!\u00ab", "tokens": ["Lasst", "uns", "die", "Stadt", "be\u00b7ren\u00b7nen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Potz Blitz! nun ward den R\u00f6mern heiss:", "tokens": ["Potz", "Blitz", "!", "nun", "ward", "den", "R\u00f6\u00b7mern", "heiss", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "ADV", "VAFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der Stadtrath sprang, als ob der Steiss", "tokens": ["Der", "Stad\u00b7trath", "sprang", ",", "als", "ob", "der", "Steiss"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOKOM", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schon anfieng' ihm zu brennen.", "tokens": ["Schon", "an\u00b7fieng'", "ihm", "zu", "bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "F\u00fcr diessmal galt wohl auch f\u00fcrwahr", "tokens": ["F\u00fcr", "diess\u00b7mal", "galt", "wohl", "auch", "f\u00fcr\u00b7wahr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "VVFIN", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kein Zaudern und Besinnen;", "tokens": ["Kein", "Zau\u00b7dern", "und", "Be\u00b7sin\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn sieh! der Deutschen wilde Schaar", "tokens": ["Denn", "sieh", "!", "der", "Deut\u00b7schen", "wil\u00b7de", "Schaar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sucht schon, trotz jeglicher Gefahr", "tokens": ["Sucht", "schon", ",", "trotz", "jeg\u00b7li\u00b7cher", "Ge\u00b7fahr"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "ADV", "$,", "APPR", "PIAT", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Die W\u00e4lle zu gewinnen.", "tokens": ["Die", "W\u00e4l\u00b7le", "zu", "ge\u00b7win\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Wohl sieben Stunden k\u00e4mpfte man", "tokens": ["Wohl", "sie\u00b7ben", "Stun\u00b7den", "k\u00e4mpf\u00b7te", "man"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "CARD", "NN", "VVFIN", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So derb von beyden Seiten,", "tokens": ["So", "derb", "von", "bey\u00b7den", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dass ringsum Blut wie Wasser rann,", "tokens": ["Dass", "ring\u00b7sum", "Blut", "wie", "Was\u00b7ser", "rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NN", "KOKOM", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bis allgemach die Nacht begann", "tokens": ["Bis", "all\u00b7ge\u00b7mach", "die", "Nacht", "be\u00b7gann"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADV", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Schleyer auszubreiten.", "tokens": ["Den", "Schle\u00b7yer", "aus\u00b7zu\u00b7brei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Gen\u00f6thigt wendeten nunmehr", "tokens": ["Ge\u00b7n\u00f6t\u00b7higt", "wen\u00b7de\u00b7ten", "nun\u00b7mehr"], "token_info": ["word", "word", "word"], "pos": ["VVPP", "VVFIN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Deutschen die Standarten,", "tokens": ["Die", "Deut\u00b7schen", "die", "Stand\u00b7ar\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und Arnulph, sinnend hin und her,", "tokens": ["Und", "Ar\u00b7nulph", ",", "sin\u00b7nend", "hin", "und", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ADJD", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Beschloss, ein gl\u00fccklich Ungef\u00e4hr", "tokens": ["Be\u00b7schloss", ",", "ein", "gl\u00fcck\u00b7lich", "Un\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NN", "$,", "ART", "ADJD", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im Lager abzuwarten.", "tokens": ["Im", "La\u00b7ger", "ab\u00b7zu\u00b7war\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Rom, das den Feind schon f\u00fcr verzagt", "tokens": ["Rom", ",", "das", "den", "Feind", "schon", "f\u00fcr", "ver\u00b7zagt"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "$,", "PRELS", "ART", "NN", "ADV", "APPR", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und muthlos hielt, verlachte", "tokens": ["Und", "muth\u00b7los", "hielt", ",", "ver\u00b7lach\u00b7te"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["KON", "ADJD", "VVFIN", "$,", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Des K\u00f6nigs Heer, bis eine Jagd", "tokens": ["Des", "K\u00f6\u00b7nigs", "Heer", ",", "bis", "ei\u00b7ne", "Jagd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Urpl\u00f6tzlich, wie die Chronik sagt,", "tokens": ["Ur\u00b7pl\u00f6tz\u00b7lich", ",", "wie", "die", "Chro\u00b7nik", "sagt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem Spott ein Ende machte.", "tokens": ["Dem", "Spott", "ein", "En\u00b7de", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Ein Rammler aus dem nahen Hain", "tokens": ["Ein", "Ramm\u00b7ler", "aus", "dem", "na\u00b7hen", "Hain"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sprang sch\u00fcchtern vor den W\u00e4llen", "tokens": ["Sprang", "sch\u00fcch\u00b7tern", "vor", "den", "W\u00e4l\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Stadt umher, und hinterdrein", "tokens": ["Der", "Stadt", "um\u00b7her", ",", "und", "hin\u00b7ter\u00b7drein"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$,", "KON", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein Sp\u00fcrhund und mit derbem Schreyn", "tokens": ["Ein", "Sp\u00fcr\u00b7hund", "und", "mit", "der\u00b7bem", "Schreyn"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "APPR", "ART", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Ein Schwarm von Weidgesellen.", "tokens": ["Ein", "Schwarm", "von", "Weid\u00b7ge\u00b7sel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Halb Rom, vom heftigen Rumor", "tokens": ["Halb", "Rom", ",", "vom", "hef\u00b7ti\u00b7gen", "Ru\u00b7mor"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["NE", "NE", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "Der Jagenden betroffen,", "tokens": ["Der", "Ja\u00b7gen\u00b7den", "be\u00b7trof\u00b7fen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Lief, ohne Hut und Roquelaur,", "tokens": ["Lief", ",", "oh\u00b7ne", "Hut", "und", "Ro\u00b7que\u00b7laur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUI", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ripsraps beym Tempel aus, und Thor", "tokens": ["Rips\u00b7raps", "beym", "Tem\u00b7pel", "aus", ",", "und", "Thor"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["NE", "APPRART", "NN", "PTKVZ", "$,", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Angel blieben offen.", "tokens": ["Und", "An\u00b7gel", "blie\u00b7ben", "of\u00b7fen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "Der K\u00f6nig sah am Horst hinab", "tokens": ["Der", "K\u00f6\u00b7nig", "sah", "am", "Horst", "hin\u00b7ab"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der Fl\u00fcchtigen Gedr\u00e4nge,", "tokens": ["Der", "Fl\u00fcch\u00b7ti\u00b7gen", "Ge\u00b7dr\u00e4n\u00b7ge", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Halt! rief er, lasst vom Hasen ab!", "tokens": ["Halt", "!", "rief", "er", ",", "lasst", "vom", "Ha\u00b7sen", "ab", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "$.", "VVFIN", "PPER", "$,", "VVFIN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was soll euch Einer? dort bergab,", "tokens": ["Was", "soll", "euch", "Ei\u00b7ner", "?", "dort", "berg\u00b7ab", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPER", "PIS", "$.", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dort kriegt ihr eine Menge.", "tokens": ["Dort", "kriegt", "ihr", "ei\u00b7ne", "Men\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Nun gieng's aus einem andern Ton.", "tokens": ["Nun", "gieng's", "aus", "ei\u00b7nem", "an\u00b7dern", "Ton", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Seht! spornstreichs galoppiren", "tokens": ["Seht", "!", "sporn\u00b7streichs", "ga\u00b7lop\u00b7pi\u00b7ren"], "token_info": ["word", "punct", "word", "word"], "pos": ["VVFIN", "$.", "NE", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Die J\u00e4ger nach: doch ferne schon", "tokens": ["Die", "J\u00e4\u00b7ger", "nach", ":", "doch", "fer\u00b7ne", "schon"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "$.", "ADV", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00f6rt man die Memmen um Pardon", "tokens": ["H\u00f6rt", "man", "die", "Mem\u00b7men", "um", "Par\u00b7don"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "ART", "NN", "APPR", "NN"], "meter": "++-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Gnade lamentiren.", "tokens": ["Und", "Gna\u00b7de", "la\u00b7men\u00b7ti\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Bewegt ward Arnulph, frank und frey", "tokens": ["Be\u00b7wegt", "ward", "Ar\u00b7nulph", ",", "frank", "und", "frey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVPP", "VAFIN", "NE", "$,", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie alle heimzuschicken:", "tokens": ["Sie", "al\u00b7le", "heim\u00b7zu\u00b7schi\u00b7cken", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Doch liess er, Rom zu Schimpf und Scheu,", "tokens": ["Doch", "liess", "er", ",", "Rom", "zu", "Schimpf", "und", "Scheu", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "NE", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von F\u00fcnfzigen je Zwey und Zwey", "tokens": ["Von", "F\u00fcnf\u00b7zi\u00b7gen", "je", "Zwey", "und", "Zwey"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ADV", "CARD", "KON", "CARD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit Hasenschw\u00e4nzen schm\u00fccken,", "tokens": ["Mit", "Ha\u00b7sen\u00b7schw\u00e4n\u00b7zen", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Wenn solche Ordenszeichen heut", "tokens": ["Wenn", "sol\u00b7che", "Or\u00b7dens\u00b7zei\u00b7chen", "heut"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zu Tag noch Sitte w\u00e4ren,", "tokens": ["Zu", "Tag", "noch", "Sit\u00b7te", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So w\u00fcrd' auch wohl zu unsrer Zeit", "tokens": ["So", "w\u00fcrd'", "auch", "wohl", "zu", "uns\u00b7rer", "Zeit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Manch liebes S\u00f6hnchen aus dem Streit", "tokens": ["Manch", "lie\u00b7bes", "S\u00f6hn\u00b7chen", "aus", "dem", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit nach Hause kehren.", "tokens": ["Da\u00b7mit", "nach", "Hau\u00b7se", "keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}