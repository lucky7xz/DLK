{"dta.poem.21826": {"metadata": {"author": {"name": "Stieler, Kaspar von", "birth": "N.A.", "death": "N.A."}, "title": "ViI.  \n  Auff ihren Morgen-schlaaff.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1660", "urn": "urn:nbn:de:kobv:b4-20586-2", "language": ["de:0.99"], "booktitle": "Filidor der Dorfferer [i. e. Stieler, Kaspar von]: Die Geharnschte Venus. Hamburg, 1660."}, "poem": {"stanza.1": {"line.1": {"text": "Rubellchen/ bistu noch nicht wach?", "tokens": ["Ru\u00b7bell\u00b7chen", "/", "bis\u00b7tu", "noch", "nicht", "wach", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "ADV", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Verla\u00df die weichen Feder-dekken/", "tokens": ["Ver\u00b7la\u00df", "die", "wei\u00b7chen", "Fe\u00b7der\u00b7dek\u00b7ken", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die so viel G\u00f6ttligkeit verstekken.", "tokens": ["die", "so", "viel", "G\u00f6tt\u00b7lig\u00b7keit", "vers\u00b7tek\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Ich geh\u2019 allhier der Hoffnung nach/", "tokens": ["Ich", "geh'", "all\u00b7hier", "der", "Hoff\u00b7nung", "nach", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "APPR", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ob ich dich m\u00f6chte/ Mein Vergn\u00fcgen/", "tokens": ["ob", "ich", "dich", "m\u00f6ch\u00b7te", "/", "Mein", "Ver\u00b7gn\u00fc\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VMFIN", "$(", "PPOSAT", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "an den Krystallen sehen liegen.", "tokens": ["an", "den", "Krys\u00b7tal\u00b7len", "se\u00b7hen", "lie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.2": {"line.1": {"text": "Auroren g\u00f6ldnes Rosen-bluht/", "tokens": ["Au\u00b7ro\u00b7ren", "g\u00f6ld\u00b7nes", "Ro\u00b7sen\u00b7bluht", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "dein Ebenbild der roten Wangen", "tokens": ["dein", "E\u00b7ben\u00b7bild", "der", "ro\u00b7ten", "Wan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "ist allbereit vorbey gegangen/", "tokens": ["ist", "all\u00b7be\u00b7reit", "vor\u00b7bey", "ge\u00b7gan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Apollo blizzt in voller Gluht/", "tokens": ["A\u00b7pol\u00b7lo", "blizzt", "in", "vol\u00b7ler", "Gluht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "der Handwerksman hat schon verzehret/", "tokens": ["der", "Hand\u00b7werks\u00b7man", "hat", "schon", "ver\u00b7zeh\u00b7ret", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVFIN", "$("], "meter": "-+---+-+-", "measure": "dactylic.init"}, "line.6": {"text": "was ihm zum Morgenbrodt geh\u00f6ret.", "tokens": ["was", "ihm", "zum", "Mor\u00b7gen\u00b7brodt", "ge\u00b7h\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Rubellchen schl\u00e4fft. Sie wei\u00df es nicht/", "tokens": ["Ru\u00b7bell\u00b7chen", "schl\u00e4fft", ".", "Sie", "wei\u00df", "es", "nicht", "/"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "da\u00df ich im gehn hier klag\u2019 und reime.", "tokens": ["da\u00df", "ich", "im", "gehn", "hier", "klag'", "und", "rei\u00b7me", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "VVFIN", "ADV", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seyd ihr der Warheit/ Morgen", "tokens": ["Seyd", "ihr", "der", "War\u00b7heit", "/", "Mor\u00b7gen"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["VAIMP", "PPER", "ART", "NN", "$(", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "als wie ich um di\u00df Fenster stehe", "tokens": ["als", "wie", "ich", "um", "di\u00df", "Fens\u00b7ter", "ste\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PWAV", "PPER", "APPR", "PDS", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und sie an-zuerwachen-flehe.", "tokens": ["und", "sie", "an\u00b7zu\u00b7er\u00b7wa\u00b7chen\u00b7fle\u00b7he", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$."], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}}, "stanza.4": {"line.1": {"text": "Ich schweer es/ Morfeus/ da\u00df ich dich", "tokens": ["Ich", "schweer", "es", "/", "Mor\u00b7feus", "/", "da\u00df", "ich", "dich"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$(", "NE", "$(", "KOUS", "PPER", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "wil mehr als alle G\u00f6tter ehren:", "tokens": ["wil", "mehr", "als", "al\u00b7le", "G\u00f6t\u00b7ter", "eh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "KOKOM", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wirstu Rubellchen so bet\u00f6hren/", "tokens": ["wirs\u00b7tu", "Ru\u00b7bell\u00b7chen", "so", "be\u00b7t\u00f6h\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "da\u00df sie es gleube kr\u00e4fftiglich", "tokens": ["da\u00df", "sie", "es", "gleu\u00b7be", "kr\u00e4ff\u00b7tig\u00b7lich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "und nach dem Fenster m\u00f6ge rennen/", "tokens": ["und", "nach", "dem", "Fens\u00b7ter", "m\u00f6\u00b7ge", "ren\u00b7nen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VMFIN", "VVFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "des Traumes Au\u00dfgang zu erkennen.", "tokens": ["des", "Trau\u00b7mes", "Au\u00df\u00b7gang", "zu", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Was meint Jhr? wenn dann ungefehr", "tokens": ["Was", "meint", "Ihr", "?", "wenn", "dann", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "KOUS", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Jhr Busem offen m\u00f6chte stehen/", "tokens": ["Ihr", "Bu\u00b7sem", "of\u00b7fen", "m\u00f6ch\u00b7te", "ste\u00b7hen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und ich die Liljen k\u00f6nnte sehen:", "tokens": ["und", "ich", "die", "Lil\u00b7jen", "k\u00f6nn\u00b7te", "se\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wer w\u00e4re gl\u00fckklicher/ sagt/ wer?", "tokens": ["Wer", "w\u00e4\u00b7re", "gl\u00fck\u00b7kli\u00b7cher", "/", "sagt", "/", "wer", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VAFIN", "ADJD", "$(", "VVFIN", "$(", "PWS", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "k\u00f6nnt\u2019 ich den Vorteil so erlauschen/", "tokens": ["k\u00f6nnt'", "ich", "den", "Vor\u00b7teil", "so", "er\u00b7lau\u00b7schen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "ich wollte nicht mit Paris tauschen.", "tokens": ["ich", "woll\u00b7te", "nicht", "mit", "Pa\u00b7ris", "tau\u00b7schen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "APPR", "NE", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ja/ mich kanstu/ du L\u00fcgen Geist/", "tokens": ["Ja", "/", "mich", "kans\u00b7tu", "/", "du", "L\u00fc\u00b7gen", "Geist", "/"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$(", "PPER", "VMFIN", "$(", "PPER", "NN", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du Treumer/ wol durch sie betriegen:", "tokens": ["du", "Treu\u00b7mer", "/", "wol", "durch", "sie", "be\u00b7trie\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$(", "ADV", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Ich kan fast keine Nacht nicht liegen/", "tokens": ["Ich", "kan", "fast", "kei\u00b7ne", "Nacht", "nicht", "lie\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Erwach\u2019 ich in dem \u00f6den Schatten", "tokens": ["Er\u00b7wach'", "ich", "in", "dem", "\u00f6\u00b7den", "Schat\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Rubellchen/ du bist nicht verliebt/", "tokens": ["Ru\u00b7bell\u00b7chen", "/", "du", "bist", "nicht", "ver\u00b7liebt", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$(", "PPER", "VAFIN", "PTKNEG", "VVPP", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wehn Amors W\u00fcten h\u00e4lt besessen/", "tokens": ["Wehn", "A\u00b7mors", "W\u00fc\u00b7ten", "h\u00e4lt", "be\u00b7ses\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "NN", "VVFIN", "VVPP", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der ruhet so nicht/ unbetr\u00fcbt.", "tokens": ["der", "ru\u00b7het", "so", "nicht", "/", "un\u00b7be\u00b7tr\u00fcbt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "VVFIN", "ADV", "PTKNEG", "$(", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wach auff/ Rubellchen", "tokens": ["Wach", "auff", "/", "Ru\u00b7bell\u00b7chen"], "token_info": ["word", "word", "punct", "word"], "pos": ["NN", "APPR", "$(", "NN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.5": {"text": "da\u00df du die meine wollest bleiben.", "tokens": ["da\u00df", "du", "die", "mei\u00b7ne", "wol\u00b7lest", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PPOSAT", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}