{"textgrid.poem.60665": {"metadata": {"author": {"name": "La Fontaine, Jean de", "birth": "N.A.", "death": "N.A."}, "title": "1L: Dem Tontopf schlug der Topf von Eisen", "genre": "verse", "period": "N.A.", "pub_year": 1658, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dem Tontopf schlug der Topf von Eisen", "tokens": ["Dem", "Ton\u00b7topf", "schlug", "der", "Topf", "von", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einst vor, mit ihm umherzureisen.", "tokens": ["Einst", "vor", ",", "mit", "ihm", "um\u00b7her\u00b7zu\u00b7rei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der irdne aber dankte sehr,", "tokens": ["Der", "ird\u00b7ne", "a\u00b7ber", "dank\u00b7te", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er meinte, kl\u00fcger t\u00e4te er,", "tokens": ["Er", "mein\u00b7te", ",", "kl\u00fc\u00b7ger", "t\u00e4\u00b7te", "er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Am warmen Fleck zu bleiben,", "tokens": ["Am", "war\u00b7men", "Fleck", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als sich umherzutreiben,", "tokens": ["Als", "sich", "um\u00b7her\u00b7zu\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dieweil er gar empfindlich sei:", "tokens": ["Die\u00b7weil", "er", "gar", "emp\u00b7find\u00b7lich", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Sto\u00df \u2013 und gleich sei er entzwei", "tokens": ["Ein", "Sto\u00df", "\u2013", "und", "gleich", "sei", "er", "ent\u00b7zwei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "KON", "ADV", "VAFIN", "PPER", "PTKVZ"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Und liege da in Scherben", "tokens": ["Und", "lie\u00b7ge", "da", "in", "Scher\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und m\u00fcsse elend sterben.", "tokens": ["Und", "m\u00fcs\u00b7se", "e\u00b7lend", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "\u00bbdu freilich, mit der Haut von Eisen,\u00ab", "tokens": ["\u00bb", "du", "frei\u00b7lich", ",", "mit", "der", "Haut", "von", "Ei\u00b7sen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "APPR", "ART", "NN", "APPR", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "So schlo\u00df er, \u00bbdu kannst ruhig reisen.\u00ab", "tokens": ["So", "schlo\u00df", "er", ",", "\u00bb", "du", "kannst", "ru\u00b7hig", "rei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VMFIN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbich will dein Schild und Sch\u00fctzer sein,\u00ab", "tokens": ["\u00bb", "ich", "will", "dein", "Schild", "und", "Sch\u00fct\u00b7zer", "sein", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPOSAT", "NN", "KON", "NN", "VAINF", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Warf da der Topf von Eisen ein;", "tokens": ["Warf", "da", "der", "Topf", "von", "Ei\u00b7sen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "\u00bbdroht dir ein harter Gegenstand,", "tokens": ["\u00bb", "droht", "dir", "ein", "har\u00b7ter", "Ge\u00b7gen\u00b7stand", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.16": {"text": "Tret ich dazwischen: feste Wand,", "tokens": ["Tret", "ich", "da\u00b7zwi\u00b7schen", ":", "fes\u00b7te", "Wand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "$.", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die gut dich schirmt vor jedem harten Schlag und Sto\u00df.\u00ab", "tokens": ["Die", "gut", "dich", "schirmt", "vor", "je\u00b7dem", "har\u00b7ten", "Schlag", "und", "Sto\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "PPER", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Da sprach der Tontopf: \u00bbAlso los!\u00ab", "tokens": ["Da", "sprach", "der", "Ton\u00b7topf", ":", "\u00bb", "Al\u00b7so", "los", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Dreibeinig humpeln Seit an Seite", "tokens": ["Drei\u00b7bei\u00b7nig", "hum\u00b7peln", "Seit", "an", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "APPR", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die guten Leutchen in die Weite.", "tokens": ["Die", "gu\u00b7ten", "Leut\u00b7chen", "in", "die", "Wei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch klipperklapper schl\u00e4gt im Wandern", "tokens": ["Doch", "klip\u00b7per\u00b7klap\u00b7per", "schl\u00e4gt", "im", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bei jedem kleinsten Hindernis", "tokens": ["Bei", "je\u00b7dem", "kleins\u00b7ten", "Hin\u00b7der\u00b7nis"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der eine immer an den andern.", "tokens": ["Der", "ei\u00b7ne", "im\u00b7mer", "an", "den", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bald hat der Tontopf einen Ri\u00df,", "tokens": ["Bald", "hat", "der", "Ton\u00b7topf", "ei\u00b7nen", "Ri\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und hundert Schritt sind kaum gemacht,", "tokens": ["Und", "hun\u00b7dert", "Schritt", "sind", "kaum", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da ist er an der Seite seines Kameraden", "tokens": ["Da", "ist", "er", "an", "der", "Sei\u00b7te", "sei\u00b7nes", "Ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In Scherben j\u00e4h zerkracht.", "tokens": ["In", "Scher\u00b7ben", "j\u00e4h", "zer\u00b7kracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Und doch traf diesen nicht einmal die Schuld am Schaden.", "tokens": ["Und", "doch", "traf", "die\u00b7sen", "nicht", "ein\u00b7mal", "die", "Schuld", "am", "Scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PDS", "PTKNEG", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Verbinde du dich nur mit gleichen Kameraden,", "tokens": ["Ver\u00b7bin\u00b7de", "du", "dich", "nur", "mit", "glei\u00b7chen", "Ka\u00b7me\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst mu\u00dft du stets in \u00c4ngsten schweben,", "tokens": ["Sonst", "mu\u00dft", "du", "stets", "in", "\u00c4ngs\u00b7ten", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Los von einem dieser T\u00f6pfe zu erleben.", "tokens": ["Das", "Los", "von", "ei\u00b7nem", "die\u00b7ser", "T\u00f6p\u00b7fe", "zu", "er\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "PDAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Dem Tontopf schlug der Topf von Eisen", "tokens": ["Dem", "Ton\u00b7topf", "schlug", "der", "Topf", "von", "Ei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Einst vor, mit ihm umherzureisen.", "tokens": ["Einst", "vor", ",", "mit", "ihm", "um\u00b7her\u00b7zu\u00b7rei\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PTKVZ", "$,", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der irdne aber dankte sehr,", "tokens": ["Der", "ird\u00b7ne", "a\u00b7ber", "dank\u00b7te", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADV", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Er meinte, kl\u00fcger t\u00e4te er,", "tokens": ["Er", "mein\u00b7te", ",", "kl\u00fc\u00b7ger", "t\u00e4\u00b7te", "er", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ADJD", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Am warmen Fleck zu bleiben,", "tokens": ["Am", "war\u00b7men", "Fleck", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Als sich umherzutreiben,", "tokens": ["Als", "sich", "um\u00b7her\u00b7zu\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.7": {"text": "Dieweil er gar empfindlich sei:", "tokens": ["Die\u00b7weil", "er", "gar", "emp\u00b7find\u00b7lich", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ein Sto\u00df \u2013 und gleich sei er entzwei", "tokens": ["Ein", "Sto\u00df", "\u2013", "und", "gleich", "sei", "er", "ent\u00b7zwei"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$(", "KON", "ADV", "VAFIN", "PPER", "PTKVZ"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.9": {"text": "Und liege da in Scherben", "tokens": ["Und", "lie\u00b7ge", "da", "in", "Scher\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Und m\u00fcsse elend sterben.", "tokens": ["Und", "m\u00fcs\u00b7se", "e\u00b7lend", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "\u00bbdu freilich, mit der Haut von Eisen,\u00ab", "tokens": ["\u00bb", "du", "frei\u00b7lich", ",", "mit", "der", "Haut", "von", "Ei\u00b7sen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "ADV", "$,", "APPR", "ART", "NN", "APPR", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "So schlo\u00df er, \u00bbdu kannst ruhig reisen.\u00ab", "tokens": ["So", "schlo\u00df", "er", ",", "\u00bb", "du", "kannst", "ru\u00b7hig", "rei\u00b7sen", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "$(", "PPER", "VMFIN", "ADJD", "VVINF", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "\u00bbich will dein Schild und Sch\u00fctzer sein,\u00ab", "tokens": ["\u00bb", "ich", "will", "dein", "Schild", "und", "Sch\u00fct\u00b7zer", "sein", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PPER", "VMFIN", "PPOSAT", "NN", "KON", "NN", "VAINF", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Warf da der Topf von Eisen ein;", "tokens": ["Warf", "da", "der", "Topf", "von", "Ei\u00b7sen", "ein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "\u00bbdroht dir ein harter Gegenstand,", "tokens": ["\u00bb", "droht", "dir", "ein", "har\u00b7ter", "Ge\u00b7gen\u00b7stand", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.16": {"text": "Tret ich dazwischen: feste Wand,", "tokens": ["Tret", "ich", "da\u00b7zwi\u00b7schen", ":", "fes\u00b7te", "Wand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "VVINF", "$.", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Die gut dich schirmt vor jedem harten Schlag und Sto\u00df.\u00ab", "tokens": ["Die", "gut", "dich", "schirmt", "vor", "je\u00b7dem", "har\u00b7ten", "Schlag", "und", "Sto\u00df", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "PPER", "VVFIN", "APPR", "PIAT", "ADJA", "NN", "KON", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Da sprach der Tontopf: \u00bbAlso los!\u00ab", "tokens": ["Da", "sprach", "der", "Ton\u00b7topf", ":", "\u00bb", "Al\u00b7so", "los", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Dreibeinig humpeln Seit an Seite", "tokens": ["Drei\u00b7bei\u00b7nig", "hum\u00b7peln", "Seit", "an", "Sei\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["CARD", "ADJA", "NN", "APPR", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Die guten Leutchen in die Weite.", "tokens": ["Die", "gu\u00b7ten", "Leut\u00b7chen", "in", "die", "Wei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Doch klipperklapper schl\u00e4gt im Wandern", "tokens": ["Doch", "klip\u00b7per\u00b7klap\u00b7per", "schl\u00e4gt", "im", "Wan\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bei jedem kleinsten Hindernis", "tokens": ["Bei", "je\u00b7dem", "kleins\u00b7ten", "Hin\u00b7der\u00b7nis"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der eine immer an den andern.", "tokens": ["Der", "ei\u00b7ne", "im\u00b7mer", "an", "den", "an\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADV", "APPR", "ART", "ADJA", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bald hat der Tontopf einen Ri\u00df,", "tokens": ["Bald", "hat", "der", "Ton\u00b7topf", "ei\u00b7nen", "Ri\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und hundert Schritt sind kaum gemacht,", "tokens": ["Und", "hun\u00b7dert", "Schritt", "sind", "kaum", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da ist er an der Seite seines Kameraden", "tokens": ["Da", "ist", "er", "an", "der", "Sei\u00b7te", "sei\u00b7nes", "Ka\u00b7me\u00b7ra\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "APPR", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "In Scherben j\u00e4h zerkracht.", "tokens": ["In", "Scher\u00b7ben", "j\u00e4h", "zer\u00b7kracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und doch traf diesen nicht einmal die Schuld am Schaden.", "tokens": ["Und", "doch", "traf", "die\u00b7sen", "nicht", "ein\u00b7mal", "die", "Schuld", "am", "Scha\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PDS", "PTKNEG", "ADV", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.12": {"line.1": {"text": "Verbinde du dich nur mit gleichen Kameraden,", "tokens": ["Ver\u00b7bin\u00b7de", "du", "dich", "nur", "mit", "glei\u00b7chen", "Ka\u00b7me\u00b7ra\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sonst mu\u00dft du stets in \u00c4ngsten schweben,", "tokens": ["Sonst", "mu\u00dft", "du", "stets", "in", "\u00c4ngs\u00b7ten", "schwe\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das Los von einem dieser T\u00f6pfe zu erleben.", "tokens": ["Das", "Los", "von", "ei\u00b7nem", "die\u00b7ser", "T\u00f6p\u00b7fe", "zu", "er\u00b7le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "PDAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}