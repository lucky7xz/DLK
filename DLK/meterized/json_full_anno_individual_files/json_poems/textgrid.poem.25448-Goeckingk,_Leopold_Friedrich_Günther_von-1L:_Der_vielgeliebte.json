{"textgrid.poem.25448": {"metadata": {"author": {"name": "Goeckingk, Leopold Friedrich G\u00fcnther von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Der vielgeliebte ", "genre": "verse", "period": "N.A.", "pub_year": 1788, "urn": "N.A.", "language": ["de:0.85", "af:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der vielgeliebte ", "tokens": ["Der", "viel\u00b7ge\u00b7lieb\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Im ", "tokens": ["Im"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "So schwatzt ihm alles schon von Steckenpferden nach;", "tokens": ["So", "schwatzt", "ihm", "al\u00b7les", "schon", "von", "Ste\u00b7cken\u00b7pfer\u00b7den", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer aber wird davon zum ", "tokens": ["Wer", "a\u00b7ber", "wird", "da\u00b7von", "zum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VAFIN", "PAV", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mir deucht, auf's W\u00f6rtlein Steckenpferd,", "tokens": ["Mir", "deucht", ",", "auf's", "W\u00f6rt\u00b7lein", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(man kannt' es schon vor ", "tokens": ["(", "man", "kannt'", "es", "schon", "vor"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PIS", "VMFIN", "PPER", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Kommt's wohl nicht an; die Sache anzudeuten,", "tokens": ["Kommt's", "wohl", "nicht", "an", ";", "die", "Sa\u00b7che", "an\u00b7zu\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "PTKVZ", "$.", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gibt's Worte noch von gleichem Werth'.", "tokens": ["Gibt's", "Wor\u00b7te", "noch", "von", "glei\u00b7chem", "Wert\u00b7h'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Inde\u00df behalt' ich's bei; nicht, ", "tokens": ["In\u00b7de\u00df", "be\u00b7halt'", "ich's", "bei", ";", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "PTKVZ", "$.", "PTKNEG", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Das \u00fcberla\u00df' ich gern Horazens Vieh':", "tokens": ["Das", "\u00fc\u00b7ber\u00b7la\u00df'", "ich", "gern", "Ho\u00b7ra\u00b7zens", "Vieh'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NE", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ich liebe die Allegorie,", "tokens": ["Ich", "lie\u00b7be", "die", "Al\u00b7le\u00b7go\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und Steckenpferd gibt mir f\u00fcr die\u00dfmal sie;", "tokens": ["Und", "Ste\u00b7cken\u00b7pferd", "gibt", "mir", "f\u00fcr", "die\u00df\u00b7mal", "sie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "ADV", "PPER", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Sollt's Kritikern schon wieder anders d\u00fcnken?", "tokens": ["Sollt's", "Kri\u00b7ti\u00b7kern", "schon", "wie\u00b7der", "an\u00b7ders", "d\u00fcn\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Je meinethalb! Sie sind ja Critici!", "tokens": ["Je", "mei\u00b7net\u00b7halb", "!", "Sie", "sind", "ja", "Cri\u00b7ti\u00b7ci", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPER", "VAFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Komm her, mein lieber ", "tokens": ["Komm", "her", ",", "mein", "lie\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.16": {"text": "Dir alle Steckenpferde vor,", "tokens": ["Dir", "al\u00b7le", "Ste\u00b7cken\u00b7pfer\u00b7de", "vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die ich vom Sch\u00fcler an, bis heute,", "tokens": ["Die", "ich", "vom", "Sch\u00fc\u00b7ler", "an", ",", "bis", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "PTKVZ", "$,", "KOUS", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Sehr theuer oft gewann und wohlfeil oft verlor.", "tokens": ["Sehr", "theu\u00b7er", "oft", "ge\u00b7wann", "und", "wohl\u00b7feil", "oft", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "KON", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sieh hier den ", "tokens": ["Sieh", "hier", "den"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "Und doch; wie bald hab' ich's nicht steif geritten!", "tokens": ["Und", "doch", ";", "wie", "bald", "hab'", "ich's", "nicht", "steif", "ge\u00b7rit\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWAV", "ADV", "VAFIN", "PIS", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Denn was nur ohne Geist und Sitten", "tokens": ["Denn", "was", "nur", "oh\u00b7ne", "Geist", "und", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Zu Fu\u00df geht, reitet oder f\u00e4hrt,", "tokens": ["Zu", "Fu\u00df", "geht", ",", "rei\u00b7tet", "o\u00b7der", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Hab' ich damit als Knabe schon gehetzt.", "tokens": ["Hab'", "ich", "da\u00b7mit", "als", "Kna\u00b7be", "schon", "ge\u00b7hetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PAV", "KOUS", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Itzt halt' ich's nicht der M\u00fche werth,", "tokens": ["Itzt", "halt'", "ich's", "nicht", "der", "M\u00fc\u00b7he", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Da\u00df man sich oft auf diesen Renner setzt.", "tokens": ["Da\u00df", "man", "sich", "oft", "auf", "die\u00b7sen", "Ren\u00b7ner", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "W\u00fc\u00dft' ich auch keinen andern Grund,", "tokens": ["W\u00fc\u00dft'", "ich", "auch", "kei\u00b7nen", "an\u00b7dern", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "So w\u00e4r's an dem genug: Man wird des Jagens m\u00fcde!", "tokens": ["So", "w\u00e4r's", "an", "dem", "ge\u00b7nug", ":", "Man", "wird", "des", "Ja\u00b7gens", "m\u00fc\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADV", "$.", "PIS", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Drum halt' ich itzt mit jedem Hund'", "tokens": ["Drum", "halt'", "ich", "itzt", "mit", "je\u00b7dem", "Hund'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und jedem Narren gerne Friede.", "tokens": ["Und", "je\u00b7dem", "Nar\u00b7ren", "ger\u00b7ne", "Frie\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Wer jenen foppt, den bei\u00dft er leicht ins Bein,", "tokens": ["Wer", "je\u00b7nen", "foppt", ",", "den", "bei\u00dft", "er", "leicht", "ins", "Bein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,", "ART", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Wer diesen neckt, macht einen Feind sich mehr.", "tokens": ["Wer", "die\u00b7sen", "neckt", ",", "macht", "ei\u00b7nen", "Feind", "sich", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,", "VVFIN", "ART", "NN", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Will Bav ein Thor seyn, mag er's seyn!", "tokens": ["Will", "Bav", "ein", "Thor", "seyn", ",", "mag", "er's", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ART", "NN", "VAINF", "$,", "VMFIN", "PIS", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Bellt Spitz mich an? Er belle noch so sehr!", "tokens": ["Bellt", "Spitz", "mich", "an", "?", "Er", "bel\u00b7le", "noch", "so", "sehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Ich suche dennoch keinen Stein!", "tokens": ["Ich", "su\u00b7che", "den\u00b7noch", "kei\u00b7nen", "Stein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Auch stand einmal im Marstall' meiner Launen", "tokens": ["Auch", "stand", "ein\u00b7mal", "im", "Mar\u00b7stall'", "mei\u00b7ner", "Lau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Ein Steckenpferd, das man die ", "tokens": ["Ein", "Ste\u00b7cken\u00b7pferd", ",", "das", "man", "die"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Nicht ein Cosack, der keinen Z\u00fcgel kennt,", "tokens": ["Nicht", "ein", "Co\u00b7sack", ",", "der", "kei\u00b7nen", "Z\u00fc\u00b7gel", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Den reiten nur die wilden Faunen.", "tokens": ["Den", "rei\u00b7ten", "nur", "die", "wil\u00b7den", "Fau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Es war ein allerliebstes Thier,", "tokens": ["Es", "war", "ein", "al\u00b7ler\u00b7liebs\u00b7tes", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Aus Herrn ", "tokens": ["Aus", "Herrn"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.41": {"text": "War fromm und willig, selbst bei mir,", "tokens": ["War", "fromm", "und", "wil\u00b7lig", ",", "selbst", "bei", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.43": {"text": "Der sanfte Trab, den dieses gute Ding", "tokens": ["Der", "sanf\u00b7te", "Trab", ",", "den", "die\u00b7ses", "gu\u00b7te", "Ding"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Mit seinem Herrn im ersten Ausritt' ging,", "tokens": ["Mit", "sei\u00b7nem", "Herrn", "im", "ers\u00b7ten", "Aus\u00b7ritt'", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "War seinem Herrn zwar ganz beh\u00e4glich;", "tokens": ["War", "sei\u00b7nem", "Herrn", "zwar", "ganz", "be\u00b7h\u00e4g\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Doch Schade war's um allen Trab!", "tokens": ["Doch", "Scha\u00b7de", "wa\u00b7r's", "um", "al\u00b7len", "Trab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Man that die Reise doch nicht ab;", "tokens": ["Man", "that", "die", "Rei\u00b7se", "doch", "nicht", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Der Umstand war wahrhaftig kl\u00e4glich.", "tokens": ["Der", "Um\u00b7stand", "war", "wahr\u00b7haf\u00b7tig", "kl\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "In unserm besten Dreischlag' \u2013 Halt!", "tokens": ["In", "un\u00b7serm", "bes\u00b7ten", "Drei\u00b7schlag'", "\u2013", "Halt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "VVIMP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Da stand auf einmal Pferd und Reiter", "tokens": ["Da", "stand", "auf", "ein\u00b7mal", "Pferd", "und", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "Vor einem Schlagbaum'!", "tokens": ["Vor", "ei\u00b7nem", "Schlag\u00b7baum'", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.52": {"text": "\u00bbach! ich bitte Sie! nicht weiter!", "tokens": ["\u00bb", "ach", "!", "ich", "bit\u00b7te", "Sie", "!", "nicht", "wei\u00b7ter", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "PPER", "VVFIN", "PPER", "$.", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.53": {"text": "(rief mir ein M\u00e4dchen zu von englischer Gestalt,)", "tokens": ["(", "rief", "mir", "ein", "M\u00e4d\u00b7chen", "zu", "von", "eng\u00b7li\u00b7scher", "Ge\u00b7stalt", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "PTKZU", "APPR", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Den Schl\u00fcssel hab' ich zwar, doch Ihnen aufzuschlie\u00dfen,", "tokens": ["Den", "Schl\u00fcs\u00b7sel", "hab'", "ich", "zwar", ",", "doch", "Ih\u00b7nen", "auf\u00b7zu\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "KON", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Sie wissen's selbst, verbeut die Tugend mir.", "tokens": ["Sie", "wis\u00b7sen's", "selbst", ",", "ver\u00b7beut", "die", "Tu\u00b7gend", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.56": {"text": "Ich Arme m\u00fc\u00dfte daf\u00fcr b\u00fc\u00dfen;", "tokens": ["Ich", "Ar\u00b7me", "m\u00fc\u00df\u00b7te", "da\u00b7f\u00fcr", "b\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VMFIN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Drum bitt' ich, bleiben Sie doch hier!\u00ab", "tokens": ["Drum", "bitt'", "ich", ",", "blei\u00b7ben", "Sie", "doch", "hier", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Was war zu thun? Aus Liebe f\u00fcr das Pferd,", "tokens": ["Was", "war", "zu", "thun", "?", "Aus", "Lie\u00b7be", "f\u00fcr", "das", "Pferd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PTKZU", "VVINF", "$.", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Und f\u00fcr das M\u00e4dchen selbst, lie\u00df ich mich gern beth\u00f6ren.", "tokens": ["Und", "f\u00fcr", "das", "M\u00e4d\u00b7chen", "selbst", ",", "lie\u00df", "ich", "mich", "gern", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$,", "VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "Vielleicht war's kl\u00fcger, umzukehren?", "tokens": ["Viel\u00b7leicht", "wa\u00b7r's", "kl\u00fc\u00b7ger", ",", "um\u00b7zu\u00b7keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "$,", "VVIZU", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.61": {"text": "Das thue, wer's von mir begehrt!", "tokens": ["Das", "thue", ",", "wer's", "von", "mir", "be\u00b7gehrt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.62": {"text": "Ich w\u00fc\u00dft' ihn diese Kunst wahrhaftig nicht zu lehren.", "tokens": ["Ich", "w\u00fc\u00dft'", "ihn", "die\u00b7se", "Kunst", "wahr\u00b7haf\u00b7tig", "nicht", "zu", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Ich blieb ein ganzes volles Jahr,", "tokens": ["Ich", "blieb", "ein", "gan\u00b7zes", "vol\u00b7les", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Und w\u00e4re wohl bis an den Tod geblieben,", "tokens": ["Und", "w\u00e4\u00b7re", "wohl", "bis", "an", "den", "Tod", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.65": {"text": "Doch ich, mit sammt dem Pferde, war", "tokens": ["Doch", "ich", ",", "mit", "sammt", "dem", "Pfer\u00b7de", ",", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "$,", "APPR", "APPR", "ART", "NN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.66": {"text": "Beinah vom Hunger aufgerieben.", "tokens": ["Bei\u00b7nah", "vom", "Hun\u00b7ger", "auf\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.67": {"text": "Fast nichts als Seufzer statt der Speise,", "tokens": ["Fast", "nichts", "als", "Seuf\u00b7zer", "statt", "der", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Fast nichts als Thr\u00e4nen nur, f\u00fcr Trank:", "tokens": ["Fast", "nichts", "als", "Thr\u00e4\u00b7nen", "nur", ",", "f\u00fcr", "Trank", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "ADV", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Wie war das auszustehn? Und, nach ", "tokens": ["Wie", "war", "das", "aus\u00b7zu\u00b7stehn", "?", "Und", ",", "nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "VAFIN", "PDS", "VVINF", "$.", "KON", "$,", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Mehr zu verlangen, brachte Zank;", "tokens": ["Mehr", "zu", "ver\u00b7lan\u00b7gen", ",", "brach\u00b7te", "Zank", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Drum sprang ich in den Sattel, sagte leise", "tokens": ["Drum", "sprang", "ich", "in", "den", "Sat\u00b7tel", ",", "sag\u00b7te", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.72": {"text": "F\u00fcr das Geno\u00dfne, sch\u00f6nen Dank!", "tokens": ["F\u00fcr", "das", "Ge\u00b7no\u00df\u00b7ne", ",", "sch\u00f6\u00b7nen", "Dank", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.73": {"text": "Und ging zur\u00fcck auf meiner Reise.", "tokens": ["Und", "ging", "zu\u00b7r\u00fcck", "auf", "mei\u00b7ner", "Rei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.74": {"text": "Das M\u00e4dchen sah mich schmachtend an,", "tokens": ["Das", "M\u00e4d\u00b7chen", "sah", "mich", "schmach\u00b7tend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Und dr\u00fcckte mir die Hand, und schlug die Augen nieder.", "tokens": ["Und", "dr\u00fcck\u00b7te", "mir", "die", "Hand", ",", "und", "schlug", "die", "Au\u00b7gen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "\u00bbein Wort, ein Wort! Ein Mann, ein Mann!", "tokens": ["\u00bb", "ein", "Wort", ",", "ein", "Wort", "!", "Ein", "Mann", ",", "ein", "Mann", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "$.", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "(sagt' ich beherzt,) Wir kommen sicher wieder,", "tokens": ["(", "sagt'", "ich", "be\u00b7herzt", ",", ")", "Wir", "kom\u00b7men", "si\u00b7cher", "wie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADJD", "$,", "$(", "PPER", "VVFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.78": {"text": "Wenn Mann und Pferd erst besser hungern kann.", "tokens": ["Wenn", "Mann", "und", "Pferd", "erst", "bes\u00b7ser", "hun\u00b7gern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.79": {"text": "Itzt aber m\u00f6cht' es, f\u00fcrcht' ich schier,", "tokens": ["Itzt", "a\u00b7ber", "m\u00f6cht'", "es", ",", "f\u00fcrcht'", "ich", "schier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Am Ende noch das ganze Spiel verderben;", "tokens": ["Am", "En\u00b7de", "noch", "das", "gan\u00b7ze", "Spiel", "ver\u00b7der\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.81": {"text": "Den weitern Weg verbeut der Schlagbaum mir,", "tokens": ["Den", "wei\u00b7tern", "Weg", "ver\u00b7beut", "der", "Schlag\u00b7baum", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.82": {"text": "Und bleiben wir noch l\u00e4nger hier,", "tokens": ["Und", "blei\u00b7ben", "wir", "noch", "l\u00e4n\u00b7ger", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "Wird Mann und Pferd bald an der Schwindsucht sterben!\u00ab", "tokens": ["Wird", "Mann", "und", "Pferd", "bald", "an", "der", "Schwind\u00b7sucht", "ster\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.84": {"text": "Das gute Thier, wie mancher Weise thut,", "tokens": ["Das", "gu\u00b7te", "Thier", ",", "wie", "man\u00b7cher", "Wei\u00b7se", "thut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.85": {"text": "Er r\u00e4th es wenigstens, ins freie Feld zu jagen,", "tokens": ["Er", "r\u00e4\u00b7th", "es", "we\u00b7nigs\u00b7tens", ",", "ins", "frei\u00b7e", "Feld", "zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.86": {"text": "Das konnt' ich nicht; ich war ihm viel zu gut,", "tokens": ["Das", "konnt'", "ich", "nicht", ";", "ich", "war", "ihm", "viel", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Und lieber wollt' ich mich noch l\u00e4nger mit ihm plagen.", "tokens": ["Und", "lie\u00b7ber", "wollt'", "ich", "mich", "noch", "l\u00e4n\u00b7ger", "mit", "ihm", "pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Ich bring' es, dacht' ich, wohl an Mann,", "tokens": ["Ich", "bring'", "es", ",", "dacht'", "ich", ",", "wohl", "an", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.89": {"text": "Ich h\u00e4rt' es auch vielleicht noch ab,", "tokens": ["Ich", "h\u00e4rt'", "es", "auch", "viel\u00b7leicht", "noch", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Bis sich's mit schmaler Kost den Hunger stillen kann;", "tokens": ["Bis", "sich's", "mit", "schma\u00b7ler", "Kost", "den", "Hun\u00b7ger", "stil\u00b7len", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wo nicht, so finden wir am Ende beid' ein Grab.", "tokens": ["Wo", "nicht", ",", "so", "fin\u00b7den", "wir", "am", "En\u00b7de", "beid'", "ein", "Grab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Das war dir eine Reiterei!", "tokens": ["Das", "war", "dir", "ei\u00b7ne", "Rei\u00b7te\u00b7rei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Am Geist', gedankenlos, am K\u00f6rper, wie zerschlagen,", "tokens": ["Am", "Geist'", ",", "ge\u00b7dan\u00b7ken\u00b7los", ",", "am", "K\u00f6r\u00b7per", ",", "wie", "zer\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADJD", "$,", "APPRART", "NN", "$,", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Ritt ich, wohin? das war mir einerlei!", "tokens": ["Ritt", "ich", ",", "wo\u00b7hin", "?", "das", "war", "mir", "ei\u00b7ner\u00b7lei", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "$.", "PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Ich brachte bald durch eine Schmeichelei", "tokens": ["Ich", "brach\u00b7te", "bald", "durch", "ei\u00b7ne", "Schmei\u00b7che\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.96": {"text": "Ein wenig neuen Muth dem armen Thiere bei,", "tokens": ["Ein", "we\u00b7nig", "neu\u00b7en", "Muth", "dem", "ar\u00b7men", "Thie\u00b7re", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Bald wollt' ich's fort zum Kuckuck jagen.", "tokens": ["Bald", "wollt'", "ich's", "fort", "zum", "Ku\u00b7ckuck", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKVZ", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Ein h\u00fcbsches Weilchen schw\u00e4rmt' ich so herum,", "tokens": ["Ein", "h\u00fcb\u00b7sches", "Weil\u00b7chen", "schw\u00e4rmt'", "ich", "so", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.99": {"text": "Die mehrste Zeit in \u00f6den Eichenhainen;", "tokens": ["Die", "mehrs\u00b7te", "Zeit", "in", "\u00f6\u00b7den", "Ei\u00b7chen\u00b7hai\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.100": {"text": "Ging, wie du denken kannst, mit Reden sparsam um,", "tokens": ["Ging", ",", "wie", "du", "den\u00b7ken", "kannst", ",", "mit", "Re\u00b7den", "spar\u00b7sam", "um", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,", "APPR", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Doch sehr verschwenderisch mit Weinen:", "tokens": ["Doch", "sehr", "ver\u00b7schwen\u00b7de\u00b7risch", "mit", "Wei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.102": {"text": "Doch, was dir sonderbar wird scheinen,", "tokens": ["Doch", ",", "was", "dir", "son\u00b7der\u00b7bar", "wird", "schei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADJD", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.103": {"text": "Ich wu\u00dfte selbst nicht recht, warum?", "tokens": ["Ich", "wu\u00df\u00b7te", "selbst", "nicht", "recht", ",", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADJD", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Zum Gl\u00fccke kann ein gro\u00dfer Schmerz", "tokens": ["Zum", "Gl\u00fc\u00b7cke", "kann", "ein", "gro\u00b7\u00dfer", "Schmerz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "Nicht gar zu lang am Herzen nagen;", "tokens": ["Nicht", "gar", "zu", "lang", "am", "Her\u00b7zen", "na\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKA", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "Entweder fri\u00dft er bald des Kranken Herz,", "tokens": ["Ent\u00b7we\u00b7der", "fri\u00dft", "er", "bald", "des", "Kran\u00b7ken", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.107": {"text": "Wo nicht, so nimmt er ab, und l\u00e4\u00dft sich dann ertragen.", "tokens": ["Wo", "nicht", ",", "so", "nimmt", "er", "ab", ",", "und", "l\u00e4\u00dft", "sich", "dann", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Die\u00df letzte war der Fall mit mir.", "tokens": ["Die\u00df", "letz\u00b7te", "war", "der", "Fall", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.109": {"text": "Da konnt' ich denn auch leicht den Weisen wieder machen,", "tokens": ["Da", "konnt'", "ich", "denn", "auch", "leicht", "den", "Wei\u00b7sen", "wie\u00b7der", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Mich h\u00f6chlich wundern, wie ich schier,", "tokens": ["Mich", "h\u00f6ch\u00b7lich", "wun\u00b7dern", ",", "wie", "ich", "schier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "$,", "PWAV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.111": {"text": "So toll und blind, dem Ungl\u00fcck' in den Rachen", "tokens": ["So", "toll", "und", "blind", ",", "dem", "Un\u00b7gl\u00fcck", "in", "den", "Ra\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.112": {"text": "Zu rennen, in Gefahr gestanden, ernstlich mir", "tokens": ["Zu", "ren\u00b7nen", ",", "in", "Ge\u00b7fahr", "ge\u00b7stan\u00b7den", ",", "ernst\u00b7lich", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "APPR", "NN", "VVPP", "$,", "ADJD", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Die Unbesonnenheit verweisen,", "tokens": ["Die", "Un\u00b7be\u00b7son\u00b7nen\u00b7heit", "ver\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.114": {"text": "So lang auf einem solchen Thier'", "tokens": ["So", "lang", "auf", "ei\u00b7nem", "sol\u00b7chen", "Thier'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "In solcher Irr' herum zu reisen,", "tokens": ["In", "sol\u00b7cher", "Irr'", "he\u00b7rum", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Und endlich, sch\u00e4mt ich mich daf\u00fcr,", "tokens": ["Und", "end\u00b7lich", ",", "sch\u00e4mt", "ich", "mich", "da\u00b7f\u00fcr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "PRF", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Warum ich doch mich so vergebens gr\u00e4mte?", "tokens": ["Wa\u00b7rum", "ich", "doch", "mich", "so", "ver\u00b7ge\u00b7bens", "gr\u00e4m\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.118": {"text": "Itzt aber, ich gesteh' es dir,", "tokens": ["Itzt", "a\u00b7ber", ",", "ich", "ge\u00b7steh'", "es", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "Das kl\u00fcgste war, ich lie\u00df mein Steckenpferd", "tokens": ["Das", "kl\u00fcgs\u00b7te", "war", ",", "ich", "lie\u00df", "mein", "Ste\u00b7cken\u00b7pferd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.120": {"text": "Mit einem tiefen Seufzer stehen,", "tokens": ["Mit", "ei\u00b7nem", "tie\u00b7fen", "Seuf\u00b7zer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.121": {"text": "Ging hurtig fort, und schwur, mich nicht mehr umzusehen,", "tokens": ["Ging", "hur\u00b7tig", "fort", ",", "und", "schwur", ",", "mich", "nicht", "mehr", "um\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "$,", "PPER", "PTKNEG", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Das \u00fcbrige \u2013 war keinen Dreier werth.", "tokens": ["Das", "\u00fcb\u00b7ri\u00b7ge", "\u2013", "war", "kei\u00b7nen", "Drei\u00b7er", "werth", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "VAFIN", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.123": {"text": "Fort war das Thier; ich kehrte nun zu Fu\u00dfe", "tokens": ["Fort", "war", "das", "Thier", ";", "ich", "kehr\u00b7te", "nun", "zu", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.124": {"text": "Nach Haus zur\u00fcck, und that f\u00fcr meinen Ritt,", "tokens": ["Nach", "Haus", "zu\u00b7r\u00fcck", ",", "und", "that", "f\u00fcr", "mei\u00b7nen", "Ritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.125": {"text": "Wenn Bu\u00dfe n\u00f6thig war, durch Pilgrimschaften Bu\u00dfe.", "tokens": ["Wenn", "Bu\u00b7\u00dfe", "n\u00f6\u00b7thig", "war", ",", "durch", "Pil\u00b7grim\u00b7schaf\u00b7ten", "Bu\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "VAFIN", "$,", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Das ging zwar anfangs gut, allein das: Schritt vor Schritt!", "tokens": ["Das", "ging", "zwar", "an\u00b7fangs", "gut", ",", "al\u00b7lein", "das", ":", "Schritt", "vor", "Schritt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "ADJD", "$,", "ADV", "PDS", "$.", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Erm\u00fcdet und macht \u00e4rgerlich.", "tokens": ["Er\u00b7m\u00fc\u00b7det", "und", "macht", "\u00e4r\u00b7ger\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Und welcher Mensch, mit so viel Mu\u00dfe,", "tokens": ["Und", "wel\u00b7cher", "Mensch", ",", "mit", "so", "viel", "Mu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "$,", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.129": {"text": "Mit so viel Trieb herum zu ziehn, als ich,", "tokens": ["Mit", "so", "viel", "Trieb", "he\u00b7rum", "zu", "ziehn", ",", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.130": {"text": "Geht wie ein Pilger gern zu Fu\u00dfe?", "tokens": ["Geht", "wie", "ein", "Pil\u00b7ger", "gern", "zu", "Fu\u00b7\u00dfe", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.131": {"text": "Wer reiten kann, der nehm' es mit!", "tokens": ["Wer", "rei\u00b7ten", "kann", ",", "der", "nehm'", "es", "mit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VMFIN", "$,", "PRELS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.132": {"text": "Sagt, was ihr wollt, der Weg, den auf der Erde", "tokens": ["Sagt", ",", "was", "ihr", "wollt", ",", "der", "Weg", ",", "den", "auf", "der", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.133": {"text": "Der Mensch zu gehen hat, wird jedem oft zu lang.", "tokens": ["Der", "Mensch", "zu", "ge\u00b7hen", "hat", ",", "wird", "je\u00b7dem", "oft", "zu", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VAFIN", "$,", "VAFIN", "PIS", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Es leben denn die Steckenpferde!", "tokens": ["Es", "le\u00b7ben", "denn", "die", "Ste\u00b7cken\u00b7pfer\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.135": {"text": "Sie gehen einen raschen Gang,", "tokens": ["Sie", "ge\u00b7hen", "ei\u00b7nen", "ra\u00b7schen", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.136": {"text": "Und mehrentheils doch ohne viel Beschwerde.", "tokens": ["Und", "meh\u00b7ren\u00b7theils", "doch", "oh\u00b7ne", "viel", "Be\u00b7schwer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.137": {"text": "Doch auf die Wahl kommt's freilich an;", "tokens": ["Doch", "auf", "die", "Wahl", "kommt's", "frei\u00b7lich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.138": {"text": "Ist's bei\u00dfig, oder sonnensch\u00fc\u00dfig,", "tokens": ["Ist's", "bei\u00b7\u00dfig", ",", "o\u00b7der", "son\u00b7nen\u00b7sch\u00fc\u00b7\u00dfig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.139": {"text": "Hartm\u00e4ulig, scheu, und was noch sonst daran", "tokens": ["Hart\u00b7m\u00e4u\u00b7lig", ",", "scheu", ",", "und", "was", "noch", "sonst", "da\u00b7ran"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "KON", "PWS", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.140": {"text": "Ein \u00e4chter Kenner tadeln kann,", "tokens": ["Ein", "\u00e4ch\u00b7ter", "Ken\u00b7ner", "ta\u00b7deln", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.141": {"text": "So wird man bald des Dinges \u00fcberdr\u00fc\u00dfig.", "tokens": ["So", "wird", "man", "bald", "des", "Din\u00b7ges", "\u00fc\u00b7berd\u00b7r\u00fc\u00b7\u00dfig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.142": {"text": "Mein Weg ging \u00fcber ", "tokens": ["Mein", "Weg", "ging", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.143": {"text": "Da willst du dich bei ", "tokens": ["Da", "willst", "du", "dich", "bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.144": {"text": "Ob der vielleicht ein be\u00dfres Stockpferd hat?", "tokens": ["Ob", "der", "viel\u00b7leicht", "ein", "be\u00df\u00b7res", "Stock\u00b7pferd", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.145": {"text": "Ich kam. Er schwur mit hundert Schw\u00fcren,", "tokens": ["Ich", "kam", ".", "Er", "schwur", "mit", "hun\u00b7dert", "Schw\u00fc\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.146": {"text": "Solch gutes Steckenpferd sey nicht mehr in der Stadt!", "tokens": ["Solch", "gu\u00b7tes", "Ste\u00b7cken\u00b7pferd", "sey", "nicht", "mehr", "in", "der", "Stadt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Nun gut! die Th\u00fcr ging auf; sieh da! da stand im Stalle", "tokens": ["Nun", "gut", "!", "die", "Th\u00fcr", "ging", "auf", ";", "sieh", "da", "!", "da", "stand", "im", "Stal\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$.", "VVIMP", "ADV", "$.", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Mein kaum verla\u00dfnes Steckenpferd,", "tokens": ["Mein", "kaum", "ver\u00b7la\u00df\u00b7nes", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.149": {"text": "Nur hatt' es schon noch \u00e4rger abgezehrt,", "tokens": ["Nur", "hatt'", "es", "schon", "noch", "\u00e4r\u00b7ger", "ab\u00b7ge\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.150": {"text": "Denn, Freund, sein Herr war grad' in meinem Falle.", "tokens": ["Denn", ",", "Freund", ",", "sein", "Herr", "war", "grad'", "in", "mei\u00b7nem", "Fal\u00b7le", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.151": {"text": "\u00bbgl\u00fcck zu! Gl\u00fcck zu! mein lieber Freund!", "tokens": ["\u00bb", "gl\u00fcck", "zu", "!", "Gl\u00fcck", "zu", "!", "mein", "lie\u00b7ber", "Freund", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "NN", "PTKVZ", "$.", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.152": {"text": "Das Thierchen hat mich auch getragen.", "tokens": ["Das", "Thier\u00b7chen", "hat", "mich", "auch", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.153": {"text": "Nimm dich damit in Acht, so fromm es immer scheint!", "tokens": ["Nimm", "dich", "da\u00b7mit", "in", "Acht", ",", "so", "fromm", "es", "im\u00b7mer", "scheint", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "PAV", "APPR", "CARD", "$,", "ADV", "ADJD", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Du freilich kannst es mit ihm wagen:", "tokens": ["Du", "frei\u00b7lich", "kannst", "es", "mit", "ihm", "wa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.155": {"text": "Denn, wenn es auch, wie man zu w\u00e4hnen pflegt,", "tokens": ["Denn", ",", "wenn", "es", "auch", ",", "wie", "man", "zu", "w\u00e4h\u00b7nen", "pflegt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "$,", "PWAV", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.156": {"text": "Zu Paphos Myrtenhain nicht tr\u00e4gt,", "tokens": ["Zu", "Pa\u00b7phos", "Myr\u00b7ten\u00b7hain", "nicht", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.157": {"text": "Kann's doch zum Lorbeerhain' auf Pindus Gipfel tragen.", "tokens": ["Kann's", "doch", "zum", "Lor\u00b7beer\u00b7hain'", "auf", "Pin\u00b7dus", "Gip\u00b7fel", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Drum rath' ich selbst, behalt' es, lieber Mann,", "tokens": ["Drum", "ra\u00b7th'", "ich", "selbst", ",", "be\u00b7halt'", "es", ",", "lie\u00b7ber", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.159": {"text": "So lang es Futter mag, und sicher geht im Schritt',", "tokens": ["So", "lang", "es", "Fut\u00b7ter", "mag", ",", "und", "si\u00b7cher", "geht", "im", "Schritt'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VMFIN", "$,", "KON", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Doch wird es krippens\u00e4tzig, f\u00e4ngt es an,", "tokens": ["Doch", "wird", "es", "krip\u00b7pen\u00b7s\u00e4t\u00b7zig", ",", "f\u00e4ngt", "es", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.161": {"text": "Sich brav zu baumen; fort damit!", "tokens": ["Sich", "brav", "zu", "bau\u00b7men", ";", "fort", "da\u00b7mit", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKZU", "VVINF", "$.", "PTKVZ", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Ich mag es gern von dir itzt reiten sehn,", "tokens": ["Ich", "mag", "es", "gern", "von", "dir", "itzt", "rei\u00b7ten", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "PPER", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.163": {"text": "Es f\u00e4llt mir dann so ein, wie ich es selbst noch ritt,", "tokens": ["Es", "f\u00e4llt", "mir", "dann", "so", "ein", ",", "wie", "ich", "es", "selbst", "noch", "ritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,", "PWAV", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Und die Erinnrung bleibt doch sch\u00f6n.", "tokens": ["Und", "die", "E\u00b7rinn\u00b7rung", "bleibt", "doch", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.165": {"text": "Denn denke nur, es trug mich Jahr' und Wochen,", "tokens": ["Denn", "den\u00b7ke", "nur", ",", "es", "trug", "mich", "Jahr'", "und", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.166": {"text": "Und doch hat meine Tugend nicht", "tokens": ["Und", "doch", "hat", "mei\u00b7ne", "Tu\u00b7gend", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.167": {"text": "Den Hals darauf gebrochen,", "tokens": ["Den", "Hals", "da\u00b7rauf", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.168": {"text": "Den sie so leicht auf diesem Pferde bricht.", "tokens": ["Den", "sie", "so", "leicht", "auf", "die\u00b7sem", "Pfer\u00b7de", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.169": {"text": "Bei allen seinen Unbequemlichkeiten,", "tokens": ["Bei", "al\u00b7len", "sei\u00b7nen", "Un\u00b7be\u00b7quem\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.170": {"text": "(denn ach! es war und bleibt ein sch\u00f6nes Steckenpferd!)", "tokens": ["(", "denn", "ach", "!", "es", "war", "und", "bleibt", "ein", "sch\u00f6\u00b7nes", "Ste\u00b7cken\u00b7pferd", "!", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "XY", "$.", "PPER", "VAFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "W\u00fcrd' ich's gewi\u00df noch heute reiten,", "tokens": ["W\u00fcrd'", "ich's", "ge\u00b7wi\u00df", "noch", "heu\u00b7te", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.172": {"text": "Nur hat ihm die Natur die Dauer nicht gew\u00e4hrt.", "tokens": ["Nur", "hat", "ihm", "die", "Na\u00b7tur", "die", "Dau\u00b7er", "nicht", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Doch h\u00e4tt' es, wie Petrarch von seinem spricht,", "tokens": ["Doch", "h\u00e4tt'", "es", ",", "wie", "Pe\u00b7trarch", "von", "sei\u00b7nem", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$,", "PWAV", "NE", "APPR", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.174": {"text": "Die Dauer auch, so hatt's doch etwas T\u00fccke;", "tokens": ["Die", "Dau\u00b7er", "auch", ",", "so", "hatt's", "doch", "et\u00b7was", "T\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADV", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.175": {"text": "Kann seyn, da\u00df ich mich nicht zu seinem Reiter schicke;", "tokens": ["Kann", "seyn", ",", "da\u00df", "ich", "mich", "nicht", "zu", "sei\u00b7nem", "Rei\u00b7ter", "schi\u00b7cke", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Wie dem auch sey, ich trau' ihm weiter nicht.", "tokens": ["Wie", "dem", "auch", "sey", ",", "ich", "trau'", "ihm", "wei\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.177": {"text": "Man ist darauf wie angepicht,", "tokens": ["Man", "ist", "da\u00b7rauf", "wie", "an\u00b7ge\u00b7picht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.178": {"text": "Will immer ab, und trabt in einem St\u00fccke", "tokens": ["Will", "im\u00b7mer", "ab", ",", "und", "trabt", "in", "ei\u00b7nem", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.179": {"text": "Nur weiter fort, als h\u00f6rt' und s\u00e4h' man nicht;", "tokens": ["Nur", "wei\u00b7ter", "fort", ",", "als", "h\u00f6rt'", "und", "s\u00e4h'", "man", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "VVFIN", "KON", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.180": {"text": "Ja, macht den Z\u00fcgel gar wohl selbst f\u00fcr sich zum Stricke,", "tokens": ["Ja", ",", "macht", "den", "Z\u00fc\u00b7gel", "gar", "wohl", "selbst", "f\u00fcr", "sich", "zum", "Stri\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ART", "NN", "ADV", "ADV", "ADV", "APPR", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Wie man so was vom jungen ", "tokens": ["Wie", "man", "so", "was", "vom", "jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PWS", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.182": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.183": {"text": "Springt man gew\u00f6hnlich auf ein Thier,", "tokens": ["Springt", "man", "ge\u00b7w\u00f6hn\u00b7lich", "auf", "ein", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.184": {"text": "Das immer mit fliegender M\u00e4hn' und Wiehern und frecher Geberde", "tokens": ["Das", "im\u00b7mer", "mit", "flie\u00b7gen\u00b7der", "M\u00e4hn'", "und", "Wie\u00b7hern", "und", "fre\u00b7cher", "Ge\u00b7ber\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+--+--+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.185": {"text": "Mit seinem Reiter lauft, wohin es die Begier", "tokens": ["Mit", "sei\u00b7nem", "Rei\u00b7ter", "lauft", ",", "wo\u00b7hin", "es", "die", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PWAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Mit ihrer Peitsche treibt. ", "tokens": ["Mit", "ih\u00b7rer", "Peit\u00b7sche", "treibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.187": {"text": "Und jede List und jede Kunst gelehrt.", "tokens": ["Und", "je\u00b7de", "List", "und", "je\u00b7de", "Kunst", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.188": {"text": "Er ist damit fast \u00fcberall gelitten,", "tokens": ["Er", "ist", "da\u00b7mit", "fast", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.189": {"text": "Auch zeigt er gern, wenn man's von ihm begehrt,", "tokens": ["Auch", "zeigt", "er", "gern", ",", "wenn", "man's", "von", "ihm", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.190": {"text": "Wie Reiter dieses Steckenpferd", "tokens": ["Wie", "Rei\u00b7ter", "die\u00b7ses", "Ste\u00b7cken\u00b7pferd"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.191": {"text": "Schulm\u00e4\u00dfig zu regieren haben,", "tokens": ["Schul\u00b7m\u00e4\u00b7\u00dfig", "zu", "re\u00b7gie\u00b7ren", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.192": {"text": "Wie man bald \u00fcber Mauern, \u00fcber Graben,", "tokens": ["Wie", "man", "bald", "\u00fc\u00b7ber", "Mau\u00b7ern", ",", "\u00fc\u00b7ber", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.193": {"text": "Und bald durch ein Verhack mit k\u00fchnen Spr\u00fcngen setzt,", "tokens": ["Und", "bald", "durch", "ein", "Ver\u00b7hack", "mit", "k\u00fch\u00b7nen", "Spr\u00fcn\u00b7gen", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Wie man zu rechter Zeit Schritt reiten oder traben,", "tokens": ["Wie", "man", "zu", "rech\u00b7ter", "Zeit", "Schritt", "rei\u00b7ten", "o\u00b7der", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ADJA", "NN", "NN", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Auch galoppiren mu\u00df, und wie man so zuletzt,", "tokens": ["Auch", "ga\u00b7lop\u00b7pi\u00b7ren", "mu\u00df", ",", "und", "wie", "man", "so", "zu\u00b7letzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$,", "KON", "PWAV", "PIS", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Die Tugend selbst im Fliehen m\u00fcde hetzt.", "tokens": ["Die", "Tu\u00b7gend", "selbst", "im", "Flie\u00b7hen", "m\u00fc\u00b7de", "hetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.197": {"text": "Das Thier mag freilich mehr erg\u00f6tzen,", "tokens": ["Das", "Thier", "mag", "frei\u00b7lich", "mehr", "er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.198": {"text": "Als jenes, Freund, wozu mir Plato rieth;", "tokens": ["Als", "je\u00b7nes", ",", "Freund", ",", "wo\u00b7zu", "mir", "Pla\u00b7to", "rieth", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "NN", "$,", "PWAV", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.199": {"text": "Nur, halten Sie zu Gnaden, Herr Ovid!", "tokens": ["Nur", ",", "hal\u00b7ten", "Sie", "zu", "Gna\u00b7den", ",", "Herr", "O\u00b7vid", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "APPR", "NN", "$,", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.200": {"text": "Wenn wir das ihrige nicht recht nach W\u00fcrden sch\u00e4tzen.", "tokens": ["Wenn", "wir", "das", "ih\u00b7ri\u00b7ge", "nicht", "recht", "nach", "W\u00fcr\u00b7den", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PPOSS", "PTKNEG", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Zwar will ich, nach Petrarchs Manier,", "tokens": ["Zwar", "will", "ich", ",", "nach", "Pe\u00b7trarchs", "Ma\u00b7nier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.202": {"text": "Nicht immer mich am Lob' des andern letzen,", "tokens": ["Nicht", "im\u00b7mer", "mich", "am", "Lob'", "des", "an\u00b7dern", "let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "APPRART", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.203": {"text": "Doch d\u00fcnkt mich, pa\u00dft das Spr\u00fcchwort hier:", "tokens": ["Doch", "d\u00fcnkt", "mich", ",", "pa\u00dft", "das", "Spr\u00fcch\u00b7wort", "hier", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.204": {"text": "Vom Pferde sich auf einen Esel setzen.", "tokens": ["Vom", "Pfer\u00b7de", "sich", "auf", "ei\u00b7nen", "E\u00b7sel", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.205": {"text": "Ich denke so: Wenn dir damit der Mann", "tokens": ["Ich", "den\u00b7ke", "so", ":", "Wenn", "dir", "da\u00b7mit", "der", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "KOUS", "PPER", "PAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.206": {"text": "In dein Gehege kommt, wer hat es auszubaden?", "tokens": ["In", "dein", "Ge\u00b7he\u00b7ge", "kommt", ",", "wer", "hat", "es", "aus\u00b7zu\u00b7ba\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PWS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.208": {"text": "Da Plato nie dir schaden kann.", "tokens": ["Da", "Pla\u00b7to", "nie", "dir", "scha\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.209": {"text": "La\u00dft Andre mit dem Spruche scherzen,", "tokens": ["La\u00dft", "And\u00b7re", "mit", "dem", "Spru\u00b7che", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.210": {"text": "Sch\u00f6n ist's doch, wenn in ", "tokens": ["Sch\u00f6n", "ist's", "doch", ",", "wenn", "in"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "$,", "KOUS", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.211": {"text": "Ein Trieb, ihn zu erf\u00fcllen, gl\u00fcht. \u2013", "tokens": ["Ein", "Trieb", ",", "ihn", "zu", "er\u00b7f\u00fcl\u00b7len", ",", "gl\u00fcht", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.212": {"text": "Du kennst den Steckenpferde-Markt,", "tokens": ["Du", "kennst", "den", "Ste\u00b7cken\u00b7pfer\u00b7de\u00b7Markt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.213": {"text": "Wohin den K\u00f6nig, der ein Land regieret,", "tokens": ["Wo\u00b7hin", "den", "K\u00f6\u00b7nig", ",", "der", "ein", "Land", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.214": {"text": "So wie den Bettler, der zusammen harkt,", "tokens": ["So", "wie", "den", "Bett\u00b7ler", ",", "der", "zu\u00b7sam\u00b7men", "harkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.215": {"text": "Was in der Stoppel sich verlieret,", "tokens": ["Was", "in", "der", "Stop\u00b7pel", "sich", "ver\u00b7lie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.216": {"text": "Der Wunsch, bequem zu reiten, f\u00fchret.", "tokens": ["Der", "Wunsch", ",", "be\u00b7quem", "zu", "rei\u00b7ten", ",", "f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "PTKZU", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.217": {"text": "Ich schlenderte darauf umher,", "tokens": ["Ich", "schlen\u00b7der\u00b7te", "da\u00b7rauf", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.218": {"text": "Und w\u00fcnscht' ein Steckenpferd zu haben,", "tokens": ["Und", "w\u00fcnscht'", "ein", "Ste\u00b7cken\u00b7pferd", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.219": {"text": "Nicht v\u00f6llig so, doch ohngef\u00e4hr", "tokens": ["Nicht", "v\u00f6l\u00b7lig", "so", ",", "doch", "ohn\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "ADJD", "ADV", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.220": {"text": "Mit solchen sonderbaren Gaben,", "tokens": ["Mit", "sol\u00b7chen", "son\u00b7der\u00b7ba\u00b7ren", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.221": {"text": "Als das, was ", "tokens": ["Als", "das", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "PDS", "$,", "PWS"], "meter": "+-+", "measure": "trochaic.di"}, "line.222": {"text": "Nicht um des Sonderbaren willen;", "tokens": ["Nicht", "um", "des", "Son\u00b7der\u00b7ba\u00b7ren", "wil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.223": {"text": "Das w\u00e4re toller noch als toll!", "tokens": ["Das", "w\u00e4\u00b7re", "tol\u00b7ler", "noch", "als", "toll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "ADV", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.224": {"text": "Ach nein! Ich sah mit meinen Grillen", "tokens": ["Ach", "nein", "!", "Ich", "sah", "mit", "mei\u00b7nen", "Gril\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.225": {"text": "Den einen Theil f\u00fcr wilde F\u00fcllen,", "tokens": ["Den", "ei\u00b7nen", "Theil", "f\u00fcr", "wil\u00b7de", "F\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.226": {"text": "Den andern Theil f\u00fcr steife M\u00e4hren an.", "tokens": ["Den", "an\u00b7dern", "Theil", "f\u00fcr", "stei\u00b7fe", "M\u00e4h\u00b7ren", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.227": {"text": "Ich hatte, wenn ich mich besann,", "tokens": ["Ich", "hat\u00b7te", ",", "wenn", "ich", "mich", "be\u00b7sann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.228": {"text": "Die mehrsten schon vordem geritten,", "tokens": ["Die", "mehrs\u00b7ten", "schon", "vor\u00b7dem", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.229": {"text": "Und wie bedauert' ich den Mann,", "tokens": ["Und", "wie", "be\u00b7dau\u00b7ert'", "ich", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.230": {"text": "Der Eins davon bestieg; was ich darauf erlitten,", "tokens": ["Der", "Eins", "da\u00b7von", "be\u00b7stieg", ";", "was", "ich", "da\u00b7rauf", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVFIN", "$.", "PWS", "PPER", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Dacht' ich betr\u00fcbt, das ficht auf seinen Ritten", "tokens": ["Dacht'", "ich", "be\u00b7tr\u00fcbt", ",", "das", "ficht", "auf", "sei\u00b7nen", "Rit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "PRELS", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.232": {"text": "Ihn sicher auch, wohl noch was \u00e4rgers an.", "tokens": ["Ihn", "si\u00b7cher", "auch", ",", "wohl", "noch", "was", "\u00e4r\u00b7gers", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "$,", "ADV", "ADV", "PWS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.233": {"text": "Tagt\u00e4glich sucht' ich da sechs Stunden,", "tokens": ["Tag\u00b7t\u00e4g\u00b7lich", "sucht'", "ich", "da", "sechs", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.234": {"text": "Doch keins gefiel mir recht. Vielleicht aus Ueberdru\u00df,", "tokens": ["Doch", "keins", "ge\u00b7fiel", "mir", "recht", ".", "Viel\u00b7leicht", "aus", "Ue\u00b7berd\u00b7ru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "ADJD", "$.", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Weil ich gerade keins gefunden,", "tokens": ["Weil", "ich", "ge\u00b7ra\u00b7de", "keins", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.236": {"text": "Das mir nach Sinne ging, macht' ich den falschen Schlu\u00df:", "tokens": ["Das", "mir", "nach", "Sin\u00b7ne", "ging", ",", "macht'", "ich", "den", "fal\u00b7schen", "Schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Ein Steckenpferd, das selten zum Verdru\u00df',", "tokens": ["Ein", "Ste\u00b7cken\u00b7pferd", ",", "das", "sel\u00b7ten", "zum", "Ver\u00b7dru\u00df'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.238": {"text": "Oft zum Vergn\u00fcgen trabt, sey mit ", "tokens": ["Oft", "zum", "Ver\u00b7gn\u00fc\u00b7gen", "trabt", ",", "sey", "mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$,", "VAFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.239": {"text": "Aus diesem Jammerthal' verschwunden.", "tokens": ["Aus", "die\u00b7sem", "Jam\u00b7mert\u00b7hal'", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.240": {"text": "Ei nicht doch! riefen viele weise M\u00e4nner,", "tokens": ["Ei", "nicht", "doch", "!", "rie\u00b7fen", "vie\u00b7le", "wei\u00b7se", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "$.", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.241": {"text": "Wir sind die rechten Steckenpferde-Kenner,", "tokens": ["Wir", "sind", "die", "rech\u00b7ten", "Ste\u00b7cken\u00b7pfer\u00b7de\u00b7Ken\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.242": {"text": "Wie unser Ruhm das schon bezeugen mu\u00df.", "tokens": ["Wie", "un\u00b7ser", "Ruhm", "das", "schon", "be\u00b7zeu\u00b7gen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "ADV", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.243": {"text": "Allein ein ", "tokens": ["Al\u00b7lein", "ein"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.244": {"text": "Das ist nur Sache f\u00fcr den Tro\u00df!", "tokens": ["Das", "ist", "nur", "Sa\u00b7che", "f\u00fcr", "den", "Tro\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.245": {"text": "Doch will der Herr ein stattlich ", "tokens": ["Doch", "will", "der", "Herr", "ein", "statt\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.246": {"text": "So k\u00f6nnen wir ihm schier das Beste weisen.", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "ihm", "schier", "das", "Bes\u00b7te", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.247": {"text": "Der D\u00fcnkel, ein Paradepferd", "tokens": ["Der", "D\u00fcn\u00b7kel", ",", "ein", "Pa\u00b7ra\u00b7de\u00b7pferd"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.248": {"text": "Wie Herr ", "tokens": ["Wie", "Herr"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.249": {"text": "Den Mancher noch als Mann erf\u00e4hrt,", "tokens": ["Den", "Man\u00b7cher", "noch", "als", "Mann", "er\u00b7f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.250": {"text": "Der sollte mich als J\u00fcngling nicht verleiten?", "tokens": ["Der", "soll\u00b7te", "mich", "als", "J\u00fcng\u00b7ling", "nicht", "ver\u00b7lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "KOUS", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.251": {"text": "Mit einem ernsten Angesicht',", "tokens": ["Mit", "ei\u00b7nem", "erns\u00b7ten", "An\u00b7ge\u00b7sicht'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.252": {"text": "Bestieg ich dieses Ro\u00df, und ritt, (ich hielt's f\u00fcr Pflicht!)", "tokens": ["Be\u00b7stieg", "ich", "die\u00b7ses", "Ro\u00df", ",", "und", "ritt", ",", "(", "ich", "hielt's", "f\u00fcr", "Pflicht", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "$,", "KON", "VVFIN", "$,", "$(", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Bei Tag und Nacht, und \u00fcber Stock und Stein,", "tokens": ["Bei", "Tag", "und", "Nacht", ",", "und", "\u00fc\u00b7ber", "Stock", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "KON", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.254": {"text": "Den Weisheitstempel aufzufinden,", "tokens": ["Den", "Weis\u00b7heits\u00b7tem\u00b7pel", "auf\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.255": {"text": "Ach aber, ach! ich fand ihn nicht.", "tokens": ["Ach", "a\u00b7ber", ",", "ach", "!", "ich", "fand", "ihn", "nicht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "ITJ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.256": {"text": "Itzt seh' ich wohl die Ursach' ein:", "tokens": ["Itzt", "seh'", "ich", "wohl", "die", "Ur\u00b7sach'", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.257": {"text": "Ich ritt, was leugn' ich's noch? im Blinden!", "tokens": ["Ich", "ritt", ",", "was", "leugn'", "ich's", "noch", "?", "im", "Blin\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "VVFIN", "PIS", "ADV", "$.", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.258": {"text": "Sonst h\u00e4tt' ich wohl den Fu\u00dfsteg sehen m\u00fcssen,", "tokens": ["Sonst", "h\u00e4tt'", "ich", "wohl", "den", "Fu\u00df\u00b7steg", "se\u00b7hen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.259": {"text": "Der zwischen zwei bebl\u00fcmten Fl\u00fcssen", "tokens": ["Der", "zwi\u00b7schen", "zwei", "be\u00b7bl\u00fcm\u00b7ten", "Fl\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.260": {"text": "Auf Rasen hin, zum Tempel lief.", "tokens": ["Auf", "Ra\u00b7sen", "hin", ",", "zum", "Tem\u00b7pel", "lief", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.261": {"text": "Auf einmal h\u00f6rt' ich eine Stimme,", "tokens": ["Auf", "ein\u00b7mal", "h\u00f6rt'", "ich", "ei\u00b7ne", "Stim\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.262": {"text": "Die, von ", "tokens": ["Die", ",", "von"], "token_info": ["word", "punct", "word"], "pos": ["ART", "$,", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.263": {"text": "\u00bbwo wollt Ihr hin? Ihr reitet in die Kr\u00fcmme!", "tokens": ["\u00bb", "wo", "wollt", "Ihr", "hin", "?", "Ihr", "rei\u00b7tet", "in", "die", "Kr\u00fcm\u00b7me", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.264": {"text": "Euch hat der Tr\u00fcbsinn ohne Streit", "tokens": ["Euch", "hat", "der", "Tr\u00fcb\u00b7sinn", "oh\u00b7ne", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.265": {"text": "Auf diesen Kn\u00fcppeldamm geleitet,", "tokens": ["Auf", "die\u00b7sen", "Kn\u00fcp\u00b7pel\u00b7damm", "ge\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.266": {"text": "Doch wi\u00dft, zu kurz ist oft die Lebenszeit,", "tokens": ["Doch", "wi\u00dft", ",", "zu", "kurz", "ist", "oft", "die", "Le\u00b7bens\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PTKA", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.267": {"text": "Und wenn Ihr noch so scharf auch reitet,", "tokens": ["Und", "wenn", "Ihr", "noch", "so", "scharf", "auch", "rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.268": {"text": "Den Tempel zu erreichen: denn so weit", "tokens": ["Den", "Tem\u00b7pel", "zu", "er\u00b7rei\u00b7chen", ":", "denn", "so", "weit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$.", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.269": {"text": "H\u00e4lt's Niemand aus; er wird, wie ein Courier,", "tokens": ["H\u00e4lt's", "Nie\u00b7mand", "aus", ";", "er", "wird", ",", "wie", "ein", "Cou\u00b7rier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PTKVZ", "$.", "PPER", "VAFIN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.270": {"text": "Wund, lahm, und mu\u00df wohl gar am Ende liegen bleiben.", "tokens": ["Wund", ",", "lahm", ",", "und", "mu\u00df", "wohl", "gar", "am", "En\u00b7de", "lie\u00b7gen", "blei\u00b7ben", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "KON", "VMFIN", "ADV", "ADV", "APPRART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Doch, guter Freund! sollt' Euch die Ruhmbegier", "tokens": ["Doch", ",", "gu\u00b7ter", "Freund", "!", "sollt'", "Euch", "die", "Ruhm\u00b7be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJA", "NN", "$.", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.272": {"text": "Mehr, als der Durst nach wahrer Weisheit, treiben,", "tokens": ["Mehr", ",", "als", "der", "Durst", "nach", "wah\u00b7rer", "Weis\u00b7heit", ",", "trei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.273": {"text": "So reitet nur!\u00ab", "tokens": ["So", "rei\u00b7tet", "nur", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.274": {"text": "Ich sah den Mann", "tokens": ["Ich", "sah", "den", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.275": {"text": "Der so entscheidend sprach, mit gro\u00dfen Augen an,", "tokens": ["Der", "so", "ent\u00b7schei\u00b7dend", "sprach", ",", "mit", "gro\u00b7\u00dfen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Und h\u00e4tt' ihn gern geha\u00dft, und doch mu\u00dft' ich ihn lieben.", "tokens": ["Und", "h\u00e4tt'", "ihn", "gern", "ge\u00b7ha\u00dft", ",", "und", "doch", "mu\u00dft'", "ich", "ihn", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$,", "KON", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.277": {"text": "Ich w\u00fcnscht' ihn weg, und folgt' ihm, als er ging.", "tokens": ["Ich", "w\u00fcnscht'", "ihn", "weg", ",", "und", "folgt'", "ihm", ",", "als", "er", "ging", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.278": {"text": "O Sympathie! du bist ein seltsam Ding.", "tokens": ["O", "Sym\u00b7pa\u00b7thie", "!", "du", "bist", "ein", "selt\u00b7sam", "Ding", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPER", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.279": {"text": "Zehn Meilen weit hast du das Herz getrieben,", "tokens": ["Zehn", "Mei\u00b7len", "weit", "hast", "du", "das", "Herz", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.280": {"text": "Eh' die Vernunft zehn Schritte ging.", "tokens": ["Eh'", "die", "Ver\u00b7nunft", "zehn", "Schrit\u00b7te", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.281": {"text": "Dank aber sey der guten Sympathie!", "tokens": ["Dank", "a\u00b7ber", "sey", "der", "gu\u00b7ten", "Sym\u00b7pa\u00b7thie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.282": {"text": "Gefunden h\u00e4tt' ich nie, gefunden", "tokens": ["Ge\u00b7fun\u00b7den", "h\u00e4tt'", "ich", "nie", ",", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "$,", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.283": {"text": "Den Freund und Retter ohne sie,", "tokens": ["Den", "Freund", "und", "Ret\u00b7ter", "oh\u00b7ne", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.284": {"text": "Der singend mich in wenig Stunden", "tokens": ["Der", "sin\u00b7gend", "mich", "in", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.285": {"text": "Dem Tempel n\u00e4her bracht', als ich im ganzen Jahr'", "tokens": ["Dem", "Tem\u00b7pel", "n\u00e4\u00b7her", "bracht'", ",", "als", "ich", "im", "gan\u00b7zen", "Jahr'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Ihm keuchend nachgekommen war.", "tokens": ["Ihm", "keu\u00b7chend", "nach\u00b7ge\u00b7kom\u00b7men", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.287": {"text": "Ihr B\u00fccher-Weisen, nehmt denn ein Exempel!", "tokens": ["Ihr", "B\u00fc\u00b7cher\u00b7Wei\u00b7sen", ",", "nehmt", "denn", "ein", "Ex\u00b7em\u00b7pel", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.288": {"text": "An mir, und sehet in der Zeit", "tokens": ["An", "mir", ",", "und", "se\u00b7het", "in", "der", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.289": {"text": "Nach solchem Freund' Euch um; denn wi\u00dft, der Tempel", "tokens": ["Nach", "sol\u00b7chem", "Freund'", "Euch", "um", ";", "denn", "wi\u00dft", ",", "der", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PPER", "PTKVZ", "$.", "KON", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.290": {"text": "War nicht der Weisheit, die Ihr sucht, geweiht:", "tokens": ["War", "nicht", "der", "Weis\u00b7heit", ",", "die", "Ihr", "sucht", ",", "ge\u00b7weiht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.291": {"text": "Die Inschrift hie\u00df: ", "tokens": ["Die", "In\u00b7schrift", "hie\u00df", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.292": {"text": "Itzt ziehen Freundschaft und Zufriedenheit", "tokens": ["Itzt", "zie\u00b7hen", "Freund\u00b7schaft", "und", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.293": {"text": "An meinem Phaeton der Freude;", "tokens": ["An", "mei\u00b7nem", "Phae\u00b7ton", "der", "Freu\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.294": {"text": "Sitz' ich darin, ei dann beneide,", "tokens": ["Sitz'", "ich", "da\u00b7rin", ",", "ei", "dann", "be\u00b7nei\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PAV", "$,", "ITJ", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.295": {"text": "Wer mag, den Mann, der stolz mit Sechsen f\u00e4hrt.", "tokens": ["Wer", "mag", ",", "den", "Mann", ",", "der", "stolz", "mit", "Sech\u00b7sen", "f\u00e4hrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "ART", "NN", "$,", "PRELS", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.296": {"text": "Noch eher war ", "tokens": ["Noch", "e\u00b7her", "war"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.297": {"text": "Auf seinem Klepper neideswerth;", "tokens": ["Auf", "sei\u00b7nem", "Klep\u00b7per", "nei\u00b7des\u00b7werth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.298": {"text": "Der ritt und sang nur zum Vergn\u00fcgen, Lieder.", "tokens": ["Der", "ritt", "und", "sang", "nur", "zum", "Ver\u00b7gn\u00fc\u00b7gen", ",", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.299": {"text": "Itzt hab' ich selbst ein \u00e4hnlich Steckenpferd.", "tokens": ["Itzt", "hab'", "ich", "selbst", "ein", "\u00e4hn\u00b7lich", "Ste\u00b7cken\u00b7pferd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.300": {"text": "Auf diesem reit' ich oft spatzieren,", "tokens": ["Auf", "die\u00b7sem", "reit'", "ich", "oft", "spat\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.301": {"text": "Um meine Grillen zu verlieren,", "tokens": ["Um", "mei\u00b7ne", "Gril\u00b7len", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.302": {"text": "Zuweilen auch, um an des Teiches Rohr", "tokens": ["Zu\u00b7wei\u00b7len", "auch", ",", "um", "an", "des", "Tei\u00b7ches", "Rohr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUI", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.303": {"text": "Die halbe Sommernacht mit ihnen zu durchwachen,", "tokens": ["Die", "hal\u00b7be", "Som\u00b7mer\u00b7nacht", "mit", "ih\u00b7nen", "zu", "durch\u00b7wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Und oft, dem Zwergfell', wenn ein Thor", "tokens": ["Und", "oft", ",", "dem", "Zwerg\u00b7fell'", ",", "wenn", "ein", "Thor"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.305": {"text": "Gereitzt es hatte, Luft zu machen.", "tokens": ["Ge\u00b7reitzt", "es", "hat\u00b7te", ",", "Luft", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "$,", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.306": {"text": "Frag' nur die Herrn Poeten allzumal,", "tokens": ["Frag'", "nur", "die", "Herrn", "Po\u00b7et\u00b7en", "all\u00b7zu\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.307": {"text": "Wie angenehm ein Ritt auf diesem Steckenpferde", "tokens": ["Wie", "an\u00b7ge\u00b7nehm", "ein", "Ritt", "auf", "die\u00b7sem", "Ste\u00b7cken\u00b7pfer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Dem Reiter thut, wenn's \u00fcber Berg und Thal", "tokens": ["Dem", "Rei\u00b7ter", "thut", ",", "wenn's", "\u00fc\u00b7ber", "Berg", "und", "Thal"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.309": {"text": "Dahinfliegt: Ha! wie klein wird da die Erde!", "tokens": ["Da\u00b7hin\u00b7fliegt", ":", "Ha", "!", "wie", "klein", "wird", "da", "die", "Er\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ITJ", "$.", "PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.310": {"text": "Mein zweites Steckenpferd, die ", "tokens": ["Mein", "zwei\u00b7tes", "Ste\u00b7cken\u00b7pferd", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.311": {"text": "Auch noch nicht Einmal ward es lahm.", "tokens": ["Auch", "noch", "nicht", "Ein\u00b7mal", "ward", "es", "lahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.312": {"text": "Es hat zuweilen wohl ein Schauer", "tokens": ["Es", "hat", "zu\u00b7wei\u00b7len", "wohl", "ein", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.313": {"text": "Von Tr\u00e4gheit, aber nie von Koller, oder Gram.", "tokens": ["Von", "Tr\u00e4g\u00b7heit", ",", "a\u00b7ber", "nie", "von", "Kol\u00b7ler", ",", "o\u00b7der", "Gram", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ADV", "APPR", "NE", "$,", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Das magst du einst als Trauerpferd,", "tokens": ["Das", "magst", "du", "einst", "als", "Trau\u00b7er\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.315": {"text": "Mein lieber ", "tokens": ["Mein", "lie\u00b7ber"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.316": {"text": "Ein Kritiker, h\u00e4lt er's der M\u00fche werth,", "tokens": ["Ein", "Kri\u00b7ti\u00b7ker", ",", "h\u00e4lt", "er's", "der", "M\u00fc\u00b7he", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PIS", "ART", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.317": {"text": "Mag meinethalb das Freudenpferd beschreiten.", "tokens": ["Mag", "mei\u00b7net\u00b7halb", "das", "Freu\u00b7den\u00b7pferd", "be\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Der vielgeliebte ", "tokens": ["Der", "viel\u00b7ge\u00b7lieb\u00b7te"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Im ", "tokens": ["Im"], "token_info": ["word"], "pos": ["APPRART"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "So schwatzt ihm alles schon von Steckenpferden nach;", "tokens": ["So", "schwatzt", "ihm", "al\u00b7les", "schon", "von", "Ste\u00b7cken\u00b7pfer\u00b7den", "nach", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer aber wird davon zum ", "tokens": ["Wer", "a\u00b7ber", "wird", "da\u00b7von", "zum"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "VAFIN", "PAV", "APPRART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Mir deucht, auf's W\u00f6rtlein Steckenpferd,", "tokens": ["Mir", "deucht", ",", "auf's", "W\u00f6rt\u00b7lein", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "APPRART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "(man kannt' es schon vor ", "tokens": ["(", "man", "kannt'", "es", "schon", "vor"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PIS", "VMFIN", "PPER", "ADV", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Kommt's wohl nicht an; die Sache anzudeuten,", "tokens": ["Kommt's", "wohl", "nicht", "an", ";", "die", "Sa\u00b7che", "an\u00b7zu\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "PTKNEG", "PTKVZ", "$.", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Gibt's Worte noch von gleichem Werth'.", "tokens": ["Gibt's", "Wor\u00b7te", "noch", "von", "glei\u00b7chem", "Wert\u00b7h'", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Inde\u00df behalt' ich's bei; nicht, ", "tokens": ["In\u00b7de\u00df", "be\u00b7halt'", "ich's", "bei", ";", "nicht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "PTKVZ", "$.", "PTKNEG", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.10": {"text": "Das \u00fcberla\u00df' ich gern Horazens Vieh':", "tokens": ["Das", "\u00fc\u00b7ber\u00b7la\u00df'", "ich", "gern", "Ho\u00b7ra\u00b7zens", "Vieh'", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADV", "NE", "NE", "$."], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.11": {"text": "Ich liebe die Allegorie,", "tokens": ["Ich", "lie\u00b7be", "die", "Al\u00b7le\u00b7go\u00b7rie", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Und Steckenpferd gibt mir f\u00fcr die\u00dfmal sie;", "tokens": ["Und", "Ste\u00b7cken\u00b7pferd", "gibt", "mir", "f\u00fcr", "die\u00df\u00b7mal", "sie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PPER", "APPR", "ADV", "PPER", "$."], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Sollt's Kritikern schon wieder anders d\u00fcnken?", "tokens": ["Sollt's", "Kri\u00b7ti\u00b7kern", "schon", "wie\u00b7der", "an\u00b7ders", "d\u00fcn\u00b7ken", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Je meinethalb! Sie sind ja Critici!", "tokens": ["Je", "mei\u00b7net\u00b7halb", "!", "Sie", "sind", "ja", "Cri\u00b7ti\u00b7ci", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$.", "PPER", "VAFIN", "ADV", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Komm her, mein lieber ", "tokens": ["Komm", "her", ",", "mein", "lie\u00b7ber"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VVFIN", "PTKVZ", "$,", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.16": {"text": "Dir alle Steckenpferde vor,", "tokens": ["Dir", "al\u00b7le", "Ste\u00b7cken\u00b7pfer\u00b7de", "vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Die ich vom Sch\u00fcler an, bis heute,", "tokens": ["Die", "ich", "vom", "Sch\u00fc\u00b7ler", "an", ",", "bis", "heu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "PTKVZ", "$,", "KOUS", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Sehr theuer oft gewann und wohlfeil oft verlor.", "tokens": ["Sehr", "theu\u00b7er", "oft", "ge\u00b7wann", "und", "wohl\u00b7feil", "oft", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "ADV", "VVFIN", "KON", "ADJD", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Sieh hier den ", "tokens": ["Sieh", "hier", "den"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADV", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.20": {"text": "Und doch; wie bald hab' ich's nicht steif geritten!", "tokens": ["Und", "doch", ";", "wie", "bald", "hab'", "ich's", "nicht", "steif", "ge\u00b7rit\u00b7ten", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$.", "PWAV", "ADV", "VAFIN", "PIS", "PTKNEG", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "Denn was nur ohne Geist und Sitten", "tokens": ["Denn", "was", "nur", "oh\u00b7ne", "Geist", "und", "Sit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "Zu Fu\u00df geht, reitet oder f\u00e4hrt,", "tokens": ["Zu", "Fu\u00df", "geht", ",", "rei\u00b7tet", "o\u00b7der", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "VVFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.23": {"text": "Hab' ich damit als Knabe schon gehetzt.", "tokens": ["Hab'", "ich", "da\u00b7mit", "als", "Kna\u00b7be", "schon", "ge\u00b7hetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PAV", "KOUS", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.24": {"text": "Itzt halt' ich's nicht der M\u00fche werth,", "tokens": ["Itzt", "halt'", "ich's", "nicht", "der", "M\u00fc\u00b7he", "werth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "PTKNEG", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "Da\u00df man sich oft auf diesen Renner setzt.", "tokens": ["Da\u00df", "man", "sich", "oft", "auf", "die\u00b7sen", "Ren\u00b7ner", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PRF", "ADV", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.26": {"text": "W\u00fc\u00dft' ich auch keinen andern Grund,", "tokens": ["W\u00fc\u00dft'", "ich", "auch", "kei\u00b7nen", "an\u00b7dern", "Grund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "So w\u00e4r's an dem genug: Man wird des Jagens m\u00fcde!", "tokens": ["So", "w\u00e4r's", "an", "dem", "ge\u00b7nug", ":", "Man", "wird", "des", "Ja\u00b7gens", "m\u00fc\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "ART", "ADV", "$.", "PIS", "VAFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Drum halt' ich itzt mit jedem Hund'", "tokens": ["Drum", "halt'", "ich", "itzt", "mit", "je\u00b7dem", "Hund'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und jedem Narren gerne Friede.", "tokens": ["Und", "je\u00b7dem", "Nar\u00b7ren", "ger\u00b7ne", "Frie\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADV", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "Wer jenen foppt, den bei\u00dft er leicht ins Bein,", "tokens": ["Wer", "je\u00b7nen", "foppt", ",", "den", "bei\u00dft", "er", "leicht", "ins", "Bein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,", "ART", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.31": {"text": "Wer diesen neckt, macht einen Feind sich mehr.", "tokens": ["Wer", "die\u00b7sen", "neckt", ",", "macht", "ei\u00b7nen", "Feind", "sich", "mehr", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDS", "VVFIN", "$,", "VVFIN", "ART", "NN", "PRF", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.32": {"text": "Will Bav ein Thor seyn, mag er's seyn!", "tokens": ["Will", "Bav", "ein", "Thor", "seyn", ",", "mag", "er's", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VMFIN", "NE", "ART", "NN", "VAINF", "$,", "VMFIN", "PIS", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.33": {"text": "Bellt Spitz mich an? Er belle noch so sehr!", "tokens": ["Bellt", "Spitz", "mich", "an", "?", "Er", "bel\u00b7le", "noch", "so", "sehr", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "ADV", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.34": {"text": "Ich suche dennoch keinen Stein!", "tokens": ["Ich", "su\u00b7che", "den\u00b7noch", "kei\u00b7nen", "Stein", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.35": {"text": "Auch stand einmal im Marstall' meiner Launen", "tokens": ["Auch", "stand", "ein\u00b7mal", "im", "Mar\u00b7stall'", "mei\u00b7ner", "Lau\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.36": {"text": "Ein Steckenpferd, das man die ", "tokens": ["Ein", "Ste\u00b7cken\u00b7pferd", ",", "das", "man", "die"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.37": {"text": "Nicht ein Cosack, der keinen Z\u00fcgel kennt,", "tokens": ["Nicht", "ein", "Co\u00b7sack", ",", "der", "kei\u00b7nen", "Z\u00fc\u00b7gel", "kennt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ART", "NN", "$,", "PRELS", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.38": {"text": "Den reiten nur die wilden Faunen.", "tokens": ["Den", "rei\u00b7ten", "nur", "die", "wil\u00b7den", "Fau\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.39": {"text": "Es war ein allerliebstes Thier,", "tokens": ["Es", "war", "ein", "al\u00b7ler\u00b7liebs\u00b7tes", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.40": {"text": "Aus Herrn ", "tokens": ["Aus", "Herrn"], "token_info": ["word", "word"], "pos": ["APPR", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.41": {"text": "War fromm und willig, selbst bei mir,", "tokens": ["War", "fromm", "und", "wil\u00b7lig", ",", "selbst", "bei", "mir", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "KON", "ADJD", "$,", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.42": {"text": "Wie ", "tokens": ["Wie"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.43": {"text": "Der sanfte Trab, den dieses gute Ding", "tokens": ["Der", "sanf\u00b7te", "Trab", ",", "den", "die\u00b7ses", "gu\u00b7te", "Ding"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.44": {"text": "Mit seinem Herrn im ersten Ausritt' ging,", "tokens": ["Mit", "sei\u00b7nem", "Herrn", "im", "ers\u00b7ten", "Aus\u00b7ritt'", "ging", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.45": {"text": "War seinem Herrn zwar ganz beh\u00e4glich;", "tokens": ["War", "sei\u00b7nem", "Herrn", "zwar", "ganz", "be\u00b7h\u00e4g\u00b7lich", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "NN", "ADV", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.46": {"text": "Doch Schade war's um allen Trab!", "tokens": ["Doch", "Scha\u00b7de", "wa\u00b7r's", "um", "al\u00b7len", "Trab", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.47": {"text": "Man that die Reise doch nicht ab;", "tokens": ["Man", "that", "die", "Rei\u00b7se", "doch", "nicht", "ab", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.48": {"text": "Der Umstand war wahrhaftig kl\u00e4glich.", "tokens": ["Der", "Um\u00b7stand", "war", "wahr\u00b7haf\u00b7tig", "kl\u00e4g\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "ADJD", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.49": {"text": "In unserm besten Dreischlag' \u2013 Halt!", "tokens": ["In", "un\u00b7serm", "bes\u00b7ten", "Drei\u00b7schlag'", "\u2013", "Halt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$(", "VVIMP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.50": {"text": "Da stand auf einmal Pferd und Reiter", "tokens": ["Da", "stand", "auf", "ein\u00b7mal", "Pferd", "und", "Rei\u00b7ter"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADV", "NN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.51": {"text": "Vor einem Schlagbaum'!", "tokens": ["Vor", "ei\u00b7nem", "Schlag\u00b7baum'", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.52": {"text": "\u00bbach! ich bitte Sie! nicht weiter!", "tokens": ["\u00bb", "ach", "!", "ich", "bit\u00b7te", "Sie", "!", "nicht", "wei\u00b7ter", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ITJ", "$.", "PPER", "VVFIN", "PPER", "$.", "PTKNEG", "PTKVZ", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.53": {"text": "(rief mir ein M\u00e4dchen zu von englischer Gestalt,)", "tokens": ["(", "rief", "mir", "ein", "M\u00e4d\u00b7chen", "zu", "von", "eng\u00b7li\u00b7scher", "Ge\u00b7stalt", ",", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "ART", "NN", "PTKZU", "APPR", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.54": {"text": "Den Schl\u00fcssel hab' ich zwar, doch Ihnen aufzuschlie\u00dfen,", "tokens": ["Den", "Schl\u00fcs\u00b7sel", "hab'", "ich", "zwar", ",", "doch", "Ih\u00b7nen", "auf\u00b7zu\u00b7schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$,", "KON", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.55": {"text": "Sie wissen's selbst, verbeut die Tugend mir.", "tokens": ["Sie", "wis\u00b7sen's", "selbst", ",", "ver\u00b7beut", "die", "Tu\u00b7gend", "mir", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.56": {"text": "Ich Arme m\u00fc\u00dfte daf\u00fcr b\u00fc\u00dfen;", "tokens": ["Ich", "Ar\u00b7me", "m\u00fc\u00df\u00b7te", "da\u00b7f\u00fcr", "b\u00fc\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "VMFIN", "PAV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.57": {"text": "Drum bitt' ich, bleiben Sie doch hier!\u00ab", "tokens": ["Drum", "bitt'", "ich", ",", "blei\u00b7ben", "Sie", "doch", "hier", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ADV", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.58": {"text": "Was war zu thun? Aus Liebe f\u00fcr das Pferd,", "tokens": ["Was", "war", "zu", "thun", "?", "Aus", "Lie\u00b7be", "f\u00fcr", "das", "Pferd", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PTKZU", "VVINF", "$.", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.59": {"text": "Und f\u00fcr das M\u00e4dchen selbst, lie\u00df ich mich gern beth\u00f6ren.", "tokens": ["Und", "f\u00fcr", "das", "M\u00e4d\u00b7chen", "selbst", ",", "lie\u00df", "ich", "mich", "gern", "be\u00b7th\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "$,", "VVFIN", "PPER", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.60": {"text": "Vielleicht war's kl\u00fcger, umzukehren?", "tokens": ["Viel\u00b7leicht", "wa\u00b7r's", "kl\u00fc\u00b7ger", ",", "um\u00b7zu\u00b7keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJD", "$,", "VVIZU", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.61": {"text": "Das thue, wer's von mir begehrt!", "tokens": ["Das", "thue", ",", "wer's", "von", "mir", "be\u00b7gehrt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "$,", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.62": {"text": "Ich w\u00fc\u00dft' ihn diese Kunst wahrhaftig nicht zu lehren.", "tokens": ["Ich", "w\u00fc\u00dft'", "ihn", "die\u00b7se", "Kunst", "wahr\u00b7haf\u00b7tig", "nicht", "zu", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "ADJD", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.63": {"text": "Ich blieb ein ganzes volles Jahr,", "tokens": ["Ich", "blieb", "ein", "gan\u00b7zes", "vol\u00b7les", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.64": {"text": "Und w\u00e4re wohl bis an den Tod geblieben,", "tokens": ["Und", "w\u00e4\u00b7re", "wohl", "bis", "an", "den", "Tod", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.65": {"text": "Doch ich, mit sammt dem Pferde, war", "tokens": ["Doch", "ich", ",", "mit", "sammt", "dem", "Pfer\u00b7de", ",", "war"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "PPER", "$,", "APPR", "APPR", "ART", "NN", "$,", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.66": {"text": "Beinah vom Hunger aufgerieben.", "tokens": ["Bei\u00b7nah", "vom", "Hun\u00b7ger", "auf\u00b7ge\u00b7rie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.67": {"text": "Fast nichts als Seufzer statt der Speise,", "tokens": ["Fast", "nichts", "als", "Seuf\u00b7zer", "statt", "der", "Spei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.68": {"text": "Fast nichts als Thr\u00e4nen nur, f\u00fcr Trank:", "tokens": ["Fast", "nichts", "als", "Thr\u00e4\u00b7nen", "nur", ",", "f\u00fcr", "Trank", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PIS", "KOKOM", "NN", "ADV", "$,", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.69": {"text": "Wie war das auszustehn? Und, nach ", "tokens": ["Wie", "war", "das", "aus\u00b7zu\u00b7stehn", "?", "Und", ",", "nach"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PWAV", "VAFIN", "PDS", "VVINF", "$.", "KON", "$,", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.70": {"text": "Mehr zu verlangen, brachte Zank;", "tokens": ["Mehr", "zu", "ver\u00b7lan\u00b7gen", ",", "brach\u00b7te", "Zank", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "PTKZU", "VVINF", "$,", "VVFIN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.71": {"text": "Drum sprang ich in den Sattel, sagte leise", "tokens": ["Drum", "sprang", "ich", "in", "den", "Sat\u00b7tel", ",", "sag\u00b7te", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "VVFIN", "ADJD"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.72": {"text": "F\u00fcr das Geno\u00dfne, sch\u00f6nen Dank!", "tokens": ["F\u00fcr", "das", "Ge\u00b7no\u00df\u00b7ne", ",", "sch\u00f6\u00b7nen", "Dank", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.73": {"text": "Und ging zur\u00fcck auf meiner Reise.", "tokens": ["Und", "ging", "zu\u00b7r\u00fcck", "auf", "mei\u00b7ner", "Rei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.74": {"text": "Das M\u00e4dchen sah mich schmachtend an,", "tokens": ["Das", "M\u00e4d\u00b7chen", "sah", "mich", "schmach\u00b7tend", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.75": {"text": "Und dr\u00fcckte mir die Hand, und schlug die Augen nieder.", "tokens": ["Und", "dr\u00fcck\u00b7te", "mir", "die", "Hand", ",", "und", "schlug", "die", "Au\u00b7gen", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ART", "NN", "$,", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.76": {"text": "\u00bbein Wort, ein Wort! Ein Mann, ein Mann!", "tokens": ["\u00bb", "ein", "Wort", ",", "ein", "Wort", "!", "Ein", "Mann", ",", "ein", "Mann", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "ART", "NN", "$.", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.77": {"text": "(sagt' ich beherzt,) Wir kommen sicher wieder,", "tokens": ["(", "sagt'", "ich", "be\u00b7herzt", ",", ")", "Wir", "kom\u00b7men", "si\u00b7cher", "wie\u00b7der", ","], "token_info": ["punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "ADJD", "$,", "$(", "PPER", "VVFIN", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.78": {"text": "Wenn Mann und Pferd erst besser hungern kann.", "tokens": ["Wenn", "Mann", "und", "Pferd", "erst", "bes\u00b7ser", "hun\u00b7gern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.79": {"text": "Itzt aber m\u00f6cht' es, f\u00fcrcht' ich schier,", "tokens": ["Itzt", "a\u00b7ber", "m\u00f6cht'", "es", ",", "f\u00fcrcht'", "ich", "schier", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "$,", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.80": {"text": "Am Ende noch das ganze Spiel verderben;", "tokens": ["Am", "En\u00b7de", "noch", "das", "gan\u00b7ze", "Spiel", "ver\u00b7der\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.81": {"text": "Den weitern Weg verbeut der Schlagbaum mir,", "tokens": ["Den", "wei\u00b7tern", "Weg", "ver\u00b7beut", "der", "Schlag\u00b7baum", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.82": {"text": "Und bleiben wir noch l\u00e4nger hier,", "tokens": ["Und", "blei\u00b7ben", "wir", "noch", "l\u00e4n\u00b7ger", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.83": {"text": "Wird Mann und Pferd bald an der Schwindsucht sterben!\u00ab", "tokens": ["Wird", "Mann", "und", "Pferd", "bald", "an", "der", "Schwind\u00b7sucht", "ster\u00b7ben", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "ADV", "APPR", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.84": {"text": "Das gute Thier, wie mancher Weise thut,", "tokens": ["Das", "gu\u00b7te", "Thier", ",", "wie", "man\u00b7cher", "Wei\u00b7se", "thut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PWAV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.85": {"text": "Er r\u00e4th es wenigstens, ins freie Feld zu jagen,", "tokens": ["Er", "r\u00e4\u00b7th", "es", "we\u00b7nigs\u00b7tens", ",", "ins", "frei\u00b7e", "Feld", "zu", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "$,", "APPRART", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-++-+-+-+-+-+-", "measure": "unknown.measure.septa"}, "line.86": {"text": "Das konnt' ich nicht; ich war ihm viel zu gut,", "tokens": ["Das", "konnt'", "ich", "nicht", ";", "ich", "war", "ihm", "viel", "zu", "gut", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PTKNEG", "$.", "PPER", "VAFIN", "PPER", "ADV", "PTKA", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.87": {"text": "Und lieber wollt' ich mich noch l\u00e4nger mit ihm plagen.", "tokens": ["Und", "lie\u00b7ber", "wollt'", "ich", "mich", "noch", "l\u00e4n\u00b7ger", "mit", "ihm", "pla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.88": {"text": "Ich bring' es, dacht' ich, wohl an Mann,", "tokens": ["Ich", "bring'", "es", ",", "dacht'", "ich", ",", "wohl", "an", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "$,", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.89": {"text": "Ich h\u00e4rt' es auch vielleicht noch ab,", "tokens": ["Ich", "h\u00e4rt'", "es", "auch", "viel\u00b7leicht", "noch", "ab", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.90": {"text": "Bis sich's mit schmaler Kost den Hunger stillen kann;", "tokens": ["Bis", "sich's", "mit", "schma\u00b7ler", "Kost", "den", "Hun\u00b7ger", "stil\u00b7len", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "APPR", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.91": {"text": "Wo nicht, so finden wir am Ende beid' ein Grab.", "tokens": ["Wo", "nicht", ",", "so", "fin\u00b7den", "wir", "am", "En\u00b7de", "beid'", "ein", "Grab", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.92": {"text": "Das war dir eine Reiterei!", "tokens": ["Das", "war", "dir", "ei\u00b7ne", "Rei\u00b7te\u00b7rei", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.93": {"text": "Am Geist', gedankenlos, am K\u00f6rper, wie zerschlagen,", "tokens": ["Am", "Geist'", ",", "ge\u00b7dan\u00b7ken\u00b7los", ",", "am", "K\u00f6r\u00b7per", ",", "wie", "zer\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "ADJD", "$,", "APPRART", "NN", "$,", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.94": {"text": "Ritt ich, wohin? das war mir einerlei!", "tokens": ["Ritt", "ich", ",", "wo\u00b7hin", "?", "das", "war", "mir", "ei\u00b7ner\u00b7lei", "!"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "$.", "PDS", "VAFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.95": {"text": "Ich brachte bald durch eine Schmeichelei", "tokens": ["Ich", "brach\u00b7te", "bald", "durch", "ei\u00b7ne", "Schmei\u00b7che\u00b7lei"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.96": {"text": "Ein wenig neuen Muth dem armen Thiere bei,", "tokens": ["Ein", "we\u00b7nig", "neu\u00b7en", "Muth", "dem", "ar\u00b7men", "Thie\u00b7re", "bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.97": {"text": "Bald wollt' ich's fort zum Kuckuck jagen.", "tokens": ["Bald", "wollt'", "ich's", "fort", "zum", "Ku\u00b7ckuck", "ja\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PIS", "PTKVZ", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.98": {"text": "Ein h\u00fcbsches Weilchen schw\u00e4rmt' ich so herum,", "tokens": ["Ein", "h\u00fcb\u00b7sches", "Weil\u00b7chen", "schw\u00e4rmt'", "ich", "so", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.99": {"text": "Die mehrste Zeit in \u00f6den Eichenhainen;", "tokens": ["Die", "mehrs\u00b7te", "Zeit", "in", "\u00f6\u00b7den", "Ei\u00b7chen\u00b7hai\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.100": {"text": "Ging, wie du denken kannst, mit Reden sparsam um,", "tokens": ["Ging", ",", "wie", "du", "den\u00b7ken", "kannst", ",", "mit", "Re\u00b7den", "spar\u00b7sam", "um", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VVINF", "VMFIN", "$,", "APPR", "NN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.101": {"text": "Doch sehr verschwenderisch mit Weinen:", "tokens": ["Doch", "sehr", "ver\u00b7schwen\u00b7de\u00b7risch", "mit", "Wei\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.102": {"text": "Doch, was dir sonderbar wird scheinen,", "tokens": ["Doch", ",", "was", "dir", "son\u00b7der\u00b7bar", "wird", "schei\u00b7nen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "PPER", "ADJD", "VAFIN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.103": {"text": "Ich wu\u00dfte selbst nicht recht, warum?", "tokens": ["Ich", "wu\u00df\u00b7te", "selbst", "nicht", "recht", ",", "wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "ADJD", "$,", "PWAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.104": {"text": "Zum Gl\u00fccke kann ein gro\u00dfer Schmerz", "tokens": ["Zum", "Gl\u00fc\u00b7cke", "kann", "ein", "gro\u00b7\u00dfer", "Schmerz"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.105": {"text": "Nicht gar zu lang am Herzen nagen;", "tokens": ["Nicht", "gar", "zu", "lang", "am", "Her\u00b7zen", "na\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PTKA", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.106": {"text": "Entweder fri\u00dft er bald des Kranken Herz,", "tokens": ["Ent\u00b7we\u00b7der", "fri\u00dft", "er", "bald", "des", "Kran\u00b7ken", "Herz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.107": {"text": "Wo nicht, so nimmt er ab, und l\u00e4\u00dft sich dann ertragen.", "tokens": ["Wo", "nicht", ",", "so", "nimmt", "er", "ab", ",", "und", "l\u00e4\u00dft", "sich", "dann", "er\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.108": {"text": "Die\u00df letzte war der Fall mit mir.", "tokens": ["Die\u00df", "letz\u00b7te", "war", "der", "Fall", "mit", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.109": {"text": "Da konnt' ich denn auch leicht den Weisen wieder machen,", "tokens": ["Da", "konnt'", "ich", "denn", "auch", "leicht", "den", "Wei\u00b7sen", "wie\u00b7der", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "ADV", "ADJD", "ART", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.110": {"text": "Mich h\u00f6chlich wundern, wie ich schier,", "tokens": ["Mich", "h\u00f6ch\u00b7lich", "wun\u00b7dern", ",", "wie", "ich", "schier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVINF", "$,", "PWAV", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.111": {"text": "So toll und blind, dem Ungl\u00fcck' in den Rachen", "tokens": ["So", "toll", "und", "blind", ",", "dem", "Un\u00b7gl\u00fcck", "in", "den", "Ra\u00b7chen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "$,", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.112": {"text": "Zu rennen, in Gefahr gestanden, ernstlich mir", "tokens": ["Zu", "ren\u00b7nen", ",", "in", "Ge\u00b7fahr", "ge\u00b7stan\u00b7den", ",", "ernst\u00b7lich", "mir"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PTKZU", "VVINF", "$,", "APPR", "NN", "VVPP", "$,", "ADJD", "PPER"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.113": {"text": "Die Unbesonnenheit verweisen,", "tokens": ["Die", "Un\u00b7be\u00b7son\u00b7nen\u00b7heit", "ver\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.114": {"text": "So lang auf einem solchen Thier'", "tokens": ["So", "lang", "auf", "ei\u00b7nem", "sol\u00b7chen", "Thier'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "APPR", "ART", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.115": {"text": "In solcher Irr' herum zu reisen,", "tokens": ["In", "sol\u00b7cher", "Irr'", "he\u00b7rum", "zu", "rei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.116": {"text": "Und endlich, sch\u00e4mt ich mich daf\u00fcr,", "tokens": ["Und", "end\u00b7lich", ",", "sch\u00e4mt", "ich", "mich", "da\u00b7f\u00fcr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "VVFIN", "PPER", "PRF", "PAV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.117": {"text": "Warum ich doch mich so vergebens gr\u00e4mte?", "tokens": ["Wa\u00b7rum", "ich", "doch", "mich", "so", "ver\u00b7ge\u00b7bens", "gr\u00e4m\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "PPER", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.118": {"text": "Itzt aber, ich gesteh' es dir,", "tokens": ["Itzt", "a\u00b7ber", ",", "ich", "ge\u00b7steh'", "es", "dir", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "PPER", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.119": {"text": "Das kl\u00fcgste war, ich lie\u00df mein Steckenpferd", "tokens": ["Das", "kl\u00fcgs\u00b7te", "war", ",", "ich", "lie\u00df", "mein", "Ste\u00b7cken\u00b7pferd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "VAFIN", "$,", "PPER", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.120": {"text": "Mit einem tiefen Seufzer stehen,", "tokens": ["Mit", "ei\u00b7nem", "tie\u00b7fen", "Seuf\u00b7zer", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.121": {"text": "Ging hurtig fort, und schwur, mich nicht mehr umzusehen,", "tokens": ["Ging", "hur\u00b7tig", "fort", ",", "und", "schwur", ",", "mich", "nicht", "mehr", "um\u00b7zu\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PTKVZ", "$,", "KON", "VVFIN", "$,", "PPER", "PTKNEG", "ADV", "VVIZU", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.122": {"text": "Das \u00fcbrige \u2013 war keinen Dreier werth.", "tokens": ["Das", "\u00fcb\u00b7ri\u00b7ge", "\u2013", "war", "kei\u00b7nen", "Drei\u00b7er", "werth", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$(", "VAFIN", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.123": {"text": "Fort war das Thier; ich kehrte nun zu Fu\u00dfe", "tokens": ["Fort", "war", "das", "Thier", ";", "ich", "kehr\u00b7te", "nun", "zu", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "ART", "NN", "$.", "PPER", "VVFIN", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.124": {"text": "Nach Haus zur\u00fcck, und that f\u00fcr meinen Ritt,", "tokens": ["Nach", "Haus", "zu\u00b7r\u00fcck", ",", "und", "that", "f\u00fcr", "mei\u00b7nen", "Ritt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.125": {"text": "Wenn Bu\u00dfe n\u00f6thig war, durch Pilgrimschaften Bu\u00dfe.", "tokens": ["Wenn", "Bu\u00b7\u00dfe", "n\u00f6\u00b7thig", "war", ",", "durch", "Pil\u00b7grim\u00b7schaf\u00b7ten", "Bu\u00b7\u00dfe", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "VAFIN", "$,", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.126": {"text": "Das ging zwar anfangs gut, allein das: Schritt vor Schritt!", "tokens": ["Das", "ging", "zwar", "an\u00b7fangs", "gut", ",", "al\u00b7lein", "das", ":", "Schritt", "vor", "Schritt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "ADJD", "$,", "ADV", "PDS", "$.", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.127": {"text": "Erm\u00fcdet und macht \u00e4rgerlich.", "tokens": ["Er\u00b7m\u00fc\u00b7det", "und", "macht", "\u00e4r\u00b7ger\u00b7lich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.128": {"text": "Und welcher Mensch, mit so viel Mu\u00dfe,", "tokens": ["Und", "wel\u00b7cher", "Mensch", ",", "mit", "so", "viel", "Mu\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAT", "NN", "$,", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.129": {"text": "Mit so viel Trieb herum zu ziehn, als ich,", "tokens": ["Mit", "so", "viel", "Trieb", "he\u00b7rum", "zu", "ziehn", ",", "als", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "APZR", "PTKZU", "VVINF", "$,", "KOUS", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.130": {"text": "Geht wie ein Pilger gern zu Fu\u00dfe?", "tokens": ["Geht", "wie", "ein", "Pil\u00b7ger", "gern", "zu", "Fu\u00b7\u00dfe", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KOKOM", "ART", "NN", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.131": {"text": "Wer reiten kann, der nehm' es mit!", "tokens": ["Wer", "rei\u00b7ten", "kann", ",", "der", "nehm'", "es", "mit", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "VMFIN", "$,", "PRELS", "VVFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.132": {"text": "Sagt, was ihr wollt, der Weg, den auf der Erde", "tokens": ["Sagt", ",", "was", "ihr", "wollt", ",", "der", "Weg", ",", "den", "auf", "der", "Er\u00b7de"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "PWS", "PPER", "VMFIN", "$,", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.133": {"text": "Der Mensch zu gehen hat, wird jedem oft zu lang.", "tokens": ["Der", "Mensch", "zu", "ge\u00b7hen", "hat", ",", "wird", "je\u00b7dem", "oft", "zu", "lang", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "VAFIN", "$,", "VAFIN", "PIS", "ADV", "PTKA", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.134": {"text": "Es leben denn die Steckenpferde!", "tokens": ["Es", "le\u00b7ben", "denn", "die", "Ste\u00b7cken\u00b7pfer\u00b7de", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.135": {"text": "Sie gehen einen raschen Gang,", "tokens": ["Sie", "ge\u00b7hen", "ei\u00b7nen", "ra\u00b7schen", "Gang", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.136": {"text": "Und mehrentheils doch ohne viel Beschwerde.", "tokens": ["Und", "meh\u00b7ren\u00b7theils", "doch", "oh\u00b7ne", "viel", "Be\u00b7schwer\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.137": {"text": "Doch auf die Wahl kommt's freilich an;", "tokens": ["Doch", "auf", "die", "Wahl", "kommt's", "frei\u00b7lich", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.138": {"text": "Ist's bei\u00dfig, oder sonnensch\u00fc\u00dfig,", "tokens": ["Ist's", "bei\u00b7\u00dfig", ",", "o\u00b7der", "son\u00b7nen\u00b7sch\u00fc\u00b7\u00dfig", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "ADJD", "$,", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.139": {"text": "Hartm\u00e4ulig, scheu, und was noch sonst daran", "tokens": ["Hart\u00b7m\u00e4u\u00b7lig", ",", "scheu", ",", "und", "was", "noch", "sonst", "da\u00b7ran"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADJD", "$,", "ADJD", "$,", "KON", "PWS", "ADV", "ADV", "PAV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.140": {"text": "Ein \u00e4chter Kenner tadeln kann,", "tokens": ["Ein", "\u00e4ch\u00b7ter", "Ken\u00b7ner", "ta\u00b7deln", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.141": {"text": "So wird man bald des Dinges \u00fcberdr\u00fc\u00dfig.", "tokens": ["So", "wird", "man", "bald", "des", "Din\u00b7ges", "\u00fc\u00b7berd\u00b7r\u00fc\u00b7\u00dfig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.142": {"text": "Mein Weg ging \u00fcber ", "tokens": ["Mein", "Weg", "ging", "\u00fc\u00b7ber"], "token_info": ["word", "word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.143": {"text": "Da willst du dich bei ", "tokens": ["Da", "willst", "du", "dich", "bei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.144": {"text": "Ob der vielleicht ein be\u00dfres Stockpferd hat?", "tokens": ["Ob", "der", "viel\u00b7leicht", "ein", "be\u00df\u00b7res", "Stock\u00b7pferd", "hat", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ART", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.145": {"text": "Ich kam. Er schwur mit hundert Schw\u00fcren,", "tokens": ["Ich", "kam", ".", "Er", "schwur", "mit", "hun\u00b7dert", "Schw\u00fc\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "PPER", "VVFIN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.146": {"text": "Solch gutes Steckenpferd sey nicht mehr in der Stadt!", "tokens": ["Solch", "gu\u00b7tes", "Ste\u00b7cken\u00b7pferd", "sey", "nicht", "mehr", "in", "der", "Stadt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "PTKNEG", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.147": {"text": "Nun gut! die Th\u00fcr ging auf; sieh da! da stand im Stalle", "tokens": ["Nun", "gut", "!", "die", "Th\u00fcr", "ging", "auf", ";", "sieh", "da", "!", "da", "stand", "im", "Stal\u00b7le"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$.", "ART", "NN", "VVFIN", "PTKVZ", "$.", "VVIMP", "ADV", "$.", "ADV", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.148": {"text": "Mein kaum verla\u00dfnes Steckenpferd,", "tokens": ["Mein", "kaum", "ver\u00b7la\u00df\u00b7nes", "Ste\u00b7cken\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.149": {"text": "Nur hatt' es schon noch \u00e4rger abgezehrt,", "tokens": ["Nur", "hatt'", "es", "schon", "noch", "\u00e4r\u00b7ger", "ab\u00b7ge\u00b7zehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.150": {"text": "Denn, Freund, sein Herr war grad' in meinem Falle.", "tokens": ["Denn", ",", "Freund", ",", "sein", "Herr", "war", "grad'", "in", "mei\u00b7nem", "Fal\u00b7le", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "NN", "$,", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.151": {"text": "\u00bbgl\u00fcck zu! Gl\u00fcck zu! mein lieber Freund!", "tokens": ["\u00bb", "gl\u00fcck", "zu", "!", "Gl\u00fcck", "zu", "!", "mein", "lie\u00b7ber", "Freund", "!"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PTKVZ", "$.", "NN", "PTKVZ", "$.", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.152": {"text": "Das Thierchen hat mich auch getragen.", "tokens": ["Das", "Thier\u00b7chen", "hat", "mich", "auch", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.153": {"text": "Nimm dich damit in Acht, so fromm es immer scheint!", "tokens": ["Nimm", "dich", "da\u00b7mit", "in", "Acht", ",", "so", "fromm", "es", "im\u00b7mer", "scheint", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PRF", "PAV", "APPR", "CARD", "$,", "ADV", "ADJD", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.154": {"text": "Du freilich kannst es mit ihm wagen:", "tokens": ["Du", "frei\u00b7lich", "kannst", "es", "mit", "ihm", "wa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.155": {"text": "Denn, wenn es auch, wie man zu w\u00e4hnen pflegt,", "tokens": ["Denn", ",", "wenn", "es", "auch", ",", "wie", "man", "zu", "w\u00e4h\u00b7nen", "pflegt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "$,", "PWAV", "PIS", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.156": {"text": "Zu Paphos Myrtenhain nicht tr\u00e4gt,", "tokens": ["Zu", "Pa\u00b7phos", "Myr\u00b7ten\u00b7hain", "nicht", "tr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NE", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.157": {"text": "Kann's doch zum Lorbeerhain' auf Pindus Gipfel tragen.", "tokens": ["Kann's", "doch", "zum", "Lor\u00b7beer\u00b7hain'", "auf", "Pin\u00b7dus", "Gip\u00b7fel", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPRART", "NN", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.158": {"text": "Drum rath' ich selbst, behalt' es, lieber Mann,", "tokens": ["Drum", "ra\u00b7th'", "ich", "selbst", ",", "be\u00b7halt'", "es", ",", "lie\u00b7ber", "Mann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "$,", "VVFIN", "PPER", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.159": {"text": "So lang es Futter mag, und sicher geht im Schritt',", "tokens": ["So", "lang", "es", "Fut\u00b7ter", "mag", ",", "und", "si\u00b7cher", "geht", "im", "Schritt'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "PPER", "NN", "VMFIN", "$,", "KON", "ADJD", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.160": {"text": "Doch wird es krippens\u00e4tzig, f\u00e4ngt es an,", "tokens": ["Doch", "wird", "es", "krip\u00b7pen\u00b7s\u00e4t\u00b7zig", ",", "f\u00e4ngt", "es", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "$,", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.161": {"text": "Sich brav zu baumen; fort damit!", "tokens": ["Sich", "brav", "zu", "bau\u00b7men", ";", "fort", "da\u00b7mit", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "ADJD", "PTKZU", "VVINF", "$.", "PTKVZ", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.162": {"text": "Ich mag es gern von dir itzt reiten sehn,", "tokens": ["Ich", "mag", "es", "gern", "von", "dir", "itzt", "rei\u00b7ten", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "APPR", "PPER", "ADV", "VVFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.163": {"text": "Es f\u00e4llt mir dann so ein, wie ich es selbst noch ritt,", "tokens": ["Es", "f\u00e4llt", "mir", "dann", "so", "ein", ",", "wie", "ich", "es", "selbst", "noch", "ritt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ADV", "PTKVZ", "$,", "PWAV", "PPER", "PPER", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.164": {"text": "Und die Erinnrung bleibt doch sch\u00f6n.", "tokens": ["Und", "die", "E\u00b7rinn\u00b7rung", "bleibt", "doch", "sch\u00f6n", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.165": {"text": "Denn denke nur, es trug mich Jahr' und Wochen,", "tokens": ["Denn", "den\u00b7ke", "nur", ",", "es", "trug", "mich", "Jahr'", "und", "Wo\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.166": {"text": "Und doch hat meine Tugend nicht", "tokens": ["Und", "doch", "hat", "mei\u00b7ne", "Tu\u00b7gend", "nicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VAFIN", "PPOSAT", "NN", "PTKNEG"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.167": {"text": "Den Hals darauf gebrochen,", "tokens": ["Den", "Hals", "da\u00b7rauf", "ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.168": {"text": "Den sie so leicht auf diesem Pferde bricht.", "tokens": ["Den", "sie", "so", "leicht", "auf", "die\u00b7sem", "Pfer\u00b7de", "bricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "APPR", "PDAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.169": {"text": "Bei allen seinen Unbequemlichkeiten,", "tokens": ["Bei", "al\u00b7len", "sei\u00b7nen", "Un\u00b7be\u00b7quem\u00b7lich\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.170": {"text": "(denn ach! es war und bleibt ein sch\u00f6nes Steckenpferd!)", "tokens": ["(", "denn", "ach", "!", "es", "war", "und", "bleibt", "ein", "sch\u00f6\u00b7nes", "Ste\u00b7cken\u00b7pferd", "!", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KON", "XY", "$.", "PPER", "VAFIN", "KON", "VVFIN", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.171": {"text": "W\u00fcrd' ich's gewi\u00df noch heute reiten,", "tokens": ["W\u00fcrd'", "ich's", "ge\u00b7wi\u00df", "noch", "heu\u00b7te", "rei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.172": {"text": "Nur hat ihm die Natur die Dauer nicht gew\u00e4hrt.", "tokens": ["Nur", "hat", "ihm", "die", "Na\u00b7tur", "die", "Dau\u00b7er", "nicht", "ge\u00b7w\u00e4hrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.173": {"text": "Doch h\u00e4tt' es, wie Petrarch von seinem spricht,", "tokens": ["Doch", "h\u00e4tt'", "es", ",", "wie", "Pe\u00b7trarch", "von", "sei\u00b7nem", "spricht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "$,", "PWAV", "NE", "APPR", "PPOSAT", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.174": {"text": "Die Dauer auch, so hatt's doch etwas T\u00fccke;", "tokens": ["Die", "Dau\u00b7er", "auch", ",", "so", "hatt's", "doch", "et\u00b7was", "T\u00fc\u00b7cke", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADV", "VAFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.175": {"text": "Kann seyn, da\u00df ich mich nicht zu seinem Reiter schicke;", "tokens": ["Kann", "seyn", ",", "da\u00df", "ich", "mich", "nicht", "zu", "sei\u00b7nem", "Rei\u00b7ter", "schi\u00b7cke", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VAINF", "$,", "KOUS", "PPER", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.176": {"text": "Wie dem auch sey, ich trau' ihm weiter nicht.", "tokens": ["Wie", "dem", "auch", "sey", ",", "ich", "trau'", "ihm", "wei\u00b7ter", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADV", "VAFIN", "$,", "PPER", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.177": {"text": "Man ist darauf wie angepicht,", "tokens": ["Man", "ist", "da\u00b7rauf", "wie", "an\u00b7ge\u00b7picht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PAV", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.178": {"text": "Will immer ab, und trabt in einem St\u00fccke", "tokens": ["Will", "im\u00b7mer", "ab", ",", "und", "trabt", "in", "ei\u00b7nem", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "PTKVZ", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.179": {"text": "Nur weiter fort, als h\u00f6rt' und s\u00e4h' man nicht;", "tokens": ["Nur", "wei\u00b7ter", "fort", ",", "als", "h\u00f6rt'", "und", "s\u00e4h'", "man", "nicht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKVZ", "$,", "KOUS", "VVFIN", "KON", "VVFIN", "PIS", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.180": {"text": "Ja, macht den Z\u00fcgel gar wohl selbst f\u00fcr sich zum Stricke,", "tokens": ["Ja", ",", "macht", "den", "Z\u00fc\u00b7gel", "gar", "wohl", "selbst", "f\u00fcr", "sich", "zum", "Stri\u00b7cke", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "VVFIN", "ART", "NN", "ADV", "ADV", "ADV", "APPR", "PRF", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.181": {"text": "Wie man so was vom jungen ", "tokens": ["Wie", "man", "so", "was", "vom", "jun\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "ADV", "PWS", "APPRART", "ADJA"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.182": {"text": "Von ", "tokens": ["Von"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.183": {"text": "Springt man gew\u00f6hnlich auf ein Thier,", "tokens": ["Springt", "man", "ge\u00b7w\u00f6hn\u00b7lich", "auf", "ein", "Thier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.184": {"text": "Das immer mit fliegender M\u00e4hn' und Wiehern und frecher Geberde", "tokens": ["Das", "im\u00b7mer", "mit", "flie\u00b7gen\u00b7der", "M\u00e4hn'", "und", "Wie\u00b7hern", "und", "fre\u00b7cher", "Ge\u00b7ber\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "APPR", "ADJA", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+--+--+-+--+--+-", "measure": "amphibrach.tri.plus"}, "line.185": {"text": "Mit seinem Reiter lauft, wohin es die Begier", "tokens": ["Mit", "sei\u00b7nem", "Rei\u00b7ter", "lauft", ",", "wo\u00b7hin", "es", "die", "Be\u00b7gier"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PWAV", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.186": {"text": "Mit ihrer Peitsche treibt. ", "tokens": ["Mit", "ih\u00b7rer", "Peit\u00b7sche", "treibt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.187": {"text": "Und jede List und jede Kunst gelehrt.", "tokens": ["Und", "je\u00b7de", "List", "und", "je\u00b7de", "Kunst", "ge\u00b7lehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.188": {"text": "Er ist damit fast \u00fcberall gelitten,", "tokens": ["Er", "ist", "da\u00b7mit", "fast", "\u00fc\u00b7be\u00b7rall", "ge\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.189": {"text": "Auch zeigt er gern, wenn man's von ihm begehrt,", "tokens": ["Auch", "zeigt", "er", "gern", ",", "wenn", "man's", "von", "ihm", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "$,", "KOUS", "PIS", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.190": {"text": "Wie Reiter dieses Steckenpferd", "tokens": ["Wie", "Rei\u00b7ter", "die\u00b7ses", "Ste\u00b7cken\u00b7pferd"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "NN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.191": {"text": "Schulm\u00e4\u00dfig zu regieren haben,", "tokens": ["Schul\u00b7m\u00e4\u00b7\u00dfig", "zu", "re\u00b7gie\u00b7ren", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PTKZU", "VVINF", "VAFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.192": {"text": "Wie man bald \u00fcber Mauern, \u00fcber Graben,", "tokens": ["Wie", "man", "bald", "\u00fc\u00b7ber", "Mau\u00b7ern", ",", "\u00fc\u00b7ber", "Gra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ADV", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.193": {"text": "Und bald durch ein Verhack mit k\u00fchnen Spr\u00fcngen setzt,", "tokens": ["Und", "bald", "durch", "ein", "Ver\u00b7hack", "mit", "k\u00fch\u00b7nen", "Spr\u00fcn\u00b7gen", "setzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.194": {"text": "Wie man zu rechter Zeit Schritt reiten oder traben,", "tokens": ["Wie", "man", "zu", "rech\u00b7ter", "Zeit", "Schritt", "rei\u00b7ten", "o\u00b7der", "tra\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "APPR", "ADJA", "NN", "NN", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.195": {"text": "Auch galoppiren mu\u00df, und wie man so zuletzt,", "tokens": ["Auch", "ga\u00b7lop\u00b7pi\u00b7ren", "mu\u00df", ",", "und", "wie", "man", "so", "zu\u00b7letzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "$,", "KON", "PWAV", "PIS", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.196": {"text": "Die Tugend selbst im Fliehen m\u00fcde hetzt.", "tokens": ["Die", "Tu\u00b7gend", "selbst", "im", "Flie\u00b7hen", "m\u00fc\u00b7de", "hetzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.197": {"text": "Das Thier mag freilich mehr erg\u00f6tzen,", "tokens": ["Das", "Thier", "mag", "frei\u00b7lich", "mehr", "er\u00b7g\u00f6t\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.198": {"text": "Als jenes, Freund, wozu mir Plato rieth;", "tokens": ["Als", "je\u00b7nes", ",", "Freund", ",", "wo\u00b7zu", "mir", "Pla\u00b7to", "rieth", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "NN", "$,", "PWAV", "PPER", "NE", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.199": {"text": "Nur, halten Sie zu Gnaden, Herr Ovid!", "tokens": ["Nur", ",", "hal\u00b7ten", "Sie", "zu", "Gna\u00b7den", ",", "Herr", "O\u00b7vid", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "VVFIN", "PPER", "APPR", "NN", "$,", "NN", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.200": {"text": "Wenn wir das ihrige nicht recht nach W\u00fcrden sch\u00e4tzen.", "tokens": ["Wenn", "wir", "das", "ih\u00b7ri\u00b7ge", "nicht", "recht", "nach", "W\u00fcr\u00b7den", "sch\u00e4t\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "PPOSS", "PTKNEG", "ADJD", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.201": {"text": "Zwar will ich, nach Petrarchs Manier,", "tokens": ["Zwar", "will", "ich", ",", "nach", "Pe\u00b7trarchs", "Ma\u00b7nier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.202": {"text": "Nicht immer mich am Lob' des andern letzen,", "tokens": ["Nicht", "im\u00b7mer", "mich", "am", "Lob'", "des", "an\u00b7dern", "let\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "PPER", "APPRART", "NN", "ART", "ADJA", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.203": {"text": "Doch d\u00fcnkt mich, pa\u00dft das Spr\u00fcchwort hier:", "tokens": ["Doch", "d\u00fcnkt", "mich", ",", "pa\u00dft", "das", "Spr\u00fcch\u00b7wort", "hier", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.204": {"text": "Vom Pferde sich auf einen Esel setzen.", "tokens": ["Vom", "Pfer\u00b7de", "sich", "auf", "ei\u00b7nen", "E\u00b7sel", "set\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PRF", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.205": {"text": "Ich denke so: Wenn dir damit der Mann", "tokens": ["Ich", "den\u00b7ke", "so", ":", "Wenn", "dir", "da\u00b7mit", "der", "Mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$.", "KOUS", "PPER", "PAV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.206": {"text": "In dein Gehege kommt, wer hat es auszubaden?", "tokens": ["In", "dein", "Ge\u00b7he\u00b7ge", "kommt", ",", "wer", "hat", "es", "aus\u00b7zu\u00b7ba\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "PWS", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.207": {"text": "Herr ", "tokens": ["Herr"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.208": {"text": "Da Plato nie dir schaden kann.", "tokens": ["Da", "Pla\u00b7to", "nie", "dir", "scha\u00b7den", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "ADV", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.209": {"text": "La\u00dft Andre mit dem Spruche scherzen,", "tokens": ["La\u00dft", "And\u00b7re", "mit", "dem", "Spru\u00b7che", "scher\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PIS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.210": {"text": "Sch\u00f6n ist's doch, wenn in ", "tokens": ["Sch\u00f6n", "ist's", "doch", ",", "wenn", "in"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NE", "VAFIN", "ADV", "$,", "KOUS", "APPR"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.211": {"text": "Ein Trieb, ihn zu erf\u00fcllen, gl\u00fcht. \u2013", "tokens": ["Ein", "Trieb", ",", "ihn", "zu", "er\u00b7f\u00fcl\u00b7len", ",", "gl\u00fcht", ".", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.212": {"text": "Du kennst den Steckenpferde-Markt,", "tokens": ["Du", "kennst", "den", "Ste\u00b7cken\u00b7pfer\u00b7de\u00b7Markt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.213": {"text": "Wohin den K\u00f6nig, der ein Land regieret,", "tokens": ["Wo\u00b7hin", "den", "K\u00f6\u00b7nig", ",", "der", "ein", "Land", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.214": {"text": "So wie den Bettler, der zusammen harkt,", "tokens": ["So", "wie", "den", "Bett\u00b7ler", ",", "der", "zu\u00b7sam\u00b7men", "harkt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.215": {"text": "Was in der Stoppel sich verlieret,", "tokens": ["Was", "in", "der", "Stop\u00b7pel", "sich", "ver\u00b7lie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.216": {"text": "Der Wunsch, bequem zu reiten, f\u00fchret.", "tokens": ["Der", "Wunsch", ",", "be\u00b7quem", "zu", "rei\u00b7ten", ",", "f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "PTKZU", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.217": {"text": "Ich schlenderte darauf umher,", "tokens": ["Ich", "schlen\u00b7der\u00b7te", "da\u00b7rauf", "um\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.218": {"text": "Und w\u00fcnscht' ein Steckenpferd zu haben,", "tokens": ["Und", "w\u00fcnscht'", "ein", "Ste\u00b7cken\u00b7pferd", "zu", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.219": {"text": "Nicht v\u00f6llig so, doch ohngef\u00e4hr", "tokens": ["Nicht", "v\u00f6l\u00b7lig", "so", ",", "doch", "ohn\u00b7ge\u00b7f\u00e4hr"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PTKNEG", "ADJD", "ADV", "$,", "ADV", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.220": {"text": "Mit solchen sonderbaren Gaben,", "tokens": ["Mit", "sol\u00b7chen", "son\u00b7der\u00b7ba\u00b7ren", "Ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.221": {"text": "Als das, was ", "tokens": ["Als", "das", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["KOUS", "PDS", "$,", "PWS"], "meter": "+-+", "measure": "trochaic.di"}, "line.222": {"text": "Nicht um des Sonderbaren willen;", "tokens": ["Nicht", "um", "des", "Son\u00b7der\u00b7ba\u00b7ren", "wil\u00b7len", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.223": {"text": "Das w\u00e4re toller noch als toll!", "tokens": ["Das", "w\u00e4\u00b7re", "tol\u00b7ler", "noch", "als", "toll", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADJD", "ADV", "KOUS", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.224": {"text": "Ach nein! Ich sah mit meinen Grillen", "tokens": ["Ach", "nein", "!", "Ich", "sah", "mit", "mei\u00b7nen", "Gril\u00b7len"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "PTKANT", "$.", "PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.225": {"text": "Den einen Theil f\u00fcr wilde F\u00fcllen,", "tokens": ["Den", "ei\u00b7nen", "Theil", "f\u00fcr", "wil\u00b7de", "F\u00fcl\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.226": {"text": "Den andern Theil f\u00fcr steife M\u00e4hren an.", "tokens": ["Den", "an\u00b7dern", "Theil", "f\u00fcr", "stei\u00b7fe", "M\u00e4h\u00b7ren", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.227": {"text": "Ich hatte, wenn ich mich besann,", "tokens": ["Ich", "hat\u00b7te", ",", "wenn", "ich", "mich", "be\u00b7sann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.228": {"text": "Die mehrsten schon vordem geritten,", "tokens": ["Die", "mehrs\u00b7ten", "schon", "vor\u00b7dem", "ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "VVPP", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.229": {"text": "Und wie bedauert' ich den Mann,", "tokens": ["Und", "wie", "be\u00b7dau\u00b7ert'", "ich", "den", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.230": {"text": "Der Eins davon bestieg; was ich darauf erlitten,", "tokens": ["Der", "Eins", "da\u00b7von", "be\u00b7stieg", ";", "was", "ich", "da\u00b7rauf", "er\u00b7lit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PAV", "VVFIN", "$.", "PWS", "PPER", "PAV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.231": {"text": "Dacht' ich betr\u00fcbt, das ficht auf seinen Ritten", "tokens": ["Dacht'", "ich", "be\u00b7tr\u00fcbt", ",", "das", "ficht", "auf", "sei\u00b7nen", "Rit\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "VVPP", "$,", "PRELS", "ADJD", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.232": {"text": "Ihn sicher auch, wohl noch was \u00e4rgers an.", "tokens": ["Ihn", "si\u00b7cher", "auch", ",", "wohl", "noch", "was", "\u00e4r\u00b7gers", "an", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "ADV", "$,", "ADV", "ADV", "PWS", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.233": {"text": "Tagt\u00e4glich sucht' ich da sechs Stunden,", "tokens": ["Tag\u00b7t\u00e4g\u00b7lich", "sucht'", "ich", "da", "sechs", "Stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "ADV", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.234": {"text": "Doch keins gefiel mir recht. Vielleicht aus Ueberdru\u00df,", "tokens": ["Doch", "keins", "ge\u00b7fiel", "mir", "recht", ".", "Viel\u00b7leicht", "aus", "Ue\u00b7berd\u00b7ru\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "ADJD", "$.", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.235": {"text": "Weil ich gerade keins gefunden,", "tokens": ["Weil", "ich", "ge\u00b7ra\u00b7de", "keins", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.236": {"text": "Das mir nach Sinne ging, macht' ich den falschen Schlu\u00df:", "tokens": ["Das", "mir", "nach", "Sin\u00b7ne", "ging", ",", "macht'", "ich", "den", "fal\u00b7schen", "Schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPER", "APPR", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.237": {"text": "Ein Steckenpferd, das selten zum Verdru\u00df',", "tokens": ["Ein", "Ste\u00b7cken\u00b7pferd", ",", "das", "sel\u00b7ten", "zum", "Ver\u00b7dru\u00df'", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.238": {"text": "Oft zum Vergn\u00fcgen trabt, sey mit ", "tokens": ["Oft", "zum", "Ver\u00b7gn\u00fc\u00b7gen", "trabt", ",", "sey", "mit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VVFIN", "$,", "VAFIN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.239": {"text": "Aus diesem Jammerthal' verschwunden.", "tokens": ["Aus", "die\u00b7sem", "Jam\u00b7mert\u00b7hal'", "ver\u00b7schwun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.240": {"text": "Ei nicht doch! riefen viele weise M\u00e4nner,", "tokens": ["Ei", "nicht", "doch", "!", "rie\u00b7fen", "vie\u00b7le", "wei\u00b7se", "M\u00e4n\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ADV", "$.", "VVFIN", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.241": {"text": "Wir sind die rechten Steckenpferde-Kenner,", "tokens": ["Wir", "sind", "die", "rech\u00b7ten", "Ste\u00b7cken\u00b7pfer\u00b7de\u00b7Ken\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.242": {"text": "Wie unser Ruhm das schon bezeugen mu\u00df.", "tokens": ["Wie", "un\u00b7ser", "Ruhm", "das", "schon", "be\u00b7zeu\u00b7gen", "mu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "ADV", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.243": {"text": "Allein ein ", "tokens": ["Al\u00b7lein", "ein"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-+", "measure": "trochaic.di"}, "line.244": {"text": "Das ist nur Sache f\u00fcr den Tro\u00df!", "tokens": ["Das", "ist", "nur", "Sa\u00b7che", "f\u00fcr", "den", "Tro\u00df", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.245": {"text": "Doch will der Herr ein stattlich ", "tokens": ["Doch", "will", "der", "Herr", "ein", "statt\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ART", "NN", "ART", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.246": {"text": "So k\u00f6nnen wir ihm schier das Beste weisen.", "tokens": ["So", "k\u00f6n\u00b7nen", "wir", "ihm", "schier", "das", "Bes\u00b7te", "wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PPER", "ADJD", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.247": {"text": "Der D\u00fcnkel, ein Paradepferd", "tokens": ["Der", "D\u00fcn\u00b7kel", ",", "ein", "Pa\u00b7ra\u00b7de\u00b7pferd"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.248": {"text": "Wie Herr ", "tokens": ["Wie", "Herr"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+", "measure": "iambic.single"}, "line.249": {"text": "Den Mancher noch als Mann erf\u00e4hrt,", "tokens": ["Den", "Man\u00b7cher", "noch", "als", "Mann", "er\u00b7f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.250": {"text": "Der sollte mich als J\u00fcngling nicht verleiten?", "tokens": ["Der", "soll\u00b7te", "mich", "als", "J\u00fcng\u00b7ling", "nicht", "ver\u00b7lei\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "KOUS", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.251": {"text": "Mit einem ernsten Angesicht',", "tokens": ["Mit", "ei\u00b7nem", "erns\u00b7ten", "An\u00b7ge\u00b7sicht'", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.252": {"text": "Bestieg ich dieses Ro\u00df, und ritt, (ich hielt's f\u00fcr Pflicht!)", "tokens": ["Be\u00b7stieg", "ich", "die\u00b7ses", "Ro\u00df", ",", "und", "ritt", ",", "(", "ich", "hielt's", "f\u00fcr", "Pflicht", "!", ")"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "PDAT", "NN", "$,", "KON", "VVFIN", "$,", "$(", "PPER", "VVFIN", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.253": {"text": "Bei Tag und Nacht, und \u00fcber Stock und Stein,", "tokens": ["Bei", "Tag", "und", "Nacht", ",", "und", "\u00fc\u00b7ber", "Stock", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "KON", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.254": {"text": "Den Weisheitstempel aufzufinden,", "tokens": ["Den", "Weis\u00b7heits\u00b7tem\u00b7pel", "auf\u00b7zu\u00b7fin\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.255": {"text": "Ach aber, ach! ich fand ihn nicht.", "tokens": ["Ach", "a\u00b7ber", ",", "ach", "!", "ich", "fand", "ihn", "nicht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "ADV", "$,", "ITJ", "$.", "PPER", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.256": {"text": "Itzt seh' ich wohl die Ursach' ein:", "tokens": ["Itzt", "seh'", "ich", "wohl", "die", "Ur\u00b7sach'", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.257": {"text": "Ich ritt, was leugn' ich's noch? im Blinden!", "tokens": ["Ich", "ritt", ",", "was", "leugn'", "ich's", "noch", "?", "im", "Blin\u00b7den", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWS", "VVFIN", "PIS", "ADV", "$.", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.258": {"text": "Sonst h\u00e4tt' ich wohl den Fu\u00dfsteg sehen m\u00fcssen,", "tokens": ["Sonst", "h\u00e4tt'", "ich", "wohl", "den", "Fu\u00df\u00b7steg", "se\u00b7hen", "m\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.259": {"text": "Der zwischen zwei bebl\u00fcmten Fl\u00fcssen", "tokens": ["Der", "zwi\u00b7schen", "zwei", "be\u00b7bl\u00fcm\u00b7ten", "Fl\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.260": {"text": "Auf Rasen hin, zum Tempel lief.", "tokens": ["Auf", "Ra\u00b7sen", "hin", ",", "zum", "Tem\u00b7pel", "lief", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKVZ", "$,", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.261": {"text": "Auf einmal h\u00f6rt' ich eine Stimme,", "tokens": ["Auf", "ein\u00b7mal", "h\u00f6rt'", "ich", "ei\u00b7ne", "Stim\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.262": {"text": "Die, von ", "tokens": ["Die", ",", "von"], "token_info": ["word", "punct", "word"], "pos": ["ART", "$,", "APPR"], "meter": "+-", "measure": "trochaic.single"}, "line.263": {"text": "\u00bbwo wollt Ihr hin? Ihr reitet in die Kr\u00fcmme!", "tokens": ["\u00bb", "wo", "wollt", "Ihr", "hin", "?", "Ihr", "rei\u00b7tet", "in", "die", "Kr\u00fcm\u00b7me", "!"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "VMFIN", "PPER", "PTKVZ", "$.", "PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.264": {"text": "Euch hat der Tr\u00fcbsinn ohne Streit", "tokens": ["Euch", "hat", "der", "Tr\u00fcb\u00b7sinn", "oh\u00b7ne", "Streit"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.265": {"text": "Auf diesen Kn\u00fcppeldamm geleitet,", "tokens": ["Auf", "die\u00b7sen", "Kn\u00fcp\u00b7pel\u00b7damm", "ge\u00b7lei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.266": {"text": "Doch wi\u00dft, zu kurz ist oft die Lebenszeit,", "tokens": ["Doch", "wi\u00dft", ",", "zu", "kurz", "ist", "oft", "die", "Le\u00b7bens\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PTKA", "ADJD", "VAFIN", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.267": {"text": "Und wenn Ihr noch so scharf auch reitet,", "tokens": ["Und", "wenn", "Ihr", "noch", "so", "scharf", "auch", "rei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "VVFIN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.268": {"text": "Den Tempel zu erreichen: denn so weit", "tokens": ["Den", "Tem\u00b7pel", "zu", "er\u00b7rei\u00b7chen", ":", "denn", "so", "weit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$.", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.269": {"text": "H\u00e4lt's Niemand aus; er wird, wie ein Courier,", "tokens": ["H\u00e4lt's", "Nie\u00b7mand", "aus", ";", "er", "wird", ",", "wie", "ein", "Cou\u00b7rier", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "PIS", "PTKVZ", "$.", "PPER", "VAFIN", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.270": {"text": "Wund, lahm, und mu\u00df wohl gar am Ende liegen bleiben.", "tokens": ["Wund", ",", "lahm", ",", "und", "mu\u00df", "wohl", "gar", "am", "En\u00b7de", "lie\u00b7gen", "blei\u00b7ben", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PTKVZ", "$,", "KON", "VMFIN", "ADV", "ADV", "APPRART", "NN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.271": {"text": "Doch, guter Freund! sollt' Euch die Ruhmbegier", "tokens": ["Doch", ",", "gu\u00b7ter", "Freund", "!", "sollt'", "Euch", "die", "Ruhm\u00b7be\u00b7gier"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "$,", "ADJA", "NN", "$.", "VMFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.272": {"text": "Mehr, als der Durst nach wahrer Weisheit, treiben,", "tokens": ["Mehr", ",", "als", "der", "Durst", "nach", "wah\u00b7rer", "Weis\u00b7heit", ",", "trei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PIS", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.273": {"text": "So reitet nur!\u00ab", "tokens": ["So", "rei\u00b7tet", "nur", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ADV", "$.", "$("], "meter": "-+-+", "measure": "iambic.di"}, "line.274": {"text": "Ich sah den Mann", "tokens": ["Ich", "sah", "den", "Mann"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.275": {"text": "Der so entscheidend sprach, mit gro\u00dfen Augen an,", "tokens": ["Der", "so", "ent\u00b7schei\u00b7dend", "sprach", ",", "mit", "gro\u00b7\u00dfen", "Au\u00b7gen", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VVFIN", "$,", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.276": {"text": "Und h\u00e4tt' ihn gern geha\u00dft, und doch mu\u00dft' ich ihn lieben.", "tokens": ["Und", "h\u00e4tt'", "ihn", "gern", "ge\u00b7ha\u00dft", ",", "und", "doch", "mu\u00dft'", "ich", "ihn", "lie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "$,", "KON", "ADV", "VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.277": {"text": "Ich w\u00fcnscht' ihn weg, und folgt' ihm, als er ging.", "tokens": ["Ich", "w\u00fcnscht'", "ihn", "weg", ",", "und", "folgt'", "ihm", ",", "als", "er", "ging", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.278": {"text": "O Sympathie! du bist ein seltsam Ding.", "tokens": ["O", "Sym\u00b7pa\u00b7thie", "!", "du", "bist", "ein", "selt\u00b7sam", "Ding", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPER", "VAFIN", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.279": {"text": "Zehn Meilen weit hast du das Herz getrieben,", "tokens": ["Zehn", "Mei\u00b7len", "weit", "hast", "du", "das", "Herz", "ge\u00b7trie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "ADJD", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.280": {"text": "Eh' die Vernunft zehn Schritte ging.", "tokens": ["Eh'", "die", "Ver\u00b7nunft", "zehn", "Schrit\u00b7te", "ging", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "CARD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.281": {"text": "Dank aber sey der guten Sympathie!", "tokens": ["Dank", "a\u00b7ber", "sey", "der", "gu\u00b7ten", "Sym\u00b7pa\u00b7thie", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.282": {"text": "Gefunden h\u00e4tt' ich nie, gefunden", "tokens": ["Ge\u00b7fun\u00b7den", "h\u00e4tt'", "ich", "nie", ",", "ge\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "VAFIN", "PPER", "ADV", "$,", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.283": {"text": "Den Freund und Retter ohne sie,", "tokens": ["Den", "Freund", "und", "Ret\u00b7ter", "oh\u00b7ne", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.284": {"text": "Der singend mich in wenig Stunden", "tokens": ["Der", "sin\u00b7gend", "mich", "in", "we\u00b7nig", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "PRF", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.285": {"text": "Dem Tempel n\u00e4her bracht', als ich im ganzen Jahr'", "tokens": ["Dem", "Tem\u00b7pel", "n\u00e4\u00b7her", "bracht'", ",", "als", "ich", "im", "gan\u00b7zen", "Jahr'"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "KOUS", "PPER", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.286": {"text": "Ihm keuchend nachgekommen war.", "tokens": ["Ihm", "keu\u00b7chend", "nach\u00b7ge\u00b7kom\u00b7men", "war", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.287": {"text": "Ihr B\u00fccher-Weisen, nehmt denn ein Exempel!", "tokens": ["Ihr", "B\u00fc\u00b7cher\u00b7Wei\u00b7sen", ",", "nehmt", "denn", "ein", "Ex\u00b7em\u00b7pel", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.288": {"text": "An mir, und sehet in der Zeit", "tokens": ["An", "mir", ",", "und", "se\u00b7het", "in", "der", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "$,", "KON", "VVFIN", "APPR", "ART", "NN"], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.289": {"text": "Nach solchem Freund' Euch um; denn wi\u00dft, der Tempel", "tokens": ["Nach", "sol\u00b7chem", "Freund'", "Euch", "um", ";", "denn", "wi\u00dft", ",", "der", "Tem\u00b7pel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PIAT", "NN", "PPER", "PTKVZ", "$.", "KON", "VVFIN", "$,", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.290": {"text": "War nicht der Weisheit, die Ihr sucht, geweiht:", "tokens": ["War", "nicht", "der", "Weis\u00b7heit", ",", "die", "Ihr", "sucht", ",", "ge\u00b7weiht", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.291": {"text": "Die Inschrift hie\u00df: ", "tokens": ["Die", "In\u00b7schrift", "hie\u00df", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.292": {"text": "Itzt ziehen Freundschaft und Zufriedenheit", "tokens": ["Itzt", "zie\u00b7hen", "Freund\u00b7schaft", "und", "Zu\u00b7frie\u00b7den\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.293": {"text": "An meinem Phaeton der Freude;", "tokens": ["An", "mei\u00b7nem", "Phae\u00b7ton", "der", "Freu\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ART", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.294": {"text": "Sitz' ich darin, ei dann beneide,", "tokens": ["Sitz'", "ich", "da\u00b7rin", ",", "ei", "dann", "be\u00b7nei\u00b7de", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PAV", "$,", "ITJ", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.295": {"text": "Wer mag, den Mann, der stolz mit Sechsen f\u00e4hrt.", "tokens": ["Wer", "mag", ",", "den", "Mann", ",", "der", "stolz", "mit", "Sech\u00b7sen", "f\u00e4hrt", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "$,", "ART", "NN", "$,", "PRELS", "ADJD", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.296": {"text": "Noch eher war ", "tokens": ["Noch", "e\u00b7her", "war"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADV", "VAFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.297": {"text": "Auf seinem Klepper neideswerth;", "tokens": ["Auf", "sei\u00b7nem", "Klep\u00b7per", "nei\u00b7des\u00b7werth", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.298": {"text": "Der ritt und sang nur zum Vergn\u00fcgen, Lieder.", "tokens": ["Der", "ritt", "und", "sang", "nur", "zum", "Ver\u00b7gn\u00fc\u00b7gen", ",", "Lie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "VVFIN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.299": {"text": "Itzt hab' ich selbst ein \u00e4hnlich Steckenpferd.", "tokens": ["Itzt", "hab'", "ich", "selbst", "ein", "\u00e4hn\u00b7lich", "Ste\u00b7cken\u00b7pferd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.300": {"text": "Auf diesem reit' ich oft spatzieren,", "tokens": ["Auf", "die\u00b7sem", "reit'", "ich", "oft", "spat\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "VVFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.301": {"text": "Um meine Grillen zu verlieren,", "tokens": ["Um", "mei\u00b7ne", "Gril\u00b7len", "zu", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.302": {"text": "Zuweilen auch, um an des Teiches Rohr", "tokens": ["Zu\u00b7wei\u00b7len", "auch", ",", "um", "an", "des", "Tei\u00b7ches", "Rohr"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "$,", "KOUI", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.303": {"text": "Die halbe Sommernacht mit ihnen zu durchwachen,", "tokens": ["Die", "hal\u00b7be", "Som\u00b7mer\u00b7nacht", "mit", "ih\u00b7nen", "zu", "durch\u00b7wa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.304": {"text": "Und oft, dem Zwergfell', wenn ein Thor", "tokens": ["Und", "oft", ",", "dem", "Zwerg\u00b7fell'", ",", "wenn", "ein", "Thor"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.305": {"text": "Gereitzt es hatte, Luft zu machen.", "tokens": ["Ge\u00b7reitzt", "es", "hat\u00b7te", ",", "Luft", "zu", "ma\u00b7chen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "$,", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.306": {"text": "Frag' nur die Herrn Poeten allzumal,", "tokens": ["Frag'", "nur", "die", "Herrn", "Po\u00b7et\u00b7en", "all\u00b7zu\u00b7mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "ART", "NN", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.307": {"text": "Wie angenehm ein Ritt auf diesem Steckenpferde", "tokens": ["Wie", "an\u00b7ge\u00b7nehm", "ein", "Ritt", "auf", "die\u00b7sem", "Ste\u00b7cken\u00b7pfer\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "ART", "NN", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.308": {"text": "Dem Reiter thut, wenn's \u00fcber Berg und Thal", "tokens": ["Dem", "Rei\u00b7ter", "thut", ",", "wenn's", "\u00fc\u00b7ber", "Berg", "und", "Thal"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$,", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.309": {"text": "Dahinfliegt: Ha! wie klein wird da die Erde!", "tokens": ["Da\u00b7hin\u00b7fliegt", ":", "Ha", "!", "wie", "klein", "wird", "da", "die", "Er\u00b7de", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "ITJ", "$.", "PWAV", "ADJD", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.310": {"text": "Mein zweites Steckenpferd, die ", "tokens": ["Mein", "zwei\u00b7tes", "Ste\u00b7cken\u00b7pferd", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["PPOSAT", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.311": {"text": "Auch noch nicht Einmal ward es lahm.", "tokens": ["Auch", "noch", "nicht", "Ein\u00b7mal", "ward", "es", "lahm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PTKNEG", "ADV", "VAFIN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.312": {"text": "Es hat zuweilen wohl ein Schauer", "tokens": ["Es", "hat", "zu\u00b7wei\u00b7len", "wohl", "ein", "Schau\u00b7er"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.313": {"text": "Von Tr\u00e4gheit, aber nie von Koller, oder Gram.", "tokens": ["Von", "Tr\u00e4g\u00b7heit", ",", "a\u00b7ber", "nie", "von", "Kol\u00b7ler", ",", "o\u00b7der", "Gram", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ADV", "APPR", "NE", "$,", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.314": {"text": "Das magst du einst als Trauerpferd,", "tokens": ["Das", "magst", "du", "einst", "als", "Trau\u00b7er\u00b7pferd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.315": {"text": "Mein lieber ", "tokens": ["Mein", "lie\u00b7ber"], "token_info": ["word", "word"], "pos": ["PPOSAT", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.316": {"text": "Ein Kritiker, h\u00e4lt er's der M\u00fche werth,", "tokens": ["Ein", "Kri\u00b7ti\u00b7ker", ",", "h\u00e4lt", "er's", "der", "M\u00fc\u00b7he", "werth", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PIS", "ART", "NN", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.317": {"text": "Mag meinethalb das Freudenpferd beschreiten.", "tokens": ["Mag", "mei\u00b7net\u00b7halb", "das", "Freu\u00b7den\u00b7pferd", "be\u00b7schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}