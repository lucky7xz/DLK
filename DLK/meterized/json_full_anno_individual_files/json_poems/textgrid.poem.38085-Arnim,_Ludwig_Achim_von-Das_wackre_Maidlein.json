{"textgrid.poem.38085": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Das wackre Maidlein", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Es war ein wacker Maidlein wohlgethan,", "tokens": ["Es", "war", "ein", "wa\u00b7cker", "Maid\u00b7lein", "wohl\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie ging an ihres Vaters Zinne stahn,", "tokens": ["Sie", "ging", "an", "ih\u00b7res", "Va\u00b7ters", "Zin\u00b7ne", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sah daraus,", "tokens": ["Sie", "sah", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sie sah dahere reiten", "tokens": ["Sie", "sah", "da\u00b7he\u00b7re", "rei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihrem Herzen einen Trost.", "tokens": ["Ih\u00b7rem", "Her\u00b7zen", "ei\u00b7nen", "Trost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Ach Maidelein voll der Wonne,", "tokens": ["Ach", "Mai\u00b7de\u00b7lein", "voll", "der", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Falbet euch die Sonne,", "tokens": ["Fal\u00b7bet", "euch", "die", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df ihr seyd worden bleich,", "tokens": ["Da\u00df", "ihr", "seyd", "wor\u00b7den", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "VAPP", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hat euch ein andrer lieber dann ich,", "tokens": ["Hat", "euch", "ein", "an\u00b7drer", "lie\u00b7ber", "dann", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "ADV", "PPER", "$,"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Das reuet mich.", "tokens": ["Das", "reu\u00b7et", "mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.3": {"line.1": {"text": "Warum sollt ich nicht werden bleich,", "tokens": ["Wa\u00b7rum", "sollt", "ich", "nicht", "wer\u00b7den", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "VAFIN", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Ich trag alle Tag gro\u00df Herzeleid,", "tokens": ["Ich", "trag", "al\u00b7le", "Tag", "gro\u00df", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Allein sch\u00f6ns Lieb um dich,", "tokens": ["Al\u00b7lein", "sch\u00f6ns", "Lieb", "um", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df du mich verkiesen willt,", "tokens": ["Da\u00df", "du", "mich", "ver\u00b7kie\u00b7sen", "willt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das reuet mich.", "tokens": ["Das", "reu\u00b7et", "mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.4": {"line.1": {"text": "Warum sollt ich dich verkiesen,", "tokens": ["Wa\u00b7rum", "sollt", "ich", "dich", "ver\u00b7kie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich hab dich noch viel lieber", "tokens": ["Ich", "hab", "dich", "noch", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als alle Freunde mein,", "tokens": ["Als", "al\u00b7le", "Freun\u00b7de", "mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPOSAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ach Maidelein la\u00df dein Sorgen", "tokens": ["Ach", "Mai\u00b7de\u00b7lein", "la\u00df", "dein", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und folge du mir.", "tokens": ["Und", "fol\u00b7ge", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.5": {"line.1": {"text": "Worin ging sie ihm entgegen?", "tokens": ["Wo\u00b7rin", "ging", "sie", "ihm", "ent\u00b7ge\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "In eim seiden Hemdlein war wohl gen\u00e4ht,", "tokens": ["In", "eim", "sei\u00b7den", "Hemd\u00b7lein", "war", "wohl", "ge\u00b7n\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das war so fein,", "tokens": ["Das", "war", "so", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Darin ging sie geschn\u00fcret", "tokens": ["Da\u00b7rin", "ging", "sie", "ge\u00b7schn\u00fc\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das wacker Maidelein.", "tokens": ["Das", "wa\u00b7cker", "Mai\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Er nahm sie bey ihrer schneewei\u00dfen Hand,", "tokens": ["Er", "nahm", "sie", "bey", "ih\u00b7rer", "schnee\u00b7wei\u00b7\u00dfen", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Er f\u00fchrt sie durch den gr\u00fcnen Wald,", "tokens": ["Er", "f\u00fchrt", "sie", "durch", "den", "gr\u00fc\u00b7nen", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da brach er ihr einen Zweig,", "tokens": ["Da", "brach", "er", "ihr", "ei\u00b7nen", "Zweig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie k\u00fcsset ihn auf seinen rothen Mund,", "tokens": ["Sie", "k\u00fcs\u00b7set", "ihn", "auf", "sei\u00b7nen", "ro\u00b7then", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das wackre Maidelein.", "tokens": ["Das", "wack\u00b7re", "Mai\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und da es kam zur halben Mitternacht", "tokens": ["Und", "da", "es", "kam", "zur", "hal\u00b7ben", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der gute Held nahm Urlaub von der Magd,", "tokens": ["Der", "gu\u00b7te", "Held", "nahm", "Ur\u00b7laub", "von", "der", "Magd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Derselbig gute Held", "tokens": ["Der\u00b7sel\u00b7big", "gu\u00b7te", "Held"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Treu, die er ihr gelobet hat,", "tokens": ["Die", "Treu", ",", "die", "er", "ihr", "ge\u00b7lo\u00b7bet", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVFIN", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die hielt er nicht.", "tokens": ["Die", "hielt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.8": {"line.1": {"text": "Und w\u00e4r ich weisser denn ein Schwan,", "tokens": ["Und", "w\u00e4r", "ich", "weis\u00b7ser", "denn", "ein", "Schwan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wollt mich schwingen \u00fcber Berg und tiefe Thal,", "tokens": ["Ich", "wollt", "mich", "schwin\u00b7gen", "\u00fc\u00b7ber", "Berg", "und", "tie\u00b7fe", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wollt fahren \u00fcber'n Rhein,", "tokens": ["Wollt", "fah\u00b7ren", "\u00fc\u00b7ber'n", "Rhein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und w\u00fc\u00dften das all die Freunde mein,", "tokens": ["Und", "w\u00fc\u00df\u00b7ten", "das", "all", "die", "Freun\u00b7de", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIAT", "ART", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie s\u00e4ngen mir ein Liedelein.", "tokens": ["Sie", "s\u00e4n\u00b7gen", "mir", "ein", "Lie\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Es war ein wacker Maidlein wohlgethan,", "tokens": ["Es", "war", "ein", "wa\u00b7cker", "Maid\u00b7lein", "wohl\u00b7ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Sie ging an ihres Vaters Zinne stahn,", "tokens": ["Sie", "ging", "an", "ih\u00b7res", "Va\u00b7ters", "Zin\u00b7ne", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sah daraus,", "tokens": ["Sie", "sah", "da\u00b7raus", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Sie sah dahere reiten", "tokens": ["Sie", "sah", "da\u00b7he\u00b7re", "rei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PAV", "VVFIN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Ihrem Herzen einen Trost.", "tokens": ["Ih\u00b7rem", "Her\u00b7zen", "ei\u00b7nen", "Trost", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Ach Maidelein voll der Wonne,", "tokens": ["Ach", "Mai\u00b7de\u00b7lein", "voll", "der", "Won\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "NN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Falbet euch die Sonne,", "tokens": ["Fal\u00b7bet", "euch", "die", "Son\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df ihr seyd worden bleich,", "tokens": ["Da\u00df", "ihr", "seyd", "wor\u00b7den", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAFIN", "VAPP", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Hat euch ein andrer lieber dann ich,", "tokens": ["Hat", "euch", "ein", "an\u00b7drer", "lie\u00b7ber", "dann", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "ADJA", "ADV", "ADV", "PPER", "$,"], "meter": "-+-+-+---", "measure": "unknown.measure.tri"}, "line.5": {"text": "Das reuet mich.", "tokens": ["Das", "reu\u00b7et", "mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.11": {"line.1": {"text": "Warum sollt ich nicht werden bleich,", "tokens": ["Wa\u00b7rum", "sollt", "ich", "nicht", "wer\u00b7den", "bleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PTKNEG", "VAFIN", "ADJD", "$,"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Ich trag alle Tag gro\u00df Herzeleid,", "tokens": ["Ich", "trag", "al\u00b7le", "Tag", "gro\u00df", "Her\u00b7ze\u00b7leid", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "ADJD", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Allein sch\u00f6ns Lieb um dich,", "tokens": ["Al\u00b7lein", "sch\u00f6ns", "Lieb", "um", "dich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df du mich verkiesen willt,", "tokens": ["Da\u00df", "du", "mich", "ver\u00b7kie\u00b7sen", "willt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Das reuet mich.", "tokens": ["Das", "reu\u00b7et", "mich", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.12": {"line.1": {"text": "Warum sollt ich dich verkiesen,", "tokens": ["Wa\u00b7rum", "sollt", "ich", "dich", "ver\u00b7kie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "PRF", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ich hab dich noch viel lieber", "tokens": ["Ich", "hab", "dich", "noch", "viel", "lie\u00b7ber"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ADV", "ADV"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als alle Freunde mein,", "tokens": ["Als", "al\u00b7le", "Freun\u00b7de", "mein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PPOSAT", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Ach Maidelein la\u00df dein Sorgen", "tokens": ["Ach", "Mai\u00b7de\u00b7lein", "la\u00df", "dein", "Sor\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ITJ", "NN", "VVIMP", "PPOSAT", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.5": {"text": "Und folge du mir.", "tokens": ["Und", "fol\u00b7ge", "du", "mir", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PPER", "$."], "meter": "-+--+", "measure": "iambic.di.chol"}}, "stanza.13": {"line.1": {"text": "Worin ging sie ihm entgegen?", "tokens": ["Wo\u00b7rin", "ging", "sie", "ihm", "ent\u00b7ge\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "PPER", "PTKVZ", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "In eim seiden Hemdlein war wohl gen\u00e4ht,", "tokens": ["In", "eim", "sei\u00b7den", "Hemd\u00b7lein", "war", "wohl", "ge\u00b7n\u00e4ht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "--+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Das war so fein,", "tokens": ["Das", "war", "so", "fein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Darin ging sie geschn\u00fcret", "tokens": ["Da\u00b7rin", "ging", "sie", "ge\u00b7schn\u00fc\u00b7ret"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Das wacker Maidelein.", "tokens": ["Das", "wa\u00b7cker", "Mai\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Er nahm sie bey ihrer schneewei\u00dfen Hand,", "tokens": ["Er", "nahm", "sie", "bey", "ih\u00b7rer", "schnee\u00b7wei\u00b7\u00dfen", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+---+-+", "measure": "zehnsilber"}, "line.2": {"text": "Er f\u00fchrt sie durch den gr\u00fcnen Wald,", "tokens": ["Er", "f\u00fchrt", "sie", "durch", "den", "gr\u00fc\u00b7nen", "Wald", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da brach er ihr einen Zweig,", "tokens": ["Da", "brach", "er", "ihr", "ei\u00b7nen", "Zweig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PPER", "ART", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sie k\u00fcsset ihn auf seinen rothen Mund,", "tokens": ["Sie", "k\u00fcs\u00b7set", "ihn", "auf", "sei\u00b7nen", "ro\u00b7then", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Das wackre Maidelein.", "tokens": ["Das", "wack\u00b7re", "Mai\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Und da es kam zur halben Mitternacht", "tokens": ["Und", "da", "es", "kam", "zur", "hal\u00b7ben", "Mit\u00b7ter\u00b7nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der gute Held nahm Urlaub von der Magd,", "tokens": ["Der", "gu\u00b7te", "Held", "nahm", "Ur\u00b7laub", "von", "der", "Magd", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Derselbig gute Held", "tokens": ["Der\u00b7sel\u00b7big", "gu\u00b7te", "Held"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Die Treu, die er ihr gelobet hat,", "tokens": ["Die", "Treu", ",", "die", "er", "ihr", "ge\u00b7lo\u00b7bet", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PPER", "VVFIN", "VAFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Die hielt er nicht.", "tokens": ["Die", "hielt", "er", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.16": {"line.1": {"text": "Und w\u00e4r ich weisser denn ein Schwan,", "tokens": ["Und", "w\u00e4r", "ich", "weis\u00b7ser", "denn", "ein", "Schwan", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADJD", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich wollt mich schwingen \u00fcber Berg und tiefe Thal,", "tokens": ["Ich", "wollt", "mich", "schwin\u00b7gen", "\u00fc\u00b7ber", "Berg", "und", "tie\u00b7fe", "Thal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wollt fahren \u00fcber'n Rhein,", "tokens": ["Wollt", "fah\u00b7ren", "\u00fc\u00b7ber'n", "Rhein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "VVINF", "APPR", "NE", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Und w\u00fc\u00dften das all die Freunde mein,", "tokens": ["Und", "w\u00fc\u00df\u00b7ten", "das", "all", "die", "Freun\u00b7de", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIAT", "ART", "NN", "PPOSAT", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Sie s\u00e4ngen mir ein Liedelein.", "tokens": ["Sie", "s\u00e4n\u00b7gen", "mir", "ein", "Lie\u00b7de\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}