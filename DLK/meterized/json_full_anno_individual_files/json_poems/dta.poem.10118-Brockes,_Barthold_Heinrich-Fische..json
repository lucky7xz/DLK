{"dta.poem.10118": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Fische.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Welch ungeheure Meng' an Fischen klein und gro\u00df,", "tokens": ["Welch", "un\u00b7ge\u00b7heu\u00b7re", "Meng'", "an", "Fi\u00b7schen", "klein", "und", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "APPR", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die alle Zahlen \u00fcbersteiget,", "tokens": ["Die", "al\u00b7le", "Zah\u00b7len", "\u00fc\u00b7bers\u00b7tei\u00b7get", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wird in des weit-und tieffen Meeres Schoo\u00df,", "tokens": ["Wird", "in", "des", "weit\u00b7\u00b7und", "tief\u00b7fen", "Mee\u00b7res", "Schoo\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "ART", "ADJA", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "O HERR, zu Deiner Ehr, und uns zum Nutz, erzeuget!", "tokens": ["O", "HeRR", ",", "zu", "Dei\u00b7ner", "Ehr", ",", "und", "uns", "zum", "Nutz", ",", "er\u00b7zeu\u00b7get", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["NE", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "KON", "PPER", "APPRART", "NN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Ich sehe diese Wasser-Thier\u2019", "tokens": ["Ich", "se\u00b7he", "die\u00b7se", "Was\u00b7ser\u00b7Thier'"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und ihre Form bewundernd an:", "tokens": ["Und", "ih\u00b7re", "Form", "be\u00b7wun\u00b7dernd", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sie kommen mir nicht anders f\u00fcr,", "tokens": ["Sie", "kom\u00b7men", "mir", "nicht", "an\u00b7ders", "f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ADV", "APPR", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als h\u00e4tten sie nur Kopf und Schwantz allein.", "tokens": ["Als", "h\u00e4t\u00b7ten", "sie", "nur", "Kopf", "und", "Schwantz", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "ADV", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie haben weder Arm noch Bein,", "tokens": ["Sie", "ha\u00b7ben", "we\u00b7der", "Arm", "noch", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ja selbst ihr Kopf ist fest, und kann sich nicht bewegen,", "tokens": ["Ja", "selbst", "ihr", "Kopf", "ist", "fest", ",", "und", "kann", "sich", "nicht", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ADV", "PPOSAT", "NN", "VAFIN", "ADJD", "$,", "KON", "VMFIN", "PRF", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So da\u00df, wenn wir nur blo\u00df von ihnen die Gestalten", "tokens": ["So", "da\u00df", ",", "wenn", "wir", "nur", "blo\u00df", "von", "ih\u00b7nen", "die", "Ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "$,", "KOUS", "PPER", "ADV", "ADV", "APPR", "PPER", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Betrachten, sehn, und \u00fcberlegen;", "tokens": ["Be\u00b7trach\u00b7ten", ",", "sehn", ",", "und", "\u00fc\u00b7berl\u00b7e\u00b7gen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$,", "KON", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "Wir anders fast nicht dencken k\u00f6nnen,", "tokens": ["Wir", "an\u00b7ders", "fast", "nicht", "den\u00b7cken", "k\u00f6n\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "PTKNEG", "VVINF", "VMINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Als h\u00e4tte die Natur, sie zu erhalten,", "tokens": ["Als", "h\u00e4t\u00b7te", "die", "Na\u00b7tur", ",", "sie", "zu", "er\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Denselben gar kein Mittel wollen g\u00f6nnen.", "tokens": ["Den\u00b7sel\u00b7ben", "gar", "kein", "Mit\u00b7tel", "wol\u00b7len", "g\u00f6n\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Doch was ich auch bey ihnen \u00e4usserlich", "tokens": ["Doch", "was", "ich", "auch", "bey", "ih\u00b7nen", "\u00e4us\u00b7ser\u00b7lich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWS", "PPER", "ADV", "APPR", "PPER", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "F\u00fcr schlechtes Werck-Zeug immer finde;", "tokens": ["F\u00fcr", "schlech\u00b7tes", "Wer\u00b7ck\u00b7Zeug", "im\u00b7mer", "fin\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Sind sie dennoch so listig, so geschwinde,", "tokens": ["Sind", "sie", "den\u00b7noch", "so", "lis\u00b7tig", ",", "so", "ge\u00b7schwin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Und schneller sich zu nehren, sich zu retten,", "tokens": ["Und", "schnel\u00b7ler", "sich", "zu", "neh\u00b7ren", ",", "sich", "zu", "ret\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "PTKZU", "VVINF", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Als wenn sie viele H\u00e4nd\u2019 und viele F\u00fcsse h\u00e4tten.", "tokens": ["Als", "wenn", "sie", "vie\u00b7le", "H\u00e4nd'", "und", "vie\u00b7le", "F\u00fcs\u00b7se", "h\u00e4t\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PIAT", "NN", "KON", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ja der Gebrauch, den sie, beym Mangel andrer Sachen,", "tokens": ["Ja", "der", "Ge\u00b7brauch", ",", "den", "sie", ",", "beym", "Man\u00b7gel", "an\u00b7drer", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "ART", "NN", "$,", "PRELS", "PPER", "$,", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Aus ihrem Schwantz und Flo\u00df-Gefieder machen,", "tokens": ["Aus", "ih\u00b7rem", "Schwantz", "und", "Flo\u00df\u00b7Ge\u00b7fie\u00b7der", "ma\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Treibt sie in so geschwinder Eil\u2019,", "tokens": ["Treibt", "sie", "in", "so", "ge\u00b7schwin\u00b7der", "Eil'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Als wie der Wind, als wie ein Pfeil.", "tokens": ["Als", "wie", "der", "Wind", ",", "als", "wie", "ein", "Pfeil", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "ART", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Da sich die\u00df Wasser-Volck einander frisst;", "tokens": ["Da", "sich", "die\u00df", "Was\u00b7ser\u00b7Volck", "ein\u00b7an\u00b7der", "frisst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "PDS", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie? da\u00df es, ohn sich aufzureiben,", "tokens": ["Wie", "?", "da\u00df", "es", ",", "ohn", "sich", "auf\u00b7zu\u00b7rei\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "KOUS", "PPER", "$,", "KOUI", "PRF", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Annoch in seiner Art zu bleiben,", "tokens": ["An\u00b7noch", "in", "sei\u00b7ner", "Art", "zu", "blei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Sich zu erhalten, f\u00e4hig ist?", "tokens": ["Sich", "zu", "er\u00b7hal\u00b7ten", ",", "f\u00e4\u00b7hig", "ist", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$,", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Daf\u00fcr hat GOTT gesorgt: indem Er, sie zu nehren,", "tokens": ["Da\u00b7f\u00fcr", "hat", "GoTT", "ge\u00b7sorgt", ":", "in\u00b7dem", "Er", ",", "sie", "zu", "neh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "NE", "VVPP", "$.", "KOUS", "PPER", "$,", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Mit solcher Fruchtbarkeit dieselbigen versehn,", "tokens": ["Mit", "sol\u00b7cher", "Frucht\u00b7bar\u00b7keit", "die\u00b7sel\u00b7bi\u00b7gen", "ver\u00b7sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Da\u00df wenn sie sich auch noch so starck verzehren,", "tokens": ["Da\u00df", "wenn", "sie", "sich", "auch", "noch", "so", "starck", "ver\u00b7zeh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOUS", "PPER", "PRF", "ADV", "ADV", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sie doch nicht k\u00f6nnen untergehn:", "tokens": ["Sie", "doch", "nicht", "k\u00f6n\u00b7nen", "un\u00b7ter\u00b7gehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Indem dasjenige, was sie zerst\u00f6ret,", "tokens": ["In\u00b7dem", "das\u00b7je\u00b7ni\u00b7ge", ",", "was", "sie", "zer\u00b7st\u00f6\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Bey weitem nicht so starck, als das, so sie vermehret.", "tokens": ["Bey", "wei\u00b7tem", "nicht", "so", "starck", ",", "als", "das", ",", "so", "sie", "ver\u00b7meh\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "PTKNEG", "ADV", "ADJD", "$,", "KOUS", "PDS", "$,", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Nur ist mir Angst, wie doch die Kleinen", "tokens": ["Nur", "ist", "mir", "Angst", ",", "wie", "doch", "die", "Klei\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "NN", "$,", "PWAV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Den grossen sich entziehn;", "tokens": ["Den", "gros\u00b7sen", "sich", "ent\u00b7ziehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PRF", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Auf welche Weise sie denselbigen entfliehn,", "tokens": ["Auf", "wel\u00b7che", "Wei\u00b7se", "sie", "den\u00b7sel\u00b7bi\u00b7gen", "ent\u00b7fliehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "PPER", "PDS", "VVINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die sie, als ihren Raub, nur zu betrachten scheinen,", "tokens": ["Die", "sie", ",", "als", "ih\u00b7ren", "Raub", ",", "nur", "zu", "be\u00b7trach\u00b7ten", "schei\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "KOUS", "PPOSAT", "NN", "$,", "ADV", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und die sie stets verfolgen: aber h\u00f6ret:", "tokens": ["Und", "die", "sie", "stets", "ver\u00b7fol\u00b7gen", ":", "a\u00b7ber", "h\u00f6\u00b7ret", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "PPER", "ADV", "VVINF", "$.", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die\u00df schwache Volck ist hurtiger im Lauff\u2019,", "tokens": ["Die\u00df", "schwa\u00b7che", "Volck", "ist", "hur\u00b7ti\u00b7ger", "im", "Lauff'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADJA", "NN", "VAFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Auch h\u00e4lt es sich da, wo das Wasser seicht,", "tokens": ["Auch", "h\u00e4lt", "es", "sich", "da", ",", "wo", "das", "Was\u00b7ser", "seicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "$,", "PWAV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und wo die grossen es nicht leicht", "tokens": ["Und", "wo", "die", "gros\u00b7sen", "es", "nicht", "leicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "PPER", "PTKNEG", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Verfolgen k\u00f6nnen, auf.", "tokens": ["Ver\u00b7fol\u00b7gen", "k\u00f6n\u00b7nen", ",", "auf", "."], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["VVINF", "VMINF", "$,", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "Es scheint, ob habe GOTT sie, da\u00df sie f\u00fcr Gefahren", "tokens": ["Es", "scheint", ",", "ob", "ha\u00b7be", "GoTT", "sie", ",", "da\u00df", "sie", "f\u00fcr", "Ge\u00b7fah\u00b7ren"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "VAFIN", "NE", "PPER", "$,", "KOUS", "PPER", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sich selber f\u00e4hig zu bewahren,", "tokens": ["Sich", "sel\u00b7ber", "f\u00e4\u00b7hig", "zu", "be\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Mit einer Vorsicht ausger\u00fcst,", "tokens": ["Mit", "ei\u00b7ner", "Vor\u00b7sicht", "aus\u00b7ge\u00b7r\u00fcst", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Die mit der Schw\u00e4ch\u2019 und Noth von gleichem Nachdruck ist.", "tokens": ["Die", "mit", "der", "Schw\u00e4ch'", "und", "Noth", "von", "glei\u00b7chem", "Nach\u00b7druck", "ist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "KON", "NN", "APPR", "ADJA", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Auf welche Weise geht es an,", "tokens": ["Auf", "wel\u00b7che", "Wei\u00b7se", "geht", "es", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df in des Meeres Fluht,", "tokens": ["Da\u00df", "in", "des", "Mee\u00b7res", "Fluht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Worin ein Saltz von solcher Sch\u00e4rffe ruht,", "tokens": ["Wo\u00b7rin", "ein", "Saltz", "von", "sol\u00b7cher", "Sch\u00e4rf\u00b7fe", "ruht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Da\u00df keiner es im Munde dulden kann;", "tokens": ["Da\u00df", "kei\u00b7ner", "es", "im", "Mun\u00b7de", "dul\u00b7den", "kann", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "APPRART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Die Fische so gesund und munter leben k\u00f6nnen?", "tokens": ["Die", "Fi\u00b7sche", "so", "ge\u00b7sund", "und", "mun\u00b7ter", "le\u00b7ben", "k\u00f6n\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJD", "KON", "ADJD", "VVINF", "VMINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und wie beh\u00e4lt ein Fisch,", "tokens": ["Und", "wie", "be\u00b7h\u00e4lt", "ein", "Fisch", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Recht mitten in dem Saltz, sein Fleisch so s\u00fc\u00df und frisch?", "tokens": ["Recht", "mit\u00b7ten", "in", "dem", "Saltz", ",", "sein", "Fleisch", "so", "s\u00fc\u00df", "und", "frisch", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "ART", "NN", "$,", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Woher kommts, da\u00df die besten sich", "tokens": ["Wo\u00b7her", "kommts", ",", "da\u00df", "die", "bes\u00b7ten", "sich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "$,", "KOUS", "ART", "ADJA", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nicht gerne weit von unsern Ufern trennen,", "tokens": ["Nicht", "ger\u00b7ne", "weit", "von", "un\u00b7sern", "U\u00b7fern", "tren\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und gleichsam selbst uns in die Netze rennen?", "tokens": ["Und", "gleich\u00b7sam", "selbst", "uns", "in", "die", "Net\u00b7ze", "ren\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Hingegen die, so nicht so n\u00fctz sind, sich bem\u00fchen", "tokens": ["Hin\u00b7ge\u00b7gen", "die", ",", "so", "nicht", "so", "n\u00fctz", "sind", ",", "sich", "be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "ART", "$,", "ADV", "PTKNEG", "ADV", "ADJD", "VAFIN", "$,", "PRF", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von unsern Ufern fern zu fliehen?", "tokens": ["Von", "un\u00b7sern", "U\u00b7fern", "fern", "zu", "flie\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Wie geht es zu, da\u00df die, so in der Zeit", "tokens": ["Wie", "geht", "es", "zu", ",", "da\u00df", "die", ",", "so", "in", "der", "Zeit"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PTKVZ", "$,", "KOUS", "ART", "$,", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Der ausgelassnen Fruchtbarkeit", "tokens": ["Der", "aus\u00b7ge\u00b7lass\u00b7nen", "Frucht\u00b7bar\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu ihrem Aufenthalt entfernte Oerter nahmen,", "tokens": ["Zu", "ih\u00b7rem", "Auf\u00b7ent\u00b7halt", "ent\u00b7fern\u00b7te", "O\u00b7er\u00b7ter", "nah\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Woselbst sie zu gewisser Gr\u00f6sse kamen,", "tokens": ["Wo\u00b7selbst", "sie", "zu", "ge\u00b7wis\u00b7ser", "Gr\u00f6s\u00b7se", "ka\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Zu einer festen Zeit mit ungezehlten Hauffen", "tokens": ["Zu", "ei\u00b7ner", "fes\u00b7ten", "Zeit", "mit", "un\u00b7ge\u00b7zehl\u00b7ten", "Hauf\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Den Fischern gleichsam selbst in Retz-und Barcken lauffen?", "tokens": ["Den", "Fi\u00b7schern", "gleich\u00b7sam", "selbst", "in", "Retz\u00b7\u00b7und", "Bar\u00b7cken", "lauf\u00b7fen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADV", "APPR", "NE", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Durch welchen Trieb sieht man viel Arten aus der", "tokens": ["Durch", "wel\u00b7chen", "Trieb", "sieht", "man", "viel", "Ar\u00b7ten", "aus", "der"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "VVFIN", "PIS", "PIAT", "NN", "APPR", "ART"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Und zwar die niedlichsten, so h\u00e4uffig sich erheben,", "tokens": ["Und", "zwar", "die", "nied\u00b7lichs\u00b7ten", ",", "so", "h\u00e4uf\u00b7fig", "sich", "er\u00b7he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "$,", "ADV", "ADJD", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und in der Fl\u00fcsse Mund, gantz in die H\u00f6h\u2019,", "tokens": ["Und", "in", "der", "Fl\u00fcs\u00b7se", "Mund", ",", "gantz", "in", "die", "H\u00f6h'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "$,", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und zu den Quellen sich begeben;", "tokens": ["Und", "zu", "den", "Quel\u00b7len", "sich", "be\u00b7ge\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PRF", "VVPP", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Damit, selbst aus des Meeres Gr\u00fcnden,", "tokens": ["Da\u00b7mit", ",", "selbst", "aus", "des", "Mee\u00b7res", "Gr\u00fcn\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADV", "APPR", "ART", "NN", "NN", "$,"], "meter": "--+--+-+-", "measure": "anapaest.di.plus"}, "line.6": {"text": "Den Vortheil, auch die weit entlegnen Oerter finden?", "tokens": ["Den", "Vor\u00b7theil", ",", "auch", "die", "weit", "ent\u00b7leg\u00b7nen", "O\u00b7er\u00b7ter", "fin\u00b7den", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ART", "ADJD", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wo ist die Hand, die sie so wunderbar regieret,", "tokens": ["Wo", "ist", "die", "Hand", ",", "die", "sie", "so", "wun\u00b7der\u00b7bar", "re\u00b7gie\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Sie leitet, und f\u00fcr uns so weite Wege f\u00fchret?", "tokens": ["Sie", "lei\u00b7tet", ",", "und", "f\u00fcr", "uns", "so", "wei\u00b7te", "We\u00b7ge", "f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "APPR", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wann es die Deine nicht, O HERR! ob iederman,", "tokens": ["Wann", "es", "die", "Dei\u00b7ne", "nicht", ",", "O", "HeRR", "!", "ob", "ie\u00b7der\u00b7man", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "PPOSAT", "PTKNEG", "$,", "NE", "NN", "$.", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Da die Versehung ja so sicht-und f\u00fchlbar ist,", "tokens": ["Da", "die", "Ver\u00b7se\u00b7hung", "ja", "so", "sicht\u00b7\u00b7und", "f\u00fchl\u00b7bar", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "ADV", "ADJD", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Da\u00df man nichts deutlichers fast sehen kann,", "tokens": ["Da\u00df", "man", "nichts", "deut\u00b7li\u00b7chers", "fast", "se\u00b7hen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PIS", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Des danckens, leider! gleich gar offt daf\u00fcr vergisst.", "tokens": ["Des", "dan\u00b7ckens", ",", "lei\u00b7der", "!", "gleich", "gar", "offt", "da\u00b7f\u00fcr", "ver\u00b7gisst", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "$,", "ADV", "$.", "ADV", "ADV", "ADV", "PAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Dieselbige Versehung zeiget sich", "tokens": ["Die\u00b7sel\u00b7bi\u00b7ge", "Ver\u00b7se\u00b7hung", "zei\u00b7get", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["PDAT", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "An allen Arten. Sonderlich", "tokens": ["An", "al\u00b7len", "Ar\u00b7ten", ".", "Son\u00b7der\u00b7lich"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["APPR", "PIAT", "NN", "$.", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Giebt uns der Schnecken-H\u00e4user Menge,", "tokens": ["Giebt", "uns", "der", "Schne\u00b7cken\u00b7H\u00e4u\u00b7ser", "Men\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die, mit unzehligem ver\u00e4nderten Gepr\u00e4nge", "tokens": ["Die", ",", "mit", "un\u00b7zeh\u00b7li\u00b7gem", "ver\u00b7\u00e4n\u00b7der\u00b7ten", "Ge\u00b7pr\u00e4n\u00b7ge"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ART", "$,", "APPR", "ADJA", "ADJA", "NN"], "meter": "+-+--+-+---+-", "measure": "trochaic.penta.relaxed"}, "line.5": {"text": "Von Farben und Figur, des Meeres Strand bedecken,", "tokens": ["Von", "Far\u00b7ben", "und", "Fi\u00b7gur", ",", "des", "Mee\u00b7res", "Strand", "be\u00b7de\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Dieselbige vor andern zu verstehn:", "tokens": ["Die\u00b7sel\u00b7bi\u00b7ge", "vor", "an\u00b7dern", "zu", "ver\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "PIS", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Da kleine Fisch\u2019 in ihren Schalen stecken,", "tokens": ["Da", "klei\u00b7ne", "Fisch'", "in", "ih\u00b7ren", "Scha\u00b7len", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Woran wir kaum ein Leben sehn,", "tokens": ["Wo\u00b7ran", "wir", "kaum", "ein", "Le\u00b7ben", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und die iedoch, zu rechter Zeit,", "tokens": ["Und", "die", "ie\u00b7doch", ",", "zu", "rech\u00b7ter", "Zeit", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Um frisches Wasser einzusaugen,", "tokens": ["Um", "fri\u00b7sches", "Was\u00b7ser", "ein\u00b7zu\u00b7sau\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Sich \u00f6ffnen, und zugleich,", "tokens": ["Sich", "\u00f6ff\u00b7nen", ",", "und", "zu\u00b7gleich", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "VVINF", "$,", "KON", "ADV", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.12": {"text": "Mit seltsamer Geschwindigkeit,", "tokens": ["Mit", "selt\u00b7sa\u00b7mer", "Ge\u00b7schwin\u00b7dig\u00b7keit", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.13": {"text": "Den \u00fcberraschten Raub mit einzuziehen taugen.", "tokens": ["Den", "\u00fc\u00b7berr\u00b7aschten", "Raub", "mit", "ein\u00b7zu\u00b7zie\u00b7hen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "VVIZU", "VVFIN", "$."], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}}}}}