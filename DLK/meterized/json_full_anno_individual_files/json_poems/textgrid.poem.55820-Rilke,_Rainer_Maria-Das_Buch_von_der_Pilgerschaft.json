{"textgrid.poem.55820": {"metadata": {"author": {"name": "Rilke, Rainer Maria", "birth": "N.A.", "death": "N.A."}, "title": "Das Buch von der Pilgerschaft", "genre": "verse", "period": "N.A.", "pub_year": 1901, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Dich wundert nicht des Sturmes Wucht, \u2013", "tokens": ["Dich", "wun\u00b7dert", "nicht", "des", "Stur\u00b7mes", "Wucht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du hast ihn wachsen sehn; \u2013", "tokens": ["du", "hast", "ihn", "wach\u00b7sen", "sehn", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "die B\u00e4ume fl\u00fcchten. Ihre Flucht", "tokens": ["die", "B\u00e4u\u00b7me", "fl\u00fcch\u00b7ten", ".", "Ih\u00b7re", "Flucht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "schafft schreitende Alleen.", "tokens": ["schafft", "schrei\u00b7ten\u00b7de", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da wei\u00dft du, der vor dem sie fliehn", "tokens": ["Da", "wei\u00dft", "du", ",", "der", "vor", "dem", "sie", "fliehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRELS", "APPR", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ist der, zu dem du gehst,", "tokens": ["ist", "der", ",", "zu", "dem", "du", "gehst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "und deine Sinne singen ihn,", "tokens": ["und", "dei\u00b7ne", "Sin\u00b7ne", "sin\u00b7gen", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wenn du am Fenster stehst.", "tokens": ["wenn", "du", "am", "Fens\u00b7ter", "stehst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Des Sommers Wochen standen still,", "tokens": ["Des", "Som\u00b7mers", "Wo\u00b7chen", "stan\u00b7den", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es stieg der B\u00e4ume Blut;", "tokens": ["es", "stieg", "der", "B\u00e4u\u00b7me", "Blut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "jetzt f\u00fchlst du, da\u00df es fallen will", "tokens": ["jetzt", "f\u00fchlst", "du", ",", "da\u00df", "es", "fal\u00b7len", "will"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in den der Alles tut.", "tokens": ["in", "den", "der", "Al\u00b7les", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Du glaubtest schon erkannt die Kraft,", "tokens": ["Du", "glaub\u00b7test", "schon", "er\u00b7kannt", "die", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als du die Frucht erfa\u00dft,", "tokens": ["als", "du", "die", "Frucht", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "jetzt wird sie wieder r\u00e4tselhaft,", "tokens": ["jetzt", "wird", "sie", "wie\u00b7der", "r\u00e4t\u00b7sel\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und du bist wieder Gast.", "tokens": ["und", "du", "bist", "wie\u00b7der", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Der Sommer war so wie dein Haus,", "tokens": ["Der", "Som\u00b7mer", "war", "so", "wie", "dein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "drin wei\u00dft du alles stehn \u2013", "tokens": ["drin", "wei\u00dft", "du", "al\u00b7les", "stehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "VVINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "jetzt mu\u00dft du in dein Herz hinaus", "tokens": ["jetzt", "mu\u00dft", "du", "in", "dein", "Herz", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie in die Ebene gehn.", "tokens": ["wie", "in", "die", "E\u00b7be\u00b7ne", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Die gro\u00dfe Einsamkeit beginnt,", "tokens": ["Die", "gro\u00b7\u00dfe", "Ein\u00b7sam\u00b7keit", "be\u00b7ginnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Tage werden taub,", "tokens": ["die", "Ta\u00b7ge", "wer\u00b7den", "taub", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "aus deinen Sinnen nimmt der Wind", "tokens": ["aus", "dei\u00b7nen", "Sin\u00b7nen", "nimmt", "der", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Welt wie welkes Laub.", "tokens": ["die", "Welt", "wie", "wel\u00b7kes", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "PWAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Durch ihre leeren Zweige sieht", "tokens": ["Durch", "ih\u00b7re", "lee\u00b7ren", "Zwei\u00b7ge", "sieht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Himmel, den du hast;", "tokens": ["der", "Him\u00b7mel", ",", "den", "du", "hast", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "sei Erde jetzt und Abendlied", "tokens": ["sei", "Er\u00b7de", "jetzt", "und", "A\u00b7ben\u00b7dlied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Land, darauf er pa\u00dft.", "tokens": ["und", "Land", ",", "da\u00b7rauf", "er", "pa\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dem\u00fctig sei jetzt wie ein Ding,", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sei", "jetzt", "wie", "ein", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu Wirklichkeit gereift, \u2013", "tokens": ["zu", "Wirk\u00b7lich\u00b7keit", "ge\u00b7reift", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "da\u00df Der, von dem die Kunde ging,", "tokens": ["da\u00df", "Der", ",", "von", "dem", "die", "Kun\u00b7de", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dich f\u00fchlt, wenn er dich greift.", "tokens": ["dich", "f\u00fchlt", ",", "wenn", "er", "dich", "greift", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich bete wieder, du Erlauchter,", "tokens": ["Ich", "be\u00b7te", "wie\u00b7der", ",", "du", "Er\u00b7lauch\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du h\u00f6rst mich wieder durch den Wind,", "tokens": ["du", "h\u00f6rst", "mich", "wie\u00b7der", "durch", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "weil meine Tiefen niegebrauchter", "tokens": ["weil", "mei\u00b7ne", "Tie\u00b7fen", "nie\u00b7ge\u00b7brauch\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "rauschender Worte m\u00e4chtig sind.", "tokens": ["rau\u00b7schen\u00b7der", "Wor\u00b7te", "m\u00e4ch\u00b7tig", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VAFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.6": {"line.1": {"text": "Ich war zerstreut; an Widersacher", "tokens": ["Ich", "war", "zer\u00b7streut", ";", "an", "Wi\u00b7der\u00b7sa\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in St\u00fccken war verteilt mein Ich.", "tokens": ["in", "St\u00fc\u00b7cken", "war", "ver\u00b7teilt", "mein", "Ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "PPOSAT", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Gott, mich lachten alle Lacher", "tokens": ["O", "Gott", ",", "mich", "lach\u00b7ten", "al\u00b7le", "La\u00b7cher"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und alle Trinker tranken mich.", "tokens": ["und", "al\u00b7le", "Trin\u00b7ker", "tran\u00b7ken", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "In H\u00f6fen hab ich mich gesammelt", "tokens": ["In", "H\u00f6\u00b7fen", "hab", "ich", "mich", "ge\u00b7sam\u00b7melt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PRF", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "aus Abfall und aus altem Glas,", "tokens": ["aus", "Ab\u00b7fall", "und", "aus", "al\u00b7tem", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit halbem Mund dich angestammelt,", "tokens": ["mit", "hal\u00b7bem", "Mund", "dich", "an\u00b7ge\u00b7stam\u00b7melt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dich, Ewiger aus Ebenma\u00df.", "tokens": ["dich", ",", "E\u00b7wi\u00b7ger", "aus", "E\u00b7ben\u00b7ma\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie hob ich meine halben H\u00e4nde", "tokens": ["Wie", "hob", "ich", "mei\u00b7ne", "hal\u00b7ben", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "zu dir in namenlosem Flehn,", "tokens": ["zu", "dir", "in", "na\u00b7men\u00b7lo\u00b7sem", "Flehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df ich die Augen wiederf\u00e4nde,", "tokens": ["da\u00df", "ich", "die", "Au\u00b7gen", "wie\u00b7der\u00b7f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "mit denen ich dich angesehn.", "tokens": ["mit", "de\u00b7nen", "ich", "dich", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich war ein Haus nach einem Brand,", "tokens": ["Ich", "war", "ein", "Haus", "nach", "ei\u00b7nem", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "darin nur M\u00f6rder manchmal schlafen,", "tokens": ["da\u00b7rin", "nur", "M\u00f6r\u00b7der", "manch\u00b7mal", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "eh ihre hungerigen Strafen", "tokens": ["eh", "ih\u00b7re", "hun\u00b7ge\u00b7ri\u00b7gen", "Stra\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sie weiterjagen in das Land;", "tokens": ["sie", "wei\u00b7ter\u00b7ja\u00b7gen", "in", "das", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ich war wie eine Stadt am Meer,", "tokens": ["ich", "war", "wie", "ei\u00b7ne", "Stadt", "am", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wenn eine Seuche sie bedr\u00e4ngte,", "tokens": ["wenn", "ei\u00b7ne", "Seu\u00b7che", "sie", "be\u00b7dr\u00e4ng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die sich wie eine Leiche schwer", "tokens": ["die", "sich", "wie", "ei\u00b7ne", "Lei\u00b7che", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PRF", "KOKOM", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "den Kindern an die H\u00e4nde h\u00e4ngte.", "tokens": ["den", "Kin\u00b7dern", "an", "die", "H\u00e4n\u00b7de", "h\u00e4ng\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Ich war mir fremd wie irgendwer,", "tokens": ["Ich", "war", "mir", "fremd", "wie", "ir\u00b7gend\u00b7wer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wu\u00dfte nur von ihm, da\u00df er", "tokens": ["und", "wu\u00df\u00b7te", "nur", "von", "ihm", ",", "da\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "einst meine junge Mutter kr\u00e4nkte", "tokens": ["einst", "mei\u00b7ne", "jun\u00b7ge", "Mut\u00b7ter", "kr\u00e4nk\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als sie mich trug,", "tokens": ["als", "sie", "mich", "trug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "und da\u00df ihr Herz, das eingeengte,", "tokens": ["und", "da\u00df", "ihr", "Herz", ",", "das", "ein\u00b7ge\u00b7eng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sehr schmerzhaft an mein Keimen schlug.", "tokens": ["sehr", "schmerz\u00b7haft", "an", "mein", "Kei\u00b7men", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Jetzt bin ich wieder aufgebaut", "tokens": ["Jetzt", "bin", "ich", "wie\u00b7der", "auf\u00b7ge\u00b7baut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "aus allen St\u00fccken meiner Schande,", "tokens": ["aus", "al\u00b7len", "St\u00fc\u00b7cken", "mei\u00b7ner", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und sehne mich nach einem Bande,", "tokens": ["und", "seh\u00b7ne", "mich", "nach", "ei\u00b7nem", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "nach einem einigen Verstande,", "tokens": ["nach", "ei\u00b7nem", "ei\u00b7ni\u00b7gen", "Ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der mich wie ", "tokens": ["der", "mich", "wie"], "token_info": ["word", "word", "word"], "pos": ["ART", "PPER", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "nach deines Herzens gro\u00dfen H\u00e4nden \u2013", "tokens": ["nach", "dei\u00b7nes", "Her\u00b7zens", "gro\u00b7\u00dfen", "H\u00e4n\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "(o k\u00e4men sie doch auf mich zu).", "tokens": ["(", "o", "k\u00e4\u00b7men", "sie", "doch", "auf", "mich", "zu", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKZU", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich z\u00e4hle mich, mein Gott, und du,", "tokens": ["Ich", "z\u00e4h\u00b7le", "mich", ",", "mein", "Gott", ",", "und", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "KON", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "du hast das Recht, mich zu verschwenden.", "tokens": ["du", "hast", "das", "Recht", ",", "mich", "zu", "ver\u00b7schwen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Ich bin derselbe noch, der kniete", "tokens": ["Ich", "bin", "der\u00b7sel\u00b7be", "noch", ",", "der", "knie\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "ADV", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "vor dir in m\u00f6nchischem Gewand:", "tokens": ["vor", "dir", "in", "m\u00f6n\u00b7chi\u00b7schem", "Ge\u00b7wand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der tiefe, dienende Levite,", "tokens": ["der", "tie\u00b7fe", ",", "die\u00b7nen\u00b7de", "Le\u00b7vi\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "den du erf\u00fcllt, der dich erfand.", "tokens": ["den", "du", "er\u00b7f\u00fcllt", ",", "der", "dich", "er\u00b7fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Stimme einer stillen Zelle,", "tokens": ["Die", "Stim\u00b7me", "ei\u00b7ner", "stil\u00b7len", "Zel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "an der die Welt vor\u00fcberweht, \u2013", "tokens": ["an", "der", "die", "Welt", "vor\u00b7\u00fc\u00b7ber\u00b7weht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und du bist immer noch die Welle", "tokens": ["und", "du", "bist", "im\u00b7mer", "noch", "die", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die \u00fcber alle Dinge geht.", "tokens": ["die", "\u00fc\u00b7ber", "al\u00b7le", "Din\u00b7ge", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Es ", "tokens": ["Es"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "aus dem die L\u00e4nder manchmal steigen.", "tokens": ["aus", "dem", "die", "L\u00e4n\u00b7der", "manch\u00b7mal", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ", "tokens": ["Es"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "von sch\u00f6nen Engeln und von Geigen,", "tokens": ["von", "sch\u00f6\u00b7nen", "En\u00b7geln", "und", "von", "Gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und der Verschwiegene ist der,", "tokens": ["und", "der", "Ver\u00b7schwie\u00b7ge\u00b7ne", "ist", "der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "zu dem sich alle Dinge neigen,", "tokens": ["zu", "dem", "sich", "al\u00b7le", "Din\u00b7ge", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "von seiner St\u00e4rke Strahlen schwer.", "tokens": ["von", "sei\u00b7ner", "St\u00e4r\u00b7ke", "Strah\u00b7len", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Bist du denn Alles, \u2013 ich der Eine,", "tokens": ["Bist", "du", "denn", "Al\u00b7les", ",", "\u2013", "ich", "der", "Ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "$,", "$(", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der sich ergiebt und sich emp\u00f6rt?", "tokens": ["der", "sich", "er\u00b7giebt", "und", "sich", "em\u00b7p\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVFIN", "KON", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bin ich denn nicht das Allgemeine,", "tokens": ["Bin", "ich", "denn", "nicht", "das", "All\u00b7ge\u00b7mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bin ich nicht ", "tokens": ["bin", "ich", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "und du der Eine, der es h\u00f6rt?", "tokens": ["und", "du", "der", "Ei\u00b7ne", ",", "der", "es", "h\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "H\u00f6rst du denn etwas neben mir?", "tokens": ["H\u00f6rst", "du", "denn", "et\u00b7was", "ne\u00b7ben", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Sind da noch Stimmen au\u00dfer meiner?", "tokens": ["Sind", "da", "noch", "Stim\u00b7men", "au\u00b7\u00dfer", "mei\u00b7ner", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist da ein Sturm? Auch ich bin einer,", "tokens": ["Ist", "da", "ein", "Sturm", "?", "Auch", "ich", "bin", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "ADV", "PPER", "VAFIN", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "und meine W\u00e4lder winken dir.", "tokens": ["und", "mei\u00b7ne", "W\u00e4l\u00b7der", "win\u00b7ken", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ist da ein Lied, ein krankes, kleines,", "tokens": ["Ist", "da", "ein", "Lied", ",", "ein", "kran\u00b7kes", ",", "klei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das dich am Micherh\u00f6ren st\u00f6rt, \u2013", "tokens": ["das", "dich", "am", "Mi\u00b7cher\u00b7h\u00f6\u00b7ren", "st\u00f6rt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PRF", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auch ich bin eines, h\u00f6re meines,", "tokens": ["auch", "ich", "bin", "ei\u00b7nes", ",", "h\u00f6\u00b7re", "mei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PIS", "$,", "VVFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das einsam ist und unerh\u00f6rt.", "tokens": ["das", "ein\u00b7sam", "ist", "und", "un\u00b7er\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Ich bin derselbe noch, der bange", "tokens": ["Ich", "bin", "der\u00b7sel\u00b7be", "noch", ",", "der", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "ADV", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dich manchmal fragte, wer du seist.", "tokens": ["dich", "manch\u00b7mal", "frag\u00b7te", ",", "wer", "du", "seist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach jedem Sonnenuntergange", "tokens": ["Nach", "je\u00b7dem", "Son\u00b7nen\u00b7un\u00b7ter\u00b7gan\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bin ich verwundet und verwaist,", "tokens": ["bin", "ich", "ver\u00b7wun\u00b7det", "und", "ver\u00b7waist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ein blasser Allem Abgel\u00f6ster", "tokens": ["ein", "blas\u00b7ser", "Al\u00b7lem", "Ab\u00b7ge\u00b7l\u00f6s\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und ein Verschm\u00e4hter jeder Schar,", "tokens": ["und", "ein", "Ver\u00b7schm\u00e4h\u00b7ter", "je\u00b7der", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und alle Dinge stehn wie Kl\u00f6ster,", "tokens": ["und", "al\u00b7le", "Din\u00b7ge", "stehn", "wie", "Kl\u00f6s\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "in denen ich gefangen war.", "tokens": ["in", "de\u00b7nen", "ich", "ge\u00b7fan\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dann brauch ich dich, du Eingeweihter,", "tokens": ["Dann", "brauch", "ich", "dich", ",", "du", "Ein\u00b7ge\u00b7weih\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "du sanfter Nachbar jeder Not,", "tokens": ["du", "sanf\u00b7ter", "Nach\u00b7bar", "je\u00b7der", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "du meines Leidens leiser Zweiter,", "tokens": ["du", "mei\u00b7nes", "Lei\u00b7dens", "lei\u00b7ser", "Zwei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "du Gott, dann brauch ich dich wie Brot.", "tokens": ["du", "Gott", ",", "dann", "brauch", "ich", "dich", "wie", "Brot", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADV", "VVFIN", "PPER", "PRF", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Du wei\u00dft vielleicht nicht, wie die N\u00e4chte", "tokens": ["Du", "wei\u00dft", "viel\u00b7leicht", "nicht", ",", "wie", "die", "N\u00e4ch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "f\u00fcr Menschen, die nicht schlafen, sind:", "tokens": ["f\u00fcr", "Men\u00b7schen", ",", "die", "nicht", "schla\u00b7fen", ",", "sind", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "da sind sie alle Ungerechte,", "tokens": ["da", "sind", "sie", "al\u00b7le", "Un\u00b7ge\u00b7rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "der Greis, die Jungfrau und das Kind.", "tokens": ["der", "Greis", ",", "die", "Jung\u00b7frau", "und", "das", "Kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Sie fahren auf wie totgesagt,", "tokens": ["Sie", "fah\u00b7ren", "auf", "wie", "tot\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "von schwarzen Dingen nah umgeben,", "tokens": ["von", "schwar\u00b7zen", "Din\u00b7gen", "nah", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "und ihre wei\u00dfen H\u00e4nde beben,", "tokens": ["und", "ih\u00b7re", "wei\u00b7\u00dfen", "H\u00e4n\u00b7de", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "verwoben in ein wildes Leben", "tokens": ["ver\u00b7wo\u00b7ben", "in", "ein", "wil\u00b7des", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "wie Hunde in ein Bild der Jagd.", "tokens": ["wie", "Hun\u00b7de", "in", "ein", "Bild", "der", "Jagd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Vergangenes steht noch bevor,", "tokens": ["Ver\u00b7gan\u00b7ge\u00b7nes", "steht", "noch", "be\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.23": {"text": "und in der Zukunft liegen Leichen,", "tokens": ["und", "in", "der", "Zu\u00b7kunft", "lie\u00b7gen", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "ein Mann im Mantel pocht am Tor,", "tokens": ["ein", "Mann", "im", "Man\u00b7tel", "pocht", "am", "Tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "und mit dem Auge und dem Ohr", "tokens": ["und", "mit", "dem", "Au\u00b7ge", "und", "dem", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "ist noch kein erstes Morgenzeichen,", "tokens": ["ist", "noch", "kein", "ers\u00b7tes", "Mor\u00b7gen\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "kein Hahnruf ist noch zu erreichen.", "tokens": ["kein", "Hahn\u00b7ruf", "ist", "noch", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Die Nacht ist wie ein gro\u00dfes Haus.", "tokens": ["Die", "Nacht", "ist", "wie", "ein", "gro\u00b7\u00dfes", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und mit der Angst der wunden H\u00e4nde", "tokens": ["Und", "mit", "der", "Angst", "der", "wun\u00b7den", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "rei\u00dfen sie T\u00fcren in die W\u00e4nde, \u2013", "tokens": ["rei\u00b7\u00dfen", "sie", "T\u00fc\u00b7ren", "in", "die", "W\u00e4n\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.31": {"text": "dann kommen G\u00e4nge ohne Ende,", "tokens": ["dann", "kom\u00b7men", "G\u00e4n\u00b7ge", "oh\u00b7ne", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "und nirgends ist ein Tor hinaus.", "tokens": ["und", "nir\u00b7gends", "ist", "ein", "Tor", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Und so, mein Gott, ist ", "tokens": ["Und", "so", ",", "mein", "Gott", ",", "ist"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "$,", "PPOSAT", "NN", "$,", "VAFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "immer sind welche aufgewacht,", "tokens": ["im\u00b7mer", "sind", "wel\u00b7che", "auf\u00b7ge\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "die gehn und gehn und dich nicht finden.", "tokens": ["die", "gehn", "und", "gehn", "und", "dich", "nicht", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "KON", "VVINF", "KON", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00f6rst du sie mit dem Schritt von Blinden", "tokens": ["H\u00f6rst", "du", "sie", "mit", "dem", "Schritt", "von", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "das Dunkel treten?", "tokens": ["das", "Dun\u00b7kel", "tre\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Auf Treppen, die sich niederwinden,", "tokens": ["Auf", "Trep\u00b7pen", ",", "die", "sich", "nie\u00b7der\u00b7win\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "h\u00f6rst du sie beten?", "tokens": ["h\u00f6rst", "du", "sie", "be\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "H\u00f6rst du sie fallen auf den schwarzen Steinen?", "tokens": ["H\u00f6rst", "du", "sie", "fal\u00b7len", "auf", "den", "schwar\u00b7zen", "Stei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du mu\u00dft sie weinen h\u00f6ren; denn sie weinen.", "tokens": ["Du", "mu\u00dft", "sie", "wei\u00b7nen", "h\u00f6\u00b7ren", ";", "denn", "sie", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$.", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ich suche dich, weil sie vor\u00fcbergehn", "tokens": ["Ich", "su\u00b7che", "dich", ",", "weil", "sie", "vor\u00b7\u00fc\u00b7ber\u00b7gehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "an meiner T\u00fcr. Ich kann sie beinah sehn.", "tokens": ["an", "mei\u00b7ner", "T\u00fcr", ".", "Ich", "kann", "sie", "bei\u00b7nah", "sehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wen soll ich rufen, wenn nicht ", "tokens": ["Wen", "soll", "ich", "ru\u00b7fen", ",", "wenn", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PTKNEG"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.13": {"text": "der dunkel ist und n\u00e4chtiger als Nacht.", "tokens": ["der", "dun\u00b7kel", "ist", "und", "n\u00e4ch\u00b7ti\u00b7ger", "als", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADJA", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Den Einzigen, der ohne Lampe wacht", "tokens": ["Den", "Ein\u00b7zi\u00b7gen", ",", "der", "oh\u00b7ne", "Lam\u00b7pe", "wacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "und doch nicht bangt; den Tiefen, den das Licht", "tokens": ["und", "doch", "nicht", "bangt", ";", "den", "Tie\u00b7fen", ",", "den", "das", "Licht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "$.", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "noch nicht verw\u00f6hnt hat und von dem ich wei\u00df,", "tokens": ["noch", "nicht", "ver\u00b7w\u00f6hnt", "hat", "und", "von", "dem", "ich", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVPP", "VAFIN", "KON", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "weil er mit B\u00e4umen aus der Erde bricht", "tokens": ["weil", "er", "mit", "B\u00e4u\u00b7men", "aus", "der", "Er\u00b7de", "bricht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "und weil er leis", "tokens": ["und", "weil", "er", "leis"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.19": {"text": "als Duft in mein gesenktes Angesicht", "tokens": ["als", "Duft", "in", "mein", "ge\u00b7senk\u00b7tes", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "aus Erde steigt.", "tokens": ["aus", "Er\u00b7de", "steigt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.17": {"line.1": {"text": "Du Ewiger, du hast dich mir gezeigt.", "tokens": ["Du", "E\u00b7wi\u00b7ger", ",", "du", "hast", "dich", "mir", "ge\u00b7zeigt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich liebe dich wie einen lieben Sohn,", "tokens": ["Ich", "lie\u00b7be", "dich", "wie", "ei\u00b7nen", "lie\u00b7ben", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der mich einmal verlassen hat als Kind,", "tokens": ["der", "mich", "ein\u00b7mal", "ver\u00b7las\u00b7sen", "hat", "als", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "VAFIN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "weil ihn das Schicksal rief auf einen Thron,", "tokens": ["weil", "ihn", "das", "Schick\u00b7sal", "rief", "auf", "ei\u00b7nen", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "vor dem die L\u00e4nder alle T\u00e4ler sind.", "tokens": ["vor", "dem", "die", "L\u00e4n\u00b7der", "al\u00b7le", "T\u00e4\u00b7ler", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich bin zur\u00fcck geblieben wie ein Greis,", "tokens": ["Ich", "bin", "zu\u00b7r\u00fcck", "ge\u00b7blie\u00b7ben", "wie", "ein", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "der seinen gro\u00dfen Sohn nichtmehr versteht", "tokens": ["der", "sei\u00b7nen", "gro\u00b7\u00dfen", "Sohn", "nicht\u00b7mehr", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und wenig von den neuen Dingen wei\u00df,", "tokens": ["und", "we\u00b7nig", "von", "den", "neu\u00b7en", "Din\u00b7gen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "zu welchen seines Samens Wille geht.", "tokens": ["zu", "wel\u00b7chen", "sei\u00b7nes", "Sa\u00b7mens", "Wil\u00b7le", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich bebe manchmal f\u00fcr dein tiefes Gl\u00fcck,", "tokens": ["Ich", "be\u00b7be", "manch\u00b7mal", "f\u00fcr", "dein", "tie\u00b7fes", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "das auf so vielen fremden Schiffen f\u00e4hrt,", "tokens": ["das", "auf", "so", "vie\u00b7len", "frem\u00b7den", "Schif\u00b7fen", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADV", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "ich w\u00fcnsche manchmal dich in mich zur\u00fcck,", "tokens": ["ich", "w\u00fcn\u00b7sche", "manch\u00b7mal", "dich", "in", "mich", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "in dieses Dunkel, das dich gro\u00dfgen\u00e4hrt.", "tokens": ["in", "die\u00b7ses", "Dun\u00b7kel", ",", "das", "dich", "gro\u00df\u00b7ge\u00b7n\u00e4hrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ich bange manchmal, da\u00df du nichtmehr bist,", "tokens": ["Ich", "ban\u00b7ge", "manch\u00b7mal", ",", "da\u00df", "du", "nicht\u00b7mehr", "bist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "wenn ich mich sehr verliere an die Zeit.", "tokens": ["wenn", "ich", "mich", "sehr", "ver\u00b7lie\u00b7re", "an", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Dann les ich von dir: der Euangelist", "tokens": ["Dann", "les", "ich", "von", "dir", ":", "der", "Eu\u00b7an\u00b7ge\u00b7list"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PIS", "PPER", "APPR", "PPER", "$.", "ART", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "schreibt \u00fcberall von deiner Ewigkeit.", "tokens": ["schreibt", "\u00fc\u00b7be\u00b7rall", "von", "dei\u00b7ner", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.18": {"line.1": {"text": "Ich bin der Vater; doch der Sohn ist mehr,", "tokens": ["Ich", "bin", "der", "Va\u00b7ter", ";", "doch", "der", "Sohn", "ist", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "ADV", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ist alles, was der Vater war, und der,", "tokens": ["ist", "al\u00b7les", ",", "was", "der", "Va\u00b7ter", "war", ",", "und", "der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "KON", "ART", "$,"], "meter": "-+-+-+-++-", "measure": "unknown.measure.penta"}, "line.3": {"text": "der er nicht wurde, wird in jenem gro\u00df;", "tokens": ["der", "er", "nicht", "wur\u00b7de", ",", "wird", "in", "je\u00b7nem", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VAFIN", "$,", "VAFIN", "APPR", "PDAT", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "er ist die Zukunft und die Wiederkehr,", "tokens": ["er", "ist", "die", "Zu\u00b7kunft", "und", "die", "Wie\u00b7der\u00b7kehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "er ist der Schoo\u00df, er ist das Meer ...", "tokens": ["er", "ist", "der", "Schoo\u00df", ",", "er", "ist", "das", "Meer", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Dir ist mein Beten keine Blasphemie:", "tokens": ["Dir", "ist", "mein", "Be\u00b7ten", "kei\u00b7ne", "Blas\u00b7phe\u00b7mie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "als schl\u00fcge ich in alten B\u00fcchern nach,", "tokens": ["als", "schl\u00fc\u00b7ge", "ich", "in", "al\u00b7ten", "B\u00fc\u00b7chern", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "da\u00df ich dir sehr verwandt bin \u2013 tausendfach.", "tokens": ["da\u00df", "ich", "dir", "sehr", "ver\u00b7wandt", "bin", "\u2013", "tau\u00b7send\u00b7fach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "VAFIN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.20": {"line.1": {"text": "Ich will dir Liebe geben. Die und die ....", "tokens": ["Ich", "will", "dir", "Lie\u00b7be", "ge\u00b7ben", ".", "Die", "und", "die", "...."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "NN", "VVINF", "$.", "ART", "KON", "ART", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.21": {"line.1": {"text": "Liebt man denn einen Vater? Geht man nicht,", "tokens": ["Liebt", "man", "denn", "ei\u00b7nen", "Va\u00b7ter", "?", "Geht", "man", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "NN", "$.", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie du von mir gingst, H\u00e4rte im Gesicht,", "tokens": ["wie", "du", "von", "mir", "gingst", ",", "H\u00e4r\u00b7te", "im", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "von seinen h\u00fclflos leeren H\u00e4nden fort?", "tokens": ["von", "sei\u00b7nen", "h\u00fcl\u00b7flos", "lee\u00b7ren", "H\u00e4n\u00b7den", "fort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Legt man nicht leise sein verwelktes Wort", "tokens": ["Legt", "man", "nicht", "lei\u00b7se", "sein", "ver\u00b7welk\u00b7tes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "ADJD", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "in alte B\u00fccher, die man selten liest?", "tokens": ["in", "al\u00b7te", "B\u00fc\u00b7cher", ",", "die", "man", "sel\u00b7ten", "liest", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.22": {"line.1": {"text": "Flie\u00dft man nicht wie von einer Wasserscheide", "tokens": ["Flie\u00dft", "man", "nicht", "wie", "von", "ei\u00b7ner", "Was\u00b7ser\u00b7schei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "KOKOM", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "von seinem Herzen ab zu Lust und Leide?", "tokens": ["von", "sei\u00b7nem", "Her\u00b7zen", "ab", "zu", "Lust", "und", "Lei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist uns der Vater denn nicht das, was ", "tokens": ["Ist", "uns", "der", "Va\u00b7ter", "denn", "nicht", "das", ",", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "PTKNEG", "PDS", "$,", "PWS"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "vergangne Jahre, welche fremd gedacht,", "tokens": ["ver\u00b7gang\u00b7ne", "Jah\u00b7re", ",", "wel\u00b7che", "fremd", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "veraltete Geb\u00e4rde, tote Tracht,", "tokens": ["ver\u00b7al\u00b7te\u00b7te", "Ge\u00b7b\u00e4r\u00b7de", ",", "to\u00b7te", "Tracht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "verbl\u00fchte H\u00e4nde und verblichnes Haar?", "tokens": ["ver\u00b7bl\u00fch\u00b7te", "H\u00e4n\u00b7de", "und", "ver\u00b7blich\u00b7nes", "Haar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und war er selbst f\u00fcr seine Zeit ein Held,", "tokens": ["Und", "war", "er", "selbst", "f\u00fcr", "sei\u00b7ne", "Zeit", "ein", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "er ist das Blatt, das, wenn wir wachsen, f\u00e4llt.", "tokens": ["er", "ist", "das", "Blatt", ",", "das", ",", "wenn", "wir", "wach\u00b7sen", ",", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PDS", "$,", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.23": {"line.1": {"text": "Und seine Sorgfalt ist uns wie ein Alb,", "tokens": ["Und", "sei\u00b7ne", "Sorg\u00b7falt", "ist", "uns", "wie", "ein", "Alb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und seine Stimme ist uns wie ein Stein, \u2013", "tokens": ["und", "sei\u00b7ne", "Stim\u00b7me", "ist", "uns", "wie", "ein", "Stein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wir m\u00f6chten seiner Rede h\u00f6rig sein,", "tokens": ["wir", "m\u00f6ch\u00b7ten", "sei\u00b7ner", "Re\u00b7de", "h\u00f6\u00b7rig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "aber wir h\u00f6ren seine Worte halb.", "tokens": ["a\u00b7ber", "wir", "h\u00f6\u00b7ren", "sei\u00b7ne", "Wor\u00b7te", "halb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Das gro\u00dfe Drama zwischen ihm und uns", "tokens": ["Das", "gro\u00b7\u00dfe", "Dra\u00b7ma", "zwi\u00b7schen", "ihm", "und", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "KON", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "l\u00e4rmt viel zu laut, einander zu verstehn,", "tokens": ["l\u00e4rmt", "viel", "zu", "laut", ",", "ein\u00b7an\u00b7der", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "wir sehen nur die Formen seines Munds,", "tokens": ["wir", "se\u00b7hen", "nur", "die", "For\u00b7men", "sei\u00b7nes", "Munds", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "aus denen Silben fallen, die vergehn.", "tokens": ["aus", "de\u00b7nen", "Sil\u00b7ben", "fal\u00b7len", ",", "die", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "VVINF", "$,", "PRELS", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So sind wir noch viel ferner ihm als fern,", "tokens": ["So", "sind", "wir", "noch", "viel", "fer\u00b7ner", "ihm", "als", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "PPER", "KOUS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "wenn auch die Liebe uns noch weit verwebt,", "tokens": ["wenn", "auch", "die", "Lie\u00b7be", "uns", "noch", "weit", "ver\u00b7webt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "erst wenn er sterben mu\u00df auf diesem Stern,", "tokens": ["erst", "wenn", "er", "ster\u00b7ben", "mu\u00df", "auf", "die\u00b7sem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "sehn wir, da\u00df er auf diesem Stern gelebt.", "tokens": ["sehn", "wir", ",", "da\u00df", "er", "auf", "die\u00b7sem", "Stern", "ge\u00b7lebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.24": {"line.1": {"text": "Das ist der Vater uns. Und ich \u2013 ich soll", "tokens": ["Das", "ist", "der", "Va\u00b7ter", "uns", ".", "Und", "ich", "\u2013", "ich", "soll"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPER", "$.", "KON", "PPER", "$(", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dich Vater nennen?", "tokens": ["dich", "Va\u00b7ter", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Das hie\u00dfe tausendmal mich von dir trennen.", "tokens": ["Das", "hie\u00b7\u00dfe", "tau\u00b7send\u00b7mal", "mich", "von", "dir", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du bist mein Sohn. Ich werde dich erkennen,", "tokens": ["Du", "bist", "mein", "Sohn", ".", "Ich", "wer\u00b7de", "dich", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wie man sein einzigliebes Kind erkennt, auch dann,", "tokens": ["wie", "man", "sein", "ein\u00b7zig\u00b7lie\u00b7bes", "Kind", "er\u00b7kennt", ",", "auch", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "wenn es ein Mann geworden ist, ein alter Mann.", "tokens": ["wenn", "es", "ein", "Mann", "ge\u00b7wor\u00b7den", "ist", ",", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAPP", "VAFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "L\u00f6sch mir die Augen aus: ich kann dich sehn,", "tokens": ["L\u00f6sch", "mir", "die", "Au\u00b7gen", "aus", ":", "ich", "kann", "dich", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wirf mir die Ohren zu: ich kann dich h\u00f6ren,", "tokens": ["wirf", "mir", "die", "Oh\u00b7ren", "zu", ":", "ich", "kann", "dich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und ohne F\u00fc\u00dfe kann ich zu dir gehn,", "tokens": ["und", "oh\u00b7ne", "F\u00fc\u00b7\u00dfe", "kann", "ich", "zu", "dir", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und ohne Mund noch kann ich dich beschw\u00f6ren.", "tokens": ["und", "oh\u00b7ne", "Mund", "noch", "kann", "ich", "dich", "be\u00b7schw\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Brich mir die Arme ab, ich fasse dich", "tokens": ["Brich", "mir", "die", "Ar\u00b7me", "ab", ",", "ich", "fas\u00b7se", "dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PPER", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit meinem Herzen wie mit einer Hand,", "tokens": ["mit", "mei\u00b7nem", "Her\u00b7zen", "wie", "mit", "ei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "halt mir das Herz zu, und mein Hirn wird schlagen,", "tokens": ["halt", "mir", "das", "Herz", "zu", ",", "und", "mein", "Hirn", "wird", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "KON", "PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "und wirfst du in mein Hirn den Brand,", "tokens": ["und", "wirfst", "du", "in", "mein", "Hirn", "den", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "so werd ich dich auf meinem Blute tragen.", "tokens": ["so", "werd", "ich", "dich", "auf", "mei\u00b7nem", "Blu\u00b7te", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.26": {"line.1": {"text": "Und meine Seele ist ein Weib vor dir.", "tokens": ["Und", "mei\u00b7ne", "See\u00b7le", "ist", "ein", "Weib", "vor", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ist wie der Na\u00ebmi Schnur, wie Ruth.", "tokens": ["Und", "ist", "wie", "der", "Na\u00eb\u00b7mi", "Schnur", ",", "wie", "Ruth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "ART", "NN", "NN", "$,", "PWAV", "NE", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sie geht bei Tag um deiner Garben Hauf", "tokens": ["Sie", "geht", "bei", "Tag", "um", "dei\u00b7ner", "Gar\u00b7ben", "Hauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "wie eine Magd, die tiefe Dienste tut.", "tokens": ["wie", "ei\u00b7ne", "Magd", ",", "die", "tie\u00b7fe", "Diens\u00b7te", "tut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Aber am Abend steigt sie in die Flut", "tokens": ["A\u00b7ber", "am", "A\u00b7bend", "steigt", "sie", "in", "die", "Flut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "und badet sich und kleidet sich sehr gut", "tokens": ["und", "ba\u00b7det", "sich", "und", "klei\u00b7det", "sich", "sehr", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "KON", "VVFIN", "PRF", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und kommt zu dir, wenn alles um dich ruht,", "tokens": ["und", "kommt", "zu", "dir", ",", "wenn", "al\u00b7les", "um", "dich", "ruht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$,", "KOUS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und kommt und deckt zu deinen F\u00fc\u00dfen auf.", "tokens": ["und", "kommt", "und", "deckt", "zu", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und fragst du sie um Mitternacht, sie sagt", "tokens": ["Und", "fragst", "du", "sie", "um", "Mit\u00b7ter\u00b7nacht", ",", "sie", "sagt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "mit tiefer Einfalt: Ich bin Ruth, die Magd.", "tokens": ["mit", "tie\u00b7fer", "Ein\u00b7falt", ":", "Ich", "bin", "Ruth", ",", "die", "Magd", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VAFIN", "NE", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Spann deine Fl\u00fcgel \u00fcber deine Magd.", "tokens": ["Spann", "dei\u00b7ne", "Fl\u00fc\u00b7gel", "\u00fc\u00b7ber", "dei\u00b7ne", "Magd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Du bist der Erbe ...", "tokens": ["Du", "bist", "der", "Er\u00b7be", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.27": {"line.1": {"text": "Und meine Seele schl\u00e4ft dann bis es tagt", "tokens": ["Und", "mei\u00b7ne", "See\u00b7le", "schl\u00e4ft", "dann", "bis", "es", "tagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "bei deinen F\u00fc\u00dfen, warm von deinem Blut.", "tokens": ["bei", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", ",", "warm", "von", "dei\u00b7nem", "Blut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ist ein Weib vor dir. Und ist wie Ruth.", "tokens": ["Und", "ist", "ein", "Weib", "vor", "dir", ".", "Und", "ist", "wie", "Ruth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PPER", "$.", "KON", "VAFIN", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.28": {"line.1": {"text": "Du bist der Erbe.", "tokens": ["Du", "bist", "der", "Er\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "S\u00f6hne sind die Erben,", "tokens": ["S\u00f6h\u00b7ne", "sind", "die", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "denn V\u00e4ter sterben.", "tokens": ["denn", "V\u00e4\u00b7ter", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "S\u00f6hne stehn und bl\u00fchn.", "tokens": ["S\u00f6h\u00b7ne", "stehn", "und", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Du bist der Erbe:", "tokens": ["Du", "bist", "der", "Er\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.29": {"line.1": {"text": "Und du erbst das Gr\u00fcn", "tokens": ["Und", "du", "erbst", "das", "Gr\u00fcn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "vergangner G\u00e4rten und das stille Blau", "tokens": ["ver\u00b7gang\u00b7ner", "G\u00e4r\u00b7ten", "und", "das", "stil\u00b7le", "Blau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zerfallner Himmel.", "tokens": ["zer\u00b7fall\u00b7ner", "Him\u00b7mel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Tau aus tausend Tagen,", "tokens": ["Tau", "aus", "tau\u00b7send", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "die vielen Sommer, die die Sonnen sagen,", "tokens": ["die", "vie\u00b7len", "Som\u00b7mer", ",", "die", "die", "Son\u00b7nen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und lauter Fr\u00fchlinge mit Glanz und Klagen", "tokens": ["und", "lau\u00b7ter", "Fr\u00fch\u00b7lin\u00b7ge", "mit", "Glanz", "und", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "wie viele Briefe einer jungen Frau.", "tokens": ["wie", "vie\u00b7le", "Brie\u00b7fe", "ei\u00b7ner", "jun\u00b7gen", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Du erbst die Herbste, die wie Prunkgew\u00e4nder", "tokens": ["Du", "erbst", "die", "Herbs\u00b7te", ",", "die", "wie", "Prunk\u00b7ge\u00b7w\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "in der Erinnerung von Dichtern liegen,", "tokens": ["in", "der", "E\u00b7rin\u00b7ne\u00b7rung", "von", "Dich\u00b7tern", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "und alle Winter, wie verwaiste L\u00e4nder,", "tokens": ["und", "al\u00b7le", "Win\u00b7ter", ",", "wie", "ver\u00b7wais\u00b7te", "L\u00e4n\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "scheinen sich leise an dich anzuschmiegen.", "tokens": ["schei\u00b7nen", "sich", "lei\u00b7se", "an", "dich", "an\u00b7zu\u00b7schmie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "PPER", "VVIZU", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Du erbst Venedig und Kasan und Rom,", "tokens": ["Du", "erbst", "Ve\u00b7ne\u00b7dig", "und", "Ka\u00b7san", "und", "Rom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NE", "KON", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Florenz wird dein sein, der Pisaner Dom,", "tokens": ["Flo\u00b7renz", "wird", "dein", "sein", ",", "der", "Pi\u00b7sa\u00b7ner", "Dom", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "VAINF", "$,", "ART", "NN", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "die Tro\u00eftzka Lawra und das Monastir,", "tokens": ["die", "Tro\u00eftz\u00b7ka", "Law\u00b7ra", "und", "das", "Mo\u00b7nas\u00b7tir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "das unter Kiews G\u00e4rten ein Gewirr", "tokens": ["das", "un\u00b7ter", "Kiews", "G\u00e4r\u00b7ten", "ein", "Ge\u00b7wirr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "NE", "NN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "von G\u00e4ngen bildet, dunkel und verschlungen, \u2013", "tokens": ["von", "G\u00e4n\u00b7gen", "bil\u00b7det", ",", "dun\u00b7kel", "und", "ver\u00b7schlun\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADJD", "KON", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Moskau mit Glocken wie Erinnerungen, \u2013", "tokens": ["Mos\u00b7kau", "mit", "Glo\u00b7cken", "wie", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "NN", "KOKOM", "NN", "$,", "$("], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.18": {"text": "und Klang wird dein sein: Geigen, H\u00f6rner, Zungen,", "tokens": ["und", "Klang", "wird", "dein", "sein", ":", "Gei\u00b7gen", ",", "H\u00f6r\u00b7ner", ",", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPOSAT", "VAINF", "$.", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und jedes Lied, das tief genug erklungen,", "tokens": ["und", "je\u00b7des", "Lied", ",", "das", "tief", "ge\u00b7nug", "er\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "wird an dir gl\u00e4nzen wie ein Edelstein.", "tokens": ["wird", "an", "dir", "gl\u00e4n\u00b7zen", "wie", "ein", "E\u00b7del\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVINF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.30": {"line.1": {"text": "F\u00fcr dich nur schlie\u00dfen sich die Dichter ein", "tokens": ["F\u00fcr", "dich", "nur", "schlie\u00b7\u00dfen", "sich", "die", "Dich\u00b7ter", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "PRF", "ART", "NN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und sammeln Bilder, rauschende und reiche,", "tokens": ["und", "sam\u00b7meln", "Bil\u00b7der", ",", "rau\u00b7schen\u00b7de", "und", "rei\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und gehn hinaus und reifen durch Vergleiche", "tokens": ["und", "gehn", "hin\u00b7aus", "und", "rei\u00b7fen", "durch", "Ver\u00b7glei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und sind ihr ganzes Leben so allein ...", "tokens": ["und", "sind", "ihr", "gan\u00b7zes", "Le\u00b7ben", "so", "al\u00b7lein", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und Maler malen ihre Bilder nur,", "tokens": ["Und", "Ma\u00b7ler", "ma\u00b7len", "ih\u00b7re", "Bil\u00b7der", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "damit du ", "tokens": ["da\u00b7mit", "du"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "die du verg\u00e4nglich schufst, zur\u00fcckempf\u00e4ngst:", "tokens": ["die", "du", "ver\u00b7g\u00e4ng\u00b7lich", "schufst", ",", "zu\u00b7r\u00fc\u00b7ckemp\u00b7f\u00e4ngst", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "alles wird ewig. Sieh, das Weib ist l\u00e4ngst", "tokens": ["al\u00b7les", "wird", "e\u00b7wig", ".", "Sieh", ",", "das", "Weib", "ist", "l\u00e4ngst"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADJD", "$.", "NE", "$,", "ART", "NN", "VAFIN", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "in der Madonna Lisa reif wie Wein;", "tokens": ["in", "der", "Ma\u00b7don\u00b7na", "Li\u00b7sa", "reif", "wie", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "es m\u00fc\u00dfte nie ein Weib mehr sein,", "tokens": ["es", "m\u00fc\u00df\u00b7te", "nie", "ein", "Weib", "mehr", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "denn Neues bringt kein neues Weib hinzu.", "tokens": ["denn", "Neu\u00b7es", "bringt", "kein", "neu\u00b7es", "Weib", "hin\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die, welche bilden, sind wie du.", "tokens": ["Die", ",", "wel\u00b7che", "bil\u00b7den", ",", "sind", "wie", "du", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "VVINF", "$,", "VAFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Sie wollen Ewigkeit. Sie sagen: Stein,", "tokens": ["Sie", "wol\u00b7len", "E\u00b7wig\u00b7keit", ".", "Sie", "sa\u00b7gen", ":", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$.", "PPER", "VVINF", "$.", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "sei ewig. Und das hei\u00dft: sei dein!", "tokens": ["sei", "e\u00b7wig", ".", "Und", "das", "hei\u00dft", ":", "sei", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "KON", "PDS", "VVFIN", "$.", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Und auch, die lieben, sammeln f\u00fcr dich ein:", "tokens": ["Und", "auch", ",", "die", "lie\u00b7ben", ",", "sam\u00b7meln", "f\u00fcr", "dich", "ein", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "ADJA", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+++", "measure": "zehnsilber"}, "line.2": {"text": "Sie sind die Dichter einer kurzen Stunde,", "tokens": ["Sie", "sind", "die", "Dich\u00b7ter", "ei\u00b7ner", "kur\u00b7zen", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sie k\u00fcssen einem ausdruckslosen Munde", "tokens": ["sie", "k\u00fcs\u00b7sen", "ei\u00b7nem", "aus\u00b7drucks\u00b7lo\u00b7sen", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ein L\u00e4cheln auf, als formten sie ihn sch\u00f6ner,", "tokens": ["ein", "L\u00e4\u00b7cheln", "auf", ",", "als", "form\u00b7ten", "sie", "ihn", "sch\u00f6\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und bringen Lust und sind die Angew\u00f6hner", "tokens": ["und", "brin\u00b7gen", "Lust", "und", "sind", "die", "An\u00b7ge\u00b7w\u00f6h\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "zu Schmerzen, welche erst erwachsen machen.", "tokens": ["zu", "Schmer\u00b7zen", ",", "wel\u00b7che", "erst", "er\u00b7wach\u00b7sen", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Sie bringen Leiden mit in ihrem Lachen,", "tokens": ["Sie", "brin\u00b7gen", "Lei\u00b7den", "mit", "in", "ih\u00b7rem", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sehns\u00fcchte, welche schlafen, und erwachen,", "tokens": ["Sehn\u00b7s\u00fcch\u00b7te", ",", "wel\u00b7che", "schla\u00b7fen", ",", "und", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "VVFIN", "$,", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "um aufzuweinen in der fremden Brust.", "tokens": ["um", "auf\u00b7zu\u00b7wei\u00b7nen", "in", "der", "frem\u00b7den", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "VVIZU", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sie h\u00e4ufen R\u00e4tselhaftes an und sterben,", "tokens": ["Sie", "h\u00e4u\u00b7fen", "R\u00e4t\u00b7sel\u00b7haf\u00b7tes", "an", "und", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "wie Tiere sterben, ohne zu begreifen, \u2013", "tokens": ["wie", "Tie\u00b7re", "ster\u00b7ben", ",", "oh\u00b7ne", "zu", "be\u00b7grei\u00b7fen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "VVINF", "$,", "KOUI", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "aber sie werden vielleicht Enkel haben,", "tokens": ["a\u00b7ber", "sie", "wer\u00b7den", "viel\u00b7leicht", "En\u00b7kel", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "VAFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.13": {"text": "in denen ihre gr\u00fcnen Leben reifen;", "tokens": ["in", "de\u00b7nen", "ih\u00b7re", "gr\u00fc\u00b7nen", "Le\u00b7ben", "rei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "durch diese wirst du jene Liebe erben,", "tokens": ["durch", "die\u00b7se", "wirst", "du", "je\u00b7ne", "Lie\u00b7be", "er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "die sie sich blind und wie im Schlafe gaben.", "tokens": ["die", "sie", "sich", "blind", "und", "wie", "im", "Schla\u00b7fe", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "PRF", "ADJD", "KON", "KOKOM", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "So flie\u00dft der Dinge \u00dcberflu\u00df dir zu.", "tokens": ["So", "flie\u00dft", "der", "Din\u00b7ge", "\u00dc\u00b7berf\u00b7lu\u00df", "dir", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und wie die obern Becken von Font\u00e4nen", "tokens": ["Und", "wie", "die", "o\u00b7bern", "Be\u00b7cken", "von", "Fon\u00b7t\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "best\u00e4ndig \u00fcberstr\u00f6men, wie von Str\u00e4hnen", "tokens": ["be\u00b7st\u00e4n\u00b7dig", "\u00fc\u00b7ber\u00b7str\u00f6\u00b7men", ",", "wie", "von", "Str\u00e4h\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "gel\u00f6sten Haares, in die tiefste Schale, \u2013", "tokens": ["ge\u00b7l\u00f6s\u00b7ten", "Haa\u00b7res", ",", "in", "die", "tiefs\u00b7te", "Scha\u00b7le", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "so f\u00e4llt die F\u00fclle dir in deine Tale,", "tokens": ["so", "f\u00e4llt", "die", "F\u00fcl\u00b7le", "dir", "in", "dei\u00b7ne", "Ta\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "wenn Dinge und Gedanken \u00fcbergehn.", "tokens": ["wenn", "Din\u00b7ge", "und", "Ge\u00b7dan\u00b7ken", "\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.32": {"line.1": {"text": "Ich bin nur einer deiner Ganzgeringen,", "tokens": ["Ich", "bin", "nur", "ei\u00b7ner", "dei\u00b7ner", "Ganz\u00b7ge\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der in das Leben aus der Zelle sieht", "tokens": ["der", "in", "das", "Le\u00b7ben", "aus", "der", "Zel\u00b7le", "sieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und der, den Menschen ferner als den Dingen,", "tokens": ["und", "der", ",", "den", "Men\u00b7schen", "fer\u00b7ner", "als", "den", "Din\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ART", "NN", "ADV", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "nicht wagt zu w\u00e4gen, was geschieht.", "tokens": ["nicht", "wagt", "zu", "w\u00e4\u00b7gen", ",", "was", "ge\u00b7schieht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch willst du mich vor deinem Angesicht,", "tokens": ["Doch", "willst", "du", "mich", "vor", "dei\u00b7nem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "aus dem sich dunkel deine Augen heben,", "tokens": ["aus", "dem", "sich", "dun\u00b7kel", "dei\u00b7ne", "Au\u00b7gen", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "dann halte es f\u00fcr meine Hoffahrt nicht,", "tokens": ["dann", "hal\u00b7te", "es", "f\u00fcr", "mei\u00b7ne", "Hof\u00b7fahrt", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "wenn ich dir sage: Keiner lebt sein Leben.", "tokens": ["wenn", "ich", "dir", "sa\u00b7ge", ":", "Kei\u00b7ner", "lebt", "sein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$.", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zuf\u00e4lle sind die Menschen, Stimmen, St\u00fccke,", "tokens": ["Zu\u00b7f\u00e4l\u00b7le", "sind", "die", "Men\u00b7schen", ",", "Stim\u00b7men", ",", "St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Alltage, \u00c4ngste, viele kleine Gl\u00fccke,", "tokens": ["All\u00b7ta\u00b7ge", ",", "\u00c4ngs\u00b7te", ",", "vie\u00b7le", "klei\u00b7ne", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "verkleidet schon als Kinder, eingemummt,", "tokens": ["ver\u00b7klei\u00b7det", "schon", "als", "Kin\u00b7der", ",", "ein\u00b7ge\u00b7mummt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "KOUS", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "als Masken m\u00fcndig, als Gesicht \u2013 verstummt.", "tokens": ["als", "Mas\u00b7ken", "m\u00fcn\u00b7dig", ",", "als", "Ge\u00b7sicht", "\u2013", "ver\u00b7stummt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "$,", "KOUS", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.33": {"line.1": {"text": "Ich denke oft: Schatzh\u00e4user m\u00fcssen sein,", "tokens": ["Ich", "den\u00b7ke", "oft", ":", "Schatz\u00b7h\u00e4u\u00b7ser", "m\u00fcs\u00b7sen", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wo alle diese vielen Leben liegen", "tokens": ["wo", "al\u00b7le", "die\u00b7se", "vie\u00b7len", "Le\u00b7ben", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PDAT", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie Panzer oder S\u00e4nften oder Wiegen,", "tokens": ["wie", "Pan\u00b7zer", "o\u00b7der", "S\u00e4nf\u00b7ten", "o\u00b7der", "Wie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in welche nie ein Wirklicher gestiegen,", "tokens": ["in", "wel\u00b7che", "nie", "ein", "Wirk\u00b7li\u00b7cher", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und wie Gew\u00e4nder, welche ganz allein", "tokens": ["und", "wie", "Ge\u00b7w\u00e4n\u00b7der", ",", "wel\u00b7che", "ganz", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "nicht stehen k\u00f6nnen und sich sinkend schmiegen", "tokens": ["nicht", "ste\u00b7hen", "k\u00f6n\u00b7nen", "und", "sich", "sin\u00b7kend", "schmie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "VMFIN", "KON", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "an starke W\u00e4nde aus gew\u00f6lbtem Stein.", "tokens": ["an", "star\u00b7ke", "W\u00e4n\u00b7de", "aus", "ge\u00b7w\u00f6lb\u00b7tem", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und wenn ich abends immer weiterginge", "tokens": ["Und", "wenn", "ich", "a\u00b7bends", "im\u00b7mer", "wei\u00b7ter\u00b7gin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "aus meinem Garten, drin ich m\u00fcde bin, \u2013", "tokens": ["aus", "mei\u00b7nem", "Gar\u00b7ten", ",", "drin", "ich", "m\u00fc\u00b7de", "bin", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "PPER", "ADJD", "VAFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "ich wei\u00df: dann f\u00fchren alle Wege hin", "tokens": ["ich", "wei\u00df", ":", "dann", "f\u00fch\u00b7ren", "al\u00b7le", "We\u00b7ge", "hin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VVFIN", "PIAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "zum Arsenal der ungelebten Dinge.", "tokens": ["zum", "Ar\u00b7se\u00b7nal", "der", "un\u00b7ge\u00b7leb\u00b7ten", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dort ist kein Baum, als legte sich das Land,", "tokens": ["Dort", "ist", "kein", "Baum", ",", "als", "leg\u00b7te", "sich", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "KOUS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und wie um ein Gef\u00e4ngnis h\u00e4ngt die Wand", "tokens": ["und", "wie", "um", "ein", "Ge\u00b7f\u00e4ng\u00b7nis", "h\u00e4ngt", "die", "Wand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "ganz fensterlos in siebenfachem Ringe.", "tokens": ["ganz", "fens\u00b7ter\u00b7los", "in", "sie\u00b7ben\u00b7fa\u00b7chem", "Rin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und ihre Tore mit den Eisenspangen,", "tokens": ["Und", "ih\u00b7re", "To\u00b7re", "mit", "den", "Ei\u00b7sen\u00b7span\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "die denen wehren, welche hinverlangen,", "tokens": ["die", "de\u00b7nen", "weh\u00b7ren", ",", "wel\u00b7che", "hin\u00b7ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PDS", "VVINF", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und ihre Gitter sind von Menschenhand.", "tokens": ["und", "ih\u00b7re", "Git\u00b7ter", "sind", "von", "Men\u00b7schen\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.34": {"line.1": {"text": "Und doch, obwohl ein jeder von sich strebt", "tokens": ["Und", "doch", ",", "ob\u00b7wohl", "ein", "je\u00b7der", "von", "sich", "strebt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "PIS", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie aus dem Kerker, der ihn ha\u00dft und h\u00e4lt, \u2013", "tokens": ["wie", "aus", "dem", "Ker\u00b7ker", ",", "der", "ihn", "ha\u00dft", "und", "h\u00e4lt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "es ist ein gro\u00dfes Wunder in der Welt:", "tokens": ["es", "ist", "ein", "gro\u00b7\u00dfes", "Wun\u00b7der", "in", "der", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ich f\u00fchle: ", "tokens": ["ich", "f\u00fch\u00b7le", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wer lebt es denn? Sind das die Dinge, die", "tokens": ["Wer", "lebt", "es", "denn", "?", "Sind", "das", "die", "Din\u00b7ge", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "VAFIN", "PDS", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wie eine ungespielte Melodie", "tokens": ["wie", "ei\u00b7ne", "un\u00b7ge\u00b7spiel\u00b7te", "Me\u00b7lo\u00b7die"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "im Abend wie in einer Harfe stehn?", "tokens": ["im", "A\u00b7bend", "wie", "in", "ei\u00b7ner", "Har\u00b7fe", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KOKOM", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sind das die Winde, die von Wassern wehn,", "tokens": ["Sind", "das", "die", "Win\u00b7de", ",", "die", "von", "Was\u00b7sern", "wehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sind das die Zweige, die sich Zeichen geben,", "tokens": ["sind", "das", "die", "Zwei\u00b7ge", ",", "die", "sich", "Zei\u00b7chen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "sind das die Blumen, die die D\u00fcfte weben,", "tokens": ["sind", "das", "die", "Blu\u00b7men", ",", "die", "die", "D\u00fcf\u00b7te", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "sind das die langen alternden Alleen?", "tokens": ["sind", "das", "die", "lan\u00b7gen", "al\u00b7tern\u00b7den", "Al\u00b7leen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sind das die warmen Tiere, welche gehn,", "tokens": ["Sind", "das", "die", "war\u00b7men", "Tie\u00b7re", ",", "wel\u00b7che", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "sind das die V\u00f6gel, die sich fremd erheben?", "tokens": ["sind", "das", "die", "V\u00f6\u00b7gel", ",", "die", "sich", "fremd", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Wer lebt es denn? Lebst du es, Gott, \u2013 das Leben?", "tokens": ["Wer", "lebt", "es", "denn", "?", "Lebst", "du", "es", ",", "Gott", ",", "\u2013", "das", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "PPER", "PPER", "$,", "NN", "$,", "$(", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.35": {"line.1": {"text": "Du bist der Alte, dem die Haare", "tokens": ["Du", "bist", "der", "Al\u00b7te", ",", "dem", "die", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Ru\u00df versengt sind und verbrannt,", "tokens": ["von", "Ru\u00df", "ver\u00b7sengt", "sind", "und", "ver\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du bist der gro\u00dfe Unscheinbare,", "tokens": ["du", "bist", "der", "gro\u00b7\u00dfe", "Un\u00b7schein\u00b7ba\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mit deinem Hammer in der Hand.", "tokens": ["mit", "dei\u00b7nem", "Ham\u00b7mer", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist der Schmied, das Lied der Jahre,", "tokens": ["Du", "bist", "der", "Schmied", ",", "das", "Lied", "der", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der immer an dem Ambo\u00df stand.", "tokens": ["der", "im\u00b7mer", "an", "dem", "Am\u00b7bo\u00df", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Du bist, der niemals Sonntag hat,", "tokens": ["Du", "bist", ",", "der", "nie\u00b7mals", "Sonn\u00b7tag", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der in die Arbeit Eingekehrte,", "tokens": ["der", "in", "die", "Ar\u00b7beit", "Ein\u00b7ge\u00b7kehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der sterben k\u00f6nnte \u00fcberm Schwerte,", "tokens": ["der", "ster\u00b7ben", "k\u00f6nn\u00b7te", "\u00fc\u00b7berm", "Schwer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das noch nicht gl\u00e4nzend wird und glatt.", "tokens": ["das", "noch", "nicht", "gl\u00e4n\u00b7zend", "wird", "und", "glatt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKNEG", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn bei uns M\u00fchle steht und S\u00e4ge", "tokens": ["Wenn", "bei", "uns", "M\u00fch\u00b7le", "steht", "und", "S\u00e4\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "NN", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und alle trunken sind und tr\u00e4ge,", "tokens": ["und", "al\u00b7le", "trun\u00b7ken", "sind", "und", "tr\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "VAFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "dann h\u00f6rt man deine Hammerschl\u00e4ge", "tokens": ["dann", "h\u00f6rt", "man", "dei\u00b7ne", "Ham\u00b7mer\u00b7schl\u00e4\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "an allen Glocken in der Stadt.", "tokens": ["an", "al\u00b7len", "Glo\u00b7cken", "in", "der", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Du bist der M\u00fcndige, der Meister,", "tokens": ["Du", "bist", "der", "M\u00fcn\u00b7di\u00b7ge", ",", "der", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und keiner hat dich lernen sehn;", "tokens": ["und", "kei\u00b7ner", "hat", "dich", "ler\u00b7nen", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Unbekannter, Hergereister,", "tokens": ["ein", "Un\u00b7be\u00b7kann\u00b7ter", ",", "Her\u00b7ge\u00b7reis\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "von dem bald fl\u00fcsternder, bald dreister", "tokens": ["von", "dem", "bald", "fl\u00fcs\u00b7tern\u00b7der", ",", "bald", "dreis\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "PTKVZ", "$,", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Reden und Ger\u00fcchte gehn.", "tokens": ["die", "Re\u00b7den", "und", "Ge\u00b7r\u00fcch\u00b7te", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Ger\u00fcchte gehn, die dich vermuten,", "tokens": ["Ge\u00b7r\u00fcch\u00b7te", "gehn", ",", "die", "dich", "ver\u00b7mu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und Zweifel gehn, die dich verwischen.", "tokens": ["und", "Zwei\u00b7fel", "gehn", ",", "die", "dich", "ver\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tr\u00e4gen und die Tr\u00e4umerischen", "tokens": ["Die", "Tr\u00e4\u00b7gen", "und", "die", "Tr\u00e4u\u00b7me\u00b7ri\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mi\u00dftrauen ihren eignen Gluten", "tokens": ["mi\u00df\u00b7trau\u00b7en", "ih\u00b7ren", "eig\u00b7nen", "Glu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und wollen, da\u00df die Berge bluten,", "tokens": ["und", "wol\u00b7len", ",", "da\u00df", "die", "Ber\u00b7ge", "blu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "denn eher glauben sie dich nicht.", "tokens": ["denn", "e\u00b7her", "glau\u00b7ben", "sie", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Du aber senkst dein Angesicht.", "tokens": ["Du", "a\u00b7ber", "senkst", "dein", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du k\u00f6nntest den Bergen die Adern aufschneiden", "tokens": ["Du", "k\u00f6nn\u00b7test", "den", "Ber\u00b7gen", "die", "A\u00b7dern", "auf\u00b7schnei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "als Zeichen eines gro\u00dfen Gerichts;", "tokens": ["als", "Zei\u00b7chen", "ei\u00b7nes", "gro\u00b7\u00dfen", "Ge\u00b7richts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "aber dir liegt nichts", "tokens": ["a\u00b7ber", "dir", "liegt", "nichts"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PIS"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "an den Heiden.", "tokens": ["an", "den", "Hei\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.39": {"line.1": {"text": "Du willst nicht streiten mit allen Listen", "tokens": ["Du", "willst", "nicht", "strei\u00b7ten", "mit", "al\u00b7len", "Lis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und nicht suchen die Liebe des Lichts;", "tokens": ["und", "nicht", "su\u00b7chen", "die", "Lie\u00b7be", "des", "Lichts", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "denn dir liegt nichts", "tokens": ["denn", "dir", "liegt", "nichts"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "an den Christen.", "tokens": ["an", "den", "Chris\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.40": {"line.1": {"text": "Dir liegt an den Fragenden nichts.", "tokens": ["Dir", "liegt", "an", "den", "Fra\u00b7gen\u00b7den", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PIS", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sanften Gesichts", "tokens": ["Sanf\u00b7ten", "Ge\u00b7sichts"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "siehst du den Tragenden zu.", "tokens": ["siehst", "du", "den", "Tra\u00b7gen\u00b7den", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.41": {"line.1": {"text": "Alle, welche dich suchen, versuchen dich.", "tokens": ["Al\u00b7le", ",", "wel\u00b7che", "dich", "su\u00b7chen", ",", "ver\u00b7su\u00b7chen", "dich", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVINF", "$,", "VVFIN", "PPER", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und die, so dich finden, binden dich", "tokens": ["Und", "die", ",", "so", "dich", "fin\u00b7den", ",", "bin\u00b7den", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "$,", "ADV", "PPER", "VVINF", "$,", "VAFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "an Bild und Geb\u00e4rde.", "tokens": ["an", "Bild", "und", "Ge\u00b7b\u00e4r\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.42": {"line.1": {"text": "Ich aber will dich begreifen", "tokens": ["Ich", "a\u00b7ber", "will", "dich", "be\u00b7grei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie dich die Erde begreift;", "tokens": ["wie", "dich", "die", "Er\u00b7de", "be\u00b7greift", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "mit meinem Reifen", "tokens": ["mit", "mei\u00b7nem", "Rei\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "reift", "tokens": ["reift"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "dein Reich.", "tokens": ["dein", "Reich", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.43": {"line.1": {"text": "Ich will von dir keine Eitelkeit,", "tokens": ["Ich", "will", "von", "dir", "kei\u00b7ne", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "die dich beweist.", "tokens": ["die", "dich", "be\u00b7weist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ich wei\u00df, da\u00df die Zeit", "tokens": ["Ich", "wei\u00df", ",", "da\u00df", "die", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "anders hei\u00dft", "tokens": ["an\u00b7ders", "hei\u00dft"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "als du.", "tokens": ["als", "du", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.44": {"line.1": {"text": "Tu mir kein Wunder zulieb.", "tokens": ["Tu", "mir", "kein", "Wun\u00b7der", "zu\u00b7lieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Gieb deinen Gesetzen recht,", "tokens": ["Gieb", "dei\u00b7nen", "Ge\u00b7set\u00b7zen", "recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "die von Geschlecht zu Geschlecht", "tokens": ["die", "von", "Ge\u00b7schlecht", "zu", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "sichtbarer sind.", "tokens": ["sicht\u00b7ba\u00b7rer", "sind", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.45": {"line.1": {"text": "Wenn etwas mir vom Fenster f\u00e4llt", "tokens": ["Wenn", "et\u00b7was", "mir", "vom", "Fens\u00b7ter", "f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(und wenn es auch das Kleinste w\u00e4re)", "tokens": ["(", "und", "wenn", "es", "auch", "das", "Kleins\u00b7te", "w\u00e4\u00b7re", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie st\u00fcrzt sich das Gesetz der Schwere", "tokens": ["wie", "st\u00fcrzt", "sich", "das", "Ge\u00b7setz", "der", "Schwe\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gewaltig wie ein Wind vom Meere", "tokens": ["ge\u00b7wal\u00b7tig", "wie", "ein", "Wind", "vom", "Mee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "auf jeden Ball und jede Beere", "tokens": ["auf", "je\u00b7den", "Ball", "und", "je\u00b7de", "Bee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und tr\u00e4gt sie in den Kern der Welt.", "tokens": ["und", "tr\u00e4gt", "sie", "in", "den", "Kern", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Ein jedes Ding ist \u00fcberwacht", "tokens": ["Ein", "je\u00b7des", "Ding", "ist", "\u00fc\u00b7ber\u00b7wacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von einer flugbereiten G\u00fcte", "tokens": ["von", "ei\u00b7ner", "flug\u00b7be\u00b7rei\u00b7ten", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie jeder Stein und jede Bl\u00fcte", "tokens": ["wie", "je\u00b7der", "Stein", "und", "je\u00b7de", "Bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und jedes kleine Kind bei Nacht.", "tokens": ["und", "je\u00b7des", "klei\u00b7ne", "Kind", "bei", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur wir, in unsrer Hoffahrt, dr\u00e4ngen", "tokens": ["Nur", "wir", ",", "in", "uns\u00b7rer", "Hof\u00b7fahrt", ",", "dr\u00e4n\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "aus einigen Zusammenh\u00e4ngen", "tokens": ["aus", "ei\u00b7ni\u00b7gen", "Zu\u00b7sam\u00b7men\u00b7h\u00e4n\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in einer Freiheit leeren Raum,", "tokens": ["in", "ei\u00b7ner", "Frei\u00b7heit", "lee\u00b7ren", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "statt, klugen Kr\u00e4ften hingegeben,", "tokens": ["statt", ",", "klu\u00b7gen", "Kr\u00e4f\u00b7ten", "hin\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "uns aufzuheben wie ein Baum.", "tokens": ["uns", "auf\u00b7zu\u00b7he\u00b7ben", "wie", "ein", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVIZU", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Statt in die weitesten Geleise", "tokens": ["Statt", "in", "die", "wei\u00b7tes\u00b7ten", "Ge\u00b7lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "sich still und willig einzureihn,", "tokens": ["sich", "still", "und", "wil\u00b7lig", "ein\u00b7zu\u00b7reihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "verkn\u00fcpft man sich auf manche Weise, \u2013", "tokens": ["ver\u00b7kn\u00fcpft", "man", "sich", "auf", "man\u00b7che", "Wei\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "PIAT", "NN", "$,", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "und wer sich ausschlie\u00dft jedem Kreise,", "tokens": ["und", "wer", "sich", "aus\u00b7schlie\u00dft", "je\u00b7dem", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "ist jetzt so namenlos allein.", "tokens": ["ist", "jetzt", "so", "na\u00b7men\u00b7los", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Da mu\u00df er lernen von den Dingen,", "tokens": ["Da", "mu\u00df", "er", "ler\u00b7nen", "von", "den", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "anfangen wieder wie ein Kind,", "tokens": ["an\u00b7fan\u00b7gen", "wie\u00b7der", "wie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "weil sie, die Gott am Herzen hingen,", "tokens": ["weil", "sie", ",", "die", "Gott", "am", "Her\u00b7zen", "hin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "nicht von ihm fortgegangen sind.", "tokens": ["nicht", "von", "ihm", "fort\u00b7ge\u00b7gan\u00b7gen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Eins mu\u00df er wieder k\u00f6nnen: ", "tokens": ["Eins", "mu\u00df", "er", "wie\u00b7der", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "geduldig in der Schwere ruhn,", "tokens": ["ge\u00b7dul\u00b7dig", "in", "der", "Schwe\u00b7re", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "der sich verma\u00df, den V\u00f6geln allen", "tokens": ["der", "sich", "ver\u00b7ma\u00df", ",", "den", "V\u00f6\u00b7geln", "al\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PRF", "VVFIN", "$,", "ART", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "im Fliegen es zuvorzutun.", "tokens": ["im", "Flie\u00b7gen", "es", "zu\u00b7vor\u00b7zu\u00b7tun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "(denn auch die Engel fliegen nicht mehr.", "tokens": ["(", "denn", "auch", "die", "En\u00b7gel", "flie\u00b7gen", "nicht", "mehr", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schweren V\u00f6geln gleichen die Seraphim,", "tokens": ["Schwe\u00b7ren", "V\u00f6\u00b7geln", "glei\u00b7chen", "die", "Se\u00b7ra\u00b7phim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "welche um ", "tokens": ["wel\u00b7che", "um"], "token_info": ["word", "word"], "pos": ["PWAT", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Tr\u00fcmmern von V\u00f6geln, Pinguinen", "tokens": ["Tr\u00fcm\u00b7mern", "von", "V\u00f6\u00b7geln", ",", "Pin\u00b7gu\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "NN", "$,", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "gleichen sie, wie sie verk\u00fcmmern ...)", "tokens": ["glei\u00b7chen", "sie", ",", "wie", "sie", "ver\u00b7k\u00fcm\u00b7mern", "...", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.48": {"line.1": {"text": "Du meinst die Demut. Angesichter", "tokens": ["Du", "meinst", "die", "De\u00b7mut", ".", "An\u00b7ge\u00b7sich\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "ART", "NN", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gesenkt in stillem Dichverstehn.", "tokens": ["ge\u00b7senkt", "in", "stil\u00b7lem", "Dich\u00b7ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gehen abends junge Dichter", "tokens": ["So", "ge\u00b7hen", "a\u00b7bends", "jun\u00b7ge", "Dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in den entlegenen Alleen.", "tokens": ["in", "den", "ent\u00b7le\u00b7ge\u00b7nen", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "So stehn die Bauern um die Leiche,", "tokens": ["So", "stehn", "die", "Bau\u00b7ern", "um", "die", "Lei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wenn sich ein Kind im Tod verlor, \u2013", "tokens": ["wenn", "sich", "ein", "Kind", "im", "Tod", "ver\u00b7lor", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und was geschieht, ist doch das Gleiche:", "tokens": ["und", "was", "ge\u00b7schieht", ",", "ist", "doch", "das", "Glei\u00b7che", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "es geht ein \u00dcbergro\u00dfes vor.", "tokens": ["es", "geht", "ein", "\u00dc\u00b7ber\u00b7gro\u00b7\u00dfes", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Wer dich zum ersten Mal gewahrt,", "tokens": ["Wer", "dich", "zum", "ers\u00b7ten", "Mal", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den st\u00f6rt der Nachbar und die Uhr,", "tokens": ["den", "st\u00f6rt", "der", "Nach\u00b7bar", "und", "die", "Uhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der geht, gebeugt zu deiner Spur,", "tokens": ["der", "geht", ",", "ge\u00b7beugt", "zu", "dei\u00b7ner", "Spur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und wie beladen und bejahrt.", "tokens": ["und", "wie", "be\u00b7la\u00b7den", "und", "be\u00b7jahrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erst sp\u00e4ter naht er der Natur", "tokens": ["Erst", "sp\u00e4\u00b7ter", "naht", "er", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und f\u00fchlt die Winde und die Fernen,", "tokens": ["und", "f\u00fchlt", "die", "Win\u00b7de", "und", "die", "Fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "h\u00f6rt dich, gefl\u00fcstert von der Flur,", "tokens": ["h\u00f6rt", "dich", ",", "ge\u00b7fl\u00fcs\u00b7tert", "von", "der", "Flur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "sieht dich, gesungen von den Sternen,", "tokens": ["sieht", "dich", ",", "ge\u00b7sun\u00b7gen", "von", "den", "Ster\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "und kann dich nirgends mehr verlernen,", "tokens": ["und", "kann", "dich", "nir\u00b7gends", "mehr", "ver\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und alles ist dein Mantel nur.", "tokens": ["und", "al\u00b7les", "ist", "dein", "Man\u00b7tel", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Ihm bist du neu und nah und gut", "tokens": ["Ihm", "bist", "du", "neu", "und", "nah", "und", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wundersch\u00f6n wie eine Reise,", "tokens": ["und", "wun\u00b7der\u00b7sch\u00f6n", "wie", "ei\u00b7ne", "Rei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die er in stillen Schiffen leise", "tokens": ["die", "er", "in", "stil\u00b7len", "Schif\u00b7fen", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf einem gro\u00dfen Flusse tut.", "tokens": ["auf", "ei\u00b7nem", "gro\u00b7\u00dfen", "Flus\u00b7se", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Land ist weit, in Winden, eben,", "tokens": ["Das", "Land", "ist", "weit", ",", "in", "Win\u00b7den", ",", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "APPR", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sehr gro\u00dfen Himmeln preisgegeben", "tokens": ["sehr", "gro\u00b7\u00dfen", "Him\u00b7meln", "preis\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und alten W\u00e4ldern untertan.", "tokens": ["und", "al\u00b7ten", "W\u00e4l\u00b7dern", "un\u00b7ter\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die kleinen D\u00f6rfer, die sich nahn,", "tokens": ["Die", "klei\u00b7nen", "D\u00f6r\u00b7fer", ",", "die", "sich", "nahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "vergehen wieder wie Gel\u00e4ute", "tokens": ["ver\u00b7ge\u00b7hen", "wie\u00b7der", "wie", "Ge\u00b7l\u00e4u\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und wie ein Gestern und ein Heute", "tokens": ["und", "wie", "ein", "Ge\u00b7stern", "und", "ein", "Heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "und so wie alles, was wir sahn.", "tokens": ["und", "so", "wie", "al\u00b7les", ",", "was", "wir", "sahn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Aber an dieses Stromes Lauf", "tokens": ["A\u00b7ber", "an", "die\u00b7ses", "Stro\u00b7mes", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "stehn immer wieder St\u00e4dte auf", "tokens": ["stehn", "im\u00b7mer", "wie\u00b7der", "St\u00e4d\u00b7te", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "und kommen wie auf Fl\u00fcgelschl\u00e4gen", "tokens": ["und", "kom\u00b7men", "wie", "auf", "Fl\u00fc\u00b7gel\u00b7schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "der feierlichen Fahrt entgegen.", "tokens": ["der", "fei\u00b7er\u00b7li\u00b7chen", "Fahrt", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Und manchmal lenkt das Schiff zu Stellen,", "tokens": ["Und", "manch\u00b7mal", "lenkt", "das", "Schiff", "zu", "Stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die einsam, sonder Dorf und Stadt,", "tokens": ["die", "ein\u00b7sam", ",", "son\u00b7der", "Dorf", "und", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auf etwas warten an den Wellen, \u2013", "tokens": ["auf", "et\u00b7was", "war\u00b7ten", "an", "den", "Wel\u00b7len", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "VVFIN", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf den, der keine Heimat hat ...", "tokens": ["auf", "den", ",", "der", "kei\u00b7ne", "Hei\u00b7mat", "hat", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr solche stehn dort kleine Wagen", "tokens": ["F\u00fcr", "sol\u00b7che", "stehn", "dort", "klei\u00b7ne", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "(ein jeder mit drei Pferden vor),", "tokens": ["(", "ein", "je\u00b7der", "mit", "drei", "Pfer\u00b7den", "vor", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIS", "APPR", "CARD", "NN", "PTKVZ", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die atemlos nach Abend jagen", "tokens": ["die", "a\u00b7tem\u00b7los", "nach", "A\u00b7bend", "ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "auf einem Weg, der sich verlor.", "tokens": ["auf", "ei\u00b7nem", "Weg", ",", "der", "sich", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "In diesem Dorfe steht das letzte Haus", "tokens": ["In", "die\u00b7sem", "Dor\u00b7fe", "steht", "das", "letz\u00b7te", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "so einsam wie das letzte Haus der Welt.", "tokens": ["so", "ein\u00b7sam", "wie", "das", "letz\u00b7te", "Haus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.53": {"line.1": {"text": "Die Stra\u00dfe, die das kleine Dorf nicht h\u00e4lt,", "tokens": ["Die", "Stra\u00b7\u00dfe", ",", "die", "das", "klei\u00b7ne", "Dorf", "nicht", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "geht langsam weiter in die Nacht hinaus.", "tokens": ["geht", "lang\u00b7sam", "wei\u00b7ter", "in", "die", "Nacht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.54": {"line.1": {"text": "Das kleine Dorf ist nur ein \u00dcbergang", "tokens": ["Das", "klei\u00b7ne", "Dorf", "ist", "nur", "ein", "\u00dc\u00b7ber\u00b7gang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "zwischen zwei Weiten, ahnungsvoll und bang,", "tokens": ["zwi\u00b7schen", "zwei", "Wei\u00b7ten", ",", "ah\u00b7nungs\u00b7voll", "und", "bang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein Weg an H\u00e4usern hin statt eines Stegs.", "tokens": ["ein", "Weg", "an", "H\u00e4u\u00b7sern", "hin", "statt", "ei\u00b7nes", "Stegs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.55": {"line.1": {"text": "Und die das Dorf verlassen, wandern lang,", "tokens": ["Und", "die", "das", "Dorf", "ver\u00b7las\u00b7sen", ",", "wan\u00b7dern", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVINF", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und viele sterben vielleicht unterwegs.", "tokens": ["und", "vie\u00b7le", "ster\u00b7ben", "viel\u00b7leicht", "un\u00b7ter\u00b7wegs", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.56": {"line.1": {"text": "Manchmal steht einer auf beim Abendbrot", "tokens": ["Manch\u00b7mal", "steht", "ei\u00b7ner", "auf", "beim", "A\u00b7bend\u00b7brot"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und geht hinaus und geht und geht und geht, \u2013", "tokens": ["und", "geht", "hin\u00b7aus", "und", "geht", "und", "geht", "und", "geht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "weil eine Kirche wo im Osten steht.", "tokens": ["weil", "ei\u00b7ne", "Kir\u00b7che", "wo", "im", "Os\u00b7ten", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PWAV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.57": {"line.1": {"text": "Und seine Kinder segnen ihn wie tot.", "tokens": ["Und", "sei\u00b7ne", "Kin\u00b7der", "seg\u00b7nen", "ihn", "wie", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.58": {"line.1": {"text": "Und einer, welcher stirbt in seinem Haus,", "tokens": ["Und", "ei\u00b7ner", ",", "wel\u00b7cher", "stirbt", "in", "sei\u00b7nem", "Haus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "bleibt drinnen wohnen, bleibt in Tisch und Glas,", "tokens": ["bleibt", "drin\u00b7nen", "woh\u00b7nen", ",", "bleibt", "in", "Tisch", "und", "Glas", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVINF", "$,", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df die Kinder in die Welt hinaus", "tokens": ["so", "da\u00df", "die", "Kin\u00b7der", "in", "die", "Welt", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "zu jener Kirche ziehn, die er verga\u00df.", "tokens": ["zu", "je\u00b7ner", "Kir\u00b7che", "ziehn", ",", "die", "er", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.59": {"line.1": {"text": "Nachtw\u00e4chter ist der Wahnsinn,", "tokens": ["Nacht\u00b7w\u00e4ch\u00b7ter", "ist", "der", "Wahn\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "weil er wacht.", "tokens": ["weil", "er", "wacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Bei jeder Stunde bleibt er lachend stehn,", "tokens": ["Bei", "je\u00b7der", "Stun\u00b7de", "bleibt", "er", "la\u00b7chend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und einen Namen sucht er f\u00fcr die Nacht", "tokens": ["und", "ei\u00b7nen", "Na\u00b7men", "sucht", "er", "f\u00fcr", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und nennt sie: sieben, achtundzwanzig, zehn ...", "tokens": ["und", "nennt", "sie", ":", "sie\u00b7ben", ",", "acht\u00b7und\u00b7zwan\u00b7zig", ",", "zehn", "..."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "CARD", "$,", "CARD", "$,", "CARD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ein Triangel tr\u00e4gt er in der Hand,", "tokens": ["Und", "ein", "Tri\u00b7an\u00b7gel", "tr\u00e4gt", "er", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und weil er zittert, schl\u00e4gt es an den Rand", "tokens": ["und", "weil", "er", "zit\u00b7tert", ",", "schl\u00e4gt", "es", "an", "den", "Rand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "des Horns, das er nicht blasen kann, und singt", "tokens": ["des", "Horns", ",", "das", "er", "nicht", "bla\u00b7sen", "kann", ",", "und", "singt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "das Lied, das er zu allen H\u00e4usern bringt.", "tokens": ["das", "Lied", ",", "das", "er", "zu", "al\u00b7len", "H\u00e4u\u00b7sern", "bringt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.60": {"line.1": {"text": "Die Kinder haben eine gute Nacht", "tokens": ["Die", "Kin\u00b7der", "ha\u00b7ben", "ei\u00b7ne", "gu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und h\u00f6ren tr\u00e4umend, da\u00df der Wahnsinn wacht.", "tokens": ["und", "h\u00f6\u00b7ren", "tr\u00e4u\u00b7mend", ",", "da\u00df", "der", "Wahn\u00b7sinn", "wacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVPP", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Hunde aber rei\u00dfen sich vom Ring", "tokens": ["Die", "Hun\u00b7de", "a\u00b7ber", "rei\u00b7\u00dfen", "sich", "vom", "Ring"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und gehen in den H\u00e4usern gro\u00df umher", "tokens": ["und", "ge\u00b7hen", "in", "den", "H\u00e4u\u00b7sern", "gro\u00df", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und zittern, wenn er schon vor\u00fcberging,", "tokens": ["und", "zit\u00b7tern", ",", "wenn", "er", "schon", "vor\u00b7\u00fc\u00b7ber\u00b7ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und f\u00fcrchten sich vor seiner Wiederkehr.", "tokens": ["und", "f\u00fcrch\u00b7ten", "sich", "vor", "sei\u00b7ner", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.61": {"line.1": {"text": "Wei\u00dft du von jenen Heiligen, mein Herr?", "tokens": ["Wei\u00dft", "du", "von", "je\u00b7nen", "Hei\u00b7li\u00b7gen", ",", "mein", "Herr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.62": {"line.1": {"text": "Sie f\u00fchlten auch verschlo\u00dfne Klosterstuben", "tokens": ["Sie", "f\u00fchl\u00b7ten", "auch", "ver\u00b7schlo\u00df\u00b7ne", "Klos\u00b7ter\u00b7stu\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "zu nahe an Gel\u00e4chter und Gepl\u00e4rr,", "tokens": ["zu", "na\u00b7he", "an", "Ge\u00b7l\u00e4ch\u00b7ter", "und", "Ge\u00b7pl\u00e4rr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie tief sich in die Erde gruben.", "tokens": ["so", "da\u00df", "sie", "tief", "sich", "in", "die", "Er\u00b7de", "gru\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.63": {"line.1": {"text": "Ein jeder atmete mit seinem Licht", "tokens": ["Ein", "je\u00b7der", "at\u00b7me\u00b7te", "mit", "sei\u00b7nem", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die kleine Luft in seiner Grube aus,", "tokens": ["die", "klei\u00b7ne", "Luft", "in", "sei\u00b7ner", "Gru\u00b7be", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "verga\u00df sein Alter und sein Angesicht", "tokens": ["ver\u00b7ga\u00df", "sein", "Al\u00b7ter", "und", "sein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und lebte wie ein fensterloses Haus", "tokens": ["und", "leb\u00b7te", "wie", "ein", "fens\u00b7ter\u00b7lo\u00b7ses", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und starb nichtmehr, als w\u00e4r er lange tot.", "tokens": ["und", "starb", "nicht\u00b7mehr", ",", "als", "w\u00e4r", "er", "lan\u00b7ge", "tot", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie lasen selten; alles war verdorrt,", "tokens": ["Sie", "la\u00b7sen", "sel\u00b7ten", ";", "al\u00b7les", "war", "ver\u00b7dorrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "als w\u00e4re Frost in jedes Buch gekrochen,", "tokens": ["als", "w\u00e4\u00b7re", "Frost", "in", "je\u00b7des", "Buch", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und wie die Kutte hing von ihren Knochen,", "tokens": ["und", "wie", "die", "Kut\u00b7te", "hing", "von", "ih\u00b7ren", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "so hing der Sinn herab von jedem Wort.", "tokens": ["so", "hing", "der", "Sinn", "her\u00b7ab", "von", "je\u00b7dem", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sie redeten einander nichtmehr an,", "tokens": ["Sie", "re\u00b7de\u00b7ten", "ein\u00b7an\u00b7der", "nicht\u00b7mehr", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIS", "PTKVZ", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "wenn sie sich f\u00fchlten in den schwarzen G\u00e4ngen,", "tokens": ["wenn", "sie", "sich", "f\u00fchl\u00b7ten", "in", "den", "schwar\u00b7zen", "G\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "sie lie\u00dfen ihre langen Haare h\u00e4ngen,", "tokens": ["sie", "lie\u00b7\u00dfen", "ih\u00b7re", "lan\u00b7gen", "Haa\u00b7re", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "und keiner wu\u00dfte, ob sein Nachbarmann", "tokens": ["und", "kei\u00b7ner", "wu\u00df\u00b7te", ",", "ob", "sein", "Nach\u00b7bar\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "nicht stehend starb.", "tokens": ["nicht", "ste\u00b7hend", "starb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "In einem runden Raum,", "tokens": ["In", "ei\u00b7nem", "run\u00b7den", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "wo Silberlampen sich von Balsam n\u00e4hrten,", "tokens": ["wo", "Sil\u00b7ber\u00b7lam\u00b7pen", "sich", "von", "Bal\u00b7sam", "n\u00e4hr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PRF", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "versammelten sich manchmal die Gef\u00e4hrten", "tokens": ["ver\u00b7sam\u00b7mel\u00b7ten", "sich", "manch\u00b7mal", "die", "Ge\u00b7f\u00e4hr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.18": {"text": "vor goldnen T\u00fcren wie vor goldnen G\u00e4rten", "tokens": ["vor", "gold\u00b7nen", "T\u00fc\u00b7ren", "wie", "vor", "gold\u00b7nen", "G\u00e4r\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und schauten voller Mi\u00dftraun in den Traum", "tokens": ["und", "schau\u00b7ten", "vol\u00b7ler", "Mi\u00df\u00b7traun", "in", "den", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "und rauschten leise mit den langen B\u00e4rten.", "tokens": ["und", "rauschten", "lei\u00b7se", "mit", "den", "lan\u00b7gen", "B\u00e4r\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.64": {"line.1": {"text": "Ihr Leben war wie tausend Jahre gro\u00df,", "tokens": ["Ihr", "Le\u00b7ben", "war", "wie", "tau\u00b7send", "Jah\u00b7re", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "seit es sich nichtmehr schied in Nacht und Helle;", "tokens": ["seit", "es", "sich", "nicht\u00b7mehr", "schied", "in", "Nacht", "und", "Hel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "sie waren, wie gew\u00e4lzt von einer Welle,", "tokens": ["sie", "wa\u00b7ren", ",", "wie", "ge\u00b7w\u00e4lzt", "von", "ei\u00b7ner", "Wel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "zur\u00fcckgekehrt in ihrer Mutter Schoo\u00df.", "tokens": ["zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "in", "ih\u00b7rer", "Mut\u00b7ter", "Schoo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie sa\u00dfen rundgekr\u00fcmmt wie Embryos", "tokens": ["Sie", "sa\u00b7\u00dfen", "rund\u00b7ge\u00b7kr\u00fcmmt", "wie", "Emb\u00b7ry\u00b7os"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVFIN", "KOKOM", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit gro\u00dfen K\u00f6pfen und mit kleinen H\u00e4nden", "tokens": ["mit", "gro\u00b7\u00dfen", "K\u00f6p\u00b7fen", "und", "mit", "klei\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und a\u00dfen nicht, als ob sie Nahrung f\u00e4nden", "tokens": ["und", "a\u00b7\u00dfen", "nicht", ",", "als", "ob", "sie", "Nah\u00b7rung", "f\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "aus jener Erde, die sie schwarz umschlo\u00df.", "tokens": ["aus", "je\u00b7ner", "Er\u00b7de", ",", "die", "sie", "schwarz", "um\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.65": {"line.1": {"text": "Jetzt zeigt man sie den tausend Pilgern, die", "tokens": ["Jetzt", "zeigt", "man", "sie", "den", "tau\u00b7send", "Pil\u00b7gern", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ART", "CARD", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus Stadt und Steppe zu dem Kloster wallen.", "tokens": ["aus", "Stadt", "und", "Step\u00b7pe", "zu", "dem", "Klos\u00b7ter", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Seit dreimal hundert Jahren liegen sie,", "tokens": ["Seit", "drei\u00b7mal", "hun\u00b7dert", "Jah\u00b7ren", "lie\u00b7gen", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "CARD", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und ihre Leiber k\u00f6nnen nicht zerfallen.", "tokens": ["und", "ih\u00b7re", "Lei\u00b7ber", "k\u00f6n\u00b7nen", "nicht", "zer\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Das Dunkel h\u00e4uft sich wie ein Licht das ru\u00dft", "tokens": ["Das", "Dun\u00b7kel", "h\u00e4uft", "sich", "wie", "ein", "Licht", "das", "ru\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "KOKOM", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "auf ihren langen lagernden Gestalten,", "tokens": ["auf", "ih\u00b7ren", "lan\u00b7gen", "la\u00b7gern\u00b7den", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "die unter T\u00fcchern heimlich sich erhalten, \u2013", "tokens": ["die", "un\u00b7ter", "T\u00fc\u00b7chern", "heim\u00b7lich", "sich", "er\u00b7hal\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "NN", "ADJD", "PRF", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und ihrer H\u00e4nde ungel\u00f6stes Falten", "tokens": ["und", "ih\u00b7rer", "H\u00e4n\u00b7de", "un\u00b7ge\u00b7l\u00f6s\u00b7tes", "Fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "liegt ihnen wie Gebirge auf der Brust.", "tokens": ["liegt", "ih\u00b7nen", "wie", "Ge\u00b7bir\u00b7ge", "auf", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.66": {"line.1": {"text": "Du gro\u00dfer alter Herzog des Erhabnen:", "tokens": ["Du", "gro\u00b7\u00dfer", "al\u00b7ter", "Her\u00b7zog", "des", "Er\u00b7hab\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "hast du vergessen, diesen Eingegrabnen", "tokens": ["hast", "du", "ver\u00b7ges\u00b7sen", ",", "die\u00b7sen", "Ein\u00b7ge\u00b7grab\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Tod zu schicken, der sie ganz verbraucht,", "tokens": ["den", "Tod", "zu", "schi\u00b7cken", ",", "der", "sie", "ganz", "ver\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "weil sie sich tief in Erde eingetaucht?", "tokens": ["weil", "sie", "sich", "tief", "in", "Er\u00b7de", "ein\u00b7ge\u00b7taucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sind die, die sich Verstorbenen vergleichen,", "tokens": ["Sind", "die", ",", "die", "sich", "Ver\u00b7stor\u00b7be\u00b7nen", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$,", "PRELS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "am \u00e4hnlichsten der Unverg\u00e4nglichkeit?", "tokens": ["am", "\u00e4hn\u00b7lichs\u00b7ten", "der", "Un\u00b7ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Ist das das gro\u00dfe Leben deiner Leichen,", "tokens": ["Ist", "das", "das", "gro\u00b7\u00dfe", "Le\u00b7ben", "dei\u00b7ner", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "das \u00fcberdauern soll den Tod der Zeit?", "tokens": ["das", "\u00fc\u00b7berd\u00b7au\u00b7ern", "soll", "den", "Tod", "der", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VMFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.67": {"line.1": {"text": "Sind sie dir noch zu deinen Pl\u00e4nen gut?", "tokens": ["Sind", "sie", "dir", "noch", "zu", "dei\u00b7nen", "Pl\u00e4\u00b7nen", "gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erh\u00e4ltst du unverg\u00e4ngliche Gef\u00e4\u00dfe,", "tokens": ["Er\u00b7h\u00e4ltst", "du", "un\u00b7ver\u00b7g\u00e4ng\u00b7li\u00b7che", "Ge\u00b7f\u00e4\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die du, der allen Ma\u00dfen Ungem\u00e4\u00dfe,", "tokens": ["die", "du", ",", "der", "al\u00b7len", "Ma\u00b7\u00dfen", "Un\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "PRELS", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "einmal erf\u00fcllen willst mit deinem Blut?", "tokens": ["ein\u00b7mal", "er\u00b7f\u00fcl\u00b7len", "willst", "mit", "dei\u00b7nem", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.68": {"line.1": {"text": "Du bist die Zukunft, gro\u00dfes Morgenrot", "tokens": ["Du", "bist", "die", "Zu\u00b7kunft", ",", "gro\u00b7\u00dfes", "Mor\u00b7gen\u00b7rot"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00fcber den Ebenen der Ewigkeit.", "tokens": ["\u00fc\u00b7ber", "den", "E\u00b7be\u00b7nen", "der", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+---+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Du bist der Hahnschrei nach der Nacht der Zeit,", "tokens": ["Du", "bist", "der", "Hahn\u00b7schrei", "nach", "der", "Nacht", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der Tau, die Morgenmette und die Maid,", "tokens": ["der", "Tau", ",", "die", "Mor\u00b7gen\u00b7met\u00b7te", "und", "die", "Maid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der fremde Mann, die Mutter und der Tod.", "tokens": ["der", "frem\u00b7de", "Mann", ",", "die", "Mut\u00b7ter", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.69": {"line.1": {"text": "Du bist die sich verwandelnde Gestalt,", "tokens": ["Du", "bist", "die", "sich", "ver\u00b7wan\u00b7deln\u00b7de", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.2": {"text": "die immer einsam aus dem Schicksal ragt,", "tokens": ["die", "im\u00b7mer", "ein\u00b7sam", "aus", "dem", "Schick\u00b7sal", "ragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die unbejubelt bleibt und unbeklagt", "tokens": ["die", "un\u00b7be\u00b7ju\u00b7belt", "bleibt", "und", "un\u00b7be\u00b7klagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und unbeschrieben wie ein wilder Wald.", "tokens": ["und", "un\u00b7be\u00b7schrie\u00b7ben", "wie", "ein", "wil\u00b7der", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.70": {"line.1": {"text": "Du bist der Dinge tiefer Inbegriff,", "tokens": ["Du", "bist", "der", "Din\u00b7ge", "tie\u00b7fer", "In\u00b7be\u00b7griff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der seines Wesens letztes Wort verschweigt", "tokens": ["der", "sei\u00b7nes", "We\u00b7sens", "letz\u00b7tes", "Wort", "ver\u00b7schweigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und sich den Andern immer anders zeigt:", "tokens": ["und", "sich", "den", "An\u00b7dern", "im\u00b7mer", "an\u00b7ders", "zeigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "ADJA", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dem Schiff als K\u00fcste und dem Land als Schiff.", "tokens": ["dem", "Schiff", "als", "K\u00fcs\u00b7te", "und", "dem", "Land", "als", "Schiff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "KON", "ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.71": {"line.1": {"text": "Du bist das Kloster zu den Wundenmalen.", "tokens": ["Du", "bist", "das", "Klos\u00b7ter", "zu", "den", "Wun\u00b7den\u00b7ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit zweiunddrei\u00dfig alten Kathedralen", "tokens": ["Mit", "zwei\u00b7und\u00b7drei\u00b7\u00dfig", "al\u00b7ten", "Ka\u00b7thed\u00b7ra\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und f\u00fcnfzig Kirchen, welche aus Opalen", "tokens": ["und", "f\u00fcnf\u00b7zig", "Kir\u00b7chen", ",", "wel\u00b7che", "aus", "O\u00b7pa\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "CARD", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und St\u00fccken Bernstein aufgemauert sind.", "tokens": ["und", "St\u00fc\u00b7cken", "Bern\u00b7stein", "auf\u00b7ge\u00b7mau\u00b7ert", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf jedem Ding im Klosterhofe", "tokens": ["Auf", "je\u00b7dem", "Ding", "im", "Klos\u00b7ter\u00b7ho\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "liegt deines Klanges eine Strophe,", "tokens": ["liegt", "dei\u00b7nes", "Klan\u00b7ges", "ei\u00b7ne", "Stro\u00b7phe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und das gewaltige Tor beginnt.", "tokens": ["und", "das", "ge\u00b7wal\u00b7ti\u00b7ge", "Tor", "be\u00b7ginnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.72": {"line.1": {"text": "In langen H\u00e4usern wohnen Nonnen,", "tokens": ["In", "lan\u00b7gen", "H\u00e4u\u00b7sern", "woh\u00b7nen", "Non\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwarzschwestern, siebenhundertzehn.", "tokens": ["Schwarz\u00b7schwes\u00b7tern", ",", "sie\u00b7ben\u00b7hun\u00b7dert\u00b7zehn", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Manchmal kommt eine an den Bronnen,", "tokens": ["Manch\u00b7mal", "kommt", "ei\u00b7ne", "an", "den", "Bron\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und eine steht wie eingesponnen,", "tokens": ["und", "ei\u00b7ne", "steht", "wie", "ein\u00b7ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "KOKOM", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und eine, wie in Abendsonnen,", "tokens": ["und", "ei\u00b7ne", ",", "wie", "in", "A\u00b7bend\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "geht schlank in schweigsamen Alleen.", "tokens": ["geht", "schlank", "in", "schweig\u00b7sa\u00b7men", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.73": {"line.1": {"text": "Aber die Meisten sieht man nie;", "tokens": ["A\u00b7ber", "die", "Meis\u00b7ten", "sieht", "man", "nie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIS", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sie bleiben in der H\u00e4user Schweigen", "tokens": ["sie", "blei\u00b7ben", "in", "der", "H\u00e4u\u00b7ser", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie in der kranken Brust der Geigen", "tokens": ["wie", "in", "der", "kran\u00b7ken", "Brust", "der", "Gei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Melodie, die keiner kann ...", "tokens": ["die", "Me\u00b7lo\u00b7die", ",", "die", "kei\u00b7ner", "kann", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.74": {"line.1": {"text": "Und um die Kirchen rings im Kreise,", "tokens": ["Und", "um", "die", "Kir\u00b7chen", "rings", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von schmachtendem Jasmin umstellt,", "tokens": ["von", "schmach\u00b7ten\u00b7dem", "Jas\u00b7min", "um\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "sind Gr\u00e4berst\u00e4tten, welche leise", "tokens": ["sind", "Gr\u00e4\u00b7ber\u00b7st\u00e4t\u00b7ten", ",", "wel\u00b7che", "lei\u00b7se"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wie Steine reden von der Welt.", "tokens": ["wie", "Stei\u00b7ne", "re\u00b7den", "von", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von jener Welt, die nichtmehr ist,", "tokens": ["Von", "je\u00b7ner", "Welt", ",", "die", "nicht\u00b7mehr", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "obwohl sie an das Kloster brandet,", "tokens": ["ob\u00b7wohl", "sie", "an", "das", "Klos\u00b7ter", "bran\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in eitel Tag und Tand gewandet", "tokens": ["in", "ei\u00b7tel", "Tag", "und", "Tand", "ge\u00b7wan\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und gleichbereit zu Lust und List.", "tokens": ["und", "gleich\u00b7be\u00b7reit", "zu", "Lust", "und", "List", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.75": {"line.1": {"text": "Sie ist vergangen: denn du bist.", "tokens": ["Sie", "ist", "ver\u00b7gan\u00b7gen", ":", "denn", "du", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "KON", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.76": {"line.1": {"text": "Sie flie\u00dft noch wie ein Spiel von Lichtern", "tokens": ["Sie", "flie\u00dft", "noch", "wie", "ein", "Spiel", "von", "Lich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00fcber das teilnahmslose Jahr;", "tokens": ["\u00fc\u00b7ber", "das", "teil\u00b7nahms\u00b7lo\u00b7se", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "doch dir, dem Abend und den Dichtern", "tokens": ["doch", "dir", ",", "dem", "A\u00b7bend", "und", "den", "Dich\u00b7tern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sind, unter rinnenden Gesichtern,", "tokens": ["sind", ",", "un\u00b7ter", "rin\u00b7nen\u00b7den", "Ge\u00b7sich\u00b7tern", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die dunkeln Dinge offenbar.", "tokens": ["die", "dun\u00b7keln", "Din\u00b7ge", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.77": {"line.1": {"text": "Die K\u00f6nige der Welt sind alt", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7ge", "der", "Welt", "sind", "alt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und werden keine Erben haben.", "tokens": ["und", "wer\u00b7den", "kei\u00b7ne", "Er\u00b7ben", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die S\u00f6hne sterben schon als Knaben,", "tokens": ["Die", "S\u00f6h\u00b7ne", "ster\u00b7ben", "schon", "als", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ihre bleichen T\u00f6chter gaben", "tokens": ["und", "ih\u00b7re", "blei\u00b7chen", "T\u00f6ch\u00b7ter", "ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die kranken Kronen der Gewalt.", "tokens": ["die", "kran\u00b7ken", "Kro\u00b7nen", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der P\u00f6bel bricht sie klein zu Geld,", "tokens": ["Der", "P\u00f6\u00b7bel", "bricht", "sie", "klein", "zu", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der zeitgem\u00e4\u00dfe Herr der Welt", "tokens": ["der", "zeit\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", "Herr", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dehnt sie im Feuer zu Maschinen,", "tokens": ["dehnt", "sie", "im", "Feu\u00b7er", "zu", "Ma\u00b7schi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die seinem Wollen grollend dienen;", "tokens": ["die", "sei\u00b7nem", "Wol\u00b7len", "grol\u00b7lend", "die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "aber das Gl\u00fcck ist nicht mit ihnen.", "tokens": ["a\u00b7ber", "das", "Gl\u00fcck", "ist", "nicht", "mit", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKNEG", "APPR", "PPER", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Das Erz hat Heimweh. Und verlassen", "tokens": ["Das", "Erz", "hat", "Heim\u00b7weh", ".", "Und", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "will es die M\u00fcnzen und die R\u00e4der,", "tokens": ["will", "es", "die", "M\u00fcn\u00b7zen", "und", "die", "R\u00e4\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "die es ein kleines Leben lehren.", "tokens": ["die", "es", "ein", "klei\u00b7nes", "Le\u00b7ben", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und aus Fabriken und aus Kassen", "tokens": ["Und", "aus", "Fab\u00b7ri\u00b7ken", "und", "aus", "Kas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "wird es zur\u00fcck in das Ge\u00e4der", "tokens": ["wird", "es", "zu\u00b7r\u00fcck", "in", "das", "Ge\u00b7\u00e4\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKVZ", "APPR", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "der aufgetanen Berge kehren,", "tokens": ["der", "auf\u00b7ge\u00b7ta\u00b7nen", "Ber\u00b7ge", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "die sich verschlie\u00dfen hinter ihm.", "tokens": ["die", "sich", "ver\u00b7schlie\u00b7\u00dfen", "hin\u00b7ter", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.78": {"line.1": {"text": "Alles wird wieder gro\u00df sein und gewaltig.", "tokens": ["Al\u00b7les", "wird", "wie\u00b7der", "gro\u00df", "sein", "und", "ge\u00b7wal\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "VAINF", "KON", "ADJD", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Die Lande einfach und die Wasser faltig,", "tokens": ["Die", "Lan\u00b7de", "ein\u00b7fach", "und", "die", "Was\u00b7ser", "fal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die B\u00e4ume riesig und sehr klein die Mauern;", "tokens": ["die", "B\u00e4u\u00b7me", "rie\u00b7sig", "und", "sehr", "klein", "die", "Mau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und in den T\u00e4lern, stark und vielgestaltig,", "tokens": ["und", "in", "den", "T\u00e4\u00b7lern", ",", "stark", "und", "viel\u00b7ge\u00b7stal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein Volk von Hirten und von Ackerbauern.", "tokens": ["ein", "Volk", "von", "Hir\u00b7ten", "und", "von", "A\u00b7cker\u00b7bau\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.79": {"line.1": {"text": "Und keine Kirchen, welche Gott umklammern", "tokens": ["Und", "kei\u00b7ne", "Kir\u00b7chen", ",", "wel\u00b7che", "Gott", "um\u00b7klam\u00b7mern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PWAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie einen Fl\u00fcchtling und ihn dann bejammern", "tokens": ["wie", "ei\u00b7nen", "Fl\u00fccht\u00b7ling", "und", "ihn", "dann", "be\u00b7jam\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KON", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie ein gefangenes und wundes Tier, \u2013", "tokens": ["wie", "ein", "ge\u00b7fan\u00b7ge\u00b7nes", "und", "wun\u00b7des", "Tier", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "ADJA", "KON", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die H\u00e4user gastlich allen Einla\u00dfklopfern", "tokens": ["die", "H\u00e4u\u00b7ser", "gast\u00b7lich", "al\u00b7len", "Ein\u00b7la\u00df\u00b7klop\u00b7fern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und ein Gef\u00fchl von unbegrenztem Opfern", "tokens": ["und", "ein", "Ge\u00b7f\u00fchl", "von", "un\u00b7be\u00b7grenz\u00b7tem", "Op\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "in allem Handeln und in dir und mir.", "tokens": ["in", "al\u00b7lem", "Han\u00b7deln", "und", "in", "dir", "und", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "APPR", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.80": {"line.1": {"text": "Kein Jenseitswarten und kein Schaun nach dr\u00fcben,", "tokens": ["Kein", "Jen\u00b7seits\u00b7war\u00b7ten", "und", "kein", "Schaun", "nach", "dr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "nur Sehnsucht, auch den Tod nicht zu entweihn", "tokens": ["nur", "Sehn\u00b7sucht", ",", "auch", "den", "Tod", "nicht", "zu", "ent\u00b7weihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "ADV", "ART", "NN", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und dienend sich am Irdischen zu \u00fcben,", "tokens": ["und", "die\u00b7nend", "sich", "am", "Ir\u00b7di\u00b7schen", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "um seinen H\u00e4nden nicht mehr neu zu sein.", "tokens": ["um", "sei\u00b7nen", "H\u00e4n\u00b7den", "nicht", "mehr", "neu", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.81": {"line.1": {"text": "Auch du wirst gro\u00df sein. Gr\u00f6\u00dfer noch als einer,", "tokens": ["Auch", "du", "wirst", "gro\u00df", "sein", ".", "Gr\u00f6\u00b7\u00dfer", "noch", "als", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADJD", "VAINF", "$.", "NN", "ADV", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der jetzt schon leben mu\u00df, dich sagen kann.", "tokens": ["der", "jetzt", "schon", "le\u00b7ben", "mu\u00df", ",", "dich", "sa\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VMFIN", "$,", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Viel ungew\u00f6hnlicher und ungemeiner", "tokens": ["Viel", "un\u00b7ge\u00b7w\u00f6hn\u00b7li\u00b7cher", "und", "un\u00b7ge\u00b7mei\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und noch viel \u00e4lter als ein alter Mann.", "tokens": ["und", "noch", "viel", "\u00e4l\u00b7ter", "als", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.82": {"line.1": {"text": "Man wird dich f\u00fchlen: da\u00df ein Duften ginge", "tokens": ["Man", "wird", "dich", "f\u00fch\u00b7len", ":", "da\u00df", "ein", "Duf\u00b7ten", "gin\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "VVFIN", "$.", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus eines Gartens naher Gegenwart;", "tokens": ["aus", "ei\u00b7nes", "Gar\u00b7tens", "na\u00b7her", "Ge\u00b7gen\u00b7wart", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wie ein Kranker seine liebsten Dinge", "tokens": ["und", "wie", "ein", "Kran\u00b7ker", "sei\u00b7ne", "liebs\u00b7ten", "Din\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wird man dich lieben ahnungsvoll und zart.", "tokens": ["wird", "man", "dich", "lie\u00b7ben", "ah\u00b7nungs\u00b7voll", "und", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "---+-+-+-+", "measure": "zehnsilber"}}, "stanza.83": {"line.1": {"text": "Es wird kein Beten geben, das die Leute", "tokens": ["Es", "wird", "kein", "Be\u00b7ten", "ge\u00b7ben", ",", "das", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVINF", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "zusammenschart. Du ", "tokens": ["zu\u00b7sam\u00b7men\u00b7schart", ".", "Du"], "token_info": ["word", "punct", "word"], "pos": ["VVPP", "$.", "PPER"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "und wer dich f\u00fchlte und sich an dir freute,", "tokens": ["und", "wer", "dich", "f\u00fchl\u00b7te", "und", "sich", "an", "dir", "freu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "KON", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wird wie der Einzige auf Erden sein:", "tokens": ["wird", "wie", "der", "Ein\u00b7zi\u00b7ge", "auf", "Er\u00b7den", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "APPR", "NN", "VAINF", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ein Ausgesto\u00dfener und ein Vereinter,", "tokens": ["Ein", "Aus\u00b7ge\u00b7sto\u00b7\u00dfe\u00b7ner", "und", "ein", "Ver\u00b7ein\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "gesammelt und vergeudet doch zugleich;", "tokens": ["ge\u00b7sam\u00b7melt", "und", "ver\u00b7geu\u00b7det", "doch", "zu\u00b7gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "ein L\u00e4chelnder und doch ein Halbverweinter,", "tokens": ["ein", "L\u00e4\u00b7cheln\u00b7der", "und", "doch", "ein", "Halb\u00b7ver\u00b7wein\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "klein wie ein Haus und m\u00e4chtig wie ein Reich.", "tokens": ["klein", "wie", "ein", "Haus", "und", "m\u00e4ch\u00b7tig", "wie", "ein", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "KON", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.84": {"line.1": {"text": "Es wird nicht Ruhe in den H\u00e4usern, sei's", "tokens": ["Es", "wird", "nicht", "Ru\u00b7he", "in", "den", "H\u00e4u\u00b7sern", ",", "sei's"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "APPR", "ART", "NN", "$,", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df einer stirbt und sie ihn weitertragen,", "tokens": ["da\u00df", "ei\u00b7ner", "stirbt", "und", "sie", "ihn", "wei\u00b7ter\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sei es da\u00df wer auf heimliches Gehei\u00df", "tokens": ["sei", "es", "da\u00df", "wer", "auf", "heim\u00b7li\u00b7ches", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "KOUS", "PWS", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "den Pilgerstock nimmt und den Pilgerkragen,", "tokens": ["den", "Pil\u00b7ger\u00b7stock", "nimmt", "und", "den", "Pil\u00b7ger\u00b7kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "um in der Fremde nach dem Weg zu fragen,", "tokens": ["um", "in", "der", "Frem\u00b7de", "nach", "dem", "Weg", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "auf welchem er dich warten wei\u00df.", "tokens": ["auf", "wel\u00b7chem", "er", "dich", "war\u00b7ten", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.85": {"line.1": {"text": "Die Stra\u00dfen werden derer niemals leer,", "tokens": ["Die", "Stra\u00b7\u00dfen", "wer\u00b7den", "de\u00b7rer", "nie\u00b7mals", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die zu dir wollen wie zu jener Rose,", "tokens": ["die", "zu", "dir", "wol\u00b7len", "wie", "zu", "je\u00b7ner", "Ro\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VMFIN", "KOKOM", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die alle tausend Jahre einmal bl\u00fcht.", "tokens": ["die", "al\u00b7le", "tau\u00b7send", "Jah\u00b7re", "ein\u00b7mal", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "CARD", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Viel dunkles Volk und beinah Namenlose,", "tokens": ["Viel", "dunk\u00b7les", "Volk", "und", "bei\u00b7nah", "Na\u00b7men\u00b7lo\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und wenn sie dich erreichen, sind sie m\u00fcd.", "tokens": ["und", "wenn", "sie", "dich", "er\u00b7rei\u00b7chen", ",", "sind", "sie", "m\u00fcd", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "$,", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.86": {"line.1": {"text": "Aber ich habe ihren Zug gesehn;", "tokens": ["A\u00b7ber", "ich", "ha\u00b7be", "ih\u00b7ren", "Zug", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "und glaube seither, da\u00df die Winde wehn", "tokens": ["und", "glau\u00b7be", "sei\u00b7ther", ",", "da\u00df", "die", "Win\u00b7de", "wehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "aus ihren M\u00e4nteln, welche sich bewegen,", "tokens": ["aus", "ih\u00b7ren", "M\u00e4n\u00b7teln", ",", "wel\u00b7che", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und stille sind wenn sie sich niederlegen \u2013:", "tokens": ["und", "stil\u00b7le", "sind", "wenn", "sie", "sich", "nie\u00b7der\u00b7le\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "VAFIN", "KOUS", "PPER", "PRF", "VVINF", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "so gro\u00df war in den Ebenen ihr Gehn.", "tokens": ["so", "gro\u00df", "war", "in", "den", "E\u00b7be\u00b7nen", "ihr", "Gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}}, "stanza.87": {"line.1": {"text": "So m\u00f6cht ich zu dir gehn: von fremden Schwellen", "tokens": ["So", "m\u00f6cht", "ich", "zu", "dir", "gehn", ":", "von", "frem\u00b7den", "Schwel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Almosen sammelnd, die mich ungern n\u00e4hren.", "tokens": ["Al\u00b7mo\u00b7sen", "sam\u00b7melnd", ",", "die", "mich", "un\u00b7gern", "n\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn der Wege wirrend viele w\u00e4ren,", "tokens": ["Und", "wenn", "der", "We\u00b7ge", "wir\u00b7rend", "vie\u00b7le", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VAFIN", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "so w\u00fcrd ich mich den \u00c4ltesten gesellen.", "tokens": ["so", "w\u00fcrd", "ich", "mich", "den", "\u00c4l\u00b7tes\u00b7ten", "ge\u00b7sel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich w\u00fcrde mich zu kleinen Greisen stellen,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mich", "zu", "klei\u00b7nen", "Grei\u00b7sen", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und wenn sie gingen, schaut ich wie im Traum,", "tokens": ["und", "wenn", "sie", "gin\u00b7gen", ",", "schaut", "ich", "wie", "im", "Traum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "da\u00df ihre Kniee aus der B\u00e4rte Wellen", "tokens": ["da\u00df", "ih\u00b7re", "Kni\u00b7ee", "aus", "der", "B\u00e4r\u00b7te", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "wie Inseln tauchen, ohne Strauch und Baum.", "tokens": ["wie", "In\u00b7seln", "tau\u00b7chen", ",", "oh\u00b7ne", "Strauch", "und", "Baum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "$,", "KOUI", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.88": {"line.1": {"text": "Wir \u00fcberholten M\u00e4nner, welche blind", "tokens": ["Wir", "\u00fc\u00b7berh\u00b7ol\u00b7ten", "M\u00e4n\u00b7ner", ",", "wel\u00b7che", "blind"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit ihren Knaben wie mit Augen schauen,", "tokens": ["mit", "ih\u00b7ren", "Kna\u00b7ben", "wie", "mit", "Au\u00b7gen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KOKOM", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und Trinkende am Flu\u00df und m\u00fcde Frauen", "tokens": ["und", "Trin\u00b7ken\u00b7de", "am", "Flu\u00df", "und", "m\u00fc\u00b7de", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPRART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und viele Frauen, welche schwanger sind.", "tokens": ["und", "vie\u00b7le", "Frau\u00b7en", ",", "wel\u00b7che", "schwan\u00b7ger", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und alle waren mir so seltsam nah, \u2013", "tokens": ["Und", "al\u00b7le", "wa\u00b7ren", "mir", "so", "selt\u00b7sam", "nah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "ADJD", "ADJD", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "als ob die M\u00e4nner einen Blutsverwandten,", "tokens": ["als", "ob", "die", "M\u00e4n\u00b7ner", "ei\u00b7nen", "Bluts\u00b7ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "die Frauen einen Freund in mir erkannten,", "tokens": ["die", "Frau\u00b7en", "ei\u00b7nen", "Freund", "in", "mir", "er\u00b7kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und auch die Hunde kamen, die ich sah.", "tokens": ["und", "auch", "die", "Hun\u00b7de", "ka\u00b7men", ",", "die", "ich", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.89": {"line.1": {"text": "Du Gott, ich m\u00f6chte viele Pilger sein,", "tokens": ["Du", "Gott", ",", "ich", "m\u00f6ch\u00b7te", "vie\u00b7le", "Pil\u00b7ger", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "VMFIN", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "um so, ein langer Zug, zu dir zu gehn,", "tokens": ["um", "so", ",", "ein", "lan\u00b7ger", "Zug", ",", "zu", "dir", "zu", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "ART", "ADJA", "NN", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und um ein gro\u00dfes St\u00fcck von dir zu sein:", "tokens": ["und", "um", "ein", "gro\u00b7\u00dfes", "St\u00fcck", "von", "dir", "zu", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du Garten mit den lebenden Alleen.", "tokens": ["du", "Gar\u00b7ten", "mit", "den", "le\u00b7ben\u00b7den", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.5": {"text": "Wenn ich so gehe wie ich bin, allein, \u2013", "tokens": ["Wenn", "ich", "so", "ge\u00b7he", "wie", "ich", "bin", ",", "al\u00b7lein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "VAFIN", "$,", "ADV", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wer merkt es denn? Wer ", "tokens": ["wer", "merkt", "es", "denn", "?", "Wer"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PWS"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Wen rei\u00dft es hin? Wen regt es auf, und wen", "tokens": ["Wen", "rei\u00dft", "es", "hin", "?", "Wen", "regt", "es", "auf", ",", "und", "wen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PWS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "bekehrt es dir?", "tokens": ["be\u00b7kehrt", "es", "dir", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Als w\u00e4re nichts geschehn,", "tokens": ["Als", "w\u00e4\u00b7re", "nichts", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "\u2013 lachen sie weiter. Und da bin ich froh,", "tokens": ["\u2013", "la\u00b7chen", "sie", "wei\u00b7ter", ".", "Und", "da", "bin", "ich", "froh", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKVZ", "$.", "KON", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "da\u00df ich so gehe wie ich bin; denn so", "tokens": ["da\u00df", "ich", "so", "ge\u00b7he", "wie", "ich", "bin", ";", "denn", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "VAFIN", "$.", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "kann keiner von den Lachenden mich sehn.", "tokens": ["kann", "kei\u00b7ner", "von", "den", "La\u00b7chen\u00b7den", "mich", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.90": {"line.1": {"text": "Bei Tag bist du das H\u00f6rensagen,", "tokens": ["Bei", "Tag", "bist", "du", "das", "H\u00f6\u00b7ren\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das fl\u00fcsternd um die Vielen flie\u00dft;", "tokens": ["das", "fl\u00fcs\u00b7ternd", "um", "die", "Vie\u00b7len", "flie\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVPP", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die Stille nach dem Stundenschlagen,", "tokens": ["die", "Stil\u00b7le", "nach", "dem", "Stun\u00b7den\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "welche sich langsam wieder schlie\u00dft.", "tokens": ["wel\u00b7che", "sich", "lang\u00b7sam", "wie\u00b7der", "schlie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADJD", "ADV", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.91": {"line.1": {"text": "Jemehr der Tag mit immer schw\u00e4chern", "tokens": ["Je\u00b7mehr", "der", "Tag", "mit", "im\u00b7mer", "schw\u00e4\u00b7chern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geb\u00e4rden sich nach Abend neigt,", "tokens": ["Ge\u00b7b\u00e4r\u00b7den", "sich", "nach", "A\u00b7bend", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "jemehr bist du, mein Gott. Es steigt", "tokens": ["je\u00b7mehr", "bist", "du", ",", "mein", "Gott", ".", "Es", "steigt"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dein Reich wie Rauch aus allen D\u00e4chern.", "tokens": ["dein", "Reich", "wie", "Rauch", "aus", "al\u00b7len", "D\u00e4\u00b7chern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.92": {"line.1": {"text": "Ein Pilgermorgen. Von den harten Lagern,", "tokens": ["Ein", "Pil\u00b7ger\u00b7mor\u00b7gen", ".", "Von", "den", "har\u00b7ten", "La\u00b7gern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auf das ein jeder wie vergiftet fiel,", "tokens": ["auf", "das", "ein", "je\u00b7der", "wie", "ver\u00b7gif\u00b7tet", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "PIAT", "KOKOM", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "erhebt sich bei dem ersten Glockenspiel", "tokens": ["er\u00b7hebt", "sich", "bei", "dem", "ers\u00b7ten", "Glo\u00b7cken\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ein Volk von hagern Morgensegen-Sagern,", "tokens": ["ein", "Volk", "von", "ha\u00b7gern", "Mor\u00b7gen\u00b7se\u00b7gen\u00b7Sa\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auf das die fr\u00fche Sonne niederbrennt:", "tokens": ["auf", "das", "die", "fr\u00fc\u00b7he", "Son\u00b7ne", "nie\u00b7der\u00b7brennt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.93": {"line.1": {"text": "B\u00e4rtige M\u00e4nner, welche sich verneigen,", "tokens": ["B\u00e4r\u00b7ti\u00b7ge", "M\u00e4n\u00b7ner", ",", "wel\u00b7che", "sich", "ver\u00b7nei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Kinder, die ernsthaft aus den Pelzen steigen,", "tokens": ["Kin\u00b7der", ",", "die", "ernst\u00b7haft", "aus", "den", "Pel\u00b7zen", "stei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und in den M\u00e4nteln, schwer von ihrem Schweigen,", "tokens": ["und", "in", "den", "M\u00e4n\u00b7teln", ",", "schwer", "von", "ih\u00b7rem", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die braunen Fraun von Tiflis und Taschkent.", "tokens": ["die", "brau\u00b7nen", "Fraun", "von", "Tif\u00b7lis", "und", "Taschkent", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Christen mit den Geb\u00e4rden des Islam", "tokens": ["Chris\u00b7ten", "mit", "den", "Ge\u00b7b\u00e4r\u00b7den", "des", "Is\u00b7lam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-++-+-+-+", "measure": "zehnsilber"}, "line.6": {"text": "sind um die Brunnen, halten ihre H\u00e4nde", "tokens": ["sind", "um", "die", "Brun\u00b7nen", ",", "hal\u00b7ten", "ih\u00b7re", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "wie flache Schalen hin, wie Gegenst\u00e4nde,", "tokens": ["wie", "fla\u00b7che", "Scha\u00b7len", "hin", ",", "wie", "Ge\u00b7gen\u00b7st\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "PTKVZ", "$,", "PWAV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "in die die Flut wie eine Seele kam.", "tokens": ["in", "die", "die", "Flut", "wie", "ei\u00b7ne", "See\u00b7le", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.94": {"line.1": {"text": "Sie neigen das Gesicht hinein und trinken,", "tokens": ["Sie", "nei\u00b7gen", "das", "Ge\u00b7sicht", "hin\u00b7ein", "und", "trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "rei\u00dfen die Kleider auf mit ihrer Linken", "tokens": ["rei\u00b7\u00dfen", "die", "Klei\u00b7der", "auf", "mit", "ih\u00b7rer", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und halten sich das Wasser an die Brust", "tokens": ["und", "hal\u00b7ten", "sich", "das", "Was\u00b7ser", "an", "die", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "als w\u00e4rs ein k\u00fchles weinendes Gesicht,", "tokens": ["als", "w\u00e4rs", "ein", "k\u00fch\u00b7les", "wei\u00b7nen\u00b7des", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das von den Schmerzen auf der Erde spricht.", "tokens": ["das", "von", "den", "Schmer\u00b7zen", "auf", "der", "Er\u00b7de", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.95": {"line.1": {"text": "Und diese Schmerzen stehen rings umher", "tokens": ["Und", "die\u00b7se", "Schmer\u00b7zen", "ste\u00b7hen", "rings", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit welken Augen; und du wei\u00dft nicht wer", "tokens": ["mit", "wel\u00b7ken", "Au\u00b7gen", ";", "und", "du", "wei\u00dft", "nicht", "wer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "$.", "KON", "PPER", "VVFIN", "PTKNEG", "PWS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sie sind und waren. Knechte oder Bauern,", "tokens": ["sie", "sind", "und", "wa\u00b7ren", ".", "Knech\u00b7te", "o\u00b7der", "Bau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VAFIN", "$.", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "vielleicht Kaufleute, welche Wohlstand sahn,", "tokens": ["viel\u00b7leicht", "Kauf\u00b7leu\u00b7te", ",", "wel\u00b7che", "Wohl\u00b7stand", "sahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PWAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "vielleicht auch laue M\u00f6nche, die nicht dauern,", "tokens": ["viel\u00b7leicht", "auch", "lau\u00b7e", "M\u00f6n\u00b7che", ",", "die", "nicht", "dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und Diebe, die auf die Versuchung lauern,", "tokens": ["und", "Die\u00b7be", ",", "die", "auf", "die", "Ver\u00b7su\u00b7chung", "lau\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "offene M\u00e4dchen, die verk\u00fcmmert kauern,", "tokens": ["of\u00b7fe\u00b7ne", "M\u00e4d\u00b7chen", ",", "die", "ver\u00b7k\u00fcm\u00b7mert", "kau\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "und Irrende in einem Wald von Wahn \u2013 :", "tokens": ["und", "Ir\u00b7ren\u00b7de", "in", "ei\u00b7nem", "Wald", "von", "Wahn", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPR", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "alle wie F\u00fcrsten, die in tiefem Trauern", "tokens": ["al\u00b7le", "wie", "F\u00fcrs\u00b7ten", ",", "die", "in", "tie\u00b7fem", "Trau\u00b7ern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "die \u00dcberfl\u00fcsse von sich abgetan.", "tokens": ["die", "\u00dc\u00b7berf\u00b7l\u00fcs\u00b7se", "von", "sich", "ab\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wie Weise alle, welche viel erfahren,", "tokens": ["Wie", "Wei\u00b7se", "al\u00b7le", ",", "wel\u00b7che", "viel", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PIS", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Erw\u00e4hlte, welche in der W\u00fcste waren,", "tokens": ["Er\u00b7w\u00e4hl\u00b7te", ",", "wel\u00b7che", "in", "der", "W\u00fcs\u00b7te", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "wo Gott sie n\u00e4hrte durch ein fremdes Tier;", "tokens": ["wo", "Gott", "sie", "n\u00e4hr\u00b7te", "durch", "ein", "frem\u00b7des", "Tier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Einsame, die durch Ebenen gegangen", "tokens": ["Ein\u00b7sa\u00b7me", ",", "die", "durch", "E\u00b7be\u00b7nen", "ge\u00b7gan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "VVPP"], "meter": "+----+---+-", "measure": "dactylic.init"}, "line.15": {"text": "mit vielen Winden an den dunklen Wangen,", "tokens": ["mit", "vie\u00b7len", "Win\u00b7den", "an", "den", "dunk\u00b7len", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "von einer Sehnsucht f\u00fcrchtig und befangen", "tokens": ["von", "ei\u00b7ner", "Sehn\u00b7sucht", "f\u00fcrch\u00b7tig", "und", "be\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und doch so wundersam erh\u00f6ht von ihr.", "tokens": ["und", "doch", "so", "wun\u00b7der\u00b7sam", "er\u00b7h\u00f6ht", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVPP", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Gel\u00f6ste aus dem Alltag, eingeschaltet", "tokens": ["Ge\u00b7l\u00f6s\u00b7te", "aus", "dem", "All\u00b7tag", ",", "ein\u00b7ge\u00b7schal\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "in gro\u00dfe Orgeln und in Chorgesang,", "tokens": ["in", "gro\u00b7\u00dfe", "Or\u00b7geln", "und", "in", "Chor\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "und Knieende, wie Steigende gestaltet;", "tokens": ["und", "Kni\u00b7e\u00b7en\u00b7de", ",", "wie", "Stei\u00b7gen\u00b7de", "ge\u00b7stal\u00b7tet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Fahnen mit Bildern, welche lang", "tokens": ["Fah\u00b7nen", "mit", "Bil\u00b7dern", ",", "wel\u00b7che", "lang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "PRELS", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.22": {"text": "verborgen waren und zusammgefaltet:", "tokens": ["ver\u00b7bor\u00b7gen", "wa\u00b7ren", "und", "zu\u00b7samm\u00b7ge\u00b7fal\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.96": {"line.1": {"text": "Jetzt h\u00e4ngen sie sich langsam wieder aus.", "tokens": ["Jetzt", "h\u00e4n\u00b7gen", "sie", "sich", "lang\u00b7sam", "wie\u00b7der", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.97": {"line.1": {"text": "Und manche stehn und schaun nach einem Haus,", "tokens": ["Und", "man\u00b7che", "stehn", "und", "schaun", "nach", "ei\u00b7nem", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVINF", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "darin die Pilger, welche krank sind, wohnen;", "tokens": ["da\u00b7rin", "die", "Pil\u00b7ger", ",", "wel\u00b7che", "krank", "sind", ",", "woh\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "denn eben wand sich dort ein M\u00f6nch heraus,", "tokens": ["denn", "e\u00b7ben", "wand", "sich", "dort", "ein", "M\u00f6nch", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Haare schlaff und die Sutane kraus,", "tokens": ["die", "Haa\u00b7re", "schlaff", "und", "die", "Su\u00b7ta\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das schattige Gesicht voll kranker Blaus", "tokens": ["das", "schat\u00b7ti\u00b7ge", "Ge\u00b7sicht", "voll", "kran\u00b7ker", "Blaus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und ganz verdunkelt von D\u00e4monen.", "tokens": ["und", "ganz", "ver\u00b7dun\u00b7kelt", "von", "D\u00e4\u00b7mo\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.98": {"line.1": {"text": "Er neigte sich, als br\u00e4ch er sich entzwei,", "tokens": ["Er", "neig\u00b7te", "sich", ",", "als", "br\u00e4ch", "er", "sich", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "KOUS", "NN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und warf sich in zwei St\u00fccken auf die Erde,", "tokens": ["und", "warf", "sich", "in", "zwei", "St\u00fc\u00b7cken", "auf", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die jetzt an seinem Munde wie ein Schrei", "tokens": ["die", "jetzt", "an", "sei\u00b7nem", "Mun\u00b7de", "wie", "ein", "Schrei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "zu h\u00e4ngen schien und so als sei", "tokens": ["zu", "h\u00e4n\u00b7gen", "schien", "und", "so", "als", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "KON", "ADV", "KOKOM", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sie seiner Arme wachsende Geb\u00e4rde.", "tokens": ["sie", "sei\u00b7ner", "Ar\u00b7me", "wach\u00b7sen\u00b7de", "Ge\u00b7b\u00e4r\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.99": {"line.1": {"text": "Und langsam ging sein Fall an ihm vorbei.", "tokens": ["Und", "lang\u00b7sam", "ging", "sein", "Fall", "an", "ihm", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er flog empor, als ob er Fl\u00fcgel sp\u00fcrte,", "tokens": ["Er", "flog", "em\u00b7por", ",", "als", "ob", "er", "Fl\u00fc\u00b7gel", "sp\u00fcr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und sein erleichtertes Gef\u00fchl verf\u00fchrte", "tokens": ["und", "sein", "er\u00b7leich\u00b7ter\u00b7tes", "Ge\u00b7f\u00fchl", "ver\u00b7f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ihn zu dem Glauben seiner Vogelwerdung.", "tokens": ["ihn", "zu", "dem", "Glau\u00b7ben", "sei\u00b7ner", "Vo\u00b7gel\u00b7wer\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er hing in seinen magern Armen schmal,", "tokens": ["Er", "hing", "in", "sei\u00b7nen", "ma\u00b7gern", "Ar\u00b7men", "schmal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wie eine schiefgeschobne Marionette,", "tokens": ["wie", "ei\u00b7ne", "schief\u00b7ge\u00b7schob\u00b7ne", "Ma\u00b7ri\u00b7o\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "und glaubte, da\u00df er gro\u00dfe Schwingen h\u00e4tte", "tokens": ["und", "glaub\u00b7te", ",", "da\u00df", "er", "gro\u00b7\u00dfe", "Schwin\u00b7gen", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und da\u00df die Welt schon lange wie ein Tal", "tokens": ["und", "da\u00df", "die", "Welt", "schon", "lan\u00b7ge", "wie", "ein", "Tal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ADV", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sich ferne unter seinen F\u00fc\u00dfen gl\u00e4tte.", "tokens": ["sich", "fer\u00b7ne", "un\u00b7ter", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "gl\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ungl\u00e4ubig sah er sich mit einem Mal", "tokens": ["Un\u00b7gl\u00e4u\u00b7big", "sah", "er", "sich", "mit", "ei\u00b7nem", "Mal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.11": {"text": "herabgelassen auf die fremde St\u00e4tte", "tokens": ["her\u00b7ab\u00b7ge\u00b7las\u00b7sen", "auf", "die", "frem\u00b7de", "St\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "und auf den gr\u00fcnen Meergrund seiner Qual.", "tokens": ["und", "auf", "den", "gr\u00fc\u00b7nen", "Meer\u00b7grund", "sei\u00b7ner", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und war ein Fisch und wand sich schlank und schwamm", "tokens": ["Und", "war", "ein", "Fisch", "und", "wand", "sich", "schlank", "und", "schwamm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "KON", "VVFIN", "PRF", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "durch tiefes Wasser, still und silbergrau,", "tokens": ["durch", "tie\u00b7fes", "Was\u00b7ser", ",", "still", "und", "sil\u00b7ber\u00b7grau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "sah Quallen hangen am Korallenstamm", "tokens": ["sah", "Qual\u00b7len", "han\u00b7gen", "am", "Ko\u00b7ral\u00b7len\u00b7stamm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "und sah die Haare einer Meerjungfrau,", "tokens": ["und", "sah", "die", "Haa\u00b7re", "ei\u00b7ner", "Meer\u00b7jung\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "durch die das Wasser rauschte wie ein Kamm.", "tokens": ["durch", "die", "das", "Was\u00b7ser", "rauschte", "wie", "ein", "Kamm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Und kam zu Land und war ein Br\u00e4utigam", "tokens": ["Und", "kam", "zu", "Land", "und", "war", "ein", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "VAFIN", "ART", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "bei einer Toten, wie man ihn erw\u00e4hlt", "tokens": ["bei", "ei\u00b7ner", "To\u00b7ten", ",", "wie", "man", "ihn", "er\u00b7w\u00e4hlt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "damit kein M\u00e4dchen fremd und unverm\u00e4hlt", "tokens": ["da\u00b7mit", "kein", "M\u00e4d\u00b7chen", "fremd", "und", "un\u00b7ver\u00b7m\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PIAT", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "des Paradieses Wiesenland beschritte.", "tokens": ["des", "Pa\u00b7ra\u00b7die\u00b7ses", "Wie\u00b7sen\u00b7land", "be\u00b7schrit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.100": {"line.1": {"text": "Er folgte ihr und ordnete die Tritte", "tokens": ["Er", "folg\u00b7te", "ihr", "und", "ord\u00b7ne\u00b7te", "die", "Trit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und tanzte rund, sie immer in der Mitte,", "tokens": ["und", "tanz\u00b7te", "rund", ",", "sie", "im\u00b7mer", "in", "der", "Mit\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und seine Arme tanzten rund um ihn.", "tokens": ["und", "sei\u00b7ne", "Ar\u00b7me", "tanz\u00b7ten", "rund", "um", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dann horchte er, als w\u00e4re eine dritte", "tokens": ["Dann", "horch\u00b7te", "er", ",", "als", "w\u00e4\u00b7re", "ei\u00b7ne", "drit\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOKOM", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gestalt ganz sachte in das Spiel getreten,", "tokens": ["Ge\u00b7stalt", "ganz", "sach\u00b7te", "in", "das", "Spiel", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die diesem Tanzen nicht zu glauben schien.", "tokens": ["die", "die\u00b7sem", "Tan\u00b7zen", "nicht", "zu", "glau\u00b7ben", "schien", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und da erkannte er: jetzt mu\u00dft du beten;", "tokens": ["Und", "da", "er\u00b7kann\u00b7te", "er", ":", "jetzt", "mu\u00dft", "du", "be\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "denn dieser ist es, welcher den Propheten", "tokens": ["denn", "die\u00b7ser", "ist", "es", ",", "wel\u00b7cher", "den", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "wie eine gro\u00dfe Krone sich verliehn.", "tokens": ["wie", "ei\u00b7ne", "gro\u00b7\u00dfe", "Kro\u00b7ne", "sich", "ver\u00b7liehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wir halten ihn, um den wir t\u00e4glich flehten,", "tokens": ["Wir", "hal\u00b7ten", "ihn", ",", "um", "den", "wir", "t\u00e4g\u00b7lich", "fleh\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUI", "ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "wir ernten ihn, den einstens Ausges\u00e4eten,", "tokens": ["wir", "ern\u00b7ten", "ihn", ",", "den", "eins\u00b7tens", "Aus\u00b7ge\u00b7s\u00e4e\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "und kehren heim mit ruhenden Ger\u00e4ten", "tokens": ["und", "keh\u00b7ren", "heim", "mit", "ru\u00b7hen\u00b7den", "Ge\u00b7r\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "in langen Reihen wie in Melodien.", "tokens": ["in", "lan\u00b7gen", "Rei\u00b7hen", "wie", "in", "Me\u00b7lo\u00b7dien", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und er verneigte sich ergriffen, tief.", "tokens": ["Und", "er", "ver\u00b7neig\u00b7te", "sich", "er\u00b7grif\u00b7fen", ",", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "VVPP", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Aber der Alte war, als ob er schliefe,", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "war", ",", "als", "ob", "er", "schlie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.16": {"text": "und sah es nicht, obwohl sein Aug nicht schlief.", "tokens": ["und", "sah", "es", "nicht", ",", "ob\u00b7wohl", "sein", "Aug", "nicht", "schlief", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.101": {"line.1": {"text": "Und er verneigte sich in solche Tiefe,", "tokens": ["Und", "er", "ver\u00b7neig\u00b7te", "sich", "in", "sol\u00b7che", "Tie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df ihm ein Zittern durch die Glieder lief.", "tokens": ["da\u00df", "ihm", "ein", "Zit\u00b7tern", "durch", "die", "Glie\u00b7der", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aber der Alte ward es nicht gewahr.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "ward", "es", "nicht", "ge\u00b7wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.102": {"line.1": {"text": "Da fa\u00dfte sich der kranke M\u00f6nch am Haar", "tokens": ["Da", "fa\u00df\u00b7te", "sich", "der", "kran\u00b7ke", "M\u00f6nch", "am", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und schlug sich wie ein Kleid an einen Baum.", "tokens": ["und", "schlug", "sich", "wie", "ein", "Kleid", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aber der Alte stand und sah es kaum.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "stand", "und", "sah", "es", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.103": {"line.1": {"text": "Da nahm der kranke M\u00f6nch sich in die H\u00e4nde", "tokens": ["Da", "nahm", "der", "kran\u00b7ke", "M\u00f6nch", "sich", "in", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie man ein Richtschwert in die H\u00e4nde nimmt,", "tokens": ["wie", "man", "ein", "Richt\u00b7schwert", "in", "die", "H\u00e4n\u00b7de", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hieb und hieb, verwundete die W\u00e4nde", "tokens": ["und", "hieb", "und", "hieb", ",", "ver\u00b7wun\u00b7de\u00b7te", "die", "W\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und stie\u00df sich endlich in den Grund ergrimmt.", "tokens": ["und", "stie\u00df", "sich", "end\u00b7lich", "in", "den", "Grund", "er\u00b7grimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Aber der Alte blickte unbestimmt.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "blick\u00b7te", "un\u00b7be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.104": {"line.1": {"text": "Da ri\u00df der M\u00f6nch sein Kleid sich ab wie Rinde", "tokens": ["Da", "ri\u00df", "der", "M\u00f6nch", "sein", "Kleid", "sich", "ab", "wie", "Rin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "PRF", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und knieend hielt er es dem Alten hin.", "tokens": ["und", "kni\u00b7e\u00b7end", "hielt", "er", "es", "dem", "Al\u00b7ten", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.105": {"line.1": {"text": "Und sieh: er kam. Kam wie zu einem Kinde", "tokens": ["Und", "sieh", ":", "er", "kam", ".", "Kam", "wie", "zu", "ei\u00b7nem", "Kin\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PPER", "VVFIN", "$.", "NE", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sagte sanft: Wei\u00dft du auch ", "tokens": ["und", "sag\u00b7te", "sanft", ":", "Wei\u00dft", "du", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$.", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das wu\u00dfte er. Und legte sich gelinde", "tokens": ["Das", "wu\u00df\u00b7te", "er", ".", "Und", "leg\u00b7te", "sich", "ge\u00b7lin\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "$.", "KON", "VVFIN", "PRF", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dem Greis wie eine Geige unters Kinn.", "tokens": ["dem", "Greis", "wie", "ei\u00b7ne", "Gei\u00b7ge", "un\u00b7ters", "Kinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.106": {"line.1": {"text": "Jetzt reifen schon die roten Berberitzen,", "tokens": ["Jetzt", "rei\u00b7fen", "schon", "die", "ro\u00b7ten", "Ber\u00b7be\u00b7rit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "alternde Astern atmen schwach im Beet.", "tokens": ["al\u00b7tern\u00b7de", "As\u00b7tern", "at\u00b7men", "schwach", "im", "Beet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wer jetzt nicht reich ist, da der Sommer geht,", "tokens": ["Wer", "jetzt", "nicht", "reich", "ist", ",", "da", "der", "Som\u00b7mer", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "wird immer warten und sich nie besitzen.", "tokens": ["wird", "im\u00b7mer", "war\u00b7ten", "und", "sich", "nie", "be\u00b7sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVINF", "KON", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.107": {"line.1": {"text": "Wer jetzt nicht seine Augen schlie\u00dfen kann,", "tokens": ["Wer", "jetzt", "nicht", "sei\u00b7ne", "Au\u00b7gen", "schlie\u00b7\u00dfen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "gewi\u00df, da\u00df eine F\u00fclle von Gesichten", "tokens": ["ge\u00b7wi\u00df", ",", "da\u00df", "ei\u00b7ne", "F\u00fcl\u00b7le", "von", "Ge\u00b7sich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "in ihm nur wartet bis die Nacht begann,", "tokens": ["in", "ihm", "nur", "war\u00b7tet", "bis", "die", "Nacht", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "um sich in seinem Dunkel aufzurichten: \u2013", "tokens": ["um", "sich", "in", "sei\u00b7nem", "Dun\u00b7kel", "auf\u00b7zu\u00b7rich\u00b7ten", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PRF", "APPR", "PPOSAT", "NN", "VVIZU", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "der ist vergangen wie ein alter Mann.", "tokens": ["der", "ist", "ver\u00b7gan\u00b7gen", "wie", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "VVPP", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.108": {"line.1": {"text": "Dem kommt nichts mehr, dem st\u00f6\u00dft kein Tag mehr zu,", "tokens": ["Dem", "kommt", "nichts", "mehr", ",", "dem", "st\u00f6\u00dft", "kein", "Tag", "mehr", "zu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "$,", "PRELS", "VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und alles l\u00fcgt ihn an, was ihm geschieht;", "tokens": ["und", "al\u00b7les", "l\u00fcgt", "ihn", "an", ",", "was", "ihm", "ge\u00b7schieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "auch du, mein Gott. Und wie ein Stein bist du,", "tokens": ["auch", "du", ",", "mein", "Gott", ".", "Und", "wie", "ein", "Stein", "bist", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$.", "KON", "PWAV", "ART", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "welcher ihn t\u00e4glich in die Tiefe zieht.", "tokens": ["wel\u00b7cher", "ihn", "t\u00e4g\u00b7lich", "in", "die", "Tie\u00b7fe", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.109": {"line.1": {"text": "Du mu\u00dft nicht bangen, Gott. Sie sagen: ", "tokens": ["Du", "mu\u00dft", "nicht", "ban\u00b7gen", ",", "Gott", ".", "Sie", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "NN", "$.", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zu allen Dingen, die geduldig sind.", "tokens": ["zu", "al\u00b7len", "Din\u00b7gen", ",", "die", "ge\u00b7dul\u00b7dig", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sind wie Wind, der an die Zweige streift", "tokens": ["Sie", "sind", "wie", "Wind", ",", "der", "an", "die", "Zwei\u00b7ge", "streift"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und sagt: ", "tokens": ["und", "sagt", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.110": {"line.1": {"text": "Sie merken kaum,", "tokens": ["Sie", "mer\u00b7ken", "kaum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "wie alles gl\u00fcht, was ihre Hand ergreift, \u2013", "tokens": ["wie", "al\u00b7les", "gl\u00fcht", ",", "was", "ih\u00b7re", "Hand", "er\u00b7greift", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie's auch an seinem letzten Saum", "tokens": ["so", "da\u00df", "sie's", "auch", "an", "sei\u00b7nem", "letz\u00b7ten", "Saum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "nicht halten k\u00f6nnten ohne zu verbrennen.", "tokens": ["nicht", "hal\u00b7ten", "k\u00f6nn\u00b7ten", "oh\u00b7ne", "zu", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.111": {"line.1": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "den F\u00fcrsten Freund nennt im Gespr\u00e4ch mit Bauern,", "tokens": ["den", "F\u00fcrs\u00b7ten", "Freund", "nennt", "im", "Ge\u00b7spr\u00e4ch", "mit", "Bau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wenn dieser F\u00fcrst sehr gro\u00df ist und \u2013 sehr fern.", "tokens": ["wenn", "die\u00b7ser", "F\u00fcrst", "sehr", "gro\u00df", "ist", "und", "\u2013", "sehr", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "ADJD", "VAFIN", "KON", "$(", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "und kennen gar nicht ihres Hauses Herrn.", "tokens": ["und", "ken\u00b7nen", "gar", "nicht", "ih\u00b7res", "Hau\u00b7ses", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "wenn jedes Ding sich schlie\u00dft, dem sie sich nahn,", "tokens": ["wenn", "je\u00b7des", "Ding", "sich", "schlie\u00dft", ",", "dem", "sie", "sich", "nahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "VVFIN", "$,", "PRELS", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "so wie ein abgeschmackter Charlatan", "tokens": ["so", "wie", "ein", "ab\u00b7ge\u00b7schmack\u00b7ter", "Char\u00b7la\u00b7tan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "vielleicht die Sonne sein nennt und den Blitz.", "tokens": ["viel\u00b7leicht", "die", "Son\u00b7ne", "sein", "nennt", "und", "den", "Blitz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAINF", "VVFIN", "KON", "ART", "NN", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "So sagen sie: mein Leben, meine Frau,", "tokens": ["So", "sa\u00b7gen", "sie", ":", "mein", "Le\u00b7ben", ",", "mei\u00b7ne", "Frau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "mein Hund, mein Kind, und wissen doch genau,", "tokens": ["mein", "Hund", ",", "mein", "Kind", ",", "und", "wis\u00b7sen", "doch", "ge\u00b7nau", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "da\u00df alles: Leben, Frau und Hund und Kind", "tokens": ["da\u00df", "al\u00b7les", ":", "Le\u00b7ben", ",", "Frau", "und", "Hund", "und", "Kind"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "$.", "NN", "$,", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "fremde Gebilde sind, daran sie blind", "tokens": ["frem\u00b7de", "Ge\u00b7bil\u00b7de", "sind", ",", "da\u00b7ran", "sie", "blind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$,", "PAV", "PPER", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.14": {"text": "mit ihren ausgestreckten H\u00e4nden sto\u00dfen.", "tokens": ["mit", "ih\u00b7ren", "aus\u00b7ge\u00b7streck\u00b7ten", "H\u00e4n\u00b7den", "sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Gewi\u00dfheit freilich ist das nur den Gro\u00dfen,", "tokens": ["Ge\u00b7wi\u00df\u00b7heit", "frei\u00b7lich", "ist", "das", "nur", "den", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PDS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "die sich nach Augen sehnen. Denn die Andern", "tokens": ["die", "sich", "nach", "Au\u00b7gen", "seh\u00b7nen", ".", "Denn", "die", "An\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRELS", "PRF", "APPR", "NN", "VVINF", "$.", "KON", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "mit keinem Dinge rings zusammenh\u00e4ngt,", "tokens": ["mit", "kei\u00b7nem", "Din\u00b7ge", "rings", "zu\u00b7sam\u00b7men\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "da\u00df sie, von ihrer Habe fortgedr\u00e4ngt,", "tokens": ["da\u00df", "sie", ",", "von", "ih\u00b7rer", "Ha\u00b7be", "fort\u00b7ge\u00b7dr\u00e4ngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "nicht anerkannt von ihrem Eigentume", "tokens": ["nicht", "an\u00b7er\u00b7kannt", "von", "ih\u00b7rem", "Ei\u00b7gen\u00b7tu\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "das Weib so wenig ", "tokens": ["das", "Weib", "so", "we\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PIS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "die eines fremden Lebens ist f\u00fcr alle.", "tokens": ["die", "ei\u00b7nes", "frem\u00b7den", "Le\u00b7bens", "ist", "f\u00fcr", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.112": {"line.1": {"text": "Falle nicht, Gott, aus deinem Gleichgewicht.", "tokens": ["Fal\u00b7le", "nicht", ",", "Gott", ",", "aus", "dei\u00b7nem", "Gleich\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Auch der dich liebt und der dein Angesicht", "tokens": ["Auch", "der", "dich", "liebt", "und", "der", "dein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PPER", "VVFIN", "KON", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "erkennt im Dunkel, wenn er wie ein Licht", "tokens": ["er\u00b7kennt", "im", "Dun\u00b7kel", ",", "wenn", "er", "wie", "ein", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "$,", "KOUS", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "in deinem Atem schwankt, \u2013 besitzt dich nicht.", "tokens": ["in", "dei\u00b7nem", "A\u00b7tem", "schwankt", ",", "\u2013", "be\u00b7sitzt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "$(", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und wenn dich einer in der Nacht erfa\u00dft,", "tokens": ["Und", "wenn", "dich", "ei\u00b7ner", "in", "der", "Nacht", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "so da\u00df du kommen mu\u00dft in sein Gebet:", "tokens": ["so", "da\u00df", "du", "kom\u00b7men", "mu\u00dft", "in", "sein", "Ge\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.113": {"line.1": {"text": "Wer kann dich halten, Gott? Denn du bist dein,", "tokens": ["Wer", "kann", "dich", "hal\u00b7ten", ",", "Gott", "?", "Denn", "du", "bist", "dein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "VVINF", "$,", "NN", "$.", "KON", "PPER", "VAFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "von keines Eigent\u00fcmers Hand gest\u00f6rt,", "tokens": ["von", "kei\u00b7nes", "Ei\u00b7gen\u00b7t\u00fc\u00b7mers", "Hand", "ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so wie der noch nicht ausgereifte Wein,", "tokens": ["so", "wie", "der", "noch", "nicht", "aus\u00b7ge\u00b7reif\u00b7te", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADV", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der immer s\u00fc\u00dfer wird, sich selbst geh\u00f6rt.", "tokens": ["der", "im\u00b7mer", "s\u00fc\u00b7\u00dfer", "wird", ",", "sich", "selbst", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$,", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.114": {"line.1": {"text": "In tiefen N\u00e4chten grab ich dich, du Schatz.", "tokens": ["In", "tie\u00b7fen", "N\u00e4ch\u00b7ten", "grab", "ich", "dich", ",", "du", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn alle \u00dcberfl\u00fcsse, die ich sah,", "tokens": ["Denn", "al\u00b7le", "\u00dc\u00b7berf\u00b7l\u00fcs\u00b7se", ",", "die", "ich", "sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sind Armut und arms\u00e4liger Ersatz", "tokens": ["sind", "Ar\u00b7mut", "und", "arm\u00b7s\u00e4\u00b7li\u00b7ger", "Er\u00b7satz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "ADJA", "NN"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "f\u00fcr deine Sch\u00f6nheit, die noch nie geschah.", "tokens": ["f\u00fcr", "dei\u00b7ne", "Sch\u00f6n\u00b7heit", ",", "die", "noch", "nie", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.115": {"line.1": {"text": "Aber der Weg zu dir ist furchtbar weit", "tokens": ["A\u00b7ber", "der", "Weg", "zu", "dir", "ist", "furcht\u00b7bar", "weit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VAFIN", "ADJD", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "und, weil ihn lange keiner ging, verweht.", "tokens": ["und", ",", "weil", "ihn", "lan\u00b7ge", "kei\u00b7ner", "ging", ",", "ver\u00b7weht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O du bist einsam. Du bist Einsamkeit,", "tokens": ["O", "du", "bist", "ein\u00b7sam", ".", "Du", "bist", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du Herz, das zu entfernten Talen geht.", "tokens": ["du", "Herz", ",", "das", "zu", "ent\u00b7fern\u00b7ten", "Ta\u00b7len", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.116": {"line.1": {"text": "Und meine H\u00e4nde, welche blutig sind", "tokens": ["Und", "mei\u00b7ne", "H\u00e4n\u00b7de", ",", "wel\u00b7che", "blu\u00b7tig", "sind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "vom Graben, heb ich offen in den Wind,", "tokens": ["vom", "Gra\u00b7ben", ",", "heb", "ich", "of\u00b7fen", "in", "den", "Wind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie sich verzweigen wie ein Baum.", "tokens": ["so", "da\u00df", "sie", "sich", "ver\u00b7zwei\u00b7gen", "wie", "ein", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "VVINF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich sauge dich mit ihnen aus dem Raum", "tokens": ["Ich", "sau\u00b7ge", "dich", "mit", "ih\u00b7nen", "aus", "dem", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "als h\u00e4ttest du dich einmal dort zerschellt", "tokens": ["als", "h\u00e4t\u00b7test", "du", "dich", "ein\u00b7mal", "dort", "zer\u00b7schellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "VAFIN", "PPER", "PRF", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "in einer ungeduldigen Geb\u00e4rde,", "tokens": ["in", "ei\u00b7ner", "un\u00b7ge\u00b7dul\u00b7di\u00b7gen", "Ge\u00b7b\u00e4r\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und fielest jetzt, eine zerst\u00e4ubte Welt,", "tokens": ["und", "fie\u00b7lest", "jetzt", ",", "ei\u00b7ne", "zer\u00b7st\u00e4ub\u00b7te", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "aus fernen Sternen wieder auf die Erde", "tokens": ["aus", "fer\u00b7nen", "Ster\u00b7nen", "wie\u00b7der", "auf", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "sanft wie ein Fr\u00fchlingsregen f\u00e4llt.", "tokens": ["sanft", "wie", "ein", "Fr\u00fch\u00b7lings\u00b7re\u00b7gen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.117": {"line.1": {"text": "Dich wundert nicht des Sturmes Wucht, \u2013", "tokens": ["Dich", "wun\u00b7dert", "nicht", "des", "Stur\u00b7mes", "Wucht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "du hast ihn wachsen sehn; \u2013", "tokens": ["du", "hast", "ihn", "wach\u00b7sen", "sehn", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVINF", "VVINF", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "die B\u00e4ume fl\u00fcchten. Ihre Flucht", "tokens": ["die", "B\u00e4u\u00b7me", "fl\u00fcch\u00b7ten", ".", "Ih\u00b7re", "Flucht"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "schafft schreitende Alleen.", "tokens": ["schafft", "schrei\u00b7ten\u00b7de", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Da wei\u00dft du, der vor dem sie fliehn", "tokens": ["Da", "wei\u00dft", "du", ",", "der", "vor", "dem", "sie", "fliehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PRELS", "APPR", "PRELS", "PPER", "VVINF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "ist der, zu dem du gehst,", "tokens": ["ist", "der", ",", "zu", "dem", "du", "gehst", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.7": {"text": "und deine Sinne singen ihn,", "tokens": ["und", "dei\u00b7ne", "Sin\u00b7ne", "sin\u00b7gen", "ihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "wenn du am Fenster stehst.", "tokens": ["wenn", "du", "am", "Fens\u00b7ter", "stehst", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.118": {"line.1": {"text": "Des Sommers Wochen standen still,", "tokens": ["Des", "Som\u00b7mers", "Wo\u00b7chen", "stan\u00b7den", "still", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "es stieg der B\u00e4ume Blut;", "tokens": ["es", "stieg", "der", "B\u00e4u\u00b7me", "Blut", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "jetzt f\u00fchlst du, da\u00df es fallen will", "tokens": ["jetzt", "f\u00fchlst", "du", ",", "da\u00df", "es", "fal\u00b7len", "will"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "in den der Alles tut.", "tokens": ["in", "den", "der", "Al\u00b7les", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "PIS", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Du glaubtest schon erkannt die Kraft,", "tokens": ["Du", "glaub\u00b7test", "schon", "er\u00b7kannt", "die", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "VVPP", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "als du die Frucht erfa\u00dft,", "tokens": ["als", "du", "die", "Frucht", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "jetzt wird sie wieder r\u00e4tselhaft,", "tokens": ["jetzt", "wird", "sie", "wie\u00b7der", "r\u00e4t\u00b7sel\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "und du bist wieder Gast.", "tokens": ["und", "du", "bist", "wie\u00b7der", "Gast", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.119": {"line.1": {"text": "Der Sommer war so wie dein Haus,", "tokens": ["Der", "Som\u00b7mer", "war", "so", "wie", "dein", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "KOKOM", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "drin wei\u00dft du alles stehn \u2013", "tokens": ["drin", "wei\u00dft", "du", "al\u00b7les", "stehn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "VVINF", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "jetzt mu\u00dft du in dein Herz hinaus", "tokens": ["jetzt", "mu\u00dft", "du", "in", "dein", "Herz", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPOSAT", "NN", "APZR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "wie in die Ebene gehn.", "tokens": ["wie", "in", "die", "E\u00b7be\u00b7ne", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Die gro\u00dfe Einsamkeit beginnt,", "tokens": ["Die", "gro\u00b7\u00dfe", "Ein\u00b7sam\u00b7keit", "be\u00b7ginnt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "die Tage werden taub,", "tokens": ["die", "Ta\u00b7ge", "wer\u00b7den", "taub", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "aus deinen Sinnen nimmt der Wind", "tokens": ["aus", "dei\u00b7nen", "Sin\u00b7nen", "nimmt", "der", "Wind"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "die Welt wie welkes Laub.", "tokens": ["die", "Welt", "wie", "wel\u00b7kes", "Laub", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "PWAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.120": {"line.1": {"text": "Durch ihre leeren Zweige sieht", "tokens": ["Durch", "ih\u00b7re", "lee\u00b7ren", "Zwei\u00b7ge", "sieht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der Himmel, den du hast;", "tokens": ["der", "Him\u00b7mel", ",", "den", "du", "hast", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "sei Erde jetzt und Abendlied", "tokens": ["sei", "Er\u00b7de", "jetzt", "und", "A\u00b7ben\u00b7dlied"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "ADV", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und Land, darauf er pa\u00dft.", "tokens": ["und", "Land", ",", "da\u00b7rauf", "er", "pa\u00dft", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dem\u00fctig sei jetzt wie ein Ding,", "tokens": ["De\u00b7m\u00fc\u00b7tig", "sei", "jetzt", "wie", "ein", "Ding", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "zu Wirklichkeit gereift, \u2013", "tokens": ["zu", "Wirk\u00b7lich\u00b7keit", "ge\u00b7reift", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "da\u00df Der, von dem die Kunde ging,", "tokens": ["da\u00df", "Der", ",", "von", "dem", "die", "Kun\u00b7de", "ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dich f\u00fchlt, wenn er dich greift.", "tokens": ["dich", "f\u00fchlt", ",", "wenn", "er", "dich", "greift", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PPER", "PRF", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.121": {"line.1": {"text": "Ich bete wieder, du Erlauchter,", "tokens": ["Ich", "be\u00b7te", "wie\u00b7der", ",", "du", "Er\u00b7lauch\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "du h\u00f6rst mich wieder durch den Wind,", "tokens": ["du", "h\u00f6rst", "mich", "wie\u00b7der", "durch", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "weil meine Tiefen niegebrauchter", "tokens": ["weil", "mei\u00b7ne", "Tie\u00b7fen", "nie\u00b7ge\u00b7brauch\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "rauschender Worte m\u00e4chtig sind.", "tokens": ["rau\u00b7schen\u00b7der", "Wor\u00b7te", "m\u00e4ch\u00b7tig", "sind", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "ADJD", "VAFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.122": {"line.1": {"text": "Ich war zerstreut; an Widersacher", "tokens": ["Ich", "war", "zer\u00b7streut", ";", "an", "Wi\u00b7der\u00b7sa\u00b7cher"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "in St\u00fccken war verteilt mein Ich.", "tokens": ["in", "St\u00fc\u00b7cken", "war", "ver\u00b7teilt", "mein", "Ich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "VVPP", "PPOSAT", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O Gott, mich lachten alle Lacher", "tokens": ["O", "Gott", ",", "mich", "lach\u00b7ten", "al\u00b7le", "La\u00b7cher"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "NN", "$,", "PPER", "VVFIN", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und alle Trinker tranken mich.", "tokens": ["und", "al\u00b7le", "Trin\u00b7ker", "tran\u00b7ken", "mich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.123": {"line.1": {"text": "In H\u00f6fen hab ich mich gesammelt", "tokens": ["In", "H\u00f6\u00b7fen", "hab", "ich", "mich", "ge\u00b7sam\u00b7melt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VAFIN", "PPER", "PRF", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "aus Abfall und aus altem Glas,", "tokens": ["aus", "Ab\u00b7fall", "und", "aus", "al\u00b7tem", "Glas", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "mit halbem Mund dich angestammelt,", "tokens": ["mit", "hal\u00b7bem", "Mund", "dich", "an\u00b7ge\u00b7stam\u00b7melt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "dich, Ewiger aus Ebenma\u00df.", "tokens": ["dich", ",", "E\u00b7wi\u00b7ger", "aus", "E\u00b7ben\u00b7ma\u00df", "."], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJA", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie hob ich meine halben H\u00e4nde", "tokens": ["Wie", "hob", "ich", "mei\u00b7ne", "hal\u00b7ben", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PPER", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "zu dir in namenlosem Flehn,", "tokens": ["zu", "dir", "in", "na\u00b7men\u00b7lo\u00b7sem", "Flehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "da\u00df ich die Augen wiederf\u00e4nde,", "tokens": ["da\u00df", "ich", "die", "Au\u00b7gen", "wie\u00b7der\u00b7f\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "mit denen ich dich angesehn.", "tokens": ["mit", "de\u00b7nen", "ich", "dich", "an\u00b7ge\u00b7sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.124": {"line.1": {"text": "Ich war ein Haus nach einem Brand,", "tokens": ["Ich", "war", "ein", "Haus", "nach", "ei\u00b7nem", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "darin nur M\u00f6rder manchmal schlafen,", "tokens": ["da\u00b7rin", "nur", "M\u00f6r\u00b7der", "manch\u00b7mal", "schla\u00b7fen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "eh ihre hungerigen Strafen", "tokens": ["eh", "ih\u00b7re", "hun\u00b7ge\u00b7ri\u00b7gen", "Stra\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sie weiterjagen in das Land;", "tokens": ["sie", "wei\u00b7ter\u00b7ja\u00b7gen", "in", "das", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ich war wie eine Stadt am Meer,", "tokens": ["ich", "war", "wie", "ei\u00b7ne", "Stadt", "am", "Meer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KOKOM", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "wenn eine Seuche sie bedr\u00e4ngte,", "tokens": ["wenn", "ei\u00b7ne", "Seu\u00b7che", "sie", "be\u00b7dr\u00e4ng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "die sich wie eine Leiche schwer", "tokens": ["die", "sich", "wie", "ei\u00b7ne", "Lei\u00b7che", "schwer"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PRF", "KOKOM", "ART", "NN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "den Kindern an die H\u00e4nde h\u00e4ngte.", "tokens": ["den", "Kin\u00b7dern", "an", "die", "H\u00e4n\u00b7de", "h\u00e4ng\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.125": {"line.1": {"text": "Ich war mir fremd wie irgendwer,", "tokens": ["Ich", "war", "mir", "fremd", "wie", "ir\u00b7gend\u00b7wer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wu\u00dfte nur von ihm, da\u00df er", "tokens": ["und", "wu\u00df\u00b7te", "nur", "von", "ihm", ",", "da\u00df", "er"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "ADV", "APPR", "PPER", "$,", "KOUS", "PPER"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "einst meine junge Mutter kr\u00e4nkte", "tokens": ["einst", "mei\u00b7ne", "jun\u00b7ge", "Mut\u00b7ter", "kr\u00e4nk\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "als sie mich trug,", "tokens": ["als", "sie", "mich", "trug", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "und da\u00df ihr Herz, das eingeengte,", "tokens": ["und", "da\u00df", "ihr", "Herz", ",", "das", "ein\u00b7ge\u00b7eng\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "$,", "PDS", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sehr schmerzhaft an mein Keimen schlug.", "tokens": ["sehr", "schmerz\u00b7haft", "an", "mein", "Kei\u00b7men", "schlug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.126": {"line.1": {"text": "Jetzt bin ich wieder aufgebaut", "tokens": ["Jetzt", "bin", "ich", "wie\u00b7der", "auf\u00b7ge\u00b7baut"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "aus allen St\u00fccken meiner Schande,", "tokens": ["aus", "al\u00b7len", "St\u00fc\u00b7cken", "mei\u00b7ner", "Schan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "und sehne mich nach einem Bande,", "tokens": ["und", "seh\u00b7ne", "mich", "nach", "ei\u00b7nem", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "nach einem einigen Verstande,", "tokens": ["nach", "ei\u00b7nem", "ei\u00b7ni\u00b7gen", "Ver\u00b7stan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "der mich wie ", "tokens": ["der", "mich", "wie"], "token_info": ["word", "word", "word"], "pos": ["ART", "PPER", "KOKOM"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "nach deines Herzens gro\u00dfen H\u00e4nden \u2013", "tokens": ["nach", "dei\u00b7nes", "Her\u00b7zens", "gro\u00b7\u00dfen", "H\u00e4n\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "(o k\u00e4men sie doch auf mich zu).", "tokens": ["(", "o", "k\u00e4\u00b7men", "sie", "doch", "auf", "mich", "zu", ")", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "FM", "VVFIN", "PPER", "ADV", "APPR", "PPER", "PTKZU", "$(", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich z\u00e4hle mich, mein Gott, und du,", "tokens": ["Ich", "z\u00e4h\u00b7le", "mich", ",", "mein", "Gott", ",", "und", "du", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPOSAT", "NN", "$,", "KON", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "du hast das Recht, mich zu verschwenden.", "tokens": ["du", "hast", "das", "Recht", ",", "mich", "zu", "ver\u00b7schwen\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.127": {"line.1": {"text": "Ich bin derselbe noch, der kniete", "tokens": ["Ich", "bin", "der\u00b7sel\u00b7be", "noch", ",", "der", "knie\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "ADV", "$,", "PRELS", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "vor dir in m\u00f6nchischem Gewand:", "tokens": ["vor", "dir", "in", "m\u00f6n\u00b7chi\u00b7schem", "Ge\u00b7wand", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der tiefe, dienende Levite,", "tokens": ["der", "tie\u00b7fe", ",", "die\u00b7nen\u00b7de", "Le\u00b7vi\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$,"], "meter": "-+-+---+-", "measure": "unknown.measure.tri"}, "line.4": {"text": "den du erf\u00fcllt, der dich erfand.", "tokens": ["den", "du", "er\u00b7f\u00fcllt", ",", "der", "dich", "er\u00b7fand", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVPP", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die Stimme einer stillen Zelle,", "tokens": ["Die", "Stim\u00b7me", "ei\u00b7ner", "stil\u00b7len", "Zel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "an der die Welt vor\u00fcberweht, \u2013", "tokens": ["an", "der", "die", "Welt", "vor\u00b7\u00fc\u00b7ber\u00b7weht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und du bist immer noch die Welle", "tokens": ["und", "du", "bist", "im\u00b7mer", "noch", "die", "Wel\u00b7le"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "die \u00fcber alle Dinge geht.", "tokens": ["die", "\u00fc\u00b7ber", "al\u00b7le", "Din\u00b7ge", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.128": {"line.1": {"text": "Es ", "tokens": ["Es"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "aus dem die L\u00e4nder manchmal steigen.", "tokens": ["aus", "dem", "die", "L\u00e4n\u00b7der", "manch\u00b7mal", "stei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Es ", "tokens": ["Es"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "von sch\u00f6nen Engeln und von Geigen,", "tokens": ["von", "sch\u00f6\u00b7nen", "En\u00b7geln", "und", "von", "Gei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und der Verschwiegene ist der,", "tokens": ["und", "der", "Ver\u00b7schwie\u00b7ge\u00b7ne", "ist", "der", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "ART", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "zu dem sich alle Dinge neigen,", "tokens": ["zu", "dem", "sich", "al\u00b7le", "Din\u00b7ge", "nei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "von seiner St\u00e4rke Strahlen schwer.", "tokens": ["von", "sei\u00b7ner", "St\u00e4r\u00b7ke", "Strah\u00b7len", "schwer", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.129": {"line.1": {"text": "Bist du denn Alles, \u2013 ich der Eine,", "tokens": ["Bist", "du", "denn", "Al\u00b7les", ",", "\u2013", "ich", "der", "Ei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "$,", "$(", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "der sich ergiebt und sich emp\u00f6rt?", "tokens": ["der", "sich", "er\u00b7giebt", "und", "sich", "em\u00b7p\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "VVFIN", "KON", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Bin ich denn nicht das Allgemeine,", "tokens": ["Bin", "ich", "denn", "nicht", "das", "All\u00b7ge\u00b7mei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PTKNEG", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bin ich nicht ", "tokens": ["bin", "ich", "nicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKNEG"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "und du der Eine, der es h\u00f6rt?", "tokens": ["und", "du", "der", "Ei\u00b7ne", ",", "der", "es", "h\u00f6rt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "H\u00f6rst du denn etwas neben mir?", "tokens": ["H\u00f6rst", "du", "denn", "et\u00b7was", "ne\u00b7ben", "mir", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "APPR", "PPER", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Sind da noch Stimmen au\u00dfer meiner?", "tokens": ["Sind", "da", "noch", "Stim\u00b7men", "au\u00b7\u00dfer", "mei\u00b7ner", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "NN", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Ist da ein Sturm? Auch ich bin einer,", "tokens": ["Ist", "da", "ein", "Sturm", "?", "Auch", "ich", "bin", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$.", "ADV", "PPER", "VAFIN", "ART", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "und meine W\u00e4lder winken dir.", "tokens": ["und", "mei\u00b7ne", "W\u00e4l\u00b7der", "win\u00b7ken", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.130": {"line.1": {"text": "Ist da ein Lied, ein krankes, kleines,", "tokens": ["Ist", "da", "ein", "Lied", ",", "ein", "kran\u00b7kes", ",", "klei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "$,", "ART", "ADJA", "$,", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das dich am Micherh\u00f6ren st\u00f6rt, \u2013", "tokens": ["das", "dich", "am", "Mi\u00b7cher\u00b7h\u00f6\u00b7ren", "st\u00f6rt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "PRF", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auch ich bin eines, h\u00f6re meines,", "tokens": ["auch", "ich", "bin", "ei\u00b7nes", ",", "h\u00f6\u00b7re", "mei\u00b7nes", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "PIS", "$,", "VVFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das einsam ist und unerh\u00f6rt.", "tokens": ["das", "ein\u00b7sam", "ist", "und", "un\u00b7er\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.131": {"line.1": {"text": "Ich bin derselbe noch, der bange", "tokens": ["Ich", "bin", "der\u00b7sel\u00b7be", "noch", ",", "der", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "PDAT", "ADV", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "dich manchmal fragte, wer du seist.", "tokens": ["dich", "manch\u00b7mal", "frag\u00b7te", ",", "wer", "du", "seist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Nach jedem Sonnenuntergange", "tokens": ["Nach", "je\u00b7dem", "Son\u00b7nen\u00b7un\u00b7ter\u00b7gan\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "bin ich verwundet und verwaist,", "tokens": ["bin", "ich", "ver\u00b7wun\u00b7det", "und", "ver\u00b7waist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "ein blasser Allem Abgel\u00f6ster", "tokens": ["ein", "blas\u00b7ser", "Al\u00b7lem", "Ab\u00b7ge\u00b7l\u00f6s\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und ein Verschm\u00e4hter jeder Schar,", "tokens": ["und", "ein", "Ver\u00b7schm\u00e4h\u00b7ter", "je\u00b7der", "Schar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und alle Dinge stehn wie Kl\u00f6ster,", "tokens": ["und", "al\u00b7le", "Din\u00b7ge", "stehn", "wie", "Kl\u00f6s\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "in denen ich gefangen war.", "tokens": ["in", "de\u00b7nen", "ich", "ge\u00b7fan\u00b7gen", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Dann brauch ich dich, du Eingeweihter,", "tokens": ["Dann", "brauch", "ich", "dich", ",", "du", "Ein\u00b7ge\u00b7weih\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "du sanfter Nachbar jeder Not,", "tokens": ["du", "sanf\u00b7ter", "Nach\u00b7bar", "je\u00b7der", "Not", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "du meines Leidens leiser Zweiter,", "tokens": ["du", "mei\u00b7nes", "Lei\u00b7dens", "lei\u00b7ser", "Zwei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "du Gott, dann brauch ich dich wie Brot.", "tokens": ["du", "Gott", ",", "dann", "brauch", "ich", "dich", "wie", "Brot", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "ADV", "VVFIN", "PPER", "PRF", "KOKOM", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Du wei\u00dft vielleicht nicht, wie die N\u00e4chte", "tokens": ["Du", "wei\u00dft", "viel\u00b7leicht", "nicht", ",", "wie", "die", "N\u00e4ch\u00b7te"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "PTKNEG", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "f\u00fcr Menschen, die nicht schlafen, sind:", "tokens": ["f\u00fcr", "Men\u00b7schen", ",", "die", "nicht", "schla\u00b7fen", ",", "sind", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "da sind sie alle Ungerechte,", "tokens": ["da", "sind", "sie", "al\u00b7le", "Un\u00b7ge\u00b7rech\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "der Greis, die Jungfrau und das Kind.", "tokens": ["der", "Greis", ",", "die", "Jung\u00b7frau", "und", "das", "Kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "Sie fahren auf wie totgesagt,", "tokens": ["Sie", "fah\u00b7ren", "auf", "wie", "tot\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PWAV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.18": {"text": "von schwarzen Dingen nah umgeben,", "tokens": ["von", "schwar\u00b7zen", "Din\u00b7gen", "nah", "um\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.19": {"text": "und ihre wei\u00dfen H\u00e4nde beben,", "tokens": ["und", "ih\u00b7re", "wei\u00b7\u00dfen", "H\u00e4n\u00b7de", "be\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.20": {"text": "verwoben in ein wildes Leben", "tokens": ["ver\u00b7wo\u00b7ben", "in", "ein", "wil\u00b7des", "Le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.21": {"text": "wie Hunde in ein Bild der Jagd.", "tokens": ["wie", "Hun\u00b7de", "in", "ein", "Bild", "der", "Jagd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.22": {"text": "Vergangenes steht noch bevor,", "tokens": ["Ver\u00b7gan\u00b7ge\u00b7nes", "steht", "noch", "be\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PTKVZ", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.23": {"text": "und in der Zukunft liegen Leichen,", "tokens": ["und", "in", "der", "Zu\u00b7kunft", "lie\u00b7gen", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.24": {"text": "ein Mann im Mantel pocht am Tor,", "tokens": ["ein", "Mann", "im", "Man\u00b7tel", "pocht", "am", "Tor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.25": {"text": "und mit dem Auge und dem Ohr", "tokens": ["und", "mit", "dem", "Au\u00b7ge", "und", "dem", "Ohr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.26": {"text": "ist noch kein erstes Morgenzeichen,", "tokens": ["ist", "noch", "kein", "ers\u00b7tes", "Mor\u00b7gen\u00b7zei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.27": {"text": "kein Hahnruf ist noch zu erreichen.", "tokens": ["kein", "Hahn\u00b7ruf", "ist", "noch", "zu", "er\u00b7rei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Die Nacht ist wie ein gro\u00dfes Haus.", "tokens": ["Die", "Nacht", "ist", "wie", "ein", "gro\u00b7\u00dfes", "Haus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.29": {"text": "Und mit der Angst der wunden H\u00e4nde", "tokens": ["Und", "mit", "der", "Angst", "der", "wun\u00b7den", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.30": {"text": "rei\u00dfen sie T\u00fcren in die W\u00e4nde, \u2013", "tokens": ["rei\u00b7\u00dfen", "sie", "T\u00fc\u00b7ren", "in", "die", "W\u00e4n\u00b7de", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "ART", "NN", "$,", "$("], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.31": {"text": "dann kommen G\u00e4nge ohne Ende,", "tokens": ["dann", "kom\u00b7men", "G\u00e4n\u00b7ge", "oh\u00b7ne", "En\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.32": {"text": "und nirgends ist ein Tor hinaus.", "tokens": ["und", "nir\u00b7gends", "ist", "ein", "Tor", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.132": {"line.1": {"text": "Und so, mein Gott, ist ", "tokens": ["Und", "so", ",", "mein", "Gott", ",", "ist"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word"], "pos": ["KON", "ADV", "$,", "PPOSAT", "NN", "$,", "VAFIN"], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "immer sind welche aufgewacht,", "tokens": ["im\u00b7mer", "sind", "wel\u00b7che", "auf\u00b7ge\u00b7wacht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "VVFIN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "die gehn und gehn und dich nicht finden.", "tokens": ["die", "gehn", "und", "gehn", "und", "dich", "nicht", "fin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "KON", "VVINF", "KON", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "H\u00f6rst du sie mit dem Schritt von Blinden", "tokens": ["H\u00f6rst", "du", "sie", "mit", "dem", "Schritt", "von", "Blin\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "APPR", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "das Dunkel treten?", "tokens": ["das", "Dun\u00b7kel", "tre\u00b7ten", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "Auf Treppen, die sich niederwinden,", "tokens": ["Auf", "Trep\u00b7pen", ",", "die", "sich", "nie\u00b7der\u00b7win\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "h\u00f6rst du sie beten?", "tokens": ["h\u00f6rst", "du", "sie", "be\u00b7ten", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}, "line.8": {"text": "H\u00f6rst du sie fallen auf den schwarzen Steinen?", "tokens": ["H\u00f6rst", "du", "sie", "fal\u00b7len", "auf", "den", "schwar\u00b7zen", "Stei\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Du mu\u00dft sie weinen h\u00f6ren; denn sie weinen.", "tokens": ["Du", "mu\u00dft", "sie", "wei\u00b7nen", "h\u00f6\u00b7ren", ";", "denn", "sie", "wei\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVINF", "VVINF", "$.", "KON", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ich suche dich, weil sie vor\u00fcbergehn", "tokens": ["Ich", "su\u00b7che", "dich", ",", "weil", "sie", "vor\u00b7\u00fc\u00b7ber\u00b7gehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUS", "PPER", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "an meiner T\u00fcr. Ich kann sie beinah sehn.", "tokens": ["an", "mei\u00b7ner", "T\u00fcr", ".", "Ich", "kann", "sie", "bei\u00b7nah", "sehn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Wen soll ich rufen, wenn nicht ", "tokens": ["Wen", "soll", "ich", "ru\u00b7fen", ",", "wenn", "nicht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VMFIN", "PPER", "VVINF", "$,", "KOUS", "PTKNEG"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.13": {"text": "der dunkel ist und n\u00e4chtiger als Nacht.", "tokens": ["der", "dun\u00b7kel", "ist", "und", "n\u00e4ch\u00b7ti\u00b7ger", "als", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "VAFIN", "KON", "ADJA", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Den Einzigen, der ohne Lampe wacht", "tokens": ["Den", "Ein\u00b7zi\u00b7gen", ",", "der", "oh\u00b7ne", "Lam\u00b7pe", "wacht"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "und doch nicht bangt; den Tiefen, den das Licht", "tokens": ["und", "doch", "nicht", "bangt", ";", "den", "Tie\u00b7fen", ",", "den", "das", "Licht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "PTKNEG", "VVFIN", "$.", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "noch nicht verw\u00f6hnt hat und von dem ich wei\u00df,", "tokens": ["noch", "nicht", "ver\u00b7w\u00f6hnt", "hat", "und", "von", "dem", "ich", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "VVPP", "VAFIN", "KON", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "weil er mit B\u00e4umen aus der Erde bricht", "tokens": ["weil", "er", "mit", "B\u00e4u\u00b7men", "aus", "der", "Er\u00b7de", "bricht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "und weil er leis", "tokens": ["und", "weil", "er", "leis"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.19": {"text": "als Duft in mein gesenktes Angesicht", "tokens": ["als", "Duft", "in", "mein", "ge\u00b7senk\u00b7tes", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "aus Erde steigt.", "tokens": ["aus", "Er\u00b7de", "steigt", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.133": {"line.1": {"text": "Du Ewiger, du hast dich mir gezeigt.", "tokens": ["Du", "E\u00b7wi\u00b7ger", ",", "du", "hast", "dich", "mir", "ge\u00b7zeigt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "$,", "PPER", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Ich liebe dich wie einen lieben Sohn,", "tokens": ["Ich", "lie\u00b7be", "dich", "wie", "ei\u00b7nen", "lie\u00b7ben", "Sohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "KOKOM", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "der mich einmal verlassen hat als Kind,", "tokens": ["der", "mich", "ein\u00b7mal", "ver\u00b7las\u00b7sen", "hat", "als", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "VVPP", "VAFIN", "KOKOM", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "weil ihn das Schicksal rief auf einen Thron,", "tokens": ["weil", "ihn", "das", "Schick\u00b7sal", "rief", "auf", "ei\u00b7nen", "Thron", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "vor dem die L\u00e4nder alle T\u00e4ler sind.", "tokens": ["vor", "dem", "die", "L\u00e4n\u00b7der", "al\u00b7le", "T\u00e4\u00b7ler", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ART", "NN", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Ich bin zur\u00fcck geblieben wie ein Greis,", "tokens": ["Ich", "bin", "zu\u00b7r\u00fcck", "ge\u00b7blie\u00b7ben", "wie", "ein", "Greis", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVPP", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "der seinen gro\u00dfen Sohn nichtmehr versteht", "tokens": ["der", "sei\u00b7nen", "gro\u00b7\u00dfen", "Sohn", "nicht\u00b7mehr", "ver\u00b7steht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "PIS", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und wenig von den neuen Dingen wei\u00df,", "tokens": ["und", "we\u00b7nig", "von", "den", "neu\u00b7en", "Din\u00b7gen", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "zu welchen seines Samens Wille geht.", "tokens": ["zu", "wel\u00b7chen", "sei\u00b7nes", "Sa\u00b7mens", "Wil\u00b7le", "geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWAT", "PPOSAT", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Ich bebe manchmal f\u00fcr dein tiefes Gl\u00fcck,", "tokens": ["Ich", "be\u00b7be", "manch\u00b7mal", "f\u00fcr", "dein", "tie\u00b7fes", "Gl\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "das auf so vielen fremden Schiffen f\u00e4hrt,", "tokens": ["das", "auf", "so", "vie\u00b7len", "frem\u00b7den", "Schif\u00b7fen", "f\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ADV", "PIAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "ich w\u00fcnsche manchmal dich in mich zur\u00fcck,", "tokens": ["ich", "w\u00fcn\u00b7sche", "manch\u00b7mal", "dich", "in", "mich", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "APPR", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "in dieses Dunkel, das dich gro\u00dfgen\u00e4hrt.", "tokens": ["in", "die\u00b7ses", "Dun\u00b7kel", ",", "das", "dich", "gro\u00df\u00b7ge\u00b7n\u00e4hrt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ich bange manchmal, da\u00df du nichtmehr bist,", "tokens": ["Ich", "ban\u00b7ge", "manch\u00b7mal", ",", "da\u00df", "du", "nicht\u00b7mehr", "bist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "$,", "KOUS", "PPER", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "wenn ich mich sehr verliere an die Zeit.", "tokens": ["wenn", "ich", "mich", "sehr", "ver\u00b7lie\u00b7re", "an", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADV", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Dann les ich von dir: der Euangelist", "tokens": ["Dann", "les", "ich", "von", "dir", ":", "der", "Eu\u00b7an\u00b7ge\u00b7list"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "PIS", "PPER", "APPR", "PPER", "$.", "ART", "NN"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.17": {"text": "schreibt \u00fcberall von deiner Ewigkeit.", "tokens": ["schreibt", "\u00fc\u00b7be\u00b7rall", "von", "dei\u00b7ner", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.134": {"line.1": {"text": "Ich bin der Vater; doch der Sohn ist mehr,", "tokens": ["Ich", "bin", "der", "Va\u00b7ter", ";", "doch", "der", "Sohn", "ist", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "ADV", "ART", "NN", "VAFIN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "ist alles, was der Vater war, und der,", "tokens": ["ist", "al\u00b7les", ",", "was", "der", "Va\u00b7ter", "war", ",", "und", "der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "$,", "PRELS", "ART", "NN", "VAFIN", "$,", "KON", "ART", "$,"], "meter": "-+-+-+-++-", "measure": "unknown.measure.penta"}, "line.3": {"text": "der er nicht wurde, wird in jenem gro\u00df;", "tokens": ["der", "er", "nicht", "wur\u00b7de", ",", "wird", "in", "je\u00b7nem", "gro\u00df", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PTKNEG", "VAFIN", "$,", "VAFIN", "APPR", "PDAT", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "er ist die Zukunft und die Wiederkehr,", "tokens": ["er", "ist", "die", "Zu\u00b7kunft", "und", "die", "Wie\u00b7der\u00b7kehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "er ist der Schoo\u00df, er ist das Meer ...", "tokens": ["er", "ist", "der", "Schoo\u00df", ",", "er", "ist", "das", "Meer", "..."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.135": {"line.1": {"text": "Dir ist mein Beten keine Blasphemie:", "tokens": ["Dir", "ist", "mein", "Be\u00b7ten", "kei\u00b7ne", "Blas\u00b7phe\u00b7mie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "als schl\u00fcge ich in alten B\u00fcchern nach,", "tokens": ["als", "schl\u00fc\u00b7ge", "ich", "in", "al\u00b7ten", "B\u00fc\u00b7chern", "nach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "PPER", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "da\u00df ich dir sehr verwandt bin \u2013 tausendfach.", "tokens": ["da\u00df", "ich", "dir", "sehr", "ver\u00b7wandt", "bin", "\u2013", "tau\u00b7send\u00b7fach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "VVPP", "VAFIN", "$(", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.136": {"line.1": {"text": "Ich will dir Liebe geben. Die und die ....", "tokens": ["Ich", "will", "dir", "Lie\u00b7be", "ge\u00b7ben", ".", "Die", "und", "die", "...."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "NN", "VVINF", "$.", "ART", "KON", "ART", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.137": {"line.1": {"text": "Liebt man denn einen Vater? Geht man nicht,", "tokens": ["Liebt", "man", "denn", "ei\u00b7nen", "Va\u00b7ter", "?", "Geht", "man", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "ART", "NN", "$.", "VVFIN", "PIS", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie du von mir gingst, H\u00e4rte im Gesicht,", "tokens": ["wie", "du", "von", "mir", "gingst", ",", "H\u00e4r\u00b7te", "im", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPER", "VVFIN", "$,", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "von seinen h\u00fclflos leeren H\u00e4nden fort?", "tokens": ["von", "sei\u00b7nen", "h\u00fcl\u00b7flos", "lee\u00b7ren", "H\u00e4n\u00b7den", "fort", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJD", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Legt man nicht leise sein verwelktes Wort", "tokens": ["Legt", "man", "nicht", "lei\u00b7se", "sein", "ver\u00b7welk\u00b7tes", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "ADJD", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "in alte B\u00fccher, die man selten liest?", "tokens": ["in", "al\u00b7te", "B\u00fc\u00b7cher", ",", "die", "man", "sel\u00b7ten", "liest", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "PRELS", "PIS", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.138": {"line.1": {"text": "Flie\u00dft man nicht wie von einer Wasserscheide", "tokens": ["Flie\u00dft", "man", "nicht", "wie", "von", "ei\u00b7ner", "Was\u00b7ser\u00b7schei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "PTKNEG", "KOKOM", "APPR", "ART", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "von seinem Herzen ab zu Lust und Leide?", "tokens": ["von", "sei\u00b7nem", "Her\u00b7zen", "ab", "zu", "Lust", "und", "Lei\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKVZ", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ist uns der Vater denn nicht das, was ", "tokens": ["Ist", "uns", "der", "Va\u00b7ter", "denn", "nicht", "das", ",", "was"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["VAFIN", "PPER", "ART", "NN", "ADV", "PTKNEG", "PDS", "$,", "PWS"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "vergangne Jahre, welche fremd gedacht,", "tokens": ["ver\u00b7gang\u00b7ne", "Jah\u00b7re", ",", "wel\u00b7che", "fremd", "ge\u00b7dacht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "veraltete Geb\u00e4rde, tote Tracht,", "tokens": ["ver\u00b7al\u00b7te\u00b7te", "Ge\u00b7b\u00e4r\u00b7de", ",", "to\u00b7te", "Tracht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "verbl\u00fchte H\u00e4nde und verblichnes Haar?", "tokens": ["ver\u00b7bl\u00fch\u00b7te", "H\u00e4n\u00b7de", "und", "ver\u00b7blich\u00b7nes", "Haar", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und war er selbst f\u00fcr seine Zeit ein Held,", "tokens": ["Und", "war", "er", "selbst", "f\u00fcr", "sei\u00b7ne", "Zeit", "ein", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "er ist das Blatt, das, wenn wir wachsen, f\u00e4llt.", "tokens": ["er", "ist", "das", "Blatt", ",", "das", ",", "wenn", "wir", "wach\u00b7sen", ",", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PDS", "$,", "KOUS", "PPER", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.139": {"line.1": {"text": "Und seine Sorgfalt ist uns wie ein Alb,", "tokens": ["Und", "sei\u00b7ne", "Sorg\u00b7falt", "ist", "uns", "wie", "ein", "Alb", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und seine Stimme ist uns wie ein Stein, \u2013", "tokens": ["und", "sei\u00b7ne", "Stim\u00b7me", "ist", "uns", "wie", "ein", "Stein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "PPER", "KOKOM", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "wir m\u00f6chten seiner Rede h\u00f6rig sein,", "tokens": ["wir", "m\u00f6ch\u00b7ten", "sei\u00b7ner", "Re\u00b7de", "h\u00f6\u00b7rig", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "aber wir h\u00f6ren seine Worte halb.", "tokens": ["a\u00b7ber", "wir", "h\u00f6\u00b7ren", "sei\u00b7ne", "Wor\u00b7te", "halb", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPOSAT", "NN", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.5": {"text": "Das gro\u00dfe Drama zwischen ihm und uns", "tokens": ["Das", "gro\u00b7\u00dfe", "Dra\u00b7ma", "zwi\u00b7schen", "ihm", "und", "uns"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "APPR", "PPER", "KON", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "l\u00e4rmt viel zu laut, einander zu verstehn,", "tokens": ["l\u00e4rmt", "viel", "zu", "laut", ",", "ein\u00b7an\u00b7der", "zu", "ver\u00b7stehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PTKA", "ADJD", "$,", "PRF", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "wir sehen nur die Formen seines Munds,", "tokens": ["wir", "se\u00b7hen", "nur", "die", "For\u00b7men", "sei\u00b7nes", "Munds", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "aus denen Silben fallen, die vergehn.", "tokens": ["aus", "de\u00b7nen", "Sil\u00b7ben", "fal\u00b7len", ",", "die", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PRELS", "NN", "VVINF", "$,", "PRELS", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "So sind wir noch viel ferner ihm als fern,", "tokens": ["So", "sind", "wir", "noch", "viel", "fer\u00b7ner", "ihm", "als", "fern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADV", "ADV", "PPER", "KOUS", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "wenn auch die Liebe uns noch weit verwebt,", "tokens": ["wenn", "auch", "die", "Lie\u00b7be", "uns", "noch", "weit", "ver\u00b7webt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "erst wenn er sterben mu\u00df auf diesem Stern,", "tokens": ["erst", "wenn", "er", "ster\u00b7ben", "mu\u00df", "auf", "die\u00b7sem", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "sehn wir, da\u00df er auf diesem Stern gelebt.", "tokens": ["sehn", "wir", ",", "da\u00df", "er", "auf", "die\u00b7sem", "Stern", "ge\u00b7lebt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "PDAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.140": {"line.1": {"text": "Das ist der Vater uns. Und ich \u2013 ich soll", "tokens": ["Das", "ist", "der", "Va\u00b7ter", "uns", ".", "Und", "ich", "\u2013", "ich", "soll"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "NN", "PPER", "$.", "KON", "PPER", "$(", "PPER", "VMFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "dich Vater nennen?", "tokens": ["dich", "Va\u00b7ter", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Das hie\u00dfe tausendmal mich von dir trennen.", "tokens": ["Das", "hie\u00b7\u00dfe", "tau\u00b7send\u00b7mal", "mich", "von", "dir", "tren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "PPER", "APPR", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "Du bist mein Sohn. Ich werde dich erkennen,", "tokens": ["Du", "bist", "mein", "Sohn", ".", "Ich", "wer\u00b7de", "dich", "er\u00b7ken\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "$.", "PPER", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "wie man sein einzigliebes Kind erkennt, auch dann,", "tokens": ["wie", "man", "sein", "ein\u00b7zig\u00b7lie\u00b7bes", "Kind", "er\u00b7kennt", ",", "auch", "dann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "PIS", "PPOSAT", "ADJA", "NN", "VVFIN", "$,", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "wenn es ein Mann geworden ist, ein alter Mann.", "tokens": ["wenn", "es", "ein", "Mann", "ge\u00b7wor\u00b7den", "ist", ",", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VAPP", "VAFIN", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.141": {"line.1": {"text": "L\u00f6sch mir die Augen aus: ich kann dich sehn,", "tokens": ["L\u00f6sch", "mir", "die", "Au\u00b7gen", "aus", ":", "ich", "kann", "dich", "sehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wirf mir die Ohren zu: ich kann dich h\u00f6ren,", "tokens": ["wirf", "mir", "die", "Oh\u00b7ren", "zu", ":", "ich", "kann", "dich", "h\u00f6\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "NN", "PTKVZ", "$.", "PPER", "VMFIN", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und ohne F\u00fc\u00dfe kann ich zu dir gehn,", "tokens": ["und", "oh\u00b7ne", "F\u00fc\u00b7\u00dfe", "kann", "ich", "zu", "dir", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und ohne Mund noch kann ich dich beschw\u00f6ren.", "tokens": ["und", "oh\u00b7ne", "Mund", "noch", "kann", "ich", "dich", "be\u00b7schw\u00f6\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "ADV", "VMFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Brich mir die Arme ab, ich fasse dich", "tokens": ["Brich", "mir", "die", "Ar\u00b7me", "ab", ",", "ich", "fas\u00b7se", "dich"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["NE", "PPER", "ART", "NN", "PTKVZ", "$,", "PPER", "VVFIN", "PPER"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit meinem Herzen wie mit einer Hand,", "tokens": ["mit", "mei\u00b7nem", "Her\u00b7zen", "wie", "mit", "ei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KOKOM", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "halt mir das Herz zu, und mein Hirn wird schlagen,", "tokens": ["halt", "mir", "das", "Herz", "zu", ",", "und", "mein", "Hirn", "wird", "schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,", "KON", "PPOSAT", "NN", "VAFIN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "und wirfst du in mein Hirn den Brand,", "tokens": ["und", "wirfst", "du", "in", "mein", "Hirn", "den", "Brand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "so werd ich dich auf meinem Blute tragen.", "tokens": ["so", "werd", "ich", "dich", "auf", "mei\u00b7nem", "Blu\u00b7te", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.142": {"line.1": {"text": "Und meine Seele ist ein Weib vor dir.", "tokens": ["Und", "mei\u00b7ne", "See\u00b7le", "ist", "ein", "Weib", "vor", "dir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und ist wie der Na\u00ebmi Schnur, wie Ruth.", "tokens": ["Und", "ist", "wie", "der", "Na\u00eb\u00b7mi", "Schnur", ",", "wie", "Ruth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VAFIN", "KOKOM", "ART", "NN", "NN", "$,", "PWAV", "NE", "$."], "meter": "--+-+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Sie geht bei Tag um deiner Garben Hauf", "tokens": ["Sie", "geht", "bei", "Tag", "um", "dei\u00b7ner", "Gar\u00b7ben", "Hauf"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "NN", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "wie eine Magd, die tiefe Dienste tut.", "tokens": ["wie", "ei\u00b7ne", "Magd", ",", "die", "tie\u00b7fe", "Diens\u00b7te", "tut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Aber am Abend steigt sie in die Flut", "tokens": ["A\u00b7ber", "am", "A\u00b7bend", "steigt", "sie", "in", "die", "Flut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.6": {"text": "und badet sich und kleidet sich sehr gut", "tokens": ["und", "ba\u00b7det", "sich", "und", "klei\u00b7det", "sich", "sehr", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "KON", "VVFIN", "PRF", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und kommt zu dir, wenn alles um dich ruht,", "tokens": ["und", "kommt", "zu", "dir", ",", "wenn", "al\u00b7les", "um", "dich", "ruht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "$,", "KOUS", "PIS", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "und kommt und deckt zu deinen F\u00fc\u00dfen auf.", "tokens": ["und", "kommt", "und", "deckt", "zu", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und fragst du sie um Mitternacht, sie sagt", "tokens": ["Und", "fragst", "du", "sie", "um", "Mit\u00b7ter\u00b7nacht", ",", "sie", "sagt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "PPER", "APPR", "NN", "$,", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "mit tiefer Einfalt: Ich bin Ruth, die Magd.", "tokens": ["mit", "tie\u00b7fer", "Ein\u00b7falt", ":", "Ich", "bin", "Ruth", ",", "die", "Magd", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VAFIN", "NE", "$,", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Spann deine Fl\u00fcgel \u00fcber deine Magd.", "tokens": ["Spann", "dei\u00b7ne", "Fl\u00fc\u00b7gel", "\u00fc\u00b7ber", "dei\u00b7ne", "Magd", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Du bist der Erbe ...", "tokens": ["Du", "bist", "der", "Er\u00b7be", "..."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$("], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.143": {"line.1": {"text": "Und meine Seele schl\u00e4ft dann bis es tagt", "tokens": ["Und", "mei\u00b7ne", "See\u00b7le", "schl\u00e4ft", "dann", "bis", "es", "tagt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "bei deinen F\u00fc\u00dfen, warm von deinem Blut.", "tokens": ["bei", "dei\u00b7nen", "F\u00fc\u00b7\u00dfen", ",", "warm", "von", "dei\u00b7nem", "Blut", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Und ist ein Weib vor dir. Und ist wie Ruth.", "tokens": ["Und", "ist", "ein", "Weib", "vor", "dir", ".", "Und", "ist", "wie", "Ruth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "NN", "APPR", "PPER", "$.", "KON", "VAFIN", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.144": {"line.1": {"text": "Du bist der Erbe.", "tokens": ["Du", "bist", "der", "Er\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "S\u00f6hne sind die Erben,", "tokens": ["S\u00f6h\u00b7ne", "sind", "die", "Er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "denn V\u00e4ter sterben.", "tokens": ["denn", "V\u00e4\u00b7ter", "ster\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "S\u00f6hne stehn und bl\u00fchn.", "tokens": ["S\u00f6h\u00b7ne", "stehn", "und", "bl\u00fchn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "KON", "VVINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.5": {"text": "Du bist der Erbe:", "tokens": ["Du", "bist", "der", "Er\u00b7be", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.145": {"line.1": {"text": "Und du erbst das Gr\u00fcn", "tokens": ["Und", "du", "erbst", "das", "Gr\u00fcn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "vergangner G\u00e4rten und das stille Blau", "tokens": ["ver\u00b7gang\u00b7ner", "G\u00e4r\u00b7ten", "und", "das", "stil\u00b7le", "Blau"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "zerfallner Himmel.", "tokens": ["zer\u00b7fall\u00b7ner", "Him\u00b7mel", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "Tau aus tausend Tagen,", "tokens": ["Tau", "aus", "tau\u00b7send", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "die vielen Sommer, die die Sonnen sagen,", "tokens": ["die", "vie\u00b7len", "Som\u00b7mer", ",", "die", "die", "Son\u00b7nen", "sa\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und lauter Fr\u00fchlinge mit Glanz und Klagen", "tokens": ["und", "lau\u00b7ter", "Fr\u00fch\u00b7lin\u00b7ge", "mit", "Glanz", "und", "Kla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "APPR", "NN", "KON", "NN"], "meter": "-+-++--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "wie viele Briefe einer jungen Frau.", "tokens": ["wie", "vie\u00b7le", "Brie\u00b7fe", "ei\u00b7ner", "jun\u00b7gen", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Du erbst die Herbste, die wie Prunkgew\u00e4nder", "tokens": ["Du", "erbst", "die", "Herbs\u00b7te", ",", "die", "wie", "Prunk\u00b7ge\u00b7w\u00e4n\u00b7der"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "in der Erinnerung von Dichtern liegen,", "tokens": ["in", "der", "E\u00b7rin\u00b7ne\u00b7rung", "von", "Dich\u00b7tern", "lie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "und alle Winter, wie verwaiste L\u00e4nder,", "tokens": ["und", "al\u00b7le", "Win\u00b7ter", ",", "wie", "ver\u00b7wais\u00b7te", "L\u00e4n\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PWAV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "scheinen sich leise an dich anzuschmiegen.", "tokens": ["schei\u00b7nen", "sich", "lei\u00b7se", "an", "dich", "an\u00b7zu\u00b7schmie\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADJD", "APPR", "PPER", "VVIZU", "$."], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.12": {"text": "Du erbst Venedig und Kasan und Rom,", "tokens": ["Du", "erbst", "Ve\u00b7ne\u00b7dig", "und", "Ka\u00b7san", "und", "Rom", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NE", "KON", "NE", "KON", "NE", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Florenz wird dein sein, der Pisaner Dom,", "tokens": ["Flo\u00b7renz", "wird", "dein", "sein", ",", "der", "Pi\u00b7sa\u00b7ner", "Dom", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPOSAT", "VAINF", "$,", "ART", "NN", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.14": {"text": "die Tro\u00eftzka Lawra und das Monastir,", "tokens": ["die", "Tro\u00eftz\u00b7ka", "Law\u00b7ra", "und", "das", "Mo\u00b7nas\u00b7tir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "NE", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "das unter Kiews G\u00e4rten ein Gewirr", "tokens": ["das", "un\u00b7ter", "Kiews", "G\u00e4r\u00b7ten", "ein", "Ge\u00b7wirr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PDS", "APPR", "NE", "NN", "ART", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.16": {"text": "von G\u00e4ngen bildet, dunkel und verschlungen, \u2013", "tokens": ["von", "G\u00e4n\u00b7gen", "bil\u00b7det", ",", "dun\u00b7kel", "und", "ver\u00b7schlun\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NN", "VVFIN", "$,", "ADJD", "KON", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "Moskau mit Glocken wie Erinnerungen, \u2013", "tokens": ["Mos\u00b7kau", "mit", "Glo\u00b7cken", "wie", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "APPR", "NN", "KOKOM", "NN", "$,", "$("], "meter": "++-+-+-+-+-", "measure": "iambic.penta.spondeus"}, "line.18": {"text": "und Klang wird dein sein: Geigen, H\u00f6rner, Zungen,", "tokens": ["und", "Klang", "wird", "dein", "sein", ":", "Gei\u00b7gen", ",", "H\u00f6r\u00b7ner", ",", "Zun\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PPOSAT", "VAINF", "$.", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und jedes Lied, das tief genug erklungen,", "tokens": ["und", "je\u00b7des", "Lied", ",", "das", "tief", "ge\u00b7nug", "er\u00b7klun\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "ADJD", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "wird an dir gl\u00e4nzen wie ein Edelstein.", "tokens": ["wird", "an", "dir", "gl\u00e4n\u00b7zen", "wie", "ein", "E\u00b7del\u00b7stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "APPR", "PPER", "VVINF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.146": {"line.1": {"text": "F\u00fcr dich nur schlie\u00dfen sich die Dichter ein", "tokens": ["F\u00fcr", "dich", "nur", "schlie\u00b7\u00dfen", "sich", "die", "Dich\u00b7ter", "ein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "PRF", "ART", "NN", "ART"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und sammeln Bilder, rauschende und reiche,", "tokens": ["und", "sam\u00b7meln", "Bil\u00b7der", ",", "rau\u00b7schen\u00b7de", "und", "rei\u00b7che", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "ADJA", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und gehn hinaus und reifen durch Vergleiche", "tokens": ["und", "gehn", "hin\u00b7aus", "und", "rei\u00b7fen", "durch", "Ver\u00b7glei\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und sind ihr ganzes Leben so allein ...", "tokens": ["und", "sind", "ihr", "gan\u00b7zes", "Le\u00b7ben", "so", "al\u00b7lein", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPOSAT", "ADJA", "NN", "ADV", "ADV", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und Maler malen ihre Bilder nur,", "tokens": ["Und", "Ma\u00b7ler", "ma\u00b7len", "ih\u00b7re", "Bil\u00b7der", "nur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "damit du ", "tokens": ["da\u00b7mit", "du"], "token_info": ["word", "word"], "pos": ["KOUS", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.7": {"text": "die du verg\u00e4nglich schufst, zur\u00fcckempf\u00e4ngst:", "tokens": ["die", "du", "ver\u00b7g\u00e4ng\u00b7lich", "schufst", ",", "zu\u00b7r\u00fc\u00b7ckemp\u00b7f\u00e4ngst", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PPER", "ADJD", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "alles wird ewig. Sieh, das Weib ist l\u00e4ngst", "tokens": ["al\u00b7les", "wird", "e\u00b7wig", ".", "Sieh", ",", "das", "Weib", "ist", "l\u00e4ngst"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "ADJD", "$.", "NE", "$,", "ART", "NN", "VAFIN", "ADV"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.9": {"text": "in der Madonna Lisa reif wie Wein;", "tokens": ["in", "der", "Ma\u00b7don\u00b7na", "Li\u00b7sa", "reif", "wie", "Wein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NE", "ADJD", "KOKOM", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "es m\u00fc\u00dfte nie ein Weib mehr sein,", "tokens": ["es", "m\u00fc\u00df\u00b7te", "nie", "ein", "Weib", "mehr", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "ART", "NN", "ADV", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "denn Neues bringt kein neues Weib hinzu.", "tokens": ["denn", "Neu\u00b7es", "bringt", "kein", "neu\u00b7es", "Weib", "hin\u00b7zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "PIAT", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Die, welche bilden, sind wie du.", "tokens": ["Die", ",", "wel\u00b7che", "bil\u00b7den", ",", "sind", "wie", "du", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "VVINF", "$,", "VAFIN", "KOKOM", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Sie wollen Ewigkeit. Sie sagen: Stein,", "tokens": ["Sie", "wol\u00b7len", "E\u00b7wig\u00b7keit", ".", "Sie", "sa\u00b7gen", ":", "Stein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VMFIN", "NN", "$.", "PPER", "VVINF", "$.", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "sei ewig. Und das hei\u00dft: sei dein!", "tokens": ["sei", "e\u00b7wig", ".", "Und", "das", "hei\u00dft", ":", "sei", "dein", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$.", "KON", "PDS", "VVFIN", "$.", "VAFIN", "PPOSAT", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.147": {"line.1": {"text": "Und auch, die lieben, sammeln f\u00fcr dich ein:", "tokens": ["Und", "auch", ",", "die", "lie\u00b7ben", ",", "sam\u00b7meln", "f\u00fcr", "dich", "ein", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "ART", "ADJA", "$,", "VVFIN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+++", "measure": "zehnsilber"}, "line.2": {"text": "Sie sind die Dichter einer kurzen Stunde,", "tokens": ["Sie", "sind", "die", "Dich\u00b7ter", "ei\u00b7ner", "kur\u00b7zen", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sie k\u00fcssen einem ausdruckslosen Munde", "tokens": ["sie", "k\u00fcs\u00b7sen", "ei\u00b7nem", "aus\u00b7drucks\u00b7lo\u00b7sen", "Mun\u00b7de"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ein L\u00e4cheln auf, als formten sie ihn sch\u00f6ner,", "tokens": ["ein", "L\u00e4\u00b7cheln", "auf", ",", "als", "form\u00b7ten", "sie", "ihn", "sch\u00f6\u00b7ner", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$,", "KOUS", "VVFIN", "PPER", "PPER", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und bringen Lust und sind die Angew\u00f6hner", "tokens": ["und", "brin\u00b7gen", "Lust", "und", "sind", "die", "An\u00b7ge\u00b7w\u00f6h\u00b7ner"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "KON", "VAFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "zu Schmerzen, welche erst erwachsen machen.", "tokens": ["zu", "Schmer\u00b7zen", ",", "wel\u00b7che", "erst", "er\u00b7wach\u00b7sen", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "ADV", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Sie bringen Leiden mit in ihrem Lachen,", "tokens": ["Sie", "brin\u00b7gen", "Lei\u00b7den", "mit", "in", "ih\u00b7rem", "La\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Sehns\u00fcchte, welche schlafen, und erwachen,", "tokens": ["Sehn\u00b7s\u00fcch\u00b7te", ",", "wel\u00b7che", "schla\u00b7fen", ",", "und", "er\u00b7wa\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "VVFIN", "$,", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "um aufzuweinen in der fremden Brust.", "tokens": ["um", "auf\u00b7zu\u00b7wei\u00b7nen", "in", "der", "frem\u00b7den", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "VVIZU", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sie h\u00e4ufen R\u00e4tselhaftes an und sterben,", "tokens": ["Sie", "h\u00e4u\u00b7fen", "R\u00e4t\u00b7sel\u00b7haf\u00b7tes", "an", "und", "ster\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "PTKVZ", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "wie Tiere sterben, ohne zu begreifen, \u2013", "tokens": ["wie", "Tie\u00b7re", "ster\u00b7ben", ",", "oh\u00b7ne", "zu", "be\u00b7grei\u00b7fen", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "NN", "VVINF", "$,", "KOUI", "PTKZU", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "aber sie werden vielleicht Enkel haben,", "tokens": ["a\u00b7ber", "sie", "wer\u00b7den", "viel\u00b7leicht", "En\u00b7kel", "ha\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "ADV", "NN", "VAFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.13": {"text": "in denen ihre gr\u00fcnen Leben reifen;", "tokens": ["in", "de\u00b7nen", "ih\u00b7re", "gr\u00fc\u00b7nen", "Le\u00b7ben", "rei\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "durch diese wirst du jene Liebe erben,", "tokens": ["durch", "die\u00b7se", "wirst", "du", "je\u00b7ne", "Lie\u00b7be", "er\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDS", "VAFIN", "PPER", "PDAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "die sie sich blind und wie im Schlafe gaben.", "tokens": ["die", "sie", "sich", "blind", "und", "wie", "im", "Schla\u00b7fe", "ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "PRF", "ADJD", "KON", "KOKOM", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "So flie\u00dft der Dinge \u00dcberflu\u00df dir zu.", "tokens": ["So", "flie\u00dft", "der", "Din\u00b7ge", "\u00dc\u00b7berf\u00b7lu\u00df", "dir", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Und wie die obern Becken von Font\u00e4nen", "tokens": ["Und", "wie", "die", "o\u00b7bern", "Be\u00b7cken", "von", "Fon\u00b7t\u00e4\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "ADJA", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.18": {"text": "best\u00e4ndig \u00fcberstr\u00f6men, wie von Str\u00e4hnen", "tokens": ["be\u00b7st\u00e4n\u00b7dig", "\u00fc\u00b7ber\u00b7str\u00f6\u00b7men", ",", "wie", "von", "Str\u00e4h\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ADJD", "VVPP", "$,", "PWAV", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "gel\u00f6sten Haares, in die tiefste Schale, \u2013", "tokens": ["ge\u00b7l\u00f6s\u00b7ten", "Haa\u00b7res", ",", "in", "die", "tiefs\u00b7te", "Scha\u00b7le", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJA", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "so f\u00e4llt die F\u00fclle dir in deine Tale,", "tokens": ["so", "f\u00e4llt", "die", "F\u00fcl\u00b7le", "dir", "in", "dei\u00b7ne", "Ta\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.21": {"text": "wenn Dinge und Gedanken \u00fcbergehn.", "tokens": ["wenn", "Din\u00b7ge", "und", "Ge\u00b7dan\u00b7ken", "\u00fc\u00b7ber\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.148": {"line.1": {"text": "Ich bin nur einer deiner Ganzgeringen,", "tokens": ["Ich", "bin", "nur", "ei\u00b7ner", "dei\u00b7ner", "Ganz\u00b7ge\u00b7rin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der in das Leben aus der Zelle sieht", "tokens": ["der", "in", "das", "Le\u00b7ben", "aus", "der", "Zel\u00b7le", "sieht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und der, den Menschen ferner als den Dingen,", "tokens": ["und", "der", ",", "den", "Men\u00b7schen", "fer\u00b7ner", "als", "den", "Din\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "ART", "NN", "ADV", "KOUS", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "nicht wagt zu w\u00e4gen, was geschieht.", "tokens": ["nicht", "wagt", "zu", "w\u00e4\u00b7gen", ",", "was", "ge\u00b7schieht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PTKNEG", "VVFIN", "PTKZU", "VVINF", "$,", "PWS", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch willst du mich vor deinem Angesicht,", "tokens": ["Doch", "willst", "du", "mich", "vor", "dei\u00b7nem", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "aus dem sich dunkel deine Augen heben,", "tokens": ["aus", "dem", "sich", "dun\u00b7kel", "dei\u00b7ne", "Au\u00b7gen", "he\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PRF", "ADJD", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "dann halte es f\u00fcr meine Hoffahrt nicht,", "tokens": ["dann", "hal\u00b7te", "es", "f\u00fcr", "mei\u00b7ne", "Hof\u00b7fahrt", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "wenn ich dir sage: Keiner lebt sein Leben.", "tokens": ["wenn", "ich", "dir", "sa\u00b7ge", ":", "Kei\u00b7ner", "lebt", "sein", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VVFIN", "$.", "PIS", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Zuf\u00e4lle sind die Menschen, Stimmen, St\u00fccke,", "tokens": ["Zu\u00b7f\u00e4l\u00b7le", "sind", "die", "Men\u00b7schen", ",", "Stim\u00b7men", ",", "St\u00fc\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Alltage, \u00c4ngste, viele kleine Gl\u00fccke,", "tokens": ["All\u00b7ta\u00b7ge", ",", "\u00c4ngs\u00b7te", ",", "vie\u00b7le", "klei\u00b7ne", "Gl\u00fc\u00b7cke", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PIAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "verkleidet schon als Kinder, eingemummt,", "tokens": ["ver\u00b7klei\u00b7det", "schon", "als", "Kin\u00b7der", ",", "ein\u00b7ge\u00b7mummt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "KOUS", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "als Masken m\u00fcndig, als Gesicht \u2013 verstummt.", "tokens": ["als", "Mas\u00b7ken", "m\u00fcn\u00b7dig", ",", "als", "Ge\u00b7sicht", "\u2013", "ver\u00b7stummt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "NN", "ADJD", "$,", "KOUS", "NN", "$(", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.149": {"line.1": {"text": "Ich denke oft: Schatzh\u00e4user m\u00fcssen sein,", "tokens": ["Ich", "den\u00b7ke", "oft", ":", "Schatz\u00b7h\u00e4u\u00b7ser", "m\u00fcs\u00b7sen", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$.", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wo alle diese vielen Leben liegen", "tokens": ["wo", "al\u00b7le", "die\u00b7se", "vie\u00b7len", "Le\u00b7ben", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PDAT", "PIAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie Panzer oder S\u00e4nften oder Wiegen,", "tokens": ["wie", "Pan\u00b7zer", "o\u00b7der", "S\u00e4nf\u00b7ten", "o\u00b7der", "Wie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "in welche nie ein Wirklicher gestiegen,", "tokens": ["in", "wel\u00b7che", "nie", "ein", "Wirk\u00b7li\u00b7cher", "ge\u00b7stie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und wie Gew\u00e4nder, welche ganz allein", "tokens": ["und", "wie", "Ge\u00b7w\u00e4n\u00b7der", ",", "wel\u00b7che", "ganz", "al\u00b7lein"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PWAV", "NN", "$,", "PRELS", "ADV", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "nicht stehen k\u00f6nnen und sich sinkend schmiegen", "tokens": ["nicht", "ste\u00b7hen", "k\u00f6n\u00b7nen", "und", "sich", "sin\u00b7kend", "schmie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVINF", "VMFIN", "KON", "PRF", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "an starke W\u00e4nde aus gew\u00f6lbtem Stein.", "tokens": ["an", "star\u00b7ke", "W\u00e4n\u00b7de", "aus", "ge\u00b7w\u00f6lb\u00b7tem", "Stein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Und wenn ich abends immer weiterginge", "tokens": ["Und", "wenn", "ich", "a\u00b7bends", "im\u00b7mer", "wei\u00b7ter\u00b7gin\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "ADV", "ADV", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "aus meinem Garten, drin ich m\u00fcde bin, \u2013", "tokens": ["aus", "mei\u00b7nem", "Gar\u00b7ten", ",", "drin", "ich", "m\u00fc\u00b7de", "bin", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "ADV", "PPER", "ADJD", "VAFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "ich wei\u00df: dann f\u00fchren alle Wege hin", "tokens": ["ich", "wei\u00df", ":", "dann", "f\u00fch\u00b7ren", "al\u00b7le", "We\u00b7ge", "hin"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$.", "ADV", "VVFIN", "PIAT", "NN", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "zum Arsenal der ungelebten Dinge.", "tokens": ["zum", "Ar\u00b7se\u00b7nal", "der", "un\u00b7ge\u00b7leb\u00b7ten", "Din\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Dort ist kein Baum, als legte sich das Land,", "tokens": ["Dort", "ist", "kein", "Baum", ",", "als", "leg\u00b7te", "sich", "das", "Land", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "KOUS", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "und wie um ein Gef\u00e4ngnis h\u00e4ngt die Wand", "tokens": ["und", "wie", "um", "ein", "Ge\u00b7f\u00e4ng\u00b7nis", "h\u00e4ngt", "die", "Wand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ART", "NN", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "ganz fensterlos in siebenfachem Ringe.", "tokens": ["ganz", "fens\u00b7ter\u00b7los", "in", "sie\u00b7ben\u00b7fa\u00b7chem", "Rin\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Und ihre Tore mit den Eisenspangen,", "tokens": ["Und", "ih\u00b7re", "To\u00b7re", "mit", "den", "Ei\u00b7sen\u00b7span\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "die denen wehren, welche hinverlangen,", "tokens": ["die", "de\u00b7nen", "weh\u00b7ren", ",", "wel\u00b7che", "hin\u00b7ver\u00b7lan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PDS", "VVINF", "$,", "PRELS", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und ihre Gitter sind von Menschenhand.", "tokens": ["und", "ih\u00b7re", "Git\u00b7ter", "sind", "von", "Men\u00b7schen\u00b7hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.150": {"line.1": {"text": "Und doch, obwohl ein jeder von sich strebt", "tokens": ["Und", "doch", ",", "ob\u00b7wohl", "ein", "je\u00b7der", "von", "sich", "strebt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$,", "KOUS", "ART", "PIS", "APPR", "PRF", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "wie aus dem Kerker, der ihn ha\u00dft und h\u00e4lt, \u2013", "tokens": ["wie", "aus", "dem", "Ker\u00b7ker", ",", "der", "ihn", "ha\u00dft", "und", "h\u00e4lt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "es ist ein gro\u00dfes Wunder in der Welt:", "tokens": ["es", "ist", "ein", "gro\u00b7\u00dfes", "Wun\u00b7der", "in", "der", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ich f\u00fchle: ", "tokens": ["ich", "f\u00fch\u00b7le", ":"], "token_info": ["word", "word", "punct"], "pos": ["PPER", "VVFIN", "$."], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Wer lebt es denn? Sind das die Dinge, die", "tokens": ["Wer", "lebt", "es", "denn", "?", "Sind", "das", "die", "Din\u00b7ge", ",", "die"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "VAFIN", "PDS", "ART", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wie eine ungespielte Melodie", "tokens": ["wie", "ei\u00b7ne", "un\u00b7ge\u00b7spiel\u00b7te", "Me\u00b7lo\u00b7die"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "im Abend wie in einer Harfe stehn?", "tokens": ["im", "A\u00b7bend", "wie", "in", "ei\u00b7ner", "Har\u00b7fe", "stehn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "KOKOM", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Sind das die Winde, die von Wassern wehn,", "tokens": ["Sind", "das", "die", "Win\u00b7de", ",", "die", "von", "Was\u00b7sern", "wehn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sind das die Zweige, die sich Zeichen geben,", "tokens": ["sind", "das", "die", "Zwei\u00b7ge", ",", "die", "sich", "Zei\u00b7chen", "ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "sind das die Blumen, die die D\u00fcfte weben,", "tokens": ["sind", "das", "die", "Blu\u00b7men", ",", "die", "die", "D\u00fcf\u00b7te", "we\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "sind das die langen alternden Alleen?", "tokens": ["sind", "das", "die", "lan\u00b7gen", "al\u00b7tern\u00b7den", "Al\u00b7leen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "Sind das die warmen Tiere, welche gehn,", "tokens": ["Sind", "das", "die", "war\u00b7men", "Tie\u00b7re", ",", "wel\u00b7che", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "$,", "PRELS", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "sind das die V\u00f6gel, die sich fremd erheben?", "tokens": ["sind", "das", "die", "V\u00f6\u00b7gel", ",", "die", "sich", "fremd", "er\u00b7he\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "NN", "$,", "PRELS", "PRF", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.14": {"text": "Wer lebt es denn? Lebst du es, Gott, \u2013 das Leben?", "tokens": ["Wer", "lebt", "es", "denn", "?", "Lebst", "du", "es", ",", "Gott", ",", "\u2013", "das", "Le\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "VVFIN", "PPER", "PPER", "$,", "NN", "$,", "$(", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.151": {"line.1": {"text": "Du bist der Alte, dem die Haare", "tokens": ["Du", "bist", "der", "Al\u00b7te", ",", "dem", "die", "Haa\u00b7re"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von Ru\u00df versengt sind und verbrannt,", "tokens": ["von", "Ru\u00df", "ver\u00b7sengt", "sind", "und", "ver\u00b7brannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVPP", "VAFIN", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "du bist der gro\u00dfe Unscheinbare,", "tokens": ["du", "bist", "der", "gro\u00b7\u00dfe", "Un\u00b7schein\u00b7ba\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mit deinem Hammer in der Hand.", "tokens": ["mit", "dei\u00b7nem", "Ham\u00b7mer", "in", "der", "Hand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist der Schmied, das Lied der Jahre,", "tokens": ["Du", "bist", "der", "Schmied", ",", "das", "Lied", "der", "Jah\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "der immer an dem Ambo\u00df stand.", "tokens": ["der", "im\u00b7mer", "an", "dem", "Am\u00b7bo\u00df", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.152": {"line.1": {"text": "Du bist, der niemals Sonntag hat,", "tokens": ["Du", "bist", ",", "der", "nie\u00b7mals", "Sonn\u00b7tag", "hat", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PRELS", "ADV", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "der in die Arbeit Eingekehrte,", "tokens": ["der", "in", "die", "Ar\u00b7beit", "Ein\u00b7ge\u00b7kehr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "der sterben k\u00f6nnte \u00fcberm Schwerte,", "tokens": ["der", "ster\u00b7ben", "k\u00f6nn\u00b7te", "\u00fc\u00b7berm", "Schwer\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "VMFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "das noch nicht gl\u00e4nzend wird und glatt.", "tokens": ["das", "noch", "nicht", "gl\u00e4n\u00b7zend", "wird", "und", "glatt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "PTKNEG", "ADJD", "VAFIN", "KON", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn bei uns M\u00fchle steht und S\u00e4ge", "tokens": ["Wenn", "bei", "uns", "M\u00fch\u00b7le", "steht", "und", "S\u00e4\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "APPR", "PPER", "NN", "VVFIN", "KON", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und alle trunken sind und tr\u00e4ge,", "tokens": ["und", "al\u00b7le", "trun\u00b7ken", "sind", "und", "tr\u00e4\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "ADJD", "VAFIN", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "dann h\u00f6rt man deine Hammerschl\u00e4ge", "tokens": ["dann", "h\u00f6rt", "man", "dei\u00b7ne", "Ham\u00b7mer\u00b7schl\u00e4\u00b7ge"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "an allen Glocken in der Stadt.", "tokens": ["an", "al\u00b7len", "Glo\u00b7cken", "in", "der", "Stadt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.153": {"line.1": {"text": "Du bist der M\u00fcndige, der Meister,", "tokens": ["Du", "bist", "der", "M\u00fcn\u00b7di\u00b7ge", ",", "der", "Meis\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und keiner hat dich lernen sehn;", "tokens": ["und", "kei\u00b7ner", "hat", "dich", "ler\u00b7nen", "sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "ein Unbekannter, Hergereister,", "tokens": ["ein", "Un\u00b7be\u00b7kann\u00b7ter", ",", "Her\u00b7ge\u00b7reis\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "von dem bald fl\u00fcsternder, bald dreister", "tokens": ["von", "dem", "bald", "fl\u00fcs\u00b7tern\u00b7der", ",", "bald", "dreis\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["APPR", "PRELS", "ADV", "PTKVZ", "$,", "ADV", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die Reden und Ger\u00fcchte gehn.", "tokens": ["die", "Re\u00b7den", "und", "Ge\u00b7r\u00fcch\u00b7te", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.154": {"line.1": {"text": "Ger\u00fcchte gehn, die dich vermuten,", "tokens": ["Ge\u00b7r\u00fcch\u00b7te", "gehn", ",", "die", "dich", "ver\u00b7mu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "und Zweifel gehn, die dich verwischen.", "tokens": ["und", "Zwei\u00b7fel", "gehn", ",", "die", "dich", "ver\u00b7wi\u00b7schen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVINF", "$,", "PRELS", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Tr\u00e4gen und die Tr\u00e4umerischen", "tokens": ["Die", "Tr\u00e4\u00b7gen", "und", "die", "Tr\u00e4u\u00b7me\u00b7ri\u00b7schen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "mi\u00dftrauen ihren eignen Gluten", "tokens": ["mi\u00df\u00b7trau\u00b7en", "ih\u00b7ren", "eig\u00b7nen", "Glu\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und wollen, da\u00df die Berge bluten,", "tokens": ["und", "wol\u00b7len", ",", "da\u00df", "die", "Ber\u00b7ge", "blu\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "denn eher glauben sie dich nicht.", "tokens": ["denn", "e\u00b7her", "glau\u00b7ben", "sie", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PRF", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Du aber senkst dein Angesicht.", "tokens": ["Du", "a\u00b7ber", "senkst", "dein", "An\u00b7ge\u00b7sicht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Du k\u00f6nntest den Bergen die Adern aufschneiden", "tokens": ["Du", "k\u00f6nn\u00b7test", "den", "Ber\u00b7gen", "die", "A\u00b7dern", "auf\u00b7schnei\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ART", "NN", "ART", "NN", "VVINF"], "meter": "-+--+--+--+-", "measure": "amphibrach.tetra"}, "line.9": {"text": "als Zeichen eines gro\u00dfen Gerichts;", "tokens": ["als", "Zei\u00b7chen", "ei\u00b7nes", "gro\u00b7\u00dfen", "Ge\u00b7richts", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.10": {"text": "aber dir liegt nichts", "tokens": ["a\u00b7ber", "dir", "liegt", "nichts"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "PPER", "VVFIN", "PIS"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.11": {"text": "an den Heiden.", "tokens": ["an", "den", "Hei\u00b7den", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.155": {"line.1": {"text": "Du willst nicht streiten mit allen Listen", "tokens": ["Du", "willst", "nicht", "strei\u00b7ten", "mit", "al\u00b7len", "Lis\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVFIN", "APPR", "PIAT", "NN"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "und nicht suchen die Liebe des Lichts;", "tokens": ["und", "nicht", "su\u00b7chen", "die", "Lie\u00b7be", "des", "Lichts", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "denn dir liegt nichts", "tokens": ["denn", "dir", "liegt", "nichts"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "VVFIN", "PIS"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "an den Christen.", "tokens": ["an", "den", "Chris\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-", "measure": "trochaic.di"}}, "stanza.156": {"line.1": {"text": "Dir liegt an den Fragenden nichts.", "tokens": ["Dir", "liegt", "an", "den", "Fra\u00b7gen\u00b7den", "nichts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "PIS", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Sanften Gesichts", "tokens": ["Sanf\u00b7ten", "Ge\u00b7sichts"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "siehst du den Tragenden zu.", "tokens": ["siehst", "du", "den", "Tra\u00b7gen\u00b7den", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}}, "stanza.157": {"line.1": {"text": "Alle, welche dich suchen, versuchen dich.", "tokens": ["Al\u00b7le", ",", "wel\u00b7che", "dich", "su\u00b7chen", ",", "ver\u00b7su\u00b7chen", "dich", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PIS", "$,", "PRELS", "PRF", "VVINF", "$,", "VVFIN", "PPER", "$."], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.2": {"text": "Und die, so dich finden, binden dich", "tokens": ["Und", "die", ",", "so", "dich", "fin\u00b7den", ",", "bin\u00b7den", "dich"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["KON", "ART", "$,", "ADV", "PPER", "VVINF", "$,", "VAFIN", "PPER"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "an Bild und Geb\u00e4rde.", "tokens": ["an", "Bild", "und", "Ge\u00b7b\u00e4r\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.158": {"line.1": {"text": "Ich aber will dich begreifen", "tokens": ["Ich", "a\u00b7ber", "will", "dich", "be\u00b7grei\u00b7fen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "VMFIN", "PRF", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "wie dich die Erde begreift;", "tokens": ["wie", "dich", "die", "Er\u00b7de", "be\u00b7greift", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "mit meinem Reifen", "tokens": ["mit", "mei\u00b7nem", "Rei\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.4": {"text": "reift", "tokens": ["reift"], "token_info": ["word"], "pos": ["VVFIN"], "meter": "+", "measure": "single.up"}, "line.5": {"text": "dein Reich.", "tokens": ["dein", "Reich", "."], "token_info": ["word", "word", "punct"], "pos": ["PPOSAT", "NN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.159": {"line.1": {"text": "Ich will von dir keine Eitelkeit,", "tokens": ["Ich", "will", "von", "dir", "kei\u00b7ne", "Ei\u00b7tel\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "die dich beweist.", "tokens": ["die", "dich", "be\u00b7weist", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Ich wei\u00df, da\u00df die Zeit", "tokens": ["Ich", "wei\u00df", ",", "da\u00df", "die", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.4": {"text": "anders hei\u00dft", "tokens": ["an\u00b7ders", "hei\u00dft"], "token_info": ["word", "word"], "pos": ["ADV", "VVFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.5": {"text": "als du.", "tokens": ["als", "du", "."], "token_info": ["word", "word", "punct"], "pos": ["KOUS", "PPER", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.160": {"line.1": {"text": "Tu mir kein Wunder zulieb.", "tokens": ["Tu", "mir", "kein", "Wun\u00b7der", "zu\u00b7lieb", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.2": {"text": "Gieb deinen Gesetzen recht,", "tokens": ["Gieb", "dei\u00b7nen", "Ge\u00b7set\u00b7zen", "recht", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPOSAT", "NN", "ADJD", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "die von Geschlecht zu Geschlecht", "tokens": ["die", "von", "Ge\u00b7schlecht", "zu", "Ge\u00b7schlecht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "APPR", "NN", "APPR", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "sichtbarer sind.", "tokens": ["sicht\u00b7ba\u00b7rer", "sind", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VAFIN", "$."], "meter": "+--+", "measure": "iambic.di.chol"}}, "stanza.161": {"line.1": {"text": "Wenn etwas mir vom Fenster f\u00e4llt", "tokens": ["Wenn", "et\u00b7was", "mir", "vom", "Fens\u00b7ter", "f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PPER", "APPRART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "(und wenn es auch das Kleinste w\u00e4re)", "tokens": ["(", "und", "wenn", "es", "auch", "das", "Kleins\u00b7te", "w\u00e4\u00b7re", ")"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "KOUS", "PPER", "ADV", "ART", "ADJA", "VAFIN", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie st\u00fcrzt sich das Gesetz der Schwere", "tokens": ["wie", "st\u00fcrzt", "sich", "das", "Ge\u00b7setz", "der", "Schwe\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "VVFIN", "PRF", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "gewaltig wie ein Wind vom Meere", "tokens": ["ge\u00b7wal\u00b7tig", "wie", "ein", "Wind", "vom", "Mee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "KOKOM", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "auf jeden Ball und jede Beere", "tokens": ["auf", "je\u00b7den", "Ball", "und", "je\u00b7de", "Bee\u00b7re"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "und tr\u00e4gt sie in den Kern der Welt.", "tokens": ["und", "tr\u00e4gt", "sie", "in", "den", "Kern", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.162": {"line.1": {"text": "Ein jedes Ding ist \u00fcberwacht", "tokens": ["Ein", "je\u00b7des", "Ding", "ist", "\u00fc\u00b7ber\u00b7wacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "PIAT", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "von einer flugbereiten G\u00fcte", "tokens": ["von", "ei\u00b7ner", "flug\u00b7be\u00b7rei\u00b7ten", "G\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie jeder Stein und jede Bl\u00fcte", "tokens": ["wie", "je\u00b7der", "Stein", "und", "je\u00b7de", "Bl\u00fc\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIAT", "NN", "KON", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und jedes kleine Kind bei Nacht.", "tokens": ["und", "je\u00b7des", "klei\u00b7ne", "Kind", "bei", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nur wir, in unsrer Hoffahrt, dr\u00e4ngen", "tokens": ["Nur", "wir", ",", "in", "uns\u00b7rer", "Hof\u00b7fahrt", ",", "dr\u00e4n\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word"], "pos": ["ADV", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "aus einigen Zusammenh\u00e4ngen", "tokens": ["aus", "ei\u00b7ni\u00b7gen", "Zu\u00b7sam\u00b7men\u00b7h\u00e4n\u00b7gen"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in einer Freiheit leeren Raum,", "tokens": ["in", "ei\u00b7ner", "Frei\u00b7heit", "lee\u00b7ren", "Raum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "statt, klugen Kr\u00e4ften hingegeben,", "tokens": ["statt", ",", "klu\u00b7gen", "Kr\u00e4f\u00b7ten", "hin\u00b7ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["PTKVZ", "$,", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "uns aufzuheben wie ein Baum.", "tokens": ["uns", "auf\u00b7zu\u00b7he\u00b7ben", "wie", "ein", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVIZU", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Statt in die weitesten Geleise", "tokens": ["Statt", "in", "die", "wei\u00b7tes\u00b7ten", "Ge\u00b7lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "sich still und willig einzureihn,", "tokens": ["sich", "still", "und", "wil\u00b7lig", "ein\u00b7zu\u00b7reihn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "KON", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "verkn\u00fcpft man sich auf manche Weise, \u2013", "tokens": ["ver\u00b7kn\u00fcpft", "man", "sich", "auf", "man\u00b7che", "Wei\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "PRF", "APPR", "PIAT", "NN", "$,", "$("], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.13": {"text": "und wer sich ausschlie\u00dft jedem Kreise,", "tokens": ["und", "wer", "sich", "aus\u00b7schlie\u00dft", "je\u00b7dem", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PRF", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "ist jetzt so namenlos allein.", "tokens": ["ist", "jetzt", "so", "na\u00b7men\u00b7los", "al\u00b7lein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ADJD", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Da mu\u00df er lernen von den Dingen,", "tokens": ["Da", "mu\u00df", "er", "ler\u00b7nen", "von", "den", "Din\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.16": {"text": "anfangen wieder wie ein Kind,", "tokens": ["an\u00b7fan\u00b7gen", "wie\u00b7der", "wie", "ein", "Kind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.17": {"text": "weil sie, die Gott am Herzen hingen,", "tokens": ["weil", "sie", ",", "die", "Gott", "am", "Her\u00b7zen", "hin\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "nicht von ihm fortgegangen sind.", "tokens": ["nicht", "von", "ihm", "fort\u00b7ge\u00b7gan\u00b7gen", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "APPR", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.19": {"text": "Eins mu\u00df er wieder k\u00f6nnen: ", "tokens": ["Eins", "mu\u00df", "er", "wie\u00b7der", "k\u00f6n\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "ADV", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.20": {"text": "geduldig in der Schwere ruhn,", "tokens": ["ge\u00b7dul\u00b7dig", "in", "der", "Schwe\u00b7re", "ruhn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.21": {"text": "der sich verma\u00df, den V\u00f6geln allen", "tokens": ["der", "sich", "ver\u00b7ma\u00df", ",", "den", "V\u00f6\u00b7geln", "al\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "PRF", "VVFIN", "$,", "ART", "NN", "PIAT"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.22": {"text": "im Fliegen es zuvorzutun.", "tokens": ["im", "Flie\u00b7gen", "es", "zu\u00b7vor\u00b7zu\u00b7tun", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.163": {"line.1": {"text": "(denn auch die Engel fliegen nicht mehr.", "tokens": ["(", "denn", "auch", "die", "En\u00b7gel", "flie\u00b7gen", "nicht", "mehr", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "ADV", "ART", "NN", "VVFIN", "PTKNEG", "ADV", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Schweren V\u00f6geln gleichen die Seraphim,", "tokens": ["Schwe\u00b7ren", "V\u00f6\u00b7geln", "glei\u00b7chen", "die", "Se\u00b7ra\u00b7phim", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "welche um ", "tokens": ["wel\u00b7che", "um"], "token_info": ["word", "word"], "pos": ["PWAT", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Tr\u00fcmmern von V\u00f6geln, Pinguinen", "tokens": ["Tr\u00fcm\u00b7mern", "von", "V\u00f6\u00b7geln", ",", "Pin\u00b7gu\u00b7i\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "NN", "$,", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.5": {"text": "gleichen sie, wie sie verk\u00fcmmern ...)", "tokens": ["glei\u00b7chen", "sie", ",", "wie", "sie", "ver\u00b7k\u00fcm\u00b7mern", "...", ")"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "PWAV", "PPER", "VVINF", "$(", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.164": {"line.1": {"text": "Du meinst die Demut. Angesichter", "tokens": ["Du", "meinst", "die", "De\u00b7mut", ".", "An\u00b7ge\u00b7sich\u00b7ter"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "ADV", "ART", "NN", "$.", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "gesenkt in stillem Dichverstehn.", "tokens": ["ge\u00b7senkt", "in", "stil\u00b7lem", "Dich\u00b7ver\u00b7stehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So gehen abends junge Dichter", "tokens": ["So", "ge\u00b7hen", "a\u00b7bends", "jun\u00b7ge", "Dich\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "in den entlegenen Alleen.", "tokens": ["in", "den", "ent\u00b7le\u00b7ge\u00b7nen", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "So stehn die Bauern um die Leiche,", "tokens": ["So", "stehn", "die", "Bau\u00b7ern", "um", "die", "Lei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "wenn sich ein Kind im Tod verlor, \u2013", "tokens": ["wenn", "sich", "ein", "Kind", "im", "Tod", "ver\u00b7lor", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPRART", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "und was geschieht, ist doch das Gleiche:", "tokens": ["und", "was", "ge\u00b7schieht", ",", "ist", "doch", "das", "Glei\u00b7che", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "VVFIN", "$,", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "es geht ein \u00dcbergro\u00dfes vor.", "tokens": ["es", "geht", "ein", "\u00dc\u00b7ber\u00b7gro\u00b7\u00dfes", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.165": {"line.1": {"text": "Wer dich zum ersten Mal gewahrt,", "tokens": ["Wer", "dich", "zum", "ers\u00b7ten", "Mal", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "den st\u00f6rt der Nachbar und die Uhr,", "tokens": ["den", "st\u00f6rt", "der", "Nach\u00b7bar", "und", "die", "Uhr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "der geht, gebeugt zu deiner Spur,", "tokens": ["der", "geht", ",", "ge\u00b7beugt", "zu", "dei\u00b7ner", "Spur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVFIN", "$,", "VVPP", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "und wie beladen und bejahrt.", "tokens": ["und", "wie", "be\u00b7la\u00b7den", "und", "be\u00b7jahrt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VVPP", "KON", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Erst sp\u00e4ter naht er der Natur", "tokens": ["Erst", "sp\u00e4\u00b7ter", "naht", "er", "der", "Na\u00b7tur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "und f\u00fchlt die Winde und die Fernen,", "tokens": ["und", "f\u00fchlt", "die", "Win\u00b7de", "und", "die", "Fer\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "h\u00f6rt dich, gefl\u00fcstert von der Flur,", "tokens": ["h\u00f6rt", "dich", ",", "ge\u00b7fl\u00fcs\u00b7tert", "von", "der", "Flur", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.8": {"text": "sieht dich, gesungen von den Sternen,", "tokens": ["sieht", "dich", ",", "ge\u00b7sun\u00b7gen", "von", "den", "Ster\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.9": {"text": "und kann dich nirgends mehr verlernen,", "tokens": ["und", "kann", "dich", "nir\u00b7gends", "mehr", "ver\u00b7ler\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und alles ist dein Mantel nur.", "tokens": ["und", "al\u00b7les", "ist", "dein", "Man\u00b7tel", "nur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.166": {"line.1": {"text": "Ihm bist du neu und nah und gut", "tokens": ["Ihm", "bist", "du", "neu", "und", "nah", "und", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "KON", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und wundersch\u00f6n wie eine Reise,", "tokens": ["und", "wun\u00b7der\u00b7sch\u00f6n", "wie", "ei\u00b7ne", "Rei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "die er in stillen Schiffen leise", "tokens": ["die", "er", "in", "stil\u00b7len", "Schif\u00b7fen", "lei\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PRELS", "PPER", "APPR", "ADJA", "NN", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf einem gro\u00dfen Flusse tut.", "tokens": ["auf", "ei\u00b7nem", "gro\u00b7\u00dfen", "Flus\u00b7se", "tut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Land ist weit, in Winden, eben,", "tokens": ["Das", "Land", "ist", "weit", ",", "in", "Win\u00b7den", ",", "e\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "APPR", "NN", "$,", "ADV", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "sehr gro\u00dfen Himmeln preisgegeben", "tokens": ["sehr", "gro\u00b7\u00dfen", "Him\u00b7meln", "preis\u00b7ge\u00b7ge\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und alten W\u00e4ldern untertan.", "tokens": ["und", "al\u00b7ten", "W\u00e4l\u00b7dern", "un\u00b7ter\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Die kleinen D\u00f6rfer, die sich nahn,", "tokens": ["Die", "klei\u00b7nen", "D\u00f6r\u00b7fer", ",", "die", "sich", "nahn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "vergehen wieder wie Gel\u00e4ute", "tokens": ["ver\u00b7ge\u00b7hen", "wie\u00b7der", "wie", "Ge\u00b7l\u00e4u\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "KOKOM", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "und wie ein Gestern und ein Heute", "tokens": ["und", "wie", "ein", "Ge\u00b7stern", "und", "ein", "Heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "KON", "ART", "NN"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.11": {"text": "und so wie alles, was wir sahn.", "tokens": ["und", "so", "wie", "al\u00b7les", ",", "was", "wir", "sahn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "KOKOM", "PIS", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Aber an dieses Stromes Lauf", "tokens": ["A\u00b7ber", "an", "die\u00b7ses", "Stro\u00b7mes", "Lauf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "PDAT", "NN", "NN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.13": {"text": "stehn immer wieder St\u00e4dte auf", "tokens": ["stehn", "im\u00b7mer", "wie\u00b7der", "St\u00e4d\u00b7te", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADV", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "und kommen wie auf Fl\u00fcgelschl\u00e4gen", "tokens": ["und", "kom\u00b7men", "wie", "auf", "Fl\u00fc\u00b7gel\u00b7schl\u00e4\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVINF", "KOKOM", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "der feierlichen Fahrt entgegen.", "tokens": ["der", "fei\u00b7er\u00b7li\u00b7chen", "Fahrt", "ent\u00b7ge\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.167": {"line.1": {"text": "Und manchmal lenkt das Schiff zu Stellen,", "tokens": ["Und", "manch\u00b7mal", "lenkt", "das", "Schiff", "zu", "Stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "die einsam, sonder Dorf und Stadt,", "tokens": ["die", "ein\u00b7sam", ",", "son\u00b7der", "Dorf", "und", "Stadt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "$,", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "auf etwas warten an den Wellen, \u2013", "tokens": ["auf", "et\u00b7was", "war\u00b7ten", "an", "den", "Wel\u00b7len", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PIS", "VVFIN", "APPR", "ART", "NN", "$,", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "auf den, der keine Heimat hat ...", "tokens": ["auf", "den", ",", "der", "kei\u00b7ne", "Hei\u00b7mat", "hat", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "PRELS", "PIAT", "NN", "VAFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr solche stehn dort kleine Wagen", "tokens": ["F\u00fcr", "sol\u00b7che", "stehn", "dort", "klei\u00b7ne", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIS", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "(ein jeder mit drei Pferden vor),", "tokens": ["(", "ein", "je\u00b7der", "mit", "drei", "Pfer\u00b7den", "vor", ")", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ART", "PIS", "APPR", "CARD", "NN", "PTKVZ", "$(", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "die atemlos nach Abend jagen", "tokens": ["die", "a\u00b7tem\u00b7los", "nach", "A\u00b7bend", "ja\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "APPR", "NN", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "auf einem Weg, der sich verlor.", "tokens": ["auf", "ei\u00b7nem", "Weg", ",", "der", "sich", "ver\u00b7lor", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.168": {"line.1": {"text": "In diesem Dorfe steht das letzte Haus", "tokens": ["In", "die\u00b7sem", "Dor\u00b7fe", "steht", "das", "letz\u00b7te", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "so einsam wie das letzte Haus der Welt.", "tokens": ["so", "ein\u00b7sam", "wie", "das", "letz\u00b7te", "Haus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.169": {"line.1": {"text": "Die Stra\u00dfe, die das kleine Dorf nicht h\u00e4lt,", "tokens": ["Die", "Stra\u00b7\u00dfe", ",", "die", "das", "klei\u00b7ne", "Dorf", "nicht", "h\u00e4lt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "ADJA", "NN", "PTKNEG", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "geht langsam weiter in die Nacht hinaus.", "tokens": ["geht", "lang\u00b7sam", "wei\u00b7ter", "in", "die", "Nacht", "hin\u00b7aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.170": {"line.1": {"text": "Das kleine Dorf ist nur ein \u00dcbergang", "tokens": ["Das", "klei\u00b7ne", "Dorf", "ist", "nur", "ein", "\u00dc\u00b7ber\u00b7gang"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VAFIN", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "zwischen zwei Weiten, ahnungsvoll und bang,", "tokens": ["zwi\u00b7schen", "zwei", "Wei\u00b7ten", ",", "ah\u00b7nungs\u00b7voll", "und", "bang", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "ein Weg an H\u00e4usern hin statt eines Stegs.", "tokens": ["ein", "Weg", "an", "H\u00e4u\u00b7sern", "hin", "statt", "ei\u00b7nes", "Stegs", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.171": {"line.1": {"text": "Und die das Dorf verlassen, wandern lang,", "tokens": ["Und", "die", "das", "Dorf", "ver\u00b7las\u00b7sen", ",", "wan\u00b7dern", "lang", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "ART", "ART", "NN", "VVINF", "$,", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und viele sterben vielleicht unterwegs.", "tokens": ["und", "vie\u00b7le", "ster\u00b7ben", "viel\u00b7leicht", "un\u00b7ter\u00b7wegs", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.172": {"line.1": {"text": "Manchmal steht einer auf beim Abendbrot", "tokens": ["Manch\u00b7mal", "steht", "ei\u00b7ner", "auf", "beim", "A\u00b7bend\u00b7brot"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "APPR", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und geht hinaus und geht und geht und geht, \u2013", "tokens": ["und", "geht", "hin\u00b7aus", "und", "geht", "und", "geht", "und", "geht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "KON", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "weil eine Kirche wo im Osten steht.", "tokens": ["weil", "ei\u00b7ne", "Kir\u00b7che", "wo", "im", "Os\u00b7ten", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PWAV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.173": {"line.1": {"text": "Und seine Kinder segnen ihn wie tot.", "tokens": ["Und", "sei\u00b7ne", "Kin\u00b7der", "seg\u00b7nen", "ihn", "wie", "tot", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "KOKOM", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.174": {"line.1": {"text": "Und einer, welcher stirbt in seinem Haus,", "tokens": ["Und", "ei\u00b7ner", ",", "wel\u00b7cher", "stirbt", "in", "sei\u00b7nem", "Haus", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PRELS", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "bleibt drinnen wohnen, bleibt in Tisch und Glas,", "tokens": ["bleibt", "drin\u00b7nen", "woh\u00b7nen", ",", "bleibt", "in", "Tisch", "und", "Glas", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "VVINF", "$,", "VVFIN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df die Kinder in die Welt hinaus", "tokens": ["so", "da\u00df", "die", "Kin\u00b7der", "in", "die", "Welt", "hin\u00b7aus"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "ART", "NN", "APPR", "ART", "NN", "APZR"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "zu jener Kirche ziehn, die er verga\u00df.", "tokens": ["zu", "je\u00b7ner", "Kir\u00b7che", "ziehn", ",", "die", "er", "ver\u00b7ga\u00df", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVINF", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.175": {"line.1": {"text": "Nachtw\u00e4chter ist der Wahnsinn,", "tokens": ["Nacht\u00b7w\u00e4ch\u00b7ter", "ist", "der", "Wahn\u00b7sinn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "weil er wacht.", "tokens": ["weil", "er", "wacht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.3": {"text": "Bei jeder Stunde bleibt er lachend stehn,", "tokens": ["Bei", "je\u00b7der", "Stun\u00b7de", "bleibt", "er", "la\u00b7chend", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und einen Namen sucht er f\u00fcr die Nacht", "tokens": ["und", "ei\u00b7nen", "Na\u00b7men", "sucht", "er", "f\u00fcr", "die", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und nennt sie: sieben, achtundzwanzig, zehn ...", "tokens": ["und", "nennt", "sie", ":", "sie\u00b7ben", ",", "acht\u00b7und\u00b7zwan\u00b7zig", ",", "zehn", "..."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$.", "CARD", "$,", "CARD", "$,", "CARD", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Und ein Triangel tr\u00e4gt er in der Hand,", "tokens": ["Und", "ein", "Tri\u00b7an\u00b7gel", "tr\u00e4gt", "er", "in", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "und weil er zittert, schl\u00e4gt es an den Rand", "tokens": ["und", "weil", "er", "zit\u00b7tert", ",", "schl\u00e4gt", "es", "an", "den", "Rand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "des Horns, das er nicht blasen kann, und singt", "tokens": ["des", "Horns", ",", "das", "er", "nicht", "bla\u00b7sen", "kann", ",", "und", "singt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "VVINF", "VMFIN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "das Lied, das er zu allen H\u00e4usern bringt.", "tokens": ["das", "Lied", ",", "das", "er", "zu", "al\u00b7len", "H\u00e4u\u00b7sern", "bringt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.176": {"line.1": {"text": "Die Kinder haben eine gute Nacht", "tokens": ["Die", "Kin\u00b7der", "ha\u00b7ben", "ei\u00b7ne", "gu\u00b7te", "Nacht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und h\u00f6ren tr\u00e4umend, da\u00df der Wahnsinn wacht.", "tokens": ["und", "h\u00f6\u00b7ren", "tr\u00e4u\u00b7mend", ",", "da\u00df", "der", "Wahn\u00b7sinn", "wacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VVPP", "$,", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Die Hunde aber rei\u00dfen sich vom Ring", "tokens": ["Die", "Hun\u00b7de", "a\u00b7ber", "rei\u00b7\u00dfen", "sich", "vom", "Ring"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und gehen in den H\u00e4usern gro\u00df umher", "tokens": ["und", "ge\u00b7hen", "in", "den", "H\u00e4u\u00b7sern", "gro\u00df", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "ADJD", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und zittern, wenn er schon vor\u00fcberging,", "tokens": ["und", "zit\u00b7tern", ",", "wenn", "er", "schon", "vor\u00b7\u00fc\u00b7ber\u00b7ging", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und f\u00fcrchten sich vor seiner Wiederkehr.", "tokens": ["und", "f\u00fcrch\u00b7ten", "sich", "vor", "sei\u00b7ner", "Wie\u00b7der\u00b7kehr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.177": {"line.1": {"text": "Wei\u00dft du von jenen Heiligen, mein Herr?", "tokens": ["Wei\u00dft", "du", "von", "je\u00b7nen", "Hei\u00b7li\u00b7gen", ",", "mein", "Herr", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.178": {"line.1": {"text": "Sie f\u00fchlten auch verschlo\u00dfne Klosterstuben", "tokens": ["Sie", "f\u00fchl\u00b7ten", "auch", "ver\u00b7schlo\u00df\u00b7ne", "Klos\u00b7ter\u00b7stu\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "zu nahe an Gel\u00e4chter und Gepl\u00e4rr,", "tokens": ["zu", "na\u00b7he", "an", "Ge\u00b7l\u00e4ch\u00b7ter", "und", "Ge\u00b7pl\u00e4rr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKA", "ADJD", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie tief sich in die Erde gruben.", "tokens": ["so", "da\u00df", "sie", "tief", "sich", "in", "die", "Er\u00b7de", "gru\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "ADJD", "PRF", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.179": {"line.1": {"text": "Ein jeder atmete mit seinem Licht", "tokens": ["Ein", "je\u00b7der", "at\u00b7me\u00b7te", "mit", "sei\u00b7nem", "Licht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PIS", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die kleine Luft in seiner Grube aus,", "tokens": ["die", "klei\u00b7ne", "Luft", "in", "sei\u00b7ner", "Gru\u00b7be", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "verga\u00df sein Alter und sein Angesicht", "tokens": ["ver\u00b7ga\u00df", "sein", "Al\u00b7ter", "und", "sein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPOSAT", "NN", "KON", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und lebte wie ein fensterloses Haus", "tokens": ["und", "leb\u00b7te", "wie", "ein", "fens\u00b7ter\u00b7lo\u00b7ses", "Haus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "und starb nichtmehr, als w\u00e4r er lange tot.", "tokens": ["und", "starb", "nicht\u00b7mehr", ",", "als", "w\u00e4r", "er", "lan\u00b7ge", "tot", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "$,", "KOKOM", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie lasen selten; alles war verdorrt,", "tokens": ["Sie", "la\u00b7sen", "sel\u00b7ten", ";", "al\u00b7les", "war", "ver\u00b7dorrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJD", "$.", "PIS", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "als w\u00e4re Frost in jedes Buch gekrochen,", "tokens": ["als", "w\u00e4\u00b7re", "Frost", "in", "je\u00b7des", "Buch", "ge\u00b7kro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "NN", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und wie die Kutte hing von ihren Knochen,", "tokens": ["und", "wie", "die", "Kut\u00b7te", "hing", "von", "ih\u00b7ren", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "so hing der Sinn herab von jedem Wort.", "tokens": ["so", "hing", "der", "Sinn", "her\u00b7ab", "von", "je\u00b7dem", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Sie redeten einander nichtmehr an,", "tokens": ["Sie", "re\u00b7de\u00b7ten", "ein\u00b7an\u00b7der", "nicht\u00b7mehr", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PIS", "PTKVZ", "$,"], "meter": "+-+--+-+-+", "measure": "trochaic.penta.relaxed"}, "line.11": {"text": "wenn sie sich f\u00fchlten in den schwarzen G\u00e4ngen,", "tokens": ["wenn", "sie", "sich", "f\u00fchl\u00b7ten", "in", "den", "schwar\u00b7zen", "G\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "sie lie\u00dfen ihre langen Haare h\u00e4ngen,", "tokens": ["sie", "lie\u00b7\u00dfen", "ih\u00b7re", "lan\u00b7gen", "Haa\u00b7re", "h\u00e4n\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "und keiner wu\u00dfte, ob sein Nachbarmann", "tokens": ["und", "kei\u00b7ner", "wu\u00df\u00b7te", ",", "ob", "sein", "Nach\u00b7bar\u00b7mann"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIS", "VVFIN", "$,", "KOUS", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "nicht stehend starb.", "tokens": ["nicht", "ste\u00b7hend", "starb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "In einem runden Raum,", "tokens": ["In", "ei\u00b7nem", "run\u00b7den", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.16": {"text": "wo Silberlampen sich von Balsam n\u00e4hrten,", "tokens": ["wo", "Sil\u00b7ber\u00b7lam\u00b7pen", "sich", "von", "Bal\u00b7sam", "n\u00e4hr\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PRF", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "versammelten sich manchmal die Gef\u00e4hrten", "tokens": ["ver\u00b7sam\u00b7mel\u00b7ten", "sich", "manch\u00b7mal", "die", "Ge\u00b7f\u00e4hr\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ADV", "ART", "NN"], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.18": {"text": "vor goldnen T\u00fcren wie vor goldnen G\u00e4rten", "tokens": ["vor", "gold\u00b7nen", "T\u00fc\u00b7ren", "wie", "vor", "gold\u00b7nen", "G\u00e4r\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "und schauten voller Mi\u00dftraun in den Traum", "tokens": ["und", "schau\u00b7ten", "vol\u00b7ler", "Mi\u00df\u00b7traun", "in", "den", "Traum"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "und rauschten leise mit den langen B\u00e4rten.", "tokens": ["und", "rauschten", "lei\u00b7se", "mit", "den", "lan\u00b7gen", "B\u00e4r\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}}, "stanza.180": {"line.1": {"text": "Ihr Leben war wie tausend Jahre gro\u00df,", "tokens": ["Ihr", "Le\u00b7ben", "war", "wie", "tau\u00b7send", "Jah\u00b7re", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "KOKOM", "CARD", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "seit es sich nichtmehr schied in Nacht und Helle;", "tokens": ["seit", "es", "sich", "nicht\u00b7mehr", "schied", "in", "Nacht", "und", "Hel\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "---+-+-+-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "sie waren, wie gew\u00e4lzt von einer Welle,", "tokens": ["sie", "wa\u00b7ren", ",", "wie", "ge\u00b7w\u00e4lzt", "von", "ei\u00b7ner", "Wel\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PWAV", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "zur\u00fcckgekehrt in ihrer Mutter Schoo\u00df.", "tokens": ["zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "in", "ih\u00b7rer", "Mut\u00b7ter", "Schoo\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sie sa\u00dfen rundgekr\u00fcmmt wie Embryos", "tokens": ["Sie", "sa\u00b7\u00dfen", "rund\u00b7ge\u00b7kr\u00fcmmt", "wie", "Emb\u00b7ry\u00b7os"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "VVFIN", "KOKOM", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "mit gro\u00dfen K\u00f6pfen und mit kleinen H\u00e4nden", "tokens": ["mit", "gro\u00b7\u00dfen", "K\u00f6p\u00b7fen", "und", "mit", "klei\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und a\u00dfen nicht, als ob sie Nahrung f\u00e4nden", "tokens": ["und", "a\u00b7\u00dfen", "nicht", ",", "als", "ob", "sie", "Nah\u00b7rung", "f\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKNEG", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "aus jener Erde, die sie schwarz umschlo\u00df.", "tokens": ["aus", "je\u00b7ner", "Er\u00b7de", ",", "die", "sie", "schwarz", "um\u00b7schlo\u00df", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.181": {"line.1": {"text": "Jetzt zeigt man sie den tausend Pilgern, die", "tokens": ["Jetzt", "zeigt", "man", "sie", "den", "tau\u00b7send", "Pil\u00b7gern", ",", "die"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "VVFIN", "PIS", "PPER", "ART", "CARD", "NN", "$,", "PRELS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "aus Stadt und Steppe zu dem Kloster wallen.", "tokens": ["aus", "Stadt", "und", "Step\u00b7pe", "zu", "dem", "Klos\u00b7ter", "wal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Seit dreimal hundert Jahren liegen sie,", "tokens": ["Seit", "drei\u00b7mal", "hun\u00b7dert", "Jah\u00b7ren", "lie\u00b7gen", "sie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "CARD", "NN", "VVFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und ihre Leiber k\u00f6nnen nicht zerfallen.", "tokens": ["und", "ih\u00b7re", "Lei\u00b7ber", "k\u00f6n\u00b7nen", "nicht", "zer\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Das Dunkel h\u00e4uft sich wie ein Licht das ru\u00dft", "tokens": ["Das", "Dun\u00b7kel", "h\u00e4uft", "sich", "wie", "ein", "Licht", "das", "ru\u00dft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF", "KOKOM", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "auf ihren langen lagernden Gestalten,", "tokens": ["auf", "ih\u00b7ren", "lan\u00b7gen", "la\u00b7gern\u00b7den", "Ge\u00b7stal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "die unter T\u00fcchern heimlich sich erhalten, \u2013", "tokens": ["die", "un\u00b7ter", "T\u00fc\u00b7chern", "heim\u00b7lich", "sich", "er\u00b7hal\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "APPR", "NN", "ADJD", "PRF", "VVPP", "$,", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und ihrer H\u00e4nde ungel\u00f6stes Falten", "tokens": ["und", "ih\u00b7rer", "H\u00e4n\u00b7de", "un\u00b7ge\u00b7l\u00f6s\u00b7tes", "Fal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "liegt ihnen wie Gebirge auf der Brust.", "tokens": ["liegt", "ih\u00b7nen", "wie", "Ge\u00b7bir\u00b7ge", "auf", "der", "Brust", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOKOM", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.182": {"line.1": {"text": "Du gro\u00dfer alter Herzog des Erhabnen:", "tokens": ["Du", "gro\u00b7\u00dfer", "al\u00b7ter", "Her\u00b7zog", "des", "Er\u00b7hab\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "hast du vergessen, diesen Eingegrabnen", "tokens": ["hast", "du", "ver\u00b7ges\u00b7sen", ",", "die\u00b7sen", "Ein\u00b7ge\u00b7grab\u00b7nen"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "PPER", "VVPP", "$,", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "den Tod zu schicken, der sie ganz verbraucht,", "tokens": ["den", "Tod", "zu", "schi\u00b7cken", ",", "der", "sie", "ganz", "ver\u00b7braucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKZU", "VVINF", "$,", "PRELS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "weil sie sich tief in Erde eingetaucht?", "tokens": ["weil", "sie", "sich", "tief", "in", "Er\u00b7de", "ein\u00b7ge\u00b7taucht", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Sind die, die sich Verstorbenen vergleichen,", "tokens": ["Sind", "die", ",", "die", "sich", "Ver\u00b7stor\u00b7be\u00b7nen", "ver\u00b7glei\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "$,", "PRELS", "PRF", "NN", "VVINF", "$,"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "am \u00e4hnlichsten der Unverg\u00e4nglichkeit?", "tokens": ["am", "\u00e4hn\u00b7lichs\u00b7ten", "der", "Un\u00b7ver\u00b7g\u00e4ng\u00b7lich\u00b7keit", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "ART", "NN", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}, "line.7": {"text": "Ist das das gro\u00dfe Leben deiner Leichen,", "tokens": ["Ist", "das", "das", "gro\u00b7\u00dfe", "Le\u00b7ben", "dei\u00b7ner", "Lei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PDS", "ART", "ADJA", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "das \u00fcberdauern soll den Tod der Zeit?", "tokens": ["das", "\u00fc\u00b7berd\u00b7au\u00b7ern", "soll", "den", "Tod", "der", "Zeit", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVINF", "VMFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.183": {"line.1": {"text": "Sind sie dir noch zu deinen Pl\u00e4nen gut?", "tokens": ["Sind", "sie", "dir", "noch", "zu", "dei\u00b7nen", "Pl\u00e4\u00b7nen", "gut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPER", "ADV", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Erh\u00e4ltst du unverg\u00e4ngliche Gef\u00e4\u00dfe,", "tokens": ["Er\u00b7h\u00e4ltst", "du", "un\u00b7ver\u00b7g\u00e4ng\u00b7li\u00b7che", "Ge\u00b7f\u00e4\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die du, der allen Ma\u00dfen Ungem\u00e4\u00dfe,", "tokens": ["die", "du", ",", "der", "al\u00b7len", "Ma\u00b7\u00dfen", "Un\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "$,", "PRELS", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "einmal erf\u00fcllen willst mit deinem Blut?", "tokens": ["ein\u00b7mal", "er\u00b7f\u00fcl\u00b7len", "willst", "mit", "dei\u00b7nem", "Blut", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVINF", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.184": {"line.1": {"text": "Du bist die Zukunft, gro\u00dfes Morgenrot", "tokens": ["Du", "bist", "die", "Zu\u00b7kunft", ",", "gro\u00b7\u00dfes", "Mor\u00b7gen\u00b7rot"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "\u00fcber den Ebenen der Ewigkeit.", "tokens": ["\u00fc\u00b7ber", "den", "E\u00b7be\u00b7nen", "der", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ART", "NN", "$."], "meter": "+--+---+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Du bist der Hahnschrei nach der Nacht der Zeit,", "tokens": ["Du", "bist", "der", "Hahn\u00b7schrei", "nach", "der", "Nacht", "der", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der Tau, die Morgenmette und die Maid,", "tokens": ["der", "Tau", ",", "die", "Mor\u00b7gen\u00b7met\u00b7te", "und", "die", "Maid", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "der fremde Mann, die Mutter und der Tod.", "tokens": ["der", "frem\u00b7de", "Mann", ",", "die", "Mut\u00b7ter", "und", "der", "Tod", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "KON", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.185": {"line.1": {"text": "Du bist die sich verwandelnde Gestalt,", "tokens": ["Du", "bist", "die", "sich", "ver\u00b7wan\u00b7deln\u00b7de", "Ge\u00b7stalt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "PRF", "ADJA", "NN", "$,"], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.2": {"text": "die immer einsam aus dem Schicksal ragt,", "tokens": ["die", "im\u00b7mer", "ein\u00b7sam", "aus", "dem", "Schick\u00b7sal", "ragt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "die unbejubelt bleibt und unbeklagt", "tokens": ["die", "un\u00b7be\u00b7ju\u00b7belt", "bleibt", "und", "un\u00b7be\u00b7klagt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJD", "VVFIN", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und unbeschrieben wie ein wilder Wald.", "tokens": ["und", "un\u00b7be\u00b7schrie\u00b7ben", "wie", "ein", "wil\u00b7der", "Wald", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.186": {"line.1": {"text": "Du bist der Dinge tiefer Inbegriff,", "tokens": ["Du", "bist", "der", "Din\u00b7ge", "tie\u00b7fer", "In\u00b7be\u00b7griff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "der seines Wesens letztes Wort verschweigt", "tokens": ["der", "sei\u00b7nes", "We\u00b7sens", "letz\u00b7tes", "Wort", "ver\u00b7schweigt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPOSAT", "NN", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und sich den Andern immer anders zeigt:", "tokens": ["und", "sich", "den", "An\u00b7dern", "im\u00b7mer", "an\u00b7ders", "zeigt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ART", "ADJA", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "dem Schiff als K\u00fcste und dem Land als Schiff.", "tokens": ["dem", "Schiff", "als", "K\u00fcs\u00b7te", "und", "dem", "Land", "als", "Schiff", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOUS", "NN", "KON", "ART", "NN", "KOUS", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.187": {"line.1": {"text": "Du bist das Kloster zu den Wundenmalen.", "tokens": ["Du", "bist", "das", "Klos\u00b7ter", "zu", "den", "Wun\u00b7den\u00b7ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Mit zweiunddrei\u00dfig alten Kathedralen", "tokens": ["Mit", "zwei\u00b7und\u00b7drei\u00b7\u00dfig", "al\u00b7ten", "Ka\u00b7thed\u00b7ra\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "CARD", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und f\u00fcnfzig Kirchen, welche aus Opalen", "tokens": ["und", "f\u00fcnf\u00b7zig", "Kir\u00b7chen", ",", "wel\u00b7che", "aus", "O\u00b7pa\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "CARD", "NN", "$,", "PRELS", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und St\u00fccken Bernstein aufgemauert sind.", "tokens": ["und", "St\u00fc\u00b7cken", "Bern\u00b7stein", "auf\u00b7ge\u00b7mau\u00b7ert", "sind", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "NN", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Auf jedem Ding im Klosterhofe", "tokens": ["Auf", "je\u00b7dem", "Ding", "im", "Klos\u00b7ter\u00b7ho\u00b7fe"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "liegt deines Klanges eine Strophe,", "tokens": ["liegt", "dei\u00b7nes", "Klan\u00b7ges", "ei\u00b7ne", "Stro\u00b7phe", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "und das gewaltige Tor beginnt.", "tokens": ["und", "das", "ge\u00b7wal\u00b7ti\u00b7ge", "Tor", "be\u00b7ginnt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.188": {"line.1": {"text": "In langen H\u00e4usern wohnen Nonnen,", "tokens": ["In", "lan\u00b7gen", "H\u00e4u\u00b7sern", "woh\u00b7nen", "Non\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Schwarzschwestern, siebenhundertzehn.", "tokens": ["Schwarz\u00b7schwes\u00b7tern", ",", "sie\u00b7ben\u00b7hun\u00b7dert\u00b7zehn", "."], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Manchmal kommt eine an den Bronnen,", "tokens": ["Manch\u00b7mal", "kommt", "ei\u00b7ne", "an", "den", "Bron\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und eine steht wie eingesponnen,", "tokens": ["und", "ei\u00b7ne", "steht", "wie", "ein\u00b7ge\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "VVFIN", "KOKOM", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "und eine, wie in Abendsonnen,", "tokens": ["und", "ei\u00b7ne", ",", "wie", "in", "A\u00b7bend\u00b7son\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "PWAV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "geht schlank in schweigsamen Alleen.", "tokens": ["geht", "schlank", "in", "schweig\u00b7sa\u00b7men", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.189": {"line.1": {"text": "Aber die Meisten sieht man nie;", "tokens": ["A\u00b7ber", "die", "Meis\u00b7ten", "sieht", "man", "nie", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIS", "ADV", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "sie bleiben in der H\u00e4user Schweigen", "tokens": ["sie", "blei\u00b7ben", "in", "der", "H\u00e4u\u00b7ser", "Schwei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "wie in der kranken Brust der Geigen", "tokens": ["wie", "in", "der", "kran\u00b7ken", "Brust", "der", "Gei\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "APPR", "ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "die Melodie, die keiner kann ...", "tokens": ["die", "Me\u00b7lo\u00b7die", ",", "die", "kei\u00b7ner", "kann", "..."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PIS", "VMFIN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.190": {"line.1": {"text": "Und um die Kirchen rings im Kreise,", "tokens": ["Und", "um", "die", "Kir\u00b7chen", "rings", "im", "Krei\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "von schmachtendem Jasmin umstellt,", "tokens": ["von", "schmach\u00b7ten\u00b7dem", "Jas\u00b7min", "um\u00b7stellt", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "sind Gr\u00e4berst\u00e4tten, welche leise", "tokens": ["sind", "Gr\u00e4\u00b7ber\u00b7st\u00e4t\u00b7ten", ",", "wel\u00b7che", "lei\u00b7se"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["VAFIN", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "wie Steine reden von der Welt.", "tokens": ["wie", "Stei\u00b7ne", "re\u00b7den", "von", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Von jener Welt, die nichtmehr ist,", "tokens": ["Von", "je\u00b7ner", "Welt", ",", "die", "nicht\u00b7mehr", "ist", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "PRELS", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "obwohl sie an das Kloster brandet,", "tokens": ["ob\u00b7wohl", "sie", "an", "das", "Klos\u00b7ter", "bran\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "in eitel Tag und Tand gewandet", "tokens": ["in", "ei\u00b7tel", "Tag", "und", "Tand", "ge\u00b7wan\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "KON", "NN", "VVPP"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "und gleichbereit zu Lust und List.", "tokens": ["und", "gleich\u00b7be\u00b7reit", "zu", "Lust", "und", "List", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.191": {"line.1": {"text": "Sie ist vergangen: denn du bist.", "tokens": ["Sie", "ist", "ver\u00b7gan\u00b7gen", ":", "denn", "du", "bist", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "$.", "KON", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.192": {"line.1": {"text": "Sie flie\u00dft noch wie ein Spiel von Lichtern", "tokens": ["Sie", "flie\u00dft", "noch", "wie", "ein", "Spiel", "von", "Lich\u00b7tern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "KOKOM", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00fcber das teilnahmslose Jahr;", "tokens": ["\u00fc\u00b7ber", "das", "teil\u00b7nahms\u00b7lo\u00b7se", "Jahr", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.3": {"text": "doch dir, dem Abend und den Dichtern", "tokens": ["doch", "dir", ",", "dem", "A\u00b7bend", "und", "den", "Dich\u00b7tern"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PPER", "$,", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "sind, unter rinnenden Gesichtern,", "tokens": ["sind", ",", "un\u00b7ter", "rin\u00b7nen\u00b7den", "Ge\u00b7sich\u00b7tern", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die dunkeln Dinge offenbar.", "tokens": ["die", "dun\u00b7keln", "Din\u00b7ge", "of\u00b7fen\u00b7bar", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.193": {"line.1": {"text": "Die K\u00f6nige der Welt sind alt", "tokens": ["Die", "K\u00f6\u00b7ni\u00b7ge", "der", "Welt", "sind", "alt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "und werden keine Erben haben.", "tokens": ["und", "wer\u00b7den", "kei\u00b7ne", "Er\u00b7ben", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PIAT", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die S\u00f6hne sterben schon als Knaben,", "tokens": ["Die", "S\u00f6h\u00b7ne", "ster\u00b7ben", "schon", "als", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "und ihre bleichen T\u00f6chter gaben", "tokens": ["und", "ih\u00b7re", "blei\u00b7chen", "T\u00f6ch\u00b7ter", "ga\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "die kranken Kronen der Gewalt.", "tokens": ["die", "kran\u00b7ken", "Kro\u00b7nen", "der", "Ge\u00b7walt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Der P\u00f6bel bricht sie klein zu Geld,", "tokens": ["Der", "P\u00f6\u00b7bel", "bricht", "sie", "klein", "zu", "Geld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "der zeitgem\u00e4\u00dfe Herr der Welt", "tokens": ["der", "zeit\u00b7ge\u00b7m\u00e4\u00b7\u00dfe", "Herr", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "dehnt sie im Feuer zu Maschinen,", "tokens": ["dehnt", "sie", "im", "Feu\u00b7er", "zu", "Ma\u00b7schi\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "++-+-+-+-", "measure": "iambic.tetra"}, "line.9": {"text": "die seinem Wollen grollend dienen;", "tokens": ["die", "sei\u00b7nem", "Wol\u00b7len", "grol\u00b7lend", "die\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "aber das Gl\u00fcck ist nicht mit ihnen.", "tokens": ["a\u00b7ber", "das", "Gl\u00fcck", "ist", "nicht", "mit", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKNEG", "APPR", "PPER", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Das Erz hat Heimweh. Und verlassen", "tokens": ["Das", "Erz", "hat", "Heim\u00b7weh", ".", "Und", "ver\u00b7las\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "NN", "$.", "KON", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "will es die M\u00fcnzen und die R\u00e4der,", "tokens": ["will", "es", "die", "M\u00fcn\u00b7zen", "und", "die", "R\u00e4\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.13": {"text": "die es ein kleines Leben lehren.", "tokens": ["die", "es", "ein", "klei\u00b7nes", "Le\u00b7ben", "leh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Und aus Fabriken und aus Kassen", "tokens": ["Und", "aus", "Fab\u00b7ri\u00b7ken", "und", "aus", "Kas\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "KON", "APPR", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "wird es zur\u00fcck in das Ge\u00e4der", "tokens": ["wird", "es", "zu\u00b7r\u00fcck", "in", "das", "Ge\u00b7\u00e4\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "PTKVZ", "APPR", "ART", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.16": {"text": "der aufgetanen Berge kehren,", "tokens": ["der", "auf\u00b7ge\u00b7ta\u00b7nen", "Ber\u00b7ge", "keh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.17": {"text": "die sich verschlie\u00dfen hinter ihm.", "tokens": ["die", "sich", "ver\u00b7schlie\u00b7\u00dfen", "hin\u00b7ter", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.194": {"line.1": {"text": "Alles wird wieder gro\u00df sein und gewaltig.", "tokens": ["Al\u00b7les", "wird", "wie\u00b7der", "gro\u00df", "sein", "und", "ge\u00b7wal\u00b7tig", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "ADV", "ADJD", "VAINF", "KON", "ADJD", "$."], "meter": "+--+--+--+-", "measure": "dactylic.tetra"}, "line.2": {"text": "Die Lande einfach und die Wasser faltig,", "tokens": ["Die", "Lan\u00b7de", "ein\u00b7fach", "und", "die", "Was\u00b7ser", "fal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die B\u00e4ume riesig und sehr klein die Mauern;", "tokens": ["die", "B\u00e4u\u00b7me", "rie\u00b7sig", "und", "sehr", "klein", "die", "Mau\u00b7ern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADV", "ADJD", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und in den T\u00e4lern, stark und vielgestaltig,", "tokens": ["und", "in", "den", "T\u00e4\u00b7lern", ",", "stark", "und", "viel\u00b7ge\u00b7stal\u00b7tig", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "ein Volk von Hirten und von Ackerbauern.", "tokens": ["ein", "Volk", "von", "Hir\u00b7ten", "und", "von", "A\u00b7cker\u00b7bau\u00b7ern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.195": {"line.1": {"text": "Und keine Kirchen, welche Gott umklammern", "tokens": ["Und", "kei\u00b7ne", "Kir\u00b7chen", ",", "wel\u00b7che", "Gott", "um\u00b7klam\u00b7mern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PIAT", "NN", "$,", "PWAT", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie einen Fl\u00fcchtling und ihn dann bejammern", "tokens": ["wie", "ei\u00b7nen", "Fl\u00fccht\u00b7ling", "und", "ihn", "dann", "be\u00b7jam\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ART", "NN", "KON", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wie ein gefangenes und wundes Tier, \u2013", "tokens": ["wie", "ein", "ge\u00b7fan\u00b7ge\u00b7nes", "und", "wun\u00b7des", "Tier", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "ADJA", "KON", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die H\u00e4user gastlich allen Einla\u00dfklopfern", "tokens": ["die", "H\u00e4u\u00b7ser", "gast\u00b7lich", "al\u00b7len", "Ein\u00b7la\u00df\u00b7klop\u00b7fern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADJD", "PIAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und ein Gef\u00fchl von unbegrenztem Opfern", "tokens": ["und", "ein", "Ge\u00b7f\u00fchl", "von", "un\u00b7be\u00b7grenz\u00b7tem", "Op\u00b7fern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "in allem Handeln und in dir und mir.", "tokens": ["in", "al\u00b7lem", "Han\u00b7deln", "und", "in", "dir", "und", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "APPR", "PPER", "KON", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.196": {"line.1": {"text": "Kein Jenseitswarten und kein Schaun nach dr\u00fcben,", "tokens": ["Kein", "Jen\u00b7seits\u00b7war\u00b7ten", "und", "kein", "Schaun", "nach", "dr\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "PIAT", "NN", "APPR", "ADV", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "nur Sehnsucht, auch den Tod nicht zu entweihn", "tokens": ["nur", "Sehn\u00b7sucht", ",", "auch", "den", "Tod", "nicht", "zu", "ent\u00b7weihn"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "$,", "ADV", "ART", "NN", "PTKNEG", "PTKZU", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und dienend sich am Irdischen zu \u00fcben,", "tokens": ["und", "die\u00b7nend", "sich", "am", "Ir\u00b7di\u00b7schen", "zu", "\u00fc\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "um seinen H\u00e4nden nicht mehr neu zu sein.", "tokens": ["um", "sei\u00b7nen", "H\u00e4n\u00b7den", "nicht", "mehr", "neu", "zu", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PTKNEG", "ADV", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.197": {"line.1": {"text": "Auch du wirst gro\u00df sein. Gr\u00f6\u00dfer noch als einer,", "tokens": ["Auch", "du", "wirst", "gro\u00df", "sein", ".", "Gr\u00f6\u00b7\u00dfer", "noch", "als", "ei\u00b7ner", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "VAFIN", "ADJD", "VAINF", "$.", "NN", "ADV", "KOUS", "PIS", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "der jetzt schon leben mu\u00df, dich sagen kann.", "tokens": ["der", "jetzt", "schon", "le\u00b7ben", "mu\u00df", ",", "dich", "sa\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADV", "VVINF", "VMFIN", "$,", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Viel ungew\u00f6hnlicher und ungemeiner", "tokens": ["Viel", "un\u00b7ge\u00b7w\u00f6hn\u00b7li\u00b7cher", "und", "un\u00b7ge\u00b7mei\u00b7ner"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und noch viel \u00e4lter als ein alter Mann.", "tokens": ["und", "noch", "viel", "\u00e4l\u00b7ter", "als", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.198": {"line.1": {"text": "Man wird dich f\u00fchlen: da\u00df ein Duften ginge", "tokens": ["Man", "wird", "dich", "f\u00fch\u00b7len", ":", "da\u00df", "ein", "Duf\u00b7ten", "gin\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "PPER", "VVFIN", "$.", "KOUS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "aus eines Gartens naher Gegenwart;", "tokens": ["aus", "ei\u00b7nes", "Gar\u00b7tens", "na\u00b7her", "Ge\u00b7gen\u00b7wart", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und wie ein Kranker seine liebsten Dinge", "tokens": ["und", "wie", "ein", "Kran\u00b7ker", "sei\u00b7ne", "liebs\u00b7ten", "Din\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "ART", "NN", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wird man dich lieben ahnungsvoll und zart.", "tokens": ["wird", "man", "dich", "lie\u00b7ben", "ah\u00b7nungs\u00b7voll", "und", "zart", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PPER", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "---+-+-+-+", "measure": "zehnsilber"}}, "stanza.199": {"line.1": {"text": "Es wird kein Beten geben, das die Leute", "tokens": ["Es", "wird", "kein", "Be\u00b7ten", "ge\u00b7ben", ",", "das", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "VVINF", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+---+-", "measure": "unknown.measure.tetra"}, "line.2": {"text": "zusammenschart. Du ", "tokens": ["zu\u00b7sam\u00b7men\u00b7schart", ".", "Du"], "token_info": ["word", "punct", "word"], "pos": ["VVPP", "$.", "PPER"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.3": {"text": "und wer dich f\u00fchlte und sich an dir freute,", "tokens": ["und", "wer", "dich", "f\u00fchl\u00b7te", "und", "sich", "an", "dir", "freu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVFIN", "KON", "PRF", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "wird wie der Einzige auf Erden sein:", "tokens": ["wird", "wie", "der", "Ein\u00b7zi\u00b7ge", "auf", "Er\u00b7den", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "KOKOM", "ART", "ADJA", "APPR", "NN", "VAINF", "$."], "meter": "-+-++--+-+", "measure": "iambic.penta.relaxed"}, "line.5": {"text": "Ein Ausgesto\u00dfener und ein Vereinter,", "tokens": ["Ein", "Aus\u00b7ge\u00b7sto\u00b7\u00dfe\u00b7ner", "und", "ein", "Ver\u00b7ein\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.6": {"text": "gesammelt und vergeudet doch zugleich;", "tokens": ["ge\u00b7sam\u00b7melt", "und", "ver\u00b7geu\u00b7det", "doch", "zu\u00b7gleich", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "ein L\u00e4chelnder und doch ein Halbverweinter,", "tokens": ["ein", "L\u00e4\u00b7cheln\u00b7der", "und", "doch", "ein", "Halb\u00b7ver\u00b7wein\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "klein wie ein Haus und m\u00e4chtig wie ein Reich.", "tokens": ["klein", "wie", "ein", "Haus", "und", "m\u00e4ch\u00b7tig", "wie", "ein", "Reich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "KON", "ADJD", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.200": {"line.1": {"text": "Es wird nicht Ruhe in den H\u00e4usern, sei's", "tokens": ["Es", "wird", "nicht", "Ru\u00b7he", "in", "den", "H\u00e4u\u00b7sern", ",", "sei's"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "NN", "APPR", "ART", "NN", "$,", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df einer stirbt und sie ihn weitertragen,", "tokens": ["da\u00df", "ei\u00b7ner", "stirbt", "und", "sie", "ihn", "wei\u00b7ter\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "VVFIN", "KON", "PPER", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "sei es da\u00df wer auf heimliches Gehei\u00df", "tokens": ["sei", "es", "da\u00df", "wer", "auf", "heim\u00b7li\u00b7ches", "Ge\u00b7hei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "KOUS", "PWS", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.4": {"text": "den Pilgerstock nimmt und den Pilgerkragen,", "tokens": ["den", "Pil\u00b7ger\u00b7stock", "nimmt", "und", "den", "Pil\u00b7ger\u00b7kra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "um in der Fremde nach dem Weg zu fragen,", "tokens": ["um", "in", "der", "Frem\u00b7de", "nach", "dem", "Weg", "zu", "fra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "auf welchem er dich warten wei\u00df.", "tokens": ["auf", "wel\u00b7chem", "er", "dich", "war\u00b7ten", "wei\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "PRF", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.201": {"line.1": {"text": "Die Stra\u00dfen werden derer niemals leer,", "tokens": ["Die", "Stra\u00b7\u00dfen", "wer\u00b7den", "de\u00b7rer", "nie\u00b7mals", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PDS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "die zu dir wollen wie zu jener Rose,", "tokens": ["die", "zu", "dir", "wol\u00b7len", "wie", "zu", "je\u00b7ner", "Ro\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "VMFIN", "KOKOM", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die alle tausend Jahre einmal bl\u00fcht.", "tokens": ["die", "al\u00b7le", "tau\u00b7send", "Jah\u00b7re", "ein\u00b7mal", "bl\u00fcht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "CARD", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Viel dunkles Volk und beinah Namenlose,", "tokens": ["Viel", "dunk\u00b7les", "Volk", "und", "bei\u00b7nah", "Na\u00b7men\u00b7lo\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "KON", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "und wenn sie dich erreichen, sind sie m\u00fcd.", "tokens": ["und", "wenn", "sie", "dich", "er\u00b7rei\u00b7chen", ",", "sind", "sie", "m\u00fcd", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PRF", "VVINF", "$,", "VAFIN", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.202": {"line.1": {"text": "Aber ich habe ihren Zug gesehn;", "tokens": ["A\u00b7ber", "ich", "ha\u00b7be", "ih\u00b7ren", "Zug", "ge\u00b7sehn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "PPOSAT", "NN", "VVPP", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "und glaube seither, da\u00df die Winde wehn", "tokens": ["und", "glau\u00b7be", "sei\u00b7ther", ",", "da\u00df", "die", "Win\u00b7de", "wehn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "$,", "KOUS", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "aus ihren M\u00e4nteln, welche sich bewegen,", "tokens": ["aus", "ih\u00b7ren", "M\u00e4n\u00b7teln", ",", "wel\u00b7che", "sich", "be\u00b7we\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und stille sind wenn sie sich niederlegen \u2013:", "tokens": ["und", "stil\u00b7le", "sind", "wenn", "sie", "sich", "nie\u00b7der\u00b7le\u00b7gen", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJA", "VAFIN", "KOUS", "PPER", "PRF", "VVINF", "$(", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "so gro\u00df war in den Ebenen ihr Gehn.", "tokens": ["so", "gro\u00df", "war", "in", "den", "E\u00b7be\u00b7nen", "ihr", "Gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}}, "stanza.203": {"line.1": {"text": "So m\u00f6cht ich zu dir gehn: von fremden Schwellen", "tokens": ["So", "m\u00f6cht", "ich", "zu", "dir", "gehn", ":", "von", "frem\u00b7den", "Schwel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$.", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Almosen sammelnd, die mich ungern n\u00e4hren.", "tokens": ["Al\u00b7mo\u00b7sen", "sam\u00b7melnd", ",", "die", "mich", "un\u00b7gern", "n\u00e4h\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PRELS", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und wenn der Wege wirrend viele w\u00e4ren,", "tokens": ["Und", "wenn", "der", "We\u00b7ge", "wir\u00b7rend", "vie\u00b7le", "w\u00e4\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "VAFIN", "PIS", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "so w\u00fcrd ich mich den \u00c4ltesten gesellen.", "tokens": ["so", "w\u00fcrd", "ich", "mich", "den", "\u00c4l\u00b7tes\u00b7ten", "ge\u00b7sel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich w\u00fcrde mich zu kleinen Greisen stellen,", "tokens": ["Ich", "w\u00fcr\u00b7de", "mich", "zu", "klei\u00b7nen", "Grei\u00b7sen", "stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und wenn sie gingen, schaut ich wie im Traum,", "tokens": ["und", "wenn", "sie", "gin\u00b7gen", ",", "schaut", "ich", "wie", "im", "Traum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "VVFIN", "PPER", "KOKOM", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "da\u00df ihre Kniee aus der B\u00e4rte Wellen", "tokens": ["da\u00df", "ih\u00b7re", "Kni\u00b7ee", "aus", "der", "B\u00e4r\u00b7te", "Wel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "wie Inseln tauchen, ohne Strauch und Baum.", "tokens": ["wie", "In\u00b7seln", "tau\u00b7chen", ",", "oh\u00b7ne", "Strauch", "und", "Baum", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "VVFIN", "$,", "KOUI", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.204": {"line.1": {"text": "Wir \u00fcberholten M\u00e4nner, welche blind", "tokens": ["Wir", "\u00fc\u00b7berh\u00b7ol\u00b7ten", "M\u00e4n\u00b7ner", ",", "wel\u00b7che", "blind"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit ihren Knaben wie mit Augen schauen,", "tokens": ["mit", "ih\u00b7ren", "Kna\u00b7ben", "wie", "mit", "Au\u00b7gen", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "KOKOM", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und Trinkende am Flu\u00df und m\u00fcde Frauen", "tokens": ["und", "Trin\u00b7ken\u00b7de", "am", "Flu\u00df", "und", "m\u00fc\u00b7de", "Frau\u00b7en"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "NN", "APPRART", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und viele Frauen, welche schwanger sind.", "tokens": ["und", "vie\u00b7le", "Frau\u00b7en", ",", "wel\u00b7che", "schwan\u00b7ger", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und alle waren mir so seltsam nah, \u2013", "tokens": ["Und", "al\u00b7le", "wa\u00b7ren", "mir", "so", "selt\u00b7sam", "nah", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIS", "VAFIN", "PPER", "ADV", "ADJD", "ADJD", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "als ob die M\u00e4nner einen Blutsverwandten,", "tokens": ["als", "ob", "die", "M\u00e4n\u00b7ner", "ei\u00b7nen", "Bluts\u00b7ver\u00b7wand\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "KOUS", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "die Frauen einen Freund in mir erkannten,", "tokens": ["die", "Frau\u00b7en", "ei\u00b7nen", "Freund", "in", "mir", "er\u00b7kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und auch die Hunde kamen, die ich sah.", "tokens": ["und", "auch", "die", "Hun\u00b7de", "ka\u00b7men", ",", "die", "ich", "sah", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VVFIN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.205": {"line.1": {"text": "Du Gott, ich m\u00f6chte viele Pilger sein,", "tokens": ["Du", "Gott", ",", "ich", "m\u00f6ch\u00b7te", "vie\u00b7le", "Pil\u00b7ger", "sein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PPER", "VMFIN", "PIAT", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "um so, ein langer Zug, zu dir zu gehn,", "tokens": ["um", "so", ",", "ein", "lan\u00b7ger", "Zug", ",", "zu", "dir", "zu", "gehn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "ADV", "$,", "ART", "ADJA", "NN", "$,", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und um ein gro\u00dfes St\u00fcck von dir zu sein:", "tokens": ["und", "um", "ein", "gro\u00b7\u00dfes", "St\u00fcck", "von", "dir", "zu", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "APPR", "PPER", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du Garten mit den lebenden Alleen.", "tokens": ["du", "Gar\u00b7ten", "mit", "den", "le\u00b7ben\u00b7den", "Al\u00b7leen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+---+", "measure": "zehnsilber"}, "line.5": {"text": "Wenn ich so gehe wie ich bin, allein, \u2013", "tokens": ["Wenn", "ich", "so", "ge\u00b7he", "wie", "ich", "bin", ",", "al\u00b7lein", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "VAFIN", "$,", "ADV", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wer merkt es denn? Wer ", "tokens": ["wer", "merkt", "es", "denn", "?", "Wer"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "$.", "PWS"], "meter": "-+--+", "measure": "iambic.di.chol"}, "line.7": {"text": "Wen rei\u00dft es hin? Wen regt es auf, und wen", "tokens": ["Wen", "rei\u00dft", "es", "hin", "?", "Wen", "regt", "es", "auf", ",", "und", "wen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "PTKVZ", "$.", "PWS", "VVFIN", "PPER", "PTKVZ", "$,", "KON", "PWS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "bekehrt es dir?", "tokens": ["be\u00b7kehrt", "es", "dir", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPER", "$."], "meter": "-+-+", "measure": "iambic.di"}, "line.9": {"text": "Als w\u00e4re nichts geschehn,", "tokens": ["Als", "w\u00e4\u00b7re", "nichts", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PIS", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.10": {"text": "\u2013 lachen sie weiter. Und da bin ich froh,", "tokens": ["\u2013", "la\u00b7chen", "sie", "wei\u00b7ter", ".", "Und", "da", "bin", "ich", "froh", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "PPER", "PTKVZ", "$.", "KON", "ADV", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.11": {"text": "da\u00df ich so gehe wie ich bin; denn so", "tokens": ["da\u00df", "ich", "so", "ge\u00b7he", "wie", "ich", "bin", ";", "denn", "so"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "KOKOM", "PPER", "VAFIN", "$.", "KON", "ADV"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "kann keiner von den Lachenden mich sehn.", "tokens": ["kann", "kei\u00b7ner", "von", "den", "La\u00b7chen\u00b7den", "mich", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PIS", "APPR", "ART", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.206": {"line.1": {"text": "Bei Tag bist du das H\u00f6rensagen,", "tokens": ["Bei", "Tag", "bist", "du", "das", "H\u00f6\u00b7ren\u00b7sa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VAFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "das fl\u00fcsternd um die Vielen flie\u00dft;", "tokens": ["das", "fl\u00fcs\u00b7ternd", "um", "die", "Vie\u00b7len", "flie\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVPP", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "die Stille nach dem Stundenschlagen,", "tokens": ["die", "Stil\u00b7le", "nach", "dem", "Stun\u00b7den\u00b7schla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "welche sich langsam wieder schlie\u00dft.", "tokens": ["wel\u00b7che", "sich", "lang\u00b7sam", "wie\u00b7der", "schlie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRELS", "PRF", "ADJD", "ADV", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}, "stanza.207": {"line.1": {"text": "Jemehr der Tag mit immer schw\u00e4chern", "tokens": ["Je\u00b7mehr", "der", "Tag", "mit", "im\u00b7mer", "schw\u00e4\u00b7chern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "APPR", "ADV", "VVINF"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Geb\u00e4rden sich nach Abend neigt,", "tokens": ["Ge\u00b7b\u00e4r\u00b7den", "sich", "nach", "A\u00b7bend", "neigt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "jemehr bist du, mein Gott. Es steigt", "tokens": ["je\u00b7mehr", "bist", "du", ",", "mein", "Gott", ".", "Es", "steigt"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$.", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "dein Reich wie Rauch aus allen D\u00e4chern.", "tokens": ["dein", "Reich", "wie", "Rauch", "aus", "al\u00b7len", "D\u00e4\u00b7chern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KOKOM", "NN", "APPR", "PIAT", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.208": {"line.1": {"text": "Ein Pilgermorgen. Von den harten Lagern,", "tokens": ["Ein", "Pil\u00b7ger\u00b7mor\u00b7gen", ".", "Von", "den", "har\u00b7ten", "La\u00b7gern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "auf das ein jeder wie vergiftet fiel,", "tokens": ["auf", "das", "ein", "je\u00b7der", "wie", "ver\u00b7gif\u00b7tet", "fiel", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "PIAT", "KOKOM", "VVPP", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "erhebt sich bei dem ersten Glockenspiel", "tokens": ["er\u00b7hebt", "sich", "bei", "dem", "ers\u00b7ten", "Glo\u00b7cken\u00b7spiel"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "ein Volk von hagern Morgensegen-Sagern,", "tokens": ["ein", "Volk", "von", "ha\u00b7gern", "Mor\u00b7gen\u00b7se\u00b7gen\u00b7Sa\u00b7gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "auf das die fr\u00fche Sonne niederbrennt:", "tokens": ["auf", "das", "die", "fr\u00fc\u00b7he", "Son\u00b7ne", "nie\u00b7der\u00b7brennt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.209": {"line.1": {"text": "B\u00e4rtige M\u00e4nner, welche sich verneigen,", "tokens": ["B\u00e4r\u00b7ti\u00b7ge", "M\u00e4n\u00b7ner", ",", "wel\u00b7che", "sich", "ver\u00b7nei\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "PRF", "VVPP", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.2": {"text": "Kinder, die ernsthaft aus den Pelzen steigen,", "tokens": ["Kin\u00b7der", ",", "die", "ernst\u00b7haft", "aus", "den", "Pel\u00b7zen", "stei\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und in den M\u00e4nteln, schwer von ihrem Schweigen,", "tokens": ["und", "in", "den", "M\u00e4n\u00b7teln", ",", "schwer", "von", "ih\u00b7rem", "Schwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "$,", "ADJD", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "die braunen Fraun von Tiflis und Taschkent.", "tokens": ["die", "brau\u00b7nen", "Fraun", "von", "Tif\u00b7lis", "und", "Taschkent", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Christen mit den Geb\u00e4rden des Islam", "tokens": ["Chris\u00b7ten", "mit", "den", "Ge\u00b7b\u00e4r\u00b7den", "des", "Is\u00b7lam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "APPR", "ART", "NN", "ART", "NN"], "meter": "+-++-+-+-+", "measure": "zehnsilber"}, "line.6": {"text": "sind um die Brunnen, halten ihre H\u00e4nde", "tokens": ["sind", "um", "die", "Brun\u00b7nen", ",", "hal\u00b7ten", "ih\u00b7re", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "wie flache Schalen hin, wie Gegenst\u00e4nde,", "tokens": ["wie", "fla\u00b7che", "Scha\u00b7len", "hin", ",", "wie", "Ge\u00b7gen\u00b7st\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "PTKVZ", "$,", "PWAV", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "in die die Flut wie eine Seele kam.", "tokens": ["in", "die", "die", "Flut", "wie", "ei\u00b7ne", "See\u00b7le", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.210": {"line.1": {"text": "Sie neigen das Gesicht hinein und trinken,", "tokens": ["Sie", "nei\u00b7gen", "das", "Ge\u00b7sicht", "hin\u00b7ein", "und", "trin\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "KON", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "rei\u00dfen die Kleider auf mit ihrer Linken", "tokens": ["rei\u00b7\u00dfen", "die", "Klei\u00b7der", "auf", "mit", "ih\u00b7rer", "Lin\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPR", "PPOSAT", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.3": {"text": "und halten sich das Wasser an die Brust", "tokens": ["und", "hal\u00b7ten", "sich", "das", "Was\u00b7ser", "an", "die", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "als w\u00e4rs ein k\u00fchles weinendes Gesicht,", "tokens": ["als", "w\u00e4rs", "ein", "k\u00fch\u00b7les", "wei\u00b7nen\u00b7des", "Ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOKOM", "VAFIN", "ART", "ADJA", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das von den Schmerzen auf der Erde spricht.", "tokens": ["das", "von", "den", "Schmer\u00b7zen", "auf", "der", "Er\u00b7de", "spricht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.211": {"line.1": {"text": "Und diese Schmerzen stehen rings umher", "tokens": ["Und", "die\u00b7se", "Schmer\u00b7zen", "ste\u00b7hen", "rings", "um\u00b7her"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDAT", "NN", "VVFIN", "ADV", "PTKVZ"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "mit welken Augen; und du wei\u00dft nicht wer", "tokens": ["mit", "wel\u00b7ken", "Au\u00b7gen", ";", "und", "du", "wei\u00dft", "nicht", "wer"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PWAT", "NN", "$.", "KON", "PPER", "VVFIN", "PTKNEG", "PWS"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sie sind und waren. Knechte oder Bauern,", "tokens": ["sie", "sind", "und", "wa\u00b7ren", ".", "Knech\u00b7te", "o\u00b7der", "Bau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "KON", "VAFIN", "$.", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "vielleicht Kaufleute, welche Wohlstand sahn,", "tokens": ["viel\u00b7leicht", "Kauf\u00b7leu\u00b7te", ",", "wel\u00b7che", "Wohl\u00b7stand", "sahn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$,", "PWAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "vielleicht auch laue M\u00f6nche, die nicht dauern,", "tokens": ["viel\u00b7leicht", "auch", "lau\u00b7e", "M\u00f6n\u00b7che", ",", "die", "nicht", "dau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJA", "NN", "$,", "PRELS", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "und Diebe, die auf die Versuchung lauern,", "tokens": ["und", "Die\u00b7be", ",", "die", "auf", "die", "Ver\u00b7su\u00b7chung", "lau\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.7": {"text": "offene M\u00e4dchen, die verk\u00fcmmert kauern,", "tokens": ["of\u00b7fe\u00b7ne", "M\u00e4d\u00b7chen", ",", "die", "ver\u00b7k\u00fcm\u00b7mert", "kau\u00b7ern", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "PRELS", "ADJD", "VVINF", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.8": {"text": "und Irrende in einem Wald von Wahn \u2013 :", "tokens": ["und", "Ir\u00b7ren\u00b7de", "in", "ei\u00b7nem", "Wald", "von", "Wahn", "\u2013", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NN", "APPR", "ART", "NN", "APPR", "NN", "$(", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "alle wie F\u00fcrsten, die in tiefem Trauern", "tokens": ["al\u00b7le", "wie", "F\u00fcrs\u00b7ten", ",", "die", "in", "tie\u00b7fem", "Trau\u00b7ern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "NN", "$,", "PRELS", "APPR", "ADJA", "NN"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.10": {"text": "die \u00dcberfl\u00fcsse von sich abgetan.", "tokens": ["die", "\u00dc\u00b7berf\u00b7l\u00fcs\u00b7se", "von", "sich", "ab\u00b7ge\u00b7tan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "Wie Weise alle, welche viel erfahren,", "tokens": ["Wie", "Wei\u00b7se", "al\u00b7le", ",", "wel\u00b7che", "viel", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PIS", "$,", "PRELS", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "Erw\u00e4hlte, welche in der W\u00fcste waren,", "tokens": ["Er\u00b7w\u00e4hl\u00b7te", ",", "wel\u00b7che", "in", "der", "W\u00fcs\u00b7te", "wa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRELS", "APPR", "ART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "wo Gott sie n\u00e4hrte durch ein fremdes Tier;", "tokens": ["wo", "Gott", "sie", "n\u00e4hr\u00b7te", "durch", "ein", "frem\u00b7des", "Tier", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "PPER", "VVFIN", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Einsame, die durch Ebenen gegangen", "tokens": ["Ein\u00b7sa\u00b7me", ",", "die", "durch", "E\u00b7be\u00b7nen", "ge\u00b7gan\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "PRELS", "APPR", "NN", "VVPP"], "meter": "+----+---+-", "measure": "dactylic.init"}, "line.15": {"text": "mit vielen Winden an den dunklen Wangen,", "tokens": ["mit", "vie\u00b7len", "Win\u00b7den", "an", "den", "dunk\u00b7len", "Wan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "von einer Sehnsucht f\u00fcrchtig und befangen", "tokens": ["von", "ei\u00b7ner", "Sehn\u00b7sucht", "f\u00fcrch\u00b7tig", "und", "be\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJD", "KON", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "und doch so wundersam erh\u00f6ht von ihr.", "tokens": ["und", "doch", "so", "wun\u00b7der\u00b7sam", "er\u00b7h\u00f6ht", "von", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADV", "ADJD", "VVPP", "APPR", "PPOSAT", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "Gel\u00f6ste aus dem Alltag, eingeschaltet", "tokens": ["Ge\u00b7l\u00f6s\u00b7te", "aus", "dem", "All\u00b7tag", ",", "ein\u00b7ge\u00b7schal\u00b7tet"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["NN", "APPR", "ART", "NN", "$,", "VVPP"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.19": {"text": "in gro\u00dfe Orgeln und in Chorgesang,", "tokens": ["in", "gro\u00b7\u00dfe", "Or\u00b7geln", "und", "in", "Chor\u00b7ge\u00b7sang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KON", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "und Knieende, wie Steigende gestaltet;", "tokens": ["und", "Kni\u00b7e\u00b7en\u00b7de", ",", "wie", "Stei\u00b7gen\u00b7de", "ge\u00b7stal\u00b7tet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "PWAV", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Fahnen mit Bildern, welche lang", "tokens": ["Fah\u00b7nen", "mit", "Bil\u00b7dern", ",", "wel\u00b7che", "lang"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["NN", "APPR", "NN", "$,", "PRELS", "ADJD"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.22": {"text": "verborgen waren und zusammgefaltet:", "tokens": ["ver\u00b7bor\u00b7gen", "wa\u00b7ren", "und", "zu\u00b7samm\u00b7ge\u00b7fal\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.212": {"line.1": {"text": "Jetzt h\u00e4ngen sie sich langsam wieder aus.", "tokens": ["Jetzt", "h\u00e4n\u00b7gen", "sie", "sich", "lang\u00b7sam", "wie\u00b7der", "aus", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADJD", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.213": {"line.1": {"text": "Und manche stehn und schaun nach einem Haus,", "tokens": ["Und", "man\u00b7che", "stehn", "und", "schaun", "nach", "ei\u00b7nem", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVINF", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "darin die Pilger, welche krank sind, wohnen;", "tokens": ["da\u00b7rin", "die", "Pil\u00b7ger", ",", "wel\u00b7che", "krank", "sind", ",", "woh\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "denn eben wand sich dort ein M\u00f6nch heraus,", "tokens": ["denn", "e\u00b7ben", "wand", "sich", "dort", "ein", "M\u00f6nch", "he\u00b7raus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "die Haare schlaff und die Sutane kraus,", "tokens": ["die", "Haa\u00b7re", "schlaff", "und", "die", "Su\u00b7ta\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "das schattige Gesicht voll kranker Blaus", "tokens": ["das", "schat\u00b7ti\u00b7ge", "Ge\u00b7sicht", "voll", "kran\u00b7ker", "Blaus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "und ganz verdunkelt von D\u00e4monen.", "tokens": ["und", "ganz", "ver\u00b7dun\u00b7kelt", "von", "D\u00e4\u00b7mo\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "APPR", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.214": {"line.1": {"text": "Er neigte sich, als br\u00e4ch er sich entzwei,", "tokens": ["Er", "neig\u00b7te", "sich", ",", "als", "br\u00e4ch", "er", "sich", "ent\u00b7zwei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "$,", "KOUS", "NN", "PPER", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und warf sich in zwei St\u00fccken auf die Erde,", "tokens": ["und", "warf", "sich", "in", "zwei", "St\u00fc\u00b7cken", "auf", "die", "Er\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "APPR", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "die jetzt an seinem Munde wie ein Schrei", "tokens": ["die", "jetzt", "an", "sei\u00b7nem", "Mun\u00b7de", "wie", "ein", "Schrei"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "PPOSAT", "NN", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "zu h\u00e4ngen schien und so als sei", "tokens": ["zu", "h\u00e4n\u00b7gen", "schien", "und", "so", "als", "sei"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PTKZU", "VVINF", "VVFIN", "KON", "ADV", "KOKOM", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "sie seiner Arme wachsende Geb\u00e4rde.", "tokens": ["sie", "sei\u00b7ner", "Ar\u00b7me", "wach\u00b7sen\u00b7de", "Ge\u00b7b\u00e4r\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.215": {"line.1": {"text": "Und langsam ging sein Fall an ihm vorbei.", "tokens": ["Und", "lang\u00b7sam", "ging", "sein", "Fall", "an", "ihm", "vor\u00b7bei", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPOSAT", "NN", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er flog empor, als ob er Fl\u00fcgel sp\u00fcrte,", "tokens": ["Er", "flog", "em\u00b7por", ",", "als", "ob", "er", "Fl\u00fc\u00b7gel", "sp\u00fcr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "KOKOM", "KOUS", "PPER", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und sein erleichtertes Gef\u00fchl verf\u00fchrte", "tokens": ["und", "sein", "er\u00b7leich\u00b7ter\u00b7tes", "Ge\u00b7f\u00fchl", "ver\u00b7f\u00fchr\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "ihn zu dem Glauben seiner Vogelwerdung.", "tokens": ["ihn", "zu", "dem", "Glau\u00b7ben", "sei\u00b7ner", "Vo\u00b7gel\u00b7wer\u00b7dung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Er hing in seinen magern Armen schmal,", "tokens": ["Er", "hing", "in", "sei\u00b7nen", "ma\u00b7gern", "Ar\u00b7men", "schmal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "ADJA", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "wie eine schiefgeschobne Marionette,", "tokens": ["wie", "ei\u00b7ne", "schief\u00b7ge\u00b7schob\u00b7ne", "Ma\u00b7ri\u00b7o\u00b7net\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "und glaubte, da\u00df er gro\u00dfe Schwingen h\u00e4tte", "tokens": ["und", "glaub\u00b7te", ",", "da\u00df", "er", "gro\u00b7\u00dfe", "Schwin\u00b7gen", "h\u00e4t\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "PPER", "ADJA", "NN", "VAFIN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "und da\u00df die Welt schon lange wie ein Tal", "tokens": ["und", "da\u00df", "die", "Welt", "schon", "lan\u00b7ge", "wie", "ein", "Tal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ADV", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "sich ferne unter seinen F\u00fc\u00dfen gl\u00e4tte.", "tokens": ["sich", "fer\u00b7ne", "un\u00b7ter", "sei\u00b7nen", "F\u00fc\u00b7\u00dfen", "gl\u00e4t\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Ungl\u00e4ubig sah er sich mit einem Mal", "tokens": ["Un\u00b7gl\u00e4u\u00b7big", "sah", "er", "sich", "mit", "ei\u00b7nem", "Mal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN"], "meter": "---+-+-+-+", "measure": "zehnsilber"}, "line.11": {"text": "herabgelassen auf die fremde St\u00e4tte", "tokens": ["her\u00b7ab\u00b7ge\u00b7las\u00b7sen", "auf", "die", "frem\u00b7de", "St\u00e4t\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "und auf den gr\u00fcnen Meergrund seiner Qual.", "tokens": ["und", "auf", "den", "gr\u00fc\u00b7nen", "Meer\u00b7grund", "sei\u00b7ner", "Qual", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "ADJA", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "Und war ein Fisch und wand sich schlank und schwamm", "tokens": ["Und", "war", "ein", "Fisch", "und", "wand", "sich", "schlank", "und", "schwamm"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "KON", "VVFIN", "PRF", "ADJD", "KON", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "durch tiefes Wasser, still und silbergrau,", "tokens": ["durch", "tie\u00b7fes", "Was\u00b7ser", ",", "still", "und", "sil\u00b7ber\u00b7grau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "sah Quallen hangen am Korallenstamm", "tokens": ["sah", "Qual\u00b7len", "han\u00b7gen", "am", "Ko\u00b7ral\u00b7len\u00b7stamm"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "NN", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "und sah die Haare einer Meerjungfrau,", "tokens": ["und", "sah", "die", "Haa\u00b7re", "ei\u00b7ner", "Meer\u00b7jung\u00b7frau", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "durch die das Wasser rauschte wie ein Kamm.", "tokens": ["durch", "die", "das", "Was\u00b7ser", "rauschte", "wie", "ein", "Kamm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ART", "NN", "VVFIN", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.18": {"text": "Und kam zu Land und war ein Br\u00e4utigam", "tokens": ["Und", "kam", "zu", "Land", "und", "war", "ein", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "VAFIN", "ART", "NE"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "bei einer Toten, wie man ihn erw\u00e4hlt", "tokens": ["bei", "ei\u00b7ner", "To\u00b7ten", ",", "wie", "man", "ihn", "er\u00b7w\u00e4hlt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "$,", "PWAV", "PIS", "PPER", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "damit kein M\u00e4dchen fremd und unverm\u00e4hlt", "tokens": ["da\u00b7mit", "kein", "M\u00e4d\u00b7chen", "fremd", "und", "un\u00b7ver\u00b7m\u00e4hlt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "PIAT", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.21": {"text": "des Paradieses Wiesenland beschritte.", "tokens": ["des", "Pa\u00b7ra\u00b7die\u00b7ses", "Wie\u00b7sen\u00b7land", "be\u00b7schrit\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.216": {"line.1": {"text": "Er folgte ihr und ordnete die Tritte", "tokens": ["Er", "folg\u00b7te", "ihr", "und", "ord\u00b7ne\u00b7te", "die", "Trit\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PPER", "KON", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und tanzte rund, sie immer in der Mitte,", "tokens": ["und", "tanz\u00b7te", "rund", ",", "sie", "im\u00b7mer", "in", "der", "Mit\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJD", "$,", "PPER", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "und seine Arme tanzten rund um ihn.", "tokens": ["und", "sei\u00b7ne", "Ar\u00b7me", "tanz\u00b7ten", "rund", "um", "ihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Dann horchte er, als w\u00e4re eine dritte", "tokens": ["Dann", "horch\u00b7te", "er", ",", "als", "w\u00e4\u00b7re", "ei\u00b7ne", "drit\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOKOM", "VAFIN", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Gestalt ganz sachte in das Spiel getreten,", "tokens": ["Ge\u00b7stalt", "ganz", "sach\u00b7te", "in", "das", "Spiel", "ge\u00b7tre\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "die diesem Tanzen nicht zu glauben schien.", "tokens": ["die", "die\u00b7sem", "Tan\u00b7zen", "nicht", "zu", "glau\u00b7ben", "schien", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "Und da erkannte er: jetzt mu\u00dft du beten;", "tokens": ["Und", "da", "er\u00b7kann\u00b7te", "er", ":", "jetzt", "mu\u00dft", "du", "be\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "ADV", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "denn dieser ist es, welcher den Propheten", "tokens": ["denn", "die\u00b7ser", "ist", "es", ",", "wel\u00b7cher", "den", "Pro\u00b7phe\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PDS", "VAFIN", "PPER", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "wie eine gro\u00dfe Krone sich verliehn.", "tokens": ["wie", "ei\u00b7ne", "gro\u00b7\u00dfe", "Kro\u00b7ne", "sich", "ver\u00b7liehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "ADJA", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Wir halten ihn, um den wir t\u00e4glich flehten,", "tokens": ["Wir", "hal\u00b7ten", "ihn", ",", "um", "den", "wir", "t\u00e4g\u00b7lich", "fleh\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "KOUI", "ART", "PPER", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "wir ernten ihn, den einstens Ausges\u00e4eten,", "tokens": ["wir", "ern\u00b7ten", "ihn", ",", "den", "eins\u00b7tens", "Aus\u00b7ge\u00b7s\u00e4e\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.12": {"text": "und kehren heim mit ruhenden Ger\u00e4ten", "tokens": ["und", "keh\u00b7ren", "heim", "mit", "ru\u00b7hen\u00b7den", "Ge\u00b7r\u00e4\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PTKVZ", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "in langen Reihen wie in Melodien.", "tokens": ["in", "lan\u00b7gen", "Rei\u00b7hen", "wie", "in", "Me\u00b7lo\u00b7dien", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "KOKOM", "APPR", "NE", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Und er verneigte sich ergriffen, tief.", "tokens": ["Und", "er", "ver\u00b7neig\u00b7te", "sich", "er\u00b7grif\u00b7fen", ",", "tief", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "VVPP", "$,", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Aber der Alte war, als ob er schliefe,", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "war", ",", "als", "ob", "er", "schlie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "$,", "KOKOM", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+--+-+-+-+-", "measure": "iambic.penta.invert"}, "line.16": {"text": "und sah es nicht, obwohl sein Aug nicht schlief.", "tokens": ["und", "sah", "es", "nicht", ",", "ob\u00b7wohl", "sein", "Aug", "nicht", "schlief", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPOSAT", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.217": {"line.1": {"text": "Und er verneigte sich in solche Tiefe,", "tokens": ["Und", "er", "ver\u00b7neig\u00b7te", "sich", "in", "sol\u00b7che", "Tie\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PRF", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "da\u00df ihm ein Zittern durch die Glieder lief.", "tokens": ["da\u00df", "ihm", "ein", "Zit\u00b7tern", "durch", "die", "Glie\u00b7der", "lief", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aber der Alte ward es nicht gewahr.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "ward", "es", "nicht", "ge\u00b7wahr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.218": {"line.1": {"text": "Da fa\u00dfte sich der kranke M\u00f6nch am Haar", "tokens": ["Da", "fa\u00df\u00b7te", "sich", "der", "kran\u00b7ke", "M\u00f6nch", "am", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "ADJA", "NN", "APPRART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und schlug sich wie ein Kleid an einen Baum.", "tokens": ["und", "schlug", "sich", "wie", "ein", "Kleid", "an", "ei\u00b7nen", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "KOKOM", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Aber der Alte stand und sah es kaum.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "stand", "und", "sah", "es", "kaum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "KON", "VVFIN", "PPER", "ADV", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.219": {"line.1": {"text": "Da nahm der kranke M\u00f6nch sich in die H\u00e4nde", "tokens": ["Da", "nahm", "der", "kran\u00b7ke", "M\u00f6nch", "sich", "in", "die", "H\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "wie man ein Richtschwert in die H\u00e4nde nimmt,", "tokens": ["wie", "man", "ein", "Richt\u00b7schwert", "in", "die", "H\u00e4n\u00b7de", "nimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "und hieb und hieb, verwundete die W\u00e4nde", "tokens": ["und", "hieb", "und", "hieb", ",", "ver\u00b7wun\u00b7de\u00b7te", "die", "W\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$,", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "und stie\u00df sich endlich in den Grund ergrimmt.", "tokens": ["und", "stie\u00df", "sich", "end\u00b7lich", "in", "den", "Grund", "er\u00b7grimmt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Aber der Alte blickte unbestimmt.", "tokens": ["A\u00b7ber", "der", "Al\u00b7te", "blick\u00b7te", "un\u00b7be\u00b7stimmt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "ADJD", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.220": {"line.1": {"text": "Da ri\u00df der M\u00f6nch sein Kleid sich ab wie Rinde", "tokens": ["Da", "ri\u00df", "der", "M\u00f6nch", "sein", "Kleid", "sich", "ab", "wie", "Rin\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPOSAT", "NN", "PRF", "PTKVZ", "KOKOM", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und knieend hielt er es dem Alten hin.", "tokens": ["und", "kni\u00b7e\u00b7end", "hielt", "er", "es", "dem", "Al\u00b7ten", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "PPER", "ART", "NN", "PTKVZ", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.221": {"line.1": {"text": "Und sieh: er kam. Kam wie zu einem Kinde", "tokens": ["Und", "sieh", ":", "er", "kam", ".", "Kam", "wie", "zu", "ei\u00b7nem", "Kin\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVIMP", "$.", "PPER", "VVFIN", "$.", "NE", "KOKOM", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und sagte sanft: Wei\u00dft du auch ", "tokens": ["und", "sag\u00b7te", "sanft", ":", "Wei\u00dft", "du", "auch"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVFIN", "ADJD", "$.", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das wu\u00dfte er. Und legte sich gelinde", "tokens": ["Das", "wu\u00df\u00b7te", "er", ".", "Und", "leg\u00b7te", "sich", "ge\u00b7lin\u00b7de"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "$.", "KON", "VVFIN", "PRF", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "dem Greis wie eine Geige unters Kinn.", "tokens": ["dem", "Greis", "wie", "ei\u00b7ne", "Gei\u00b7ge", "un\u00b7ters", "Kinn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KOKOM", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.222": {"line.1": {"text": "Jetzt reifen schon die roten Berberitzen,", "tokens": ["Jetzt", "rei\u00b7fen", "schon", "die", "ro\u00b7ten", "Ber\u00b7be\u00b7rit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "alternde Astern atmen schwach im Beet.", "tokens": ["al\u00b7tern\u00b7de", "As\u00b7tern", "at\u00b7men", "schwach", "im", "Beet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "VVFIN", "APPRART", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.3": {"text": "Wer jetzt nicht reich ist, da der Sommer geht,", "tokens": ["Wer", "jetzt", "nicht", "reich", "ist", ",", "da", "der", "Som\u00b7mer", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "wird immer warten und sich nie besitzen.", "tokens": ["wird", "im\u00b7mer", "war\u00b7ten", "und", "sich", "nie", "be\u00b7sit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "VVINF", "KON", "PRF", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.223": {"line.1": {"text": "Wer jetzt nicht seine Augen schlie\u00dfen kann,", "tokens": ["Wer", "jetzt", "nicht", "sei\u00b7ne", "Au\u00b7gen", "schlie\u00b7\u00dfen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PTKNEG", "PPOSAT", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "gewi\u00df, da\u00df eine F\u00fclle von Gesichten", "tokens": ["ge\u00b7wi\u00df", ",", "da\u00df", "ei\u00b7ne", "F\u00fcl\u00b7le", "von", "Ge\u00b7sich\u00b7ten"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "KOUS", "ART", "NN", "APPR", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "in ihm nur wartet bis die Nacht begann,", "tokens": ["in", "ihm", "nur", "war\u00b7tet", "bis", "die", "Nacht", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ADV", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "um sich in seinem Dunkel aufzurichten: \u2013", "tokens": ["um", "sich", "in", "sei\u00b7nem", "Dun\u00b7kel", "auf\u00b7zu\u00b7rich\u00b7ten", ":", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PRF", "APPR", "PPOSAT", "NN", "VVIZU", "$.", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "der ist vergangen wie ein alter Mann.", "tokens": ["der", "ist", "ver\u00b7gan\u00b7gen", "wie", "ein", "al\u00b7ter", "Mann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "VVPP", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.224": {"line.1": {"text": "Dem kommt nichts mehr, dem st\u00f6\u00dft kein Tag mehr zu,", "tokens": ["Dem", "kommt", "nichts", "mehr", ",", "dem", "st\u00f6\u00dft", "kein", "Tag", "mehr", "zu", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PIS", "ADV", "$,", "PRELS", "VVFIN", "PIAT", "NN", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "und alles l\u00fcgt ihn an, was ihm geschieht;", "tokens": ["und", "al\u00b7les", "l\u00fcgt", "ihn", "an", ",", "was", "ihm", "ge\u00b7schieht", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "PPER", "PTKVZ", "$,", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "auch du, mein Gott. Und wie ein Stein bist du,", "tokens": ["auch", "du", ",", "mein", "Gott", ".", "Und", "wie", "ein", "Stein", "bist", "du", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "PPOSAT", "NN", "$.", "KON", "PWAV", "ART", "NN", "VAFIN", "PPER", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "welcher ihn t\u00e4glich in die Tiefe zieht.", "tokens": ["wel\u00b7cher", "ihn", "t\u00e4g\u00b7lich", "in", "die", "Tie\u00b7fe", "zieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADJD", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}}, "stanza.225": {"line.1": {"text": "Du mu\u00dft nicht bangen, Gott. Sie sagen: ", "tokens": ["Du", "mu\u00dft", "nicht", "ban\u00b7gen", ",", "Gott", ".", "Sie", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PTKNEG", "VVINF", "$,", "NN", "$.", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "zu allen Dingen, die geduldig sind.", "tokens": ["zu", "al\u00b7len", "Din\u00b7gen", ",", "die", "ge\u00b7dul\u00b7dig", "sind", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PRELS", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Sie sind wie Wind, der an die Zweige streift", "tokens": ["Sie", "sind", "wie", "Wind", ",", "der", "an", "die", "Zwei\u00b7ge", "streift"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "KOKOM", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "und sagt: ", "tokens": ["und", "sagt", ":"], "token_info": ["word", "word", "punct"], "pos": ["KON", "VVFIN", "$."], "meter": "-+", "measure": "iambic.single"}}, "stanza.226": {"line.1": {"text": "Sie merken kaum,", "tokens": ["Sie", "mer\u00b7ken", "kaum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "wie alles gl\u00fcht, was ihre Hand ergreift, \u2013", "tokens": ["wie", "al\u00b7les", "gl\u00fcht", ",", "was", "ih\u00b7re", "Hand", "er\u00b7greift", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "PIS", "VVFIN", "$,", "PRELS", "PPOSAT", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie's auch an seinem letzten Saum", "tokens": ["so", "da\u00df", "sie's", "auch", "an", "sei\u00b7nem", "letz\u00b7ten", "Saum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "PPER", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "nicht halten k\u00f6nnten ohne zu verbrennen.", "tokens": ["nicht", "hal\u00b7ten", "k\u00f6nn\u00b7ten", "oh\u00b7ne", "zu", "ver\u00b7bren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVINF", "VMFIN", "KOUI", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.227": {"line.1": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "den F\u00fcrsten Freund nennt im Gespr\u00e4ch mit Bauern,", "tokens": ["den", "F\u00fcrs\u00b7ten", "Freund", "nennt", "im", "Ge\u00b7spr\u00e4ch", "mit", "Bau\u00b7ern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPRART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "wenn dieser F\u00fcrst sehr gro\u00df ist und \u2013 sehr fern.", "tokens": ["wenn", "die\u00b7ser", "F\u00fcrst", "sehr", "gro\u00df", "ist", "und", "\u2013", "sehr", "fern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "ADV", "ADJD", "VAFIN", "KON", "$(", "ADV", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "und kennen gar nicht ihres Hauses Herrn.", "tokens": ["und", "ken\u00b7nen", "gar", "nicht", "ih\u00b7res", "Hau\u00b7ses", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PTKNEG", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Sie sagen ", "tokens": ["Sie", "sa\u00b7gen"], "token_info": ["word", "word"], "pos": ["PPER", "VVINF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "wenn jedes Ding sich schlie\u00dft, dem sie sich nahn,", "tokens": ["wenn", "je\u00b7des", "Ding", "sich", "schlie\u00dft", ",", "dem", "sie", "sich", "nahn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "PRF", "VVFIN", "$,", "PRELS", "PPER", "PRF", "ADJA", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "so wie ein abgeschmackter Charlatan", "tokens": ["so", "wie", "ein", "ab\u00b7ge\u00b7schmack\u00b7ter", "Char\u00b7la\u00b7tan"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "vielleicht die Sonne sein nennt und den Blitz.", "tokens": ["viel\u00b7leicht", "die", "Son\u00b7ne", "sein", "nennt", "und", "den", "Blitz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VAINF", "VVFIN", "KON", "ART", "NN", "$."], "meter": "-+-+--++-+", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "So sagen sie: mein Leben, meine Frau,", "tokens": ["So", "sa\u00b7gen", "sie", ":", "mein", "Le\u00b7ben", ",", "mei\u00b7ne", "Frau", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.11": {"text": "mein Hund, mein Kind, und wissen doch genau,", "tokens": ["mein", "Hund", ",", "mein", "Kind", ",", "und", "wis\u00b7sen", "doch", "ge\u00b7nau", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "KON", "VVFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.12": {"text": "da\u00df alles: Leben, Frau und Hund und Kind", "tokens": ["da\u00df", "al\u00b7les", ":", "Le\u00b7ben", ",", "Frau", "und", "Hund", "und", "Kind"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "$.", "NN", "$,", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.13": {"text": "fremde Gebilde sind, daran sie blind", "tokens": ["frem\u00b7de", "Ge\u00b7bil\u00b7de", "sind", ",", "da\u00b7ran", "sie", "blind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "VAFIN", "$,", "PAV", "PPER", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.14": {"text": "mit ihren ausgestreckten H\u00e4nden sto\u00dfen.", "tokens": ["mit", "ih\u00b7ren", "aus\u00b7ge\u00b7streck\u00b7ten", "H\u00e4n\u00b7den", "sto\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Gewi\u00dfheit freilich ist das nur den Gro\u00dfen,", "tokens": ["Ge\u00b7wi\u00df\u00b7heit", "frei\u00b7lich", "ist", "das", "nur", "den", "Gro\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "PDS", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.16": {"text": "die sich nach Augen sehnen. Denn die Andern", "tokens": ["die", "sich", "nach", "Au\u00b7gen", "seh\u00b7nen", ".", "Denn", "die", "An\u00b7dern"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PRELS", "PRF", "APPR", "NN", "VVINF", "$.", "KON", "ART", "ADJA"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.17": {"text": "mit keinem Dinge rings zusammenh\u00e4ngt,", "tokens": ["mit", "kei\u00b7nem", "Din\u00b7ge", "rings", "zu\u00b7sam\u00b7men\u00b7h\u00e4ngt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.18": {"text": "da\u00df sie, von ihrer Habe fortgedr\u00e4ngt,", "tokens": ["da\u00df", "sie", ",", "von", "ih\u00b7rer", "Ha\u00b7be", "fort\u00b7ge\u00b7dr\u00e4ngt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.19": {"text": "nicht anerkannt von ihrem Eigentume", "tokens": ["nicht", "an\u00b7er\u00b7kannt", "von", "ih\u00b7rem", "Ei\u00b7gen\u00b7tu\u00b7me"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PTKNEG", "VVPP", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.20": {"text": "das Weib so wenig ", "tokens": ["das", "Weib", "so", "we\u00b7nig"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "PIS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.21": {"text": "die eines fremden Lebens ist f\u00fcr alle.", "tokens": ["die", "ei\u00b7nes", "frem\u00b7den", "Le\u00b7bens", "ist", "f\u00fcr", "al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJA", "NN", "VAFIN", "APPR", "PIS", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.228": {"line.1": {"text": "Falle nicht, Gott, aus deinem Gleichgewicht.", "tokens": ["Fal\u00b7le", "nicht", ",", "Gott", ",", "aus", "dei\u00b7nem", "Gleich\u00b7ge\u00b7wicht", "."], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "$,", "NN", "$,", "APPR", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Auch der dich liebt und der dein Angesicht", "tokens": ["Auch", "der", "dich", "liebt", "und", "der", "dein", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "PPER", "VVFIN", "KON", "ART", "PPOSAT", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "erkennt im Dunkel, wenn er wie ein Licht", "tokens": ["er\u00b7kennt", "im", "Dun\u00b7kel", ",", "wenn", "er", "wie", "ein", "Licht"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPRART", "NN", "$,", "KOUS", "PPER", "KOKOM", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "in deinem Atem schwankt, \u2013 besitzt dich nicht.", "tokens": ["in", "dei\u00b7nem", "A\u00b7tem", "schwankt", ",", "\u2013", "be\u00b7sitzt", "dich", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVFIN", "$,", "$(", "VVFIN", "PPER", "PTKNEG", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "Und wenn dich einer in der Nacht erfa\u00dft,", "tokens": ["Und", "wenn", "dich", "ei\u00b7ner", "in", "der", "Nacht", "er\u00b7fa\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "so da\u00df du kommen mu\u00dft in sein Gebet:", "tokens": ["so", "da\u00df", "du", "kom\u00b7men", "mu\u00dft", "in", "sein", "Ge\u00b7bet", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "VVINF", "VMFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.229": {"line.1": {"text": "Wer kann dich halten, Gott? Denn du bist dein,", "tokens": ["Wer", "kann", "dich", "hal\u00b7ten", ",", "Gott", "?", "Denn", "du", "bist", "dein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PRF", "VVINF", "$,", "NN", "$.", "KON", "PPER", "VAFIN", "PPOSAT", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "von keines Eigent\u00fcmers Hand gest\u00f6rt,", "tokens": ["von", "kei\u00b7nes", "Ei\u00b7gen\u00b7t\u00fc\u00b7mers", "Hand", "ge\u00b7st\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so wie der noch nicht ausgereifte Wein,", "tokens": ["so", "wie", "der", "noch", "nicht", "aus\u00b7ge\u00b7reif\u00b7te", "Wein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "ADV", "PTKNEG", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "der immer s\u00fc\u00dfer wird, sich selbst geh\u00f6rt.", "tokens": ["der", "im\u00b7mer", "s\u00fc\u00b7\u00dfer", "wird", ",", "sich", "selbst", "ge\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "VAFIN", "$,", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.230": {"line.1": {"text": "In tiefen N\u00e4chten grab ich dich, du Schatz.", "tokens": ["In", "tie\u00b7fen", "N\u00e4ch\u00b7ten", "grab", "ich", "dich", ",", "du", "Schatz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "PRF", "$,", "PPER", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Denn alle \u00dcberfl\u00fcsse, die ich sah,", "tokens": ["Denn", "al\u00b7le", "\u00dc\u00b7berf\u00b7l\u00fcs\u00b7se", ",", "die", "ich", "sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "sind Armut und arms\u00e4liger Ersatz", "tokens": ["sind", "Ar\u00b7mut", "und", "arm\u00b7s\u00e4\u00b7li\u00b7ger", "Er\u00b7satz"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "NN", "KON", "ADJA", "NN"], "meter": "-+--++-+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "f\u00fcr deine Sch\u00f6nheit, die noch nie geschah.", "tokens": ["f\u00fcr", "dei\u00b7ne", "Sch\u00f6n\u00b7heit", ",", "die", "noch", "nie", "ge\u00b7schah", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PRELS", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.231": {"line.1": {"text": "Aber der Weg zu dir ist furchtbar weit", "tokens": ["A\u00b7ber", "der", "Weg", "zu", "dir", "ist", "furcht\u00b7bar", "weit"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "APPR", "PPER", "VAFIN", "ADJD", "ADJD"], "meter": "+--+-+-+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "und, weil ihn lange keiner ging, verweht.", "tokens": ["und", ",", "weil", "ihn", "lan\u00b7ge", "kei\u00b7ner", "ging", ",", "ver\u00b7weht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PPER", "ADV", "PIS", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "O du bist einsam. Du bist Einsamkeit,", "tokens": ["O", "du", "bist", "ein\u00b7sam", ".", "Du", "bist", "Ein\u00b7sam\u00b7keit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ADJD", "$.", "PPER", "VAFIN", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "du Herz, das zu entfernten Talen geht.", "tokens": ["du", "Herz", ",", "das", "zu", "ent\u00b7fern\u00b7ten", "Ta\u00b7len", "geht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "$,", "PRELS", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.232": {"line.1": {"text": "Und meine H\u00e4nde, welche blutig sind", "tokens": ["Und", "mei\u00b7ne", "H\u00e4n\u00b7de", ",", "wel\u00b7che", "blu\u00b7tig", "sind"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "PPOSAT", "NN", "$,", "PRELS", "ADJD", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "vom Graben, heb ich offen in den Wind,", "tokens": ["vom", "Gra\u00b7ben", ",", "heb", "ich", "of\u00b7fen", "in", "den", "Wind", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "PPER", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "so da\u00df sie sich verzweigen wie ein Baum.", "tokens": ["so", "da\u00df", "sie", "sich", "ver\u00b7zwei\u00b7gen", "wie", "ein", "Baum", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PPER", "PRF", "VVINF", "KOKOM", "ART", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Ich sauge dich mit ihnen aus dem Raum", "tokens": ["Ich", "sau\u00b7ge", "dich", "mit", "ih\u00b7nen", "aus", "dem", "Raum"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.5": {"text": "als h\u00e4ttest du dich einmal dort zerschellt", "tokens": ["als", "h\u00e4t\u00b7test", "du", "dich", "ein\u00b7mal", "dort", "zer\u00b7schellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOKOM", "VAFIN", "PPER", "PRF", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "in einer ungeduldigen Geb\u00e4rde,", "tokens": ["in", "ei\u00b7ner", "un\u00b7ge\u00b7dul\u00b7di\u00b7gen", "Ge\u00b7b\u00e4r\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "und fielest jetzt, eine zerst\u00e4ubte Welt,", "tokens": ["und", "fie\u00b7lest", "jetzt", ",", "ei\u00b7ne", "zer\u00b7st\u00e4ub\u00b7te", "Welt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "aus fernen Sternen wieder auf die Erde", "tokens": ["aus", "fer\u00b7nen", "Ster\u00b7nen", "wie\u00b7der", "auf", "die", "Er\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "sanft wie ein Fr\u00fchlingsregen f\u00e4llt.", "tokens": ["sanft", "wie", "ein", "Fr\u00fch\u00b7lings\u00b7re\u00b7gen", "f\u00e4llt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}}}}}