{"textgrid.poem.57483": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "1L: Ihr Forscher tiefer Dunkelheiten,", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ihr Forscher tiefer Dunkelheiten,", "tokens": ["Ihr", "For\u00b7scher", "tie\u00b7fer", "Dun\u00b7kel\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Darinn die Klugheit grauer Zeiten", "tokens": ["Da\u00b7rinn", "die", "Klug\u00b7heit", "grau\u00b7er", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Weisheit reines Gold der Thoren Blick entzog;", "tokens": ["Der", "Weis\u00b7heit", "rei\u00b7nes", "Gold", "der", "Tho\u00b7ren", "Blick", "ent\u00b7zog", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Meister in der Kunst zu finden,", "tokens": ["Ihr", "Meis\u00b7ter", "in", "der", "Kunst", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was aus der Alterth\u00fcmer Gr\u00fcnden", "tokens": ["Was", "aus", "der", "Al\u00b7tert\u00b7h\u00fc\u00b7mer", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So mancher edle Geist f\u00fcr s\u00fc\u00dfe Nahrung sog:", "tokens": ["So", "man\u00b7cher", "ed\u00b7le", "Geist", "f\u00fcr", "s\u00fc\u00b7\u00dfe", "Nah\u00b7rung", "sog", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der, wenn er kaum die Schale brach,", "tokens": ["Der", ",", "wenn", "er", "kaum", "die", "Scha\u00b7le", "brach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von lauter S\u00fc\u00dfigkeit der G\u00f6tterspeisen sprach.", "tokens": ["Von", "lau\u00b7ter", "S\u00fc\u00b7\u00dfig\u00b7keit", "der", "G\u00f6t\u00b7ter\u00b7spei\u00b7sen", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Erheitert mir die weisen Schatten,", "tokens": ["Er\u00b7hei\u00b7tert", "mir", "die", "wei\u00b7sen", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Worinn sich Witz und Wahrheit gatten,", "tokens": ["Wo\u00b7rinn", "sich", "Witz", "und", "Wahr\u00b7heit", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In Stellen, wo ", "tokens": ["In", "Stel\u00b7len", ",", "wo"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "PWAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Wann er der Tugend Wuchs zu st\u00e4rken,", "tokens": ["Wann", "er", "der", "Tu\u00b7gend", "Wuchs", "zu", "st\u00e4r\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den Lohn von loberf\u00fcllten Werken", "tokens": ["Den", "Lohn", "von", "lo\u00b7berf\u00b7\u00fcll\u00b7ten", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Im selgen Aufenthalt begl\u00fcckter Inseln pries:", "tokens": ["Im", "sel\u00b7gen", "Auf\u00b7ent\u00b7halt", "be\u00b7gl\u00fcck\u00b7ter", "In\u00b7seln", "pries", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Elysiens erw\u00fcnschtes Land,", "tokens": ["E\u00b7ly\u00b7si\u00b7ens", "er\u00b7w\u00fcnschtes", "Land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Wo, mit der Sterblichkeit, auch alle Noth verschwand.", "tokens": ["Wo", ",", "mit", "der", "Sterb\u00b7lich\u00b7keit", ",", "auch", "al\u00b7le", "Noth", "ver\u00b7schwand", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Des weisen Greises scharfe Blicke,", "tokens": ["Des", "wei\u00b7sen", "Grei\u00b7ses", "schar\u00b7fe", "Bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O Mensch! sahn tiefer ins Geschicke,", "tokens": ["O", "Mensch", "!", "sahn", "tie\u00b7fer", "ins", "Ge\u00b7schi\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das deiner Dauer l\u00e4ngst der Vorsicht Hand gesteckt;", "tokens": ["Das", "dei\u00b7ner", "Dau\u00b7er", "l\u00e4ngst", "der", "Vor\u00b7sicht", "Hand", "ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als jener Schwarm von Epikuren,", "tokens": ["Als", "je\u00b7ner", "Schwarm", "von", "E\u00b7pi\u00b7ku\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der dir auf der Verwesung Fluren", "tokens": ["Der", "dir", "auf", "der", "Ver\u00b7we\u00b7sung", "Flu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So Leib als Geist zugleich mit ewgem Staube deckt;", "tokens": ["So", "Leib", "als", "Geist", "zu\u00b7gleich", "mit", "ew\u00b7gem", "Stau\u00b7be", "deckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, wenn man ihrem Wahnwitz glaubt,", "tokens": ["Und", ",", "wenn", "man", "ih\u00b7rem", "Wahn\u00b7witz", "glaubt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dir mit dem letzten Hauch das ganze Daseyn raubt.", "tokens": ["Dir", "mit", "dem", "letz\u00b7ten", "Hauch", "das", "gan\u00b7ze", "Da\u00b7seyn", "raubt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Der fernen Zukunft Seligkeiten,", "tokens": ["Der", "fer\u00b7nen", "Zu\u00b7kunft", "Se\u00b7lig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Belobten Seelen vorzudeuten,", "tokens": ["Be\u00b7lob\u00b7ten", "See\u00b7len", "vor\u00b7zu\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "War aller Weisheit werth, die sein Gedicht belebt:", "tokens": ["War", "al\u00b7ler", "Weis\u00b7heit", "werth", ",", "die", "sein", "Ge\u00b7dicht", "be\u00b7lebt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sein Held verwest nicht ganz in Gr\u00fcften,", "tokens": ["Sein", "Held", "ver\u00b7west", "nicht", "ganz", "in", "Gr\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt noch, wo in heitern L\u00fcften", "tokens": ["Er", "lebt", "noch", ",", "wo", "in", "hei\u00b7tern", "L\u00fcf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Manch gl\u00fccklich Eyland sich aus tiefer See erhebt;", "tokens": ["Manch", "gl\u00fcck\u00b7lich", "Ey\u00b7land", "sich", "aus", "tie\u00b7fer", "See", "er\u00b7hebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ungest\u00f6rt der Lenz regiert,", "tokens": ["Wo", "un\u00b7ge\u00b7st\u00f6rt", "der", "Lenz", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und Ewigkeiten durch nur Gl\u00fcck und Lust gebiehrt.", "tokens": ["Und", "E\u00b7wig\u00b7kei\u00b7ten", "durch", "nur", "Gl\u00fcck", "und", "Lust", "ge\u00b7biehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Allein, wo sind, so wird man sprechen,", "tokens": ["Al\u00b7lein", ",", "wo", "sind", ",", "so", "wird", "man", "spre\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VAFIN", "$,", "ADV", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf aller Meere blauen Fl\u00e4chen,", "tokens": ["Auf", "al\u00b7ler", "Mee\u00b7re", "blau\u00b7en", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Inseln voller Heil, davon der Dichter singt?", "tokens": ["Die", "In\u00b7seln", "vol\u00b7ler", "Heil", ",", "da\u00b7von", "der", "Dich\u00b7ter", "singt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ist ein Eyland auszusp\u00fcren,", "tokens": ["Wo", "ist", "ein", "Ey\u00b7land", "aus\u00b7zu\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darauf nur Gl\u00fcck und Lust regieren,", "tokens": ["Da\u00b7rauf", "nur", "Gl\u00fcck", "und", "Lust", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wo den Seligen die Tugend Palmen bringt?", "tokens": ["Und", "wo", "den", "Se\u00b7li\u00b7gen", "die", "Tu\u00b7gend", "Pal\u00b7men", "bringt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Palmen, die der Unschuld Stand,", "tokens": ["Die", "Pal\u00b7men", ",", "die", "der", "Un\u00b7schuld", "Stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im stillen Urthelsspruch des innern Richters fand.", "tokens": ["Im", "stil\u00b7len", "Ur\u00b7thels\u00b7spruch", "des", "in\u00b7nern", "Rich\u00b7ters", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seit dem ", "tokens": ["Seit", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Sich wagte, L\u00e4nder aufzukl\u00e4ren,", "tokens": ["Sich", "wag\u00b7te", ",", "L\u00e4n\u00b7der", "auf\u00b7zu\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Davon uns ", "tokens": ["Da\u00b7von", "uns"], "token_info": ["word", "word"], "pos": ["PAV", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Seit dem ", "tokens": ["Seit", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Die blo\u00df ihr Gold ins Joch gebunden,", "tokens": ["Die", "blo\u00df", "ihr", "Gold", "ins", "Joch", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Traf noch kein sp\u00e4hend Boot dergleichen Eyland an;", "tokens": ["Traf", "noch", "kein", "sp\u00e4\u00b7hend", "Boot", "derg\u00b7lei\u00b7chen", "Ey\u00b7land", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "ADJD", "NN", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Hat noch kein Mast das Land erblickt,", "tokens": ["Hat", "noch", "kein", "Mast", "das", "Land", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wo ungekr\u00e4nkte Ruh der Menschen Herz erquickt.", "tokens": ["Wo", "un\u00b7ge\u00b7kr\u00e4nk\u00b7te", "Ruh", "der", "Men\u00b7schen", "Herz", "er\u00b7quickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Ists jenes Land vieleicht gewesen,", "tokens": ["Ists", "je\u00b7nes", "Land", "vie\u00b7leicht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "ADV", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Davon wir ", "tokens": ["Da\u00b7von", "wir"], "token_info": ["word", "word"], "pos": ["PAV", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Das vormals westlich lag, ", "tokens": ["Das", "vor\u00b7mals", "west\u00b7lich", "lag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das durch die Macht verborgner Gluthen,", "tokens": ["Das", "durch", "die", "Macht", "ver\u00b7borg\u00b7ner", "Glu\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wo nicht im Toben wilder Fluthen,", "tokens": ["Wo", "nicht", "im", "To\u00b7ben", "wil\u00b7der", "Flut\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich unsrer Welt entzog und in der See verschwand?", "tokens": ["Sich", "uns\u00b7rer", "Welt", "ent\u00b7zog", "und", "in", "der", "See", "ver\u00b7schwand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vieleicht wars ", "tokens": ["Vie\u00b7leicht", "wars"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und K\u00fcsten noch kein Kahn der Sterblichen befuhr.", "tokens": ["Und", "K\u00fcs\u00b7ten", "noch", "kein", "Kahn", "der", "Sterb\u00b7li\u00b7chen", "be\u00b7fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Umsonst! in Deutschlands hoher Mitten,", "tokens": ["Um\u00b7sonst", "!", "in", "Deutschlands", "ho\u00b7her", "Mit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo Rom und ", "tokens": ["Wo", "Rom", "und"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "KON"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Zeigt sich der Fabel Reich in heller Wahrheit Licht,", "tokens": ["Zeigt", "sich", "der", "Fa\u00b7bel", "Reich", "in", "hel\u00b7ler", "Wahr\u00b7heit", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "F\u00e4llt mir ein fruchtbar Thal entz\u00fcckend ins Gesicht:", "tokens": ["F\u00e4llt", "mir", "ein", "frucht\u00b7bar", "Thal", "ent\u00b7z\u00fc\u00b7ckend", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "NN", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das keiner St\u00fcrme Wuth erschreckt,", "tokens": ["Das", "kei\u00b7ner", "St\u00fcr\u00b7me", "Wuth", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil gr\u00fcner Berge Wall es vor den Wettern deckt.", "tokens": ["Weil", "gr\u00fc\u00b7ner", "Ber\u00b7ge", "Wall", "es", "vor", "den", "Wet\u00b7tern", "deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NE", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Du Kleinod gl\u00fccklicher Provinzen,", "tokens": ["Du", "Klei\u00b7nod", "gl\u00fcck\u00b7li\u00b7cher", "Pro\u00b7vin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "An deines Stromes flachem Rande,", "tokens": ["An", "dei\u00b7nes", "Stro\u00b7mes", "fla\u00b7chem", "Ran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Stolziert das Bild von jenem Lande,", "tokens": ["Stol\u00b7ziert", "das", "Bild", "von", "je\u00b7nem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wohin der Dichter Witz die Seligen gef\u00fchrt.", "tokens": ["Wo\u00b7hin", "der", "Dich\u00b7ter", "Witz", "die", "Se\u00b7li\u00b7gen", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Auch in der Oberwelt Elyserfelder macht.", "tokens": ["Auch", "in", "der", "O\u00b7ber\u00b7welt", "E\u00b7ly\u00b7ser\u00b7fel\u00b7der", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.9": {"line.1": {"text": "Was Oberwelt? Von deinen H\u00f6hen,", "tokens": ["Was", "O\u00b7ber\u00b7welt", "?", "Von", "dei\u00b7nen", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo so viel F\u00fcrstenh\u00e4user stehen,", "tokens": ["Wo", "so", "viel", "F\u00fcrs\u00b7ten\u00b7h\u00e4u\u00b7ser", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Steig ich, o ", "tokens": ["Steig", "ich", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Hier geh ich, wie der Thrazerdichter,", "tokens": ["Hier", "geh", "ich", ",", "wie", "der", "Thra\u00b7zer\u00b7dich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zur Wohnung der gerechten Richter,", "tokens": ["Zur", "Woh\u00b7nung", "der", "ge\u00b7rech\u00b7ten", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In deren Sorgfalt ", "tokens": ["In", "de\u00b7ren", "Sorg\u00b7falt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PRELAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Hier steht, hier steht der Themis Thron!", "tokens": ["Hier", "steht", ",", "hier", "steht", "der", "The\u00b7mis", "Thron", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hier ist der Tugend Sitz, der Unschuld edler Lohn.", "tokens": ["Hier", "ist", "der", "Tu\u00b7gend", "Sitz", ",", "der", "Un\u00b7schuld", "ed\u00b7ler", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.10": {"line.1": {"text": "Bey nimmer welken Lorberstr\u00e4uchen,", "tokens": ["Bey", "nim\u00b7mer", "wel\u00b7ken", "Lor\u00b7ber\u00b7str\u00e4u\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Kraft und Wachsthum nie entweichen,", "tokens": ["Wo", "Kraft", "und", "Wach\u00b7sthum", "nie", "ent\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seh ich den Wunderstamm des hohen Lorbers leicht.", "tokens": ["Seh", "ich", "den", "Wun\u00b7der\u00b7stamm", "des", "ho\u00b7hen", "Lor\u00b7bers", "leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Der Musen Hand zurecht gebogen,", "tokens": ["Der", "Mu\u00b7sen", "Hand", "zu\u00b7recht", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und zu der H\u00f6h gebracht, darinn er Cedern gleicht:", "tokens": ["Und", "zu", "der", "H\u00f6h", "ge\u00b7bracht", ",", "da\u00b7rinn", "er", "Ce\u00b7dern", "gleicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "PAV", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darunter, wenn die Wolke thaut,", "tokens": ["Da\u00b7run\u00b7ter", ",", "wenn", "die", "Wol\u00b7ke", "thaut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr ganzes Chor nebst ihm, sich v\u00f6llig sicher schaut.", "tokens": ["Ihr", "gan\u00b7zes", "Chor", "nebst", "ihm", ",", "sich", "v\u00f6l\u00b7lig", "si\u00b7cher", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "$,", "PRF", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.11": {"line.1": {"text": "Nein! nirgends hat er gleiche Br\u00fcder!", "tokens": ["Nein", "!", "nir\u00b7gends", "hat", "er", "glei\u00b7che", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O Deutschland! nirgends siehst du wieder,", "tokens": ["O", "Deutschland", "!", "nir\u00b7gends", "siehst", "du", "wie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was dieser Aue Raum f\u00fcr Wunder liefern kann.", "tokens": ["Was", "die\u00b7ser", "Au\u00b7e", "Raum", "f\u00fcr", "Wun\u00b7der", "lie\u00b7fern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was seh ich? Pomeranzenw\u00e4lder,", "tokens": ["Was", "seh", "ich", "?", "Po\u00b7me\u00b7ran\u00b7zen\u00b7w\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dergleichen auch Arkaderfelder,", "tokens": ["Derg\u00b7lei\u00b7chen", "auch", "Ar\u00b7ka\u00b7der\u00b7fel\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ja ", "tokens": ["Ja"], "token_info": ["word"], "pos": ["PTKANT"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Weil Umfang, Menge, Bl\u00fcth und Frucht,", "tokens": ["Weil", "Um\u00b7fang", ",", "Men\u00b7ge", ",", "Bl\u00fcth", "und", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Wettkampf trotzig heischt, vergebens Streiter sucht.", "tokens": ["Den", "Wett\u00b7kampf", "trot\u00b7zig", "heischt", ",", "ver\u00b7ge\u00b7bens", "Strei\u00b7ter", "sucht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie weit erstreckt auf beyden Seiten", "tokens": ["Wie", "weit", "er\u00b7streckt", "auf", "bey\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVPP", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Der Lustbau seiner Fl\u00fcgel Breiten;", "tokens": ["Der", "Lust\u00b7bau", "sei\u00b7ner", "Fl\u00fc\u00b7gel", "Brei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Davon der Aue Grund des ", "tokens": ["Da\u00b7von", "der", "Au\u00b7e", "Grund", "des"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Von drey empor gehabnen Zinnen", "tokens": ["Von", "drey", "em\u00b7por", "ge\u00b7hab\u00b7nen", "Zin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "PTKVZ", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "L\u00e4\u00dft sich so mancher Gang gewinnen,", "tokens": ["L\u00e4\u00dft", "sich", "so", "man\u00b7cher", "Gang", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Den hoher Linden Wand in k\u00fchle Schatten setzt;", "tokens": ["Den", "ho\u00b7her", "Lin\u00b7den", "Wand", "in", "k\u00fch\u00b7le", "Schat\u00b7ten", "setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und deren L\u00e4nge w\u00fcrdig ist,", "tokens": ["Und", "de\u00b7ren", "L\u00e4n\u00b7ge", "w\u00fcr\u00b7dig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Da\u00df sie der K\u00fcnstler Hand auch durch Feldweges mi\u00dft.", "tokens": ["Da\u00df", "sie", "der", "K\u00fcnst\u00b7ler", "Hand", "auch", "durch", "Feld\u00b7we\u00b7ges", "mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.12": {"line.1": {"text": "Was sieht man da zur Rechten liegen?", "tokens": ["Was", "sieht", "man", "da", "zur", "Rech\u00b7ten", "lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Tempel ists, auf dessen Stiegen", "tokens": ["Ein", "Tem\u00b7pel", "ists", ",", "auf", "des\u00b7sen", "Stie\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ehrfurcht zum Altar der h\u00f6chsten Gottheit trat!", "tokens": ["Die", "Ehr\u00b7furcht", "zum", "Al\u00b7tar", "der", "h\u00f6chs\u00b7ten", "Got\u00b7theit", "trat", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch nein! in kunsterf\u00fcllten W\u00e4nden,", "tokens": ["Doch", "nein", "!", "in", "kuns\u00b7ter\u00b7f\u00fcll\u00b7ten", "W\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Daran Geschmack und Marmor blenden,", "tokens": ["Da\u00b7ran", "Ge\u00b7schmack", "und", "Mar\u00b7mor", "blen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Erblickt mein Auge nur ein kostbar F\u00fcrstenbad;", "tokens": ["Er\u00b7blickt", "mein", "Au\u00b7ge", "nur", "ein", "kost\u00b7bar", "F\u00fcrs\u00b7ten\u00b7bad", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Daran der Schnitzkunst Witz und Flei\u00df", "tokens": ["Da\u00b7ran", "der", "Schnitz\u00b7kunst", "Witz", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch Meisterst\u00fccke sich empor zu heben weis.", "tokens": ["Durch", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "sich", "em\u00b7por", "zu", "he\u00b7ben", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "PTKVZ", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "O C", "tokens": ["O", "C"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "Du, dem der Aufenthalt gefallen,", "tokens": ["Du", ",", "dem", "der", "Auf\u00b7ent\u00b7halt", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du, dessen Heldengeist manch gro\u00dfes Werk gebahr.", "tokens": ["Du", ",", "des\u00b7sen", "Hel\u00b7den\u00b7geist", "manch", "gro\u00b7\u00dfes", "Werk", "ge\u00b7bahr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort steht auf dem entlegnen Berge,", "tokens": ["Dort", "steht", "auf", "dem", "ent\u00b7leg\u00b7nen", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Der in der N\u00e4he doch Kolossen \u00e4hnlich war;", "tokens": ["Der", "in", "der", "N\u00e4\u00b7he", "doch", "Ko\u00b7los\u00b7sen", "\u00e4hn\u00b7lich", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo Wasserfall und Grott und Stein,", "tokens": ["Wo", "Was\u00b7ser\u00b7fall", "und", "Grott", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das achte Wunderwerk der Erden scheint zu seyn.", "tokens": ["Das", "ach\u00b7te", "Wun\u00b7der\u00b7werk", "der", "Er\u00b7den", "scheint", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.14": {"line.1": {"text": "Ists nicht die Arbeit jener Riesen,", "tokens": ["Ists", "nicht", "die", "Ar\u00b7beit", "je\u00b7ner", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die vormals sich gesch\u00e4fftig wiesen,", "tokens": ["Die", "vor\u00b7mals", "sich", "ge\u00b7sch\u00e4ff\u00b7tig", "wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ihr bem\u00fchter Arm des Himmels Burg best\u00fcrmt?", "tokens": ["Als", "ihr", "be\u00b7m\u00fch\u00b7ter", "Arm", "des", "Him\u00b7mels", "Burg", "be\u00b7st\u00fcrmt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie trugen Berg auf Berg zusammen;", "tokens": ["Sie", "tru\u00b7gen", "Berg", "auf", "Berg", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bis Jupiter mit Blitz und Flammen,", "tokens": ["Bis", "Ju\u00b7pi\u00b7ter", "mit", "Blitz", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den gro\u00dfen Bau zerschlug, den sie empor geth\u00fcrmt.", "tokens": ["Den", "gro\u00b7\u00dfen", "Bau", "zer\u00b7schlug", ",", "den", "sie", "em\u00b7por", "ge\u00b7th\u00fcrmt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "F\u00fcrwahr! was hier das Auge schaut,", "tokens": ["F\u00fcr\u00b7wahr", "!", "was", "hier", "das", "Au\u00b7ge", "schaut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hat ein ", "tokens": ["Hat", "ein"], "token_info": ["word", "word"], "pos": ["VAFIN", "ART"], "meter": "-+", "measure": "iambic.single"}}, "stanza.15": {"line.1": {"text": "Wer kann die Wunder alle nennnen,", "tokens": ["Wer", "kann", "die", "Wun\u00b7der", "al\u00b7le", "nenn\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kennerblicke hier erkennen?", "tokens": ["Die", "Ken\u00b7ner\u00b7bli\u00b7cke", "hier", "er\u00b7ken\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer z\u00e4hlt, was ", "tokens": ["Wer", "z\u00e4hlt", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "PWS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wie gro\u00df ", "tokens": ["Wie", "gro\u00df"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Kann man aus ", "tokens": ["Kann", "man", "aus"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PIS", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Im Kriege streng, im Frieden mild;", "tokens": ["Im", "Krie\u00b7ge", "streng", ",", "im", "Frie\u00b7den", "mild", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das, das, o ", "tokens": ["Das", ",", "das", ",", "o"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["PDS", "$,", "PDS", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.16": {"line.1": {"text": "Durch Tapferkeit und sanfte K\u00fcnste", "tokens": ["Durch", "Tap\u00b7fer\u00b7keit", "und", "sanf\u00b7te", "K\u00fcns\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ward dir der Lobspruch zum Gewinnste,", "tokens": ["Ward", "dir", "der", "Lob\u00b7spruch", "zum", "Ge\u00b7winns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Womit Europa l\u00e4ngst ", "tokens": ["Wo\u00b7mit", "Eu\u00b7ro\u00b7pa", "l\u00e4ngst"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Des Fremden Auge wird entz\u00fccket,", "tokens": ["Des", "Frem\u00b7den", "Au\u00b7ge", "wird", "ent\u00b7z\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn er die Wunderkraft erblicket,", "tokens": ["Wenn", "er", "die", "Wun\u00b7der\u00b7kraft", "er\u00b7bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Und die auch j\u00fcngst durch einen Ruff,", "tokens": ["Und", "die", "auch", "j\u00fcngst", "durch", "ei\u00b7nen", "Ruff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das stolze ", "tokens": ["Das", "stol\u00b7ze"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.17": {"line.1": {"text": "Bey Berg und Wald und dunklen Gr\u00fcnden", "tokens": ["Bey", "Berg", "und", "Wald", "und", "dunk\u00b7len", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Lehrt Er den Regen B\u00e4che finden,", "tokens": ["Lehrt", "Er", "den", "Re\u00b7gen", "B\u00e4\u00b7che", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der sonst das ganze Thal zur weiten See gemacht.", "tokens": ["Der", "sonst", "das", "gan\u00b7ze", "Thal", "zur", "wei\u00b7ten", "See", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "L\u00e4\u00dft H\u00fcgel in die Tiefe tragen,", "tokens": ["L\u00e4\u00dft", "H\u00fc\u00b7gel", "in", "die", "Tie\u00b7fe", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hei\u00dft Grott und Springbrunn seyn, und B\u00e4cken voller Pracht.", "tokens": ["Hei\u00dft", "Grott", "und", "Spring\u00b7brunn", "seyn", ",", "und", "B\u00e4\u00b7cken", "vol\u00b7ler", "Pracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "VAINF", "$,", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein wilder Irrgang ziert das Holz,", "tokens": ["Ein", "wil\u00b7der", "Irr\u00b7gang", "ziert", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und auf des Gartens Schmuck w\u00e4r auch ein K\u00f6nig stolz.", "tokens": ["Und", "auf", "des", "Gar\u00b7tens", "Schmuck", "w\u00e4r", "auch", "ein", "K\u00f6\u00b7nig", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was dort in Thraziens Gefilden,", "tokens": ["Was", "dort", "in", "Thra\u00b7zi\u00b7ens", "Ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gott f\u00fcr Gefl\u00fcgel pflegt zu bilden,", "tokens": ["Gott", "f\u00fcr", "Ge\u00b7fl\u00fc\u00b7gel", "pflegt", "zu", "bil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Wo Mahomeths Geboth den stolzen Tulband lenkt.", "tokens": ["Wo", "Ma\u00b7ho\u00b7me\u00b7ths", "Ge\u00b7both", "den", "stol\u00b7zen", "Tul\u00b7band", "lenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "Was Asien auf seinen H\u00f6hen,", "tokens": ["Was", "A\u00b7sien", "auf", "sei\u00b7nen", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.13": {"text": "Sieht schwimmend durch die Fluthen gehen,", "tokens": ["Sieht", "schwim\u00b7mend", "durch", "die", "Flut\u00b7hen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das hat der ", "tokens": ["Das", "hat", "der"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Und China selbst sah nie so sch\u00f6n,", "tokens": ["Und", "Chi\u00b7na", "selbst", "sah", "nie", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Als l\u00e4ngst dem Ufer hin, Chineserh\u00fctten stehn.", "tokens": ["Als", "l\u00e4ngst", "dem", "U\u00b7fer", "hin", ",", "Chi\u00b7ne\u00b7ser\u00b7h\u00fct\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKVZ", "$,", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.18": {"line.1": {"text": "Nun steigt aus dem bew\u00e4hrten Grunde,", "tokens": ["Nun", "steigt", "aus", "dem", "be\u00b7w\u00e4hr\u00b7ten", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit jedem Tag und jeder Stunde,", "tokens": ["Mit", "je\u00b7dem", "Tag", "und", "je\u00b7der", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das neue F\u00fcrstenhaus recht sichtbarlich empor.", "tokens": ["Das", "neu\u00b7e", "F\u00fcrs\u00b7ten\u00b7haus", "recht", "sicht\u00b7bar\u00b7lich", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die K\u00f6nigstochter edler Britten,", "tokens": ["Die", "K\u00f6\u00b7nig\u00b7stoch\u00b7ter", "ed\u00b7ler", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Setzt selbst den ersten Stein, weil ", "tokens": ["Setzt", "selbst", "den", "ers\u00b7ten", "Stein", ",", "weil"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,", "KOUS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In kurzem zeigt sich der Palast,", "tokens": ["In", "kur\u00b7zem", "zeigt", "sich", "der", "Pa\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Davon der blo\u00dfe Ri\u00df schon Wunder in sich fa\u00dft.", "tokens": ["Da\u00b7von", "der", "blo\u00b7\u00dfe", "Ri\u00df", "schon", "Wun\u00b7der", "in", "sich", "fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.19": {"line.1": {"text": "Verg\u00f6ttert nur mit Witz und Schriften,", "tokens": ["Ver\u00b7g\u00f6t\u00b7tert", "nur", "mit", "Witz", "und", "Schrif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Ihr Schm\u00e4uchler zu Paris, die Stolz und Sold erhob;", "tokens": ["Ihr", "Schm\u00e4uch\u00b7ler", "zu", "Pa\u00b7ris", ",", "die", "Stolz", "und", "Sold", "er\u00b7hob", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier regt ein ", "tokens": ["Hier", "regt", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Zwingt die Natur, versetzet H\u00fcgel,", "tokens": ["Zwingt", "die", "Na\u00b7tur", ",", "ver\u00b7set\u00b7zet", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bl\u00e4ht sich gleichwohl nicht auf ein erkauftes Lob.", "tokens": ["Und", "bl\u00e4ht", "sich", "gleich\u00b7wohl", "nicht", "auf", "ein", "er\u00b7kauf\u00b7tes", "Lob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die freye Muse nur gesteht,", "tokens": ["Die", "frey\u00b7e", "Mu\u00b7se", "nur", "ge\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.20": {"line.1": {"text": "Der Kenner Auge zu erfreuen,", "tokens": ["Der", "Ken\u00b7ner", "Au\u00b7ge", "zu", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von redender Natur f\u00fcr Meisterst\u00fccke lie\u00df;", "tokens": ["Von", "re\u00b7den\u00b7der", "Na\u00b7tur", "f\u00fcr", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "lie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Die oft den Preis der Kunst gewonnen,", "tokens": ["Die", "oft", "den", "Preis", "der", "Kunst", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn selbst ", "tokens": ["Wenn", "selbst"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Das liebt der ", "tokens": ["Das", "liebt", "der"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Dem widmet sein Geschmack den neuvollf\u00fchrten Saal.", "tokens": ["Dem", "wid\u00b7met", "sein", "Ge\u00b7schmack", "den", "neu\u00b7voll\u00b7f\u00fchr\u00b7ten", "Saal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.21": {"line.1": {"text": "Was macht ", "tokens": ["Was", "macht"], "token_info": ["word", "word"], "pos": ["PWS", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "So gro\u00dfer Muster, schm\u00fcckt er Fluren;", "tokens": ["So", "gro\u00b7\u00dfer", "Mus\u00b7ter", ",", "schm\u00fcckt", "er", "Flu\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Pflanzt G\u00e4rten neuer Art, die Deutschland nie gekannt:", "tokens": ["Pflanzt", "G\u00e4r\u00b7ten", "neu\u00b7er", "Art", ",", "die", "Deutschland", "nie", "ge\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein j\u00e4her Berg wird ihm zur Fl\u00e4che:", "tokens": ["Ein", "j\u00e4\u00b7her", "Berg", "wird", "ihm", "zur", "Fl\u00e4\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er st\u00e4rkt des rauhen Bodens Schw\u00e4che,", "tokens": ["Er", "st\u00e4rkt", "des", "rau\u00b7hen", "Bo\u00b7dens", "Schw\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zeugt Hayne wilder Zucht, so klug als Engelland.", "tokens": ["Zeugt", "Hay\u00b7ne", "wil\u00b7der", "Zucht", ",", "so", "klug", "als", "En\u00b7gel\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,", "ADV", "ADJD", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein Irrgang zeiget ", "tokens": ["Sein", "Irr\u00b7gang", "zei\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und mitten in der Kunst herrscht gleichwohl die Natur.", "tokens": ["Und", "mit\u00b7ten", "in", "der", "Kunst", "herrscht", "gleich\u00b7wohl", "die", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.22": {"line.1": {"text": "Dort, wo aus den verborgnen Sch\u00e4tzen,", "tokens": ["Dort", ",", "wo", "aus", "den", "ver\u00b7borg\u00b7nen", "Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Menschen Kr\u00e4fte zu ersetzen,", "tokens": ["Der", "Men\u00b7schen", "Kr\u00e4f\u00b7te", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Abgrund tiefer Kluft ein heilsam Wasser quillt:", "tokens": ["Der", "Ab\u00b7grund", "tie\u00b7fer", "Kluft", "ein", "heil\u00b7sam", "Was\u00b7ser", "quillt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Da sieht man andrer B\u00e4der Bl\u00f6\u00dfe,", "tokens": ["Da", "sieht", "man", "an\u00b7drer", "B\u00e4\u00b7der", "Bl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Indem den Ort, der Heil gebracht,", "tokens": ["In\u00b7dem", "den", "Ort", ",", "der", "Heil", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Was seh ich? Sind es Thuillerien,", "tokens": ["Was", "seh", "ich", "?", "Sind", "es", "Thu\u00b7il\u00b7le\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VAFIN", "PPER", "NE", "$,"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo tausend dichte Linden bl\u00fchen,", "tokens": ["Wo", "tau\u00b7send", "dich\u00b7te", "Lin\u00b7den", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und G\u00e4nge sonder Schlu\u00df den sch\u00e4rfsten Blick erfreun?", "tokens": ["Und", "G\u00e4n\u00b7ge", "son\u00b7der", "Schlu\u00df", "den", "sch\u00e4rfs\u00b7ten", "Blick", "er\u00b7freun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sind es ", "tokens": ["Sind", "es"], "token_info": ["word", "word"], "pos": ["VAFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "O nein! auch ", "tokens": ["O", "nein", "!", "auch"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "PTKANT", "$.", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Hat ihres gleichen nicht, und mu\u00df ein Wunder seyn.", "tokens": ["Hat", "ih\u00b7res", "glei\u00b7chen", "nicht", ",", "und", "mu\u00df", "ein", "Wun\u00b7der", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "PTKNEG", "$,", "KON", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und gieng ihr nicht die Aue vor,", "tokens": ["Und", "gieng", "ihr", "nicht", "die", "Au\u00b7e", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was gliche wohl dem Raum um Cassels sch\u00f6nstes Thor?", "tokens": ["Was", "gli\u00b7che", "wohl", "dem", "Raum", "um", "Cas\u00b7sels", "sch\u00f6ns\u00b7tes", "Thor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "K\u00f6nnt ich Geschmack und Anstalt zeigen,", "tokens": ["K\u00f6nnt", "ich", "Ge\u00b7schmack", "und", "An\u00b7stalt", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Womit so Dein Pallast, als edler Garten prangt!", "tokens": ["Wo\u00b7mit", "so", "Dein", "Pal\u00b7last", ",", "als", "ed\u00b7ler", "Gar\u00b7ten", "prangt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "$,", "KOUS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nach Thaten, so die Welt verehret,", "tokens": ["Nach", "Tha\u00b7ten", ",", "so", "die", "Welt", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hast Du die Ruh, die Dir geh\u00f6ret,", "tokens": ["Hast", "Du", "die", "Ruh", ",", "die", "Dir", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Als zweyter ", "tokens": ["Als", "zwey\u00b7ter"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Wo Dich ein kluges Buch ergetzt,", "tokens": ["Wo", "Dich", "ein", "klu\u00b7ges", "Buch", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Wenn Dich das Spiel der Welt oft in Verwundrung setzt.", "tokens": ["Wenn", "Dich", "das", "Spiel", "der", "Welt", "oft", "in", "Ver\u00b7wund\u00b7rung", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.24": {"line.1": {"text": "Und du, o ", "tokens": ["Und", "du", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Sich sch\u00f6ner kaum gedenken lassen,", "tokens": ["Sich", "sch\u00f6\u00b7ner", "kaum", "ge\u00b7den\u00b7ken", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du bestes Musterbild von neuer St\u00e4dte Bau!", "tokens": ["Du", "bes\u00b7tes", "Mus\u00b7ter\u00b7bild", "von", "neu\u00b7er", "St\u00e4d\u00b7te", "Bau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kann eine Schnur wohl gleicher gehen,", "tokens": ["Kann", "ei\u00b7ne", "Schnur", "wohl", "glei\u00b7cher", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Als H\u00e4user und Pall\u00e4ste stehen?", "tokens": ["Als", "H\u00e4u\u00b7ser", "und", "Pal\u00b7l\u00e4s\u00b7te", "ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sogar dein Tempel folgt dem Ebenmaa\u00df genau.", "tokens": ["So\u00b7gar", "dein", "Tem\u00b7pel", "folgt", "dem", "E\u00b7ben\u00b7maa\u00df", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Stra\u00dfen Durchschnitt stellt ihn dar,", "tokens": ["Der", "Stra\u00b7\u00dfen", "Durch\u00b7schnitt", "stellt", "ihn", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und hoher Linden Kreis umschlie\u00dft den Vorhoff gar.", "tokens": ["Und", "ho\u00b7her", "Lin\u00b7den", "Kreis", "um\u00b7schlie\u00dft", "den", "Vor\u00b7hoff", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NE", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.25": {"line.1": {"text": "Ob ihrer Baukunst Seltenheiten", "tokens": ["Ob", "ih\u00b7rer", "Bau\u00b7kunst", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die\u00df Kleinod Hessens nicht, der M\u00e4ngel wegen, schilt?", "tokens": ["Die\u00df", "Klei\u00b7nod", "Hes\u00b7sens", "nicht", ",", "der", "M\u00e4n\u00b7gel", "we\u00b7gen", ",", "schilt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "NN", "NE", "PTKNEG", "$,", "ART", "NN", "APPR", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An Gr\u00f6\u00dfe kann ", "tokens": ["An", "Gr\u00f6\u00b7\u00dfe", "kann"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "An Ordnung mu\u00df es unterliegen:", "tokens": ["An", "Ord\u00b7nung", "mu\u00df", "es", "un\u00b7ter\u00b7lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil Schnur und Winkelmaa\u00df hier sonder Ausnahm gilt;", "tokens": ["Weil", "Schnur", "und", "Win\u00b7kel\u00b7maa\u00df", "hier", "son\u00b7der", "Aus\u00b7nahm", "gilt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seiner lichten Stra\u00dfen Pracht,", "tokens": ["Und", "sei\u00b7ner", "lich\u00b7ten", "Stra\u00b7\u00dfen", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kein eingeschr\u00e4nkter Wall das Wachsthum schwierig macht.", "tokens": ["Kein", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ter", "Wall", "das", "Wach\u00b7sthum", "schwie\u00b7rig", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.26": {"line.1": {"text": "Ihr Musen! soll ich weiter singen?", "tokens": ["Ihr", "Mu\u00b7sen", "!", "soll", "ich", "wei\u00b7ter", "sin\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00dft k\u00fcnftig mir ein Lied gelingen;", "tokens": ["La\u00dft", "k\u00fcnf\u00b7tig", "mir", "ein", "Lied", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sein B\u00fcchersaal, und hundert St\u00fccke", "tokens": ["Sein", "B\u00fc\u00b7cher\u00b7saal", ",", "und", "hun\u00b7dert", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von Kunst und Witz, ziehn eure Blicke", "tokens": ["Von", "Kunst", "und", "Witz", ",", "ziehn", "eu\u00b7re", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Schon l\u00e4ngst auf das Geb\u00e4u, wo ", "tokens": ["Schon", "l\u00e4ngst", "auf", "das", "Ge\u00b7b\u00e4u", ",", "wo"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,", "PWAV"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Hier wird einst, stimmt ", "tokens": ["Hier", "wird", "einst", ",", "stimmt"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "ADV", "$,", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Von jeder Wissenschaft ein ewger Wohnplatz seyn.", "tokens": ["Von", "je\u00b7der", "Wis\u00b7sen\u00b7schaft", "ein", "ew\u00b7ger", "Wohn\u00b7platz", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.27": {"line.1": {"text": "Gesellschaft! die du bey den Siegen", "tokens": ["Ge\u00b7sell\u00b7schaft", "!", "die", "du", "bey", "den", "Sie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des r\u00e4chenden ", "tokens": ["Des", "r\u00e4\u00b7chen\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Der so gerecht als klug Europens Wage lenkt;", "tokens": ["Der", "so", "ge\u00b7recht", "als", "klug", "Eu\u00b7ro\u00b7pens", "Wa\u00b7ge", "lenkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KOKOM", "ADJD", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Versammlung, reich an edlen Geistern,", "tokens": ["Ver\u00b7samm\u00b7lung", ",", "reich", "an", "ed\u00b7len", "Geis\u00b7tern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df dich die rege Glut bemeistern,", "tokens": ["La\u00df", "dich", "die", "re\u00b7ge", "Glut", "be\u00b7meis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Die Dank und Ehrfurcht l\u00e4ngst in deine Brust gesenkt;", "tokens": ["Die", "Dank", "und", "Ehr\u00b7furcht", "l\u00e4ngst", "in", "dei\u00b7ne", "Brust", "ge\u00b7senkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und stimme solche Lieder an,", "tokens": ["Und", "stim\u00b7me", "sol\u00b7che", "Lie\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df selbst der Britte sie nicht sch\u00f6ner opfern kann.", "tokens": ["Da\u00df", "selbst", "der", "Brit\u00b7te", "sie", "nicht", "sch\u00f6\u00b7ner", "op\u00b7fern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.28": {"line.1": {"text": "Und unsrer Zeit von Gott beschieden,", "tokens": ["Und", "uns\u00b7rer", "Zeit", "von", "Gott", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der deutschen Freyheit Schutz, der ", "tokens": ["Der", "deut\u00b7schen", "Frey\u00b7heit", "Schutz", ",", "der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bey Detting kann er Lorbern brechen,", "tokens": ["Bey", "Det\u00b7ting", "kann", "er", "Lor\u00b7bern", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Feinde Wuth und Hochmuth schw\u00e4chen;", "tokens": ["Der", "Fein\u00b7de", "Wuth", "und", "Hoch\u00b7muth", "schw\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Hause l\u00e4\u00dft Sein Arm den Musen Tempel weihn.", "tokens": ["Zu", "Hau\u00b7se", "l\u00e4\u00dft", "Sein", "Arm", "den", "Mu\u00b7sen", "Tem\u00b7pel", "weihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "O! die\u00df besinge, theures Chor;", "tokens": ["O", "!", "die\u00df", "be\u00b7sin\u00b7ge", ",", "theu\u00b7res", "Chor", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PDS", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und stell Ihn sp\u00e4ter Zeit zum Heldenmuster vor.", "tokens": ["Und", "stell", "Ihn", "sp\u00e4\u00b7ter", "Zeit", "zum", "Hel\u00b7den\u00b7mus\u00b7ter", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADJD", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.29": {"line.1": {"text": "Zwar ", "tokens": ["Zwar"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Folg ihr in feurigen Gedichten;", "tokens": ["Folg", "ihr", "in", "feu\u00b7ri\u00b7gen", "Ge\u00b7dich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Davon der laute Ton in alle Gr\u00e4nzen dringt.", "tokens": ["Da\u00b7von", "der", "lau\u00b7te", "Ton", "in", "al\u00b7le", "Gr\u00e4n\u00b7zen", "dringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und diese That nach Werth zu loben,", "tokens": ["Und", "die\u00b7se", "That", "nach", "Werth", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist ein erhabnes Werk, das Dichtern Ehre bringt.", "tokens": ["Ist", "ein", "er\u00b7hab\u00b7nes", "Werk", ",", "das", "Dich\u00b7tern", "Eh\u00b7re", "bringt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf! Seine Gro\u00dfmuth ganz allein,", "tokens": ["Auf", "!", "Sei\u00b7ne", "Gro\u00df\u00b7muth", "ganz", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PPOSAT", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00df k\u00fcnftighin der Stoff zu deinen Liedern seyn!", "tokens": ["Mu\u00df", "k\u00fcnf\u00b7tig\u00b7hin", "der", "Stoff", "zu", "dei\u00b7nen", "Lie\u00b7dern", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.30": {"line.1": {"text": "Ihr Forscher tiefer Dunkelheiten,", "tokens": ["Ihr", "For\u00b7scher", "tie\u00b7fer", "Dun\u00b7kel\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Darinn die Klugheit grauer Zeiten", "tokens": ["Da\u00b7rinn", "die", "Klug\u00b7heit", "grau\u00b7er", "Zei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Weisheit reines Gold der Thoren Blick entzog;", "tokens": ["Der", "Weis\u00b7heit", "rei\u00b7nes", "Gold", "der", "Tho\u00b7ren", "Blick", "ent\u00b7zog", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ihr Meister in der Kunst zu finden,", "tokens": ["Ihr", "Meis\u00b7ter", "in", "der", "Kunst", "zu", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Was aus der Alterth\u00fcmer Gr\u00fcnden", "tokens": ["Was", "aus", "der", "Al\u00b7tert\u00b7h\u00fc\u00b7mer", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So mancher edle Geist f\u00fcr s\u00fc\u00dfe Nahrung sog:", "tokens": ["So", "man\u00b7cher", "ed\u00b7le", "Geist", "f\u00fcr", "s\u00fc\u00b7\u00dfe", "Nah\u00b7rung", "sog", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIAT", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der, wenn er kaum die Schale brach,", "tokens": ["Der", ",", "wenn", "er", "kaum", "die", "Scha\u00b7le", "brach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Von lauter S\u00fc\u00dfigkeit der G\u00f6tterspeisen sprach.", "tokens": ["Von", "lau\u00b7ter", "S\u00fc\u00b7\u00dfig\u00b7keit", "der", "G\u00f6t\u00b7ter\u00b7spei\u00b7sen", "sprach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.31": {"line.1": {"text": "Erheitert mir die weisen Schatten,", "tokens": ["Er\u00b7hei\u00b7tert", "mir", "die", "wei\u00b7sen", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Worinn sich Witz und Wahrheit gatten,", "tokens": ["Wo\u00b7rinn", "sich", "Witz", "und", "Wahr\u00b7heit", "gat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "In Stellen, wo ", "tokens": ["In", "Stel\u00b7len", ",", "wo"], "token_info": ["word", "word", "punct", "word"], "pos": ["APPR", "NN", "$,", "PWAV"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "Wann er der Tugend Wuchs zu st\u00e4rken,", "tokens": ["Wann", "er", "der", "Tu\u00b7gend", "Wuchs", "zu", "st\u00e4r\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Den Lohn von loberf\u00fcllten Werken", "tokens": ["Den", "Lohn", "von", "lo\u00b7berf\u00b7\u00fcll\u00b7ten", "Wer\u00b7ken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Im selgen Aufenthalt begl\u00fcckter Inseln pries:", "tokens": ["Im", "sel\u00b7gen", "Auf\u00b7ent\u00b7halt", "be\u00b7gl\u00fcck\u00b7ter", "In\u00b7seln", "pries", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Elysiens erw\u00fcnschtes Land,", "tokens": ["E\u00b7ly\u00b7si\u00b7ens", "er\u00b7w\u00fcnschtes", "Land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.8": {"text": "Wo, mit der Sterblichkeit, auch alle Noth verschwand.", "tokens": ["Wo", ",", "mit", "der", "Sterb\u00b7lich\u00b7keit", ",", "auch", "al\u00b7le", "Noth", "ver\u00b7schwand", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "ART", "NN", "$,", "ADV", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.32": {"line.1": {"text": "Des weisen Greises scharfe Blicke,", "tokens": ["Des", "wei\u00b7sen", "Grei\u00b7ses", "schar\u00b7fe", "Bli\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O Mensch! sahn tiefer ins Geschicke,", "tokens": ["O", "Mensch", "!", "sahn", "tie\u00b7fer", "ins", "Ge\u00b7schi\u00b7cke", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "VVFIN", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das deiner Dauer l\u00e4ngst der Vorsicht Hand gesteckt;", "tokens": ["Das", "dei\u00b7ner", "Dau\u00b7er", "l\u00e4ngst", "der", "Vor\u00b7sicht", "Hand", "ge\u00b7steckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PPOSAT", "NN", "ADV", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als jener Schwarm von Epikuren,", "tokens": ["Als", "je\u00b7ner", "Schwarm", "von", "E\u00b7pi\u00b7ku\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Der dir auf der Verwesung Fluren", "tokens": ["Der", "dir", "auf", "der", "Ver\u00b7we\u00b7sung", "Flu\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "PPER", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "So Leib als Geist zugleich mit ewgem Staube deckt;", "tokens": ["So", "Leib", "als", "Geist", "zu\u00b7gleich", "mit", "ew\u00b7gem", "Stau\u00b7be", "deckt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KOUS", "NN", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und, wenn man ihrem Wahnwitz glaubt,", "tokens": ["Und", ",", "wenn", "man", "ih\u00b7rem", "Wahn\u00b7witz", "glaubt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KOUS", "PIS", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Dir mit dem letzten Hauch das ganze Daseyn raubt.", "tokens": ["Dir", "mit", "dem", "letz\u00b7ten", "Hauch", "das", "gan\u00b7ze", "Da\u00b7seyn", "raubt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.33": {"line.1": {"text": "Der fernen Zukunft Seligkeiten,", "tokens": ["Der", "fer\u00b7nen", "Zu\u00b7kunft", "Se\u00b7lig\u00b7kei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Belobten Seelen vorzudeuten,", "tokens": ["Be\u00b7lob\u00b7ten", "See\u00b7len", "vor\u00b7zu\u00b7deu\u00b7ten", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "War aller Weisheit werth, die sein Gedicht belebt:", "tokens": ["War", "al\u00b7ler", "Weis\u00b7heit", "werth", ",", "die", "sein", "Ge\u00b7dicht", "be\u00b7lebt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ADJD", "$,", "PRELS", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sein Held verwest nicht ganz in Gr\u00fcften,", "tokens": ["Sein", "Held", "ver\u00b7west", "nicht", "ganz", "in", "Gr\u00fcf\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PTKNEG", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er lebt noch, wo in heitern L\u00fcften", "tokens": ["Er", "lebt", "noch", ",", "wo", "in", "hei\u00b7tern", "L\u00fcf\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWAV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Manch gl\u00fccklich Eyland sich aus tiefer See erhebt;", "tokens": ["Manch", "gl\u00fcck\u00b7lich", "Ey\u00b7land", "sich", "aus", "tie\u00b7fer", "See", "er\u00b7hebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJD", "NN", "PRF", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ungest\u00f6rt der Lenz regiert,", "tokens": ["Wo", "un\u00b7ge\u00b7st\u00f6rt", "der", "Lenz", "re\u00b7giert", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und Ewigkeiten durch nur Gl\u00fcck und Lust gebiehrt.", "tokens": ["Und", "E\u00b7wig\u00b7kei\u00b7ten", "durch", "nur", "Gl\u00fcck", "und", "Lust", "ge\u00b7biehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADV", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.34": {"line.1": {"text": "Allein, wo sind, so wird man sprechen,", "tokens": ["Al\u00b7lein", ",", "wo", "sind", ",", "so", "wird", "man", "spre\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "VAFIN", "$,", "ADV", "VAFIN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Auf aller Meere blauen Fl\u00e4chen,", "tokens": ["Auf", "al\u00b7ler", "Mee\u00b7re", "blau\u00b7en", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Inseln voller Heil, davon der Dichter singt?", "tokens": ["Die", "In\u00b7seln", "vol\u00b7ler", "Heil", ",", "da\u00b7von", "der", "Dich\u00b7ter", "singt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "PAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ist ein Eyland auszusp\u00fcren,", "tokens": ["Wo", "ist", "ein", "Ey\u00b7land", "aus\u00b7zu\u00b7sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darauf nur Gl\u00fcck und Lust regieren,", "tokens": ["Da\u00b7rauf", "nur", "Gl\u00fcck", "und", "Lust", "re\u00b7gie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und wo den Seligen die Tugend Palmen bringt?", "tokens": ["Und", "wo", "den", "Se\u00b7li\u00b7gen", "die", "Tu\u00b7gend", "Pal\u00b7men", "bringt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ART", "NN", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Palmen, die der Unschuld Stand,", "tokens": ["Die", "Pal\u00b7men", ",", "die", "der", "Un\u00b7schuld", "Stand", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Im stillen Urthelsspruch des innern Richters fand.", "tokens": ["Im", "stil\u00b7len", "Ur\u00b7thels\u00b7spruch", "des", "in\u00b7nern", "Rich\u00b7ters", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Seit dem ", "tokens": ["Seit", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.10": {"text": "Sich wagte, L\u00e4nder aufzukl\u00e4ren,", "tokens": ["Sich", "wag\u00b7te", ",", "L\u00e4n\u00b7der", "auf\u00b7zu\u00b7kl\u00e4\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["PRF", "VVFIN", "$,", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Davon uns ", "tokens": ["Da\u00b7von", "uns"], "token_info": ["word", "word"], "pos": ["PAV", "PPER"], "meter": "+-+", "measure": "trochaic.di"}, "line.12": {"text": "Seit dem ", "tokens": ["Seit", "dem"], "token_info": ["word", "word"], "pos": ["APPR", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.13": {"text": "Die blo\u00df ihr Gold ins Joch gebunden,", "tokens": ["Die", "blo\u00df", "ihr", "Gold", "ins", "Joch", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PPOSAT", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Traf noch kein sp\u00e4hend Boot dergleichen Eyland an;", "tokens": ["Traf", "noch", "kein", "sp\u00e4\u00b7hend", "Boot", "derg\u00b7lei\u00b7chen", "Ey\u00b7land", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "PIAT", "ADJD", "NN", "PIS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Hat noch kein Mast das Land erblickt,", "tokens": ["Hat", "noch", "kein", "Mast", "das", "Land", "er\u00b7blickt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "PIAT", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Wo ungekr\u00e4nkte Ruh der Menschen Herz erquickt.", "tokens": ["Wo", "un\u00b7ge\u00b7kr\u00e4nk\u00b7te", "Ruh", "der", "Men\u00b7schen", "Herz", "er\u00b7quickt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJA", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Ists jenes Land vieleicht gewesen,", "tokens": ["Ists", "je\u00b7nes", "Land", "vie\u00b7leicht", "ge\u00b7we\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PDAT", "NN", "ADV", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Davon wir ", "tokens": ["Da\u00b7von", "wir"], "token_info": ["word", "word"], "pos": ["PAV", "PPER"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Das vormals westlich lag, ", "tokens": ["Das", "vor\u00b7mals", "west\u00b7lich", "lag", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Das durch die Macht verborgner Gluthen,", "tokens": ["Das", "durch", "die", "Macht", "ver\u00b7borg\u00b7ner", "Glu\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wo nicht im Toben wilder Fluthen,", "tokens": ["Wo", "nicht", "im", "To\u00b7ben", "wil\u00b7der", "Flut\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PTKNEG", "APPRART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sich unsrer Welt entzog und in der See verschwand?", "tokens": ["Sich", "uns\u00b7rer", "Welt", "ent\u00b7zog", "und", "in", "der", "See", "ver\u00b7schwand", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "PPOSAT", "NN", "VVFIN", "KON", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Vieleicht wars ", "tokens": ["Vie\u00b7leicht", "wars"], "token_info": ["word", "word"], "pos": ["ADV", "VAFIN"], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und K\u00fcsten noch kein Kahn der Sterblichen befuhr.", "tokens": ["Und", "K\u00fcs\u00b7ten", "noch", "kein", "Kahn", "der", "Sterb\u00b7li\u00b7chen", "be\u00b7fuhr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "ADV", "PIAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.36": {"line.1": {"text": "Umsonst! in Deutschlands hoher Mitten,", "tokens": ["Um\u00b7sonst", "!", "in", "Deutschlands", "ho\u00b7her", "Mit\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$.", "APPR", "NE", "ADJA", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Wo Rom und ", "tokens": ["Wo", "Rom", "und"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "KON"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Zeigt sich der Fabel Reich in heller Wahrheit Licht,", "tokens": ["Zeigt", "sich", "der", "Fa\u00b7bel", "Reich", "in", "hel\u00b7ler", "Wahr\u00b7heit", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "NN", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "F\u00e4llt mir ein fruchtbar Thal entz\u00fcckend ins Gesicht:", "tokens": ["F\u00e4llt", "mir", "ein", "frucht\u00b7bar", "Thal", "ent\u00b7z\u00fc\u00b7ckend", "ins", "Ge\u00b7sicht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJD", "NN", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Das keiner St\u00fcrme Wuth erschreckt,", "tokens": ["Das", "kei\u00b7ner", "St\u00fcr\u00b7me", "Wuth", "er\u00b7schreckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Weil gr\u00fcner Berge Wall es vor den Wettern deckt.", "tokens": ["Weil", "gr\u00fc\u00b7ner", "Ber\u00b7ge", "Wall", "es", "vor", "den", "Wet\u00b7tern", "deckt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "NE", "PPER", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.37": {"line.1": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Du Kleinod gl\u00fccklicher Provinzen,", "tokens": ["Du", "Klei\u00b7nod", "gl\u00fcck\u00b7li\u00b7cher", "Pro\u00b7vin\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "An deines Stromes flachem Rande,", "tokens": ["An", "dei\u00b7nes", "Stro\u00b7mes", "fla\u00b7chem", "Ran\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Stolziert das Bild von jenem Lande,", "tokens": ["Stol\u00b7ziert", "das", "Bild", "von", "je\u00b7nem", "Lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wohin der Dichter Witz die Seligen gef\u00fchrt.", "tokens": ["Wo\u00b7hin", "der", "Dich\u00b7ter", "Witz", "die", "Se\u00b7li\u00b7gen", "ge\u00b7f\u00fchrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.8": {"text": "Auch in der Oberwelt Elyserfelder macht.", "tokens": ["Auch", "in", "der", "O\u00b7ber\u00b7welt", "E\u00b7ly\u00b7ser\u00b7fel\u00b7der", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.38": {"line.1": {"text": "Was Oberwelt? Von deinen H\u00f6hen,", "tokens": ["Was", "O\u00b7ber\u00b7welt", "?", "Von", "dei\u00b7nen", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "$.", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo so viel F\u00fcrstenh\u00e4user stehen,", "tokens": ["Wo", "so", "viel", "F\u00fcrs\u00b7ten\u00b7h\u00e4u\u00b7ser", "ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Steig ich, o ", "tokens": ["Steig", "ich", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["VVFIN", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Hier geh ich, wie der Thrazerdichter,", "tokens": ["Hier", "geh", "ich", ",", "wie", "der", "Thra\u00b7zer\u00b7dich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "PWAV", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zur Wohnung der gerechten Richter,", "tokens": ["Zur", "Woh\u00b7nung", "der", "ge\u00b7rech\u00b7ten", "Rich\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "In deren Sorgfalt ", "tokens": ["In", "de\u00b7ren", "Sorg\u00b7falt"], "token_info": ["word", "word", "word"], "pos": ["APPR", "PRELAT", "NN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.7": {"text": "Hier steht, hier steht der Themis Thron!", "tokens": ["Hier", "steht", ",", "hier", "steht", "der", "The\u00b7mis", "Thron", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$,", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hier ist der Tugend Sitz, der Unschuld edler Lohn.", "tokens": ["Hier", "ist", "der", "Tu\u00b7gend", "Sitz", ",", "der", "Un\u00b7schuld", "ed\u00b7ler", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "NN", "$,", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.39": {"line.1": {"text": "Bey nimmer welken Lorberstr\u00e4uchen,", "tokens": ["Bey", "nim\u00b7mer", "wel\u00b7ken", "Lor\u00b7ber\u00b7str\u00e4u\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wo Kraft und Wachsthum nie entweichen,", "tokens": ["Wo", "Kraft", "und", "Wach\u00b7sthum", "nie", "ent\u00b7wei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Seh ich den Wunderstamm des hohen Lorbers leicht.", "tokens": ["Seh", "ich", "den", "Wun\u00b7der\u00b7stamm", "des", "ho\u00b7hen", "Lor\u00b7bers", "leicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Der Musen Hand zurecht gebogen,", "tokens": ["Der", "Mu\u00b7sen", "Hand", "zu\u00b7recht", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKVZ", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Und zu der H\u00f6h gebracht, darinn er Cedern gleicht:", "tokens": ["Und", "zu", "der", "H\u00f6h", "ge\u00b7bracht", ",", "da\u00b7rinn", "er", "Ce\u00b7dern", "gleicht", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVPP", "$,", "PAV", "PPER", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Darunter, wenn die Wolke thaut,", "tokens": ["Da\u00b7run\u00b7ter", ",", "wenn", "die", "Wol\u00b7ke", "thaut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Ihr ganzes Chor nebst ihm, sich v\u00f6llig sicher schaut.", "tokens": ["Ihr", "gan\u00b7zes", "Chor", "nebst", "ihm", ",", "sich", "v\u00f6l\u00b7lig", "si\u00b7cher", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "APPR", "PPER", "$,", "PRF", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Nein! nirgends hat er gleiche Br\u00fcder!", "tokens": ["Nein", "!", "nir\u00b7gends", "hat", "er", "glei\u00b7che", "Br\u00fc\u00b7der", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "ADV", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "O Deutschland! nirgends siehst du wieder,", "tokens": ["O", "Deutschland", "!", "nir\u00b7gends", "siehst", "du", "wie\u00b7der", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was dieser Aue Raum f\u00fcr Wunder liefern kann.", "tokens": ["Was", "die\u00b7ser", "Au\u00b7e", "Raum", "f\u00fcr", "Wun\u00b7der", "lie\u00b7fern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "NN", "APPR", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Was seh ich? Pomeranzenw\u00e4lder,", "tokens": ["Was", "seh", "ich", "?", "Po\u00b7me\u00b7ran\u00b7zen\u00b7w\u00e4l\u00b7der", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dergleichen auch Arkaderfelder,", "tokens": ["Derg\u00b7lei\u00b7chen", "auch", "Ar\u00b7ka\u00b7der\u00b7fel\u00b7der", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Ja ", "tokens": ["Ja"], "token_info": ["word"], "pos": ["PTKANT"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Weil Umfang, Menge, Bl\u00fcth und Frucht,", "tokens": ["Weil", "Um\u00b7fang", ",", "Men\u00b7ge", ",", "Bl\u00fcth", "und", "Frucht", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Den Wettkampf trotzig heischt, vergebens Streiter sucht.", "tokens": ["Den", "Wett\u00b7kampf", "trot\u00b7zig", "heischt", ",", "ver\u00b7ge\u00b7bens", "Strei\u00b7ter", "sucht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "$,", "ADV", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wie weit erstreckt auf beyden Seiten", "tokens": ["Wie", "weit", "er\u00b7streckt", "auf", "bey\u00b7den", "Sei\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "ADJD", "VVPP", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Der Lustbau seiner Fl\u00fcgel Breiten;", "tokens": ["Der", "Lust\u00b7bau", "sei\u00b7ner", "Fl\u00fc\u00b7gel", "Brei\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "Davon der Aue Grund des ", "tokens": ["Da\u00b7von", "der", "Au\u00b7e", "Grund", "des"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "NN", "ART"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Von drey empor gehabnen Zinnen", "tokens": ["Von", "drey", "em\u00b7por", "ge\u00b7hab\u00b7nen", "Zin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "CARD", "PTKVZ", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "L\u00e4\u00dft sich so mancher Gang gewinnen,", "tokens": ["L\u00e4\u00dft", "sich", "so", "man\u00b7cher", "Gang", "ge\u00b7win\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Den hoher Linden Wand in k\u00fchle Schatten setzt;", "tokens": ["Den", "ho\u00b7her", "Lin\u00b7den", "Wand", "in", "k\u00fch\u00b7le", "Schat\u00b7ten", "setzt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NE", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Und deren L\u00e4nge w\u00fcrdig ist,", "tokens": ["Und", "de\u00b7ren", "L\u00e4n\u00b7ge", "w\u00fcr\u00b7dig", "ist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Da\u00df sie der K\u00fcnstler Hand auch durch Feldweges mi\u00dft.", "tokens": ["Da\u00df", "sie", "der", "K\u00fcnst\u00b7ler", "Hand", "auch", "durch", "Feld\u00b7we\u00b7ges", "mi\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}}, "stanza.41": {"line.1": {"text": "Was sieht man da zur Rechten liegen?", "tokens": ["Was", "sieht", "man", "da", "zur", "Rech\u00b7ten", "lie\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PIS", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Tempel ists, auf dessen Stiegen", "tokens": ["Ein", "Tem\u00b7pel", "ists", ",", "auf", "des\u00b7sen", "Stie\u00b7gen"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ehrfurcht zum Altar der h\u00f6chsten Gottheit trat!", "tokens": ["Die", "Ehr\u00b7furcht", "zum", "Al\u00b7tar", "der", "h\u00f6chs\u00b7ten", "Got\u00b7theit", "trat", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch nein! in kunsterf\u00fcllten W\u00e4nden,", "tokens": ["Doch", "nein", "!", "in", "kuns\u00b7ter\u00b7f\u00fcll\u00b7ten", "W\u00e4n\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PTKANT", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Daran Geschmack und Marmor blenden,", "tokens": ["Da\u00b7ran", "Ge\u00b7schmack", "und", "Mar\u00b7mor", "blen\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Erblickt mein Auge nur ein kostbar F\u00fcrstenbad;", "tokens": ["Er\u00b7blickt", "mein", "Au\u00b7ge", "nur", "ein", "kost\u00b7bar", "F\u00fcrs\u00b7ten\u00b7bad", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Daran der Schnitzkunst Witz und Flei\u00df", "tokens": ["Da\u00b7ran", "der", "Schnitz\u00b7kunst", "Witz", "und", "Flei\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PAV", "ART", "NN", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Durch Meisterst\u00fccke sich empor zu heben weis.", "tokens": ["Durch", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "sich", "em\u00b7por", "zu", "he\u00b7ben", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PRF", "PTKVZ", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.42": {"line.1": {"text": "O C", "tokens": ["O", "C"], "token_info": ["word", "word"], "pos": ["NE", "NE"], "meter": "++", "measure": "spondeus"}, "line.2": {"text": "Du, dem der Aufenthalt gefallen,", "tokens": ["Du", ",", "dem", "der", "Auf\u00b7ent\u00b7halt", "ge\u00b7fal\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du, dessen Heldengeist manch gro\u00dfes Werk gebahr.", "tokens": ["Du", ",", "des\u00b7sen", "Hel\u00b7den\u00b7geist", "manch", "gro\u00b7\u00dfes", "Werk", "ge\u00b7bahr", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELAT", "NN", "PIAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dort steht auf dem entlegnen Berge,", "tokens": ["Dort", "steht", "auf", "dem", "ent\u00b7leg\u00b7nen", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dein ", "tokens": ["Dein"], "token_info": ["word"], "pos": ["PPOSAT"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Der in der N\u00e4he doch Kolossen \u00e4hnlich war;", "tokens": ["Der", "in", "der", "N\u00e4\u00b7he", "doch", "Ko\u00b7los\u00b7sen", "\u00e4hn\u00b7lich", "war", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ADV", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo Wasserfall und Grott und Stein,", "tokens": ["Wo", "Was\u00b7ser\u00b7fall", "und", "Grott", "und", "Stein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das achte Wunderwerk der Erden scheint zu seyn.", "tokens": ["Das", "ach\u00b7te", "Wun\u00b7der\u00b7werk", "der", "Er\u00b7den", "scheint", "zu", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "NN", "VVFIN", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.43": {"line.1": {"text": "Ists nicht die Arbeit jener Riesen,", "tokens": ["Ists", "nicht", "die", "Ar\u00b7beit", "je\u00b7ner", "Rie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PTKNEG", "ART", "NN", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die vormals sich gesch\u00e4fftig wiesen,", "tokens": ["Die", "vor\u00b7mals", "sich", "ge\u00b7sch\u00e4ff\u00b7tig", "wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "PRF", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Als ihr bem\u00fchter Arm des Himmels Burg best\u00fcrmt?", "tokens": ["Als", "ihr", "be\u00b7m\u00fch\u00b7ter", "Arm", "des", "Him\u00b7mels", "Burg", "be\u00b7st\u00fcrmt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "ADJA", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie trugen Berg auf Berg zusammen;", "tokens": ["Sie", "tru\u00b7gen", "Berg", "auf", "Berg", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "APPR", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Bis Jupiter mit Blitz und Flammen,", "tokens": ["Bis", "Ju\u00b7pi\u00b7ter", "mit", "Blitz", "und", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Den gro\u00dfen Bau zerschlug, den sie empor geth\u00fcrmt.", "tokens": ["Den", "gro\u00b7\u00dfen", "Bau", "zer\u00b7schlug", ",", "den", "sie", "em\u00b7por", "ge\u00b7th\u00fcrmt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PRELS", "PPER", "PTKVZ", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "F\u00fcrwahr! was hier das Auge schaut,", "tokens": ["F\u00fcr\u00b7wahr", "!", "was", "hier", "das", "Au\u00b7ge", "schaut", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hat ein ", "tokens": ["Hat", "ein"], "token_info": ["word", "word"], "pos": ["VAFIN", "ART"], "meter": "-+", "measure": "iambic.single"}}, "stanza.44": {"line.1": {"text": "Wer kann die Wunder alle nennnen,", "tokens": ["Wer", "kann", "die", "Wun\u00b7der", "al\u00b7le", "nenn\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ART", "NN", "PIS", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kennerblicke hier erkennen?", "tokens": ["Die", "Ken\u00b7ner\u00b7bli\u00b7cke", "hier", "er\u00b7ken\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer z\u00e4hlt, was ", "tokens": ["Wer", "z\u00e4hlt", ",", "was"], "token_info": ["word", "word", "punct", "word"], "pos": ["PWS", "VVFIN", "$,", "PWS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wie gro\u00df ", "tokens": ["Wie", "gro\u00df"], "token_info": ["word", "word"], "pos": ["PWAV", "ADJD"], "meter": "-+", "measure": "iambic.single"}, "line.5": {"text": "Kann man aus ", "tokens": ["Kann", "man", "aus"], "token_info": ["word", "word", "word"], "pos": ["VMFIN", "PIS", "APPR"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Denn ", "tokens": ["Denn"], "token_info": ["word"], "pos": ["KON"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Im Kriege streng, im Frieden mild;", "tokens": ["Im", "Krie\u00b7ge", "streng", ",", "im", "Frie\u00b7den", "mild", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das, das, o ", "tokens": ["Das", ",", "das", ",", "o"], "token_info": ["word", "punct", "word", "punct", "word"], "pos": ["PDS", "$,", "PDS", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}}, "stanza.45": {"line.1": {"text": "Durch Tapferkeit und sanfte K\u00fcnste", "tokens": ["Durch", "Tap\u00b7fer\u00b7keit", "und", "sanf\u00b7te", "K\u00fcns\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ward dir der Lobspruch zum Gewinnste,", "tokens": ["Ward", "dir", "der", "Lob\u00b7spruch", "zum", "Ge\u00b7winns\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Womit Europa l\u00e4ngst ", "tokens": ["Wo\u00b7mit", "Eu\u00b7ro\u00b7pa", "l\u00e4ngst"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NE", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.4": {"text": "Des Fremden Auge wird entz\u00fccket,", "tokens": ["Des", "Frem\u00b7den", "Au\u00b7ge", "wird", "ent\u00b7z\u00fc\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn er die Wunderkraft erblicket,", "tokens": ["Wenn", "er", "die", "Wun\u00b7der\u00b7kraft", "er\u00b7bli\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.7": {"text": "Und die auch j\u00fcngst durch einen Ruff,", "tokens": ["Und", "die", "auch", "j\u00fcngst", "durch", "ei\u00b7nen", "Ruff", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADV", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Das stolze ", "tokens": ["Das", "stol\u00b7ze"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.46": {"line.1": {"text": "Bey Berg und Wald und dunklen Gr\u00fcnden", "tokens": ["Bey", "Berg", "und", "Wald", "und", "dunk\u00b7len", "Gr\u00fcn\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Lehrt Er den Regen B\u00e4che finden,", "tokens": ["Lehrt", "Er", "den", "Re\u00b7gen", "B\u00e4\u00b7che", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der sonst das ganze Thal zur weiten See gemacht.", "tokens": ["Der", "sonst", "das", "gan\u00b7ze", "Thal", "zur", "wei\u00b7ten", "See", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "ADJA", "NN", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "L\u00e4\u00dft H\u00fcgel in die Tiefe tragen,", "tokens": ["L\u00e4\u00dft", "H\u00fc\u00b7gel", "in", "die", "Tie\u00b7fe", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Hei\u00dft Grott und Springbrunn seyn, und B\u00e4cken voller Pracht.", "tokens": ["Hei\u00dft", "Grott", "und", "Spring\u00b7brunn", "seyn", ",", "und", "B\u00e4\u00b7cken", "vol\u00b7ler", "Pracht", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "KON", "NN", "VAINF", "$,", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein wilder Irrgang ziert das Holz,", "tokens": ["Ein", "wil\u00b7der", "Irr\u00b7gang", "ziert", "das", "Holz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und auf des Gartens Schmuck w\u00e4r auch ein K\u00f6nig stolz.", "tokens": ["Und", "auf", "des", "Gar\u00b7tens", "Schmuck", "w\u00e4r", "auch", "ein", "K\u00f6\u00b7nig", "stolz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "NN", "VAFIN", "ADV", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Was dort in Thraziens Gefilden,", "tokens": ["Was", "dort", "in", "Thra\u00b7zi\u00b7ens", "Ge\u00b7fil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Gott f\u00fcr Gefl\u00fcgel pflegt zu bilden,", "tokens": ["Gott", "f\u00fcr", "Ge\u00b7fl\u00fc\u00b7gel", "pflegt", "zu", "bil\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVFIN", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.11": {"text": "Wo Mahomeths Geboth den stolzen Tulband lenkt.", "tokens": ["Wo", "Ma\u00b7ho\u00b7me\u00b7ths", "Ge\u00b7both", "den", "stol\u00b7zen", "Tul\u00b7band", "lenkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "NN", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.12": {"text": "Was Asien auf seinen H\u00f6hen,", "tokens": ["Was", "A\u00b7sien", "auf", "sei\u00b7nen", "H\u00f6\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.13": {"text": "Sieht schwimmend durch die Fluthen gehen,", "tokens": ["Sieht", "schwim\u00b7mend", "durch", "die", "Flut\u00b7hen", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.14": {"text": "Das hat der ", "tokens": ["Das", "hat", "der"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.15": {"text": "Und China selbst sah nie so sch\u00f6n,", "tokens": ["Und", "Chi\u00b7na", "selbst", "sah", "nie", "so", "sch\u00f6n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "ADV", "VVFIN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Als l\u00e4ngst dem Ufer hin, Chineserh\u00fctten stehn.", "tokens": ["Als", "l\u00e4ngst", "dem", "U\u00b7fer", "hin", ",", "Chi\u00b7ne\u00b7ser\u00b7h\u00fct\u00b7ten", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PTKVZ", "$,", "NN", "VVINF", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.47": {"line.1": {"text": "Nun steigt aus dem bew\u00e4hrten Grunde,", "tokens": ["Nun", "steigt", "aus", "dem", "be\u00b7w\u00e4hr\u00b7ten", "Grun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Mit jedem Tag und jeder Stunde,", "tokens": ["Mit", "je\u00b7dem", "Tag", "und", "je\u00b7der", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "KON", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Das neue F\u00fcrstenhaus recht sichtbarlich empor.", "tokens": ["Das", "neu\u00b7e", "F\u00fcrs\u00b7ten\u00b7haus", "recht", "sicht\u00b7bar\u00b7lich", "em\u00b7por", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die K\u00f6nigstochter edler Britten,", "tokens": ["Die", "K\u00f6\u00b7nig\u00b7stoch\u00b7ter", "ed\u00b7ler", "Brit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Setzt selbst den ersten Stein, weil ", "tokens": ["Setzt", "selbst", "den", "ers\u00b7ten", "Stein", ",", "weil"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["VVFIN", "ADV", "ART", "ADJA", "NN", "$,", "KOUS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "In kurzem zeigt sich der Palast,", "tokens": ["In", "kur\u00b7zem", "zeigt", "sich", "der", "Pa\u00b7last", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "VVFIN", "PRF", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Davon der blo\u00dfe Ri\u00df schon Wunder in sich fa\u00dft.", "tokens": ["Da\u00b7von", "der", "blo\u00b7\u00dfe", "Ri\u00df", "schon", "Wun\u00b7der", "in", "sich", "fa\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "ADV", "NN", "APPR", "PRF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.48": {"line.1": {"text": "Verg\u00f6ttert nur mit Witz und Schriften,", "tokens": ["Ver\u00b7g\u00f6t\u00b7tert", "nur", "mit", "Witz", "und", "Schrif\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.3": {"text": "Ihr Schm\u00e4uchler zu Paris, die Stolz und Sold erhob;", "tokens": ["Ihr", "Schm\u00e4uch\u00b7ler", "zu", "Pa\u00b7ris", ",", "die", "Stolz", "und", "Sold", "er\u00b7hob", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "APPR", "NE", "$,", "ART", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Hier regt ein ", "tokens": ["Hier", "regt", "ein"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.5": {"text": "Zwingt die Natur, versetzet H\u00fcgel,", "tokens": ["Zwingt", "die", "Na\u00b7tur", ",", "ver\u00b7set\u00b7zet", "H\u00fc\u00b7gel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und bl\u00e4ht sich gleichwohl nicht auf ein erkauftes Lob.", "tokens": ["Und", "bl\u00e4ht", "sich", "gleich\u00b7wohl", "nicht", "auf", "ein", "er\u00b7kauf\u00b7tes", "Lob", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "PTKNEG", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die freye Muse nur gesteht,", "tokens": ["Die", "frey\u00b7e", "Mu\u00b7se", "nur", "ge\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}}, "stanza.49": {"line.1": {"text": "Der Kenner Auge zu erfreuen,", "tokens": ["Der", "Ken\u00b7ner", "Au\u00b7ge", "zu", "er\u00b7freu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Von redender Natur f\u00fcr Meisterst\u00fccke lie\u00df;", "tokens": ["Von", "re\u00b7den\u00b7der", "Na\u00b7tur", "f\u00fcr", "Meis\u00b7ter\u00b7st\u00fc\u00b7cke", "lie\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Was ", "tokens": ["Was"], "token_info": ["word"], "pos": ["PWS"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Die oft den Preis der Kunst gewonnen,", "tokens": ["Die", "oft", "den", "Preis", "der", "Kunst", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Wenn selbst ", "tokens": ["Wenn", "selbst"], "token_info": ["word", "word"], "pos": ["KOUS", "ADV"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Das liebt der ", "tokens": ["Das", "liebt", "der"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.7": {"text": "Dem widmet sein Geschmack den neuvollf\u00fchrten Saal.", "tokens": ["Dem", "wid\u00b7met", "sein", "Ge\u00b7schmack", "den", "neu\u00b7voll\u00b7f\u00fchr\u00b7ten", "Saal", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.50": {"line.1": {"text": "Was macht ", "tokens": ["Was", "macht"], "token_info": ["word", "word"], "pos": ["PWS", "VVFIN"], "meter": "-+", "measure": "iambic.single"}, "line.2": {"text": "So gro\u00dfer Muster, schm\u00fcckt er Fluren;", "tokens": ["So", "gro\u00b7\u00dfer", "Mus\u00b7ter", ",", "schm\u00fcckt", "er", "Flu\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJA", "NN", "$,", "VVFIN", "PPER", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Pflanzt G\u00e4rten neuer Art, die Deutschland nie gekannt:", "tokens": ["Pflanzt", "G\u00e4r\u00b7ten", "neu\u00b7er", "Art", ",", "die", "Deutschland", "nie", "ge\u00b7kannt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Ein j\u00e4her Berg wird ihm zur Fl\u00e4che:", "tokens": ["Ein", "j\u00e4\u00b7her", "Berg", "wird", "ihm", "zur", "Fl\u00e4\u00b7che", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er st\u00e4rkt des rauhen Bodens Schw\u00e4che,", "tokens": ["Er", "st\u00e4rkt", "des", "rau\u00b7hen", "Bo\u00b7dens", "Schw\u00e4\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Zeugt Hayne wilder Zucht, so klug als Engelland.", "tokens": ["Zeugt", "Hay\u00b7ne", "wil\u00b7der", "Zucht", ",", "so", "klug", "als", "En\u00b7gel\u00b7land", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ADJA", "NN", "$,", "ADV", "ADJD", "KOKOM", "NE", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein Irrgang zeiget ", "tokens": ["Sein", "Irr\u00b7gang", "zei\u00b7get"], "token_info": ["word", "word", "word"], "pos": ["PPOSAT", "NN", "VVFIN"], "meter": "-+-+-", "measure": "iambic.di"}, "line.8": {"text": "Und mitten in der Kunst herrscht gleichwohl die Natur.", "tokens": ["Und", "mit\u00b7ten", "in", "der", "Kunst", "herrscht", "gleich\u00b7wohl", "die", "Na\u00b7tur", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Dort, wo aus den verborgnen Sch\u00e4tzen,", "tokens": ["Dort", ",", "wo", "aus", "den", "ver\u00b7borg\u00b7nen", "Sch\u00e4t\u00b7zen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "PWAV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der Menschen Kr\u00e4fte zu ersetzen,", "tokens": ["Der", "Men\u00b7schen", "Kr\u00e4f\u00b7te", "zu", "er\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Abgrund tiefer Kluft ein heilsam Wasser quillt:", "tokens": ["Der", "Ab\u00b7grund", "tie\u00b7fer", "Kluft", "ein", "heil\u00b7sam", "Was\u00b7ser", "quillt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "ART", "ADJD", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "In ", "tokens": ["In"], "token_info": ["word"], "pos": ["APPR"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Da sieht man andrer B\u00e4der Bl\u00f6\u00dfe,", "tokens": ["Da", "sieht", "man", "an\u00b7drer", "B\u00e4\u00b7der", "Bl\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Wenn ", "tokens": ["Wenn"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Indem den Ort, der Heil gebracht,", "tokens": ["In\u00b7dem", "den", "Ort", ",", "der", "Heil", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "$,", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Was seh ich? Sind es Thuillerien,", "tokens": ["Was", "seh", "ich", "?", "Sind", "es", "Thu\u00b7il\u00b7le\u00b7ri\u00b7en", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "VAFIN", "PPER", "NE", "$,"], "meter": "-+-+-+----", "measure": "unknown.measure.tri"}, "line.2": {"text": "Wo tausend dichte Linden bl\u00fchen,", "tokens": ["Wo", "tau\u00b7send", "dich\u00b7te", "Lin\u00b7den", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "CARD", "ADJA", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Und G\u00e4nge sonder Schlu\u00df den sch\u00e4rfsten Blick erfreun?", "tokens": ["Und", "G\u00e4n\u00b7ge", "son\u00b7der", "Schlu\u00df", "den", "sch\u00e4rfs\u00b7ten", "Blick", "er\u00b7freun", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sind es ", "tokens": ["Sind", "es"], "token_info": ["word", "word"], "pos": ["VAFIN", "PPER"], "meter": "+-", "measure": "trochaic.single"}, "line.5": {"text": "O nein! auch ", "tokens": ["O", "nein", "!", "auch"], "token_info": ["word", "word", "punct", "word"], "pos": ["NE", "PTKANT", "$.", "ADV"], "meter": "+-+", "measure": "trochaic.di"}, "line.6": {"text": "Hat ihres gleichen nicht, und mu\u00df ein Wunder seyn.", "tokens": ["Hat", "ih\u00b7res", "glei\u00b7chen", "nicht", ",", "und", "mu\u00df", "ein", "Wun\u00b7der", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPOSAT", "ADJA", "PTKNEG", "$,", "KON", "VMFIN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und gieng ihr nicht die Aue vor,", "tokens": ["Und", "gieng", "ihr", "nicht", "die", "Au\u00b7e", "vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Was gliche wohl dem Raum um Cassels sch\u00f6nstes Thor?", "tokens": ["Was", "gli\u00b7che", "wohl", "dem", "Raum", "um", "Cas\u00b7sels", "sch\u00f6ns\u00b7tes", "Thor", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "K\u00f6nnt ich Geschmack und Anstalt zeigen,", "tokens": ["K\u00f6nnt", "ich", "Ge\u00b7schmack", "und", "An\u00b7stalt", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.10": {"text": "Womit so Dein Pallast, als edler Garten prangt!", "tokens": ["Wo\u00b7mit", "so", "Dein", "Pal\u00b7last", ",", "als", "ed\u00b7ler", "Gar\u00b7ten", "prangt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPOSAT", "NN", "$,", "KOUS", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nach Thaten, so die Welt verehret,", "tokens": ["Nach", "Tha\u00b7ten", ",", "so", "die", "Welt", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Hast Du die Ruh, die Dir geh\u00f6ret,", "tokens": ["Hast", "Du", "die", "Ruh", ",", "die", "Dir", "ge\u00b7h\u00f6\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Als zweyter ", "tokens": ["Als", "zwey\u00b7ter"], "token_info": ["word", "word"], "pos": ["KOUS", "NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.14": {"text": "Wo Dich ein kluges Buch ergetzt,", "tokens": ["Wo", "Dich", "ein", "klu\u00b7ges", "Buch", "er\u00b7getzt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.15": {"text": "Wenn Dich das Spiel der Welt oft in Verwundrung setzt.", "tokens": ["Wenn", "Dich", "das", "Spiel", "der", "Welt", "oft", "in", "Ver\u00b7wund\u00b7rung", "setzt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN", "ADV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.53": {"line.1": {"text": "Und du, o ", "tokens": ["Und", "du", ",", "o"], "token_info": ["word", "word", "punct", "word"], "pos": ["KON", "PPER", "$,", "FM"], "meter": "+-+", "measure": "trochaic.di"}, "line.2": {"text": "Sich sch\u00f6ner kaum gedenken lassen,", "tokens": ["Sich", "sch\u00f6\u00b7ner", "kaum", "ge\u00b7den\u00b7ken", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADV", "VVINF", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Du bestes Musterbild von neuer St\u00e4dte Bau!", "tokens": ["Du", "bes\u00b7tes", "Mus\u00b7ter\u00b7bild", "von", "neu\u00b7er", "St\u00e4d\u00b7te", "Bau", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "APPR", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Kann eine Schnur wohl gleicher gehen,", "tokens": ["Kann", "ei\u00b7ne", "Schnur", "wohl", "glei\u00b7cher", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "ADV", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Als H\u00e4user und Pall\u00e4ste stehen?", "tokens": ["Als", "H\u00e4u\u00b7ser", "und", "Pal\u00b7l\u00e4s\u00b7te", "ste\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Sogar dein Tempel folgt dem Ebenmaa\u00df genau.", "tokens": ["So\u00b7gar", "dein", "Tem\u00b7pel", "folgt", "dem", "E\u00b7ben\u00b7maa\u00df", "ge\u00b7nau", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Stra\u00dfen Durchschnitt stellt ihn dar,", "tokens": ["Der", "Stra\u00b7\u00dfen", "Durch\u00b7schnitt", "stellt", "ihn", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Und hoher Linden Kreis umschlie\u00dft den Vorhoff gar.", "tokens": ["Und", "ho\u00b7her", "Lin\u00b7den", "Kreis", "um\u00b7schlie\u00dft", "den", "Vor\u00b7hoff", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NE", "NN", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.54": {"line.1": {"text": "Ob ihrer Baukunst Seltenheiten", "tokens": ["Ob", "ih\u00b7rer", "Bau\u00b7kunst", "Sel\u00b7ten\u00b7hei\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die\u00df Kleinod Hessens nicht, der M\u00e4ngel wegen, schilt?", "tokens": ["Die\u00df", "Klei\u00b7nod", "Hes\u00b7sens", "nicht", ",", "der", "M\u00e4n\u00b7gel", "we\u00b7gen", ",", "schilt", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PDS", "NN", "NE", "PTKNEG", "$,", "ART", "NN", "APPR", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "An Gr\u00f6\u00dfe kann ", "tokens": ["An", "Gr\u00f6\u00b7\u00dfe", "kann"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NN", "VMFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.4": {"text": "An Ordnung mu\u00df es unterliegen:", "tokens": ["An", "Ord\u00b7nung", "mu\u00df", "es", "un\u00b7ter\u00b7lie\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Weil Schnur und Winkelmaa\u00df hier sonder Ausnahm gilt;", "tokens": ["Weil", "Schnur", "und", "Win\u00b7kel\u00b7maa\u00df", "hier", "son\u00b7der", "Aus\u00b7nahm", "gilt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "ADV", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und seiner lichten Stra\u00dfen Pracht,", "tokens": ["Und", "sei\u00b7ner", "lich\u00b7ten", "Stra\u00b7\u00dfen", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Kein eingeschr\u00e4nkter Wall das Wachsthum schwierig macht.", "tokens": ["Kein", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ter", "Wall", "das", "Wach\u00b7sthum", "schwie\u00b7rig", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.55": {"line.1": {"text": "Ihr Musen! soll ich weiter singen?", "tokens": ["Ihr", "Mu\u00b7sen", "!", "soll", "ich", "wei\u00b7ter", "sin\u00b7gen", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "La\u00dft k\u00fcnftig mir ein Lied gelingen;", "tokens": ["La\u00dft", "k\u00fcnf\u00b7tig", "mir", "ein", "Lied", "ge\u00b7lin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df ", "tokens": ["Da\u00df"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.4": {"text": "Sein B\u00fcchersaal, und hundert St\u00fccke", "tokens": ["Sein", "B\u00fc\u00b7cher\u00b7saal", ",", "und", "hun\u00b7dert", "St\u00fc\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "$,", "KON", "CARD", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Von Kunst und Witz, ziehn eure Blicke", "tokens": ["Von", "Kunst", "und", "Witz", ",", "ziehn", "eu\u00b7re", "Bli\u00b7cke"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Schon l\u00e4ngst auf das Geb\u00e4u, wo ", "tokens": ["Schon", "l\u00e4ngst", "auf", "das", "Ge\u00b7b\u00e4u", ",", "wo"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$,", "PWAV"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.7": {"text": "Hier wird einst, stimmt ", "tokens": ["Hier", "wird", "einst", ",", "stimmt"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ADV", "VAFIN", "ADV", "$,", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.8": {"text": "Von jeder Wissenschaft ein ewger Wohnplatz seyn.", "tokens": ["Von", "je\u00b7der", "Wis\u00b7sen\u00b7schaft", "ein", "ew\u00b7ger", "Wohn\u00b7platz", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.56": {"line.1": {"text": "Gesellschaft! die du bey den Siegen", "tokens": ["Ge\u00b7sell\u00b7schaft", "!", "die", "du", "bey", "den", "Sie\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "PRELS", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des r\u00e4chenden ", "tokens": ["Des", "r\u00e4\u00b7chen\u00b7den"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Der so gerecht als klug Europens Wage lenkt;", "tokens": ["Der", "so", "ge\u00b7recht", "als", "klug", "Eu\u00b7ro\u00b7pens", "Wa\u00b7ge", "lenkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ADJD", "KOKOM", "ADJD", "NE", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Versammlung, reich an edlen Geistern,", "tokens": ["Ver\u00b7samm\u00b7lung", ",", "reich", "an", "ed\u00b7len", "Geis\u00b7tern", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJD", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "La\u00df dich die rege Glut bemeistern,", "tokens": ["La\u00df", "dich", "die", "re\u00b7ge", "Glut", "be\u00b7meis\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "+-+--+-+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Die Dank und Ehrfurcht l\u00e4ngst in deine Brust gesenkt;", "tokens": ["Die", "Dank", "und", "Ehr\u00b7furcht", "l\u00e4ngst", "in", "dei\u00b7ne", "Brust", "ge\u00b7senkt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und stimme solche Lieder an,", "tokens": ["Und", "stim\u00b7me", "sol\u00b7che", "Lie\u00b7der", "an", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Da\u00df selbst der Britte sie nicht sch\u00f6ner opfern kann.", "tokens": ["Da\u00df", "selbst", "der", "Brit\u00b7te", "sie", "nicht", "sch\u00f6\u00b7ner", "op\u00b7fern", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "PPER", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.57": {"line.1": {"text": "Und unsrer Zeit von Gott beschieden,", "tokens": ["Und", "uns\u00b7rer", "Zeit", "von", "Gott", "be\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Der deutschen Freyheit Schutz, der ", "tokens": ["Der", "deut\u00b7schen", "Frey\u00b7heit", "Schutz", ",", "der"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "NN", "$,", "PRELS"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bey Detting kann er Lorbern brechen,", "tokens": ["Bey", "Det\u00b7ting", "kann", "er", "Lor\u00b7bern", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VMFIN", "PPER", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Der Feinde Wuth und Hochmuth schw\u00e4chen;", "tokens": ["Der", "Fein\u00b7de", "Wuth", "und", "Hoch\u00b7muth", "schw\u00e4\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Zu Hause l\u00e4\u00dft Sein Arm den Musen Tempel weihn.", "tokens": ["Zu", "Hau\u00b7se", "l\u00e4\u00dft", "Sein", "Arm", "den", "Mu\u00b7sen", "Tem\u00b7pel", "weihn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPOSAT", "NN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "O! die\u00df besinge, theures Chor;", "tokens": ["O", "!", "die\u00df", "be\u00b7sin\u00b7ge", ",", "theu\u00b7res", "Chor", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$.", "PDS", "VVFIN", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und stell Ihn sp\u00e4ter Zeit zum Heldenmuster vor.", "tokens": ["Und", "stell", "Ihn", "sp\u00e4\u00b7ter", "Zeit", "zum", "Hel\u00b7den\u00b7mus\u00b7ter", "vor", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADJD", "NN", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.58": {"line.1": {"text": "Zwar ", "tokens": ["Zwar"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Folg ihr in feurigen Gedichten;", "tokens": ["Folg", "ihr", "in", "feu\u00b7ri\u00b7gen", "Ge\u00b7dich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Davon der laute Ton in alle Gr\u00e4nzen dringt.", "tokens": ["Da\u00b7von", "der", "lau\u00b7te", "Ton", "in", "al\u00b7le", "Gr\u00e4n\u00b7zen", "dringt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "ADJA", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und diese That nach Werth zu loben,", "tokens": ["Und", "die\u00b7se", "That", "nach", "Werth", "zu", "lo\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "APPR", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Ist ein erhabnes Werk, das Dichtern Ehre bringt.", "tokens": ["Ist", "ein", "er\u00b7hab\u00b7nes", "Werk", ",", "das", "Dich\u00b7tern", "Eh\u00b7re", "bringt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Auf! Seine Gro\u00dfmuth ganz allein,", "tokens": ["Auf", "!", "Sei\u00b7ne", "Gro\u00df\u00b7muth", "ganz", "al\u00b7lein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "$.", "PPOSAT", "NN", "ADV", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Mu\u00df k\u00fcnftighin der Stoff zu deinen Liedern seyn!", "tokens": ["Mu\u00df", "k\u00fcnf\u00b7tig\u00b7hin", "der", "Stoff", "zu", "dei\u00b7nen", "Lie\u00b7dern", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}