{"textgrid.poem.67821": {"metadata": {"author": {"name": "Herder, Johann Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "17. Die Herrlichkeit Granada's", "genre": "verse", "period": "N.A.", "pub_year": 1773, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Abenamar, Abenamar!", "tokens": ["A\u00b7be\u00b7na\u00b7mar", ",", "A\u00b7be\u00b7na\u00b7mar", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mohr aus diesem Mohrenlande,", "tokens": ["Mohr", "aus", "die\u00b7sem", "Moh\u00b7ren\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener Tag, der dich gebohren,", "tokens": ["Je\u00b7ner", "Tag", ",", "der", "dich", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hatte sch\u00f6ne grosse Zeichen:", "tokens": ["Hat\u00b7te", "sch\u00f6\u00b7ne", "gros\u00b7se", "Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "An ihm stand das Meer in Ruhe,", "tokens": ["An", "ihm", "stand", "das", "Meer", "in", "Ru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Mond, er war im Wachsen;", "tokens": ["Und", "der", "Mond", ",", "er", "war", "im", "Wach\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "APPRART", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Mohr, wer unter solchen Zeichen", "tokens": ["Mohr", ",", "wer", "un\u00b7ter", "sol\u00b7chen", "Zei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWS", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward gebohren, mu\u00df nicht l\u00fcgen.", "tokens": ["Ward", "ge\u00b7boh\u00b7ren", ",", "mu\u00df", "nicht", "l\u00fc\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VMFIN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Drauf erwiederte der Mohr ihm:", "tokens": ["Drauf", "er\u00b7wie\u00b7der\u00b7te", "der", "Mohr", "ihm", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "(wohl vernimm es, was er sagte!)", "tokens": ["(", "wohl", "ver\u00b7nimm", "es", ",", "was", "er", "sag\u00b7te", "!", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, Sennor, ich l\u00fcge dir nicht,", "tokens": ["Nein", ",", "Sen\u00b7nor", ",", "ich", "l\u00fc\u00b7ge", "dir", "nicht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Ob es mir das Leben koste.", "tokens": ["Ob", "es", "mir", "das", "Le\u00b7ben", "kos\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Denn ich bin Sohn eines Mohren,", "tokens": ["Denn", "ich", "bin", "Sohn", "ei\u00b7nes", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und einer gefangnen Christin;", "tokens": ["Und", "ei\u00b7ner", "ge\u00b7fang\u00b7nen", "Chris\u00b7tin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und noch war ich Kind und Knabe,", "tokens": ["Und", "noch", "war", "ich", "Kind", "und", "Kna\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als die Mutter oft mir sagte:", "tokens": ["Als", "die", "Mut\u00b7ter", "oft", "mir", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "L\u00fcgen, Sohn, das must du nimmer!", "tokens": ["L\u00fc\u00b7gen", ",", "Sohn", ",", "das", "must", "du", "nim\u00b7mer", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PDS", "VMFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00fcgen, Sohn, ist niedertr\u00e4chtig.", "tokens": ["L\u00fc\u00b7gen", ",", "Sohn", ",", "ist", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Um deswillen frage, K\u00f6nig,", "tokens": ["Um", "des\u00b7wil\u00b7len", "fra\u00b7ge", ",", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUI", "ADV", "VVFIN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich will dir Wahrheit reden.", "tokens": ["Und", "ich", "will", "dir", "Wahr\u00b7heit", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "\u00bbhabe Dank, Mohr Abenamar,", "tokens": ["\u00bb", "ha\u00b7be", "Dank", ",", "Mohr", "A\u00b7be\u00b7na\u00b7mar", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "NE", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df du also h\u00f6flich redest.", "tokens": ["Da\u00df", "du", "al\u00b7so", "h\u00f6f\u00b7lich", "re\u00b7dest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was sind das f\u00fcr hohe Schl\u00f6sser,", "tokens": ["Was", "sind", "das", "f\u00fcr", "ho\u00b7he", "Schl\u00f6s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die dort stehn und wiedergl\u00e4nzen?\u00ab", "tokens": ["Die", "dort", "stehn", "und", "wie\u00b7der\u00b7gl\u00e4n\u00b7zen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "VVINF", "KON", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Dies, Sennor, ist der Alhambra,", "tokens": ["Dies", ",", "Sen\u00b7nor", ",", "ist", "der", "Al\u00b7hamb\u00b7ra", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "NE", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und das andre die Mesquita;", "tokens": ["Und", "das", "and\u00b7re", "die", "Mes\u00b7qui\u00b7ta", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "ART", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Jenes sind die Alijares,", "tokens": ["Je\u00b7nes", "sind", "die", "A\u00b7li\u00b7ja\u00b7res", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundernsw\u00fcrdig aufgef\u00fchret.", "tokens": ["Wun\u00b7derns\u00b7w\u00fcr\u00b7dig", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und der Mohr, der auf sie f\u00fchrte,", "tokens": ["Und", "der", "Mohr", ",", "der", "auf", "sie", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hatte Tags hundert Dublonen,", "tokens": ["Hat\u00b7te", "Tags", "hun\u00b7dert", "Du\u00b7blo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber wenn er nicht am Bau war,", "tokens": ["A\u00b7ber", "wenn", "er", "nicht", "am", "Bau", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Must' er Tages hundert zahlen.", "tokens": ["Must'", "er", "Ta\u00b7ges", "hun\u00b7dert", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "CARD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Jenes ist der Gen'ralife,", "tokens": ["Je\u00b7nes", "ist", "der", "Gen'\u00b7ra\u00b7li\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein Garte sonder Gleichen.", "tokens": ["Ist", "ein", "Gar\u00b7te", "son\u00b7der", "Glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Diese Th\u00fcrme sind Bermejas,", "tokens": ["Die\u00b7se", "Th\u00fcr\u00b7me", "sind", "Ber\u00b7me\u00b7jas", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Sind ein Schlo\u00df von grosser Veste.", "tokens": ["Sind", "ein", "Schlo\u00df", "von", "gros\u00b7ser", "Ves\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Da erwiedert K\u00f6nig Juan:", "tokens": ["Da", "er\u00b7wie\u00b7dert", "K\u00f6\u00b7nig", "Juan", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "(wohl vernimm es, was er sagte!)", "tokens": ["(", "wohl", "ver\u00b7nimm", "es", ",", "was", "er", "sag\u00b7te", "!", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn du es, Granada, wolltest,", "tokens": ["Wenn", "du", "es", ",", "Gra\u00b7na\u00b7da", ",", "woll\u00b7test", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "NE", "$,", "VMFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wollt' ich mich mit dir verm\u00e4hlen,", "tokens": ["Wollt'", "ich", "mich", "mit", "dir", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "G\u00e4be dir zur Morgengabe", "tokens": ["G\u00e4\u00b7be", "dir", "zur", "Mor\u00b7gen\u00b7ga\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mein Cordova und Sevilla.", "tokens": ["Mein", "Cor\u00b7do\u00b7va", "und", "Se\u00b7vil\u00b7la", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "\u00bbbin verm\u00e4hlet, K\u00f6nig Juan,", "tokens": ["\u00bb", "bin", "ver\u00b7m\u00e4h\u00b7let", ",", "K\u00f6\u00b7nig", "Juan", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "VVPP", "$,", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bin verm\u00e4hlt und bin nicht Wittwe;", "tokens": ["Bin", "ver\u00b7m\u00e4hlt", "und", "bin", "nicht", "Witt\u00b7we", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VAFIN", "PTKNEG", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mein Gemahl der Mohrenk\u00f6nig,", "tokens": ["Mein", "Ge\u00b7mahl", "der", "Moh\u00b7ren\u00b7k\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebt mich, als sein grosses Gut.\u00ab", "tokens": ["Liebt", "mich", ",", "als", "sein", "gros\u00b7ses", "Gut", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Abenamar, Abenamar!", "tokens": ["A\u00b7be\u00b7na\u00b7mar", ",", "A\u00b7be\u00b7na\u00b7mar", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Mohr aus diesem Mohrenlande,", "tokens": ["Mohr", "aus", "die\u00b7sem", "Moh\u00b7ren\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PDAT", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Jener Tag, der dich gebohren,", "tokens": ["Je\u00b7ner", "Tag", ",", "der", "dich", "ge\u00b7boh\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Hatte sch\u00f6ne grosse Zeichen:", "tokens": ["Hat\u00b7te", "sch\u00f6\u00b7ne", "gros\u00b7se", "Zei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "An ihm stand das Meer in Ruhe,", "tokens": ["An", "ihm", "stand", "das", "Meer", "in", "Ru\u00b7he", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "ART", "NN", "APPR", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der Mond, er war im Wachsen;", "tokens": ["Und", "der", "Mond", ",", "er", "war", "im", "Wach\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PPER", "VAFIN", "APPRART", "NN", "$."], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Mohr, wer unter solchen Zeichen", "tokens": ["Mohr", ",", "wer", "un\u00b7ter", "sol\u00b7chen", "Zei\u00b7chen"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "PWS", "APPR", "PIAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ward gebohren, mu\u00df nicht l\u00fcgen.", "tokens": ["Ward", "ge\u00b7boh\u00b7ren", ",", "mu\u00df", "nicht", "l\u00fc\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "$,", "VMFIN", "PTKNEG", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Drauf erwiederte der Mohr ihm:", "tokens": ["Drauf", "er\u00b7wie\u00b7der\u00b7te", "der", "Mohr", "ihm", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "PPER", "$."], "meter": "+-+---+-", "measure": "unknown.measure.tri"}, "line.2": {"text": "(wohl vernimm es, was er sagte!)", "tokens": ["(", "wohl", "ver\u00b7nimm", "es", ",", "was", "er", "sag\u00b7te", "!", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Nein, Sennor, ich l\u00fcge dir nicht,", "tokens": ["Nein", ",", "Sen\u00b7nor", ",", "ich", "l\u00fc\u00b7ge", "dir", "nicht", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NE", "$,", "PPER", "VVFIN", "PPER", "PTKNEG", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Ob es mir das Leben koste.", "tokens": ["Ob", "es", "mir", "das", "Le\u00b7ben", "kos\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Denn ich bin Sohn eines Mohren,", "tokens": ["Denn", "ich", "bin", "Sohn", "ei\u00b7nes", "Moh\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VAFIN", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und einer gefangnen Christin;", "tokens": ["Und", "ei\u00b7ner", "ge\u00b7fang\u00b7nen", "Chris\u00b7tin", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Und noch war ich Kind und Knabe,", "tokens": ["Und", "noch", "war", "ich", "Kind", "und", "Kna\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Als die Mutter oft mir sagte:", "tokens": ["Als", "die", "Mut\u00b7ter", "oft", "mir", "sag\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "ADV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "L\u00fcgen, Sohn, das must du nimmer!", "tokens": ["L\u00fc\u00b7gen", ",", "Sohn", ",", "das", "must", "du", "nim\u00b7mer", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "PDS", "VMFIN", "PPER", "ADV", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "L\u00fcgen, Sohn, ist niedertr\u00e4chtig.", "tokens": ["L\u00fc\u00b7gen", ",", "Sohn", ",", "ist", "nie\u00b7der\u00b7tr\u00e4ch\u00b7tig", "."], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "VAFIN", "ADJD", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Um deswillen frage, K\u00f6nig,", "tokens": ["Um", "des\u00b7wil\u00b7len", "fra\u00b7ge", ",", "K\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KOUI", "ADV", "VVFIN", "$,", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Und ich will dir Wahrheit reden.", "tokens": ["Und", "ich", "will", "dir", "Wahr\u00b7heit", "re\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "\u00bbhabe Dank, Mohr Abenamar,", "tokens": ["\u00bb", "ha\u00b7be", "Dank", ",", "Mohr", "A\u00b7be\u00b7na\u00b7mar", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "NN", "$,", "NE", "NE", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Da\u00df du also h\u00f6flich redest.", "tokens": ["Da\u00df", "du", "al\u00b7so", "h\u00f6f\u00b7lich", "re\u00b7dest", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Was sind das f\u00fcr hohe Schl\u00f6sser,", "tokens": ["Was", "sind", "das", "f\u00fcr", "ho\u00b7he", "Schl\u00f6s\u00b7ser", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PDS", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die dort stehn und wiedergl\u00e4nzen?\u00ab", "tokens": ["Die", "dort", "stehn", "und", "wie\u00b7der\u00b7gl\u00e4n\u00b7zen", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "VVINF", "KON", "VVINF", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "Dies, Sennor, ist der Alhambra,", "tokens": ["Dies", ",", "Sen\u00b7nor", ",", "ist", "der", "Al\u00b7hamb\u00b7ra", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "$,", "NE", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Und das andre die Mesquita;", "tokens": ["Und", "das", "and\u00b7re", "die", "Mes\u00b7qui\u00b7ta", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PIS", "ART", "NE", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Jenes sind die Alijares,", "tokens": ["Je\u00b7nes", "sind", "die", "A\u00b7li\u00b7ja\u00b7res", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wundernsw\u00fcrdig aufgef\u00fchret.", "tokens": ["Wun\u00b7derns\u00b7w\u00fcr\u00b7dig", "auf\u00b7ge\u00b7f\u00fch\u00b7ret", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Und der Mohr, der auf sie f\u00fchrte,", "tokens": ["Und", "der", "Mohr", ",", "der", "auf", "sie", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$,", "PRELS", "APPR", "PPER", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Hatte Tags hundert Dublonen,", "tokens": ["Hat\u00b7te", "Tags", "hun\u00b7dert", "Du\u00b7blo\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "CARD", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber wenn er nicht am Bau war,", "tokens": ["A\u00b7ber", "wenn", "er", "nicht", "am", "Bau", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PTKNEG", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Must' er Tages hundert zahlen.", "tokens": ["Must'", "er", "Ta\u00b7ges", "hun\u00b7dert", "zah\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "NN", "CARD", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.20": {"line.1": {"text": "Jenes ist der Gen'ralife,", "tokens": ["Je\u00b7nes", "ist", "der", "Gen'\u00b7ra\u00b7li\u00b7fe", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist ein Garte sonder Gleichen.", "tokens": ["Ist", "ein", "Gar\u00b7te", "son\u00b7der", "Glei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Diese Th\u00fcrme sind Bermejas,", "tokens": ["Die\u00b7se", "Th\u00fcr\u00b7me", "sind", "Ber\u00b7me\u00b7jas", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VAFIN", "NE", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.4": {"text": "Sind ein Schlo\u00df von grosser Veste.", "tokens": ["Sind", "ein", "Schlo\u00df", "von", "gros\u00b7ser", "Ves\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Da erwiedert K\u00f6nig Juan:", "tokens": ["Da", "er\u00b7wie\u00b7dert", "K\u00f6\u00b7nig", "Juan", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "NE", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "(wohl vernimm es, was er sagte!)", "tokens": ["(", "wohl", "ver\u00b7nimm", "es", ",", "was", "er", "sag\u00b7te", "!", ")"], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "ADJD", "PPER", "$,", "PWS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Wenn du es, Granada, wolltest,", "tokens": ["Wenn", "du", "es", ",", "Gra\u00b7na\u00b7da", ",", "woll\u00b7test", ","], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "$,", "NE", "$,", "VMFIN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wollt' ich mich mit dir verm\u00e4hlen,", "tokens": ["Wollt'", "ich", "mich", "mit", "dir", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "G\u00e4be dir zur Morgengabe", "tokens": ["G\u00e4\u00b7be", "dir", "zur", "Mor\u00b7gen\u00b7ga\u00b7be"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "APPRART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Mein Cordova und Sevilla.", "tokens": ["Mein", "Cor\u00b7do\u00b7va", "und", "Se\u00b7vil\u00b7la", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "\u00bbbin verm\u00e4hlet, K\u00f6nig Juan,", "tokens": ["\u00bb", "bin", "ver\u00b7m\u00e4h\u00b7let", ",", "K\u00f6\u00b7nig", "Juan", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "VAFIN", "VVPP", "$,", "NN", "NE", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Bin verm\u00e4hlt und bin nicht Wittwe;", "tokens": ["Bin", "ver\u00b7m\u00e4hlt", "und", "bin", "nicht", "Witt\u00b7we", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "VVPP", "KON", "VAFIN", "PTKNEG", "NN", "$."], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Mein Gemahl der Mohrenk\u00f6nig,", "tokens": ["Mein", "Ge\u00b7mahl", "der", "Moh\u00b7ren\u00b7k\u00f6\u00b7nig", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Liebt mich, als sein grosses Gut.\u00ab", "tokens": ["Liebt", "mich", ",", "als", "sein", "gros\u00b7ses", "Gut", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PPOSAT", "ADJA", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}