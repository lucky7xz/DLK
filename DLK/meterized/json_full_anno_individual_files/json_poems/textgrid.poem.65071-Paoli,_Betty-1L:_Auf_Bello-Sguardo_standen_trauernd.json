{"textgrid.poem.65071": {"metadata": {"author": {"name": "Paoli, Betty", "birth": "N.A.", "death": "N.A."}, "title": "1L: Auf Bello-Sguardo standen trauernd", "genre": "verse", "period": "N.A.", "pub_year": 1854, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Auf Bello-Sguardo standen trauernd", "tokens": ["Auf", "Bel\u00b7lo\u00b7\u00b7S\u00b7guar\u00b7do", "stan\u00b7den", "trau\u00b7ernd"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADJD"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir, still und stumm, im Abendschein',", "tokens": ["Wir", ",", "still", "und", "stumm", ",", "im", "A\u00b7bend\u00b7schein'", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "KON", "ADJD", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Seelen in einander schauernd", "tokens": ["Die", "See\u00b7len", "in", "ein\u00b7an\u00b7der", "schau\u00b7ernd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Weiheku\u00df derselben Pein.", "tokens": ["Vom", "Wei\u00b7he\u00b7ku\u00df", "der\u00b7sel\u00b7ben", "Pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Erklungen war der Ruf zum Scheiden,", "tokens": ["Er\u00b7klun\u00b7gen", "war", "der", "Ruf", "zum", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Schicksals unerbittlich Wort;", "tokens": ["Des", "Schick\u00b7sals", "un\u00b7er\u00b7bitt\u00b7lich", "Wort", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob Menschen jubeln, ob sie leiden,", "tokens": ["Ob", "Men\u00b7schen", "ju\u00b7beln", ",", "ob", "sie", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unaufgehalten schreitet's fort.", "tokens": ["Un\u00b7auf\u00b7ge\u00b7hal\u00b7ten", "schrei\u00b7tet's", "fort", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Ich starrte, w\u00fcst und qualversunken,", "tokens": ["Ich", "starr\u00b7te", ",", "w\u00fcst", "und", "qual\u00b7ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Inde\u00df mein Herz im Busen brach,", "tokens": ["In\u00b7de\u00df", "mein", "Herz", "im", "Bu\u00b7sen", "brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Tages rasch verspr\u00fch'nden Funken,", "tokens": ["Des", "Ta\u00b7ges", "rasch", "ver\u00b7spr\u00fch'n\u00b7den", "Fun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Untergang der Sonne nach.", "tokens": ["Dem", "Un\u00b7ter\u00b7gang", "der", "Son\u00b7ne", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Und in dem Abendroth erkannte", "tokens": ["Und", "in", "dem", "A\u00b7ben\u00b7droth", "er\u00b7kann\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich, tief umstrickt von wachem Traum,", "tokens": ["Ich", ",", "tief", "um\u00b7strickt", "von", "wa\u00b7chem", "Traum", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Flammenschwert, das mich verbannte", "tokens": ["Das", "Flam\u00b7men\u00b7schwert", ",", "das", "mich", "ver\u00b7bann\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus kaum gefund'nen Edensraum!", "tokens": ["Aus", "kaum", "ge\u00b7fun\u00b7d'\u00b7nen", "E\u00b7dens\u00b7raum", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.5": {"line.1": {"text": "Du sah'st mich zittern und erbleichen,", "tokens": ["Du", "sah'st", "mich", "zit\u00b7tern", "und", "er\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, folgend meines Denkens Lauf,", "tokens": ["Und", ",", "fol\u00b7gend", "mei\u00b7nes", "Den\u00b7kens", "Lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sprachst du: \u00bbSieh hoffend sie entweichen!", "tokens": ["Sprachst", "du", ":", "\u00bb", "Sieh", "hof\u00b7fend", "sie", "ent\u00b7wei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "NE", "VVPP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur sch\u00f6ner geht sie wieder auf!\u00ab", "tokens": ["Nur", "sch\u00f6\u00b7ner", "geht", "sie", "wie\u00b7der", "auf", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ja! sie ersteht mit neuem Prangen,", "tokens": ["Ja", "!", "sie", "er\u00b7steht", "mit", "neu\u00b7em", "Pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie viel der Blumen, frostversehrt,", "tokens": ["Wie", "viel", "der", "Blu\u00b7men", ",", "frost\u00b7ver\u00b7sehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verduftet auch und hingegangen,", "tokens": ["Ver\u00b7duf\u00b7tet", "auch", "und", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil sie ihr w\u00e4rmend Licht entbehrt!", "tokens": ["Weil", "sie", "ihr", "w\u00e4r\u00b7mend", "Licht", "ent\u00b7behrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Hinweg mit diesem Trost, der bange", "tokens": ["Hin\u00b7weg", "mit", "die\u00b7sem", "Trost", ",", "der", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und drohend meine Brust durchbebt!", "tokens": ["Und", "dro\u00b7hend", "mei\u00b7ne", "Brust", "durch\u00b7bebt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wei\u00dft du, ob Ein's von uns die lange,", "tokens": ["Wei\u00dft", "du", ",", "ob", "Ein's", "von", "uns", "die", "lan\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PIS", "APPR", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die finst're Nacht auch \u00fcberlebt?", "tokens": ["Die", "finst'\u00b7re", "Nacht", "auch", "\u00fc\u00b7ber\u00b7lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Und mag das G\u00fcnstigste geschehen,", "tokens": ["Und", "mag", "das", "G\u00fcns\u00b7tigs\u00b7te", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Strahlt uns einst wieder Sonnenschein,", "tokens": ["Strahlt", "uns", "einst", "wie\u00b7der", "Son\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird ein dereinst'ges Wiedersehen", "tokens": ["Wird", "ein", "der\u00b7einst'\u00b7ges", "Wie\u00b7der\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn auch ein Wiederfinden sein?", "tokens": ["Denn", "auch", "ein", "Wie\u00b7der\u00b7fin\u00b7den", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Jedweder forschende Gedanke,", "tokens": ["Jed\u00b7we\u00b7der", "for\u00b7schen\u00b7de", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+--+---+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Erkenntni\u00df, welche neu entbrennt,", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", ",", "wel\u00b7che", "neu", "ent\u00b7brennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Abgrund sind sie, eine Schranke,", "tokens": ["Ein", "Ab\u00b7grund", "sind", "sie", ",", "ei\u00b7ne", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wodurch Getrennte ", "tokens": ["Wo\u00b7durch", "Ge\u00b7trenn\u00b7te"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "Der Fluch ist dieses, der hienieden", "tokens": ["Der", "Fluch", "ist", "die\u00b7ses", ",", "der", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PDS", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Schaar der Strebenden umflicht!", "tokens": ["Die", "Schaar", "der", "Stre\u00b7ben\u00b7den", "um\u00b7flicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat sich erst Geist von Geist geschieden,", "tokens": ["Hat", "sich", "erst", "Geist", "von", "Geist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald findet Herz zum Herzen nicht!", "tokens": ["Bald", "fin\u00b7det", "Herz", "zum", "Her\u00b7zen", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPRART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Des Weisen Wort hallt ewig wieder:", "tokens": ["Des", "Wei\u00b7sen", "Wort", "hallt", "e\u00b7wig", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdie Asche wird nicht mehr zur Gluth!", "tokens": ["\u00bb", "die", "A\u00b7sche", "wird", "nicht", "mehr", "zur", "Gluth", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du tauchst zur K\u00fchlung deine Glieder", "tokens": ["Du", "tauchst", "zur", "K\u00fch\u00b7lung", "dei\u00b7ne", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht zweimal in dieselbe Fluth!\u00ab", "tokens": ["Nicht", "zwei\u00b7mal", "in", "die\u00b7sel\u00b7be", "Fluth", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Auf Bello-Sguardo standen trauernd", "tokens": ["Auf", "Bel\u00b7lo\u00b7\u00b7S\u00b7guar\u00b7do", "stan\u00b7den", "trau\u00b7ernd"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NE", "VVFIN", "ADJD"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Wir, still und stumm, im Abendschein',", "tokens": ["Wir", ",", "still", "und", "stumm", ",", "im", "A\u00b7bend\u00b7schein'", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "KON", "ADJD", "$,", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Seelen in einander schauernd", "tokens": ["Die", "See\u00b7len", "in", "ein\u00b7an\u00b7der", "schau\u00b7ernd"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PRF", "ADJD"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Vom Weiheku\u00df derselben Pein.", "tokens": ["Vom", "Wei\u00b7he\u00b7ku\u00df", "der\u00b7sel\u00b7ben", "Pein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Erklungen war der Ruf zum Scheiden,", "tokens": ["Er\u00b7klun\u00b7gen", "war", "der", "Ruf", "zum", "Schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Des Schicksals unerbittlich Wort;", "tokens": ["Des", "Schick\u00b7sals", "un\u00b7er\u00b7bitt\u00b7lich", "Wort", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ob Menschen jubeln, ob sie leiden,", "tokens": ["Ob", "Men\u00b7schen", "ju\u00b7beln", ",", "ob", "sie", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVINF", "$,", "KOUS", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Unaufgehalten schreitet's fort.", "tokens": ["Un\u00b7auf\u00b7ge\u00b7hal\u00b7ten", "schrei\u00b7tet's", "fort", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Ich starrte, w\u00fcst und qualversunken,", "tokens": ["Ich", "starr\u00b7te", ",", "w\u00fcst", "und", "qual\u00b7ver\u00b7sun\u00b7ken", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Inde\u00df mein Herz im Busen brach,", "tokens": ["In\u00b7de\u00df", "mein", "Herz", "im", "Bu\u00b7sen", "brach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Des Tages rasch verspr\u00fch'nden Funken,", "tokens": ["Des", "Ta\u00b7ges", "rasch", "ver\u00b7spr\u00fch'n\u00b7den", "Fun\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Untergang der Sonne nach.", "tokens": ["Dem", "Un\u00b7ter\u00b7gang", "der", "Son\u00b7ne", "nach", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Und in dem Abendroth erkannte", "tokens": ["Und", "in", "dem", "A\u00b7ben\u00b7droth", "er\u00b7kann\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ich, tief umstrickt von wachem Traum,", "tokens": ["Ich", ",", "tief", "um\u00b7strickt", "von", "wa\u00b7chem", "Traum", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Flammenschwert, das mich verbannte", "tokens": ["Das", "Flam\u00b7men\u00b7schwert", ",", "das", "mich", "ver\u00b7bann\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Aus kaum gefund'nen Edensraum!", "tokens": ["Aus", "kaum", "ge\u00b7fun\u00b7d'\u00b7nen", "E\u00b7dens\u00b7raum", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "ADJA", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.16": {"line.1": {"text": "Du sah'st mich zittern und erbleichen,", "tokens": ["Du", "sah'st", "mich", "zit\u00b7tern", "und", "er\u00b7blei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "VVFIN", "KON", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und, folgend meines Denkens Lauf,", "tokens": ["Und", ",", "fol\u00b7gend", "mei\u00b7nes", "Den\u00b7kens", "Lauf", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADJD", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sprachst du: \u00bbSieh hoffend sie entweichen!", "tokens": ["Sprachst", "du", ":", "\u00bb", "Sieh", "hof\u00b7fend", "sie", "ent\u00b7wei\u00b7chen", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$.", "$(", "NE", "VVPP", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nur sch\u00f6ner geht sie wieder auf!\u00ab", "tokens": ["Nur", "sch\u00f6\u00b7ner", "geht", "sie", "wie\u00b7der", "auf", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Ja! sie ersteht mit neuem Prangen,", "tokens": ["Ja", "!", "sie", "er\u00b7steht", "mit", "neu\u00b7em", "Pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wie viel der Blumen, frostversehrt,", "tokens": ["Wie", "viel", "der", "Blu\u00b7men", ",", "frost\u00b7ver\u00b7sehrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Verduftet auch und hingegangen,", "tokens": ["Ver\u00b7duf\u00b7tet", "auch", "und", "hin\u00b7ge\u00b7gan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Weil sie ihr w\u00e4rmend Licht entbehrt!", "tokens": ["Weil", "sie", "ihr", "w\u00e4r\u00b7mend", "Licht", "ent\u00b7behrt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "VAFIN", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Hinweg mit diesem Trost, der bange", "tokens": ["Hin\u00b7weg", "mit", "die\u00b7sem", "Trost", ",", "der", "ban\u00b7ge"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "APPR", "PDAT", "NN", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Und drohend meine Brust durchbebt!", "tokens": ["Und", "dro\u00b7hend", "mei\u00b7ne", "Brust", "durch\u00b7bebt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wei\u00dft du, ob Ein's von uns die lange,", "tokens": ["Wei\u00dft", "du", ",", "ob", "Ein's", "von", "uns", "die", "lan\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PIS", "APPR", "PPER", "ART", "ADJA", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Die finst're Nacht auch \u00fcberlebt?", "tokens": ["Die", "finst'\u00b7re", "Nacht", "auch", "\u00fc\u00b7ber\u00b7lebt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Und mag das G\u00fcnstigste geschehen,", "tokens": ["Und", "mag", "das", "G\u00fcns\u00b7tigs\u00b7te", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Strahlt uns einst wieder Sonnenschein,", "tokens": ["Strahlt", "uns", "einst", "wie\u00b7der", "Son\u00b7nen\u00b7schein", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wird ein dereinst'ges Wiedersehen", "tokens": ["Wird", "ein", "der\u00b7einst'\u00b7ges", "Wie\u00b7der\u00b7se\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Denn auch ein Wiederfinden sein?", "tokens": ["Denn", "auch", "ein", "Wie\u00b7der\u00b7fin\u00b7den", "sein", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Jedweder forschende Gedanke,", "tokens": ["Jed\u00b7we\u00b7der", "for\u00b7schen\u00b7de", "Ge\u00b7dan\u00b7ke", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "$,"], "meter": "+--+---+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Erkenntni\u00df, welche neu entbrennt,", "tokens": ["Er\u00b7kennt\u00b7ni\u00df", ",", "wel\u00b7che", "neu", "ent\u00b7brennt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Abgrund sind sie, eine Schranke,", "tokens": ["Ein", "Ab\u00b7grund", "sind", "sie", ",", "ei\u00b7ne", "Schran\u00b7ke", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "$,", "ART", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wodurch Getrennte ", "tokens": ["Wo\u00b7durch", "Ge\u00b7trenn\u00b7te"], "token_info": ["word", "word"], "pos": ["PWAV", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.21": {"line.1": {"text": "Der Fluch ist dieses, der hienieden", "tokens": ["Der", "Fluch", "ist", "die\u00b7ses", ",", "der", "hien\u00b7ie\u00b7den"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "VAFIN", "PDS", "$,", "PRELS", "ADV"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Die Schaar der Strebenden umflicht!", "tokens": ["Die", "Schaar", "der", "Stre\u00b7ben\u00b7den", "um\u00b7flicht", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hat sich erst Geist von Geist geschieden,", "tokens": ["Hat", "sich", "erst", "Geist", "von", "Geist", "ge\u00b7schie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "ADV", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Bald findet Herz zum Herzen nicht!", "tokens": ["Bald", "fin\u00b7det", "Herz", "zum", "Her\u00b7zen", "nicht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "APPRART", "NN", "PTKNEG", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Des Weisen Wort hallt ewig wieder:", "tokens": ["Des", "Wei\u00b7sen", "Wort", "hallt", "e\u00b7wig", "wie\u00b7der", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "ADJD", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbdie Asche wird nicht mehr zur Gluth!", "tokens": ["\u00bb", "die", "A\u00b7sche", "wird", "nicht", "mehr", "zur", "Gluth", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Du tauchst zur K\u00fchlung deine Glieder", "tokens": ["Du", "tauchst", "zur", "K\u00fch\u00b7lung", "dei\u00b7ne", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Nicht zweimal in dieselbe Fluth!\u00ab", "tokens": ["Nicht", "zwei\u00b7mal", "in", "die\u00b7sel\u00b7be", "Fluth", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PTKNEG", "ADV", "APPR", "PDAT", "NN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}