{"textgrid.poem.45030": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Stammbuch", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Die Musen neun, die Grazien drei,", "tokens": ["Die", "Mu\u00b7sen", "neun", ",", "die", "Gra\u00b7zi\u00b7en", "drei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "$,", "ART", "NN", "CARD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nach ungleichen Zahlen zu z\u00e4hlen.", "tokens": ["Nach", "un\u00b7glei\u00b7chen", "Zah\u00b7len", "zu", "z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Vielleicht damit keinem benommen sei,", "tokens": ["Viel\u00b7leicht", "da\u00b7mit", "kei\u00b7nem", "be\u00b7nom\u00b7men", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VVPP", "VAFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sich eine dazu noch zu w\u00e4hlen.", "tokens": ["Sich", "ei\u00b7ne", "da\u00b7zu", "noch", "zu", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "PAV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Die Musen neun, die Grazien drei,", "tokens": ["Die", "Mu\u00b7sen", "neun", ",", "die", "Gra\u00b7zi\u00b7en", "drei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "CARD", "$,", "ART", "NN", "CARD", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Nach ungleichen Zahlen zu z\u00e4hlen.", "tokens": ["Nach", "un\u00b7glei\u00b7chen", "Zah\u00b7len", "zu", "z\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.3": {"text": "Vielleicht damit keinem benommen sei,", "tokens": ["Viel\u00b7leicht", "da\u00b7mit", "kei\u00b7nem", "be\u00b7nom\u00b7men", "sei", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VVPP", "VAFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Sich eine dazu noch zu w\u00e4hlen.", "tokens": ["Sich", "ei\u00b7ne", "da\u00b7zu", "noch", "zu", "w\u00e4h\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "ART", "PAV", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}