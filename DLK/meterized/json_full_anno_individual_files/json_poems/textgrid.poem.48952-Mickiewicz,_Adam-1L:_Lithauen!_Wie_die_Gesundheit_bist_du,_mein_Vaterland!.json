{"textgrid.poem.48952": {"metadata": {"author": {"name": "Mickiewicz, Adam", "birth": "N.A.", "death": "N.A."}, "title": "1L: Lithauen! Wie die Gesundheit bist du, mein Vaterland!", "genre": "verse", "period": "N.A.", "pub_year": 1826, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Lithauen! Wie die Gesundheit bist du, mein Vaterland!", "tokens": ["Lit\u00b7hau\u00b7en", "!", "Wie", "die", "Ge\u00b7sund\u00b7heit", "bist", "du", ",", "mein", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PWAV", "ART", "NN", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wer dich noch nie verloren, der hat dich nicht erkannt.", "tokens": ["Wer", "dich", "noch", "nie", "ver\u00b7lo\u00b7ren", ",", "der", "hat", "dich", "nicht", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVPP", "$,", "PRELS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "In deiner ganzen Sch\u00f6nheit prangst du heut' vor mir,", "tokens": ["In", "dei\u00b7ner", "gan\u00b7zen", "Sch\u00f6n\u00b7heit", "prangst", "du", "heut'", "vor", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So will ich von dir singen, \u2013 denn mich verlangt nach dir!", "tokens": ["So", "will", "ich", "von", "dir", "sin\u00b7gen", ",", "\u2013", "denn", "mich", "ver\u00b7langt", "nach", "dir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,", "$(", "KON", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.2": {"line.1": {"text": "O heil'ge Jungfrau, Czenstochowa's Schirm und Schild,", "tokens": ["O", "heil'\u00b7ge", "Jung\u00b7frau", ",", "Czen\u00b7stocho\u00b7wa's", "Schirm", "und", "Schild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "NE", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Leuchte der Ostrabrama! Du, deren Gnadenbild", "tokens": ["Leuch\u00b7te", "der", "O\u00b7strab\u00b7ra\u00b7ma", "!", "Du", ",", "de\u00b7ren", "Gna\u00b7den\u00b7bild"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "PPER", "$,", "PRELAT", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Schlo\u00df Nowogrodek und sein treues Volk bewacht:", "tokens": ["Schlo\u00df", "No\u00b7wo\u00b7gro\u00b7dek", "und", "sein", "treu\u00b7es", "Volk", "be\u00b7wacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie mich, als Kind, dein Wunder einst gesund gemacht,", "tokens": ["Wie", "mich", ",", "als", "Kind", ",", "dein", "Wun\u00b7der", "einst", "ge\u00b7sund", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "KOUS", "NN", "$,", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als von der weinenden Mutter in deinen Schutz gegeben,", "tokens": ["Als", "von", "der", "wei\u00b7nen\u00b7den", "Mut\u00b7ter", "in", "dei\u00b7nen", "Schutz", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Ich das erstorb'ne Auge erhob zu neuem Leben,", "tokens": ["Ich", "das", "er\u00b7stor\u00b7b'\u00b7ne", "Au\u00b7ge", "er\u00b7hob", "zu", "neu\u00b7em", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Und konnte gleich zu Fu\u00df in deine Tempel geh'n,", "tokens": ["Und", "konn\u00b7te", "gleich", "zu", "Fu\u00df", "in", "dei\u00b7ne", "Tem\u00b7pel", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gerettet, Gott zu danken f\u00fcr's Heil, das mir gescheh'n:", "tokens": ["Ge\u00b7ret\u00b7tet", ",", "Gott", "zu", "dan\u00b7ken", "f\u00fcr's", "Heil", ",", "das", "mir", "ge\u00b7scheh'n", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "NN", "PTKZU", "VVINF", "APPRART", "NN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "So wird zum Schoo\u00df der Heimat dein Wunder uns wiederbringen!", "tokens": ["So", "wird", "zum", "Schoo\u00df", "der", "Hei\u00b7mat", "dein", "Wun\u00b7der", "uns", "wie\u00b7der\u00b7brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ART", "NN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Indessen trage du mir der sehnenden Seele Schwingen", "tokens": ["In\u00b7des\u00b7sen", "tra\u00b7ge", "du", "mir", "der", "seh\u00b7nen\u00b7den", "See\u00b7le", "Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Zu jenen waldigen H\u00fcgeln, zu jenen gr\u00fcnen Auen,", "tokens": ["Zu", "je\u00b7nen", "wal\u00b7di\u00b7gen", "H\u00fc\u00b7geln", ",", "zu", "je\u00b7nen", "gr\u00fc\u00b7nen", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die weit und breit sich dehnen am Niemenstrom, dem blauen, \u2013", "tokens": ["Die", "weit", "und", "breit", "sich", "deh\u00b7nen", "am", "Nie\u00b7mens\u00b7trom", ",", "dem", "blau\u00b7en", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "PRF", "PDS", "APPRART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Zu jenen Feldern, prangend voll bunter \u00c4hren und Garben,", "tokens": ["Zu", "je\u00b7nen", "Fel\u00b7dern", ",", "pran\u00b7gend", "voll", "bun\u00b7ter", "\u00c4h\u00b7ren", "und", "Gar\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ADJD", "ADJD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "R\u00fcbsamen bernsteinhell, Buchweizen schneeig bl\u00fcht,", "tokens": ["R\u00fcb\u00b7sa\u00b7men", "bern\u00b7stein\u00b7hell", ",", "Buch\u00b7wei\u00b7zen", "schne\u00b7e\u00b7ig", "bl\u00fcht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "NN", "ADJD", "VVFIN", "$,"], "meter": "----+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "In jungfr\u00e4ulichem Roth der duftige Quendel gl\u00fcht,", "tokens": ["In", "jung\u00b7fr\u00e4u\u00b7li\u00b7chem", "Roth", "der", "duf\u00b7ti\u00b7ge", "Quen\u00b7del", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.16": {"text": "Und, wie ein Band, durch Alles der gr\u00fcne Rain sich schmiegt,", "tokens": ["Und", ",", "wie", "ein", "Band", ",", "durch", "Al\u00b7les", "der", "gr\u00fc\u00b7ne", "Rain", "sich", "schmiegt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "APPR", "PIS", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Drauf da und dort ein Birnbaum still die Krone wiegt.", "tokens": ["Drauf", "da", "und", "dort", "ein", "Birn\u00b7baum", "still", "die", "Kro\u00b7ne", "wiegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "KON", "ADV", "ART", "NN", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Auf einem H\u00fcgel erhob sich mitten in solchem Land,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "er\u00b7hob", "sich", "mit\u00b7ten", "in", "sol\u00b7chem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von Birkengeh\u00f6lz umgeben, an eines B\u00e4chleins Rand,", "tokens": ["Von", "Bir\u00b7ken\u00b7ge\u00b7h\u00f6lz", "um\u00b7ge\u00b7ben", ",", "an", "ei\u00b7nes", "B\u00e4ch\u00b7leins", "Rand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein Herrenhaus, \u2013 von Holz, der Unterstock von Stein;", "tokens": ["Ein", "Her\u00b7ren\u00b7haus", ",", "\u2013", "von", "Holz", ",", "der", "Un\u00b7ter\u00b7stock", "von", "Stein", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es leuchteten von Ferne die W\u00e4nde wei\u00df und rein,", "tokens": ["Es", "leuch\u00b7te\u00b7ten", "von", "Fer\u00b7ne", "die", "W\u00e4n\u00b7de", "wei\u00df", "und", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Das Wei\u00df vom dunklen Gr\u00fcn der Pappeln noch gehoben,", "tokens": ["Das", "Wei\u00df", "vom", "dunk\u00b7len", "Gr\u00fcn", "der", "Pap\u00b7peln", "noch", "ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ihm zum Schutze dienen vor des Herbstwinds Toben;", "tokens": ["Die", "ihm", "zum", "Schut\u00b7ze", "die\u00b7nen", "vor", "des", "Herbst\u00b7winds", "To\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVINF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein wohnlich saub'res Haus, wenn auch von m\u00e4\u00dfiger Gr\u00f6\u00dfe,", "tokens": ["Ein", "wohn\u00b7lich", "saub'\u00b7res", "Haus", ",", "wenn", "auch", "von", "m\u00e4\u00b7\u00dfi\u00b7ger", "Gr\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "KOUS", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Hat eine gro\u00dfe Scheuer, und drei Getreidest\u00f6\u00dfe", "tokens": ["Hat", "ei\u00b7ne", "gro\u00b7\u00dfe", "Scheu\u00b7er", ",", "und", "drei", "Ge\u00b7trei\u00b7de\u00b7st\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "KON", "CARD", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Liegen noch neben ihr \u2013 die fa\u00dfte der S\u00f6ller nicht mehr.", "tokens": ["Lie\u00b7gen", "noch", "ne\u00b7ben", "ihr", "\u2013", "die", "fa\u00df\u00b7te", "der", "S\u00f6l\u00b7ler", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "$(", "ART", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "+-+-+--+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Man sieht wohl, reichgesegnet ist das Land umher.", "tokens": ["Man", "sieht", "wohl", ",", "reich\u00b7ge\u00b7seg\u00b7net", "ist", "das", "Land", "um\u00b7her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "VVFIN", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Garben Zahl auch, die weit und breit auf dem Gelenge,", "tokens": ["Der", "Gar\u00b7ben", "Zahl", "auch", ",", "die", "weit", "und", "breit", "auf", "dem", "Ge\u00b7len\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$,", "PRELS", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+--+--", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wie Sterne, dicht ergl\u00e4nzen, und auch der Pfl\u00fcge Menge,", "tokens": ["Wie", "Ster\u00b7ne", ",", "dicht", "er\u00b7gl\u00e4n\u00b7zen", ",", "und", "auch", "der", "Pfl\u00fc\u00b7ge", "Men\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJD", "VVINF", "$,", "KON", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die sich schon zeitig auf dem m\u00e4chtigen Brachfeld zeigen,", "tokens": ["Die", "sich", "schon", "zei\u00b7tig", "auf", "dem", "m\u00e4ch\u00b7ti\u00b7gen", "Brach\u00b7feld", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Dem schwarzscholligen, (sicher derselben Herrschaft eigen", "tokens": ["Dem", "schwarz\u00b7schol\u00b7li\u00b7gen", ",", "(", "si\u00b7cher", "der\u00b7sel\u00b7ben", "Herr\u00b7schaft", "ei\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "$(", "ADJD", "PDAT", "NN", "ADJD"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Und wohl bestellt, es sieht wie Gartenbeete aus \u2013)", "tokens": ["Und", "wohl", "be\u00b7stellt", ",", "es", "sieht", "wie", "Gar\u00b7ten\u00b7bee\u00b7te", "aus", "\u2013", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "PPER", "VVFIN", "KOKOM", "NN", "PTKVZ", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das alles zeigt, da\u00df F\u00fclle und Ordnung herrscht im Haus;", "tokens": ["Das", "al\u00b7les", "zeigt", ",", "da\u00df", "F\u00fcl\u00b7le", "und", "Ord\u00b7nung", "herrscht", "im", "Haus", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Das Thor ist weitge\u00f6ffnet und sagt dem Wand'rer an,", "tokens": ["Das", "Thor", "ist", "weit\u00b7ge\u00f6ff\u00b7net", "und", "sagt", "dem", "Wan\u00b7d'\u00b7rer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.18": {"text": "Da\u00df freundlichen Empfang der Gast gew\u00e4rtigen kann.", "tokens": ["Da\u00df", "freund\u00b7li\u00b7chen", "Emp\u00b7fang", "der", "Gast", "ge\u00b7w\u00e4r\u00b7ti\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.4": {"line.1": {"text": "Ein zweisp\u00e4nniges Fuhrwerk kam eben durch das Thor,", "tokens": ["Ein", "zwei\u00b7sp\u00e4n\u00b7ni\u00b7ges", "Fuhr\u00b7werk", "kam", "e\u00b7ben", "durch", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Flog um den Schlo\u00dfhof, f\u00e4hrt beim Gange wieder vor.", "tokens": ["Flog", "um", "den", "Schlo\u00df\u00b7hof", ",", "f\u00e4hrt", "beim", "Gan\u00b7ge", "wie\u00b7der", "vor", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "APPRART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein junger Herr steigt aus; die verlassenen Pferde zieh'n", "tokens": ["Ein", "jun\u00b7ger", "Herr", "steigt", "aus", ";", "die", "ver\u00b7las\u00b7se\u00b7nen", "Pfer\u00b7de", "zieh'n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+----+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Gras abrupfend, langsam wieder zur Einfahrt hin.", "tokens": ["Das", "Gras", "ab\u00b7rup\u00b7fend", ",", "lang\u00b7sam", "wie\u00b7der", "zur", "Ein\u00b7fahrt", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADJD", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Im Hof ist's \u00f6d'; ein Riegel verschlie\u00dft die Th\u00fcr zum Gang,", "tokens": ["Im", "Hof", "ist's", "\u00f6d'", ";", "ein", "Rie\u00b7gel", "ver\u00b7schlie\u00dft", "die", "Th\u00fcr", "zum", "Gang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Von einem Pfl\u00f6ckchen durchsteckt. \u2013 Der Fremde fragt nicht lang,", "tokens": ["Von", "ei\u00b7nem", "Pfl\u00f6\u00b7ck\u00b7chen", "durch\u00b7steckt", ".", "\u2013", "Der", "Frem\u00b7de", "fragt", "nicht", "lang", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$.", "$(", "ART", "NN", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+---+-+-+-+", "measure": "unknown.measure.hexa"}, "line.7": {"text": "Sucht kein Gesinde auf: er \u00f6ffnet, ohne zu s\u00e4umen,", "tokens": ["Sucht", "kein", "Ge\u00b7sin\u00b7de", "auf", ":", "er", "\u00f6ff\u00b7net", ",", "oh\u00b7ne", "zu", "s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und tritt in's Haus. Wie lange war er nicht in den R\u00e4umen!", "tokens": ["Und", "tritt", "in's", "Haus", ".", "Wie", "lan\u00b7ge", "war", "er", "nicht", "in", "den", "R\u00e4u\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PWAV", "ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Bis nun hielt ihn die Schule in der Stadt entfernt, \u2013", "tokens": ["Bis", "nun", "hielt", "ihn", "die", "Schu\u00b7le", "in", "der", "Stadt", "ent\u00b7fernt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Wie wohl ist ihm! Er hat doch endlich ausgelernt!", "tokens": ["Wie", "wohl", "ist", "ihm", "!", "Er", "hat", "doch", "end\u00b7lich", "aus\u00b7ge\u00b7lernt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "$.", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nun wird von jeder Wand sein Blick so festgehalten,", "tokens": ["Nun", "wird", "von", "je\u00b7der", "Wand", "sein", "Blick", "so", "fest\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "PPOSAT", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Er gr\u00fc\u00dft sie mit vollem Herzen, die wohlbekannten, die alten!", "tokens": ["Er", "gr\u00fc\u00dft", "sie", "mit", "vol\u00b7lem", "Her\u00b7zen", ",", "die", "wohl\u00b7be\u00b7kann\u00b7ten", ",", "die", "al\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "ART", "ADJA", "$,", "ART", "ADJA", "$."], "meter": "-+--+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.5": {"line.1": {"text": "Der Hausrath ganz wie damals in seiner Kindheit Tagen;", "tokens": ["Der", "Haus\u00b7rath", "ganz", "wie", "da\u00b7mals", "in", "sei\u00b7ner", "Kind\u00b7heit", "Ta\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KOKOM", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+----+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Jetzt scheint ihm Alles freilich nicht mehr so gro\u00df, so sch\u00f6n; \u2013", "tokens": ["Jetzt", "scheint", "ihm", "Al\u00b7les", "frei\u00b7lich", "nicht", "mehr", "so", "gro\u00df", ",", "so", "sch\u00f6n", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "PTKNEG", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dieselben Bilder sieht er, die er damals geseh'n:", "tokens": ["Die\u00b7sel\u00b7ben", "Bil\u00b7der", "sieht", "er", ",", "die", "er", "da\u00b7mals", "ge\u00b7seh'n", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Hier in der Czamarka Kosciuszko, den Blick zum Himmel gekehrt,", "tokens": ["Hier", "in", "der", "Cza\u00b7mar\u00b7ka", "Ko\u00b7sciusz\u00b7ko", ",", "den", "Blick", "zum", "Him\u00b7mel", "ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NE", "NE", "$,", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+---+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Mit beiden H\u00e4nden h\u00e4lt er umspannt sein starkes Schwert,", "tokens": ["Mit", "bei\u00b7den", "H\u00e4n\u00b7den", "h\u00e4lt", "er", "um\u00b7spannt", "sein", "star\u00b7kes", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "So war er, als er einstmals am Altar geschworen,", "tokens": ["So", "war", "er", ",", "als", "er", "einst\u00b7mals", "am", "Al\u00b7tar", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit diesem Schwert zu verjagen die drei Usurpatoren", "tokens": ["Mit", "die\u00b7sem", "Schwert", "zu", "ver\u00b7ja\u00b7gen", "die", "drei", "U\u00b7sur\u00b7pa\u00b7to\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "ART", "CARD", "NN"], "meter": "-+-+--+---+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Oder auf ihm zu verbluten. Im polnischen Gewand", "tokens": ["O\u00b7der", "auf", "ihm", "zu", "ver\u00b7blu\u00b7ten", ".", "Im", "pol\u00b7ni\u00b7schen", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "PTKZU", "VVINF", "$.", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.9": {"text": "Sitzt dort, die Freiheit betrauernd, Rejtan,", "tokens": ["Sitzt", "dort", ",", "die", "Frei\u00b7heit", "be\u00b7trau\u00b7ernd", ",", "Rej\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ART", "NN", "VVPP", "$,", "NE", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Sieht man, auf's Herz gerichtet, ein blitzendes Messer ragen, \u2013", "tokens": ["Sieht", "man", ",", "auf's", "Herz", "ge\u00b7rich\u00b7tet", ",", "ein", "blit\u00b7zen\u00b7des", "Mes\u00b7ser", "ra\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "$,", "APPRART", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ph\u00e4don und Cato's Leben sind vor ihm aufgeschlagen.", "tokens": ["Ph\u00e4\u00b7don", "und", "Ca\u00b7to's", "Le\u00b7ben", "sind", "vor", "ihm", "auf\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und dort der junge Jasinski,", "tokens": ["Und", "dort", "der", "jun\u00b7ge", "Ja\u00b7sins\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.13": {"text": "Daneben Korsak, der niemals von seiner Seite kam,", "tokens": ["Da\u00b7ne\u00b7ben", "Kor\u00b7sak", ",", "der", "nie\u00b7mals", "von", "sei\u00b7ner", "Sei\u00b7te", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Auf Praga's Schanzen steh'n sie, auf Russenhaufen beisammen,", "tokens": ["Auf", "Pra\u00b7ga's", "Schan\u00b7zen", "steh'n", "sie", ",", "auf", "Rus\u00b7sen\u00b7hau\u00b7fen", "bei\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPER", "$,", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "K\u00fchn hau'n sie drein, \u2013 und Praga steht schon ringsum in Flammen.", "tokens": ["K\u00fchn", "hau'n", "sie", "drein", ",", "\u2013", "und", "Pra\u00b7ga", "steht", "schon", "ring\u00b7sum", "in", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "KON", "NE", "VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Und sieh', im Holzgeh\u00e4use, an der Alkoventh\u00fcr", "tokens": ["Und", "sieh'", ",", "im", "Holz\u00b7ge\u00b7h\u00e4u\u00b7se", ",", "an", "der", "Al\u00b7ko\u00b7vent\u00b7h\u00fcr"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "APPRART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Die alte liebe Spieluhr sogar erkennt er hier,", "tokens": ["Die", "al\u00b7te", "lie\u00b7be", "Spie\u00b7luhr", "so\u00b7gar", "er\u00b7kennt", "er", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}, "line.18": {"text": "Und zieht in kindischer Freude, wie einstmals, an der Schnur,", "tokens": ["Und", "zieht", "in", "kin\u00b7di\u00b7scher", "Freu\u00b7de", ",", "wie", "einst\u00b7mals", ",", "an", "der", "Schnur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,", "PWAV", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und Dombrowski's alte Weise", "tokens": ["Und", "Dom\u00b7brow\u00b7ski's", "al\u00b7te", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.6": {"line.1": {"text": "Er eilt durch's ganze Haus, nach jenem trauten St\u00fcbchen,", "tokens": ["Er", "eilt", "durch's", "gan\u00b7ze", "Haus", ",", "nach", "je\u00b7nem", "trau\u00b7ten", "St\u00fcb\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo er vor zehn Jahren gespielt als kleines B\u00fcbchen.", "tokens": ["Wo", "er", "vor", "zehn", "Jah\u00b7ren", "ge\u00b7spielt", "als", "klei\u00b7nes", "B\u00fcb\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "CARD", "NN", "VVPP", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Kaum ist er eingetreten, stutzt er und weicht zur\u00fcck:", "tokens": ["Kaum", "ist", "er", "ein\u00b7ge\u00b7tre\u00b7ten", ",", "stutzt", "er", "und", "weicht", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "VVFIN", "PPER", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein Frauengemach! Er mustert's mit erstauntem Blick;", "tokens": ["Ein", "Frau\u00b7en\u00b7ge\u00b7mach", "!", "Er", "mus\u00b7tert's", "mit", "er\u00b7staun\u00b7tem", "Blick", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Wer mag hier wohnen? Der alte Oheim war unverm\u00e4hlt, \u2013", "tokens": ["Wer", "mag", "hier", "woh\u00b7nen", "?", "Der", "al\u00b7te", "O\u00b7heim", "war", "un\u00b7ver\u00b7m\u00e4hlt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVINF", "$.", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Die Tante hatte zum Wohnort Petersburg erw\u00e4hlt!", "tokens": ["Die", "Tan\u00b7te", "hat\u00b7te", "zum", "Wohn\u00b7ort", "Pe\u00b7ters\u00b7burg", "er\u00b7w\u00e4hlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "NE", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Die Wirthschaftsfrau? Unm\u00f6glich! \u2013 Was soll der Fl\u00fcgel nur?", "tokens": ["Die", "Wirth\u00b7schafts\u00b7frau", "?", "Un\u00b7m\u00f6g\u00b7lich", "!", "\u2013", "Was", "soll", "der", "Fl\u00fc\u00b7gel", "nur", "?"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADJD", "$.", "$(", "PWS", "VMFIN", "ART", "NN", "ADV", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.8": {"text": "Und Noten auf ihm und B\u00fccher, \u2013 von Ordnung keine Spur;", "tokens": ["Und", "No\u00b7ten", "auf", "ihm", "und", "B\u00fc\u00b7cher", ",", "\u2013", "von", "Ord\u00b7nung", "kei\u00b7ne", "Spur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "KON", "NN", "$,", "$(", "APPR", "NN", "PIAT", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "In holdem Durcheinander Alles umhergezaust, \u2013", "tokens": ["In", "hol\u00b7dem", "Durch\u00b7ein\u00b7an\u00b7der", "Al\u00b7les", "um\u00b7her\u00b7ge\u00b7zaust", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "PIS", "VVFIN", "$,", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Das waren nicht alte H\u00e4ndchen, die da so gehaust.", "tokens": ["Das", "wa\u00b7ren", "nicht", "al\u00b7te", "H\u00e4nd\u00b7chen", ",", "die", "da", "so", "ge\u00b7haust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Und hier ein wei\u00dfes Kleid auf die Sessellehne gebreitet,", "tokens": ["Und", "hier", "ein", "wei\u00b7\u00dfes", "Kleid", "auf", "die", "Ses\u00b7sel\u00b7leh\u00b7ne", "ge\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Frisch vom Nagel geholt, zum Anzieh'n vorbereitet;", "tokens": ["Frisch", "vom", "Na\u00b7gel", "ge\u00b7holt", ",", "zum", "An\u00b7zieh'n", "vor\u00b7be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NE", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.13": {"text": "Und auf den Fenstern duften, in Blument\u00f6pfen gehegt,", "tokens": ["Und", "auf", "den", "Fens\u00b7tern", "duf\u00b7ten", ",", "in", "Blu\u00b7men\u00b7t\u00f6p\u00b7fen", "ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Geranium, Veilchen, Astern, Levkojen, wohlgepflegt;", "tokens": ["Ge\u00b7ra\u00b7ni\u00b7um", ",", "Veil\u00b7chen", ",", "As\u00b7tern", ",", "Lev\u00b7ko\u00b7jen", ",", "wohl\u00b7ge\u00b7pflegt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NE", "$,", "VVFIN", "$."], "meter": "----+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Er tritt an eins der Fenster: ein neues Wunder, sieh'!", "tokens": ["Er", "tritt", "an", "eins", "der", "Fens\u00b7ter", ":", "ein", "neu\u00b7es", "Wun\u00b7der", ",", "sieh'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ART", "NN", "$.", "ART", "ADJA", "NN", "$,", "VVIMP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Im Obstgarten, am Rande, wo Unkraut sonst gedieh,", "tokens": ["Im", "Obst\u00b7gar\u00b7ten", ",", "am", "Ran\u00b7de", ",", "wo", "Un\u00b7kraut", "sonst", "ge\u00b7dieh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "PWAV", "NN", "ADV", "VVFIN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Und Str\u00e4u\u00dfe von englischem Gras und M\u00fcnze allerwegen;", "tokens": ["Und", "Str\u00e4u\u00b7\u00dfe", "von", "eng\u00b7li\u00b7schem", "Gras", "und", "M\u00fcn\u00b7ze", "al\u00b7ler\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Als Namenszug geformt, fa\u00dft es ein Z\u00e4unchen ein,", "tokens": ["Als", "Na\u00b7mens\u00b7zug", "ge\u00b7formt", ",", "fa\u00dft", "es", "ein", "Z\u00e4un\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Ein winziges, h\u00f6lzernes, mit schimmernden Ma\u00dfliebreih'n;", "tokens": ["Ein", "win\u00b7zi\u00b7ges", ",", "h\u00f6l\u00b7zer\u00b7nes", ",", "mit", "schim\u00b7mern\u00b7den", "Ma\u00df\u00b7lieb\u00b7reih'n", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+--+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Die Beetchen waren frisch begossen von sorgender Hand,", "tokens": ["Die", "Beet\u00b7chen", "wa\u00b7ren", "frisch", "be\u00b7gos\u00b7sen", "von", "sor\u00b7gen\u00b7der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Man sah noch das Blechgef\u00e4\u00df, das auf dem Boden stand.", "tokens": ["Man", "sah", "noch", "das", "Blech\u00b7ge\u00b7f\u00e4\u00df", ",", "das", "auf", "dem", "Bo\u00b7den", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Doch wo ist die G\u00e4rtnerin? sie war wohl eben hier;", "tokens": ["Doch", "wo", "ist", "die", "G\u00e4rt\u00b7ne\u00b7rin", "?", "sie", "war", "wohl", "e\u00b7ben", "hier", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.23": {"text": "Noch zittert ja in den Angeln dort die kleine Th\u00fcr, \u2013", "tokens": ["Noch", "zit\u00b7tert", "ja", "in", "den", "An\u00b7geln", "dort", "die", "klei\u00b7ne", "Th\u00fcr", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Und nah' der Th\u00fcr im Sande, trocken, wei\u00df und fein,", "tokens": ["Und", "nah'", "der", "Th\u00fcr", "im", "San\u00b7de", ",", "tro\u00b7cken", ",", "wei\u00df", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "ADJD", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "War eine Spur so leicht von einem F\u00fc\u00dfchen klein;", "tokens": ["War", "ei\u00b7ne", "Spur", "so", "leicht", "von", "ei\u00b7nem", "F\u00fc\u00df\u00b7chen", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das hatte nicht Schuh, noch Strumpf \u2013 und rasch durchlief's den Raum,", "tokens": ["Das", "hat\u00b7te", "nicht", "Schuh", ",", "noch", "Strumpf", "\u2013", "und", "rasch", "durch\u00b7lie\u00b7f's", "den", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "NN", "$,", "ADV", "NN", "$(", "KON", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und wie es lief, man sieht's, ber\u00fchrt' es den Boden kaum.", "tokens": ["Und", "wie", "es", "lief", ",", "man", "sieht's", ",", "be\u00b7r\u00fchrt'", "es", "den", "Bo\u00b7den", "kaum", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "PIS", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.7": {"line.1": {"text": "Der Fremde stand am Fenster und sann und schaute lange \u2013", "tokens": ["Der", "Frem\u00b7de", "stand", "am", "Fens\u00b7ter", "und", "sann", "und", "schau\u00b7te", "lan\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Blumen s\u00fc\u00dfer Duft umspielt ihm Brust und Wange,", "tokens": ["Der", "Blu\u00b7men", "s\u00fc\u00b7\u00dfer", "Duft", "um\u00b7spielt", "ihm", "Brust", "und", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bis zum Veilchenstrauch neigt er das Antlitz nieder,", "tokens": ["Und", "bis", "zum", "Veil\u00b7chen\u00b7strauch", "neigt", "er", "das", "Ant\u00b7litz", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Augen suchen umher \u2013 und bleiben haften wieder,", "tokens": ["Die", "Au\u00b7gen", "su\u00b7chen", "um\u00b7her", "\u2013", "und", "blei\u00b7ben", "haf\u00b7ten", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "KON", "VVINF", "VVFIN", "ADV", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Dort an den Spuren haften von jenen F\u00fc\u00dfchen klein \u2013", "tokens": ["Dort", "an", "den", "Spu\u00b7ren", "haf\u00b7ten", "von", "je\u00b7nen", "F\u00fc\u00df\u00b7chen", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "ADJD", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Er schaut' und sann: we\u00df mochten wohl die F\u00fc\u00dfchen sein?", "tokens": ["Er", "schaut'", "und", "sann", ":", "we\u00df", "moch\u00b7ten", "wohl", "die", "F\u00fc\u00df\u00b7chen", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "PWAV", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zuf\u00e4llig blickt er auf \u2013 und sieh', auf der Planke stand", "tokens": ["Zu\u00b7f\u00e4l\u00b7lig", "blickt", "er", "auf", "\u2013", "und", "sieh'", ",", "auf", "der", "Plan\u00b7ke", "stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "$(", "KON", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Ein junges M\u00e4dchen, gekleidet in ein wei\u00df Gewand,", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", ",", "ge\u00b7klei\u00b7det", "in", "ein", "wei\u00df", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "APPR", "ART", "VVFIN", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Das von der Brust hinab den schlanken Leib umflo\u00df \u2013", "tokens": ["Das", "von", "der", "Brust", "hin\u00b7ab", "den", "schlan\u00b7ken", "Leib", "um\u00b7flo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Schwanenhals, die Arme blieben frei und blo\u00df.", "tokens": ["Der", "Schwa\u00b7nen\u00b7hals", ",", "die", "Ar\u00b7me", "blie\u00b7ben", "frei", "und", "blo\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So pflegt ein lithauisch M\u00e4dchen des Morgens nur zu geh'n,", "tokens": ["So", "pflegt", "ein", "lit\u00b7hau\u00b7isch", "M\u00e4d\u00b7chen", "des", "Mor\u00b7gens", "nur", "zu", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "ART", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "So wird's von eines Mannes Augen nie geseh'n.", "tokens": ["So", "wird's", "von", "ei\u00b7nes", "Man\u00b7nes", "Au\u00b7gen", "nie", "ge\u00b7seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Drum h\u00e4lt sie auch die H\u00e4nde ob der Brust verschr\u00e4nkt,", "tokens": ["Drum", "h\u00e4lt", "sie", "auch", "die", "H\u00e4n\u00b7de", "ob", "der", "Brust", "ver\u00b7schr\u00e4nkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wiewohl sie ja gewi\u00df an keine Lauscher denkt.", "tokens": ["Wie\u00b7wohl", "sie", "ja", "ge\u00b7wi\u00df", "an", "kei\u00b7ne", "Lau\u00b7scher", "denkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das Haar, in Locken nicht gel\u00f6st, in kleine Kn\u00f6tchen", "tokens": ["Das", "Haar", ",", "in", "Lo\u00b7cken", "nicht", "ge\u00b7l\u00f6st", ",", "in", "klei\u00b7ne", "Kn\u00f6t\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "NN", "PTKNEG", "VVPP", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Gebunden nur und rings besteckt mit wei\u00dfen Sch\u00f6tchen,", "tokens": ["Ge\u00b7bun\u00b7den", "nur", "und", "rings", "be\u00b7steckt", "mit", "wei\u00b7\u00dfen", "Sch\u00f6t\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ziert wundersam den Kopf, wie's in der Sonne strahlt:", "tokens": ["Ziert", "wun\u00b7der\u00b7sam", "den", "Kopf", ",", "wie's", "in", "der", "Son\u00b7ne", "strahlt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den Kronen gleich, die man um Heiligenstirnen malt.", "tokens": ["Den", "Kro\u00b7nen", "gleich", ",", "die", "man", "um", "Hei\u00b7li\u00b7gen\u00b7stir\u00b7nen", "malt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Sie blickt in's Feld, das Antlitz ist drum nicht zu sehen,", "tokens": ["Sie", "blickt", "in's", "Feld", ",", "das", "Ant\u00b7litz", "ist", "drum", "nicht", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "ART", "NN", "VAFIN", "PAV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Dort unten weit, dort scheint sie nach Jemand auszusp\u00e4hen.", "tokens": ["Dort", "un\u00b7ten", "weit", ",", "dort", "scheint", "sie", "nach", "Je\u00b7mand", "aus\u00b7zu\u00b7sp\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "ADV", "VVFIN", "PPER", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Nun hat sie gefunden \u2013 lacht, klatscht in die Hand \u2013 und schnell,", "tokens": ["Nun", "hat", "sie", "ge\u00b7fun\u00b7den", "\u2013", "lacht", ",", "klatscht", "in", "die", "Hand", "\u2013", "und", "schnell", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$(", "VVFIN", "$,", "VVFIN", "APPR", "ART", "NN", "$(", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Gleich wie ein wei\u00dfer Vogel, entfliegt sie von der Stell'", "tokens": ["Gleich", "wie", "ein", "wei\u00b7\u00dfer", "Vo\u00b7gel", ",", "ent\u00b7fliegt", "sie", "von", "der", "Stell'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Und flattert durch Garten und Blumen \u2013 und flink kommt sie gerannt", "tokens": ["Und", "flat\u00b7tert", "durch", "Gar\u00b7ten", "und", "Blu\u00b7men", "\u2013", "und", "flink", "kommt", "sie", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$(", "KON", "ADJD", "VVFIN", "PPER", "VVPP"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.24": {"text": "Und eh' er's merkt, da fliegt sie schon durch's Fenster herein,", "tokens": ["Und", "eh'", "er's", "merkt", ",", "da", "fliegt", "sie", "schon", "durch's", "Fens\u00b7ter", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.25": {"text": "So still und leicht und gl\u00e4nzend, wie des Mondes Schein.", "tokens": ["So", "still", "und", "leicht", "und", "gl\u00e4n\u00b7zend", ",", "wie", "des", "Mon\u00b7des", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,", "PWAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und summend ergreift sie das Kleid, will sich zum Spiegel wenden:", "tokens": ["Und", "sum\u00b7mend", "er\u00b7greift", "sie", "das", "Kleid", ",", "will", "sich", "zum", "Spie\u00b7gel", "wen\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "$,", "VMFIN", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "Da sieht sie den J\u00fcngling \u2013 das Kleidchen f\u00e4llt ihr aus den H\u00e4nden \u2013", "tokens": ["Da", "sieht", "sie", "den", "J\u00fcng\u00b7ling", "\u2013", "das", "Kleid\u00b7chen", "f\u00e4llt", "ihr", "aus", "den", "H\u00e4n\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$(", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Bleich wird sie vor Staunen und Schreck \u2013 roth wird sein Angesicht,", "tokens": ["Bleich", "wird", "sie", "vor", "Stau\u00b7nen", "und", "Schreck", "\u2013", "roth", "wird", "sein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "$(", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.29": {"text": "Gleich dem Gew\u00f6lk, das hinflie\u00dft durch des Morgens Licht.", "tokens": ["Gleich", "dem", "Ge\u00b7w\u00f6lk", ",", "das", "hin\u00b7flie\u00dft", "durch", "des", "Mor\u00b7gens", "Licht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PDS", "VVFIN", "APPR", "ART", "ADV", "NN", "$."], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.30": {"text": "Er dr\u00fcckt die Augen zu, bedeckt sie in scheuem Schweigen \u2013", "tokens": ["Er", "dr\u00fcckt", "die", "Au\u00b7gen", "zu", ",", "be\u00b7deckt", "sie", "in", "scheu\u00b7em", "Schwei\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Will reden, Entschuldigung stammeln \u2013 kann sich nur verneigen", "tokens": ["Will", "re\u00b7den", ",", "Ent\u00b7schul\u00b7di\u00b7gung", "stam\u00b7meln", "\u2013", "kann", "sich", "nur", "ver\u00b7nei\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "NN", "VVFIN", "$(", "VMFIN", "PRF", "ADV", "VVINF"], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.32": {"text": "Und tritt zur\u00fcck. Und schmerzlich schrie auf die holde Maid,", "tokens": ["Und", "tritt", "zu\u00b7r\u00fcck", ".", "Und", "schmerz\u00b7lich", "schrie", "auf", "die", "hol\u00b7de", "Maid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "KON", "ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "Undeutlich, wie ein Kind furchtsam im Schlafe schreit.", "tokens": ["Un\u00b7deut\u00b7lich", ",", "wie", "ein", "Kind", "furcht\u00b7sam", "im", "Schla\u00b7fe", "schreit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Erschrocken blickt' er auf \u2013 doch sie war nicht mehr da,", "tokens": ["Er\u00b7schro\u00b7cken", "blickt'", "er", "auf", "\u2013", "doch", "sie", "war", "nicht", "mehr", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "$(", "KON", "PPER", "VAFIN", "PTKNEG", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Verwirrt ging er hinaus, wu\u00dft' nicht wie ihm geschah:", "tokens": ["Ver\u00b7wirrt", "ging", "er", "hin\u00b7aus", ",", "wu\u00dft'", "nicht", "wie", "ihm", "ge\u00b7schah", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PTKNEG", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Sollt' er sich freu'n darob, was da sich zugetragen?", "tokens": ["Sollt'", "er", "sich", "freu'n", "da\u00b7rob", ",", "was", "da", "sich", "zu\u00b7ge\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVFIN", "PAV", "$,", "PRELS", "ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Sich sch\u00e4men? oder lachen? er konnt' es selbst nicht sagen.", "tokens": ["Sich", "sch\u00e4\u00b7men", "?", "o\u00b7der", "la\u00b7chen", "?", "er", "konnt'", "es", "selbst", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "$.", "KON", "VVINF", "$.", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.8": {"line.1": {"text": "Im Meierhof inde\u00df hat man schon wahrgenommen,", "tokens": ["Im", "Mei\u00b7er\u00b7hof", "in\u00b7de\u00df", "hat", "man", "schon", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df heut' ein neuer Gast im Hause angekommen.", "tokens": ["Da\u00df", "heut'", "ein", "neu\u00b7er", "Gast", "im", "Hau\u00b7se", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schon hatte man die Pferde in den Stall gebracht,", "tokens": ["Schon", "hat\u00b7te", "man", "die", "Pfer\u00b7de", "in", "den", "Stall", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und, wie sich ziemt, sie reichlich mit Hafer und Heu bedacht.", "tokens": ["Und", ",", "wie", "sich", "ziemt", ",", "sie", "reich\u00b7lich", "mit", "Ha\u00b7fer", "und", "Heu", "be\u00b7dacht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PRF", "VVFIN", "$,", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Der Richter leidet sie nicht, alle die neuen Manieren,", "tokens": ["Der", "Rich\u00b7ter", "lei\u00b7det", "sie", "nicht", ",", "al\u00b7le", "die", "neu\u00b7en", "Ma\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Da\u00df man beim Juden l\u00e4\u00dft die Pferde einquartieren.", "tokens": ["Da\u00df", "man", "beim", "Ju\u00b7den", "l\u00e4\u00dft", "die", "Pfer\u00b7de", "ein\u00b7quar\u00b7tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kein Diener kommt ihm entgegen; doch meine darum nicht,", "tokens": ["Kein", "Die\u00b7ner", "kommt", "ihm", "ent\u00b7ge\u00b7gen", ";", "doch", "mei\u00b7ne", "da\u00b7rum", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "PPOSAT", "PAV", "PTKNEG", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Da\u00df man in Richters Hause vers\u00e4ume Dienstespflicht.", "tokens": ["Da\u00df", "man", "in", "Rich\u00b7ters", "Hau\u00b7se", "ver\u00b7s\u00e4u\u00b7me", "Diens\u00b7tes\u00b7pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NE", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Sie warten bis der Wojski im Staat erscheinen kann,", "tokens": ["Sie", "war\u00b7ten", "bis", "der", "Wojs\u00b7ki", "im", "Staat", "er\u00b7schei\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der ordnet hinter dem Hause eben das Nachtmahl an:", "tokens": ["Der", "ord\u00b7net", "hin\u00b7ter", "dem", "Hau\u00b7se", "e\u00b7ben", "das", "Nacht\u00b7mahl", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ein Hausfreund ist's, dem Richter auch entfernt verwandt,", "tokens": ["Ein", "Haus\u00b7freund", "ist's", ",", "dem", "Rich\u00b7ter", "auch", "ent\u00b7fernt", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der in der Regel die G\u00e4ste, wenn nicht der Herr zur Hand,", "tokens": ["Der", "in", "der", "Re\u00b7gel", "die", "G\u00e4s\u00b7te", ",", "wenn", "nicht", "der", "Herr", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "$,", "KOUS", "PTKNEG", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Empf\u00e4ngt und unterh\u00e4lt. Sobald der Fremde erschien,", "tokens": ["Emp\u00b7f\u00e4ngt", "und", "un\u00b7ter\u00b7h\u00e4lt", ".", "So\u00b7bald", "der", "Frem\u00b7de", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$.", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.14": {"text": "Sucht' er in aller Stille in's Vorwerk zu entflieh'n;", "tokens": ["Sucht'", "er", "in", "al\u00b7ler", "Stil\u00b7le", "in's", "Vor\u00b7werk", "zu", "ent\u00b7flieh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.15": {"text": "Da er im Pudermantel nicht gut empfangen kann,", "tokens": ["Da", "er", "im", "Pu\u00b7der\u00b7man\u00b7tel", "nicht", "gut", "emp\u00b7fan\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Legt er nun m\u00f6glichst rasch die Sonntagskleider an;", "tokens": ["Legt", "er", "nun", "m\u00f6g\u00b7lichst", "rasch", "die", "Sonn\u00b7tags\u00b7klei\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die lagen seit fr\u00fch bereit \u2013 denn da schon hatt' er vernommen,", "tokens": ["Die", "la\u00b7gen", "seit", "fr\u00fch", "be\u00b7reit", "\u2013", "denn", "da", "schon", "hatt'", "er", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJD", "ADJD", "$(", "KON", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Da\u00df heute viele G\u00e4ste zur Abendmahlzeit kommen.", "tokens": ["Da\u00df", "heu\u00b7te", "vie\u00b7le", "G\u00e4s\u00b7te", "zur", "A\u00b7bend\u00b7mahl\u00b7zeit", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.9": {"line.1": {"text": "Von fern erkennt er den Gast; mit lautem Freudenschrei,", "tokens": ["Von", "fern", "er\u00b7kennt", "er", "den", "Gast", ";", "mit", "lau\u00b7tem", "Freu\u00b7den\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "PPER", "ART", "NN", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit ausgebreiteten Armen eilt er nun herbei,", "tokens": ["Mit", "aus\u00b7ge\u00b7brei\u00b7te\u00b7ten", "Ar\u00b7men", "eilt", "er", "nun", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von Jahren erz\u00e4hlte man gern in wenigen Worten geschwind,", "tokens": ["Von", "Jah\u00b7ren", "er\u00b7z\u00e4hl\u00b7te", "man", "gern", "in", "we\u00b7ni\u00b7gen", "Wor\u00b7ten", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+--+-+--+--+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Stets unterbrochen von Fragen und Seufzern und Entz\u00fccken,", "tokens": ["Stets", "un\u00b7ter\u00b7bro\u00b7chen", "von", "Fra\u00b7gen", "und", "Seuf\u00b7zern", "und", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ausrufen, neuen Gr\u00fc\u00dfen und neuen H\u00e4ndedr\u00fccken.", "tokens": ["Aus\u00b7ru\u00b7fen", ",", "neu\u00b7en", "Gr\u00fc\u00b7\u00dfen", "und", "neu\u00b7en", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Als endlich der Wojski genug hat an aller Art Berichten,", "tokens": ["Als", "end\u00b7lich", "der", "Wojs\u00b7ki", "ge\u00b7nug", "hat", "an", "al\u00b7ler", "Art", "Be\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VAFIN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.7": {"text": "Erz\u00e4hlt er ganz zum Schlu\u00df des heutigen Tags Geschichten:", "tokens": ["Er\u00b7z\u00e4hlt", "er", "ganz", "zum", "Schlu\u00df", "des", "heu\u00b7ti\u00b7gen", "Tags", "Ge\u00b7schich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.10": {"line.1": {"text": "\u00bbgut, mein Thadd\u00e4us,\u00ab sagt' er \u2013 (so war der J\u00fcngling genannt;", "tokens": ["\u00bb", "gut", ",", "mein", "Thad\u00b7d\u00e4us", ",", "\u00ab", "sagt'", "er", "\u2013", "(", "so", "war", "der", "J\u00fcng\u00b7ling", "ge\u00b7nannt", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "PPER", "$(", "$(", "ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Als er zur Welt gekommen, war der Krieg im Land,", "tokens": ["Als", "er", "zur", "Welt", "ge\u00b7kom\u00b7men", ",", "war", "der", "Krieg", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVPP", "$,", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da hatte man ihm den Namen von Kosciuszko gegeben);", "tokens": ["Da", "hat\u00b7te", "man", "ihm", "den", "Na\u00b7men", "von", "Ko\u00b7sciusz\u00b7ko", "ge\u00b7ge\u00b7ben", ")", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "ART", "NN", "APPR", "NE", "VVPP", "$(", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbgut, mein Thadd\u00e4us, da\u00df du heim kommst ", "tokens": ["\u00bb", "gut", ",", "mein", "Thad\u00b7d\u00e4us", ",", "da\u00df", "du", "heim", "kommst"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PTKVZ", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Da wir so viele M\u00e4dchen bei uns im Hause sehen;", "tokens": ["Da", "wir", "so", "vie\u00b7le", "M\u00e4d\u00b7chen", "bei", "uns", "im", "Hau\u00b7se", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "APPR", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wir d\u00fcrften ja in Kurzem hier deine Hochzeit begehen:", "tokens": ["Wir", "d\u00fcrf\u00b7ten", "ja", "in", "Kur\u00b7zem", "hier", "dei\u00b7ne", "Hoch\u00b7zeit", "be\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So meint der Onkel. \u2013 An Auswahl fehlt es g'rade nicht;", "tokens": ["So", "meint", "der", "On\u00b7kel", ".", "\u2013", "An", "Aus\u00b7wahl", "fehlt", "es", "g'\u00b7ra\u00b7de", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "APPR", "NN", "VVFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+--+----+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Viel Leute sind jetzt bei uns versammelt zum Grenzgericht,", "tokens": ["Viel", "Leu\u00b7te", "sind", "jetzt", "bei", "uns", "ver\u00b7sam\u00b7melt", "zum", "Grenz\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--++--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Den Handel mit dem Grafen, der sich schon schleppt seit Jahren,", "tokens": ["Den", "Han\u00b7del", "mit", "dem", "Gra\u00b7fen", ",", "der", "sich", "schon", "schleppt", "seit", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Zu endigen. Er selbst kommt morgen hergefahren.", "tokens": ["Zu", "en\u00b7di\u00b7gen", ".", "Er", "selbst", "kommt", "mor\u00b7gen", "her\u00b7ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "PPER", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.11": {"text": "Der K\u00e4mmerer", "tokens": ["Der", "K\u00e4m\u00b7me\u00b7rer"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--", "measure": "dactylic.init"}, "line.12": {"text": "Die Jugend ist im Wald und jagt dort im Revier \u2013", "tokens": ["Die", "Ju\u00b7gend", "ist", "im", "Wald", "und", "jagt", "dort", "im", "Re\u00b7vier", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.13": {"text": "Die Alten und die Damen sehen sich nahe beim Wald", "tokens": ["Die", "Al\u00b7ten", "und", "die", "Da\u00b7men", "se\u00b7hen", "sich", "na\u00b7he", "beim", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die Ernte an. Dahin kommt auch die Jugend bald.", "tokens": ["Die", "Ern\u00b7te", "an", ".", "Da\u00b7hin", "kommt", "auch", "die", "Ju\u00b7gend", "bald", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PAV", "VVFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Willst du, so geh'n wir hin, da wirst du sie gleich erschauen:", "tokens": ["Willst", "du", ",", "so", "geh'n", "wir", "hin", ",", "da", "wirst", "du", "sie", "gleich", "er\u00b7schau\u00b7en", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+--+---+--+-+-", "measure": "dactylic.di.plus"}, "line.16": {"text": "Den Onkel, die K\u00e4mm'rerschaft und die geehrten Frauen.\u00ab", "tokens": ["Den", "On\u00b7kel", ",", "die", "K\u00e4m\u00b7m'\u00b7rer\u00b7schaft", "und", "die", "ge\u00b7ehr\u00b7ten", "Frau\u00b7en", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.11": {"line.1": {"text": "Nun haben sie den Weg zum Walde eingeschlagen", "tokens": ["Nun", "ha\u00b7ben", "sie", "den", "Weg", "zum", "Wal\u00b7de", "ein\u00b7ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und thun sich nimmer genug mit Sagen und mit Fragen \u2013", "tokens": ["Und", "thun", "sich", "nim\u00b7mer", "ge\u00b7nug", "mit", "Sa\u00b7gen", "und", "mit", "Fra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Sonne sank. Sie strahlte wol in schw\u00e4cherem Glanz,", "tokens": ["Die", "Son\u00b7ne", "sank", ".", "Sie", "strahl\u00b7te", "wol", "in", "schw\u00e4\u00b7che\u00b7rem", "Glanz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Doch breiter, als bei Tage \u2013 und ger\u00f6thet ganz,", "tokens": ["Doch", "brei\u00b7ter", ",", "als", "bei", "Ta\u00b7ge", "\u2013", "und", "ge\u00b7r\u00f6\u00b7thet", "ganz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "APPR", "NN", "$(", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleich wie des Ackermanns gesundes Antlitz gl\u00fcht,", "tokens": ["Gleich", "wie", "des", "A\u00b7cker\u00b7manns", "ge\u00b7sun\u00b7des", "Ant\u00b7litz", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn er den langen Tag sich auf dem Feld gem\u00fcht", "tokens": ["Wenn", "er", "den", "lan\u00b7gen", "Tag", "sich", "auf", "dem", "Feld", "ge\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und nun zur Ruhe geht. Schon auf des Waldes Wipfel", "tokens": ["Und", "nun", "zur", "Ru\u00b7he", "geht", ".", "Schon", "auf", "des", "Wal\u00b7des", "Wip\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "$.", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Senkt sich die Scheibe nieder, und Gezweig und Gipfel", "tokens": ["Senkt", "sich", "die", "Schei\u00b7be", "nie\u00b7der", ",", "und", "Ge\u00b7zweig", "und", "Gip\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Erf\u00fcllt ein neblicht Dunkel, das in Eines schlie\u00dft", "tokens": ["Er\u00b7f\u00fcllt", "ein", "neb\u00b7licht", "Dun\u00b7kel", ",", "das", "in", "Ei\u00b7nes", "schlie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "NN", "$,", "PRELS", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den ganzen weiten Wald und wie zusammengie\u00dft.", "tokens": ["Den", "gan\u00b7zen", "wei\u00b7ten", "Wald", "und", "wie", "zu\u00b7sam\u00b7men\u00b7gie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "PWAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und schwarz und schw\u00e4rzer wird er, ein riesengro\u00df Gemach,", "tokens": ["Und", "schwarz", "und", "schw\u00e4r\u00b7zer", "wird", "er", ",", "ein", "rie\u00b7sen\u00b7gro\u00df", "Ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VAFIN", "PPER", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Roth \u00fcber ihm die Sonne, wie Feuer auf dem Dach.", "tokens": ["Roth", "\u00fc\u00b7ber", "ihm", "die", "Son\u00b7ne", ",", "wie", "Feu\u00b7er", "auf", "dem", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "$,", "PWAV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.12": {"line.1": {"text": "Wie eine Kerze durch des Fensterladens Spalt, \u2013", "tokens": ["Wie", "ei\u00b7ne", "Ker\u00b7ze", "durch", "des", "Fens\u00b7ter\u00b7la\u00b7dens", "Spalt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und es verlischt. Und die Rechen, die die M\u00e4gde schwangen,", "tokens": ["Und", "es", "ver\u00b7lischt", ".", "Und", "die", "Re\u00b7chen", ",", "die", "die", "M\u00e4g\u00b7de", "schwan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "$.", "KON", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Sicheln, die im Getreide vereint zusammenklangen,", "tokens": ["Die", "Si\u00b7cheln", ",", "die", "im", "Ge\u00b7trei\u00b7de", "ver\u00b7eint", "zu\u00b7sam\u00b7men\u00b7klan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-++-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Erschweigen und ruh'n. Denn also ist des Richters Wille:", "tokens": ["Er\u00b7schwei\u00b7gen", "und", "ruh'", "n.", "Denn", "al\u00b7so", "ist", "des", "Rich\u00b7ters", "Wil\u00b7le", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "NE", "KON", "ADV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sobald der Tag beschlossen, halte der Landmann stille;", "tokens": ["So\u00b7bald", "der", "Tag", "be\u00b7schlos\u00b7sen", ",", "hal\u00b7te", "der", "Land\u00b7mann", "stil\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$,", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der Herr der Welten ma\u00df die Zeit der Arbeit zu:", "tokens": ["Der", "Herr", "der", "Wel\u00b7ten", "ma\u00df", "die", "Zeit", "der", "Ar\u00b7beit", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn seine Dienerin, die Sonne, geht zur Ruh',", "tokens": ["Wenn", "sei\u00b7ne", "Die\u00b7ne\u00b7rin", ",", "die", "Son\u00b7ne", ",", "geht", "zur", "Ruh'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist's Zeit auch, da\u00df der Bauer ruht und sich behagt;", "tokens": ["Ist's", "Zeit", "auch", ",", "da\u00df", "der", "Bau\u00b7er", "ruht", "und", "sich", "be\u00b7hagt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "KON", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So pflegt der Richter zu sagen, und was der Richter sagt,", "tokens": ["So", "pflegt", "der", "Rich\u00b7ter", "zu", "sa\u00b7gen", ",", "und", "was", "der", "Rich\u00b7ter", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,", "KON", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der bied're \u00d6konom sieht es als heilig an.", "tokens": ["Der", "bie\u00b7d'\u00b7re", "\u00d6\u00b7kon\u00b7om", "sieht", "es", "als", "hei\u00b7lig", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KOUS", "ADJD", "PTKVZ", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.11": {"text": "Die Wagen auch, in die man Schober zu legen begann,", "tokens": ["Die", "Wa\u00b7gen", "auch", ",", "in", "die", "man", "Scho\u00b7ber", "zu", "le\u00b7gen", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPR", "PRELS", "PIS", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.12": {"text": "Heimfahren sie ungef\u00fcllt; die Thiere geh'n zur Rast,", "tokens": ["Heim\u00b7fah\u00b7ren", "sie", "un\u00b7ge\u00b7f\u00fcllt", ";", "die", "Thie\u00b7re", "geh'n", "zur", "Rast", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Mit Freuden f\u00fchlend die leichte, ungewohnte Last.", "tokens": ["Mit", "Freu\u00b7den", "f\u00fch\u00b7lend", "die", "leich\u00b7te", ",", "un\u00b7ge\u00b7wohn\u00b7te", "Last", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.13": {"line.1": {"text": "Eben kommt die Gesellschaft vom Walde, \u2013 lachend und heiter,", "tokens": ["E\u00b7ben", "kommt", "die", "Ge\u00b7sell\u00b7schaft", "vom", "Wal\u00b7de", ",", "\u2013", "la\u00b7chend", "und", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "$(", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Doch wohlgeordnet. Voran die Kinder mit ihrem Begleiter,", "tokens": ["Doch", "wohl\u00b7ge\u00b7ord\u00b7net", ".", "Vo\u00b7ran", "die", "Kin\u00b7der", "mit", "ih\u00b7rem", "Be\u00b7glei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Drauf mit der K\u00e4mm'rersfrau der Richter, und daneben", "tokens": ["Drauf", "mit", "der", "K\u00e4m\u00b7m'\u00b7rers\u00b7frau", "der", "Rich\u00b7ter", ",", "und", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "APPR", "ART", "NN", "ART", "NN", "$,", "KON", "PAV"], "meter": "---+--+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der K\u00e4mmerer selber, fr\u00f6hlich von den Seinen umgeben.", "tokens": ["Der", "K\u00e4m\u00b7me\u00b7rer", "sel\u00b7ber", ",", "fr\u00f6h\u00b7lich", "von", "den", "Sei\u00b7nen", "um\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Gleich d'rauf die jungen Damen, die jungen Herrn zur Seite,", "tokens": ["Gleich", "d'\u00b7rauf", "die", "jun\u00b7gen", "Da\u00b7men", ",", "die", "jun\u00b7gen", "Herrn", "zur", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Die Damen den Herrn voran, um halben Schrittes Weite:", "tokens": ["Die", "Da\u00b7men", "den", "Herrn", "vo\u00b7ran", ",", "um", "hal\u00b7ben", "Schrit\u00b7tes", "Wei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$,", "KOUI", "ADJA", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So will's die Sitte. Niemand wies da zur Ordnung an,", "tokens": ["So", "will's", "die", "Sit\u00b7te", ".", "Nie\u00b7mand", "wies", "da", "zur", "Ord\u00b7nung", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$.", "PIS", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Niemand stellte in Reih und Glied \u2013 nein, Jedermann", "tokens": ["Nie\u00b7mand", "stell\u00b7te", "in", "Reih", "und", "Glied", "\u2013", "nein", ",", "Je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$(", "PTKANT", "$,", "PIS"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Befolgte unwillk\u00fcrlich Ordnung und rechte Art.", "tokens": ["Be\u00b7folg\u00b7te", "un\u00b7will\u00b7k\u00fcr\u00b7lich", "Ord\u00b7nung", "und", "rech\u00b7te", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Denn beim Richter, da wurden die alten Sitten gewahrt,", "tokens": ["Denn", "beim", "Rich\u00b7ter", ",", "da", "wur\u00b7den", "die", "al\u00b7ten", "Sit\u00b7ten", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "--+--+--+-+--+", "measure": "anapaest.tri.plus"}, "line.11": {"text": "Und niemals hat er Verst\u00f6\u00dfe gegen die Achtung geduldet,", "tokens": ["Und", "nie\u00b7mals", "hat", "er", "Ver\u00b7st\u00f6\u00b7\u00dfe", "ge\u00b7gen", "die", "Ach\u00b7tung", "ge\u00b7dul\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die man dem Alter, dem Geist, dem Stand, der W\u00fcrde schuldet.", "tokens": ["Die", "man", "dem", "Al\u00b7ter", ",", "dem", "Geist", ",", "dem", "Stand", ",", "der", "W\u00fcr\u00b7de", "schul\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.13": {"text": "Denn rechte Sitte, sagt er, erh\u00e4lt Geschlecht und Reich.", "tokens": ["Denn", "rech\u00b7te", "Sit\u00b7te", ",", "sagt", "er", ",", "er\u00b7h\u00e4lt", "Ge\u00b7schlecht", "und", "Reich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und wenn sie sinkt, so sinken Geschlecht und Reich zugleich.", "tokens": ["Und", "wenn", "sie", "sinkt", ",", "so", "sin\u00b7ken", "Ge\u00b7schlecht", "und", "Reich", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "So hatten sich Haus und Gesinde der Ordnung angepa\u00dft;", "tokens": ["So", "hat\u00b7ten", "sich", "Haus", "und", "Ge\u00b7sin\u00b7de", "der", "Ord\u00b7nung", "an\u00b7ge\u00b7pa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "NN", "KON", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.16": {"text": "Und kam zu Besuch ein Verwandter oder ein fremder Gast:", "tokens": ["Und", "kam", "zu", "Be\u00b7such", "ein", "Ver\u00b7wand\u00b7ter", "o\u00b7der", "ein", "frem\u00b7der", "Gast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Wenn er nur kurze Zeit in Haus sich aufgehalten,", "tokens": ["Wenn", "er", "nur", "kur\u00b7ze", "Zeit", "in", "Haus", "sich", "auf\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "APPR", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zollt' er den Sitten Gehorsam, die beim Richter galten.", "tokens": ["Zollt'", "er", "den", "Sit\u00b7ten", "Ge\u00b7hor\u00b7sam", ",", "die", "beim", "Rich\u00b7ter", "gal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}}, "stanza.14": {"line.1": {"text": "Nur kurz begr\u00fc\u00dft er den Neffen: reicht ihm w\u00fcrdig zum Ku\u00df", "tokens": ["Nur", "kurz", "be\u00b7gr\u00fc\u00dft", "er", "den", "Nef\u00b7fen", ":", "reicht", "ihm", "w\u00fcr\u00b7dig", "zum", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Hand, k\u00fc\u00dft ihm die Stirn und sagt ihm freundlichen Gru\u00df.", "tokens": ["Die", "Hand", ",", "k\u00fc\u00dft", "ihm", "die", "Stirn", "und", "sagt", "ihm", "freund\u00b7li\u00b7chen", "Gru\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+---+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Er spricht nur wenig \u2013 es sind so viele G\u00e4ste zur Stell' \u2013", "tokens": ["Er", "spricht", "nur", "we\u00b7nig", "\u2013", "es", "sind", "so", "vie\u00b7le", "G\u00e4s\u00b7te", "zur", "Stell'", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die helle Thr\u00e4ne wegwischt, die ihm vom Auge rinnt:", "tokens": ["Die", "hel\u00b7le", "Thr\u00e4\u00b7ne", "weg\u00b7wischt", ",", "die", "ihm", "vom", "Au\u00b7ge", "rinnt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sieht man, er liebt Thadd\u00e4us, wie ein eigen Kind.", "tokens": ["Sieht", "man", ",", "er", "liebt", "Thad\u00b7d\u00e4us", ",", "wie", "ein", "ei\u00b7gen", "Kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PPER", "VVFIN", "NE", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.15": {"line.1": {"text": "Aus Feld und Flur und Wald und Weide nah' und fern", "tokens": ["Aus", "Feld", "und", "Flur", "und", "Wald", "und", "Wei\u00b7de", "nah'", "und", "fern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "PTKVZ", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kehrt Alles nun zur\u00fcck nach Hause mit dem Herrn;", "tokens": ["Kehrt", "Al\u00b7les", "nun", "zu\u00b7r\u00fcck", "nach", "Hau\u00b7se", "mit", "dem", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKVZ", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier eine Heerde Schafe, sie w\u00e4lzt sich in die Gasse", "tokens": ["Hier", "ei\u00b7ne", "Heer\u00b7de", "Scha\u00b7fe", ",", "sie", "w\u00e4lzt", "sich", "in", "die", "Gas\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Lautbl\u00f6kend und Staub aufwirbelnd; dort die schwere Masse", "tokens": ["Laut\u00b7bl\u00f6\u00b7kend", "und", "Staub", "auf\u00b7wir\u00b7belnd", ";", "dort", "die", "schwe\u00b7re", "Mas\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "NN", "VVPP", "$.", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Tyroler K\u00e4lber, die H\u00e4lse mit Messingglocken beh\u00e4ngt;", "tokens": ["Ty\u00b7ro\u00b7ler", "K\u00e4l\u00b7ber", ",", "die", "H\u00e4l\u00b7se", "mit", "Mes\u00b7sing\u00b7glo\u00b7cken", "be\u00b7h\u00e4ngt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Da fliegen vom Anger her die Pferde \u2013 Alles dr\u00e4ngt", "tokens": ["Da", "flie\u00b7gen", "vom", "An\u00b7ger", "her", "die", "Pfer\u00b7de", "\u2013", "Al\u00b7les", "dr\u00e4ngt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APZR", "ART", "NN", "$(", "PIS", "VVFIN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Zum Brunnen, wo auf und nieder kreischt der h\u00f6lzerne Arm,", "tokens": ["Zum", "Brun\u00b7nen", ",", "wo", "auf", "und", "nie\u00b7der", "kreischt", "der", "h\u00f6l\u00b7zer\u00b7ne", "Arm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PWAV", "PTKVZ", "KON", "PTKVZ", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Den Trog mit Wasser zu f\u00fcllen f\u00fcr den durstigen Schwarm.", "tokens": ["Den", "Trog", "mit", "Was\u00b7ser", "zu", "f\u00fcl\u00b7len", "f\u00fcr", "den", "durs\u00b7ti\u00b7gen", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.16": {"line.1": {"text": "M\u00fcd', und von G\u00e4sten umringt, s\u00e4umt doch der Richter nicht,", "tokens": ["M\u00fcd'", ",", "und", "von", "G\u00e4s\u00b7ten", "um\u00b7ringt", ",", "s\u00e4umt", "doch", "der", "Rich\u00b7ter", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "APPR", "NN", "VVPP", "$,", "VVFIN", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Auch jetzt genau zu erf\u00fcllen die wichtige Landwirthspflicht.", "tokens": ["Auch", "jetzt", "ge\u00b7nau", "zu", "er\u00b7f\u00fcl\u00b7len", "die", "wich\u00b7ti\u00b7ge", "Land\u00b7wirths\u00b7pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er selbst begiebt sich zum Brunnen. Wenn's Abends heimw\u00e4rts geht,", "tokens": ["Er", "selbst", "be\u00b7giebt", "sich", "zum", "Brun\u00b7nen", ".", "Wenn's", "A\u00b7bends", "heim\u00b7w\u00e4rts", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "APPRART", "NN", "$.", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da sieht der Wirth am Besten, wie's mit dem Viehstall steht.", "tokens": ["Da", "sieht", "der", "Wirth", "am", "Bes\u00b7ten", ",", "wie's", "mit", "dem", "Vieh\u00b7stall", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Die Pr\u00fcfung \u00fcberlie\u00df er seinen Knechten nie:", "tokens": ["Die", "Pr\u00fc\u00b7fung", "\u00fc\u00b7ber\u00b7lie\u00df", "er", "sei\u00b7nen", "Knech\u00b7ten", "nie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er wei\u00df, des Herrn Auge f\u00fcttert wohl das Vieh.", "tokens": ["Er", "wei\u00df", ",", "des", "Herrn", "Au\u00b7ge", "f\u00fct\u00b7tert", "wohl", "das", "Vieh", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.17": {"line.1": {"text": "Im Vorhaus, Licht in den H\u00e4nden, standen um diese Zeit", "tokens": ["Im", "Vor\u00b7haus", ",", "Licht", "in", "den", "H\u00e4n\u00b7den", ",", "stan\u00b7den", "um", "die\u00b7se", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "APPR", "ART", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Protasius, der Gerichtsfrohn,", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", ",", "der", "Ge\u00b7richts\u00b7frohn", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Protasius n\u00e4mlich hatte heimlich aus dem Saal", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "n\u00e4m\u00b7lich", "hat\u00b7te", "heim\u00b7lich", "aus", "dem", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VAFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Tisch fortschaffen lassen sammt dem Abendmahl", "tokens": ["Den", "Tisch", "fort\u00b7schaf\u00b7fen", "las\u00b7sen", "sammt", "dem", "A\u00b7bend\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVINF", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und anzurichten befohlen, so rasch sich's machen l\u00e4\u00dft,", "tokens": ["Und", "an\u00b7zu\u00b7rich\u00b7ten", "be\u00b7foh\u00b7len", ",", "so", "rasch", "sich's", "ma\u00b7chen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVPP", "$,", "ADV", "ADJD", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Im Schlo\u00df, unweit des Walds: ein altes Tr\u00fcmmernest.", "tokens": ["Im", "Schlo\u00df", ",", "un\u00b7weit", "des", "Walds", ":", "ein", "al\u00b7tes", "Tr\u00fcm\u00b7mer\u00b7nest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was sollte dies? Der Wojski macht \u00e4rgerliche Gesichter,", "tokens": ["Was", "soll\u00b7te", "dies", "?", "Der", "Wojs\u00b7ki", "macht", "\u00e4r\u00b7ger\u00b7li\u00b7che", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "$.", "ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-++-+--+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Zankt, \u2013 entschuldigt sich dann bei dem erstaunten Richter;", "tokens": ["Zankt", ",", "\u2013", "ent\u00b7schul\u00b7digt", "sich", "dann", "bei", "dem", "er\u00b7staun\u00b7ten", "Rich\u00b7ter", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "$(", "VVFIN", "PRF", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Was hilft's? es ist schon sp\u00e4t: der Richter mu\u00df die G\u00e4ste", "tokens": ["Was", "hilft's", "?", "es", "ist", "schon", "sp\u00e4t", ":", "der", "Rich\u00b7ter", "mu\u00df", "die", "G\u00e4s\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$.", "ART", "NN", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Um Nachsicht bitten und f\u00fchrt sie in die verfallene Veste.", "tokens": ["Um", "Nach\u00b7sicht", "bit\u00b7ten", "und", "f\u00fchrt", "sie", "in", "die", "ver\u00b7fal\u00b7le\u00b7ne", "Ves\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVINF", "KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Im Geh'n erkl\u00e4rt ihm Protas des Breiten und des Langen,", "tokens": ["Im", "Geh'n", "er\u00b7kl\u00e4rt", "ihm", "Pro\u00b7tas", "des", "Brei\u00b7ten", "und", "des", "Lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Warum er sich die Befehle zu \u00e4ndern unterfangen:", "tokens": ["Wa\u00b7rum", "er", "sich", "die", "Be\u00b7feh\u00b7le", "zu", "\u00e4n\u00b7dern", "un\u00b7ter\u00b7fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ART", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Es ist im Hause kein gen\u00fcgend gro\u00dfer Saal", "tokens": ["Es", "ist", "im", "Hau\u00b7se", "kein", "ge\u00b7n\u00fc\u00b7gend", "gro\u00b7\u00dfer", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PIAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "F\u00fcr G\u00e4ste von solchem Range und von solcher Zahl;", "tokens": ["F\u00fcr", "G\u00e4s\u00b7te", "von", "sol\u00b7chem", "Ran\u00b7ge", "und", "von", "sol\u00b7cher", "Zahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "KON", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Im Schlo\u00df giebt's eine Halle, recht gro\u00df und wohlerhalten,", "tokens": ["Im", "Schlo\u00df", "giebt's", "ei\u00b7ne", "Hal\u00b7le", ",", "recht", "gro\u00df", "und", "woh\u00b7ler\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Die W\u00f6lbung ganz \u2013 es ist zwar eine Wand gespalten,", "tokens": ["Die", "W\u00f6l\u00b7bung", "ganz", "\u2013", "es", "ist", "zwar", "ei\u00b7ne", "Wand", "ge\u00b7spal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Fenster ohne Scheiben, doch ist's ja Sommerzeit,", "tokens": ["Die", "Fens\u00b7ter", "oh\u00b7ne", "Schei\u00b7ben", ",", "doch", "ist's", "ja", "Som\u00b7mer\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ADV", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "So spricht er und blinzelt ihm zu \u2013 und seine Miene zeigt,", "tokens": ["So", "spricht", "er", "und", "blin\u00b7zelt", "ihm", "zu", "\u2013", "und", "sei\u00b7ne", "Mie\u00b7ne", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKZU", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Er hat noch andre Gr\u00fcnde, die er klug verschweigt.", "tokens": ["Er", "hat", "noch", "and\u00b7re", "Gr\u00fcn\u00b7de", ",", "die", "er", "klug", "ver\u00b7schweigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$,", "PRELS", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.18": {"line.1": {"text": "Zweitausend Schritt vom Hause sah man das Schlo\u00df nun ragen:", "tokens": ["Zweit\u00b7au\u00b7send", "Schritt", "vom", "Hau\u00b7se", "sah", "man", "das", "Schlo\u00df", "nun", "ra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein stolzer, m\u00e4cht'ger Bau. Hier hauste in fr\u00fchern Tagen", "tokens": ["Ein", "stol\u00b7zer", ",", "m\u00e4cht'\u00b7ger", "Bau", ".", "Hier", "haus\u00b7te", "in", "fr\u00fc\u00b7hern", "Ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das alte Geschlecht der Horeszko; der Schlo\u00dfherr war gefallen", "tokens": ["Das", "al\u00b7te", "Ge\u00b7schlecht", "der", "Hor\u00b7esz\u00b7ko", ";", "der", "Schlo\u00df\u00b7herr", "war", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NE", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Zur Zeit der innern Wirren; und von den G\u00fctern allen", "tokens": ["Zur", "Zeit", "der", "in\u00b7nern", "Wir\u00b7ren", ";", "und", "von", "den", "G\u00fc\u00b7tern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$.", "KON", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "War Nichts geblieben; schlecht verwaltet und gepflegt,", "tokens": ["War", "Nichts", "ge\u00b7blie\u00b7ben", ";", "schlecht", "ver\u00b7wal\u00b7tet", "und", "ge\u00b7pflegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$.", "ADJD", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Theils durch Processe zerrieben, theils mit Beschlag belegt,", "tokens": ["Theils", "durch", "Pro\u00b7ces\u00b7se", "zer\u00b7rie\u00b7ben", ",", "theils", "mit", "Be\u00b7schlag", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.7": {"text": "Ward endlich, was nicht Verwandte von Mutterseite bekommen,", "tokens": ["Ward", "end\u00b7lich", ",", "was", "nicht", "Ver\u00b7wand\u00b7te", "von", "Mut\u00b7ter\u00b7sei\u00b7te", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PRELS", "PTKNEG", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-++-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Von Gl\u00e4ubigern getheilt. Das Schlo\u00df hat Niemand genommen;", "tokens": ["Von", "Gl\u00e4u\u00b7bi\u00b7gern", "ge\u00b7theilt", ".", "Das", "Schlo\u00df", "hat", "Nie\u00b7mand", "ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Denn es zu erhalten, fiel bei m\u00e4\u00dfigen Mitteln nicht leicht.", "tokens": ["Denn", "es", "zu", "er\u00b7hal\u00b7ten", ",", "fiel", "bei", "m\u00e4\u00b7\u00dfi\u00b7gen", "Mit\u00b7teln", "nicht", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "APPR", "ADJA", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Als aber der Graf die Jahre der M\u00fcndigkeit erreicht \u2013", "tokens": ["Als", "a\u00b7ber", "der", "Graf", "die", "Jah\u00b7re", "der", "M\u00fcn\u00b7dig\u00b7keit", "er\u00b7reicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ein naher Nachbar, entfernt mit den Horeszko verwandt, \u2013", "tokens": ["Ein", "na\u00b7her", "Nach\u00b7bar", ",", "ent\u00b7fernt", "mit", "den", "Hor\u00b7esz\u00b7ko", "ver\u00b7wandt", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "APPR", "ART", "NE", "VVPP", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Kam er, ein reicher Junker, heim aus fremdem Land,", "tokens": ["Kam", "er", ",", "ein", "rei\u00b7cher", "Jun\u00b7ker", ",", "heim", "aus", "frem\u00b7dem", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "ART", "ADJA", "NN", "$,", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und ihm gefiel das Nest. Warum es ihm gefiel?", "tokens": ["Und", "ihm", "ge\u00b7fiel", "das", "Nest", ".", "Wa\u00b7rum", "es", "ihm", "ge\u00b7fiel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wer sagt es? Er erkl\u00e4rte, es w\u00e4r' in gothischem Stil \u2013", "tokens": ["Wer", "sagt", "es", "?", "Er", "er\u00b7kl\u00e4r\u00b7te", ",", "es", "w\u00e4r'", "in", "go\u00b7thi\u00b7schem", "Stil", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Und standen doch dem Richter die Akten zu Gebote,", "tokens": ["Und", "stan\u00b7den", "doch", "dem", "Rich\u00b7ter", "die", "Ak\u00b7ten", "zu", "Ge\u00b7bo\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Da\u00df der Erbauer aus Wilna gewesen, und kein Gothe.", "tokens": ["Da\u00df", "der", "Er\u00b7bau\u00b7er", "aus", "Wil\u00b7na", "ge\u00b7we\u00b7sen", ",", "und", "kein", "Go\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "VAPP", "$,", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.17": {"text": "Genug, den Grafen gel\u00fcstet's nach dem Schlo\u00df \u2013 und just", "tokens": ["Ge\u00b7nug", ",", "den", "Gra\u00b7fen", "ge\u00b7l\u00fcs\u00b7tet's", "nach", "dem", "Schlo\u00df", "\u2013", "und", "just"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "ART", "NN", "NE", "APPR", "ART", "NN", "$(", "KON", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Bef\u00e4llt, Gott wei\u00df warum, den Richter dieselbe Lust.", "tokens": ["Be\u00b7f\u00e4llt", ",", "Gott", "wei\u00df", "wa\u00b7rum", ",", "den", "Rich\u00b7ter", "die\u00b7sel\u00b7be", "Lust", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VVFIN", "PWAV", "$,", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Nun stritt man im Grundgericht, im Obergericht, im Senat,", "tokens": ["Nun", "stritt", "man", "im", "Grund\u00b7ge\u00b7richt", ",", "im", "O\u00b7ber\u00b7ge\u00b7richt", ",", "im", "Se\u00b7nat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Und wieder im Grundgericht und dann im Regierungsrath;", "tokens": ["Und", "wie\u00b7der", "im", "Grund\u00b7ge\u00b7richt", "und", "dann", "im", "Re\u00b7gie\u00b7rungs\u00b7rath", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "KON", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Endlich, nachdem man viel Geld und viel Papier verthan,", "tokens": ["End\u00b7lich", ",", "nach\u00b7dem", "man", "viel", "Geld", "und", "viel", "Pa\u00b7pier", "ver\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.22": {"text": "Langt nun die Sache wieder beim Grenzgerichte an.", "tokens": ["Langt", "nun", "die", "Sa\u00b7che", "wie\u00b7der", "beim", "Grenz\u00b7ge\u00b7rich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.19": {"line.1": {"text": "Protasius hatte Recht; es fa\u00dfte bequem die Halle", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "hat\u00b7te", "Recht", ";", "es", "fa\u00df\u00b7te", "be\u00b7quem", "die", "Hal\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NN", "$.", "PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Leute vom Gericht und auch die G\u00e4ste alle, \u2013", "tokens": ["Die", "Leu\u00b7te", "vom", "Ge\u00b7richt", "und", "auch", "die", "G\u00e4s\u00b7te", "al\u00b7le", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "ADV", "ART", "NN", "PIS", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gro\u00df wie ein Refectorium: die W\u00f6lbung hochgestreckt,", "tokens": ["Gro\u00df", "wie", "ein", "Re\u00b7fec\u00b7to\u00b7ri\u00b7um", ":", "die", "W\u00f6l\u00b7bung", "hoch\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$.", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Auf Pfeilern ruhend, der Estrich ganz mit Stein gedeckt.", "tokens": ["Auf", "Pfei\u00b7lern", "ru\u00b7hend", ",", "der", "Est\u00b7rich", "ganz", "mit", "Stein", "ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Schmucklose, nackte W\u00e4nde, doch war die Mauer rein \u2013", "tokens": ["Schmuck\u00b7lo\u00b7se", ",", "nack\u00b7te", "W\u00e4n\u00b7de", ",", "doch", "war", "die", "Mau\u00b7er", "rein", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "ADJD", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Rings eine gro\u00dfe Menge von Reh- und Hirschgeweih'n", "tokens": ["Rings", "ei\u00b7ne", "gro\u00b7\u00dfe", "Men\u00b7ge", "von", "Reh", "und", "Hirschge\u00b7weih'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "TRUNC", "KON", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Mit Aufschriften, wann und wo die Beute ward erlegt,", "tokens": ["Mit", "Auf\u00b7schrif\u00b7ten", ",", "wann", "und", "wo", "die", "Beu\u00b7te", "ward", "er\u00b7legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "KON", "PWAV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.8": {"text": "Der J\u00e4ger Wappenbilder \u00fcberall eingepr\u00e4gt,", "tokens": ["Der", "J\u00e4\u00b7ger", "Wap\u00b7pen\u00b7bil\u00b7der", "\u00fc\u00b7be\u00b7rall", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und Jeder mit Namen genannt; und \u00fcber alle erhoben,", "tokens": ["Und", "Je\u00b7der", "mit", "Na\u00b7men", "ge\u00b7nannt", ";", "und", "\u00fc\u00b7ber", "al\u00b7le", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "VVPP", "$.", "KON", "APPR", "PIS", "VVPP", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Prangt der Horeszko Halbbock an der W\u00f6lbung droben.", "tokens": ["Prangt", "der", "Hor\u00b7esz\u00b7ko", "Halb\u00b7bock", "an", "der", "W\u00f6l\u00b7bung", "dro\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "NE", "APPR", "ART", "NN", "ADV", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Ringsum im Kreise auf; der K\u00e4mm'rer obenan.", "tokens": ["Ring\u00b7sum", "im", "Krei\u00b7se", "auf", ";", "der", "K\u00e4m\u00b7m'\u00b7rer", "o\u00b7be\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PTKVZ", "$.", "ART", "NN", "ADV", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Seinem Alter und Amt ertheilt man die Ehre gern;", "tokens": ["Sei\u00b7nem", "Al\u00b7ter", "und", "Amt", "er\u00b7theilt", "man", "die", "Eh\u00b7re", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "Im Gehen gr\u00fc\u00dft er die Damen, die \u00e4ltern und j\u00fcngern Herrn.", "tokens": ["Im", "Ge\u00b7hen", "gr\u00fc\u00dft", "er", "die", "Da\u00b7men", ",", "die", "\u00e4l\u00b7tern", "und", "j\u00fcn\u00b7gern", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Daneben der Almosenier, bei dem der Richter steht;", "tokens": ["Da\u00b7ne\u00b7ben", "der", "Al\u00b7mo\u00b7se\u00b7nier", ",", "bei", "dem", "der", "Rich\u00b7ter", "steht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.15": {"text": "Der Priester spricht ein kurzes lateinisches Gebet;", "tokens": ["Der", "Pries\u00b7ter", "spricht", "ein", "kur\u00b7zes", "la\u00b7tei\u00b7ni\u00b7sches", "Ge\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Man giebt den M\u00e4nnern Branntwein; dann setzen sich Alle in Ruh'", "tokens": ["Man", "giebt", "den", "M\u00e4n\u00b7nern", "Brannt\u00b7wein", ";", "dann", "set\u00b7zen", "sich", "Al\u00b7le", "in", "Ruh'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$.", "ADV", "VVFIN", "PRF", "PIS", "APPR", "NN"], "meter": "-+-+-++-+--+--+", "measure": "iambic.septa.relaxed"}, "line.17": {"text": "Und sprechen der Lithauersuppe schweigend und tapfer zu.", "tokens": ["Und", "spre\u00b7chen", "der", "Lit\u00b7hau\u00b7er\u00b7sup\u00b7pe", "schwei\u00b7gend", "und", "tap\u00b7fer", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.20": {"line.1": {"text": "Thadd\u00e4us geh\u00f6rt wohl zur Jugend, doch sitzt er nach Gastesrecht", "tokens": ["Thad\u00b7d\u00e4us", "ge\u00b7h\u00f6rt", "wohl", "zur", "Ju\u00b7gend", ",", "doch", "sitzt", "er", "nach", "Gas\u00b7tes\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPRART", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heut' oben, nah' dem Hausherrn, beim weiblichen Geschlecht.", "tokens": ["Heut'", "o\u00b7ben", ",", "nah'", "dem", "Haus\u00b7herrn", ",", "beim", "weib\u00b7li\u00b7chen", "Ge\u00b7schlecht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zwischen dem Onkel und ihm ist aber ein Sitz noch leer,", "tokens": ["Zwi\u00b7schen", "dem", "On\u00b7kel", "und", "ihm", "ist", "a\u00b7ber", "ein", "Sitz", "noch", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+--+-+-+---+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Als sollt' noch Jemand kommen. Oft sieht der Onkel her", "tokens": ["Als", "sollt'", "noch", "Je\u00b7mand", "kom\u00b7men", ".", "Oft", "sieht", "der", "On\u00b7kel", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "ADV", "PIS", "VVINF", "$.", "ADV", "VVFIN", "ART", "NN", "APZR"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und wendet sich dann wieder zur Th\u00fcr, erwartungsvoll, \u2013", "tokens": ["Und", "wen\u00b7det", "sich", "dann", "wie\u00b7der", "zur", "Th\u00fcr", ",", "er\u00b7war\u00b7tungs\u00b7voll", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "APPRART", "NN", "$,", "ADJD", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Als wollt' er und w\u00fc\u00dfte sicher, da\u00df Jemand erscheinen soll.", "tokens": ["Als", "wollt'", "er", "und", "w\u00fc\u00df\u00b7te", "si\u00b7cher", ",", "da\u00df", "Je\u00b7mand", "er\u00b7schei\u00b7nen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "KON", "VVFIN", "ADJD", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Zur Th\u00fcr begleitet Thadd\u00e4us seinen suchenden Blick", "tokens": ["Zur", "Th\u00fcr", "be\u00b7glei\u00b7tet", "Thad\u00b7d\u00e4us", "sei\u00b7nen", "su\u00b7chen\u00b7den", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "NE", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Und kehrt mit ihm dann wieder zum leeren Sitz zur\u00fcck.", "tokens": ["Und", "kehrt", "mit", "ihm", "dann", "wie\u00b7der", "zum", "lee\u00b7ren", "Sitz", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ADV", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Seltsam, da sitzt ja rings ein ganzer M\u00e4dchenreigen, \u2013", "tokens": ["Selt\u00b7sam", ",", "da", "sitzt", "ja", "rings", "ein", "gan\u00b7zer", "M\u00e4d\u00b7chen\u00b7rei\u00b7gen", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Er d\u00fcrft' sich vor den Augen eines Prinzen zeigen, \u2013", "tokens": ["Er", "d\u00fcrft'", "sich", "vor", "den", "Au\u00b7gen", "ei\u00b7nes", "Prin\u00b7zen", "zei\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Lauter Edelgeborene, Junge, Sch\u00f6ne, Feine:", "tokens": ["Lau\u00b7ter", "E\u00b7del\u00b7ge\u00b7bo\u00b7re\u00b7ne", ",", "Jun\u00b7ge", ",", "Sch\u00f6\u00b7ne", ",", "Fei\u00b7ne", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Wo aber Thadd\u00e4us hinschaut, da sitzt ja g'rade keine!", "tokens": ["Wo", "a\u00b7ber", "Thad\u00b7d\u00e4us", "hin\u00b7schaut", ",", "da", "sitzt", "ja", "g'\u00b7ra\u00b7de", "kei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "VVPP", "$,", "ADV", "VVFIN", "ADV", "ADV", "PIAT", "$."], "meter": "-+-+-++-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "Die Jugend liebt die R\u00e4thsel, und r\u00e4thselhaft ist der Ort.", "tokens": ["Die", "Ju\u00b7gend", "liebt", "die", "R\u00e4th\u00b7sel", ",", "und", "r\u00e4th\u00b7sel\u00b7haft", "ist", "der", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Zerstreut spricht er nur hin und wieder kaum ein Wort", "tokens": ["Zer\u00b7streut", "spricht", "er", "nur", "hin", "und", "wie\u00b7der", "kaum", "ein", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zur holden Nachbarin, zu K\u00e4mmerer's T\u00f6chterlein,", "tokens": ["Zur", "hol\u00b7den", "Nach\u00b7ba\u00b7rin", ",", "zu", "K\u00e4m\u00b7me\u00b7rer's", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Er wechselt ihr nicht die Teller, gie\u00dft nichts in's Glas ihr ein,", "tokens": ["Er", "wech\u00b7selt", "ihr", "nicht", "die", "Tel\u00b7ler", ",", "gie\u00dft", "nichts", "in's", "Glas", "ihr", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "VVFIN", "PIS", "APPRART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Denkt nicht daran, den Damen artige Reden zu bieten,", "tokens": ["Denkt", "nicht", "da\u00b7ran", ",", "den", "Da\u00b7men", "ar\u00b7ti\u00b7ge", "Re\u00b7den", "zu", "bie\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PAV", "$,", "ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Die da an ihm der Hauptstadt feine Erziehung verriethen, \u2013", "tokens": ["Die", "da", "an", "ihm", "der", "Haupt\u00b7stadt", "fei\u00b7ne", "Er\u00b7zie\u00b7hung", "ver\u00b7rie\u00b7then", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "ART", "NN", "ADJA", "NN", "VVINF", "$,", "$("], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.19": {"text": "Zu jenem leeren Platz lockt es ihn einzig hin:", "tokens": ["Zu", "je\u00b7nem", "lee\u00b7ren", "Platz", "lockt", "es", "ihn", "ein\u00b7zig", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.20": {"text": "Nun nicht mehr leer, \u2013 es f\u00fcllen seine Gedanken ihn, \u2013", "tokens": ["Nun", "nicht", "mehr", "leer", ",", "\u2013", "es", "f\u00fcl\u00b7len", "sei\u00b7ne", "Ge\u00b7dan\u00b7ken", "ihn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADJD", "$,", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "PPER", "$,", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Vermuthungen, unz\u00e4hlige, l\u00e4\u00dft er dar\u00fcber laufen,", "tokens": ["Ver\u00b7mu\u00b7thun\u00b7gen", ",", "un\u00b7z\u00e4h\u00b7li\u00b7ge", ",", "l\u00e4\u00dft", "er", "da\u00b7r\u00fc\u00b7ber", "lau\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,", "VVFIN", "PPER", "PAV", "VVINF", "$,"], "meter": "-+--++--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Wie nach dem Regen im Feld der muntern Fr\u00f6schlein Haufen;", "tokens": ["Wie", "nach", "dem", "Re\u00b7gen", "im", "Feld", "der", "mun\u00b7tern", "Fr\u00f6schlein", "Hau\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.23": {"text": "Doch k\u00f6niglich ob Allem ein trautes Bildni\u00df schwebt,", "tokens": ["Doch", "k\u00f6\u00b7nig\u00b7lich", "ob", "Al\u00b7lem", "ein", "trau\u00b7tes", "Bild\u00b7ni\u00df", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOUS", "PIS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Der Wasserlilie gleich, die aus der Fluth sich hebt.", "tokens": ["Der", "Was\u00b7ser\u00b7li\u00b7lie", "gleich", ",", "die", "aus", "der", "Fluth", "sich", "hebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}}, "stanza.21": {"line.1": {"text": "Man war beim dritten Gang. Da go\u00df ein Tr\u00f6pfchen Wein", "tokens": ["Man", "war", "beim", "drit\u00b7ten", "Gang", ".", "Da", "go\u00df", "ein", "Tr\u00f6pf\u00b7chen", "Wein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der K\u00e4mm'rer in das Gl\u00e4schen des Fr\u00e4uleins Rosa ein,", "tokens": ["Der", "K\u00e4m\u00b7m'\u00b7rer", "in", "das", "Gl\u00e4s\u00b7chen", "des", "Fr\u00e4u\u00b7leins", "Ro\u00b7sa", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "NE", "PTKVZ", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und schob der j\u00fcngern Tochter den Gurkenteller hin", "tokens": ["Und", "schob", "der", "j\u00fcn\u00b7gern", "Toch\u00b7ter", "den", "Gur\u00b7ken\u00b7tel\u00b7ler", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Mu\u00df ich euch heut' bedenken.\u00ab \u2013 Da st\u00fcrzen rasch zu ihnen", "tokens": ["Mu\u00df", "ich", "euch", "heut'", "be\u00b7den\u00b7ken", ".", "\u00ab", "\u2013", "Da", "st\u00fcr\u00b7zen", "rasch", "zu", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "$(", "$(", "ADV", "VVFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ein paar der jungen Herrn, die Damen zu bedienen.", "tokens": ["Ein", "paar", "der", "jun\u00b7gen", "Herrn", ",", "die", "Da\u00b7men", "zu", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Richter warf auf Thadd\u00e4us einen Seitenblick,", "tokens": ["Der", "Rich\u00b7ter", "warf", "auf", "Thad\u00b7d\u00e4us", "ei\u00b7nen", "Sei\u00b7ten\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schob sich die \u00c4rmel des Kontusz erst ein wenig zur\u00fcck,", "tokens": ["Schob", "sich", "die", "\u00c4r\u00b7mel", "des", "Kon\u00b7tusz", "erst", "ein", "we\u00b7nig", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ART", "NN", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Go\u00df dann Tokaier ein und sprach: \u00bbWir schicken heute", "tokens": ["Go\u00df", "dann", "To\u00b7kai\u00b7er", "ein", "und", "sprach", ":", "\u00bb", "Wir", "schi\u00b7cken", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "NN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Zur Schule in die Hauptstadt unsre jungen Leute,", "tokens": ["Zur", "Schu\u00b7le", "in", "die", "Haupt\u00b7stadt", "uns\u00b7re", "jun\u00b7gen", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So will's die neue Mode. Und wir r\u00e4umen ein:", "tokens": ["So", "will's", "die", "neu\u00b7e", "Mo\u00b7de", ".", "Und", "wir", "r\u00e4u\u00b7men", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$.", "KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sie m\u00f6gen an B\u00fccherweisheit uns \u00fcberlegen sein.", "tokens": ["Sie", "m\u00f6\u00b7gen", "an", "B\u00fc\u00b7cher\u00b7weis\u00b7heit", "uns", "\u00fc\u00b7berl\u00b7e\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Doch t\u00e4glich mu\u00df ich die Jugend daran kranken seh'n,", "tokens": ["Doch", "t\u00e4g\u00b7lich", "mu\u00df", "ich", "die", "Ju\u00b7gend", "da\u00b7ran", "kran\u00b7ken", "seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "ART", "NN", "PAV", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Da\u00df keine Schule lehrt mit Menschen umzugeh'n.", "tokens": ["Da\u00df", "kei\u00b7ne", "Schu\u00b7le", "lehrt", "mit", "Men\u00b7schen", "um\u00b7zu\u00b7geh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "APPR", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vor Zeiten pflegte der Junker an einen Hof zu fahren,", "tokens": ["Vor", "Zei\u00b7ten", "pfleg\u00b7te", "der", "Jun\u00b7ker", "an", "ei\u00b7nen", "Hof", "zu", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Ich selber diente einen Zeitraum von zehn Jahren,", "tokens": ["Ich", "sel\u00b7ber", "dien\u00b7te", "ei\u00b7nen", "Zeit\u00b7raum", "von", "zehn", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Beim Wojewoden, unsres verehrten K\u00e4mm'rers Vater;", "tokens": ["Beim", "Wo\u00b7je\u00b7wo\u00b7den", ",", "uns\u00b7res", "ver\u00b7ehr\u00b7ten", "K\u00e4m\u00b7m'\u00b7rers", "Va\u00b7ter", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "(hier dr\u00fcckt' er den K\u00e4mm'rer am Knie), der war mein treuer Berather,", "tokens": ["(", "hier", "dr\u00fcckt'", "er", "den", "K\u00e4m\u00b7m'\u00b7rer", "am", "Knie", ")", ",", "der", "war", "mein", "treu\u00b7er", "Be\u00b7ra\u00b7ther", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$(", "$,", "PRELS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--++--+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "Als ich den Staatsdienst lernte \u2013 und hielt mich lang' in Acht,", "tokens": ["Als", "ich", "den", "Staats\u00b7dienst", "lern\u00b7te", "\u2013", "und", "hielt", "mich", "lang'", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$(", "KON", "VVFIN", "PPER", "ADV", "APPR", "CARD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und hat dann endlich aus Einem einen Menschen gemacht.", "tokens": ["Und", "hat", "dann", "end\u00b7lich", "aus", "Ei\u00b7nem", "ei\u00b7nen", "Men\u00b7schen", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sein Name bleibt uns theuer, so lang' mein Haus besteht,", "tokens": ["Sein", "Na\u00b7me", "bleibt", "uns", "theu\u00b7er", ",", "so", "lang'", "mein", "Haus", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Und seiner Seele gedenk' ich t\u00e4glich im Gebet.", "tokens": ["Und", "sei\u00b7ner", "See\u00b7le", "ge\u00b7denk'", "ich", "t\u00e4g\u00b7lich", "im", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Und hat mir's weniger Nutzen als Anderen gew\u00e4hrt,", "tokens": ["Und", "hat", "mir's", "we\u00b7ni\u00b7ger", "Nut\u00b7zen", "als", "An\u00b7de\u00b7ren", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NE", "PIAT", "NN", "KOUS", "ADJA", "VVPP", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Bin ich vom Hofe wieder zum Acker zur\u00fcckgekehrt.", "tokens": ["Bin", "ich", "vom", "Ho\u00b7fe", "wie\u00b7der", "zum", "A\u00b7cker", "zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Inde\u00df die Andern, die wohl w\u00fcrdiger erschienen,", "tokens": ["In\u00b7de\u00df", "die", "An\u00b7dern", ",", "die", "wohl", "w\u00fcr\u00b7di\u00b7ger", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "PRELS", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hernach in h\u00f6chsten \u00c4mtern dem Staate durften dienen:", "tokens": ["Her\u00b7nach", "in", "h\u00f6chs\u00b7ten", "\u00c4m\u00b7tern", "dem", "Staa\u00b7te", "durf\u00b7ten", "die\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Hab' ich doch so viel gewonnen, da\u00df Jeder mu\u00df gesteh'n:", "tokens": ["Hab'", "ich", "doch", "so", "viel", "ge\u00b7won\u00b7nen", ",", "da\u00df", "Je\u00b7der", "mu\u00df", "ge\u00b7steh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,", "KOUS", "PIS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.27": {"text": "Bei mir ist nie was wider die Artigkeit gescheh'n,", "tokens": ["Bei", "mir", "ist", "nie", "was", "wi\u00b7der", "die", "Ar\u00b7tig\u00b7keit", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "PIS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Noch gegen das rechte Benehmen. Und ein Benehmen, ein feines, \u2013", "tokens": ["Noch", "ge\u00b7gen", "das", "rech\u00b7te", "Be\u00b7neh\u00b7men", ".", "Und", "ein", "Be\u00b7neh\u00b7men", ",", "ein", "fei\u00b7nes", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$.", "KON", "ART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+--+--+--+-+--+-", "measure": "amphibrach.tetra.plus"}, "line.29": {"text": "Das sag' ich k\u00fchn, ist weder was Leichtes noch Kleines.", "tokens": ["Das", "sag'", "ich", "k\u00fchn", ",", "ist", "we\u00b7der", "was", "Leich\u00b7tes", "noch", "Klei\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "KON", "PWS", "ADJA", "ADV", "NE", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Nichts Leichtes \u2013 denn mit dem Kratzfu\u00df ist es nicht gethan,", "tokens": ["Nichts", "Leich\u00b7tes", "\u2013", "denn", "mit", "dem", "Kratz\u00b7fu\u00df", "ist", "es", "nicht", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "$(", "KON", "APPR", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Anl\u00e4cheln, den Ersten Besten, das lernt ein Jeder an,", "tokens": ["An\u00b7l\u00e4\u00b7cheln", ",", "den", "Ers\u00b7ten", "Bes\u00b7ten", ",", "das", "lernt", "ein", "Je\u00b7der", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Das ist die Artigkeit des Kr\u00e4mers, das ist modern,", "tokens": ["Das", "ist", "die", "Ar\u00b7tig\u00b7keit", "des", "Kr\u00e4\u00b7mers", ",", "das", "ist", "mo\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Doch nicht altpolnisch, nicht die Art der edlen Herrn.", "tokens": ["Doch", "nicht", "alt\u00b7pol\u00b7nisch", ",", "nicht", "die", "Art", "der", "ed\u00b7len", "Herrn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "$,", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Artigkeit schuldet man Jedem, doch Jedem auf andre Art,", "tokens": ["Ar\u00b7tig\u00b7keit", "schul\u00b7det", "man", "Je\u00b7dem", ",", "doch", "Je\u00b7dem", "auf", "and\u00b7re", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "PIAT", "$,", "ADV", "PIAT", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+--+--+-+", "measure": "diphilius"}, "line.35": {"text": "Denn Kindesliebe mu\u00df auch sein mit Artigkeit gepaart,", "tokens": ["Denn", "Kin\u00b7des\u00b7lie\u00b7be", "mu\u00df", "auch", "sein", "mit", "Ar\u00b7tig\u00b7keit", "ge\u00b7paart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "PPOSAT", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.36": {"text": "Auch das Verhalten des Mannes zum Weibe \u2013 vor der Welt, \u2013", "tokens": ["Auch", "das", "Ver\u00b7hal\u00b7ten", "des", "Man\u00b7nes", "zum", "Wei\u00b7be", "\u2013", "vor", "der", "Welt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "APPRART", "NN", "$(", "APPR", "ART", "NN", "$,", "$("], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.37": {"text": "Des Herrn zur Dienerschaft: und nirgends ist's gleich bestellt.", "tokens": ["Des", "Herrn", "zur", "Die\u00b7ner\u00b7schaft", ":", "und", "nir\u00b7gends", "ist's", "gleich", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "KON", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Da mu\u00df man lange lernen, um wirklich nie zu fehlen", "tokens": ["Da", "mu\u00df", "man", "lan\u00b7ge", "ler\u00b7nen", ",", "um", "wirk\u00b7lich", "nie", "zu", "feh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "VVINF", "$,", "KOUI", "ADJD", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.39": {"text": "Und Jedem die schuldige Achtung richtig zuzuw\u00e4h len. \u2013", "tokens": ["Und", "Je\u00b7dem", "die", "schul\u00b7di\u00b7ge", "Ach\u00b7tung", "rich\u00b7tig", "zu\u00b7zu\u00b7w\u00e4h", "len", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.40": {"text": "Die polnische Zeitgeschichte \u2013 die Schlachta redete gern", "tokens": ["Die", "pol\u00b7ni\u00b7sche", "Zeit\u00b7ge\u00b7schich\u00b7te", "\u2013", "die", "Schlach\u00b7ta", "re\u00b7de\u00b7te", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VVFIN", "ADV"], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.41": {"text": "Von Allem, was im engeren Bezirk geschehen;", "tokens": ["Von", "Al\u00b7lem", ",", "was", "im", "en\u00b7ge\u00b7ren", "Be\u00b7zirk", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So gab man denn dem Bruder Schlachcic zu verstehen,", "tokens": ["So", "gab", "man", "denn", "dem", "Bru\u00b7der", "Schlach\u00b7cic", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Da\u00df Alles ihn kennt, ihn nicht zu \u00fcbersehen vermag;", "tokens": ["Da\u00df", "Al\u00b7les", "ihn", "kennt", ",", "ihn", "nicht", "zu", "\u00fc\u00b7ber\u00b7se\u00b7hen", "ver\u00b7mag", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Drum lie\u00df sich auch der Schlachcic nicht gehen. \u2013 Heutzutag,", "tokens": ["Drum", "lie\u00df", "sich", "auch", "der", "Schlach\u00b7cic", "nicht", "ge\u00b7hen", ".", "\u2013", "Heut\u00b7zu\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$.", "$(", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "Heut' fr\u00e4gt man Keinen: wer bist du? welcher Eltern Sohn?", "tokens": ["Heut'", "fr\u00e4gt", "man", "Kei\u00b7nen", ":", "wer", "bist", "du", "?", "wel\u00b7cher", "El\u00b7tern", "Sohn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "$.", "PWS", "VAFIN", "PPER", "$.", "PWAT", "NN", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.46": {"text": "Mit wem hast du gelebt? Und wie? Nein, nichts davon \u2013", "tokens": ["Mit", "wem", "hast", "du", "ge\u00b7lebt", "?", "Und", "wie", "?", "Nein", ",", "nichts", "da\u00b7von", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "PPER", "VVPP", "$.", "KON", "PWAV", "$.", "PTKANT", "$,", "PIS", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ist Einer nur kein Bettler oder gar ein Spion,", "tokens": ["Ist", "Ei\u00b7ner", "nur", "kein", "Bett\u00b7ler", "o\u00b7der", "gar", "ein", "Spi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PIAT", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "So wird in jedem Haus gleich k\u00fchnlich vorgesprochen.", "tokens": ["So", "wird", "in", "je\u00b7dem", "Haus", "gleich", "k\u00fchn\u00b7lich", "vor\u00b7ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wie jener Vespasian, der nie zum Geld gerochen,", "tokens": ["Wie", "je\u00b7ner", "Ves\u00b7pa\u00b7si\u00b7an", ",", "der", "nie", "zum", "Geld", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NE", "$,", "PRELS", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.50": {"text": "Und nie nach seinem Ursprung und Wege mochte fragen:", "tokens": ["Und", "nie", "nach", "sei\u00b7nem", "Ur\u00b7sprung", "und", "We\u00b7ge", "moch\u00b7te", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.51": {"text": "So scheert man heut' sich nicht um Abkunft und Betragen;", "tokens": ["So", "scheert", "man", "heut'", "sich", "nicht", "um", "Ab\u00b7kunft", "und", "Be\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PRF", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Hat Einer Gewicht und Stempel, so gilt er in der Welt:", "tokens": ["Hat", "Ei\u00b7ner", "Ge\u00b7wicht", "und", "Stem\u00b7pel", ",", "so", "gilt", "er", "in", "der", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.53": {"text": "So sch\u00e4tzt man denn die Freunde, wie die Juden das Geld.\u00ab", "tokens": ["So", "sch\u00e4tzt", "man", "denn", "die", "Freun\u00b7de", ",", "wie", "die", "Ju\u00b7den", "das", "Geld", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.22": {"line.1": {"text": "So sprach der Richter und pr\u00fcfend blickt er umher im Kreis.", "tokens": ["So", "sprach", "der", "Rich\u00b7ter", "und", "pr\u00fc\u00b7fend", "blickt", "er", "um\u00b7her", "im", "Kreis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn ob er gel\u00e4ufig redet und mit Verstand: er wei\u00df,", "tokens": ["Denn", "ob", "er", "ge\u00b7l\u00e4u\u00b7fig", "re\u00b7det", "und", "mit", "Ver\u00b7stand", ":", "er", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "KON", "APPR", "NN", "$.", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da\u00df ungeduldig die Jugend sei in unsren Tagen,", "tokens": ["Da\u00df", "un\u00b7ge\u00b7dul\u00b7dig", "die", "Ju\u00b7gend", "sei", "in", "un\u00b7sren", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und langes Er\u00f6rtern sie langweilt, wie gut auch vorgetragen.", "tokens": ["Und", "lan\u00b7ges", "Er\u00b7\u00f6r\u00b7tern", "sie", "lang\u00b7weilt", ",", "wie", "gut", "auch", "vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Allein in tiefem Schweigen sitzen und horchen Alle.", "tokens": ["Al\u00b7lein", "in", "tie\u00b7fem", "Schwei\u00b7gen", "sit\u00b7zen", "und", "hor\u00b7chen", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Nun blickt er auf den K\u00e4mm'rer, wie das wohl ", "tokens": ["Nun", "blickt", "er", "auf", "den", "K\u00e4m\u00b7m'\u00b7rer", ",", "wie", "das", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "PDS", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der hat zwar nie mit Worten des Lobes unterbrochen,", "tokens": ["Der", "hat", "zwar", "nie", "mit", "Wor\u00b7ten", "des", "Lo\u00b7bes", "un\u00b7ter\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Doch \u00f6fter Beifall genickt, inde\u00df der Richter gesprochen.", "tokens": ["Doch", "\u00f6f\u00b7ter", "Bei\u00b7fall", "ge\u00b7nickt", ",", "in\u00b7de\u00df", "der", "Rich\u00b7ter", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Der Redner schweigt. Der K\u00e4mm'rer nickt noch immerfort;", "tokens": ["Der", "Red\u00b7ner", "schweigt", ".", "Der", "K\u00e4m\u00b7m'\u00b7rer", "nickt", "noch", "im\u00b7mer\u00b7fort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "So f\u00fcllt er denn Beider Becher und nimmt auf's Neu' das Wort:", "tokens": ["So", "f\u00fcllt", "er", "denn", "Bei\u00b7der", "Be\u00b7cher", "und", "nimmt", "auf's", "Neu'", "das", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "KON", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "\u00bbdie Artigkeit ist auch von nicht geringem Werth:", "tokens": ["\u00bb", "die", "Ar\u00b7tig\u00b7keit", "ist", "auch", "von", "nicht", "ge\u00b7rin\u00b7gem", "Werth", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "APPR", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hat Einer Andre sch\u00e4tzen gelernt, wie sich geh\u00f6rt,", "tokens": ["Hat", "Ei\u00b7ner", "And\u00b7re", "sch\u00e4t\u00b7zen", "ge\u00b7lernt", ",", "wie", "sich", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PIS", "VVINF", "VVPP", "$,", "PWAV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Nach Alter und Geburt, nach Tugend und Gebahren,", "tokens": ["Nach", "Al\u00b7ter", "und", "Ge\u00b7burt", ",", "nach", "Tu\u00b7gend", "und", "Ge\u00b7bah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So mag er auch ", "tokens": ["So", "mag", "er", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Wie wir auch bei der Wage, um unser Gewicht zu wissen,", "tokens": ["Wie", "wir", "auch", "bei", "der", "Wa\u00b7ge", ",", "um", "un\u00b7ser", "Ge\u00b7wicht", "zu", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "NN", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "---+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Ein Gegengewicht an's andre Ende setzen m\u00fcssen.", "tokens": ["Ein", "Ge\u00b7gen\u00b7ge\u00b7wicht", "an's", "and\u00b7re", "En\u00b7de", "set\u00b7zen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "VMINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Werth aber ist, ihr Herren, besonderer Beachtung,", "tokens": ["Werth", "a\u00b7ber", "ist", ",", "ihr", "Her\u00b7ren", ",", "be\u00b7son\u00b7de\u00b7rer", "Be\u00b7ach\u00b7tung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "$,", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Wie J\u00fcnglinge den Damen erweisen schuld'ge Achtung.", "tokens": ["Wie", "J\u00fcng\u00b7lin\u00b7ge", "den", "Da\u00b7men", "er\u00b7wei\u00b7sen", "schuld'\u00b7ge", "Ach\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "VVINF", "ADJA", "NN", "$."], "meter": "-+---+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Zumal wenn Gl\u00fcckesg\u00fcter und hoher Stand noch heben", "tokens": ["Zu\u00b7mal", "wenn", "Gl\u00fc\u00b7ckes\u00b7g\u00fc\u00b7ter", "und", "ho\u00b7her", "Stand", "noch", "he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NN", "KON", "ADJA", "NN", "ADV", "VVINF"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Die Tugenden und Reize, die Natur gegeben.", "tokens": ["Die", "Tu\u00b7gen\u00b7den", "und", "Rei\u00b7ze", ",", "die", "Na\u00b7tur", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da finden sich die Herzen, \u2013 da sah man sich gestalten", "tokens": ["Da", "fin\u00b7den", "sich", "die", "Her\u00b7zen", ",", "\u2013", "da", "sah", "man", "sich", "ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "$(", "ADV", "VVFIN", "PIS", "PRF", "VVPP"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und drum\u00ab \u2013 hier wandt' er rasch den Kopf zur Seite hin,", "tokens": ["Und", "drum", "\u00ab", "\u2013", "hier", "wandt'", "er", "rasch", "den", "Kopf", "zur", "Sei\u00b7te", "hin", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$(", "$(", "ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Winkt' zu Thadd\u00e4us hin\u00fcber und blickte streng' auf ihn \u2013", "tokens": ["Winkt'", "zu", "Thad\u00b7d\u00e4us", "hin\u00b7\u00fc\u00b7ber", "und", "blick\u00b7te", "streng'", "auf", "ihn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "ADV", "KON", "VVFIN", "ADV", "APPR", "PPER", "$("], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.24": {"text": "Man sah, jetzt werd' er gleich die Nutzanwendung zieh'n.", "tokens": ["Man", "sah", ",", "jetzt", "werd'", "er", "gleich", "die", "Nut\u00b7zan\u00b7wen\u00b7dung", "zieh'", "n."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PIS", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.23": {"line.1": {"text": "Da schlug der K\u00e4mm'rer klimpernd auf die goldne Dose", "tokens": ["Da", "schlug", "der", "K\u00e4m\u00b7m'\u00b7rer", "klim\u00b7pernd", "auf", "die", "gold\u00b7ne", "Do\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und sprach: \u00bbEs mag schon sein, jetzt geht es etwas lose, \u2013", "tokens": ["Und", "sprach", ":", "\u00bb", "Es", "mag", "schon", "sein", ",", "jetzt", "geht", "es", "et\u00b7was", "lo\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VMFIN", "ADV", "VAINF", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch einst, mein lieber Richter, war's schlechter noch als heut!", "tokens": ["Doch", "einst", ",", "mein", "lie\u00b7ber", "Rich\u00b7ter", ",", "wa\u00b7r's", "schlech\u00b7ter", "noch", "als", "heut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,", "VAFIN", "ADJD", "ADV", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Hat nun die neue Mode uns Alte auch erneut,", "tokens": ["Hat", "nun", "die", "neu\u00b7e", "Mo\u00b7de", "uns", "Al\u00b7te", "auch", "er\u00b7neut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PPER", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Oder ist's wirklich besser, genug, so scheint es mir. \u2013", "tokens": ["O\u00b7der", "ist's", "wirk\u00b7lich", "bes\u00b7ser", ",", "ge\u00b7nug", ",", "so", "scheint", "es", "mir", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADJD", "$,", "ADV", "$,", "ADV", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ach, ich gedenke der Tage, da die Franzosenmanier", "tokens": ["Ach", ",", "ich", "ge\u00b7den\u00b7ke", "der", "Ta\u00b7ge", ",", "da", "die", "Fran\u00b7zo\u00b7sen\u00b7ma\u00b7nier"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+--+-++-+--+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Zum ersten Mal in's Land kam. Herrchen str\u00f6mten in Schaaren", "tokens": ["Zum", "ers\u00b7ten", "Mal", "in's", "Land", "kam", ".", "Herr\u00b7chen", "str\u00f6m\u00b7ten", "in", "Schaa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aus fremden L\u00e4ndern her\u00fcber, \u00e4rger als Tataren,", "tokens": ["Aus", "frem\u00b7den", "L\u00e4n\u00b7dern", "her\u00b7\u00fc\u00b7ber", ",", "\u00e4r\u00b7ger", "als", "Ta\u00b7ta\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Die Gott und Glauben verfolgten und was uns die V\u00e4ter vermacht,", "tokens": ["Die", "Gott", "und", "Glau\u00b7ben", "ver\u00b7folg\u00b7ten", "und", "was", "uns", "die", "V\u00e4\u00b7ter", "ver\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "KON", "PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Gesetz und Recht und Sitten und selbst die alte Tracht!", "tokens": ["Ge\u00b7setz", "und", "Recht", "und", "Sit\u00b7ten", "und", "selbst", "die", "al\u00b7te", "Tracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Milchb\u00e4rte, vergilbt und n\u00e4selnd, oft auch nasenlos, \u2013", "tokens": ["Milch\u00b7b\u00e4r\u00b7te", ",", "ver\u00b7gilbt", "und", "n\u00e4\u00b7selnd", ",", "oft", "auch", "na\u00b7sen\u00b7los", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVPP", "KON", "VVPP", "$,", "ADV", "ADV", "ADJD", "$,", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Es war ein Jammer zu sehen, \u2013 die kamen und thaten gro\u00df,", "tokens": ["Es", "war", "ein", "Jam\u00b7mer", "zu", "se\u00b7hen", ",", "\u2013", "die", "ka\u00b7men", "und", "tha\u00b7ten", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,", "$(", "ART", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Hatten Brochuren in H\u00e4nden und allerlei Zeitungsbl\u00e4tter,", "tokens": ["Hat\u00b7ten", "Broc\u00b7hu\u00b7ren", "in", "H\u00e4n\u00b7den", "und", "al\u00b7ler\u00b7lei", "Zei\u00b7tungs\u00b7bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+--+--+--+-++-+-", "measure": "dactylic.tri.plus"}, "line.14": {"text": "Verk\u00fcndeten neue Moden, neue Gesetze und G\u00f6tter;", "tokens": ["Ver\u00b7k\u00fcn\u00b7de\u00b7ten", "neu\u00b7e", "Mo\u00b7den", ",", "neu\u00b7e", "Ge\u00b7set\u00b7ze", "und", "G\u00f6t\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Die Rotte nahm die Geister gefangen in kurzer Zeit;", "tokens": ["Die", "Rot\u00b7te", "nahm", "die", "Geis\u00b7ter", "ge\u00b7fan\u00b7gen", "in", "kur\u00b7zer", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Denn wenn der Herr einmal ein Volk der Strafe geweiht,", "tokens": ["Denn", "wenn", "der", "Herr", "ein\u00b7mal", "ein", "Volk", "der", "Stra\u00b7fe", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.17": {"text": "Dann pflegt er zuerst die K\u00f6pfe der B\u00fcrger zu verkehren.", "tokens": ["Dann", "pflegt", "er", "zu\u00b7erst", "die", "K\u00f6p\u00b7fe", "der", "B\u00fcr\u00b7ger", "zu", "ver\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "So wagten denn die Vern\u00fcnft'gen den Stutzern nicht zu wehren;", "tokens": ["So", "wag\u00b7ten", "denn", "die", "Ver\u00b7n\u00fcnft'\u00b7gen", "den", "Stut\u00b7zern", "nicht", "zu", "weh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Es f\u00fcrchtete sich vor ihnen das Volk, wie vor der Pest,", "tokens": ["Es", "f\u00fcrch\u00b7te\u00b7te", "sich", "vor", "ih\u00b7nen", "das", "Volk", ",", "wie", "vor", "der", "Pest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$,", "PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sa\u00df ja der Keim der Krankheit schon in den Herzen fest.", "tokens": ["Sa\u00df", "ja", "der", "Keim", "der", "Krank\u00b7heit", "schon", "in", "den", "Her\u00b7zen", "fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Man schrie wol \u00fcber die Gecken, doch that man, wie sie thaten, \u2013", "tokens": ["Man", "schrie", "wol", "\u00fc\u00b7ber", "die", "Ge\u00b7cken", ",", "doch", "that", "man", ",", "wie", "sie", "tha\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "$,", "PWAV", "PPER", "VVFIN", "$,", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Gesetz und Glauben und Sprache \u2013 Alles wurde verrathen!", "tokens": ["Ge\u00b7setz", "und", "Glau\u00b7ben", "und", "Spra\u00b7che", "\u2013", "Al\u00b7les", "wur\u00b7de", "ver\u00b7ra\u00b7then", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$(", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Es war ein Faschingspossen, voll Tollheit und voll Schmach,", "tokens": ["Es", "war", "ein", "Fa\u00b7schings\u00b7pos\u00b7sen", ",", "voll", "Toll\u00b7heit", "und", "voll", "Schmach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADJD", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Dem bald das gro\u00dfe Fasten, die Knechtschaft, folgte nach!", "tokens": ["Dem", "bald", "das", "gro\u00b7\u00dfe", "Fas\u00b7ten", ",", "die", "Knecht\u00b7schaft", ",", "folg\u00b7te", "nach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.24": {"line.1": {"text": "Wie ich aus meiner Kindheit mich zu erinnern wei\u00df,", "tokens": ["Wie", "ich", "aus", "mei\u00b7ner", "Kind\u00b7heit", "mich", "zu", "e\u00b7rin\u00b7nern", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Da kam zu meinem Vater in den Oszmianer Kreis", "tokens": ["Da", "kam", "zu", "mei\u00b7nem", "Va\u00b7ter", "in", "den", "Osz\u00b7mi\u00b7a\u00b7ner", "Kreis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Der Herr Podczaszyc", "tokens": ["Der", "Herr", "Pod\u00b7czas\u00b7zyc"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Der Erste, der in Lithau'n franz\u00f6sische Kleider getragen.", "tokens": ["Der", "Ers\u00b7te", ",", "der", "in", "Lit\u00b7hau'n", "fran\u00b7z\u00f6\u00b7si\u00b7sche", "Klei\u00b7der", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "APPR", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Als w\u00e4r's ein Wunderthier, so lief man hinter ihm her;", "tokens": ["Als", "w\u00e4r's", "ein", "Wun\u00b7der\u00b7thier", ",", "so", "lief", "man", "hin\u00b7ter", "ihm", "her", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Beneidet wurde das Haus, das da geno\u00df die Ehr',", "tokens": ["Be\u00b7nei\u00b7det", "wur\u00b7de", "das", "Haus", ",", "das", "da", "ge\u00b7no\u00df", "die", "Ehr'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das W\u00e4gelein mit den zwei R\u00e4dlein zu seh'n vor seiner Schwelle,", "tokens": ["Das", "W\u00e4\u00b7ge\u00b7lein", "mit", "den", "zwei", "R\u00e4d\u00b7lein", "zu", "seh'n", "vor", "sei\u00b7ner", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "CARD", "NN", "PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Sah man im Wagenkasten zwei H\u00fcndchen auf dem Lager,", "tokens": ["Sah", "man", "im", "Wa\u00b7gen\u00b7kas\u00b7ten", "zwei", "H\u00fcnd\u00b7chen", "auf", "dem", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "NN", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Auf dem Bock ein deutscher Kerl, als wie ein Brett, so mager,", "tokens": ["Auf", "dem", "Bock", "ein", "deut\u00b7scher", "Kerl", ",", "als", "wie", "ein", "Brett", ",", "so", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ART", "ADJA", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.10": {"text": "Mit langen, d\u00fcrren Beinen, wie die Hopfenstangen", "tokens": ["Mit", "lan\u00b7gen", ",", "d\u00fcr\u00b7ren", "Bei\u00b7nen", ",", "wie", "die", "Hop\u00b7fen\u00b7stan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit Str\u00fcmpfen daran, die Schuhe geziert mit silbernen Spangen.", "tokens": ["Mit", "Str\u00fcmp\u00b7fen", "da\u00b7ran", ",", "die", "Schu\u00b7he", "ge\u00b7ziert", "mit", "sil\u00b7ber\u00b7nen", "Span\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "$,", "ART", "NN", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-++-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Der Zopf an der Perr\u00fccke von einem Beutel gehalten \u2013", "tokens": ["Der", "Zopf", "an", "der", "Per\u00b7r\u00fc\u00b7cke", "von", "ei\u00b7nem", "Beu\u00b7tel", "ge\u00b7hal\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+--+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wie sie das seh'n: vor Lachen bersten fast die Alten;", "tokens": ["Wie", "sie", "das", "seh'n", ":", "vor", "La\u00b7chen", "bers\u00b7ten", "fast", "die", "Al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "VVINF", "$.", "APPR", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Bauersleute aber bekreuzen sich und sagen:", "tokens": ["Die", "Bau\u00b7ers\u00b7leu\u00b7te", "a\u00b7ber", "be\u00b7kreu\u00b7zen", "sich", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Der venetianische Teufel fahre im deutschen Wagen.", "tokens": ["Der", "ve\u00b7ne\u00b7ti\u00b7a\u00b7ni\u00b7sche", "Teu\u00b7fel", "fah\u00b7re", "im", "deut\u00b7schen", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+---+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Lang' aber w\u00e4r's, zu geben des Herrchens Konterfei:", "tokens": ["Lang'", "a\u00b7ber", "w\u00e4r's", ",", "zu", "ge\u00b7ben", "des", "Herr\u00b7chens", "Kon\u00b7ter\u00b7fei", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "$,", "PTKZU", "VVINF", "ART", "NN", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Uns kam er vor, wie ein Affe oder ein Papagei,", "tokens": ["Uns", "kam", "er", "vor", ",", "wie", "ein", "Af\u00b7fe", "o\u00b7der", "ein", "Pa\u00b7pa\u00b7gei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+----+-+-+--+", "measure": "iambic.penta.chol"}, "line.18": {"text": "In seiner gro\u00dfen Perr\u00fccke, die der n\u00e4rrische Tropf", "tokens": ["In", "sei\u00b7ner", "gro\u00b7\u00dfen", "Per\u00b7r\u00fc\u00b7cke", ",", "die", "der", "n\u00e4r\u00b7ri\u00b7sche", "Tropf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Dem goldnen Vlie\u00df verglich, \u2013 wir einem Weichselzopf.", "tokens": ["Dem", "gold\u00b7nen", "Vlie\u00df", "ver\u00b7glich", ",", "\u2013", "wir", "ei\u00b7nem", "Weich\u00b7sel\u00b7zopf", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "$(", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wenn damals auch Mancher f\u00fchlte, da\u00df unsre polnische Tracht", "tokens": ["Wenn", "da\u00b7mals", "auch", "Man\u00b7cher", "f\u00fchl\u00b7te", ",", "da\u00df", "uns\u00b7re", "pol\u00b7ni\u00b7sche", "Tracht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "PIS", "VVFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Viel sch\u00f6ner sei, als das Fremde, das wir nachgemacht,", "tokens": ["Viel", "sch\u00f6\u00b7ner", "sei", ",", "als", "das", "Frem\u00b7de", ",", "das", "wir", "nach\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "So schwieg er. Sonst h\u00e4tte \u203aVerrath!\u2039 geschrie'n die gr\u00fcne Schaar,", "tokens": ["So", "schwieg", "er", ".", "Sonst", "h\u00e4t\u00b7te", "\u203a", "Ver\u00b7rath", "!", "\u2039", "ge\u00b7schrie'n", "die", "gr\u00fc\u00b7ne", "Schaar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "VAFIN", "CARD", "NN", "$.", "$(", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "\u203averrath an der Cultur! Der Fortschritt in Gefahr!\u2039 \u2013", "tokens": ["\u203a", "ver\u00b7rath", "an", "der", "Cul\u00b7tur", "!", "Der", "Fort\u00b7schritt", "in", "Ge\u00b7fahr", "!", "\u2039", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "APPR", "ART", "NN", "$.", "ART", "NN", "APPR", "NN", "$.", "$(", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.24": {"text": "Also beherrschte die Narrheit die K\u00f6pfe ganz und gar.", "tokens": ["Al\u00b7so", "be\u00b7herrschte", "die", "Nar\u00b7rheit", "die", "K\u00f6p\u00b7fe", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "KON", "ADV", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.25": {"line.1": {"text": "Der Ank\u00f6mmling versprach, er wolle uns reformiren,", "tokens": ["Der", "An\u00b7k\u00f6mm\u00b7ling", "ver\u00b7sprach", ",", "er", "wol\u00b7le", "uns", "re\u00b7for\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Uns konstituiren und civilisiren \u2013", "tokens": ["Uns", "kons\u00b7ti\u00b7tu\u00b7i\u00b7ren", "und", "ci\u00b7vi\u00b7li\u00b7si\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Erkl\u00e4rt' uns, da\u00df welche Redner im Franzosenreich", "tokens": ["Er\u00b7kl\u00e4rt'", "uns", ",", "da\u00df", "wel\u00b7che", "Red\u00b7ner", "im", "Fran\u00b7zo\u00b7sen\u00b7reich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PWAT", "NN", "APPRART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die neue Erfindung gemacht: die Menschen w\u00e4ren gleich.", "tokens": ["Die", "neu\u00b7e", "Er\u00b7fin\u00b7dung", "ge\u00b7macht", ":", "die", "Men\u00b7schen", "w\u00e4\u00b7ren", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wiewohl doch diesen Punkt die Bibel l\u00e4ngst erledigt,", "tokens": ["Wie\u00b7wohl", "doch", "die\u00b7sen", "Punkt", "die", "Bi\u00b7bel", "l\u00e4ngst", "er\u00b7le\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDAT", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und jeder Geistliche das von der Kanzel predigt.", "tokens": ["Und", "je\u00b7der", "Geist\u00b7li\u00b7che", "das", "von", "der", "Kan\u00b7zel", "pre\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Satz war alt; es galt nur, da\u00df man ihn erf\u00fcllt!", "tokens": ["Der", "Satz", "war", "alt", ";", "es", "galt", "nur", ",", "da\u00df", "man", "ihn", "er\u00b7f\u00fcllt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "ADV", "$,", "KOUS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch damals hat alle K\u00f6pfe solche Blindheit umh\u00fcllt,", "tokens": ["Doch", "da\u00b7mals", "hat", "al\u00b7le", "K\u00f6p\u00b7fe", "sol\u00b7che", "Blind\u00b7heit", "um\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Da\u00df selbst die \u00e4lteste Sache keinen Glauben fand,", "tokens": ["Da\u00df", "selbst", "die", "\u00e4l\u00b7tes\u00b7te", "Sa\u00b7che", "kei\u00b7nen", "Glau\u00b7ben", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wenn's in franz\u00f6sischen Bl\u00e4ttern nicht zu lesen stand.", "tokens": ["Wenn's", "in", "fran\u00b7z\u00f6\u00b7si\u00b7schen", "Bl\u00e4t\u00b7tern", "nicht", "zu", "le\u00b7sen", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df sich der Herr Podczaszyc Marquis benennen lie\u00df,", "tokens": ["Da\u00df", "sich", "der", "Herr", "Pod\u00b7czas\u00b7zyc", "Mar\u00b7quis", "be\u00b7nen\u00b7nen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "NE", "NE", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Verschlug nicht gegen die Gleichheit. Die Titel sind aus Paris \u2013", "tokens": ["Ver\u00b7schlug", "nicht", "ge\u00b7gen", "die", "Gleich\u00b7heit", ".", "Die", "Ti\u00b7tel", "sind", "aus", "Pa\u00b7ris", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "APPR", "NE", "$("], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Und damals waren sie dort modern, die \u203aHerrn Marquis.\u2039", "tokens": ["Und", "da\u00b7mals", "wa\u00b7ren", "sie", "dort", "mo\u00b7dern", ",", "die", "\u203a", "Herrn", "Mar\u00b7quis", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,", "ART", "ADJA", "NN", "NE", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Als aber sp\u00e4ter die Mode in andre Geleise trat,", "tokens": ["Als", "a\u00b7ber", "sp\u00e4\u00b7ter", "die", "Mo\u00b7de", "in", "and\u00b7re", "Ge\u00b7lei\u00b7se", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Da f\u00fchrte derselbe Marquis den Titel Demokrat;", "tokens": ["Da", "f\u00fchr\u00b7te", "der\u00b7sel\u00b7be", "Mar\u00b7quis", "den", "Ti\u00b7tel", "De\u00b7mo\u00b7krat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ART", "NN", "NN", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Zuletzt, bei der neuen Mode, unter Napoleon,", "tokens": ["Zu\u00b7letzt", ",", "bei", "der", "neu\u00b7en", "Mo\u00b7de", ",", "un\u00b7ter", "Na\u00b7po\u00b7le\u00b7on", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "NE", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Kam unser Demokrat zur\u00fcck aus Paris: als Baron;", "tokens": ["Kam", "un\u00b7ser", "De\u00b7mo\u00b7krat", "zu\u00b7r\u00fcck", "aus", "Pa\u00b7ris", ":", "als", "Ba\u00b7ron", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "APPR", "NE", "$.", "KOUS", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Vielleicht, im Lauf der Zeit, h\u00e4tt' sich bei l\u00e4ng'rem Leben", "tokens": ["Viel\u00b7leicht", ",", "im", "Lauf", "der", "Zeit", ",", "h\u00e4tt'", "sich", "bei", "l\u00e4ng'\u00b7rem", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "APPRART", "NN", "ART", "NN", "$,", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Paris lebt ja am liebsten nach immer neuem Schnitt,", "tokens": ["Pa\u00b7ris", "lebt", "ja", "am", "liebs\u00b7ten", "nach", "im\u00b7mer", "neu\u00b7em", "Schnitt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKA", "ADJD", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Und was der Franzmann aufbringt, das macht der Pole mit.", "tokens": ["Und", "was", "der", "Franz\u00b7mann", "auf\u00b7bringt", ",", "das", "macht", "der", "Po\u00b7le", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.26": {"line.1": {"text": "Gottlob, da\u00df wenn die Jugend jetzt in's Ausland zieht,", "tokens": ["Gott\u00b7lob", ",", "da\u00df", "wenn", "die", "Ju\u00b7gend", "jetzt", "in's", "Aus\u00b7land", "zieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "KOUS", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es nicht mehr so, wie fr\u00fcher, der Kleider wegen geschieht, \u2013", "tokens": ["Es", "nicht", "mehr", "so", ",", "wie", "fr\u00fc\u00b7her", ",", "der", "Klei\u00b7der", "we\u00b7gen", "ge\u00b7schieht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "$,", "PWAV", "ADJD", "$,", "ART", "NN", "APPR", "VVFIN", "$,", "$("], "meter": "--+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Nicht um in gedrucktem Kram nach neuen Gesetzen zu sp\u00fcren,", "tokens": ["Nicht", "um", "in", "ge\u00b7druck\u00b7tem", "Kram", "nach", "neu\u00b7en", "Ge\u00b7set\u00b7zen", "zu", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUI", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Oder Beredtsamkeit im Caf\u00e9 zu studiren.", "tokens": ["O\u00b7der", "Be\u00b7redt\u00b7sam\u00b7keit", "im", "Ca\u00b7f\u00e9", "zu", "stu\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Denn der Napoleon, ein energischer Mann und gescheidt,", "tokens": ["Denn", "der", "Na\u00b7po\u00b7le\u00b7on", ",", "ein", "e\u00b7ner\u00b7gi\u00b7scher", "Mann", "und", "ge\u00b7scheidt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "$,", "ART", "ADJA", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.6": {"text": "Der l\u00e4\u00dft f\u00fcr Plaudereien und Moden keine Zeit;", "tokens": ["Der", "l\u00e4\u00dft", "f\u00fcr", "Plau\u00b7de\u00b7rei\u00b7en", "und", "Mo\u00b7den", "kei\u00b7ne", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NE", "KON", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Jetzt dr\u00f6hnen die Waffen; da schwillt uns alten Leuten das Herz,", "tokens": ["Jetzt", "dr\u00f6h\u00b7nen", "die", "Waf\u00b7fen", ";", "da", "schwillt", "uns", "al\u00b7ten", "Leu\u00b7ten", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+--+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Da\u00df wieder man von den Polen h\u00f6rt reden allerw\u00e4rts.", "tokens": ["Da\u00df", "wie\u00b7der", "man", "von", "den", "Po\u00b7len", "h\u00f6rt", "re\u00b7den", "al\u00b7ler\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "ART", "NN", "VVFIN", "VVFIN", "ADV", "$."], "meter": "-+----+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Ruhm ist da \u2013 so ist auch die Republik nicht fern!", "tokens": ["Der", "Ruhm", "ist", "da", "\u2013", "so", "ist", "auch", "die", "Re\u00b7pub\u00b7lik", "nicht", "fern", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$(", "ADV", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der Baum der Freiheit sprie\u00dft ja aus dem Lorbeer gern; \u2013", "tokens": ["Der", "Baum", "der", "Frei\u00b7heit", "sprie\u00dft", "ja", "aus", "dem", "Lor\u00b7beer", "gern", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nur traurig, da\u00df sich uns so ohne Th\u00e4tigkeit", "tokens": ["Nur", "trau\u00b7rig", ",", "da\u00df", "sich", "uns", "so", "oh\u00b7ne", "Th\u00e4\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PRF", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Jahre schleppen! Und Jene so ferne allezeit, \u2013", "tokens": ["Die", "Jah\u00b7re", "schlep\u00b7pen", "!", "Und", "Je\u00b7ne", "so", "fer\u00b7ne", "al\u00b7le\u00b7zeit", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "KON", "PDS", "ADV", "ADV", "ADV", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "So lange warten! Und selten kommt eine Nachricht sogar!", "tokens": ["So", "lan\u00b7ge", "war\u00b7ten", "!", "Und", "sel\u00b7ten", "kommt", "ei\u00b7ne", "Nach\u00b7richt", "so\u00b7gar", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "KON", "ADJD", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "H\u00f6rt,\u00ab \u2013 sprach er leise zum M\u00f6nch, \u2013 \u00bbh\u00f6rt, Pater Robak, ist's wahr,", "tokens": ["H\u00f6rt", ",", "\u00ab", "\u2013", "sprach", "er", "lei\u00b7se", "zum", "M\u00f6nch", ",", "\u2013", "\u00bb", "h\u00f6rt", ",", "Pa\u00b7ter", "Ro\u00b7bak", ",", "ist's", "wahr", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "$(", "$(", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,", "$(", "$(", "VVFIN", "$,", "NN", "NE", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+----+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Da\u00df ihr von jenseits des Niemen Briefe habt bekommen?", "tokens": ["Da\u00df", "ihr", "von", "jen\u00b7seits", "des", "Nie\u00b7men", "Brie\u00b7fe", "habt", "be\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "APPR", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Habt ihr nicht etwas auch von unsrem Heer vernommen?\u00ab", "tokens": ["Habt", "ihr", "nicht", "et\u00b7was", "auch", "von", "uns\u00b7rem", "Heer", "ver\u00b7nom\u00b7men", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u00bbgar nichts,\u00ab warf k\u00fchlen Tons der Bernhardiner hin,", "tokens": ["\u00bb", "gar", "nichts", ",", "\u00ab", "warf", "k\u00fch\u00b7len", "Tons", "der", "Bern\u00b7har\u00b7di\u00b7ner", "hin", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$,", "$(", "VVFIN", "ADJA", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Das ganze Gespr\u00e4ch war sichtlich nicht nach seinem Sinn \u2013", "tokens": ["Das", "gan\u00b7ze", "Ge\u00b7spr\u00e4ch", "war", "sicht\u00b7lich", "nicht", "nach", "sei\u00b7nem", "Sinn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "\u00bbwas scheert's mich auch? Mich langweilt das politische Treiben;", "tokens": ["\u00bb", "was", "scheert's", "mich", "auch", "?", "Mich", "lang\u00b7weilt", "das", "po\u00b7li\u00b7ti\u00b7sche", "Trei\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Hab' ich auch was aus Warschau, so betrifft das Schreiben", "tokens": ["Hab'", "ich", "auch", "was", "aus", "Warsc\u00b7hau", ",", "so", "be\u00b7tr\u00b7ifft", "das", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PRELS", "APPR", "NE", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.21": {"text": "Nur Ordenssachen. Wer f\u00e4ngt davon beim Nachtmahl an?", "tokens": ["Nur", "Or\u00b7dens\u00b7sa\u00b7chen", ".", "Wer", "f\u00e4ngt", "da\u00b7von", "beim", "Nacht\u00b7mahl", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$.", "PWS", "VVFIN", "PAV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Hier giebt es Laien, f\u00fcr die das nicht geh\u00f6ren kann.\u00ab", "tokens": ["Hier", "giebt", "es", "Lai\u00b7en", ",", "f\u00fcr", "die", "das", "nicht", "ge\u00b7h\u00f6\u00b7ren", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "APPR", "PRELS", "PDS", "PTKNEG", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.27": {"line.1": {"text": "So sprach der M\u00f6nch und schielte zur Seite bei dem Wort.", "tokens": ["So", "sprach", "der", "M\u00f6nch", "und", "schiel\u00b7te", "zur", "Sei\u00b7te", "bei", "dem", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Russe, der Hauptmann Rykow, sa\u00df unter den G\u00e4sten dort,", "tokens": ["Ein", "Rus\u00b7se", ",", "der", "Haupt\u00b7mann", "Ry\u00b7kow", ",", "sa\u00df", "un\u00b7ter", "den", "G\u00e4s\u00b7ten", "dort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NE", "$,", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein alter Kriegsmann, im nahen D\u00f6rfchen einquartiert,", "tokens": ["Ein", "al\u00b7ter", "Kriegs\u00b7mann", ",", "im", "na\u00b7hen", "D\u00f6rf\u00b7chen", "ein\u00b7quar\u00b7tiert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Aus H\u00f6flichkeit geladen. Der hatte nur wenig gesp\u00fcrt", "tokens": ["Aus", "H\u00f6f\u00b7lich\u00b7keit", "ge\u00b7la\u00b7den", ".", "Der", "hat\u00b7te", "nur", "we\u00b7nig", "ge\u00b7sp\u00fcrt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$.", "PDS", "VAFIN", "ADV", "PIS", "VVPP"], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Von allen den Reden; in's Essen war er versunken tief.", "tokens": ["Von", "al\u00b7len", "den", "Re\u00b7den", ";", "in's", "Es\u00b7sen", "war", "er", "ver\u00b7sun\u00b7ken", "tief", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$.", "APPRART", "NN", "VAFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Doch nun er von Warschau h\u00f6rte, erhob er den Kopf und rief:", "tokens": ["Doch", "nun", "er", "von", "Warsc\u00b7hau", "h\u00f6r\u00b7te", ",", "er\u00b7hob", "er", "den", "Kopf", "und", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "APPR", "NE", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "\u00bbherr K\u00e4mmerer! O, ihr! Ihr wollt nur allerhand", "tokens": ["\u00bb", "herr", "K\u00e4m\u00b7me\u00b7rer", "!", "O", ",", "ihr", "!", "Ihr", "wollt", "nur", "al\u00b7ler\u00b7hand"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "NN", "$.", "NE", "$,", "PPER", "$.", "PPER", "VMFIN", "ADV", "PIAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Von Bonaparte! von Warschau! Ja, das Vaterland!", "tokens": ["Von", "Bo\u00b7na\u00b7par\u00b7te", "!", "von", "Warsc\u00b7hau", "!", "Ja", ",", "das", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "APPR", "NE", "$.", "PTKANT", "$,", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Ich bin kein Spion \u2013 kann polnisch kann Das wohl versteh'n,", "tokens": ["Ich", "bin", "kein", "Spi\u00b7on", "\u2013", "kann", "pol\u00b7nisch", "kann", "Das", "wohl", "ver\u00b7steh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$(", "VMFIN", "ADJD", "VMFIN", "PDS", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Ja, Vaterland! ja wohl! kann mir zu Herzen geh'n!", "tokens": ["Ja", ",", "Va\u00b7ter\u00b7land", "!", "ja", "wohl", "!", "kann", "mir", "zu", "Her\u00b7zen", "geh'n", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "ADV", "ADV", "$.", "VMFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Jetzt ist ja Waffenstillstand, drum br\u00fcderlich essen, saufen!", "tokens": ["Jetzt", "ist", "ja", "Waf\u00b7fen\u00b7still\u00b7stand", ",", "drum", "br\u00fc\u00b7der\u00b7lich", "es\u00b7sen", ",", "sau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "$,", "PAV", "ADJD", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Thun oft so mit dem Franzmann auf den Posten schwatzen,", "tokens": ["Thun", "oft", "so", "mit", "dem", "Franz\u00b7mann", "auf", "den", "Pos\u00b7ten", "schwat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Schnaps trinken, \u2013 dann hei\u00dft's: Hurrah! und die Kart\u00e4tschen platzen.", "tokens": ["Schnaps", "trin\u00b7ken", ",", "\u2013", "dann", "hei\u00dft's", ":", "Hur\u00b7rah", "!", "und", "die", "Kar\u00b7t\u00e4t\u00b7schen", "plat\u00b7zen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "$(", "ADV", "NE", "$.", "NN", "$.", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Ein russisches Sprichwort: Geliebt, geklopft! \u2013 wie mit den Frauen:", "tokens": ["Ein", "rus\u00b7si\u00b7sches", "Sprich\u00b7wort", ":", "Ge\u00b7liebt", ",", "ge\u00b7klopft", "!", "\u2013", "wie", "mit", "den", "Frau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVPP", "$,", "VVPP", "$.", "$(", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Gestreichelt, wie mit der Pl\u00e4tte, wie einen Pelz gehauen!", "tokens": ["Ge\u00b7strei\u00b7chelt", ",", "wie", "mit", "der", "Pl\u00e4t\u00b7te", ",", "wie", "ei\u00b7nen", "Pelz", "ge\u00b7hau\u00b7en", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Ich sag': 'S wird Krieg! \u2013 Vorgestern kam die Ordre herab,", "tokens": ["Ich", "sag'", ":", "'s", "wird", "Krieg", "!", "\u2013", "Vor\u00b7ges\u00b7tern", "kam", "die", "Ord\u00b7re", "her\u00b7ab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "VAFIN", "NN", "$.", "$(", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Es brachte sie dem Major der Adjutant vom Stab:", "tokens": ["Es", "brach\u00b7te", "sie", "dem", "Ma\u00b7jor", "der", "Ad\u00b7ju\u00b7tant", "vom", "Stab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NE", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Marschfertig stehen! Gilt's nun dem T\u00fcrken oder Franzen; \u2013", "tokens": ["Marschfer\u00b7tig", "ste\u00b7hen", "!", "Gilt's", "nun", "dem", "T\u00fcr\u00b7ken", "o\u00b7der", "Fran\u00b7zen", ";", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVINF", "$.", "NE", "ADV", "ART", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "He! dieser Bonaparte! der k\u00f6nnt' uns kuranzen!", "tokens": ["He", "!", "die\u00b7ser", "Bo\u00b7na\u00b7par\u00b7te", "!", "der", "k\u00f6nnt'", "uns", "ku\u00b7ran\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PDAT", "NN", "$.", "ART", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ohne Suwarow n\u00e4hm's vielleicht ein b\u00f6ses End'; \u2013", "tokens": ["Oh\u00b7ne", "Su\u00b7wa\u00b7row", "n\u00e4hm's", "viel\u00b7leicht", "ein", "b\u00f6\u00b7ses", "End'", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.21": {"text": "Wie's mit dem Franzmann losging, da hie\u00df es im Regiment:", "tokens": ["Wie's", "mit", "dem", "Franz\u00b7mann", "los\u00b7ging", ",", "da", "hie\u00df", "es", "im", "Re\u00b7gi\u00b7ment", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+--+-+--+--+-+", "measure": "iambic.hexa.invert"}, "line.22": {"text": "Der Bonaparte hext.", "tokens": ["Der", "Bo\u00b7na\u00b7par\u00b7te", "hext", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Denn Suwarow hext auch. Einst, in der Schlacht, verschwand er:", "tokens": ["Denn", "Su\u00b7wa\u00b7row", "hext", "auch", ".", "Einst", ",", "in", "der", "Schlacht", ",", "ver\u00b7schwand", "er", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "$.", "ADV", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Wohin? Sucht Bonaparten; nun aber ging's euch bunt,", "tokens": ["Wo\u00b7hin", "?", "Sucht", "Bo\u00b7na\u00b7par\u00b7ten", ";", "nun", "a\u00b7ber", "ging's", "euch", "bunt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "NN", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Der Franzmann wird zum Fuchs \u2013 und Suwarow zum Hund,", "tokens": ["Der", "Franz\u00b7mann", "wird", "zum", "Fuchs", "\u2013", "und", "Su\u00b7wa\u00b7row", "zum", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NE", "$(", "KON", "NE", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Drauf Bonaparte zum Kater und kratzt' euch mit den Krallen \u2013", "tokens": ["Drauf", "Bo\u00b7na\u00b7par\u00b7te", "zum", "Ka\u00b7ter", "und", "kratzt'", "euch", "mit", "den", "Kral\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "APPRART", "NN", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und Suwarow zum Fohlen. \u2013 Was weiter vorgefallen,", "tokens": ["Und", "Su\u00b7wa\u00b7row", "zum", "Foh\u00b7len", ".", "\u2013", "Was", "wei\u00b7ter", "vor\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "$.", "$(", "PWS", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Mit unsern Hexenmeistern \u2013 nun, da gebt nur Acht \u2013\u00ab", "tokens": ["Mit", "un\u00b7sern", "He\u00b7xen\u00b7meis\u00b7tern", "\u2013", "nun", ",", "da", "gebt", "nur", "Acht", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "$,", "ADV", "VVFIN", "ADV", "CARD", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hier schwieg er und a\u00df. Es wurde der vierte Gang gebracht,", "tokens": ["Hier", "schwieg", "er", "und", "a\u00df", ".", "Es", "wur\u00b7de", "der", "vier\u00b7te", "Gang", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Als pl\u00f6tzlich die Seitenth\u00fcre rasch ward aufgemacht.", "tokens": ["Als", "pl\u00f6tz\u00b7lich", "die", "Sei\u00b7tent\u00b7h\u00fc\u00b7re", "rasch", "ward", "auf\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.28": {"line.1": {"text": "Eintrat ein weiblich Wesen, jung und wohlgestaltet;", "tokens": ["Ein\u00b7trat", "ein", "weib\u00b7lich", "We\u00b7sen", ",", "jung", "und", "wohl\u00b7ge\u00b7stal\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr pl\u00f6tzlich Kommen, ihr Reiz, der Putz, den sie entfaltet,", "tokens": ["Ihr", "pl\u00f6tz\u00b7lich", "Kom\u00b7men", ",", "ihr", "Reiz", ",", "der", "Putz", ",", "den", "sie", "ent\u00b7fal\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Lenkt Aller Blick auf sie; man hei\u00dft sie froh willkommen,", "tokens": ["Lenkt", "Al\u00b7ler", "Blick", "auf", "sie", ";", "man", "hei\u00dft", "sie", "froh", "will\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Offenbar kennen sie Alle, Thadd\u00e4us ausgenommen; \u2013", "tokens": ["Of\u00b7fen\u00b7bar", "ken\u00b7nen", "sie", "Al\u00b7le", ",", "Thad\u00b7d\u00e4us", "aus\u00b7ge\u00b7nom\u00b7men", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PIS", "$,", "NE", "VVPP", "$.", "$("], "meter": "+-----+-+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Von schwerem rosafarbnem Seidengewand umflossen", "tokens": ["Von", "schwe\u00b7rem", "ro\u00b7sa\u00b7farb\u00b7nem", "Sei\u00b7den\u00b7ge\u00b7wand", "um\u00b7flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der schlanke Leib, der Hals von Spitzen rund umschlossen;", "tokens": ["Der", "schlan\u00b7ke", "Leib", ",", "der", "Hals", "von", "Spit\u00b7zen", "rund", "um\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Krause ausgeschnitten an der holden Brust,", "tokens": ["Die", "Krau\u00b7se", "aus\u00b7ge\u00b7schnit\u00b7ten", "an", "der", "hol\u00b7den", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die \u00c4rmel kurz, \u2013 den F\u00e4cher h\u00e4lt sie nur zur Lust,", "tokens": ["Die", "\u00c4r\u00b7mel", "kurz", ",", "\u2013", "den", "F\u00e4\u00b7cher", "h\u00e4lt", "sie", "nur", "zur", "Lust", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "$(", "ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es ist ja gar nicht hei\u00df \u2013 der F\u00e4cher, mit Gold belegt,", "tokens": ["Es", "ist", "ja", "gar", "nicht", "hei\u00df", "\u2013", "der", "F\u00e4\u00b7cher", ",", "mit", "Gold", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "ADJD", "$(", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Spr\u00fcht Funken rings umher, wie sie ihn spielend bewegt.", "tokens": ["Spr\u00fcht", "Fun\u00b7ken", "rings", "um\u00b7her", ",", "wie", "sie", "ihn", "spie\u00b7lend", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PTKVZ", "$,", "PWAV", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Der Kopf, wie ein Haubenstock: das Haar in Locken gebunden,", "tokens": ["Der", "Kopf", ",", "wie", "ein", "Hau\u00b7ben\u00b7stock", ":", "das", "Haar", "in", "Lo\u00b7cken", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "$.", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Von rosafarbnen B\u00e4ndern \u00fcberall durchwunden \u2013", "tokens": ["Von", "ro\u00b7sa\u00b7farb\u00b7nen", "B\u00e4n\u00b7dern", "\u00fc\u00b7be\u00b7rall", "durch\u00b7wun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Inmitten, dem Aug' zur Folie, gl\u00e4nzt ein Edelstein,", "tokens": ["In\u00b7mit\u00b7ten", ",", "dem", "Aug'", "zur", "Fo\u00b7lie", ",", "gl\u00e4nzt", "ein", "E\u00b7del\u00b7stein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie im Kometenschweife eines Sternes Schein.", "tokens": ["Wie", "im", "Ko\u00b7me\u00b7ten\u00b7schwei\u00b7fe", "ei\u00b7nes", "Ster\u00b7nes", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kurz, eine Galatracht; und Manche fl\u00fcstern still,", "tokens": ["Kurz", ",", "ei\u00b7ne", "Ga\u00b7la\u00b7tracht", ";", "und", "Man\u00b7che", "fl\u00fcs\u00b7tern", "still", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "$.", "KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das Kleid ist kurz, und doch entdeckt man die F\u00fc\u00dfchen schwer \u2013", "tokens": ["Das", "Kleid", "ist", "kurz", ",", "und", "doch", "ent\u00b7deckt", "man", "die", "F\u00fc\u00df\u00b7chen", "schwer", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KON", "ADV", "VVFIN", "PIS", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Wie sie so schnell dahinl\u00e4uft oder sich schiebt vielmehr,", "tokens": ["Wie", "sie", "so", "schnell", "da\u00b7hin\u00b7l\u00e4uft", "o\u00b7der", "sich", "schiebt", "viel\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVFIN", "KON", "PRF", "VVFIN", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Gleich den Pers\u00f6nchen, die man am Dreik\u00f6nigsfest", "tokens": ["Gleich", "den", "Per\u00b7s\u00f6n\u00b7chen", ",", "die", "man", "am", "Drei\u00b7k\u00f6\u00b7nigs\u00b7fest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PIS", "APPRART", "NN"], "meter": "+-++-+-+-+-+", "measure": "unknown.measure.septa"}, "line.19": {"text": "Im Krippenspiel von versteckten Knaben schieben l\u00e4\u00dft.", "tokens": ["Im", "Krip\u00b7pen\u00b7spiel", "von", "ver\u00b7steck\u00b7ten", "Kna\u00b7ben", "schie\u00b7ben", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Mit leichtem Neigen gr\u00fc\u00dft sie im Laufen der G\u00e4ste Schaar,", "tokens": ["Mit", "leich\u00b7tem", "Nei\u00b7gen", "gr\u00fc\u00dft", "sie", "im", "Lau\u00b7fen", "der", "G\u00e4s\u00b7te", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Und will zum Sitz gelangen, der ihr bereitet war.", "tokens": ["Und", "will", "zum", "Sitz", "ge\u00b7lan\u00b7gen", ",", "der", "ihr", "be\u00b7rei\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPRART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Das war nicht leicht. Es mochte an St\u00fchlen Mangel sein,", "tokens": ["Das", "war", "nicht", "leicht", ".", "Es", "moch\u00b7te", "an", "St\u00fch\u00b7len", "Man\u00b7gel", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$.", "PPER", "VVFIN", "APPR", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "So sa\u00dfen auf vier B\u00e4nken die G\u00e4ste in vier Reih'n;", "tokens": ["So", "sa\u00b7\u00dfen", "auf", "vier", "B\u00e4n\u00b7ken", "die", "G\u00e4s\u00b7te", "in", "vier", "Reih'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "CARD", "NN", "ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Man mu\u00dfte sie st\u00f6ren, wollt' man \u00fcber die Bank nicht springen;", "tokens": ["Man", "mu\u00df\u00b7te", "sie", "st\u00f6\u00b7ren", ",", "wollt'", "man", "\u00fc\u00b7ber", "die", "Bank", "nicht", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "VMFIN", "PIS", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Sie aber wei\u00df behende zwischen die B\u00e4nke zu dringen,", "tokens": ["Sie", "a\u00b7ber", "wei\u00df", "be\u00b7hen\u00b7de", "zwi\u00b7schen", "die", "B\u00e4n\u00b7ke", "zu", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJA", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und dreht sich dann zwischen den Sitzenden und dem Tische fort,", "tokens": ["Und", "dreht", "sich", "dann", "zwi\u00b7schen", "den", "Sit\u00b7zen\u00b7den", "und", "dem", "Ti\u00b7sche", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.27": {"text": "Wie eine Billardkugel, bis zu ihrem Ort.", "tokens": ["Wie", "ei\u00b7ne", "Bil\u00b7lard\u00b7ku\u00b7gel", ",", "bis", "zu", "ih\u00b7rem", "Ort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "KOUS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und unsern J\u00fcngling ber\u00fchrt sie ganz nah' im Weiterschieben, \u2013", "tokens": ["Und", "un\u00b7sern", "J\u00fcng\u00b7ling", "be\u00b7r\u00fchrt", "sie", "ganz", "nah'", "im", "Wei\u00b7ter\u00b7schie\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$,", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Sie war mit einer Falbel an Jemand h\u00e4ngen geblieben,", "tokens": ["Sie", "war", "mit", "ei\u00b7ner", "Fal\u00b7bel", "an", "Je\u00b7mand", "h\u00e4n\u00b7gen", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "PIS", "VVINF", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und gleitet ein wenig \u2013 und ehe sie sich fassen kann,", "tokens": ["Und", "glei\u00b7tet", "ein", "we\u00b7nig", "\u2013", "und", "e\u00b7he", "sie", "sich", "fas\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIS", "$(", "KON", "KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.31": {"text": "H\u00e4lt sie sich fest am Arm des Herrn Thadd\u00e4us an.", "tokens": ["H\u00e4lt", "sie", "sich", "fest", "am", "Arm", "des", "Herrn", "Thad\u00b7d\u00e4us", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPRART", "NN", "ART", "NN", "NE", "PTKVZ", "$."], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Und nun, nachdem sie sich bei ihm entschuldigt fein,", "tokens": ["Und", "nun", ",", "nach\u00b7dem", "sie", "sich", "bei", "ihm", "ent\u00b7schul\u00b7digt", "fein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.33": {"text": "Nimmt zwischen ihm und dem Richter sie ihre Stelle ein \u2013", "tokens": ["Nimmt", "zwi\u00b7schen", "ihm", "und", "dem", "Rich\u00b7ter", "sie", "ih\u00b7re", "Stel\u00b7le", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "KON", "ART", "NN", "PPER", "PPOSAT", "NN", "ART", "$("], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch i\u00dft sie gar nichts \u2013 f\u00e4chelt sich nur ohne Ruh',", "tokens": ["Doch", "i\u00dft", "sie", "gar", "nichts", "\u2013", "f\u00e4\u00b7chelt", "sich", "nur", "oh\u00b7ne", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "$(", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Dreht an dem Heft des F\u00e4chers, \u2013 legt sich ab und zu", "tokens": ["Dreht", "an", "dem", "Heft", "des", "F\u00e4\u00b7chers", ",", "\u2013", "legt", "sich", "ab", "und", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,", "$(", "VVFIN", "PRF", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Den Spitzenkragen zurecht und streift mit leichter Hand", "tokens": ["Den", "Spit\u00b7zen\u00b7kra\u00b7gen", "zu\u00b7recht", "und", "streift", "mit", "leich\u00b7ter", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.37": {"text": "Bald \u00fcber eine Locke, bald \u00fcber ein Rosenband.", "tokens": ["Bald", "\u00fc\u00b7ber", "ei\u00b7ne", "Lo\u00b7cke", ",", "bald", "\u00fc\u00b7ber", "ein", "Ro\u00b7sen\u00b7band", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.29": {"line.1": {"text": "So war wohl vier Minuten das Reden unterbrochen.", "tokens": ["So", "war", "wohl", "vier", "Mi\u00b7nu\u00b7ten", "das", "Re\u00b7den", "un\u00b7ter\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "CARD", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Inde\u00df wird unten am Tisch, erst fl\u00fcsternd nur gesprochen,", "tokens": ["In\u00b7de\u00df", "wird", "un\u00b7ten", "am", "Tisch", ",", "erst", "fl\u00fcs\u00b7ternd", "nur", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "APPRART", "NN", "$,", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dann zwischen den M\u00e4nnern halblaut ein Gespr\u00e4ch gef\u00fchrt:", "tokens": ["Dann", "zwi\u00b7schen", "den", "M\u00e4n\u00b7nern", "hal\u00b7blaut", "ein", "Ge\u00b7spr\u00e4ch", "ge\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Es ist das heutige Jagen, das man discutirt:", "tokens": ["Es", "ist", "das", "heu\u00b7ti\u00b7ge", "Ja\u00b7gen", ",", "das", "man", "dis\u00b7cu\u00b7tirt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Notar und Assessor", "tokens": ["No\u00b7tar", "und", "As\u00b7ses\u00b7sor"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Um einen gestutzten Hund, ein Windspiel, Mutz genannt;", "tokens": ["Um", "ei\u00b7nen", "ge\u00b7stutz\u00b7ten", "Hund", ",", "ein", "Wind\u00b7spiel", ",", "Mutz", "ge\u00b7nannt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das der Notar mit Stolz sein theures Eigen hei\u00dft,", "tokens": ["Das", "der", "No\u00b7tar", "mit", "Stolz", "sein", "theu\u00b7res", "Ei\u00b7gen", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "APPR", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und das auch den Hasen gefangen, wie er jetzt beweist.", "tokens": ["Und", "das", "auch", "den", "Ha\u00b7sen", "ge\u00b7fan\u00b7gen", ",", "wie", "er", "jetzt", "be\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ART", "NN", "PTKVZ", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Worauf der Assessor zeigt, dem Herrn Notar zum Trutz,", "tokens": ["Wo\u00b7rauf", "der", "As\u00b7ses\u00b7sor", "zeigt", ",", "dem", "Herrn", "No\u00b7tar", "zum", "Trutz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "$,", "ART", "NN", "NN", "APPRART", "NN", "$,"], "meter": "-+----+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Dies Lob geb\u00fchre dem Falk und keineswegs dem Mutz.", "tokens": ["Dies", "Lob", "ge\u00b7b\u00fch\u00b7re", "dem", "Falk", "und", "kei\u00b7nes\u00b7wegs", "dem", "Mutz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die Anderen alle befragt, was ihre Meinung sei,", "tokens": ["Die", "An\u00b7de\u00b7ren", "al\u00b7le", "be\u00b7fragt", ",", "was", "ih\u00b7re", "Mei\u00b7nung", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIS", "VVPP", "$,", "PRELS", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Ergriffen theils f\u00fcr Mutzen, theils f\u00fcr Falken Partei,", "tokens": ["Er\u00b7grif\u00b7fen", "theils", "f\u00fcr", "Mut\u00b7zen", ",", "theils", "f\u00fcr", "Fal\u00b7ken", "Par\u00b7tei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.13": {"text": "Als Augenzeuge der, und der nach Kennersinn. \u2013", "tokens": ["Als", "Au\u00b7gen\u00b7zeu\u00b7ge", "der", ",", "und", "der", "nach", "Ken\u00b7ner\u00b7sinn", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "ART", "$,", "KON", "ART", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Halblaut der Richter: \u00bbVergieb, es war nicht zu verschieben;", "tokens": ["Hal\u00b7blaut", "der", "Rich\u00b7ter", ":", "\u00bb", "Ver\u00b7gieb", ",", "es", "war", "nicht", "zu", "ver\u00b7schie\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$(", "VVIMP", "$,", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.15": {"text": "Die G\u00e4ste hatten sich lang im Freien herumgetrieben \u2013", "tokens": ["Die", "G\u00e4s\u00b7te", "hat\u00b7ten", "sich", "lang", "im", "Frei\u00b7en", "her\u00b7um\u00b7ge\u00b7trie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADJD", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Und Alle bekamen Hunger nach dem vielen Geh'n;", "tokens": ["Und", "Al\u00b7le", "be\u00b7ka\u00b7men", "Hun\u00b7ger", "nach", "dem", "vie\u00b7len", "Geh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "NN", "APPR", "ART", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Auch dacht' ich nicht, dich heute bei uns zu Tisch zu seh'n.\u00ab", "tokens": ["Auch", "dacht'", "ich", "nicht", ",", "dich", "heu\u00b7te", "bei", "uns", "zu", "Tisch", "zu", "seh'", "n.", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "ADV", "APPR", "PPER", "APPR", "NN", "PTKZU", "VVFIN", "NE", "$("], "meter": "-+--++-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Drauf wandt' er, die Becher f\u00fcllend, zum K\u00e4mm'rer sich zur\u00fcck,", "tokens": ["Drauf", "wandt'", "er", ",", "die", "Be\u00b7cher", "f\u00fcl\u00b7lend", ",", "zum", "K\u00e4m\u00b7m'\u00b7rer", "sich", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "ART", "NN", "VVPP", "$,", "APPRART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+--++-+-+", "measure": "iambic.septa.relaxed"}, "line.19": {"text": "Und leise besprachen beide die neuste Politik.", "tokens": ["Und", "lei\u00b7se", "be\u00b7spra\u00b7chen", "bei\u00b7de", "die", "neus\u00b7te", "Po\u00b7li\u00b7tik", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.30": {"line.1": {"text": "Wie rechts und links sich so besch\u00e4ftigt Jedermann,", "tokens": ["Wie", "rechts", "und", "links", "sich", "so", "be\u00b7sch\u00e4f\u00b7tigt", "Je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "KON", "ADV", "PRF", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blickt Herr Thadd\u00e4us n\u00e4her die Unbekannte an.", "tokens": ["Blickt", "Herr", "Thad\u00b7d\u00e4us", "n\u00e4\u00b7her", "die", "Un\u00b7be\u00b7kann\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NE", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-++-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er denkt, wie er doch fr\u00fcher errathen hab' sofort,", "tokens": ["Er", "denkt", ",", "wie", "er", "doch", "fr\u00fc\u00b7her", "er\u00b7ra\u00b7then", "hab'", "so\u00b7fort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ADJD", "VVINF", "VAFIN", "ADV", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "F\u00fcr wen bestimmt gewesen der leergelass'ne Ort.", "tokens": ["F\u00fcr", "wen", "be\u00b7stimmt", "ge\u00b7we\u00b7sen", "der", "leer\u00b7ge\u00b7lass'\u00b7ne", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VVPP", "VAPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Laut klopft sein Herz \u2013 err\u00f6thend gl\u00fcht sein Wangenpaar:", "tokens": ["Laut", "klopft", "sein", "Herz", "\u2013", "er\u00b7r\u00f6\u00b7thend", "gl\u00fcht", "sein", "Wan\u00b7gen\u00b7paar", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPOSAT", "NN", "$(", "VVPP", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was er im Stillen vermuthet, so sah er's offenbar!", "tokens": ["Was", "er", "im", "Stil\u00b7len", "ver\u00b7mu\u00b7thet", ",", "so", "sah", "er's", "of\u00b7fen\u00b7bar", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.7": {"text": "So war's bestimmt, da\u00df sitzen sollt' bei ihm so traut", "tokens": ["So", "wa\u00b7r's", "be\u00b7stimmt", ",", "da\u00df", "sit\u00b7zen", "sollt'", "bei", "ihm", "so", "traut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "KOUS", "VVINF", "VMFIN", "APPR", "PPER", "ADV", "VVFIN"], "meter": "----+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Die Sch\u00f6ne, die er heut' im D\u00e4mmerlicht erschaut!", "tokens": ["Die", "Sch\u00f6\u00b7ne", ",", "die", "er", "heut'", "im", "D\u00e4m\u00b7mer\u00b7licht", "er\u00b7schaut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zwar die Gestalt \u2013 sie schien ihm schlanker jetzt zu sein:", "tokens": ["Zwar", "die", "Ge\u00b7stalt", "\u2013", "sie", "schien", "ihm", "schlan\u00b7ker", "jetzt", "zu", "sein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil sie im Anzug war, und der macht gro\u00df und klein.", "tokens": ["Weil", "sie", "im", "An\u00b7zug", "war", ",", "und", "der", "macht", "gro\u00df", "und", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "$,", "KON", "ART", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dort hatt' er kurz das Haar und goldig-hell gefunden,", "tokens": ["Dort", "hatt'", "er", "kurz", "das", "Haar", "und", "gol\u00b7dig\u00b7hell", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hier ist es rabenschwarz, in lange Locken gewunden;", "tokens": ["Hier", "ist", "es", "ra\u00b7ben\u00b7schwarz", ",", "in", "lan\u00b7ge", "Lo\u00b7cken", "ge\u00b7wun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Gewi\u00df, die Farbe kam wohl von den Sonnenstrahlen,", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "Far\u00b7be", "kam", "wohl", "von", "den", "Son\u00b7nen\u00b7strah\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die ja des Abends Alles r\u00f6thlich golden malen.", "tokens": ["Die", "ja", "des", "A\u00b7bends", "Al\u00b7les", "r\u00f6th\u00b7lich", "gol\u00b7den", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PIS", "ADJD", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht hatt' er das Antlitz geseh'n, \u2013 sie war zu rasch entschwunden \u2013", "tokens": ["Nicht", "hatt'", "er", "das", "Ant\u00b7litz", "ge\u00b7seh'n", ",", "\u2013", "sie", "war", "zu", "rasch", "ent\u00b7schwun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,", "$(", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Doch war's ein sch\u00f6nes Bildni\u00df, was sich sein Sinn erfunden;", "tokens": ["Doch", "wa\u00b7r's", "ein", "sch\u00f6\u00b7nes", "Bild\u00b7ni\u00df", ",", "was", "sich", "sein", "Sinn", "er\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PRF", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Schwarz\u00e4ugig, wei\u00df an Wangen \u2013 so stellte sich's ihm dar \u2013", "tokens": ["Schwarz\u00b7\u00e4u\u00b7gig", ",", "wei\u00df", "an", "Wan\u00b7gen", "\u2013", "so", "stell\u00b7te", "sich's", "ihm", "dar", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "APPR", "NN", "$(", "ADV", "VVFIN", "PIS", "PPER", "PTKVZ", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Die Lippen, wie ein prangend Kirschenzwillingspaar,", "tokens": ["Die", "Lip\u00b7pen", ",", "wie", "ein", "pran\u00b7gend", "Kir\u00b7schenz\u00b7wil\u00b7lings\u00b7paar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und Mund und Aug' und Wangen \u2013 hier war's, wie er gedacht.", "tokens": ["Und", "Mund", "und", "Aug'", "und", "Wan\u00b7gen", "\u2013", "hier", "wa\u00b7r's", ",", "wie", "er", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "$(", "ADV", "VAFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "Das Alter ist's, was noch am meisten denken macht:", "tokens": ["Das", "Al\u00b7ter", "ist's", ",", "was", "noch", "am", "meis\u00b7ten", "den\u00b7ken", "macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "PTKA", "PIS", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein junges M\u00e4dchen glaubt' er im Garten zu gewahren,", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", "glaubt'", "er", "im", "Gar\u00b7ten", "zu", "ge\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und diese Dame war ein Weib in reifern Jahren.", "tokens": ["Und", "die\u00b7se", "Da\u00b7me", "war", "ein", "Weib", "in", "rei\u00b7fern", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Doch Jugend fr\u00e4gt die Sch\u00f6nheit nach dem Taufschein nicht,", "tokens": ["Doch", "Ju\u00b7gend", "fr\u00e4gt", "die", "Sch\u00f6n\u00b7heit", "nach", "dem", "Tauf\u00b7schein", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Jung ist dem jungen Manne jedes Frauengesicht,", "tokens": ["Jung", "ist", "dem", "jun\u00b7gen", "Man\u00b7ne", "je\u00b7des", "Frau\u00b7en\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.25": {"text": "Gleichaltrig d\u00fcnkt dem Burschen, was nur in Sch\u00f6nheit bl\u00fcht,", "tokens": ["Gleich\u00b7alt\u00b7rig", "d\u00fcnkt", "dem", "Bur\u00b7schen", ",", "was", "nur", "in", "Sch\u00f6n\u00b7heit", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und jedes Lieb jungfr\u00e4ulich dem schuldlosen Gem\u00fcth.", "tokens": ["Und", "je\u00b7des", "Lieb", "jung\u00b7fr\u00e4u\u00b7lich", "dem", "schuld\u00b7lo\u00b7sen", "Ge\u00b7m\u00fcth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.31": {"line.1": {"text": "Thadd\u00e4us war wohl schon fast zwanzig Jahre alt,", "tokens": ["Thad\u00b7d\u00e4us", "war", "wohl", "schon", "fast", "zwan\u00b7zig", "Jah\u00b7re", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ADV", "CARD", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und Wilno, die gro\u00dfe Stadt, seit Jahren sein Aufenthalt;", "tokens": ["Und", "Wil\u00b7no", ",", "die", "gro\u00b7\u00dfe", "Stadt", ",", "seit", "Jah\u00b7ren", "sein", "Auf\u00b7ent\u00b7halt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ART", "ADJA", "NN", "$,", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gar streng erzogen worden in der V\u00e4ter Art.", "tokens": ["Gar", "streng", "er\u00b7zo\u00b7gen", "wor\u00b7den", "in", "der", "V\u00e4\u00b7ter", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So bracht' er denn nach Hause der herben Zucht Gewinn:", "tokens": ["So", "bracht'", "er", "denn", "nach", "Hau\u00b7se", "der", "her\u00b7ben", "Zucht", "Ge\u00b7winn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ein schuldlos-reines Herz und einen lebendigen Sinn;", "tokens": ["Ein", "schuld\u00b7los\u00b7rei\u00b7nes", "Herz", "und", "ei\u00b7nen", "le\u00b7ben\u00b7di\u00b7gen", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Doch auch nicht wenig Neigung, \u00fcber die Schnur zu hauen.", "tokens": ["Doch", "auch", "nicht", "we\u00b7nig", "Nei\u00b7gung", ",", "\u00fc\u00b7ber", "die", "Schnur", "zu", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "PIAT", "NN", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Im Voraus plant' er schon in fr\u00f6hlichem Selbstvertrauen:", "tokens": ["Im", "Vo\u00b7raus", "plant'", "er", "schon", "in", "fr\u00f6h\u00b7li\u00b7chem", "Selbst\u00b7ver\u00b7trau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Die langentbehrte Freiheit nun zu genie\u00dfen nach Lust;", "tokens": ["Die", "lan\u00b7gent\u00b7behr\u00b7te", "Frei\u00b7heit", "nun", "zu", "ge\u00b7nie\u00b7\u00dfen", "nach", "Lust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "APPR", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Jung war er, flink und stattlich, und war sich auch dessen bewu\u00dft:", "tokens": ["Jung", "war", "er", ",", "flink", "und", "statt\u00b7lich", ",", "und", "war", "sich", "auch", "des\u00b7sen", "be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,", "KON", "VAFIN", "PRF", "ADV", "PDS", "ADJD", "$."], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "An Kraft und Frische war er seiner Eltern Kind \u2013", "tokens": ["An", "Kraft", "und", "Fri\u00b7sche", "war", "er", "sei\u00b7ner", "El\u00b7tern", "Kind", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er hie\u00df Soplica, \u2013 und alle die Soplica's sind", "tokens": ["Er", "hie\u00df", "Sop\u00b7li\u00b7ca", ",", "\u2013", "und", "al\u00b7le", "die", "Sop\u00b7li\u00b7ca's", "sind"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "$,", "$(", "KON", "PIS", "ART", "NE", "VAFIN"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Bekanntlich gut bei Leibe und voll gesunder Kraft,", "tokens": ["Be\u00b7kannt\u00b7lich", "gut", "bei", "Lei\u00b7be", "und", "voll", "ge\u00b7sun\u00b7der", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Zum Waffenhandwerk einzig, nicht so zur Wissenschaft.", "tokens": ["Zum", "Waf\u00b7fen\u00b7hand\u00b7werk", "ein\u00b7zig", ",", "nicht", "so", "zur", "Wis\u00b7sen\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.32": {"line.1": {"text": "Thadd\u00e4us war in Allem der Ahnen rechter Spro\u00df.", "tokens": ["Thad\u00b7d\u00e4us", "war", "in", "Al\u00b7lem", "der", "Ah\u00b7nen", "rech\u00b7ter", "Spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PIS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Er war vortrefflich zu Fu\u00df, auch recht geschickt zu Ro\u00df;", "tokens": ["Er", "war", "vor\u00b7treff\u00b7lich", "zu", "Fu\u00df", ",", "auch", "recht", "ge\u00b7schickt", "zu", "Ro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "NN", "$,", "ADV", "ADJD", "VVPP", "APPR", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nicht dumm, jedoch im Wissen nicht gar weit gedieh'n \u2013", "tokens": ["Nicht", "dumm", ",", "je\u00b7doch", "im", "Wis\u00b7sen", "nicht", "gar", "weit", "ge\u00b7dieh'n", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADV", "APPRART", "NN", "PTKNEG", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wiewohl der Ohm nichts sparte, ihn w\u00fcrdig zu erzieh'n \u2013", "tokens": ["Wie\u00b7wohl", "der", "Ohm", "nichts", "spar\u00b7te", ",", "ihn", "w\u00fcr\u00b7dig", "zu", "er\u00b7zieh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Er hantirte lieber mit S\u00e4bel und Schie\u00dfgewehr:", "tokens": ["Er", "han\u00b7tir\u00b7te", "lie\u00b7ber", "mit", "S\u00e4\u00b7bel", "und", "Schie\u00df\u00b7ge\u00b7wehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "Er wu\u00dfte, da\u00df man ihn bestimmt zum Milit\u00e4r,", "tokens": ["Er", "wu\u00df\u00b7te", ",", "da\u00df", "man", "ihn", "be\u00b7stimmt", "zum", "Mi\u00b7li\u00b7t\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie es sein seliger Vater im Testament gewollt \u2013", "tokens": ["Wie", "es", "sein", "se\u00b7li\u00b7ger", "Va\u00b7ter", "im", "Tes\u00b7ta\u00b7ment", "ge\u00b7wollt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "VMPP", "$("], "meter": "+-+---+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Und seufzte nach der Trommel, wenn er studiren sollt'.", "tokens": ["Und", "seufz\u00b7te", "nach", "der", "Trom\u00b7mel", ",", "wenn", "er", "stu\u00b7di\u00b7ren", "sollt'", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Doch pl\u00f6tzlich gefiel's dem Onkel, anders f\u00fcr ihn zu w\u00e4hlen,", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "ge\u00b7fiel's", "dem", "On\u00b7kel", ",", "an\u00b7ders", "f\u00fcr", "ihn", "zu", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "ART", "NN", "$,", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Er hie\u00df ihn nach Hause kommen, sich m\u00f6glichst bald verm\u00e4hlen,", "tokens": ["Er", "hie\u00df", "ihn", "nach", "Hau\u00b7se", "kom\u00b7men", ",", "sich", "m\u00f6g\u00b7lichst", "bald", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Und dann die Wirthschaft f\u00fchren; versprach, ihm als erste Gabe", "tokens": ["Und", "dann", "die", "Wirth\u00b7schaft", "f\u00fch\u00b7ren", ";", "ver\u00b7sprach", ",", "ihm", "als", "ers\u00b7te", "Ga\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVINF", "$.", "VVFIN", "$,", "PPER", "KOUS", "ADJA", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Ein kleines Gut zu geben, \u2013 dann seine ganze Habe.", "tokens": ["Ein", "klei\u00b7nes", "Gut", "zu", "ge\u00b7ben", ",", "\u2013", "dann", "sei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,", "$(", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+----+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.33": {"line.1": {"text": "All' diese Tugenden, die Herrn Thadd\u00e4us schm\u00fccken,", "tokens": ["All'", "die\u00b7se", "Tu\u00b7gen\u00b7den", ",", "die", "Herrn", "Thad\u00b7d\u00e4us", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,", "ART", "NN", "NE", "VVINF", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Bemerkt die Nachbarin, ein Weib von scharfen Blicken, \u2013", "tokens": ["Be\u00b7merkt", "die", "Nach\u00b7ba\u00b7rin", ",", "ein", "Weib", "von", "schar\u00b7fen", "Bli\u00b7cken", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die hohe, sch\u00f6ne Gestalt betrachtet sie mit Lust,", "tokens": ["Die", "ho\u00b7he", ",", "sch\u00f6\u00b7ne", "Ge\u00b7stalt", "be\u00b7trach\u00b7tet", "sie", "mit", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die kraftgeschwellten Arme, die m\u00e4nnlich-breite Brust, \u2013", "tokens": ["Die", "kraft\u00b7ge\u00b7schwell\u00b7ten", "Ar\u00b7me", ",", "die", "m\u00e4nn\u00b7lich\u00b7brei\u00b7te", "Brust", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Die Wangen auch, die immer ergl\u00fch'n in rothen Flammen,", "tokens": ["Die", "Wan\u00b7gen", "auch", ",", "die", "im\u00b7mer", "er\u00b7gl\u00fch'n", "in", "ro\u00b7then", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+---+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "So oft mit ihrem Blick der seine trifft zusammen;", "tokens": ["So", "oft", "mit", "ih\u00b7rem", "Blick", "der", "sei\u00b7ne", "trifft", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "ART", "PPOSAT", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn seine Bl\u00f6digkeit war nun verschwunden ganz,", "tokens": ["Denn", "sei\u00b7ne", "Bl\u00f6\u00b7dig\u00b7keit", "war", "nun", "ver\u00b7schwun\u00b7den", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "K\u00fchn blickte jetzt sein Auge, voller Glut und Glanz \u2013", "tokens": ["K\u00fchn", "blick\u00b7te", "jetzt", "sein", "Au\u00b7ge", ",", "vol\u00b7ler", "Glut", "und", "Glanz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und sie gleich ihm \u2013 und wie die Kerzen am Altare,", "tokens": ["Und", "sie", "gleich", "ihm", "\u2013", "und", "wie", "die", "Ker\u00b7zen", "am", "Al\u00b7ta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PPER", "$(", "KON", "PWAV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.10": {"text": "So gl\u00fchten gen einander zwei helle Augenpaare.", "tokens": ["So", "gl\u00fch\u00b7ten", "gen", "ein\u00b7an\u00b7der", "zwei", "hel\u00b7le", "Au\u00b7gen\u00b7paa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PRF", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.34": {"line.1": {"text": "Er kam aus der Stadt, vom Studium \u2013 weshalb sie von B\u00fcchern begann,", "tokens": ["Er", "kam", "aus", "der", "Stadt", ",", "vom", "Stu\u00b7di\u00b7um", "\u2013", "we\u00b7shalb", "sie", "von", "B\u00fc\u00b7chern", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$(", "PWAV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+---+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und was seine Meinung w\u00e4re von der und jener Erscheinung \u2013", "tokens": ["Und", "was", "sei\u00b7ne", "Mei\u00b7nung", "w\u00e4\u00b7re", "von", "der", "und", "je\u00b7ner", "Er\u00b7schei\u00b7nung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VAFIN", "APPR", "ART", "KON", "PDAT", "NN", "$("], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und neue Fragen erzeugte jede gegebene Meinung.", "tokens": ["Und", "neu\u00b7e", "Fra\u00b7gen", "er\u00b7zeug\u00b7te", "je\u00b7de", "ge\u00b7ge\u00b7be\u00b7ne", "Mei\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und wie sie nun gar anf\u00e4ngt von der Malerei,", "tokens": ["Und", "wie", "sie", "nun", "gar", "an\u00b7f\u00e4ngt", "von", "der", "Ma\u00b7le\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Von Tanzkunst, von Musik, ja von der Bildhauerei \u2013", "tokens": ["Von", "Tanz\u00b7kunst", ",", "von", "Mu\u00b7sik", ",", "ja", "von", "der", "Bild\u00b7hau\u00b7e\u00b7rei", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+--+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Zeigt sie in Farben und Noten und B\u00fccher sich eingeweiht,", "tokens": ["Zeigt", "sie", "in", "Far\u00b7ben", "und", "No\u00b7ten", "und", "B\u00fc\u00b7cher", "sich", "ein\u00b7ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "KON", "NN", "PRF", "VVPP", "$,"], "meter": "+--+--+--+--+-+", "measure": "diphilius"}, "line.7": {"text": "Da\u00df fast Thadd\u00e4us versteinert vor so viel Gelehrsamkeit!", "tokens": ["Da\u00df", "fast", "Thad\u00b7d\u00e4us", "ver\u00b7stei\u00b7nert", "vor", "so", "viel", "Ge\u00b7lehr\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "VVFIN", "APPR", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "Er f\u00fcrchtet, Schand' und Spott zum Schlu\u00df davonzutragen,", "tokens": ["Er", "f\u00fcrch\u00b7tet", ",", "Schand'", "und", "Spott", "zum", "Schlu\u00df", "da\u00b7von\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "KON", "NN", "APPRART", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und stottert, wie ein Schulbub vor des Lehrers Fragen.", "tokens": ["Und", "stot\u00b7tert", ",", "wie", "ein", "Schul\u00b7bub", "vor", "des", "Leh\u00b7rers", "Fra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum Gl\u00fcck ist der Lehrer h\u00fcbsch und h\u00e4lt kein streng Gericht.", "tokens": ["Zum", "Gl\u00fcck", "ist", "der", "Leh\u00b7rer", "h\u00fcbsch", "und", "h\u00e4lt", "kein", "streng", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "ADJD", "KON", "VVFIN", "PIAT", "ADJD", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die holde Nachbarin err\u00e4th, woran's gebricht,", "tokens": ["Die", "hol\u00b7de", "Nach\u00b7ba\u00b7rin", "er\u00b7r\u00e4\u00b7th", ",", "wor\u00b7an's", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und bringt die Sprache auf leicht're und minder weise Dinge:", "tokens": ["Und", "bringt", "die", "Spra\u00b7che", "auf", "leicht'\u00b7re", "und", "min\u00b7der", "wei\u00b7se", "Din\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.13": {"text": "Auf's Landleben, \u2013 wie viel Langweil' und M\u00fch'n es mit sich bringe,", "tokens": ["Auf's", "Land\u00b7le\u00b7ben", ",", "\u2013", "wie", "viel", "Lang\u00b7weil'", "und", "M\u00fch'n", "es", "mit", "sich", "brin\u00b7ge", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "$(", "KOKOM", "PIAT", "NN", "KON", "NN", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.14": {"text": "Wie man die Zeit mu\u00df n\u00fctzen, wie sich unterhalten,", "tokens": ["Wie", "man", "die", "Zeit", "mu\u00df", "n\u00fct\u00b7zen", ",", "wie", "sich", "un\u00b7ter\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VMFIN", "VVINF", "$,", "PWAV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das Leben fr\u00f6hlicher und sch\u00f6ner zu gestalten.", "tokens": ["Das", "Le\u00b7ben", "fr\u00f6h\u00b7li\u00b7cher", "und", "sch\u00f6\u00b7ner", "zu", "ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Thadd\u00e4us erwidert k\u00fchner, nun geht es glatt vom Munde:", "tokens": ["Thad\u00b7d\u00e4us", "er\u00b7wi\u00b7dert", "k\u00fch\u00b7ner", ",", "nun", "geht", "es", "glatt", "vom", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Man war auf vertrautem Fu\u00df nach einer halben Stunde,", "tokens": ["Man", "war", "auf", "ver\u00b7trau\u00b7tem", "Fu\u00df", "nach", "ei\u00b7ner", "hal\u00b7ben", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-+-+-+-", "measure": "dactylic.init"}, "line.18": {"text": "Beginnt selbst kleine Sp\u00e4\u00dfe, neckt und zankt und droht;", "tokens": ["Be\u00b7ginnt", "selbst", "klei\u00b7ne", "Sp\u00e4\u00b7\u00dfe", ",", "neckt", "und", "zankt", "und", "droht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Zum Schlu\u00df stellt sie vor ihn drei K\u00fcgelchen aus Brod,", "tokens": ["Zum", "Schlu\u00df", "stellt", "sie", "vor", "ihn", "drei", "K\u00fc\u00b7gel\u00b7chen", "aus", "Brod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "PPER", "CARD", "NN", "APPR", "NN", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.20": {"text": "Als drei Personen zur Wahl: er w\u00e4hlt die N\u00e4chste aus;", "tokens": ["Als", "drei", "Per\u00b7so\u00b7nen", "zur", "Wahl", ":", "er", "w\u00e4hlt", "die", "N\u00e4chs\u00b7te", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APPRART", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Die beiden K\u00e4mm'rerst\u00f6chter zieh'n die Stirne kraus,", "tokens": ["Die", "bei\u00b7den", "K\u00e4m\u00b7m'\u00b7rer\u00b7st\u00f6ch\u00b7ter", "zieh'n", "die", "Stir\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Die Nachbarin lacht auf, aber sie verschweigt,", "tokens": ["Die", "Nach\u00b7ba\u00b7rin", "lacht", "auf", ",", "a\u00b7ber", "sie", "ver\u00b7schweigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Wen jene gl\u00fccklichere Kugel angezeigt.", "tokens": ["Wen", "je\u00b7ne", "gl\u00fcck\u00b7li\u00b7che\u00b7re", "Ku\u00b7gel", "an\u00b7ge\u00b7zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.35": {"line.1": {"text": "Ganz anders unterhielt man sich auf der andern Seite:", "tokens": ["Ganz", "an\u00b7ders", "un\u00b7ter\u00b7hielt", "man", "sich", "auf", "der", "an\u00b7dern", "Sei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn Falk's Partei hat pl\u00f6tzlich sich aufgerafft zum Streite,", "tokens": ["Denn", "Fal\u00b7k's", "Par\u00b7tei", "hat", "pl\u00f6tz\u00b7lich", "sich", "auf\u00b7ge\u00b7rafft", "zum", "Strei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VAFIN", "ADJD", "PRF", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und \u00fcber Mutzens Freunde ging's unbarmherzig her.", "tokens": ["Und", "\u00fc\u00b7ber", "Mut\u00b7zens", "Freun\u00b7de", "ging's", "un\u00b7barm\u00b7her\u00b7zig", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gro\u00df war der Kampf, \u2013 man a\u00df die letzten Speisen nicht mehr,", "tokens": ["Gro\u00df", "war", "der", "Kampf", ",", "\u2013", "man", "a\u00df", "die", "letz\u00b7ten", "Spei\u00b7sen", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "$(", "PIS", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Man stritt nur, stehend und trinkend; am schrecklichsten aber war,", "tokens": ["Man", "stritt", "nur", ",", "ste\u00b7hend", "und", "trin\u00b7kend", ";", "am", "schreck\u00b7lichs\u00b7ten", "a\u00b7ber", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "ADJD", "KON", "VVPP", "$.", "APPRART", "ADJA", "ADV", "VAFIN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Gleich wie ein Birkhahn zu schauen, der hitzige Notar.", "tokens": ["Gleich", "wie", "ein", "Birk\u00b7hahn", "zu", "schau\u00b7en", ",", "der", "hit\u00b7zi\u00b7ge", "No\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wenn er einmal begonnen, so sprach er in Einem fort,", "tokens": ["Wenn", "er", "ein\u00b7mal", "be\u00b7gon\u00b7nen", ",", "so", "sprach", "er", "in", "Ei\u00b7nem", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ADV", "VVFIN", "PPER", "APPR", "PIS", "PTKVZ", "$,"], "meter": "--+--+--+--+-+", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "Eindringlich mit Geberden malend jedes Wort.", "tokens": ["Ein\u00b7dring\u00b7lich", "mit", "Ge\u00b7ber\u00b7den", "ma\u00b7lend", "je\u00b7des", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "PIAT", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Der Herr Notar Bolesta war fr\u00fcher Advokat,", "tokens": ["Der", "Herr", "No\u00b7tar", "Bo\u00b7les\u00b7ta", "war", "fr\u00fc\u00b7her", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VAFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.10": {"text": "Man nennt ihn Prediger, weil er so rege Gesten hat.", "tokens": ["Man", "nennt", "ihn", "Pre\u00b7di\u00b7ger", ",", "weil", "er", "so", "re\u00b7ge", "Ges\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "$,", "KOUS", "PPER", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+----+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Die H\u00e4nde an der Seite, nach hinten die Ellenbogen,", "tokens": ["Die", "H\u00e4n\u00b7de", "an", "der", "Sei\u00b7te", ",", "nach", "hin\u00b7ten", "die", "El\u00b7len\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die Finger mit den langen N\u00e4geln vorgezogen,", "tokens": ["Die", "Fin\u00b7ger", "mit", "den", "lan\u00b7gen", "N\u00e4\u00b7geln", "vor\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nun schlie\u00dft er: \u00bbHussah! Wir lassen in Einem Augenblick", "tokens": ["Nun", "schlie\u00dft", "er", ":", "\u00bb", "Hus\u00b7sah", "!", "Wir", "las\u00b7sen", "in", "Ei\u00b7nem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "ITJ", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Ich und der Assessor, auf Einmal, unsre Hunde los,", "tokens": ["Ich", "und", "der", "As\u00b7ses\u00b7sor", ",", "auf", "Ein\u00b7mal", ",", "uns\u00b7re", "Hun\u00b7de", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ART", "NN", "$,", "APPR", "ADV", "$,", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.15": {"text": "Als wie mit Einem Finger zwei H\u00e4hne am Doppelgescho\u00df \u2013", "tokens": ["Als", "wie", "mit", "Ei\u00b7nem", "Fin\u00b7ger", "zwei", "H\u00e4h\u00b7ne", "am", "Dop\u00b7pel\u00b7ge\u00b7scho\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "CARD", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Hussah! Sie liefen \u2013 der Hase, ripps! in's Feld, \u2013 sie nach \u2013\u00ab", "tokens": ["Hus\u00b7sah", "!", "Sie", "lie\u00b7fen", "\u2013", "der", "Ha\u00b7se", ",", "ripps", "!", "in's", "Feld", ",", "\u2013", "sie", "nach", "\u2013", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "$(", "ART", "NN", "$,", "VVFIN", "$.", "APPRART", "NN", "$,", "$(", "PPER", "APPR", "$(", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Hier fuhr er \u00fcber den Tisch und stellte, w\u00e4hrend er sprach,", "tokens": ["Hier", "fuhr", "er", "\u00fc\u00b7ber", "den", "Tisch", "und", "stell\u00b7te", ",", "w\u00e4h\u00b7rend", "er", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "KON", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Den Lauf mit den Fingern dar, mit wunderbarem Geschick;", "tokens": ["Den", "Lauf", "mit", "den", "Fin\u00b7gern", "dar", ",", "mit", "wun\u00b7der\u00b7ba\u00b7rem", "Ge\u00b7schick", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "\u00bbsie nach \u2013 und waren vom Wald schon weg ein gutes St\u00fcck.", "tokens": ["\u00bb", "sie", "nach", "\u2013", "und", "wa\u00b7ren", "vom", "Wald", "schon", "weg", "ein", "gu\u00b7tes", "St\u00fcck", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "APPR", "$(", "KON", "VAFIN", "APPRART", "NN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Falk ripps! voran \u2013 ein Hitzkopf, obzwar ein flinker Springer,", "tokens": ["Falk", "ripps", "!", "vo\u00b7ran", "\u2013", "ein", "Hitz\u00b7kopf", ",", "ob\u00b7zwar", "ein", "flin\u00b7ker", "Sprin\u00b7ger", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PTKVZ", "$(", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Er rannte Mutzen vor \u2013 um ", "tokens": ["Er", "rann\u00b7te", "Mut\u00b7zen", "vor", "\u2013", "um"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "$(", "KOUI"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.22": {"text": "Ich wu\u00dft' es: er blamirt sich! \u2013 Der Graue, pfiffig und fein,", "tokens": ["Ich", "wu\u00dft'", "es", ":", "er", "bla\u00b7mirt", "sich", "!", "\u2013", "Der", "Grau\u00b7e", ",", "pfif\u00b7fig", "und", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PRF", "$.", "$(", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Schie\u00dft scheinbar g'rad in's Feld, \u2013 die Hunde hinterdrein \u2013", "tokens": ["Schie\u00dft", "schein\u00b7bar", "g'\u00b7rad", "in's", "Feld", ",", "\u2013", "die", "Hun\u00b7de", "hin\u00b7ter\u00b7drein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJD", "APPRART", "NN", "$,", "$(", "ART", "NN", "ADV", "$("], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.24": {"text": "Ein Schlaukopf! Wie er die Meute beisammen wei\u00df, \u2013 bums! ging's", "tokens": ["Ein", "Schlau\u00b7kopf", "!", "Wie", "er", "die", "Meu\u00b7te", "bei\u00b7sam\u00b7men", "wei\u00df", ",", "\u2013", "bums", "!", "ging's"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "PWAV", "PPER", "ART", "NN", "VVIZU", "VVFIN", "$,", "$(", "NE", "$.", "VVFIN"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Nach rechts \u2013 ein Purzelbaum \u2013 sie nach \u2013 er wieder links:", "tokens": ["Nach", "rechts", "\u2013", "ein", "Pur\u00b7zel\u00b7baum", "\u2013", "sie", "nach", "\u2013", "er", "wie\u00b7der", "links", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "NN", "$(", "PPER", "APPR", "$(", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Flink in zwei S\u00e4tzen, \u2013 er macht sich die Dummheit der Hunde zu Nutz \u2013", "tokens": ["Flink", "in", "zwei", "S\u00e4t\u00b7zen", ",", "\u2013", "er", "macht", "sich", "die", "Dumm\u00b7heit", "der", "Hun\u00b7de", "zu", "Nutz", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "$,", "$(", "PPER", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "APPR", "NN", "$("], "meter": "+--+--+--+--+--+", "measure": "dactylic.tetra.plus"}, "line.27": {"text": "Sie flugs nach links ihm nach: er in den Wald, und mein Mutz:", "tokens": ["Sie", "flugs", "nach", "links", "ihm", "nach", ":", "er", "in", "den", "Wald", ",", "und", "mein", "Mutz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADV", "PPER", "PTKVZ", "$.", "PPER", "APPR", "ART", "NN", "$,", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.28": {"text": "Rapps!\u00ab \u2013 Also schreiend war er, \u00fcber den Tisch gebogen,", "tokens": ["Rapps", "!", "\u00ab", "\u2013", "Al\u00b7so", "schrei\u00b7end", "war", "er", ",", "\u00fc\u00b7ber", "den", "Tisch", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "$(", "ADV", "ADJD", "VAFIN", "PPER", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Bis auf die andre Seite mit seinen Fingern geflogen \u2013", "tokens": ["Bis", "auf", "die", "and\u00b7re", "Sei\u00b7te", "mit", "sei\u00b7nen", "Fin\u00b7gern", "ge\u00b7flo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und \u00bbRapps!\u00ab so schrie er m\u00e4chtig Thadd\u00e4us dicht in's Ohr \u2013", "tokens": ["Und", "\u00bb", "Rapps", "!", "\u00ab", "so", "schrie", "er", "m\u00e4ch\u00b7tig", "Thad\u00b7d\u00e4us", "dicht", "in's", "Ohr", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "NE", "$.", "$(", "ADV", "VVFIN", "PPER", "ADJD", "NE", "ADJD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Thadd\u00e4us und seine Dame schrecken j\u00e4h empor,", "tokens": ["Thad\u00b7d\u00e4us", "und", "sei\u00b7ne", "Da\u00b7me", "schre\u00b7cken", "j\u00e4h", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Aus traulichem Gespr\u00e4ch. Es fliehen wider Willen", "tokens": ["Aus", "trau\u00b7li\u00b7chem", "Ge\u00b7spr\u00e4ch", ".", "Es", "flie\u00b7hen", "wi\u00b7der", "Wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die Stirnen von einander vor dem lauten Br\u00fcllen:", "tokens": ["Die", "Stir\u00b7nen", "von", "ein\u00b7an\u00b7der", "vor", "dem", "lau\u00b7ten", "Br\u00fcl\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Gleich zwei verbund'nen Wipfeln, die der Wirbelwind", "tokens": ["Gleich", "zwei", "ver\u00b7bun\u00b7d'\u00b7nen", "Wip\u00b7feln", ",", "die", "der", "Wir\u00b7bel\u00b7wind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "CARD", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Mit j\u00e4hem Sto\u00dfe scheidet. Es trennen sich auch geschwind", "tokens": ["Mit", "j\u00e4\u00b7hem", "Sto\u00b7\u00dfe", "schei\u00b7det", ".", "Es", "tren\u00b7nen", "sich", "auch", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PRF", "ADV", "ADJD"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.36": {"text": "Die H\u00e4nde, die unter'm Tisch nah' bei einander lagen \u2013", "tokens": ["Die", "H\u00e4n\u00b7de", ",", "die", "un\u00b7ter'm", "Tisch", "nah'", "bei", "ein\u00b7an\u00b7der", "la\u00b7gen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.37": {"text": "Und Eine R\u00f6the sieht man aus zwei Gesichtern schlagen.", "tokens": ["Und", "Ei\u00b7ne", "R\u00f6\u00b7the", "sieht", "man", "aus", "zwei", "Ge\u00b7sich\u00b7tern", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIS", "APPR", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.36": {"line.1": {"text": "Thadd\u00e4us wollt' verbergen, wie zerstreut er war,", "tokens": ["Thad\u00b7d\u00e4us", "wollt'", "ver\u00b7ber\u00b7gen", ",", "wie", "zer\u00b7streut", "er", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "VVINF", "$,", "PWAV", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und meinte: \u00bbJa, ohne Zweifel, ja, mein lieber Notar,", "tokens": ["Und", "mein\u00b7te", ":", "\u00bb", "Ja", ",", "oh\u00b7ne", "Zwei\u00b7fel", ",", "ja", ",", "mein", "lie\u00b7ber", "No\u00b7tar", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PTKANT", "$,", "KOUI", "NN", "$,", "PTKANT", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sch\u00f6n ist der Mutz, ist er nur auch ein t\u00fcchtiger Packer \u2013\u00ab", "tokens": ["Sch\u00f6n", "ist", "der", "Mutz", ",", "ist", "er", "nur", "auch", "ein", "t\u00fcch\u00b7ti\u00b7ger", "Pa\u00b7cker", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,", "VAFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$(", "$("], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.4": {"text": "\u00bbein Packer\u00ab? schrie der Notar, \u00bbmein Lieblingshund, so wacker,", "tokens": ["\u00bb", "ein", "Pa\u00b7cker", "\u00ab", "?", "schrie", "der", "No\u00b7tar", ",", "\u00bb", "mein", "Lieb\u00b7lings\u00b7hund", ",", "so", "wa\u00b7cker", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$.", "VVFIN", "ART", "NN", "$,", "$(", "PPOSAT", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Der w\u00e4r' vielleicht kein Packer?\u00ab Thadd\u00e4us freut sich nun sehr,", "tokens": ["Der", "w\u00e4r'", "viel\u00b7leicht", "kein", "Pa\u00b7cker", "?", "\u00ab", "Thad\u00b7d\u00e4us", "freut", "sich", "nun", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "NN", "$.", "$(", "NE", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Da\u00df ein so sch\u00f6ner Hund ganz ohne Tadel w\u00e4r',", "tokens": ["Da\u00df", "ein", "so", "sch\u00f6\u00b7ner", "Hund", "ganz", "oh\u00b7ne", "Ta\u00b7del", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJA", "NN", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bedauert, ihn nur beim Gang vom Wald geseh'n zu haben,", "tokens": ["Be\u00b7dau\u00b7ert", ",", "ihn", "nur", "beim", "Gang", "vom", "Wald", "ge\u00b7seh'n", "zu", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "ADV", "APPRART", "NN", "APPRART", "NN", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und ihn nicht n\u00e4her zu kennen nach allen seinen Gaben.", "tokens": ["Und", "ihn", "nicht", "n\u00e4\u00b7her", "zu", "ken\u00b7nen", "nach", "al\u00b7len", "sei\u00b7nen", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADJD", "PTKZU", "VVINF", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Mit Basiliskenblicken durchbohrt er den jungen Sprecher \u2013", "tokens": ["Mit", "Ba\u00b7si\u00b7lis\u00b7ken\u00b7bli\u00b7cken", "durch\u00b7bohrt", "er", "den", "jun\u00b7gen", "Spre\u00b7cher", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Er war nicht so beweglich, konnt auch nicht so schrei'n,", "tokens": ["Er", "war", "nicht", "so", "be\u00b7weg\u00b7lich", ",", "konnt", "auch", "nicht", "so", "schrei'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,", "VMFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie der Notar, er war viel schm\u00e4chtiger und klein,", "tokens": ["Wie", "der", "No\u00b7tar", ",", "er", "war", "viel", "schm\u00e4ch\u00b7ti\u00b7ger", "und", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch Kreistag, Ball und Redoute kannten seine Schrecken:", "tokens": ["Doch", "Kreis\u00b7tag", ",", "Ball", "und", "Re\u00b7dou\u00b7te", "kann\u00b7ten", "sei\u00b7ne", "Schre\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Der Mann hat einen Stachel in der Zunge stecken,", "tokens": ["Der", "Mann", "hat", "ei\u00b7nen", "Sta\u00b7chel", "in", "der", "Zun\u00b7ge", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Hie\u00df es von ihm; so witzig wu\u00dfte er zu spa\u00dfen,", "tokens": ["Hie\u00df", "es", "von", "ihm", ";", "so", "wit\u00b7zig", "wu\u00df\u00b7te", "er", "zu", "spa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$.", "ADV", "ADJD", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.15": {"text": "Man h\u00e4tt' es im Kalender k\u00f6nnen drucken lassen \u2013", "tokens": ["Man", "h\u00e4tt'", "es", "im", "Ka\u00b7len\u00b7der", "k\u00f6n\u00b7nen", "dru\u00b7cken", "las\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "APPRART", "NN", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Und immer scharf und bissig. \u2013 Fr\u00fcher ziemlich reich,", "tokens": ["Und", "im\u00b7mer", "scharf", "und", "bis\u00b7sig", ".", "\u2013", "Fr\u00fc\u00b7her", "ziem\u00b7lich", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "ADJD", "$.", "$(", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Verputzt' er sein eigenes Erbtheil und das des Bruders zugleich,", "tokens": ["Ver\u00b7putzt'", "er", "sein", "ei\u00b7ge\u00b7nes", "E\u00b7rbtheil", "und", "das", "des", "Bru\u00b7ders", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "KON", "PDS", "ART", "NN", "ADV", "$,"], "meter": "-+--+---+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Um in der gro\u00dfen Welt nur recht viel Pomp zu entfalten;", "tokens": ["Um", "in", "der", "gro\u00b7\u00dfen", "Welt", "nur", "recht", "viel", "Pomp", "zu", "ent\u00b7fal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN", "ADV", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Drauf trat er in den Staatsdienst, um im Bezirk zu schalten.", "tokens": ["Drauf", "trat", "er", "in", "den", "Staats\u00b7dienst", ",", "um", "im", "Be\u00b7zirk", "zu", "schal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KOUI", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Er jagt f\u00fcr's Leben gerne, theils der Kurzweil wegen,", "tokens": ["Er", "jagt", "f\u00fcr's", "Le\u00b7ben", "ger\u00b7ne", ",", "theils", "der", "Kurz\u00b7weil", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "$,", "ADV", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Theils, weil ihm Horn und Treibjagd Erinn'rungen erregen", "tokens": ["Theils", ",", "weil", "ihm", "Horn", "und", "Treib\u00b7jagd", "Er\u00b7inn'\u00b7run\u00b7gen", "er\u00b7re\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "NE", "KON", "NN", "NN", "VVINF"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.22": {"text": "An seine jungen Jahre, da er noch sein genannt", "tokens": ["An", "sei\u00b7ne", "jun\u00b7gen", "Jah\u00b7re", ",", "da", "er", "noch", "sein", "ge\u00b7nannt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "ADV", "PPOSAT", "VVPP"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Viel J\u00e4gersleute und Meuten, weit und breit bekannt.", "tokens": ["Viel", "J\u00e4\u00b7gers\u00b7leu\u00b7te", "und", "Meu\u00b7ten", ",", "weit", "und", "breit", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$,", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Zwei Windspiele besa\u00df er noch aus jenen Zeiten,", "tokens": ["Zwei", "Wind\u00b7spie\u00b7le", "be\u00b7sa\u00df", "er", "noch", "aus", "je\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.25": {"text": "Und Einem von diesen wollt' man noch den Ruhm bestreiten!", "tokens": ["Und", "Ei\u00b7nem", "von", "die\u00b7sen", "wollt'", "man", "noch", "den", "Ruhm", "be\u00b7strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PDAT", "VMFIN", "PIS", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "So r\u00fcckt er denn n\u00e4her, streichelt langsam den Backenbart,", "tokens": ["So", "r\u00fcckt", "er", "denn", "n\u00e4\u00b7her", ",", "strei\u00b7chelt", "lang\u00b7sam", "den", "Ba\u00b7cken\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$,", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und l\u00e4chelnd beginnt er (es war ein L\u00e4cheln giftiger Art):", "tokens": ["Und", "l\u00e4\u00b7chelnd", "be\u00b7ginnt", "er", "(", "es", "war", "ein", "L\u00e4\u00b7cheln", "gif\u00b7ti\u00b7ger", "Art", ")", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+-+-+--+", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "\u00bbein Hund ohne Schwanz, das ist ein Schlachcic ohne Amt \u2013", "tokens": ["\u00bb", "ein", "Hund", "oh\u00b7ne", "Schwanz", ",", "das", "ist", "ein", "Schlach\u00b7cic", "oh\u00b7ne", "Amt", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Der Schwanz macht ihn behender: woher auch das Sprichwort stammt,", "tokens": ["Der", "Schwanz", "macht", "ihn", "be\u00b7hen\u00b7der", ":", "wo\u00b7her", "auch", "das", "Sprich\u00b7wort", "stammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.30": {"text": "Ihr scheint euch aber den Stutzschwanz als Vorzug vorzustellen?", "tokens": ["Ihr", "scheint", "euch", "a\u00b7ber", "den", "Stutz\u00b7schwanz", "als", "Vor\u00b7zug", "vor\u00b7zu\u00b7stel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "KOUS", "NN", "VVIZU", "$."], "meter": "-+-+--++-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.31": {"text": "\u00dcbrigens mag eure Tante hier das Urtheil f\u00e4llen,", "tokens": ["\u00dcb\u00b7ri\u00b7gens", "mag", "eu\u00b7re", "Tan\u00b7te", "hier", "das", "Ur\u00b7theil", "f\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.32": {"text": "Ob auch Frau Telimene in der Hauptstadt geweilt", "tokens": ["Ob", "auch", "Frau", "Te\u00b7li\u00b7me\u00b7ne", "in", "der", "Haupt\u00b7stadt", "ge\u00b7weilt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "---+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Und unser l\u00e4ndliches Leben erst seit Kurzem theilt,", "tokens": ["Und", "un\u00b7ser", "l\u00e4nd\u00b7li\u00b7ches", "Le\u00b7ben", "erst", "seit", "Kur\u00b7zem", "theilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch wei\u00df sie im Jagen besser, als junge J\u00e4ger, Bescheid, \u2013", "tokens": ["Doch", "wei\u00df", "sie", "im", "Ja\u00b7gen", "bes\u00b7ser", ",", "als", "jun\u00b7ge", "J\u00e4\u00b7ger", ",", "Be\u00b7scheid", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "ADJD", "$,", "KOUS", "ADJA", "NN", "$,", "NN", "$,", "$("], "meter": "-+--+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Seht ihr: So kommt die Einsicht von selber mit der Zeit.\u00ab", "tokens": ["Seht", "ihr", ":", "So", "kommt", "die", "Ein\u00b7sicht", "von", "sel\u00b7ber", "mit", "der", "Zeit", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.37": {"line.1": {"text": "Thadd\u00e4us, so angedonnert, er wu\u00dfte kaum, warum, \u2013", "tokens": ["Thad\u00b7d\u00e4us", ",", "so", "an\u00b7ge\u00b7don\u00b7nert", ",", "er", "wu\u00df\u00b7te", "kaum", ",", "wa\u00b7rum", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "$,", "ADV", "VVPP", "$,", "PPER", "VVFIN", "ADV", "$,", "PWAV", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Erhebt sich ganz verwirrt, bleibt eine Weile stumm,", "tokens": ["Er\u00b7hebt", "sich", "ganz", "ver\u00b7wirrt", ",", "bleibt", "ei\u00b7ne", "Wei\u00b7le", "stumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADJD", "$,", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mi\u00dft aber den Assessor mit immer wild'rem Blick:", "tokens": ["Mi\u00dft", "a\u00b7ber", "den", "As\u00b7ses\u00b7sor", "mit", "im\u00b7mer", "wild'\u00b7rem", "Blick", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da niest der K\u00e4mmerer zweimal, es war ein gro\u00dfes Gl\u00fcck \u2013", "tokens": ["Da", "niest", "der", "K\u00e4m\u00b7me\u00b7rer", "zwei\u00b7mal", ",", "es", "war", "ein", "gro\u00b7\u00dfes", "Gl\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-----+-+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Helfgott! ruft Alles \u2013 er neigt sich dankend im ganzen Kreise", "tokens": ["Helf\u00b7gott", "!", "ruft", "Al\u00b7les", "\u2013", "er", "neigt", "sich", "dan\u00b7kend", "im", "gan\u00b7zen", "Krei\u00b7se"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVFIN", "PIS", "$(", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Und an die Dose klopft er mit den Fingern leise.", "tokens": ["Und", "an", "die", "Do\u00b7se", "klopft", "er", "mit", "den", "Fin\u00b7gern", "lei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Dose war von Gold, mit Edelsteinen belegt,", "tokens": ["Die", "Do\u00b7se", "war", "von", "Gold", ",", "mit", "E\u00b7del\u00b7stei\u00b7nen", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Das Bild des K\u00f6nigs Stanislaus mitten eingepr\u00e4gt;", "tokens": ["Das", "Bild", "des", "K\u00f6\u00b7nigs", "Sta\u00b7nis\u00b7laus", "mit\u00b7ten", "ein\u00b7ge\u00b7pr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "In Ehren hielt sie nun der Sohn sein ganzes Leben.", "tokens": ["In", "Eh\u00b7ren", "hielt", "sie", "nun", "der", "Sohn", "sein", "gan\u00b7zes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Klopft er an diese Dose, so hei\u00dft das: er will sprechen.", "tokens": ["Klopft", "er", "an", "die\u00b7se", "Do\u00b7se", ",", "so", "hei\u00dft", "das", ":", "er", "will", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "ADV", "VVFIN", "PDS", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Da schweigen Alle und Keiner wagt ihn zu unterbrechen. \u2013", "tokens": ["Da", "schwei\u00b7gen", "Al\u00b7le", "und", "Kei\u00b7ner", "wagt", "ihn", "zu", "un\u00b7ter\u00b7bre\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "KON", "PIS", "VVFIN", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Er sprach: \u00bbGro\u00dfm\u00e4chtige Herrn und Br\u00fcder allzumal!", "tokens": ["Er", "sprach", ":", "\u00bb", "Gro\u00df\u00b7m\u00e4ch\u00b7ti\u00b7ge", "Herrn", "und", "Br\u00fc\u00b7der", "all\u00b7zu\u00b7mal", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Nur Forst und Felder sind des J\u00e4gers Tribunal,", "tokens": ["Nur", "Forst", "und", "Fel\u00b7der", "sind", "des", "J\u00e4\u00b7gers", "Tri\u00b7bu\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Weshalb ich in solchen Dingen zu Haus kein Urtheil k\u00fcnde,", "tokens": ["We\u00b7shalb", "ich", "in", "sol\u00b7chen", "Din\u00b7gen", "zu", "Haus", "kein", "Ur\u00b7theil", "k\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "NN", "APPR", "NN", "PIAT", "NN", "ADJA", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.15": {"text": "Und unsere Sitzung f\u00fcr morgen anzuberaumen finde,", "tokens": ["Und", "un\u00b7se\u00b7re", "Sit\u00b7zung", "f\u00fcr", "mor\u00b7gen", "an\u00b7zu\u00b7be\u00b7rau\u00b7men", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADV", "VVIZU", "VVFIN", "$,"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.16": {"text": "Und weitere Repliken den Streitenden untersage.", "tokens": ["Und", "wei\u00b7te\u00b7re", "Re\u00b7pli\u00b7ken", "den", "Strei\u00b7ten\u00b7den", "un\u00b7ter\u00b7sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Frohnbote, f\u00fcr morgen, f\u00fcr's Feld, vertage du die Frage!", "tokens": ["Frohn\u00b7bo\u00b7te", ",", "f\u00fcr", "mor\u00b7gen", ",", "f\u00fcr's", "Feld", ",", "ver\u00b7ta\u00b7ge", "du", "die", "Fra\u00b7ge", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADV", "$,", "APPRART", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Der Graf mit seinem Jagdtro\u00df trifft hier morgen ein,", "tokens": ["Der", "Graf", "mit", "sei\u00b7nem", "Jagd\u00b7tro\u00df", "trifft", "hier", "mor\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und ihr auch, Nachbar Richter, werdet mit uns sein,", "tokens": ["Und", "ihr", "auch", ",", "Nach\u00b7bar", "Rich\u00b7ter", ",", "wer\u00b7det", "mit", "uns", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "NN", "NN", "$,", "VAFIN", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Frau Telimene auch, die Fr\u00e4ulein und die Frauen \u2013", "tokens": ["Frau", "Te\u00b7li\u00b7me\u00b7ne", "auch", ",", "die", "Fr\u00e4u\u00b7lein", "und", "die", "Frau\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "$,", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Kurz, morgen kriegen wir ein wacker Jagen zu schauen \u2013", "tokens": ["Kurz", ",", "mor\u00b7gen", "krie\u00b7gen", "wir", "ein", "wa\u00b7cker", "Ja\u00b7gen", "zu", "schau\u00b7en", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und unser Wojski auch wird sich uns nicht entzieh'n.\u00ab", "tokens": ["Und", "un\u00b7ser", "Wojs\u00b7ki", "auch", "wird", "sich", "uns", "nicht", "ent\u00b7zieh'", "n.", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VAFIN", "PRF", "PPER", "PTKNEG", "VVFIN", "NE", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Mit diesen Worten reicht er dem Greis die Dose hin.", "tokens": ["Mit", "die\u00b7sen", "Wor\u00b7ten", "reicht", "er", "dem", "Greis", "die", "Do\u00b7se", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.38": {"line.1": {"text": "Der sa\u00df an der Ecke mitten unter den J\u00e4gersleuten,", "tokens": ["Der", "sa\u00df", "an", "der", "E\u00b7cke", "mit\u00b7ten", "un\u00b7ter", "den", "J\u00e4\u00b7gers\u00b7leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Geschlossenen Auges h\u00f6rt' er all' das Reden und Streiten,", "tokens": ["Ge\u00b7schlos\u00b7se\u00b7nen", "Au\u00b7ges", "h\u00f6rt'", "er", "all'", "das", "Re\u00b7den", "und", "Strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "PIS", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Doch ohne ein Wort zu sprechen, wiewohl man ihn \u00f6fter fragt, \u2013", "tokens": ["Doch", "oh\u00b7ne", "ein", "Wort", "zu", "spre\u00b7chen", ",", "wie\u00b7wohl", "man", "ihn", "\u00f6f\u00b7ter", "fragt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Denn Keiner wei\u00df, wie er, Bescheid in Sachen der Jagd.", "tokens": ["Denn", "Kei\u00b7ner", "wei\u00df", ",", "wie", "er", ",", "Be\u00b7scheid", "in", "Sa\u00b7chen", "der", "Jagd", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWAV", "PPER", "$,", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Er schwieg; die Prise, die er zwischen die Finger schlo\u00df,", "tokens": ["Er", "schwieg", ";", "die", "Pri\u00b7se", ",", "die", "er", "zwi\u00b7schen", "die", "Fin\u00b7ger", "schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wog er in langem Sinnen, bis er sie endlich geno\u00df \u2013", "tokens": ["Wog", "er", "in", "lan\u00b7gem", "Sin\u00b7nen", ",", "bis", "er", "sie", "end\u00b7lich", "ge\u00b7no\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$("], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Er niest: da\u00df es gewaltig hallt im ganzen Gemach;", "tokens": ["Er", "niest", ":", "da\u00df", "es", "ge\u00b7wal\u00b7tig", "hallt", "im", "gan\u00b7zen", "Ge\u00b7mach", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KOUS", "PPER", "ADJD", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Kopfsch\u00fcttelnd und bitter l\u00e4chelnd begann er drauf und sprach:", "tokens": ["Kopf\u00b7sch\u00fct\u00b7telnd", "und", "bit\u00b7ter", "l\u00e4\u00b7chelnd", "be\u00b7gann", "er", "drauf", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "\u00bbo! Wie mich alten Mann das wundern mu\u00df und gr\u00e4men!", "tokens": ["\u00bb", "o", "!", "Wie", "mich", "al\u00b7ten", "Mann", "das", "wun\u00b7dern", "mu\u00df", "und", "gr\u00e4\u00b7men", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "$.", "PWAV", "PPER", "ADJA", "NN", "ART", "VVINF", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was sagten die alten J\u00e4ger, wenn sie das vern\u00e4hmen,", "tokens": ["Was", "sag\u00b7ten", "die", "al\u00b7ten", "J\u00e4\u00b7ger", ",", "wenn", "sie", "das", "ver\u00b7n\u00e4h\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df mitten in so vieler edler Herren Kranz", "tokens": ["Da\u00df", "mit\u00b7ten", "in", "so", "vie\u00b7ler", "ed\u00b7ler", "Her\u00b7ren", "Kranz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADV", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Processe verhandelt werden um eines Windspiels Schwanz?", "tokens": ["Pro\u00b7ces\u00b7se", "ver\u00b7han\u00b7delt", "wer\u00b7den", "um", "ei\u00b7nes", "Wind\u00b7spiels", "Schwanz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAINF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Was sagte der alte Rejtan, k\u00e4m' er zur Erde wieder?", "tokens": ["Was", "sag\u00b7te", "der", "al\u00b7te", "Rej\u00b7tan", ",", "k\u00e4m'", "er", "zur", "Er\u00b7de", "wie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Er gienge nach Lachowicze und legt' auf's neu' sich nieder.", "tokens": ["Er", "gien\u00b7ge", "nach", "La\u00b7cho\u00b7wic\u00b7ze", "und", "legt'", "auf's", "neu'", "sich", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "VVFIN", "APPRART", "ADJA", "PRF", "PTKVZ", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Was d\u00e4cht' sich der Wojewode Niesiolowski", "tokens": ["Was", "d\u00e4cht'", "sich", "der", "Wo\u00b7je\u00b7wo\u00b7de", "Nie\u00b7si\u00b7o\u00b7lo\u00b7wski"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "ART", "NN", "NE"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Er, der jetzt in der Welt besitzt die erste Meute,", "tokens": ["Er", ",", "der", "jetzt", "in", "der", "Welt", "be\u00b7sitzt", "die", "ers\u00b7te", "Meu\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und h\u00e4lt zweihundert J\u00e4ger, nach gro\u00dfer Herren Art,", "tokens": ["Und", "h\u00e4lt", "zwei\u00b7hun\u00b7dert", "J\u00e4\u00b7ger", ",", "nach", "gro\u00b7\u00dfer", "Her\u00b7ren", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "CARD", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Und hundert Wagen Netze in seinem Schlo\u00df bewahrt,", "tokens": ["Und", "hun\u00b7dert", "Wa\u00b7gen", "Net\u00b7ze", "in", "sei\u00b7nem", "Schlo\u00df", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und doch, wie ein M\u00f6nch, seit Jahren sitzt in seinem Nest,", "tokens": ["Und", "doch", ",", "wie", "ein", "M\u00f6nch", ",", "seit", "Jah\u00b7ren", "sitzt", "in", "sei\u00b7nem", "Nest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ART", "NN", "$,", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.20": {"text": "Und sich um keinen Preis zur Jagd erbitten l\u00e4\u00dft,", "tokens": ["Und", "sich", "um", "kei\u00b7nen", "Preis", "zur", "Jagd", "er\u00b7bit\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPRART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Denn was auch soll der Alte auf euren Jagden jagen?", "tokens": ["Denn", "was", "auch", "soll", "der", "Al\u00b7te", "auf", "eu\u00b7ren", "Jag\u00b7den", "ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Das w\u00e4r' ein sch\u00f6ner Ruhm, den solch ein Herr erstritte,", "tokens": ["Das", "w\u00e4r'", "ein", "sch\u00f6\u00b7ner", "Ruhm", ",", "den", "solch", "ein", "Herr", "er\u00b7strit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "PIAT", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wenn er, nach heut'ger Mode, auf Hasenf\u00e4hrten ritte!", "tokens": ["Wenn", "er", ",", "nach", "heut'\u00b7ger", "Mo\u00b7de", ",", "auf", "Ha\u00b7sen\u00b7f\u00e4hr\u00b7ten", "rit\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Zu meinen Zeiten, ihr Herrn, da hie\u00dfen wir J\u00e4gersleute", "tokens": ["Zu", "mei\u00b7nen", "Zei\u00b7ten", ",", "ihr", "Herrn", ",", "da", "hie\u00b7\u00dfen", "wir", "J\u00e4\u00b7gers\u00b7leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+--+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Wolf, Elenn, B\u00e4r und Eber edelm\u00e4nnische Beute,", "tokens": ["Wolf", ",", "E\u00b7lenn", ",", "B\u00e4r", "und", "E\u00b7ber", "e\u00b7del\u00b7m\u00e4n\u00b7ni\u00b7sche", "Beu\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und was nicht Klauen, Hauer oder H\u00f6rner trug,", "tokens": ["Und", "was", "nicht", "Klau\u00b7en", ",", "Hau\u00b7er", "o\u00b7der", "H\u00f6r\u00b7ner", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Lie\u00df man f\u00fcr Bursch und Tro\u00dfknecht mit gutem Recht und Fug.", "tokens": ["Lie\u00df", "man", "f\u00fcr", "Bursch", "und", "Tro\u00df\u00b7knecht", "mit", "gu\u00b7tem", "Recht", "und", "Fug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "KON", "NN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Es h\u00e4tte ja jeder Herr mit Grau'n sich weggewendet", "tokens": ["Es", "h\u00e4t\u00b7te", "ja", "je\u00b7der", "Herr", "mit", "Grau'n", "sich", "weg\u00b7ge\u00b7wen\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "PRF", "VVPP"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Von einer Flinte, die jemals d\u00fcnnes Schrot gesch\u00e4ndet!", "tokens": ["Von", "ei\u00b7ner", "Flin\u00b7te", ",", "die", "je\u00b7mals", "d\u00fcn\u00b7nes", "Schrot", "ge\u00b7sch\u00e4n\u00b7det", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Windspiele hielt man wohl, denn bei der Heimkehr geschah's,", "tokens": ["Wind\u00b7spie\u00b7le", "hielt", "man", "wohl", ",", "denn", "bei", "der", "Heim\u00b7kehr", "ge\u00b7scha\u00b7h's", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "ADV", "$,", "KON", "APPR", "ART", "NN", "NE", "$,"], "meter": "++-+-+-+-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.31": {"text": "Da\u00df unter dem Ro\u00df hervorglitt so ein armer Has',", "tokens": ["Da\u00df", "un\u00b7ter", "dem", "Ro\u00df", "her\u00b7vor\u00b7glitt", "so", "ein", "ar\u00b7mer", "Has'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Da mochte man zur Kurzweil auf ihn die Hunde hetzen,", "tokens": ["Da", "moch\u00b7te", "man", "zur", "Kurz\u00b7weil", "auf", "ihn", "die", "Hun\u00b7de", "het\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "APPR", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "Und B\u00fcrschlein auf kleinen R\u00f6\u00dflein pflegten ihm nachzusetzen,", "tokens": ["Und", "B\u00fcr\u00b7schlein", "auf", "klei\u00b7nen", "R\u00f6\u00df\u00b7lein", "pfleg\u00b7ten", "ihm", "nach\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVIZU", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Vor ihrer Eltern Augen, die solche Lustbarkeiten", "tokens": ["Vor", "ih\u00b7rer", "El\u00b7tern", "Au\u00b7gen", ",", "die", "sol\u00b7che", "Lust\u00b7bar\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Kaum w\u00fcrdigten anzuschauen, geschweige dr\u00fcber zu streiten.", "tokens": ["Kaum", "w\u00fcr\u00b7dig\u00b7ten", "an\u00b7zu\u00b7schau\u00b7en", ",", "ge\u00b7schwei\u00b7ge", "dr\u00fc\u00b7ber", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVIZU", "$,", "ADJA", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.36": {"text": "Drum, gn\u00e4digster Herr K\u00e4mm'rer, m\u00f6g's euch gef\u00e4llig sein,", "tokens": ["Drum", ",", "gn\u00e4\u00b7digs\u00b7ter", "Herr", "K\u00e4m\u00b7m'\u00b7rer", ",", "m\u00f6g's", "euch", "ge\u00b7f\u00e4l\u00b7lig", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJA", "NN", "NN", "$,", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+---+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Die Ordre zur\u00fcckzunehmen, mir aber zu verzeih'n,", "tokens": ["Die", "Ord\u00b7re", "zu\u00b7r\u00fcck\u00b7zu\u00b7neh\u00b7men", ",", "mir", "a\u00b7ber", "zu", "ver\u00b7zeih'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Da\u00df ich auf solch ein Jagen mich keineswegs begebe,", "tokens": ["Da\u00df", "ich", "auf", "solch", "ein", "Ja\u00b7gen", "mich", "kei\u00b7nes\u00b7wegs", "be\u00b7ge\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "---+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Und nie begeben werde, so lange ich noch lebe.", "tokens": ["Und", "nie", "be\u00b7ge\u00b7ben", "wer\u00b7de", ",", "so", "lan\u00b7ge", "ich", "noch", "le\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.40": {"text": "Hreczecha hei\u00df' ich und seit Lech's, des K\u00f6nigs Zeiten,", "tokens": ["Hre\u00b7cze\u00b7cha", "hei\u00df'", "ich", "und", "seit", "Lech's", ",", "des", "K\u00f6\u00b7nigs", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "KON", "APPR", "NE", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "That niemals ein Hreczecha wider Hasen reiten.\u00ab", "tokens": ["That", "nie\u00b7mals", "ein", "Hre\u00b7cze\u00b7cha", "wi\u00b7der", "Ha\u00b7sen", "rei\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "ART", "NE", "APPR", "NE", "VVFIN", "$.", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.39": {"line.1": {"text": "Hier fingen die jungen Leute laut zu lachen an;", "tokens": ["Hier", "fin\u00b7gen", "die", "jun\u00b7gen", "Leu\u00b7te", "laut", "zu", "la\u00b7chen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Man stand vom Tische auf, der K\u00e4mmerer schritt voran,", "tokens": ["Man", "stand", "vom", "Ti\u00b7sche", "auf", ",", "der", "K\u00e4m\u00b7me\u00b7rer", "schritt", "vo\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Seinem Alter und Amt ertheilt man die Ehre gern;", "tokens": ["Sei\u00b7nem", "Al\u00b7ter", "und", "Amt", "er\u00b7theilt", "man", "die", "Eh\u00b7re", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Im Gehen gr\u00fc\u00dft er die Damen, die \u00e4ltern und j\u00fcngern Herrn.", "tokens": ["Im", "Ge\u00b7hen", "gr\u00fc\u00dft", "er", "die", "Da\u00b7men", ",", "die", "\u00e4l\u00b7tern", "und", "j\u00fcn\u00b7gern", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Drauf folgt der M\u00f6nch, der Richter schlie\u00dft sich dicht an ihn,", "tokens": ["Drauf", "folgt", "der", "M\u00f6nch", ",", "der", "Rich\u00b7ter", "schlie\u00dft", "sich", "dicht", "an", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PRF", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Richter giebt an der Th\u00fcr den Arm der K\u00e4mm'rerin,", "tokens": ["Der", "Rich\u00b7ter", "giebt", "an", "der", "Th\u00fcr", "den", "Arm", "der", "K\u00e4m\u00b7m'\u00b7re\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Thadd\u00e4us bietet ihn Frau Telimenen dar,", "tokens": ["Thad\u00b7d\u00e4us", "bie\u00b7tet", "ihn", "Frau", "Te\u00b7li\u00b7me\u00b7nen", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "NN", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "Assessor und Krajczanka bilden das n\u00e4chste Paar,", "tokens": ["As\u00b7ses\u00b7sor", "und", "Kraj\u00b7czan\u00b7ka", "bil\u00b7den", "das", "n\u00e4chs\u00b7te", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Zum Schlu\u00df des Wojski Tochter mit dem Herrn Notar.", "tokens": ["Zum", "Schlu\u00df", "des", "Wojs\u00b7ki", "Toch\u00b7ter", "mit", "dem", "Herrn", "No\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.40": {"line.1": {"text": "Thadd\u00e4us f\u00fchrt einige G\u00e4ste zur Scheuer; \u2013 er ist verstimmt,", "tokens": ["Thad\u00b7d\u00e4us", "f\u00fchrt", "ei\u00b7ni\u00b7ge", "G\u00e4s\u00b7te", "zur", "Scheu\u00b7er", ";", "\u2013", "er", "ist", "ver\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "APPRART", "NN", "$.", "$(", "PPER", "VAFIN", "VVPP", "$,"], "meter": "---+--+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durchaus nicht guter Laune, verwirrt, sogar ergrimmt;", "tokens": ["Durc\u00b7haus", "nicht", "gu\u00b7ter", "Lau\u00b7ne", ",", "ver\u00b7wirrt", ",", "so\u00b7gar", "er\u00b7grimmt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJA", "NN", "$,", "ADJD", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und alles, was heut' geschehen, zergliedert er im Sinn,", "tokens": ["Und", "al\u00b7les", ",", "was", "heut'", "ge\u00b7sche\u00b7hen", ",", "zer\u00b7glie\u00b7dert", "er", "im", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADV", "VVPP", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die erste Begegnung, die Mahlzeit neben der Nachbarin;", "tokens": ["Die", "ers\u00b7te", "Be\u00b7geg\u00b7nung", ",", "die", "Mahl\u00b7zeit", "ne\u00b7ben", "der", "Nach\u00b7ba\u00b7rin", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.5": {"text": "Wie eine l\u00e4stige Fliege, umsummt's ihn immerfort", "tokens": ["Wie", "ei\u00b7ne", "l\u00e4s\u00b7ti\u00b7ge", "Flie\u00b7ge", ",", "um\u00b7summt's", "ihn", "im\u00b7mer\u00b7fort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Gern m\u00f6cht' er vom Gerichtsfrohn sich n\u00e4her berichten lassen,", "tokens": ["Gern", "m\u00f6cht'", "er", "vom", "Ge\u00b7richts\u00b7frohn", "sich", "n\u00e4\u00b7her", "be\u00b7rich\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPRART", "NN", "PRF", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "\u00dcber Frau Telimene, \u2013 doch der war nicht zu fassen;", "tokens": ["\u00dc\u00b7ber", "Frau", "Te\u00b7li\u00b7me\u00b7ne", ",", "\u2013", "doch", "der", "war", "nicht", "zu", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,", "$(", "ADV", "ART", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Auch der Wojski war fort. Sie waren allesammt", "tokens": ["Auch", "der", "Wojs\u00b7ki", "war", "fort", ".", "Sie", "wa\u00b7ren", "al\u00b7le\u00b7sammt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKVZ", "$.", "PPER", "VAFIN", "ADJD"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Den G\u00e4sten gleich gefolgt, wie's des Gesindes Amt,", "tokens": ["Den", "G\u00e4s\u00b7ten", "gleich", "ge\u00b7folgt", ",", "wie's", "des", "Ge\u00b7sin\u00b7des", "Amt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Stuben herzurichten. Die Damen und die Alten", "tokens": ["Die", "Stu\u00b7ben", "her\u00b7zu\u00b7rich\u00b7ten", ".", "Die", "Da\u00b7men", "und", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Sollten im Herrengeb\u00e4ude ihre Nachtruh' halten,", "tokens": ["Soll\u00b7ten", "im", "Her\u00b7ren\u00b7ge\u00b7b\u00e4u\u00b7de", "ih\u00b7re", "Nachtruh'", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+--+-+-++-", "measure": "dactylic.di.plus"}, "line.12": {"text": "Indessen, an Stelle des Hausherrn, Thadd\u00e4us die jungen Leute", "tokens": ["In\u00b7des\u00b7sen", ",", "an", "Stel\u00b7le", "des", "Haus\u00b7herrn", ",", "Thad\u00b7d\u00e4us", "die", "jun\u00b7gen", "Leu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "NN", "ART", "NN", "$,", "NE", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.13": {"text": "Zur Scheuer f\u00fchrt, aufs Heu; dort \u00fcbernachten sie heute.", "tokens": ["Zur", "Scheu\u00b7er", "f\u00fchrt", ",", "aufs", "Heu", ";", "dort", "\u00fc\u00b7bern\u00b7ach\u00b7ten", "sie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.41": {"line.1": {"text": "Bald drauf lag tiefe Stille \u00fcber das Haus gebreitet,", "tokens": ["Bald", "drauf", "lag", "tie\u00b7fe", "Stil\u00b7le", "\u00fc\u00b7ber", "das", "Haus", "ge\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gleichwie in Klosterhallen, wenn man zur Hora gel\u00e4utet.", "tokens": ["Gleich\u00b7wie", "in", "Klos\u00b7ter\u00b7hal\u00b7len", ",", "wenn", "man", "zur", "Ho\u00b7ra", "ge\u00b7l\u00e4u\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "KOUS", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Des W\u00e4chters Stimme nur durcht\u00f6nt die Ruh' der Nacht.", "tokens": ["Des", "W\u00e4ch\u00b7ters", "Stim\u00b7me", "nur", "durch\u00b7t\u00f6nt", "die", "Ruh'", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Entschlummert sind schon Alle. Nur der Richter wacht;", "tokens": ["Ent\u00b7schlum\u00b7mert", "sind", "schon", "Al\u00b7le", ".", "Nur", "der", "Rich\u00b7ter", "wacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "PIS", "$.", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als Oberhaupt des Hauses durchdenkt er nun den Zug", "tokens": ["Als", "O\u00b7ber\u00b7haupt", "des", "Hau\u00b7ses", "durch\u00b7denkt", "er", "nun", "den", "Zug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "In's Feld \u2013 und ordnet auch die ferneren Spiele klug;", "tokens": ["In's", "Feld", "\u2013", "und", "ord\u00b7net", "auch", "die", "fer\u00b7ne\u00b7ren", "Spie\u00b7le", "klug", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Aufseher, Verwalter, V\u00f6gte erhalten Befehle genau,", "tokens": ["Auf\u00b7se\u00b7her", ",", "Ver\u00b7wal\u00b7ter", ",", "V\u00f6g\u00b7te", "er\u00b7hal\u00b7ten", "Be\u00b7feh\u00b7le", "ge\u00b7nau", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+--+--+--+", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "Stallknechte, Schreiber und J\u00e4ger, und auch die Wirthschaftsfrau,", "tokens": ["Stall\u00b7knech\u00b7te", ",", "Schrei\u00b7ber", "und", "J\u00e4\u00b7ger", ",", "und", "auch", "die", "Wirth\u00b7schafts\u00b7frau", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "KON", "NN", "$,", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Auch alle Rechnungen vom Tag sind durchzuseh'n.", "tokens": ["Auch", "al\u00b7le", "Rech\u00b7nun\u00b7gen", "vom", "Tag", "sind", "durch\u00b7zu\u00b7seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "PIAT", "NN", "APPRART", "NN", "VAFIN", "XY", "XY"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nun sagt er dem Gerichtsfrohn, er wolle zu Bette geh'n.", "tokens": ["Nun", "sagt", "er", "dem", "Ge\u00b7richts\u00b7frohn", ",", "er", "wol\u00b7le", "zu", "Bet\u00b7te", "geh'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VMFIN", "APPR", "NN", "VVFIN", "NE"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der bindet ihm den Gurt ab \u2013 ein Slucker Gurt und gediegen", "tokens": ["Der", "bin\u00b7det", "ihm", "den", "Gurt", "ab", "\u2013", "ein", "Slu\u00b7cker", "Gurt", "und", "ge\u00b7die\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$(", "ART", "NN", "NE", "KON", "NN"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Mit strahlenden dichten Quasten, die wie ein Helmbusch fliegen; \u2013", "tokens": ["Mit", "strah\u00b7len\u00b7den", "dich\u00b7ten", "Quas\u00b7ten", ",", "die", "wie", "ein", "Helm\u00b7busch", "flie\u00b7gen", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,", "PRELS", "KOKOM", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die eine Seite aus Goldstoff, mit Purpurblumen geschm\u00fcckt,", "tokens": ["Die", "ei\u00b7ne", "Sei\u00b7te", "aus", "Gold\u00b7stoff", ",", "mit", "Pur\u00b7pur\u00b7blu\u00b7men", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die andre aus schwarzer Seide, mit Streifen, in Silber gestickt;", "tokens": ["Die", "and\u00b7re", "aus", "schwar\u00b7zer", "Sei\u00b7de", ",", "mit", "Strei\u00b7fen", ",", "in", "Sil\u00b7ber", "ge\u00b7stickt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ADJA", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Man kann einen solchen Gurt auf beiden Seiten tragen,", "tokens": ["Man", "kann", "ei\u00b7nen", "sol\u00b7chen", "Gurt", "auf", "bei\u00b7den", "Sei\u00b7ten", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "PIAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.16": {"text": "Die goldne an festlichen, die schwarze an Trauertagen.", "tokens": ["Die", "gold\u00b7ne", "an", "fest\u00b7li\u00b7chen", ",", "die", "schwar\u00b7ze", "an", "Trau\u00b7er\u00b7ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ADJA", "$,", "PRELS", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+---+--+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Der Frohn nur wei\u00df es, wie man ihn l\u00f6sen und falten mu\u00df \u2013", "tokens": ["Der", "Frohn", "nur", "wei\u00df", "es", ",", "wie", "man", "ihn", "l\u00f6\u00b7sen", "und", "fal\u00b7ten", "mu\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "$,", "PWAV", "PIS", "PPER", "VVINF", "KON", "VVINF", "VMFIN", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Jetzt ist er eben daran, und sagt noch dies zum Schlu\u00df:", "tokens": ["Jetzt", "ist", "er", "e\u00b7ben", "da\u00b7ran", ",", "und", "sagt", "noch", "dies", "zum", "Schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PAV", "$,", "KON", "VVFIN", "ADV", "PDS", "APPRART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.42": {"line.1": {"text": "\u00bbwas macht's, da\u00df ich die Tische geschafft zum Schlo\u00df hinein?", "tokens": ["\u00bb", "was", "macht's", ",", "da\u00df", "ich", "die", "Ti\u00b7sche", "ge\u00b7schafft", "zum", "Schlo\u00df", "hin\u00b7ein", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Geschadet hat es Niemand \u2013 und Euch kann's n\u00fctzlich sein.", "tokens": ["Ge\u00b7scha\u00b7det", "hat", "es", "Nie\u00b7mand", "\u2013", "und", "Euch", "kann's", "n\u00fctz\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PIS", "$(", "KON", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hat doch um dieses Schlo\u00df sich der Proce\u00df entsponnen,", "tokens": ["Hat", "doch", "um", "die\u00b7ses", "Schlo\u00df", "sich", "der", "Pro\u00b7ce\u00df", "ent\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PDAT", "NN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und heute haben wir darauf ein Recht gewonnen.", "tokens": ["Und", "heu\u00b7te", "ha\u00b7ben", "wir", "da\u00b7rauf", "ein", "Recht", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da m\u00f6gen unsre Gegner noch so viel Ingrimm zeigen:", "tokens": ["Da", "m\u00f6\u00b7gen", "uns\u00b7re", "Geg\u00b7ner", "noch", "so", "viel", "In\u00b7grimm", "zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Ich weise nach, wir nahmen das alte Nest zu Eigen.", "tokens": ["Ich", "wei\u00b7se", "nach", ",", "wir", "nah\u00b7men", "das", "al\u00b7te", "Nest", "zu", "Ei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wer auf ein Schlo\u00df zur Mahlzeit l\u00e4dt eine ganze Schaar,", "tokens": ["Wer", "auf", "ein", "Schlo\u00df", "zur", "Mahl\u00b7zeit", "l\u00e4dt", "ei\u00b7ne", "gan\u00b7ze", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Sogar die Gegner selber sollen uns Zeugni\u00df geben:", "tokens": ["So\u00b7gar", "die", "Geg\u00b7ner", "sel\u00b7ber", "sol\u00b7len", "uns", "Zeug\u00b7ni\u00df", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Ich wei\u00df dergleichen F\u00e4lle genug aus meinem Leben.\u00ab", "tokens": ["Ich", "wei\u00df", "derg\u00b7lei\u00b7chen", "F\u00e4l\u00b7le", "ge\u00b7nug", "aus", "mei\u00b7nem", "Le\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIS", "NN", "ADV", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.43": {"line.1": {"text": "Schon schlief der Richter. Der Frohn geht sacht in's Vorhaus hinein,", "tokens": ["Schon", "schlief", "der", "Rich\u00b7ter", ".", "Der", "Frohn", "geht", "sacht", "in's", "Vor\u00b7haus", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Setzt sich und zieht aus der Tasche bei einer Kerze Schein", "tokens": ["Setzt", "sich", "und", "zieht", "aus", "der", "Ta\u00b7sche", "bei", "ei\u00b7ner", "Ker\u00b7ze", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "KON", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Ein B\u00fcchlein, das er immer und \u00fcberall mit sich tr\u00e4gt,", "tokens": ["Ein", "B\u00fcch\u00b7lein", ",", "das", "er", "im\u00b7mer", "und", "\u00fc\u00b7be\u00b7rall", "mit", "sich", "tr\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "KON", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zu Haus und auf der Reise, und wie ein Gebetbuch hegt.", "tokens": ["Zu", "Haus", "und", "auf", "der", "Rei\u00b7se", ",", "und", "wie", "ein", "Ge\u00b7bet\u00b7buch", "hegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ART", "NN", "$,", "KON", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--++-+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Es war die Gerichtsvocanda;", "tokens": ["Es", "war", "die", "Ge\u00b7richts\u00b7vo\u00b7can\u00b7da", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die F\u00e4lle all' verzeichnet, die vor dem Tribunal", "tokens": ["Die", "F\u00e4l\u00b7le", "all'", "ver\u00b7zeich\u00b7net", ",", "die", "vor", "dem", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIS", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Protasius selbst verk\u00fcndigt mit eignem Mund vor Jahren,", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "selbst", "ver\u00b7k\u00fcn\u00b7digt", "mit", "eig\u00b7nem", "Mund", "vor", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Oder von denen er sp\u00e4ter N\u00e4heres mocht' erfahren.", "tokens": ["O\u00b7der", "von", "de\u00b7nen", "er", "sp\u00e4\u00b7ter", "N\u00e4\u00b7he\u00b7res", "mocht'", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRELS", "PPER", "ADJD", "NN", "VMFIN", "VVINF", "$."], "meter": "+--+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "Andern scheint die Liste nur Namen zu enthalten,", "tokens": ["An\u00b7dern", "scheint", "die", "Lis\u00b7te", "nur", "Na\u00b7men", "zu", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "VVFIN", "ART", "NN", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Ihm ist sie ein Gem\u00e4lde voll herrlicher Gestalten.", "tokens": ["Ihm", "ist", "sie", "ein", "Ge\u00b7m\u00e4l\u00b7de", "voll", "herr\u00b7li\u00b7cher", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.11": {"text": "In Sinnen versunken, las er: Oginski mit Wizgird,", "tokens": ["In", "Sin\u00b7nen", "ver\u00b7sun\u00b7ken", ",", "las", "er", ":", "O\u00b7gins\u00b7ki", "mit", "Wiz\u00b7gird", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,", "VVFIN", "PPER", "$.", "NE", "APPR", "NN", "$,"], "meter": "-+--+-+--+-++-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die Dominikaner mit Rymsza, Rymsza mit Wyzogird,", "tokens": ["Die", "Do\u00b7mi\u00b7ni\u00b7ka\u00b7ner", "mit", "Ryms\u00b7za", ",", "Ryms\u00b7za", "mit", "Wy\u00b7zo\u00b7gird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "NE", "APPR", "NE", "$,"], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Radziwill mit Wereszczaka, Giedroic mit Rdultowski,", "tokens": ["Rad\u00b7zi\u00b7will", "mit", "We\u00b7resz\u00b7cza\u00b7ka", ",", "Gied\u00b7roic", "mit", "Rdul\u00b7tows\u00b7ki", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-+--+--", "measure": "trochaic.hexa.relaxed"}, "line.14": {"text": "Obuchowicz mit dem Kahal, Juraha mit Piotrowski,", "tokens": ["O\u00b7buc\u00b7ho\u00b7wicz", "mit", "dem", "Ka\u00b7hal", ",", "Ju\u00b7ra\u00b7ha", "mit", "Pio\u00b7trows\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "NE", "APPR", "NN", "$,"], "meter": "++-+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.15": {"text": "Malewski mit Mickiewicz, und zum Schlu\u00df der Graf", "tokens": ["Ma\u00b7lews\u00b7ki", "mit", "Mic\u00b7kie\u00b7wicz", ",", "und", "zum", "Schlu\u00df", "der", "Graf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NE", "$,", "KON", "APPRART", "NN", "ART", "NN"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Mit Richter Soplica; \u2013 und jeder Name, auf den er traf,", "tokens": ["Mit", "Rich\u00b7ter", "Sop\u00b7li\u00b7ca", ";", "\u2013", "und", "je\u00b7der", "Na\u00b7me", ",", "auf", "den", "er", "traf", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$.", "$(", "KON", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.17": {"text": "Mahnt ihn an gro\u00dfe H\u00e4ndel, an alle Einzelheiten,", "tokens": ["Mahnt", "ihn", "an", "gro\u00b7\u00dfe", "H\u00e4n\u00b7del", ",", "an", "al\u00b7le", "Ein\u00b7zel\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Er sieht Gericht und Zeugen, h\u00f6rt die Parteien streiten,", "tokens": ["Er", "sieht", "Ge\u00b7richt", "und", "Zeu\u00b7gen", ",", "h\u00f6rt", "die", "Par\u00b7tei\u00b7en", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Er sieht sich selbst, wie er im wei\u00dfen Zupan stand,", "tokens": ["Er", "sieht", "sich", "selbst", ",", "wie", "er", "im", "wei\u00b7\u00dfen", "Zu\u00b7pan", "stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "PWAV", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den blauen Kontusz dar\u00fcber, am S\u00e4bel die eine Hand,", "tokens": ["Den", "blau\u00b7en", "Kon\u00b7tusz", "da\u00b7r\u00fc\u00b7ber", ",", "am", "S\u00e4\u00b7bel", "die", "ei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "$,", "APPRART", "NN", "ART", "ART", "NN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Die andre auf dem Tisch \u2013 und vor dem Tribunal", "tokens": ["Die", "and\u00b7re", "auf", "dem", "Tisch", "\u2013", "und", "vor", "dem", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "$(", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Beide Parteien aufrief, und \u00bbRuhe!\u00ab laut befahl \u2013", "tokens": ["Bei\u00b7de", "Par\u00b7tei\u00b7en", "auf\u00b7rief", ",", "und", "\u00bb", "Ru\u00b7he", "!", "\u00ab", "laut", "be\u00b7fahl", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "KON", "$(", "NN", "$.", "$(", "ADJD", "VVFIN", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.23": {"text": "So tr\u00e4umend und leise betend schlo\u00df sodann zur Ruh'", "tokens": ["So", "tr\u00e4u\u00b7mend", "und", "lei\u00b7se", "be\u00b7tend", "schlo\u00df", "so\u00b7dann", "zur", "Ruh'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVPP", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Lithauens letzter Gerichtsfrohn sacht die Augen zu.", "tokens": ["Lit\u00b7hau\u00b7ens", "letz\u00b7ter", "Ge\u00b7richts\u00b7frohn", "sacht", "die", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.44": {"line.1": {"text": "Also war Spiel und Streit zu jener Zeit bestellt", "tokens": ["Al\u00b7so", "war", "Spiel", "und", "Streit", "zu", "je\u00b7ner", "Zeit", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVFIN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Im stillen Lithauerdorf, da rings die \u00fcbrige Welt", "tokens": ["Im", "stil\u00b7len", "Lit\u00b7hau\u00b7er\u00b7dorf", ",", "da", "rings", "die", "\u00fcb\u00b7ri\u00b7ge", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-++-+-+-+--+", "measure": "iambic.septa.chol"}, "line.3": {"text": "In Blut und Thr\u00e4nen schwamm; als jener Gott der Schlacht,", "tokens": ["In", "Blut", "und", "Thr\u00e4\u00b7nen", "schwamm", ";", "als", "je\u00b7ner", "Gott", "der", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$.", "KOUS", "PDAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit tausend Geschossen bewehrt, mit brausender Heeresmacht,", "tokens": ["Mit", "tau\u00b7send", "Ge\u00b7schos\u00b7sen", "be\u00b7wehrt", ",", "mit", "brau\u00b7sen\u00b7der", "Hee\u00b7res\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Zum silbernen Adler den goldnen gespannt an den Siegeswagen,", "tokens": ["Zum", "sil\u00b7ber\u00b7nen", "Ad\u00b7ler", "den", "gold\u00b7nen", "ge\u00b7spannt", "an", "den", "Sie\u00b7ges\u00b7wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}, "line.6": {"text": "Vom lybischen Sand dahinflog bis wo die Alpen ragen \u2013", "tokens": ["Vom", "ly\u00b7bi\u00b7schen", "Sand", "da\u00b7hin\u00b7flog", "bis", "wo", "die", "Al\u00b7pen", "ra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPR", "PWAV", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+--+-++-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Blitz schleudernd um Blitz: so sahen die Pyramiden ihn,", "tokens": ["Blitz", "schleu\u00b7dernd", "um", "Blitz", ":", "so", "sa\u00b7hen", "die", "Py\u00b7ra\u00b7mi\u00b7den", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "++--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "Marengo, Austerlitz, Ulm; Sieg und Erob'rung zieh'n", "tokens": ["Ma\u00b7ren\u00b7go", ",", "Aus\u00b7ter\u00b7litz", ",", "Ulm", ";", "Sieg", "und", "Er\u00b7ob'\u00b7rung", "zieh'n"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$.", "NN", "KON", "NN", "VVFIN"], "meter": "+--+---+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Mit allen den Heldennamen, die durch die Welt er trug,", "tokens": ["Mit", "al\u00b7len", "den", "Hel\u00b7den\u00b7na\u00b7men", ",", "die", "durch", "die", "Welt", "er", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Vom Nil gen Norden hin \u2013 bis an des Niemens Strand", "tokens": ["Vom", "Nil", "gen", "Nor\u00b7den", "hin", "\u2013", "bis", "an", "des", "Nie\u00b7mens", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "PTKVZ", "$(", "KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gleich einer ehernen Mauer, ihn Moskau's Heerschaar bannt,", "tokens": ["Gleich", "ei\u00b7ner", "e\u00b7her\u00b7nen", "Mau\u00b7er", ",", "ihn", "Mos\u00b7kau's", "Heer\u00b7schaar", "bannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PPER", "NE", "NN", "ADJD", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die da von Lithauens Grenzen abwehrt stark und fest", "tokens": ["Die", "da", "von", "Lit\u00b7hau\u00b7ens", "Gren\u00b7zen", "ab\u00b7wehrt", "stark", "und", "fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NE", "NN", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die Botschaft, die f\u00fcr Ru\u00dfland schrecklich, wie die Pest.", "tokens": ["Die", "Bot\u00b7schaft", ",", "die", "f\u00fcr", "Ru\u00df\u00b7land", "schreck\u00b7lich", ",", "wie", "die", "Pest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NE", "ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.45": {"line.1": {"text": "Und doch: wie ein Stein vom Himmel, kam Kunde dann und wann", "tokens": ["Und", "doch", ":", "wie", "ein", "Stein", "vom", "Him\u00b7mel", ",", "kam", "Kun\u00b7de", "dann", "und", "wann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "PWAV", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "NN", "ADV", "KON", "PWAV"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nach Lithauen. Manchmal bettelt um Brod ein alter Mann,", "tokens": ["Nach", "Lit\u00b7hau\u00b7en", ".", "Manch\u00b7mal", "bet\u00b7telt", "um", "Brod", "ein", "al\u00b7ter", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "ADV", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Ohne Fu\u00df oder Hand \u2013 der, wenn ihm die Gabe gespendet,", "tokens": ["Oh\u00b7ne", "Fu\u00df", "o\u00b7der", "Hand", "\u2013", "der", ",", "wenn", "ihm", "die", "Ga\u00b7be", "ge\u00b7spen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "ART", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Steh'n bleibt, und scheu die Blicke nach allen Seiten wendet.", "tokens": ["Steh'n", "bleibt", ",", "und", "scheu", "die", "Bli\u00b7cke", "nach", "al\u00b7len", "Sei\u00b7ten", "wen\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "KON", "ADJD", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und sieht er, da\u00df der Kreis von russischen S\u00f6ldnern frei,", "tokens": ["Und", "sieht", "er", ",", "da\u00df", "der", "Kreis", "von", "rus\u00b7si\u00b7schen", "S\u00f6ld\u00b7nern", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Von K\u00e4ppchen und rothen Kragen: dann sagt er, wer er sei:", "tokens": ["Von", "K\u00e4pp\u00b7chen", "und", "ro\u00b7then", "Kra\u00b7gen", ":", "dann", "sagt", "er", ",", "wer", "er", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Er ist ein Legionist. Zur Heimat, die er nicht mehr", "tokens": ["Er", "ist", "ein", "Le\u00b7gi\u00b7o\u00b7nist", ".", "Zur", "Hei\u00b7mat", ",", "die", "er", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "APPRART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ADV"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Vertheidigen kann, bringt er die alten Knochen her.", "tokens": ["Ver\u00b7thei\u00b7di\u00b7gen", "kann", ",", "bringt", "er", "die", "al\u00b7ten", "Kno\u00b7chen", "her", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "O wie ihn dann die Herrschaft, wie ihn das ganze Gesind'", "tokens": ["O", "wie", "ihn", "dann", "die", "Herr\u00b7schaft", ",", "wie", "ihn", "das", "gan\u00b7ze", "Ge\u00b7sind'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "PPER", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+-+--+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Hei\u00df in die Arme schlie\u00dft und laut zu schluchzen beginnt!", "tokens": ["Hei\u00df", "in", "die", "Ar\u00b7me", "schlie\u00dft", "und", "laut", "zu", "schluch\u00b7zen", "be\u00b7ginnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Dann setzt er sich an den Tisch, und seltsame Geschichten,", "tokens": ["Dann", "setzt", "er", "sich", "an", "den", "Tisch", ",", "und", "selt\u00b7sa\u00b7me", "Ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Erstaunlicher, als M\u00e4rchen, wei\u00df er zu berichten:", "tokens": ["Er\u00b7staun\u00b7li\u00b7cher", ",", "als", "M\u00e4r\u00b7chen", ",", "wei\u00df", "er", "zu", "be\u00b7rich\u00b7ten", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "NN", "$,", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie General Dombrowski", "tokens": ["Wie", "Ge\u00b7ne\u00b7ral", "Dom\u00b7brow\u00b7ski"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NN", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.14": {"text": "Nach Polen vorzudringen, wie er fern im S\u00fcd", "tokens": ["Nach", "Po\u00b7len", "vor\u00b7zu\u00b7drin\u00b7gen", ",", "wie", "er", "fern", "im", "S\u00fcd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVPP", "$,", "PWAV", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Um sich die Br\u00fcder sammelt, auf dem lombardischen Feld, \u2013", "tokens": ["Um", "sich", "die", "Br\u00fc\u00b7der", "sam\u00b7melt", ",", "auf", "dem", "lom\u00b7bar\u00b7di\u00b7schen", "Feld", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PRF", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "Wie vom Kapitol Kniaziewicz befiehlt, der m\u00e4cht'ge Held,", "tokens": ["Wie", "vom", "Ka\u00b7pi\u00b7tol", "Knia\u00b7zie\u00b7wicz", "be\u00b7fiehlt", ",", "der", "m\u00e4cht'\u00b7ge", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.17": {"text": "Und hundert blutige Fahnen", "tokens": ["Und", "hun\u00b7dert", "blu\u00b7ti\u00b7ge", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "CARD", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Hinwarf, entwunden alle den S\u00f6hnen der C\u00e4saren, \u2013", "tokens": ["Hin\u00b7warf", ",", "ent\u00b7wun\u00b7den", "al\u00b7le", "den", "S\u00f6h\u00b7nen", "der", "C\u00e4\u00b7sa\u00b7ren", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PIS", "ART", "NN", "ART", "NN", "$,", "$("], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.19": {"text": "Wie Jablonowski gar dahin sich aufgemacht,", "tokens": ["Wie", "Ja\u00b7blo\u00b7nows\u00b7ki", "gar", "da\u00b7hin", "sich", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "PAV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wo man den Zucker ausschmilzt,", "tokens": ["Wo", "man", "den", "Zu\u00b7cker", "aus\u00b7schmilzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.21": {"text": "Die w\u00fcrzigen W\u00e4lder bl\u00fch'n \u2013 die Mohren schl\u00e4gt er dort", "tokens": ["Die", "w\u00fcr\u00b7zi\u00b7gen", "W\u00e4l\u00b7der", "bl\u00fch'n", "\u2013", "die", "Moh\u00b7ren", "schl\u00e4gt", "er", "dort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Mit der Donaulegion \u2013 und m\u00f6cht' nach Polen fort.", "tokens": ["Mit", "der", "Do\u00b7nau\u00b7le\u00b7gi\u00b7on", "\u2013", "und", "m\u00f6cht'", "nach", "Po\u00b7len", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$(", "KON", "VMFIN", "APPR", "NE", "PTKVZ", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.23": {"text": "Die Reden des Alten kreisen dann im Dorf geheim,", "tokens": ["Die", "Re\u00b7den", "des", "Al\u00b7ten", "krei\u00b7sen", "dann", "im", "Dorf", "ge\u00b7heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Der Bursch, der sie vernommen, ist pl\u00f6tzlich nicht daheim \u2013", "tokens": ["Der", "Bursch", ",", "der", "sie", "ver\u00b7nom\u00b7men", ",", "ist", "pl\u00f6tz\u00b7lich", "nicht", "da\u00b7heim", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "VAFIN", "ADJD", "PTKNEG", "ADV", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Durch W\u00e4lder und Mor\u00e4ste stiehlt er sich unverzagt,", "tokens": ["Durch", "W\u00e4l\u00b7der", "und", "Mo\u00b7r\u00e4s\u00b7te", "stiehlt", "er", "sich", "un\u00b7ver\u00b7zagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Der Niemen rettet ihn, wenn ihn der Russe jagt,", "tokens": ["Der", "Nie\u00b7men", "ret\u00b7tet", "ihn", ",", "wenn", "ihn", "der", "Rus\u00b7se", "jagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Bis er unter den Wellen an's Herzogthum Warschau geschwommen,", "tokens": ["Bis", "er", "un\u00b7ter", "den", "Wel\u00b7len", "an's", "Her\u00b7zog\u00b7thum", "Warsc\u00b7hau", "ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "APPRART", "NN", "NN", "VVPP", "$,"], "meter": "+-+--+--+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.28": {"text": "Wo liebe Stimmen ihn gr\u00fc\u00dfen: \u00bbKamerad, sei willkommen!\u00ab", "tokens": ["Wo", "lie\u00b7be", "Stim\u00b7men", "ihn", "gr\u00fc\u00b7\u00dfen", ":", "\u00bb", "Ka\u00b7me\u00b7rad", ",", "sei", "will\u00b7kom\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "NN", "PPER", "VVINF", "$.", "$(", "NN", "$,", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Dann springt er auf einen H\u00fcgel vor dem Weitergehen,", "tokens": ["Dann", "springt", "er", "auf", "ei\u00b7nen", "H\u00fc\u00b7gel", "vor", "dem", "Wei\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und \u00fcber den Niemen ruft er den Russen: \u00bbAuf Wiedersehen!\u00ab", "tokens": ["Und", "\u00fc\u00b7ber", "den", "Nie\u00b7men", "ruft", "er", "den", "Rus\u00b7sen", ":", "\u00bb", "Auf", "Wie\u00b7der\u00b7se\u00b7hen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "APPR", "NN", "$.", "$("], "meter": "-+--+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Piotrowski, Obolewski, Rozycki, Janowicz,", "tokens": ["Pio\u00b7trows\u00b7ki", ",", "O\u00b7bo\u00b7lews\u00b7ki", ",", "Ro\u00b7zy\u00b7cki", ",", "Ja\u00b7no\u00b7wicz", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Brochocki, die Mierzejewski's und die Bernatowicz,", "tokens": ["Broc\u00b7ho\u00b7cki", ",", "die", "Mier\u00b7ze\u00b7jew\u00b7ski's", "und", "die", "Ber\u00b7na\u00b7to\u00b7wicz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+--++-+", "measure": "amphibrach.tri.plus"}, "line.33": {"text": "Kupsc, Gedymin und Andre \u2013 wer z\u00e4hlte alle die Schaaren,", "tokens": ["Kupsc", ",", "Ge\u00b7dy\u00b7min", "und", "And\u00b7re", "\u2013", "wer", "z\u00e4hl\u00b7te", "al\u00b7le", "die", "Schaa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "PIS", "$(", "PWS", "VVFIN", "PIS", "ART", "NN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.34": {"text": "Sie lie\u00dfen das Land und die Lieben, sie lie\u00dfen Alles fahren, \u2013", "tokens": ["Sie", "lie\u00b7\u00dfen", "das", "Land", "und", "die", "Lie\u00b7ben", ",", "sie", "lie\u00b7\u00dfen", "Al\u00b7les", "fah\u00b7ren", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$,", "PPER", "VVFIN", "PIS", "VVINF", "$,", "$("], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.35": {"text": "Und ihre G\u00fcter nahm der lange Arm des Czaren.", "tokens": ["Und", "ih\u00b7re", "G\u00fc\u00b7ter", "nahm", "der", "lan\u00b7ge", "Arm", "des", "Cza\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.46": {"line.1": {"text": "Zu Zeiten kam auch ein fremder Almosenier in's Land,", "tokens": ["Zu", "Zei\u00b7ten", "kam", "auch", "ein", "frem\u00b7der", "Al\u00b7mo\u00b7se\u00b7nier", "in's", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und wenn er mit den Schlo\u00dfherrn n\u00e4her ward bekannt,", "tokens": ["Und", "wenn", "er", "mit", "den", "Schlo\u00df\u00b7herrn", "n\u00e4\u00b7her", "ward", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADJD", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So trennt' er eine Zeitung aus dem Skapulier.", "tokens": ["So", "trennt'", "er", "ei\u00b7ne", "Zei\u00b7tung", "aus", "dem", "Ska\u00b7pu\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Anzahl der Soldaten war verzeichnet hier,", "tokens": ["Die", "An\u00b7zahl", "der", "Sol\u00b7da\u00b7ten", "war", "ver\u00b7zeich\u00b7net", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Legionenf\u00fchrer alle genannt \u2013 von allen", "tokens": ["Die", "Le\u00b7gi\u00b7o\u00b7nen\u00b7f\u00fch\u00b7rer", "al\u00b7le", "ge\u00b7nannt", "\u2013", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PIS", "VVPP", "$(", "APPR", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Erz\u00e4hlt, wie sie gesiegt oder im Kampf gefallen.", "tokens": ["Er\u00b7z\u00e4hlt", ",", "wie", "sie", "ge\u00b7siegt", "o\u00b7der", "im", "Kampf", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VVPP", "KON", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So mochte die Familie zum ersten Mal seit Jahren", "tokens": ["So", "moch\u00b7te", "die", "Fa\u00b7mi\u00b7lie", "zum", "ers\u00b7ten", "Mal", "seit", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "APPR", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Vom Leben, Ruhm und Tod des theuren Sohns erfahren;", "tokens": ["Vom", "Le\u00b7ben", ",", "Ruhm", "und", "Tod", "des", "theu\u00b7ren", "Sohns", "er\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man legte Trauer an. Doch scheu verschwieg der Mund,", "tokens": ["Man", "leg\u00b7te", "Trau\u00b7er", "an", ".", "Doch", "scheu", "ver\u00b7schwieg", "der", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "PTKVZ", "$.", "KON", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Um wen; in der Umgebung errieth man nur den Grund.", "tokens": ["Um", "wen", ";", "in", "der", "Um\u00b7ge\u00b7bung", "er\u00b7rieth", "man", "nur", "den", "Grund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "VVIZU", "$.", "APPR", "ART", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der Herrschaft stille Freude oder stiller Gram,", "tokens": ["Der", "Herr\u00b7schaft", "stil\u00b7le", "Freu\u00b7de", "o\u00b7der", "stil\u00b7ler", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das war die einzige Zeitung, die ihr zu Augen kam.", "tokens": ["Das", "war", "die", "ein\u00b7zi\u00b7ge", "Zei\u00b7tung", ",", "die", "ihr", "zu", "Au\u00b7gen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.47": {"line.1": {"text": "Ein solcher geheimer Bote mocht' auch Robak sein:", "tokens": ["Ein", "sol\u00b7cher", "ge\u00b7hei\u00b7mer", "Bo\u00b7te", "mocht'", "auch", "Ro\u00b7bak", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit dem Richter besprach er sich oftmals ganz allein;", "tokens": ["Mit", "dem", "Rich\u00b7ter", "be\u00b7sprach", "er", "sich", "oft\u00b7mals", "ganz", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PRF", "ADV", "ADV", "ADV", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Nach einem solchen Gespr\u00e4ch war in der Nachbarschaft", "tokens": ["Nach", "ei\u00b7nem", "sol\u00b7chen", "Ge\u00b7spr\u00e4ch", "war", "in", "der", "Nach\u00b7bar\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Stets etwas Neues verbreitet. Auch die Gestalt voll Kraft", "tokens": ["Stets", "et\u00b7was", "Neu\u00b7es", "ver\u00b7brei\u00b7tet", ".", "Auch", "die", "Ge\u00b7stalt", "voll", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$.", "ADV", "ART", "NN", "ADJD", "NN"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Zeigt, da\u00df der M\u00f6nch nicht immer die Kapuze getragen,", "tokens": ["Zeigt", ",", "da\u00df", "der", "M\u00f6nch", "nicht", "im\u00b7mer", "die", "Ka\u00b7pu\u00b7ze", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PTKNEG", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Und schwerlich sich von jeher im Kloster mocht' behagen.", "tokens": ["Und", "schwer\u00b7lich", "sich", "von", "je\u00b7her", "im", "Klos\u00b7ter", "mocht'", "be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPR", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Ein wenig ober der Schl\u00e4fe, \u00fcber dem rechten Ohr,", "tokens": ["Ein", "we\u00b7nig", "o\u00b7ber", "der", "Schl\u00e4\u00b7fe", ",", "\u00fc\u00b7ber", "dem", "rech\u00b7ten", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Tritt handbreit eine L\u00fccke in der Haut hervor,", "tokens": ["Tritt", "hand\u00b7breit", "ei\u00b7ne", "L\u00fc\u00b7cke", "in", "der", "Haut", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von einem Schu\u00df oder Stich ist eine Spur zu seh'n", "tokens": ["Von", "ei\u00b7nem", "Schu\u00df", "o\u00b7der", "Stich", "ist", "ei\u00b7ne", "Spur", "zu", "seh'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Am Kinn, \u2013 das ist ihm sicher nicht bei der Messe gescheh'n.", "tokens": ["Am", "Kinn", ",", "\u2013", "das", "ist", "ihm", "si\u00b7cher", "nicht", "bei", "der", "Mes\u00b7se", "ge\u00b7scheh'", "n."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPRART", "NN", "$,", "$(", "PDS", "VAFIN", "PPER", "ADJD", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-++-+--+", "measure": "iambic.septa.chol"}, "line.11": {"text": "Doch nicht blos in den Narben und in des Blickes Droh'n:", "tokens": ["Doch", "nicht", "blos", "in", "den", "Nar\u00b7ben", "und", "in", "des", "Bli\u00b7ckes", "Droh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "NN", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.12": {"text": "Er hatte was vom Kriegsmann in Gang und Stimme schon.", "tokens": ["Er", "hat\u00b7te", "was", "vom", "Kriegs\u00b7mann", "in", "Gang", "und", "Stim\u00b7me", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPRART", "NN", "APPR", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.48": {"line.1": {"text": "Wenn er sich vom Altar mit aufgehob'nen H\u00e4nden", "tokens": ["Wenn", "er", "sich", "vom", "Al\u00b7tar", "mit", "auf\u00b7ge\u00b7hob'\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beim \u00bbDominus Vobiscum!\u00ab sollt' zum Volke wenden,", "tokens": ["Beim", "\u00bb", "Do\u00b7mi\u00b7nus", "Vo\u00b7bis\u00b7cum", "!", "\u00ab", "sollt'", "zum", "Vol\u00b7ke", "wen\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "$(", "FM.la", "FM.la", "$.", "$(", "VMFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da konnt' er sich so flink umdreh'n mit einem Mal,", "tokens": ["Da", "konnt'", "er", "sich", "so", "flink", "um\u00b7dreh'n", "mit", "ei\u00b7nem", "Mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als w\u00e4r' ihm commandirt: \u00bbRechtsum!\u00ab vom General.", "tokens": ["Als", "w\u00e4r'", "ihm", "com\u00b7man\u00b7dirt", ":", "\u00bb", "Recht\u00b7sum", "!", "\u00ab", "vom", "Ge\u00b7ne\u00b7ral", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVPP", "$.", "$(", "ADV", "$.", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als redete ein Hauptmann vor der Escadron.", "tokens": ["Als", "re\u00b7de\u00b7te", "ein", "Haupt\u00b7mann", "vor", "der", "E\u00b7sca\u00b7dron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Me\u00dfnerbuben bemerkten das mit klugem Blick. \u2013", "tokens": ["Die", "Me\u00df\u00b7ner\u00b7bu\u00b7ben", "be\u00b7merk\u00b7ten", "das", "mit", "klu\u00b7gem", "Blick", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Auch war er viel vertrauter mit der Politik,", "tokens": ["Auch", "war", "er", "viel", "ver\u00b7trau\u00b7ter", "mit", "der", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als mit den Heil'gen. Fuhr er nach Almosen herum,", "tokens": ["Als", "mit", "den", "Heil'\u00b7gen", ".", "Fuhr", "er", "nach", "Al\u00b7mo\u00b7sen", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$.", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.9": {"text": "So that er sich gar h\u00e4ufig in der Kreisstadt um.", "tokens": ["So", "that", "er", "sich", "gar", "h\u00e4u\u00b7fig", "in", "der", "Kreis\u00b7stadt", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er steckte voller Gesch\u00e4fte; bald kommen Briefe an,", "tokens": ["Er", "steck\u00b7te", "vol\u00b7ler", "Ge\u00b7sch\u00e4f\u00b7te", ";", "bald", "kom\u00b7men", "Brie\u00b7fe", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$.", "ADV", "VVINF", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die er vor fremden Zeugen nicht er\u00f6ffnen kann,", "tokens": ["Die", "er", "vor", "frem\u00b7den", "Zeu\u00b7gen", "nicht", "er\u00b7\u00f6ff\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bald schickt er Boten aus, doch sagt er nie ein Wort,", "tokens": ["Bald", "schickt", "er", "Bo\u00b7ten", "aus", ",", "doch", "sagt", "er", "nie", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wohin und wozu; oft schl\u00fcpft er in die Schl\u00f6sser fort", "tokens": ["Wo\u00b7hin", "und", "wo\u00b7zu", ";", "oft", "schl\u00fcpft", "er", "in", "die", "Schl\u00f6s\u00b7ser", "fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "KON", "PWAV", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Bei Nacht \u2013 hat mit der Schlachta zu fl\u00fcstern allezeit,", "tokens": ["Bei", "Nacht", "\u2013", "hat", "mit", "der", "Schlach\u00b7ta", "zu", "fl\u00fcs\u00b7tern", "al\u00b7le\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "VAFIN", "APPR", "ART", "NN", "PTKZU", "VVINF", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Die D\u00f6rfer in der N\u00e4he durchstreift er weit und breit;", "tokens": ["Die", "D\u00f6r\u00b7fer", "in", "der", "N\u00e4\u00b7he", "durch\u00b7streift", "er", "weit", "und", "breit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Verhandelt mit den Bauern \u00f6fters in den Schenken", "tokens": ["Ver\u00b7han\u00b7delt", "mit", "den", "Bau\u00b7ern", "\u00f6f\u00b7ters", "in", "den", "Schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und mag die Rede immer nur auf's Ausland lenken.", "tokens": ["Und", "mag", "die", "Re\u00b7de", "im\u00b7mer", "nur", "auf's", "Aus\u00b7land", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Jetzt will er den Richter wecken, der schon seit einer Stunde", "tokens": ["Jetzt", "will", "er", "den", "Rich\u00b7ter", "we\u00b7cken", ",", "der", "schon", "seit", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,", "PRELS", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Im Schlafe liegt; gewi\u00df kommt er mit neuer Kunde.", "tokens": ["Im", "Schla\u00b7fe", "liegt", ";", "ge\u00b7wi\u00df", "kommt", "er", "mit", "neu\u00b7er", "Kun\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.49": {"line.1": {"text": "Lithauen! Wie die Gesundheit bist du, mein Vaterland!", "tokens": ["Lit\u00b7hau\u00b7en", "!", "Wie", "die", "Ge\u00b7sund\u00b7heit", "bist", "du", ",", "mein", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "PWAV", "ART", "NN", "VAFIN", "PPER", "$,", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Wer dich noch nie verloren, der hat dich nicht erkannt.", "tokens": ["Wer", "dich", "noch", "nie", "ver\u00b7lo\u00b7ren", ",", "der", "hat", "dich", "nicht", "er\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "ADV", "VVPP", "$,", "PRELS", "VAFIN", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "In deiner ganzen Sch\u00f6nheit prangst du heut' vor mir,", "tokens": ["In", "dei\u00b7ner", "gan\u00b7zen", "Sch\u00f6n\u00b7heit", "prangst", "du", "heut'", "vor", "mir", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So will ich von dir singen, \u2013 denn mich verlangt nach dir!", "tokens": ["So", "will", "ich", "von", "dir", "sin\u00b7gen", ",", "\u2013", "denn", "mich", "ver\u00b7langt", "nach", "dir", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PPER", "VVINF", "$,", "$(", "KON", "PPER", "VVFIN", "APPR", "PPER", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.50": {"line.1": {"text": "O heil'ge Jungfrau, Czenstochowa's Schirm und Schild,", "tokens": ["O", "heil'\u00b7ge", "Jung\u00b7frau", ",", "Czen\u00b7stocho\u00b7wa's", "Schirm", "und", "Schild", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,", "NE", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Leuchte der Ostrabrama! Du, deren Gnadenbild", "tokens": ["Leuch\u00b7te", "der", "O\u00b7strab\u00b7ra\u00b7ma", "!", "Du", ",", "de\u00b7ren", "Gna\u00b7den\u00b7bild"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "ART", "NN", "$.", "PPER", "$,", "PRELAT", "NN"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.3": {"text": "Schlo\u00df Nowogrodek und sein treues Volk bewacht:", "tokens": ["Schlo\u00df", "No\u00b7wo\u00b7gro\u00b7dek", "und", "sein", "treu\u00b7es", "Volk", "be\u00b7wacht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "KON", "PPOSAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie mich, als Kind, dein Wunder einst gesund gemacht,", "tokens": ["Wie", "mich", ",", "als", "Kind", ",", "dein", "Wun\u00b7der", "einst", "ge\u00b7sund", "ge\u00b7macht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "$,", "KOUS", "NN", "$,", "PPOSAT", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als von der weinenden Mutter in deinen Schutz gegeben,", "tokens": ["Als", "von", "der", "wei\u00b7nen\u00b7den", "Mut\u00b7ter", "in", "dei\u00b7nen", "Schutz", "ge\u00b7ge\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Ich das erstorb'ne Auge erhob zu neuem Leben,", "tokens": ["Ich", "das", "er\u00b7stor\u00b7b'\u00b7ne", "Au\u00b7ge", "er\u00b7hob", "zu", "neu\u00b7em", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Und konnte gleich zu Fu\u00df in deine Tempel geh'n,", "tokens": ["Und", "konn\u00b7te", "gleich", "zu", "Fu\u00df", "in", "dei\u00b7ne", "Tem\u00b7pel", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADV", "APPR", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Gerettet, Gott zu danken f\u00fcr's Heil, das mir gescheh'n:", "tokens": ["Ge\u00b7ret\u00b7tet", ",", "Gott", "zu", "dan\u00b7ken", "f\u00fcr's", "Heil", ",", "das", "mir", "ge\u00b7scheh'n", ":"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "NN", "PTKZU", "VVINF", "APPRART", "NN", "$,", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "So wird zum Schoo\u00df der Heimat dein Wunder uns wiederbringen!", "tokens": ["So", "wird", "zum", "Schoo\u00df", "der", "Hei\u00b7mat", "dein", "Wun\u00b7der", "uns", "wie\u00b7der\u00b7brin\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPRART", "NN", "ART", "NN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Indessen trage du mir der sehnenden Seele Schwingen", "tokens": ["In\u00b7des\u00b7sen", "tra\u00b7ge", "du", "mir", "der", "seh\u00b7nen\u00b7den", "See\u00b7le", "Schwin\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "PPER", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Zu jenen waldigen H\u00fcgeln, zu jenen gr\u00fcnen Auen,", "tokens": ["Zu", "je\u00b7nen", "wal\u00b7di\u00b7gen", "H\u00fc\u00b7geln", ",", "zu", "je\u00b7nen", "gr\u00fc\u00b7nen", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die weit und breit sich dehnen am Niemenstrom, dem blauen, \u2013", "tokens": ["Die", "weit", "und", "breit", "sich", "deh\u00b7nen", "am", "Nie\u00b7mens\u00b7trom", ",", "dem", "blau\u00b7en", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ART", "ADJD", "KON", "ADJD", "PRF", "PDS", "APPRART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Zu jenen Feldern, prangend voll bunter \u00c4hren und Garben,", "tokens": ["Zu", "je\u00b7nen", "Fel\u00b7dern", ",", "pran\u00b7gend", "voll", "bun\u00b7ter", "\u00c4h\u00b7ren", "und", "Gar\u00b7ben", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "$,", "ADJD", "ADJD", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "R\u00fcbsamen bernsteinhell, Buchweizen schneeig bl\u00fcht,", "tokens": ["R\u00fcb\u00b7sa\u00b7men", "bern\u00b7stein\u00b7hell", ",", "Buch\u00b7wei\u00b7zen", "schne\u00b7e\u00b7ig", "bl\u00fcht", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "$,", "NN", "ADJD", "VVFIN", "$,"], "meter": "----+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.15": {"text": "In jungfr\u00e4ulichem Roth der duftige Quendel gl\u00fcht,", "tokens": ["In", "jung\u00b7fr\u00e4u\u00b7li\u00b7chem", "Roth", "der", "duf\u00b7ti\u00b7ge", "Quen\u00b7del", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.16": {"text": "Und, wie ein Band, durch Alles der gr\u00fcne Rain sich schmiegt,", "tokens": ["Und", ",", "wie", "ein", "Band", ",", "durch", "Al\u00b7les", "der", "gr\u00fc\u00b7ne", "Rain", "sich", "schmiegt", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "ART", "NN", "$,", "APPR", "PIS", "ART", "ADJA", "NN", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Drauf da und dort ein Birnbaum still die Krone wiegt.", "tokens": ["Drauf", "da", "und", "dort", "ein", "Birn\u00b7baum", "still", "die", "Kro\u00b7ne", "wiegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "KON", "ADV", "ART", "NN", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.51": {"line.1": {"text": "Auf einem H\u00fcgel erhob sich mitten in solchem Land,", "tokens": ["Auf", "ei\u00b7nem", "H\u00fc\u00b7gel", "er\u00b7hob", "sich", "mit\u00b7ten", "in", "sol\u00b7chem", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PRF", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Von Birkengeh\u00f6lz umgeben, an eines B\u00e4chleins Rand,", "tokens": ["Von", "Bir\u00b7ken\u00b7ge\u00b7h\u00f6lz", "um\u00b7ge\u00b7ben", ",", "an", "ei\u00b7nes", "B\u00e4ch\u00b7leins", "Rand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "APPR", "ART", "NN", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein Herrenhaus, \u2013 von Holz, der Unterstock von Stein;", "tokens": ["Ein", "Her\u00b7ren\u00b7haus", ",", "\u2013", "von", "Holz", ",", "der", "Un\u00b7ter\u00b7stock", "von", "Stein", ";"], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "$(", "APPR", "NN", "$,", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Es leuchteten von Ferne die W\u00e4nde wei\u00df und rein,", "tokens": ["Es", "leuch\u00b7te\u00b7ten", "von", "Fer\u00b7ne", "die", "W\u00e4n\u00b7de", "wei\u00df", "und", "rein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "ART", "NN", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Das Wei\u00df vom dunklen Gr\u00fcn der Pappeln noch gehoben,", "tokens": ["Das", "Wei\u00df", "vom", "dunk\u00b7len", "Gr\u00fcn", "der", "Pap\u00b7peln", "noch", "ge\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die ihm zum Schutze dienen vor des Herbstwinds Toben;", "tokens": ["Die", "ihm", "zum", "Schut\u00b7ze", "die\u00b7nen", "vor", "des", "Herbst\u00b7winds", "To\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPRART", "NN", "VVINF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein wohnlich saub'res Haus, wenn auch von m\u00e4\u00dfiger Gr\u00f6\u00dfe,", "tokens": ["Ein", "wohn\u00b7lich", "saub'\u00b7res", "Haus", ",", "wenn", "auch", "von", "m\u00e4\u00b7\u00dfi\u00b7ger", "Gr\u00f6\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "ADJA", "NN", "$,", "KOUS", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Hat eine gro\u00dfe Scheuer, und drei Getreidest\u00f6\u00dfe", "tokens": ["Hat", "ei\u00b7ne", "gro\u00b7\u00dfe", "Scheu\u00b7er", ",", "und", "drei", "Ge\u00b7trei\u00b7de\u00b7st\u00f6\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$,", "KON", "CARD", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Liegen noch neben ihr \u2013 die fa\u00dfte der S\u00f6ller nicht mehr.", "tokens": ["Lie\u00b7gen", "noch", "ne\u00b7ben", "ihr", "\u2013", "die", "fa\u00df\u00b7te", "der", "S\u00f6l\u00b7ler", "nicht", "mehr", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "PPOSAT", "$(", "ART", "VVFIN", "ART", "NN", "PTKNEG", "ADV", "$."], "meter": "+-+-+--+--+--+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Man sieht wohl, reichgesegnet ist das Land umher.", "tokens": ["Man", "sieht", "wohl", ",", "reich\u00b7ge\u00b7seg\u00b7net", "ist", "das", "Land", "um\u00b7her", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "VVFIN", "VAFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Der Garben Zahl auch, die weit und breit auf dem Gelenge,", "tokens": ["Der", "Gar\u00b7ben", "Zahl", "auch", ",", "die", "weit", "und", "breit", "auf", "dem", "Ge\u00b7len\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "$,", "PRELS", "ADJD", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+--+--", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Wie Sterne, dicht ergl\u00e4nzen, und auch der Pfl\u00fcge Menge,", "tokens": ["Wie", "Ster\u00b7ne", ",", "dicht", "er\u00b7gl\u00e4n\u00b7zen", ",", "und", "auch", "der", "Pfl\u00fc\u00b7ge", "Men\u00b7ge", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "$,", "ADJD", "VVINF", "$,", "KON", "ADV", "ART", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die sich schon zeitig auf dem m\u00e4chtigen Brachfeld zeigen,", "tokens": ["Die", "sich", "schon", "zei\u00b7tig", "auf", "dem", "m\u00e4ch\u00b7ti\u00b7gen", "Brach\u00b7feld", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADV", "ADJD", "APPR", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Dem schwarzscholligen, (sicher derselben Herrschaft eigen", "tokens": ["Dem", "schwarz\u00b7schol\u00b7li\u00b7gen", ",", "(", "si\u00b7cher", "der\u00b7sel\u00b7ben", "Herr\u00b7schaft", "ei\u00b7gen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "$(", "ADJD", "PDAT", "NN", "ADJD"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Und wohl bestellt, es sieht wie Gartenbeete aus \u2013)", "tokens": ["Und", "wohl", "be\u00b7stellt", ",", "es", "sieht", "wie", "Gar\u00b7ten\u00b7bee\u00b7te", "aus", "\u2013", ")"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VVPP", "$,", "PPER", "VVFIN", "KOKOM", "NN", "PTKVZ", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das alles zeigt, da\u00df F\u00fclle und Ordnung herrscht im Haus;", "tokens": ["Das", "al\u00b7les", "zeigt", ",", "da\u00df", "F\u00fcl\u00b7le", "und", "Ord\u00b7nung", "herrscht", "im", "Haus", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Das Thor ist weitge\u00f6ffnet und sagt dem Wand'rer an,", "tokens": ["Das", "Thor", "ist", "weit\u00b7ge\u00f6ff\u00b7net", "und", "sagt", "dem", "Wan\u00b7d'\u00b7rer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVFIN", "KON", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.18": {"text": "Da\u00df freundlichen Empfang der Gast gew\u00e4rtigen kann.", "tokens": ["Da\u00df", "freund\u00b7li\u00b7chen", "Emp\u00b7fang", "der", "Gast", "ge\u00b7w\u00e4r\u00b7ti\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.52": {"line.1": {"text": "Ein zweisp\u00e4nniges Fuhrwerk kam eben durch das Thor,", "tokens": ["Ein", "zwei\u00b7sp\u00e4n\u00b7ni\u00b7ges", "Fuhr\u00b7werk", "kam", "e\u00b7ben", "durch", "das", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Flog um den Schlo\u00dfhof, f\u00e4hrt beim Gange wieder vor.", "tokens": ["Flog", "um", "den", "Schlo\u00df\u00b7hof", ",", "f\u00e4hrt", "beim", "Gan\u00b7ge", "wie\u00b7der", "vor", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ART", "NN", "$,", "VVFIN", "APPRART", "NN", "ADV", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ein junger Herr steigt aus; die verlassenen Pferde zieh'n", "tokens": ["Ein", "jun\u00b7ger", "Herr", "steigt", "aus", ";", "die", "ver\u00b7las\u00b7se\u00b7nen", "Pfer\u00b7de", "zieh'n"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "$.", "ART", "ADJA", "NN", "VVINF"], "meter": "-+-+----+--+-+", "measure": "iambic.penta.relaxed"}, "line.4": {"text": "Das Gras abrupfend, langsam wieder zur Einfahrt hin.", "tokens": ["Das", "Gras", "ab\u00b7rup\u00b7fend", ",", "lang\u00b7sam", "wie\u00b7der", "zur", "Ein\u00b7fahrt", "hin", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "ADJD", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Im Hof ist's \u00f6d'; ein Riegel verschlie\u00dft die Th\u00fcr zum Gang,", "tokens": ["Im", "Hof", "ist's", "\u00f6d'", ";", "ein", "Rie\u00b7gel", "ver\u00b7schlie\u00dft", "die", "Th\u00fcr", "zum", "Gang", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ADJD", "$.", "ART", "NN", "VVFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Von einem Pfl\u00f6ckchen durchsteckt. \u2013 Der Fremde fragt nicht lang,", "tokens": ["Von", "ei\u00b7nem", "Pfl\u00f6\u00b7ck\u00b7chen", "durch\u00b7steckt", ".", "\u2013", "Der", "Frem\u00b7de", "fragt", "nicht", "lang", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVPP", "$.", "$(", "ART", "NN", "VVFIN", "PTKNEG", "ADJD", "$,"], "meter": "-+-+---+-+-+-+", "measure": "unknown.measure.hexa"}, "line.7": {"text": "Sucht kein Gesinde auf: er \u00f6ffnet, ohne zu s\u00e4umen,", "tokens": ["Sucht", "kein", "Ge\u00b7sin\u00b7de", "auf", ":", "er", "\u00f6ff\u00b7net", ",", "oh\u00b7ne", "zu", "s\u00e4u\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIAT", "NN", "PTKVZ", "$.", "PPER", "VVFIN", "$,", "KOUI", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und tritt in's Haus. Wie lange war er nicht in den R\u00e4umen!", "tokens": ["Und", "tritt", "in's", "Haus", ".", "Wie", "lan\u00b7ge", "war", "er", "nicht", "in", "den", "R\u00e4u\u00b7men", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPRART", "NN", "$.", "PWAV", "ADV", "VAFIN", "PPER", "PTKNEG", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Bis nun hielt ihn die Schule in der Stadt entfernt, \u2013", "tokens": ["Bis", "nun", "hielt", "ihn", "die", "Schu\u00b7le", "in", "der", "Stadt", "ent\u00b7fernt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Wie wohl ist ihm! Er hat doch endlich ausgelernt!", "tokens": ["Wie", "wohl", "ist", "ihm", "!", "Er", "hat", "doch", "end\u00b7lich", "aus\u00b7ge\u00b7lernt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "PPER", "$.", "PPER", "VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nun wird von jeder Wand sein Blick so festgehalten,", "tokens": ["Nun", "wird", "von", "je\u00b7der", "Wand", "sein", "Blick", "so", "fest\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "PPOSAT", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Er gr\u00fc\u00dft sie mit vollem Herzen, die wohlbekannten, die alten!", "tokens": ["Er", "gr\u00fc\u00dft", "sie", "mit", "vol\u00b7lem", "Her\u00b7zen", ",", "die", "wohl\u00b7be\u00b7kann\u00b7ten", ",", "die", "al\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "ART", "ADJA", "$,", "ART", "ADJA", "$."], "meter": "-+--+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.53": {"line.1": {"text": "Der Hausrath ganz wie damals in seiner Kindheit Tagen;", "tokens": ["Der", "Haus\u00b7rath", "ganz", "wie", "da\u00b7mals", "in", "sei\u00b7ner", "Kind\u00b7heit", "Ta\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "KOKOM", "ADV", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+----+-+-+-", "measure": "unknown.measure.penta"}, "line.2": {"text": "Jetzt scheint ihm Alles freilich nicht mehr so gro\u00df, so sch\u00f6n; \u2013", "tokens": ["Jetzt", "scheint", "ihm", "Al\u00b7les", "frei\u00b7lich", "nicht", "mehr", "so", "gro\u00df", ",", "so", "sch\u00f6n", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PIS", "ADV", "PTKNEG", "ADV", "ADV", "ADJD", "$,", "ADV", "ADJD", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dieselben Bilder sieht er, die er damals geseh'n:", "tokens": ["Die\u00b7sel\u00b7ben", "Bil\u00b7der", "sieht", "er", ",", "die", "er", "da\u00b7mals", "ge\u00b7seh'n", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVFIN", "PPER", "$,", "PRELS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Hier in der Czamarka Kosciuszko, den Blick zum Himmel gekehrt,", "tokens": ["Hier", "in", "der", "Cza\u00b7mar\u00b7ka", "Ko\u00b7sciusz\u00b7ko", ",", "den", "Blick", "zum", "Him\u00b7mel", "ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NE", "NE", "$,", "ART", "NN", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+---+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Mit beiden H\u00e4nden h\u00e4lt er umspannt sein starkes Schwert,", "tokens": ["Mit", "bei\u00b7den", "H\u00e4n\u00b7den", "h\u00e4lt", "er", "um\u00b7spannt", "sein", "star\u00b7kes", "Schwert", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "So war er, als er einstmals am Altar geschworen,", "tokens": ["So", "war", "er", ",", "als", "er", "einst\u00b7mals", "am", "Al\u00b7tar", "ge\u00b7schwo\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "KOUS", "PPER", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Mit diesem Schwert zu verjagen die drei Usurpatoren", "tokens": ["Mit", "die\u00b7sem", "Schwert", "zu", "ver\u00b7ja\u00b7gen", "die", "drei", "U\u00b7sur\u00b7pa\u00b7to\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "PTKZU", "VVINF", "ART", "CARD", "NN"], "meter": "-+-+--+---+--+-", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Oder auf ihm zu verbluten. Im polnischen Gewand", "tokens": ["O\u00b7der", "auf", "ihm", "zu", "ver\u00b7blu\u00b7ten", ".", "Im", "pol\u00b7ni\u00b7schen", "Ge\u00b7wand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "PPER", "PTKZU", "VVINF", "$.", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.9": {"text": "Sitzt dort, die Freiheit betrauernd, Rejtan,", "tokens": ["Sitzt", "dort", ",", "die", "Frei\u00b7heit", "be\u00b7trau\u00b7ernd", ",", "Rej\u00b7tan", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["VVFIN", "ADV", "$,", "ART", "NN", "VVPP", "$,", "NE", "$,"], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.10": {"text": "Sieht man, auf's Herz gerichtet, ein blitzendes Messer ragen, \u2013", "tokens": ["Sieht", "man", ",", "auf's", "Herz", "ge\u00b7rich\u00b7tet", ",", "ein", "blit\u00b7zen\u00b7des", "Mes\u00b7ser", "ra\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PIS", "$,", "APPRART", "NN", "VVPP", "$,", "ART", "ADJA", "NN", "VVFIN", "$,", "$("], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ph\u00e4don und Cato's Leben sind vor ihm aufgeschlagen.", "tokens": ["Ph\u00e4\u00b7don", "und", "Ca\u00b7to's", "Le\u00b7ben", "sind", "vor", "ihm", "auf\u00b7ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NE", "NN", "VAFIN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und dort der junge Jasinski,", "tokens": ["Und", "dort", "der", "jun\u00b7ge", "Ja\u00b7sins\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.13": {"text": "Daneben Korsak, der niemals von seiner Seite kam,", "tokens": ["Da\u00b7ne\u00b7ben", "Kor\u00b7sak", ",", "der", "nie\u00b7mals", "von", "sei\u00b7ner", "Sei\u00b7te", "kam", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "$,", "PRELS", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Auf Praga's Schanzen steh'n sie, auf Russenhaufen beisammen,", "tokens": ["Auf", "Pra\u00b7ga's", "Schan\u00b7zen", "steh'n", "sie", ",", "auf", "Rus\u00b7sen\u00b7hau\u00b7fen", "bei\u00b7sam\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVFIN", "PPER", "$,", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "K\u00fchn hau'n sie drein, \u2013 und Praga steht schon ringsum in Flammen.", "tokens": ["K\u00fchn", "hau'n", "sie", "drein", ",", "\u2013", "und", "Pra\u00b7ga", "steht", "schon", "ring\u00b7sum", "in", "Flam\u00b7men", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "PTKVZ", "$,", "$(", "KON", "NE", "VVFIN", "ADV", "ADV", "APPR", "NN", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Und sieh', im Holzgeh\u00e4use, an der Alkoventh\u00fcr", "tokens": ["Und", "sieh'", ",", "im", "Holz\u00b7ge\u00b7h\u00e4u\u00b7se", ",", "an", "der", "Al\u00b7ko\u00b7vent\u00b7h\u00fcr"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "VVIMP", "$,", "APPRART", "NN", "$,", "APPR", "ART", "NN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Die alte liebe Spieluhr sogar erkennt er hier,", "tokens": ["Die", "al\u00b7te", "lie\u00b7be", "Spie\u00b7luhr", "so\u00b7gar", "er\u00b7kennt", "er", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-++-+-+-+", "measure": "unknown.measure.septa"}, "line.18": {"text": "Und zieht in kindischer Freude, wie einstmals, an der Schnur,", "tokens": ["Und", "zieht", "in", "kin\u00b7di\u00b7scher", "Freu\u00b7de", ",", "wie", "einst\u00b7mals", ",", "an", "der", "Schnur", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$,", "PWAV", "ADV", "$,", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und Dombrowski's alte Weise", "tokens": ["Und", "Dom\u00b7brow\u00b7ski's", "al\u00b7te", "Wei\u00b7se"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "NE", "ADJA", "NN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.54": {"line.1": {"text": "Er eilt durch's ganze Haus, nach jenem trauten St\u00fcbchen,", "tokens": ["Er", "eilt", "durch's", "gan\u00b7ze", "Haus", ",", "nach", "je\u00b7nem", "trau\u00b7ten", "St\u00fcb\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wo er vor zehn Jahren gespielt als kleines B\u00fcbchen.", "tokens": ["Wo", "er", "vor", "zehn", "Jah\u00b7ren", "ge\u00b7spielt", "als", "klei\u00b7nes", "B\u00fcb\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "CARD", "NN", "VVPP", "KOKOM", "ADJA", "NN", "$."], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "Kaum ist er eingetreten, stutzt er und weicht zur\u00fcck:", "tokens": ["Kaum", "ist", "er", "ein\u00b7ge\u00b7tre\u00b7ten", ",", "stutzt", "er", "und", "weicht", "zu\u00b7r\u00fcck", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$,", "VVFIN", "PPER", "KON", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Ein Frauengemach! Er mustert's mit erstauntem Blick;", "tokens": ["Ein", "Frau\u00b7en\u00b7ge\u00b7mach", "!", "Er", "mus\u00b7tert's", "mit", "er\u00b7staun\u00b7tem", "Blick", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PPER", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Wer mag hier wohnen? Der alte Oheim war unverm\u00e4hlt, \u2013", "tokens": ["Wer", "mag", "hier", "woh\u00b7nen", "?", "Der", "al\u00b7te", "O\u00b7heim", "war", "un\u00b7ver\u00b7m\u00e4hlt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWS", "VMFIN", "ADV", "VVINF", "$.", "ART", "ADJA", "NN", "VAFIN", "ADJD", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Die Tante hatte zum Wohnort Petersburg erw\u00e4hlt!", "tokens": ["Die", "Tan\u00b7te", "hat\u00b7te", "zum", "Wohn\u00b7ort", "Pe\u00b7ters\u00b7burg", "er\u00b7w\u00e4hlt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "NE", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Die Wirthschaftsfrau? Unm\u00f6glich! \u2013 Was soll der Fl\u00fcgel nur?", "tokens": ["Die", "Wirth\u00b7schafts\u00b7frau", "?", "Un\u00b7m\u00f6g\u00b7lich", "!", "\u2013", "Was", "soll", "der", "Fl\u00fc\u00b7gel", "nur", "?"], "token_info": ["word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "ADJD", "$.", "$(", "PWS", "VMFIN", "ART", "NN", "ADV", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.8": {"text": "Und Noten auf ihm und B\u00fccher, \u2013 von Ordnung keine Spur;", "tokens": ["Und", "No\u00b7ten", "auf", "ihm", "und", "B\u00fc\u00b7cher", ",", "\u2013", "von", "Ord\u00b7nung", "kei\u00b7ne", "Spur", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "KON", "NN", "$,", "$(", "APPR", "NN", "PIAT", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "In holdem Durcheinander Alles umhergezaust, \u2013", "tokens": ["In", "hol\u00b7dem", "Durch\u00b7ein\u00b7an\u00b7der", "Al\u00b7les", "um\u00b7her\u00b7ge\u00b7zaust", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "NN", "PIS", "VVFIN", "$,", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Das waren nicht alte H\u00e4ndchen, die da so gehaust.", "tokens": ["Das", "wa\u00b7ren", "nicht", "al\u00b7te", "H\u00e4nd\u00b7chen", ",", "die", "da", "so", "ge\u00b7haust", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJA", "NN", "$,", "PRELS", "ADV", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Und hier ein wei\u00dfes Kleid auf die Sessellehne gebreitet,", "tokens": ["Und", "hier", "ein", "wei\u00b7\u00dfes", "Kleid", "auf", "die", "Ses\u00b7sel\u00b7leh\u00b7ne", "ge\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Frisch vom Nagel geholt, zum Anzieh'n vorbereitet;", "tokens": ["Frisch", "vom", "Na\u00b7gel", "ge\u00b7holt", ",", "zum", "An\u00b7zieh'n", "vor\u00b7be\u00b7rei\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPRART", "NE", "VVPP", "$,", "APPRART", "NN", "VVPP", "$."], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.13": {"text": "Und auf den Fenstern duften, in Blument\u00f6pfen gehegt,", "tokens": ["Und", "auf", "den", "Fens\u00b7tern", "duf\u00b7ten", ",", "in", "Blu\u00b7men\u00b7t\u00f6p\u00b7fen", "ge\u00b7hegt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Geranium, Veilchen, Astern, Levkojen, wohlgepflegt;", "tokens": ["Ge\u00b7ra\u00b7ni\u00b7um", ",", "Veil\u00b7chen", ",", "As\u00b7tern", ",", "Lev\u00b7ko\u00b7jen", ",", "wohl\u00b7ge\u00b7pflegt", ";"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "NE", "$,", "VVFIN", "$."], "meter": "----+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Er tritt an eins der Fenster: ein neues Wunder, sieh'!", "tokens": ["Er", "tritt", "an", "eins", "der", "Fens\u00b7ter", ":", "ein", "neu\u00b7es", "Wun\u00b7der", ",", "sieh'", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PIS", "ART", "NN", "$.", "ART", "ADJA", "NN", "$,", "VVIMP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Im Obstgarten, am Rande, wo Unkraut sonst gedieh,", "tokens": ["Im", "Obst\u00b7gar\u00b7ten", ",", "am", "Ran\u00b7de", ",", "wo", "Un\u00b7kraut", "sonst", "ge\u00b7dieh", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "NN", "$,", "PWAV", "NN", "ADV", "VVFIN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Und Str\u00e4u\u00dfe von englischem Gras und M\u00fcnze allerwegen;", "tokens": ["Und", "Str\u00e4u\u00b7\u00dfe", "von", "eng\u00b7li\u00b7schem", "Gras", "und", "M\u00fcn\u00b7ze", "al\u00b7ler\u00b7we\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADJA", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Als Namenszug geformt, fa\u00dft es ein Z\u00e4unchen ein,", "tokens": ["Als", "Na\u00b7mens\u00b7zug", "ge\u00b7formt", ",", "fa\u00dft", "es", "ein", "Z\u00e4un\u00b7chen", "ein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "VVPP", "$,", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.19": {"text": "Ein winziges, h\u00f6lzernes, mit schimmernden Ma\u00dfliebreih'n;", "tokens": ["Ein", "win\u00b7zi\u00b7ges", ",", "h\u00f6l\u00b7zer\u00b7nes", ",", "mit", "schim\u00b7mern\u00b7den", "Ma\u00df\u00b7lieb\u00b7reih'n", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+--+---+--+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Die Beetchen waren frisch begossen von sorgender Hand,", "tokens": ["Die", "Beet\u00b7chen", "wa\u00b7ren", "frisch", "be\u00b7gos\u00b7sen", "von", "sor\u00b7gen\u00b7der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "VVPP", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Man sah noch das Blechgef\u00e4\u00df, das auf dem Boden stand.", "tokens": ["Man", "sah", "noch", "das", "Blech\u00b7ge\u00b7f\u00e4\u00df", ",", "das", "auf", "dem", "Bo\u00b7den", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Doch wo ist die G\u00e4rtnerin? sie war wohl eben hier;", "tokens": ["Doch", "wo", "ist", "die", "G\u00e4rt\u00b7ne\u00b7rin", "?", "sie", "war", "wohl", "e\u00b7ben", "hier", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "VAFIN", "ART", "NN", "$.", "PPER", "VAFIN", "ADV", "ADV", "ADV", "$."], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.23": {"text": "Noch zittert ja in den Angeln dort die kleine Th\u00fcr, \u2013", "tokens": ["Noch", "zit\u00b7tert", "ja", "in", "den", "An\u00b7geln", "dort", "die", "klei\u00b7ne", "Th\u00fcr", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "ADV", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Und nah' der Th\u00fcr im Sande, trocken, wei\u00df und fein,", "tokens": ["Und", "nah'", "der", "Th\u00fcr", "im", "San\u00b7de", ",", "tro\u00b7cken", ",", "wei\u00df", "und", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "ADJD", "$,", "VVFIN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "War eine Spur so leicht von einem F\u00fc\u00dfchen klein;", "tokens": ["War", "ei\u00b7ne", "Spur", "so", "leicht", "von", "ei\u00b7nem", "F\u00fc\u00df\u00b7chen", "klein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "ADJD", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Das hatte nicht Schuh, noch Strumpf \u2013 und rasch durchlief's den Raum,", "tokens": ["Das", "hat\u00b7te", "nicht", "Schuh", ",", "noch", "Strumpf", "\u2013", "und", "rasch", "durch\u00b7lie\u00b7f's", "den", "Raum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "NN", "$,", "ADV", "NN", "$(", "KON", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und wie es lief, man sieht's, ber\u00fchrt' es den Boden kaum.", "tokens": ["Und", "wie", "es", "lief", ",", "man", "sieht's", ",", "be\u00b7r\u00fchrt'", "es", "den", "Bo\u00b7den", "kaum", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "VVFIN", "$,", "PIS", "NE", "$,", "VVFIN", "PPER", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.55": {"line.1": {"text": "Der Fremde stand am Fenster und sann und schaute lange \u2013", "tokens": ["Der", "Frem\u00b7de", "stand", "am", "Fens\u00b7ter", "und", "sann", "und", "schau\u00b7te", "lan\u00b7ge", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPRART", "NN", "KON", "VVFIN", "KON", "VVFIN", "ADV", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Der Blumen s\u00fc\u00dfer Duft umspielt ihm Brust und Wange,", "tokens": ["Der", "Blu\u00b7men", "s\u00fc\u00b7\u00dfer", "Duft", "um\u00b7spielt", "ihm", "Brust", "und", "Wan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "PPER", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und bis zum Veilchenstrauch neigt er das Antlitz nieder,", "tokens": ["Und", "bis", "zum", "Veil\u00b7chen\u00b7strauch", "neigt", "er", "das", "Ant\u00b7litz", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Augen suchen umher \u2013 und bleiben haften wieder,", "tokens": ["Die", "Au\u00b7gen", "su\u00b7chen", "um\u00b7her", "\u2013", "und", "blei\u00b7ben", "haf\u00b7ten", "wie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$(", "KON", "VVINF", "VVFIN", "ADV", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Dort an den Spuren haften von jenen F\u00fc\u00dfchen klein \u2013", "tokens": ["Dort", "an", "den", "Spu\u00b7ren", "haf\u00b7ten", "von", "je\u00b7nen", "F\u00fc\u00df\u00b7chen", "klein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "APPR", "PDAT", "NN", "ADJD", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Er schaut' und sann: we\u00df mochten wohl die F\u00fc\u00dfchen sein?", "tokens": ["Er", "schaut'", "und", "sann", ":", "we\u00df", "moch\u00b7ten", "wohl", "die", "F\u00fc\u00df\u00b7chen", "sein", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "$.", "PWAV", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zuf\u00e4llig blickt er auf \u2013 und sieh', auf der Planke stand", "tokens": ["Zu\u00b7f\u00e4l\u00b7lig", "blickt", "er", "auf", "\u2013", "und", "sieh'", ",", "auf", "der", "Plan\u00b7ke", "stand"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "VVFIN", "PPER", "APPR", "$(", "KON", "VVFIN", "$,", "APPR", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Ein junges M\u00e4dchen, gekleidet in ein wei\u00df Gewand,", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", ",", "ge\u00b7klei\u00b7det", "in", "ein", "wei\u00df", "Ge\u00b7wand", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "VVPP", "APPR", "ART", "VVFIN", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Das von der Brust hinab den schlanken Leib umflo\u00df \u2013", "tokens": ["Das", "von", "der", "Brust", "hin\u00b7ab", "den", "schlan\u00b7ken", "Leib", "um\u00b7flo\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "APPR", "ART", "NN", "ADV", "ART", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Der Schwanenhals, die Arme blieben frei und blo\u00df.", "tokens": ["Der", "Schwa\u00b7nen\u00b7hals", ",", "die", "Ar\u00b7me", "blie\u00b7ben", "frei", "und", "blo\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "VVFIN", "ADJD", "KON", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So pflegt ein lithauisch M\u00e4dchen des Morgens nur zu geh'n,", "tokens": ["So", "pflegt", "ein", "lit\u00b7hau\u00b7isch", "M\u00e4d\u00b7chen", "des", "Mor\u00b7gens", "nur", "zu", "geh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJD", "NN", "ART", "ADV", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "So wird's von eines Mannes Augen nie geseh'n.", "tokens": ["So", "wird's", "von", "ei\u00b7nes", "Man\u00b7nes", "Au\u00b7gen", "nie", "ge\u00b7seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VAFIN", "APPR", "ART", "NN", "NN", "ADV", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Drum h\u00e4lt sie auch die H\u00e4nde ob der Brust verschr\u00e4nkt,", "tokens": ["Drum", "h\u00e4lt", "sie", "auch", "die", "H\u00e4n\u00b7de", "ob", "der", "Brust", "ver\u00b7schr\u00e4nkt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "KOUS", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wiewohl sie ja gewi\u00df an keine Lauscher denkt.", "tokens": ["Wie\u00b7wohl", "sie", "ja", "ge\u00b7wi\u00df", "an", "kei\u00b7ne", "Lau\u00b7scher", "denkt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADV", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das Haar, in Locken nicht gel\u00f6st, in kleine Kn\u00f6tchen", "tokens": ["Das", "Haar", ",", "in", "Lo\u00b7cken", "nicht", "ge\u00b7l\u00f6st", ",", "in", "klei\u00b7ne", "Kn\u00f6t\u00b7chen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "APPR", "NN", "PTKNEG", "VVPP", "$,", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Gebunden nur und rings besteckt mit wei\u00dfen Sch\u00f6tchen,", "tokens": ["Ge\u00b7bun\u00b7den", "nur", "und", "rings", "be\u00b7steckt", "mit", "wei\u00b7\u00dfen", "Sch\u00f6t\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "KON", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Ziert wundersam den Kopf, wie's in der Sonne strahlt:", "tokens": ["Ziert", "wun\u00b7der\u00b7sam", "den", "Kopf", ",", "wie's", "in", "der", "Son\u00b7ne", "strahlt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Den Kronen gleich, die man um Heiligenstirnen malt.", "tokens": ["Den", "Kro\u00b7nen", "gleich", ",", "die", "man", "um", "Hei\u00b7li\u00b7gen\u00b7stir\u00b7nen", "malt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "PIS", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Sie blickt in's Feld, das Antlitz ist drum nicht zu sehen,", "tokens": ["Sie", "blickt", "in's", "Feld", ",", "das", "Ant\u00b7litz", "ist", "drum", "nicht", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "$,", "ART", "NN", "VAFIN", "PAV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Dort unten weit, dort scheint sie nach Jemand auszusp\u00e4hen.", "tokens": ["Dort", "un\u00b7ten", "weit", ",", "dort", "scheint", "sie", "nach", "Je\u00b7mand", "aus\u00b7zu\u00b7sp\u00e4\u00b7hen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "$,", "ADV", "VVFIN", "PPER", "APPR", "PIS", "VVIZU", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Nun hat sie gefunden \u2013 lacht, klatscht in die Hand \u2013 und schnell,", "tokens": ["Nun", "hat", "sie", "ge\u00b7fun\u00b7den", "\u2013", "lacht", ",", "klatscht", "in", "die", "Hand", "\u2013", "und", "schnell", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "VVPP", "$(", "VVFIN", "$,", "VVFIN", "APPR", "ART", "NN", "$(", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Gleich wie ein wei\u00dfer Vogel, entfliegt sie von der Stell'", "tokens": ["Gleich", "wie", "ein", "wei\u00b7\u00dfer", "Vo\u00b7gel", ",", "ent\u00b7fliegt", "sie", "von", "der", "Stell'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Und flattert durch Garten und Blumen \u2013 und flink kommt sie gerannt", "tokens": ["Und", "flat\u00b7tert", "durch", "Gar\u00b7ten", "und", "Blu\u00b7men", "\u2013", "und", "flink", "kommt", "sie", "ge\u00b7rannt"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "NN", "KON", "NN", "$(", "KON", "ADJD", "VVFIN", "PPER", "VVPP"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.24": {"text": "Und eh' er's merkt, da fliegt sie schon durch's Fenster herein,", "tokens": ["Und", "eh'", "er's", "merkt", ",", "da", "fliegt", "sie", "schon", "durch's", "Fens\u00b7ter", "her\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.25": {"text": "So still und leicht und gl\u00e4nzend, wie des Mondes Schein.", "tokens": ["So", "still", "und", "leicht", "und", "gl\u00e4n\u00b7zend", ",", "wie", "des", "Mon\u00b7des", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "KON", "ADJD", "$,", "PWAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Und summend ergreift sie das Kleid, will sich zum Spiegel wenden:", "tokens": ["Und", "sum\u00b7mend", "er\u00b7greift", "sie", "das", "Kleid", ",", "will", "sich", "zum", "Spie\u00b7gel", "wen\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "ART", "NN", "$,", "VMFIN", "PRF", "APPRART", "NN", "VVINF", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.27": {"text": "Da sieht sie den J\u00fcngling \u2013 das Kleidchen f\u00e4llt ihr aus den H\u00e4nden \u2013", "tokens": ["Da", "sieht", "sie", "den", "J\u00fcng\u00b7ling", "\u2013", "das", "Kleid\u00b7chen", "f\u00e4llt", "ihr", "aus", "den", "H\u00e4n\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$(", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "Bleich wird sie vor Staunen und Schreck \u2013 roth wird sein Angesicht,", "tokens": ["Bleich", "wird", "sie", "vor", "Stau\u00b7nen", "und", "Schreck", "\u2013", "roth", "wird", "sein", "An\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "PPER", "APPR", "NN", "KON", "NN", "$(", "ADJD", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.29": {"text": "Gleich dem Gew\u00f6lk, das hinflie\u00dft durch des Morgens Licht.", "tokens": ["Gleich", "dem", "Ge\u00b7w\u00f6lk", ",", "das", "hin\u00b7flie\u00dft", "durch", "des", "Mor\u00b7gens", "Licht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "PDS", "VVFIN", "APPR", "ART", "ADV", "NN", "$."], "meter": "++-+-+-+-+-+", "measure": "unknown.measure.septa"}, "line.30": {"text": "Er dr\u00fcckt die Augen zu, bedeckt sie in scheuem Schweigen \u2013", "tokens": ["Er", "dr\u00fcckt", "die", "Au\u00b7gen", "zu", ",", "be\u00b7deckt", "sie", "in", "scheu\u00b7em", "Schwei\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKVZ", "$,", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Will reden, Entschuldigung stammeln \u2013 kann sich nur verneigen", "tokens": ["Will", "re\u00b7den", ",", "Ent\u00b7schul\u00b7di\u00b7gung", "stam\u00b7meln", "\u2013", "kann", "sich", "nur", "ver\u00b7nei\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VMFIN", "VVINF", "$,", "NN", "VVFIN", "$(", "VMFIN", "PRF", "ADV", "VVINF"], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.32": {"text": "Und tritt zur\u00fcck. Und schmerzlich schrie auf die holde Maid,", "tokens": ["Und", "tritt", "zu\u00b7r\u00fcck", ".", "Und", "schmerz\u00b7lich", "schrie", "auf", "die", "hol\u00b7de", "Maid", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKVZ", "$.", "KON", "ADJD", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "Undeutlich, wie ein Kind furchtsam im Schlafe schreit.", "tokens": ["Un\u00b7deut\u00b7lich", ",", "wie", "ein", "Kind", "furcht\u00b7sam", "im", "Schla\u00b7fe", "schreit", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "PWAV", "ART", "NN", "ADJD", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Erschrocken blickt' er auf \u2013 doch sie war nicht mehr da,", "tokens": ["Er\u00b7schro\u00b7cken", "blickt'", "er", "auf", "\u2013", "doch", "sie", "war", "nicht", "mehr", "da", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "$(", "KON", "PPER", "VAFIN", "PTKNEG", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Verwirrt ging er hinaus, wu\u00dft' nicht wie ihm geschah:", "tokens": ["Ver\u00b7wirrt", "ging", "er", "hin\u00b7aus", ",", "wu\u00dft'", "nicht", "wie", "ihm", "ge\u00b7schah", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PTKVZ", "$,", "VVFIN", "PTKNEG", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Sollt' er sich freu'n darob, was da sich zugetragen?", "tokens": ["Sollt'", "er", "sich", "freu'n", "da\u00b7rob", ",", "was", "da", "sich", "zu\u00b7ge\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "VVFIN", "PAV", "$,", "PRELS", "ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.37": {"text": "Sich sch\u00e4men? oder lachen? er konnt' es selbst nicht sagen.", "tokens": ["Sich", "sch\u00e4\u00b7men", "?", "o\u00b7der", "la\u00b7chen", "?", "er", "konnt'", "es", "selbst", "nicht", "sa\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "VVINF", "$.", "KON", "VVINF", "$.", "PPER", "VMFIN", "PPER", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.56": {"line.1": {"text": "Im Meierhof inde\u00df hat man schon wahrgenommen,", "tokens": ["Im", "Mei\u00b7er\u00b7hof", "in\u00b7de\u00df", "hat", "man", "schon", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df heut' ein neuer Gast im Hause angekommen.", "tokens": ["Da\u00df", "heut'", "ein", "neu\u00b7er", "Gast", "im", "Hau\u00b7se", "an\u00b7ge\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Schon hatte man die Pferde in den Stall gebracht,", "tokens": ["Schon", "hat\u00b7te", "man", "die", "Pfer\u00b7de", "in", "den", "Stall", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIS", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und, wie sich ziemt, sie reichlich mit Hafer und Heu bedacht.", "tokens": ["Und", ",", "wie", "sich", "ziemt", ",", "sie", "reich\u00b7lich", "mit", "Ha\u00b7fer", "und", "Heu", "be\u00b7dacht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PRF", "VVFIN", "$,", "PPER", "ADJD", "APPR", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Der Richter leidet sie nicht, alle die neuen Manieren,", "tokens": ["Der", "Rich\u00b7ter", "lei\u00b7det", "sie", "nicht", ",", "al\u00b7le", "die", "neu\u00b7en", "Ma\u00b7nie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "PIS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Da\u00df man beim Juden l\u00e4\u00dft die Pferde einquartieren.", "tokens": ["Da\u00df", "man", "beim", "Ju\u00b7den", "l\u00e4\u00dft", "die", "Pfer\u00b7de", "ein\u00b7quar\u00b7tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPRART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Kein Diener kommt ihm entgegen; doch meine darum nicht,", "tokens": ["Kein", "Die\u00b7ner", "kommt", "ihm", "ent\u00b7ge\u00b7gen", ";", "doch", "mei\u00b7ne", "da\u00b7rum", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "ADV", "PPOSAT", "PAV", "PTKNEG", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Da\u00df man in Richters Hause vers\u00e4ume Dienstespflicht.", "tokens": ["Da\u00df", "man", "in", "Rich\u00b7ters", "Hau\u00b7se", "ver\u00b7s\u00e4u\u00b7me", "Diens\u00b7tes\u00b7pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "APPR", "NE", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Sie warten bis der Wojski im Staat erscheinen kann,", "tokens": ["Sie", "war\u00b7ten", "bis", "der", "Wojs\u00b7ki", "im", "Staat", "er\u00b7schei\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "APPRART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der ordnet hinter dem Hause eben das Nachtmahl an:", "tokens": ["Der", "ord\u00b7net", "hin\u00b7ter", "dem", "Hau\u00b7se", "e\u00b7ben", "das", "Nacht\u00b7mahl", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ein Hausfreund ist's, dem Richter auch entfernt verwandt,", "tokens": ["Ein", "Haus\u00b7freund", "ist's", ",", "dem", "Rich\u00b7ter", "auch", "ent\u00b7fernt", "ver\u00b7wandt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "ART", "NN", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Der in der Regel die G\u00e4ste, wenn nicht der Herr zur Hand,", "tokens": ["Der", "in", "der", "Re\u00b7gel", "die", "G\u00e4s\u00b7te", ",", "wenn", "nicht", "der", "Herr", "zur", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "NN", "ART", "NN", "$,", "KOUS", "PTKNEG", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Empf\u00e4ngt und unterh\u00e4lt. Sobald der Fremde erschien,", "tokens": ["Emp\u00b7f\u00e4ngt", "und", "un\u00b7ter\u00b7h\u00e4lt", ".", "So\u00b7bald", "der", "Frem\u00b7de", "er\u00b7schien", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVFIN", "$.", "KOUS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.14": {"text": "Sucht' er in aller Stille in's Vorwerk zu entflieh'n;", "tokens": ["Sucht'", "er", "in", "al\u00b7ler", "Stil\u00b7le", "in's", "Vor\u00b7werk", "zu", "ent\u00b7flieh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PIAT", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.15": {"text": "Da er im Pudermantel nicht gut empfangen kann,", "tokens": ["Da", "er", "im", "Pu\u00b7der\u00b7man\u00b7tel", "nicht", "gut", "emp\u00b7fan\u00b7gen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "PTKNEG", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Legt er nun m\u00f6glichst rasch die Sonntagskleider an;", "tokens": ["Legt", "er", "nun", "m\u00f6g\u00b7lichst", "rasch", "die", "Sonn\u00b7tags\u00b7klei\u00b7der", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADV", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die lagen seit fr\u00fch bereit \u2013 denn da schon hatt' er vernommen,", "tokens": ["Die", "la\u00b7gen", "seit", "fr\u00fch", "be\u00b7reit", "\u2013", "denn", "da", "schon", "hatt'", "er", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJD", "ADJD", "$(", "KON", "ADV", "ADV", "VAFIN", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Da\u00df heute viele G\u00e4ste zur Abendmahlzeit kommen.", "tokens": ["Da\u00df", "heu\u00b7te", "vie\u00b7le", "G\u00e4s\u00b7te", "zur", "A\u00b7bend\u00b7mahl\u00b7zeit", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.57": {"line.1": {"text": "Von fern erkennt er den Gast; mit lautem Freudenschrei,", "tokens": ["Von", "fern", "er\u00b7kennt", "er", "den", "Gast", ";", "mit", "lau\u00b7tem", "Freu\u00b7den\u00b7schrei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJD", "VVFIN", "PPER", "ART", "NN", "$.", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit ausgebreiteten Armen eilt er nun herbei,", "tokens": ["Mit", "aus\u00b7ge\u00b7brei\u00b7te\u00b7ten", "Ar\u00b7men", "eilt", "er", "nun", "her\u00b7bei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "ADV", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Von Jahren erz\u00e4hlte man gern in wenigen Worten geschwind,", "tokens": ["Von", "Jah\u00b7ren", "er\u00b7z\u00e4hl\u00b7te", "man", "gern", "in", "we\u00b7ni\u00b7gen", "Wor\u00b7ten", "ge\u00b7schwind", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PIS", "ADV", "APPR", "PIAT", "NN", "VVPP", "$,"], "meter": "-+--+--+-+--+--+", "measure": "amphibrach.tri.plus"}, "line.4": {"text": "Stets unterbrochen von Fragen und Seufzern und Entz\u00fccken,", "tokens": ["Stets", "un\u00b7ter\u00b7bro\u00b7chen", "von", "Fra\u00b7gen", "und", "Seuf\u00b7zern", "und", "Ent\u00b7z\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "APPR", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ausrufen, neuen Gr\u00fc\u00dfen und neuen H\u00e4ndedr\u00fccken.", "tokens": ["Aus\u00b7ru\u00b7fen", ",", "neu\u00b7en", "Gr\u00fc\u00b7\u00dfen", "und", "neu\u00b7en", "H\u00e4n\u00b7de\u00b7dr\u00fc\u00b7cken", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Als endlich der Wojski genug hat an aller Art Berichten,", "tokens": ["Als", "end\u00b7lich", "der", "Wojs\u00b7ki", "ge\u00b7nug", "hat", "an", "al\u00b7ler", "Art", "Be\u00b7rich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VAFIN", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.7": {"text": "Erz\u00e4hlt er ganz zum Schlu\u00df des heutigen Tags Geschichten:", "tokens": ["Er\u00b7z\u00e4hlt", "er", "ganz", "zum", "Schlu\u00df", "des", "heu\u00b7ti\u00b7gen", "Tags", "Ge\u00b7schich\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "APPRART", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.58": {"line.1": {"text": "\u00bbgut, mein Thadd\u00e4us,\u00ab sagt' er \u2013 (so war der J\u00fcngling genannt;", "tokens": ["\u00bb", "gut", ",", "mein", "Thad\u00b7d\u00e4us", ",", "\u00ab", "sagt'", "er", "\u2013", "(", "so", "war", "der", "J\u00fcng\u00b7ling", "ge\u00b7nannt", ";"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,", "$(", "VVFIN", "PPER", "$(", "$(", "ADV", "VAFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.2": {"text": "Als er zur Welt gekommen, war der Krieg im Land,", "tokens": ["Als", "er", "zur", "Welt", "ge\u00b7kom\u00b7men", ",", "war", "der", "Krieg", "im", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VVPP", "$,", "VAFIN", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da hatte man ihm den Namen von Kosciuszko gegeben);", "tokens": ["Da", "hat\u00b7te", "man", "ihm", "den", "Na\u00b7men", "von", "Ko\u00b7sciusz\u00b7ko", "ge\u00b7ge\u00b7ben", ")", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VAFIN", "PIS", "PPER", "ART", "NN", "APPR", "NE", "VVPP", "$(", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "\u00bbgut, mein Thadd\u00e4us, da\u00df du heim kommst ", "tokens": ["\u00bb", "gut", ",", "mein", "Thad\u00b7d\u00e4us", ",", "da\u00df", "du", "heim", "kommst"], "token_info": ["punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,", "KOUS", "PPER", "PTKVZ", "VVFIN"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.5": {"text": "Da wir so viele M\u00e4dchen bei uns im Hause sehen;", "tokens": ["Da", "wir", "so", "vie\u00b7le", "M\u00e4d\u00b7chen", "bei", "uns", "im", "Hau\u00b7se", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIAT", "NN", "APPR", "PPER", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wir d\u00fcrften ja in Kurzem hier deine Hochzeit begehen:", "tokens": ["Wir", "d\u00fcrf\u00b7ten", "ja", "in", "Kur\u00b7zem", "hier", "dei\u00b7ne", "Hoch\u00b7zeit", "be\u00b7ge\u00b7hen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So meint der Onkel. \u2013 An Auswahl fehlt es g'rade nicht;", "tokens": ["So", "meint", "der", "On\u00b7kel", ".", "\u2013", "An", "Aus\u00b7wahl", "fehlt", "es", "g'\u00b7ra\u00b7de", "nicht", ";"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "$(", "APPR", "NN", "VVFIN", "PPER", "VVFIN", "PTKNEG", "$."], "meter": "-+-+-+--+----+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Viel Leute sind jetzt bei uns versammelt zum Grenzgericht,", "tokens": ["Viel", "Leu\u00b7te", "sind", "jetzt", "bei", "uns", "ver\u00b7sam\u00b7melt", "zum", "Grenz\u00b7ge\u00b7richt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--++--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Den Handel mit dem Grafen, der sich schon schleppt seit Jahren,", "tokens": ["Den", "Han\u00b7del", "mit", "dem", "Gra\u00b7fen", ",", "der", "sich", "schon", "schleppt", "seit", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "PRELS", "PRF", "ADV", "VVFIN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Zu endigen. Er selbst kommt morgen hergefahren.", "tokens": ["Zu", "en\u00b7di\u00b7gen", ".", "Er", "selbst", "kommt", "mor\u00b7gen", "her\u00b7ge\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "$.", "PPER", "ADV", "VVFIN", "ADV", "VVINF", "$."], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.11": {"text": "Der K\u00e4mmerer", "tokens": ["Der", "K\u00e4m\u00b7me\u00b7rer"], "token_info": ["word", "word"], "pos": ["ART", "NN"], "meter": "-+--", "measure": "dactylic.init"}, "line.12": {"text": "Die Jugend ist im Wald und jagt dort im Revier \u2013", "tokens": ["Die", "Ju\u00b7gend", "ist", "im", "Wald", "und", "jagt", "dort", "im", "Re\u00b7vier", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NN", "KON", "VVFIN", "ADV", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+++", "measure": "unknown.measure.septa"}, "line.13": {"text": "Die Alten und die Damen sehen sich nahe beim Wald", "tokens": ["Die", "Al\u00b7ten", "und", "die", "Da\u00b7men", "se\u00b7hen", "sich", "na\u00b7he", "beim", "Wald"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN", "PRF", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die Ernte an. Dahin kommt auch die Jugend bald.", "tokens": ["Die", "Ern\u00b7te", "an", ".", "Da\u00b7hin", "kommt", "auch", "die", "Ju\u00b7gend", "bald", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "$.", "PAV", "VVFIN", "ADV", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Willst du, so geh'n wir hin, da wirst du sie gleich erschauen:", "tokens": ["Willst", "du", ",", "so", "geh'n", "wir", "hin", ",", "da", "wirst", "du", "sie", "gleich", "er\u00b7schau\u00b7en", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "$,", "ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ADV", "VAFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "+--+---+--+-+-", "measure": "dactylic.di.plus"}, "line.16": {"text": "Den Onkel, die K\u00e4mm'rerschaft und die geehrten Frauen.\u00ab", "tokens": ["Den", "On\u00b7kel", ",", "die", "K\u00e4m\u00b7m'\u00b7rer\u00b7schaft", "und", "die", "ge\u00b7ehr\u00b7ten", "Frau\u00b7en", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "KON", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+++-+-+-+-+-", "measure": "unknown.measure.octa.plus"}}, "stanza.59": {"line.1": {"text": "Nun haben sie den Weg zum Walde eingeschlagen", "tokens": ["Nun", "ha\u00b7ben", "sie", "den", "Weg", "zum", "Wal\u00b7de", "ein\u00b7ge\u00b7schla\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "ART", "NN", "APPRART", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und thun sich nimmer genug mit Sagen und mit Fragen \u2013", "tokens": ["Und", "thun", "sich", "nim\u00b7mer", "ge\u00b7nug", "mit", "Sa\u00b7gen", "und", "mit", "Fra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "APPR", "NN", "KON", "APPR", "NN", "$("], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Sonne sank. Sie strahlte wol in schw\u00e4cherem Glanz,", "tokens": ["Die", "Son\u00b7ne", "sank", ".", "Sie", "strahl\u00b7te", "wol", "in", "schw\u00e4\u00b7che\u00b7rem", "Glanz", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.4": {"text": "Doch breiter, als bei Tage \u2013 und ger\u00f6thet ganz,", "tokens": ["Doch", "brei\u00b7ter", ",", "als", "bei", "Ta\u00b7ge", "\u2013", "und", "ge\u00b7r\u00f6\u00b7thet", "ganz", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "$,", "KOUS", "APPR", "NN", "$(", "KON", "VVFIN", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Gleich wie des Ackermanns gesundes Antlitz gl\u00fcht,", "tokens": ["Gleich", "wie", "des", "A\u00b7cker\u00b7manns", "ge\u00b7sun\u00b7des", "Ant\u00b7litz", "gl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wenn er den langen Tag sich auf dem Feld gem\u00fcht", "tokens": ["Wenn", "er", "den", "lan\u00b7gen", "Tag", "sich", "auf", "dem", "Feld", "ge\u00b7m\u00fcht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "ADJA", "NN", "PRF", "APPR", "ART", "NN", "VVPP"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Und nun zur Ruhe geht. Schon auf des Waldes Wipfel", "tokens": ["Und", "nun", "zur", "Ru\u00b7he", "geht", ".", "Schon", "auf", "des", "Wal\u00b7des", "Wip\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPRART", "NN", "VVFIN", "$.", "ADV", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Senkt sich die Scheibe nieder, und Gezweig und Gipfel", "tokens": ["Senkt", "sich", "die", "Schei\u00b7be", "nie\u00b7der", ",", "und", "Ge\u00b7zweig", "und", "Gip\u00b7fel"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "NN", "PTKVZ", "$,", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Erf\u00fcllt ein neblicht Dunkel, das in Eines schlie\u00dft", "tokens": ["Er\u00b7f\u00fcllt", "ein", "neb\u00b7licht", "Dun\u00b7kel", ",", "das", "in", "Ei\u00b7nes", "schlie\u00dft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "ART", "APPR", "NN", "$,", "PRELS", "APPR", "PIS", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Den ganzen weiten Wald und wie zusammengie\u00dft.", "tokens": ["Den", "gan\u00b7zen", "wei\u00b7ten", "Wald", "und", "wie", "zu\u00b7sam\u00b7men\u00b7gie\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ADJA", "NN", "KON", "PWAV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Und schwarz und schw\u00e4rzer wird er, ein riesengro\u00df Gemach,", "tokens": ["Und", "schwarz", "und", "schw\u00e4r\u00b7zer", "wird", "er", ",", "ein", "rie\u00b7sen\u00b7gro\u00df", "Ge\u00b7mach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KON", "ADJD", "VAFIN", "PPER", "$,", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Roth \u00fcber ihm die Sonne, wie Feuer auf dem Dach.", "tokens": ["Roth", "\u00fc\u00b7ber", "ihm", "die", "Son\u00b7ne", ",", "wie", "Feu\u00b7er", "auf", "dem", "Dach", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "ART", "NN", "$,", "PWAV", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.60": {"line.1": {"text": "Wie eine Kerze durch des Fensterladens Spalt, \u2013", "tokens": ["Wie", "ei\u00b7ne", "Ker\u00b7ze", "durch", "des", "Fens\u00b7ter\u00b7la\u00b7dens", "Spalt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "ART", "NN", "APPR", "ART", "NN", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und es verlischt. Und die Rechen, die die M\u00e4gde schwangen,", "tokens": ["Und", "es", "ver\u00b7lischt", ".", "Und", "die", "Re\u00b7chen", ",", "die", "die", "M\u00e4g\u00b7de", "schwan\u00b7gen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVPP", "$.", "KON", "ART", "NN", "$,", "PRELS", "ART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Die Sicheln, die im Getreide vereint zusammenklangen,", "tokens": ["Die", "Si\u00b7cheln", ",", "die", "im", "Ge\u00b7trei\u00b7de", "ver\u00b7eint", "zu\u00b7sam\u00b7men\u00b7klan\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVPP", "VVINF", "$,"], "meter": "-+-++-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Erschweigen und ruh'n. Denn also ist des Richters Wille:", "tokens": ["Er\u00b7schwei\u00b7gen", "und", "ruh'", "n.", "Denn", "al\u00b7so", "ist", "des", "Rich\u00b7ters", "Wil\u00b7le", ":"], "token_info": ["word", "word", "word", "abbreviation", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "NE", "KON", "ADV", "VAFIN", "ART", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sobald der Tag beschlossen, halte der Landmann stille;", "tokens": ["So\u00b7bald", "der", "Tag", "be\u00b7schlos\u00b7sen", ",", "hal\u00b7te", "der", "Land\u00b7mann", "stil\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVPP", "$,", "VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der Herr der Welten ma\u00df die Zeit der Arbeit zu:", "tokens": ["Der", "Herr", "der", "Wel\u00b7ten", "ma\u00df", "die", "Zeit", "der", "Ar\u00b7beit", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn seine Dienerin, die Sonne, geht zur Ruh',", "tokens": ["Wenn", "sei\u00b7ne", "Die\u00b7ne\u00b7rin", ",", "die", "Son\u00b7ne", ",", "geht", "zur", "Ruh'", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Ist's Zeit auch, da\u00df der Bauer ruht und sich behagt;", "tokens": ["Ist's", "Zeit", "auch", ",", "da\u00df", "der", "Bau\u00b7er", "ruht", "und", "sich", "be\u00b7hagt", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ADV", "$,", "KOUS", "ART", "NN", "VVFIN", "KON", "PRF", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "So pflegt der Richter zu sagen, und was der Richter sagt,", "tokens": ["So", "pflegt", "der", "Rich\u00b7ter", "zu", "sa\u00b7gen", ",", "und", "was", "der", "Rich\u00b7ter", "sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKZU", "VVINF", "$,", "KON", "PWS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der bied're \u00d6konom sieht es als heilig an.", "tokens": ["Der", "bie\u00b7d'\u00b7re", "\u00d6\u00b7kon\u00b7om", "sieht", "es", "als", "hei\u00b7lig", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "KOUS", "ADJD", "PTKVZ", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.11": {"text": "Die Wagen auch, in die man Schober zu legen begann,", "tokens": ["Die", "Wa\u00b7gen", "auch", ",", "in", "die", "man", "Scho\u00b7ber", "zu", "le\u00b7gen", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "APPR", "PRELS", "PIS", "NN", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.12": {"text": "Heimfahren sie ungef\u00fcllt; die Thiere geh'n zur Rast,", "tokens": ["Heim\u00b7fah\u00b7ren", "sie", "un\u00b7ge\u00b7f\u00fcllt", ";", "die", "Thie\u00b7re", "geh'n", "zur", "Rast", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "$.", "ART", "NN", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Mit Freuden f\u00fchlend die leichte, ungewohnte Last.", "tokens": ["Mit", "Freu\u00b7den", "f\u00fch\u00b7lend", "die", "leich\u00b7te", ",", "un\u00b7ge\u00b7wohn\u00b7te", "Last", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "ART", "ADJA", "$,", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.61": {"line.1": {"text": "Eben kommt die Gesellschaft vom Walde, \u2013 lachend und heiter,", "tokens": ["E\u00b7ben", "kommt", "die", "Ge\u00b7sell\u00b7schaft", "vom", "Wal\u00b7de", ",", "\u2013", "la\u00b7chend", "und", "hei\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "$(", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.2": {"text": "Doch wohlgeordnet. Voran die Kinder mit ihrem Begleiter,", "tokens": ["Doch", "wohl\u00b7ge\u00b7ord\u00b7net", ".", "Vo\u00b7ran", "die", "Kin\u00b7der", "mit", "ih\u00b7rem", "Be\u00b7glei\u00b7ter", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Drauf mit der K\u00e4mm'rersfrau der Richter, und daneben", "tokens": ["Drauf", "mit", "der", "K\u00e4m\u00b7m'\u00b7rers\u00b7frau", "der", "Rich\u00b7ter", ",", "und", "da\u00b7ne\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PAV", "APPR", "ART", "NN", "ART", "NN", "$,", "KON", "PAV"], "meter": "---+--+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Der K\u00e4mmerer selber, fr\u00f6hlich von den Seinen umgeben.", "tokens": ["Der", "K\u00e4m\u00b7me\u00b7rer", "sel\u00b7ber", ",", "fr\u00f6h\u00b7lich", "von", "den", "Sei\u00b7nen", "um\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADJD", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Gleich d'rauf die jungen Damen, die jungen Herrn zur Seite,", "tokens": ["Gleich", "d'\u00b7rauf", "die", "jun\u00b7gen", "Da\u00b7men", ",", "die", "jun\u00b7gen", "Herrn", "zur", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Die Damen den Herrn voran, um halben Schrittes Weite:", "tokens": ["Die", "Da\u00b7men", "den", "Herrn", "vo\u00b7ran", ",", "um", "hal\u00b7ben", "Schrit\u00b7tes", "Wei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "PTKVZ", "$,", "KOUI", "ADJA", "NN", "NN", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "So will's die Sitte. Niemand wies da zur Ordnung an,", "tokens": ["So", "will's", "die", "Sit\u00b7te", ".", "Nie\u00b7mand", "wies", "da", "zur", "Ord\u00b7nung", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "$.", "PIS", "VVFIN", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Niemand stellte in Reih und Glied \u2013 nein, Jedermann", "tokens": ["Nie\u00b7mand", "stell\u00b7te", "in", "Reih", "und", "Glied", "\u2013", "nein", ",", "Je\u00b7der\u00b7mann"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["PIS", "VVFIN", "APPR", "NN", "KON", "NN", "$(", "PTKANT", "$,", "PIS"], "meter": "+-+--+-+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Befolgte unwillk\u00fcrlich Ordnung und rechte Art.", "tokens": ["Be\u00b7folg\u00b7te", "un\u00b7will\u00b7k\u00fcr\u00b7lich", "Ord\u00b7nung", "und", "rech\u00b7te", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Denn beim Richter, da wurden die alten Sitten gewahrt,", "tokens": ["Denn", "beim", "Rich\u00b7ter", ",", "da", "wur\u00b7den", "die", "al\u00b7ten", "Sit\u00b7ten", "ge\u00b7wahrt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPRART", "NN", "$,", "ADV", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "--+--+--+-+--+", "measure": "anapaest.tri.plus"}, "line.11": {"text": "Und niemals hat er Verst\u00f6\u00dfe gegen die Achtung geduldet,", "tokens": ["Und", "nie\u00b7mals", "hat", "er", "Ver\u00b7st\u00f6\u00b7\u00dfe", "ge\u00b7gen", "die", "Ach\u00b7tung", "ge\u00b7dul\u00b7det", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die man dem Alter, dem Geist, dem Stand, der W\u00fcrde schuldet.", "tokens": ["Die", "man", "dem", "Al\u00b7ter", ",", "dem", "Geist", ",", "dem", "Stand", ",", "der", "W\u00fcr\u00b7de", "schul\u00b7det", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "$,", "ART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.13": {"text": "Denn rechte Sitte, sagt er, erh\u00e4lt Geschlecht und Reich.", "tokens": ["Denn", "rech\u00b7te", "Sit\u00b7te", ",", "sagt", "er", ",", "er\u00b7h\u00e4lt", "Ge\u00b7schlecht", "und", "Reich", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "$,", "VVFIN", "PPER", "$,", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und wenn sie sinkt, so sinken Geschlecht und Reich zugleich.", "tokens": ["Und", "wenn", "sie", "sinkt", ",", "so", "sin\u00b7ken", "Ge\u00b7schlecht", "und", "Reich", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "$,", "ADV", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "So hatten sich Haus und Gesinde der Ordnung angepa\u00dft;", "tokens": ["So", "hat\u00b7ten", "sich", "Haus", "und", "Ge\u00b7sin\u00b7de", "der", "Ord\u00b7nung", "an\u00b7ge\u00b7pa\u00dft", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PRF", "NN", "KON", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.16": {"text": "Und kam zu Besuch ein Verwandter oder ein fremder Gast:", "tokens": ["Und", "kam", "zu", "Be\u00b7such", "ein", "Ver\u00b7wand\u00b7ter", "o\u00b7der", "ein", "frem\u00b7der", "Gast", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "NN", "ART", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.17": {"text": "Wenn er nur kurze Zeit in Haus sich aufgehalten,", "tokens": ["Wenn", "er", "nur", "kur\u00b7ze", "Zeit", "in", "Haus", "sich", "auf\u00b7ge\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "APPR", "NN", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Zollt' er den Sitten Gehorsam, die beim Richter galten.", "tokens": ["Zollt'", "er", "den", "Sit\u00b7ten", "Ge\u00b7hor\u00b7sam", ",", "die", "beim", "Rich\u00b7ter", "gal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}}, "stanza.62": {"line.1": {"text": "Nur kurz begr\u00fc\u00dft er den Neffen: reicht ihm w\u00fcrdig zum Ku\u00df", "tokens": ["Nur", "kurz", "be\u00b7gr\u00fc\u00dft", "er", "den", "Nef\u00b7fen", ":", "reicht", "ihm", "w\u00fcr\u00b7dig", "zum", "Ku\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$.", "VVFIN", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Hand, k\u00fc\u00dft ihm die Stirn und sagt ihm freundlichen Gru\u00df.", "tokens": ["Die", "Hand", ",", "k\u00fc\u00dft", "ihm", "die", "Stirn", "und", "sagt", "ihm", "freund\u00b7li\u00b7chen", "Gru\u00df", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+---+-+-+--+", "measure": "iambic.penta.chol"}, "line.3": {"text": "Er spricht nur wenig \u2013 es sind so viele G\u00e4ste zur Stell' \u2013", "tokens": ["Er", "spricht", "nur", "we\u00b7nig", "\u2013", "es", "sind", "so", "vie\u00b7le", "G\u00e4s\u00b7te", "zur", "Stell'", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIS", "$(", "PPER", "VAFIN", "ADV", "PIAT", "NN", "APPRART", "NN", "$("], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die helle Thr\u00e4ne wegwischt, die ihm vom Auge rinnt:", "tokens": ["Die", "hel\u00b7le", "Thr\u00e4\u00b7ne", "weg\u00b7wischt", ",", "die", "ihm", "vom", "Au\u00b7ge", "rinnt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Sieht man, er liebt Thadd\u00e4us, wie ein eigen Kind.", "tokens": ["Sieht", "man", ",", "er", "liebt", "Thad\u00b7d\u00e4us", ",", "wie", "ein", "ei\u00b7gen", "Kind", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "$,", "PPER", "VVFIN", "NE", "$,", "PWAV", "ART", "ADJA", "NN", "$."], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.63": {"line.1": {"text": "Aus Feld und Flur und Wald und Weide nah' und fern", "tokens": ["Aus", "Feld", "und", "Flur", "und", "Wald", "und", "Wei\u00b7de", "nah'", "und", "fern"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN", "PTKVZ", "KON", "ADJD"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Kehrt Alles nun zur\u00fcck nach Hause mit dem Herrn;", "tokens": ["Kehrt", "Al\u00b7les", "nun", "zu\u00b7r\u00fcck", "nach", "Hau\u00b7se", "mit", "dem", "Herrn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "PTKVZ", "APPR", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier eine Heerde Schafe, sie w\u00e4lzt sich in die Gasse", "tokens": ["Hier", "ei\u00b7ne", "Heer\u00b7de", "Scha\u00b7fe", ",", "sie", "w\u00e4lzt", "sich", "in", "die", "Gas\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "NN", "$,", "PPER", "VVFIN", "PRF", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Lautbl\u00f6kend und Staub aufwirbelnd; dort die schwere Masse", "tokens": ["Laut\u00b7bl\u00f6\u00b7kend", "und", "Staub", "auf\u00b7wir\u00b7belnd", ";", "dort", "die", "schwe\u00b7re", "Mas\u00b7se"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "KON", "NN", "VVPP", "$.", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Tyroler K\u00e4lber, die H\u00e4lse mit Messingglocken beh\u00e4ngt;", "tokens": ["Ty\u00b7ro\u00b7ler", "K\u00e4l\u00b7ber", ",", "die", "H\u00e4l\u00b7se", "mit", "Mes\u00b7sing\u00b7glo\u00b7cken", "be\u00b7h\u00e4ngt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Da fliegen vom Anger her die Pferde \u2013 Alles dr\u00e4ngt", "tokens": ["Da", "flie\u00b7gen", "vom", "An\u00b7ger", "her", "die", "Pfer\u00b7de", "\u2013", "Al\u00b7les", "dr\u00e4ngt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "APPRART", "NN", "APZR", "ART", "NN", "$(", "PIS", "VVFIN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Zum Brunnen, wo auf und nieder kreischt der h\u00f6lzerne Arm,", "tokens": ["Zum", "Brun\u00b7nen", ",", "wo", "auf", "und", "nie\u00b7der", "kreischt", "der", "h\u00f6l\u00b7zer\u00b7ne", "Arm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PWAV", "PTKVZ", "KON", "PTKVZ", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Den Trog mit Wasser zu f\u00fcllen f\u00fcr den durstigen Schwarm.", "tokens": ["Den", "Trog", "mit", "Was\u00b7ser", "zu", "f\u00fcl\u00b7len", "f\u00fcr", "den", "durs\u00b7ti\u00b7gen", "Schwarm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "PTKZU", "VVINF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}}, "stanza.64": {"line.1": {"text": "M\u00fcd', und von G\u00e4sten umringt, s\u00e4umt doch der Richter nicht,", "tokens": ["M\u00fcd'", ",", "und", "von", "G\u00e4s\u00b7ten", "um\u00b7ringt", ",", "s\u00e4umt", "doch", "der", "Rich\u00b7ter", "nicht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "KON", "APPR", "NN", "VVPP", "$,", "VVFIN", "ADV", "ART", "NN", "PTKNEG", "$,"], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Auch jetzt genau zu erf\u00fcllen die wichtige Landwirthspflicht.", "tokens": ["Auch", "jetzt", "ge\u00b7nau", "zu", "er\u00b7f\u00fcl\u00b7len", "die", "wich\u00b7ti\u00b7ge", "Land\u00b7wirths\u00b7pflicht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "PTKZU", "VVINF", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er selbst begiebt sich zum Brunnen. Wenn's Abends heimw\u00e4rts geht,", "tokens": ["Er", "selbst", "be\u00b7giebt", "sich", "zum", "Brun\u00b7nen", ".", "Wenn's", "A\u00b7bends", "heim\u00b7w\u00e4rts", "geht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "PRF", "APPRART", "NN", "$.", "PIAT", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da sieht der Wirth am Besten, wie's mit dem Viehstall steht.", "tokens": ["Da", "sieht", "der", "Wirth", "am", "Bes\u00b7ten", ",", "wie's", "mit", "dem", "Vieh\u00b7stall", "steht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Die Pr\u00fcfung \u00fcberlie\u00df er seinen Knechten nie:", "tokens": ["Die", "Pr\u00fc\u00b7fung", "\u00fc\u00b7ber\u00b7lie\u00df", "er", "sei\u00b7nen", "Knech\u00b7ten", "nie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Er wei\u00df, des Herrn Auge f\u00fcttert wohl das Vieh.", "tokens": ["Er", "wei\u00df", ",", "des", "Herrn", "Au\u00b7ge", "f\u00fct\u00b7tert", "wohl", "das", "Vieh", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "ART", "NN", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}}, "stanza.65": {"line.1": {"text": "Im Vorhaus, Licht in den H\u00e4nden, standen um diese Zeit", "tokens": ["Im", "Vor\u00b7haus", ",", "Licht", "in", "den", "H\u00e4n\u00b7den", ",", "stan\u00b7den", "um", "die\u00b7se", "Zeit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "$,", "NN", "APPR", "ART", "NN", "$,", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Protasius, der Gerichtsfrohn,", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", ",", "der", "Ge\u00b7richts\u00b7frohn", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Protasius n\u00e4mlich hatte heimlich aus dem Saal", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "n\u00e4m\u00b7lich", "hat\u00b7te", "heim\u00b7lich", "aus", "dem", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "VAFIN", "ADJD", "APPR", "ART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Den Tisch fortschaffen lassen sammt dem Abendmahl", "tokens": ["Den", "Tisch", "fort\u00b7schaf\u00b7fen", "las\u00b7sen", "sammt", "dem", "A\u00b7bend\u00b7mahl"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVINF", "VVINF", "VVFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und anzurichten befohlen, so rasch sich's machen l\u00e4\u00dft,", "tokens": ["Und", "an\u00b7zu\u00b7rich\u00b7ten", "be\u00b7foh\u00b7len", ",", "so", "rasch", "sich's", "ma\u00b7chen", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVIZU", "VVPP", "$,", "ADV", "ADJD", "PIS", "VVINF", "VVFIN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Im Schlo\u00df, unweit des Walds: ein altes Tr\u00fcmmernest.", "tokens": ["Im", "Schlo\u00df", ",", "un\u00b7weit", "des", "Walds", ":", "ein", "al\u00b7tes", "Tr\u00fcm\u00b7mer\u00b7nest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Was sollte dies? Der Wojski macht \u00e4rgerliche Gesichter,", "tokens": ["Was", "soll\u00b7te", "dies", "?", "Der", "Wojs\u00b7ki", "macht", "\u00e4r\u00b7ger\u00b7li\u00b7che", "Ge\u00b7sich\u00b7ter", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PDS", "$.", "ART", "NN", "VVFIN", "ADJA", "NN", "$,"], "meter": "-+-+-+-++-+--+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Zankt, \u2013 entschuldigt sich dann bei dem erstaunten Richter;", "tokens": ["Zankt", ",", "\u2013", "ent\u00b7schul\u00b7digt", "sich", "dann", "bei", "dem", "er\u00b7staun\u00b7ten", "Rich\u00b7ter", ";"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "$(", "VVFIN", "PRF", "ADV", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Was hilft's? es ist schon sp\u00e4t: der Richter mu\u00df die G\u00e4ste", "tokens": ["Was", "hilft's", "?", "es", "ist", "schon", "sp\u00e4t", ":", "der", "Rich\u00b7ter", "mu\u00df", "die", "G\u00e4s\u00b7te"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "$.", "PPER", "VAFIN", "ADV", "ADJD", "$.", "ART", "NN", "VMFIN", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Um Nachsicht bitten und f\u00fchrt sie in die verfallene Veste.", "tokens": ["Um", "Nach\u00b7sicht", "bit\u00b7ten", "und", "f\u00fchrt", "sie", "in", "die", "ver\u00b7fal\u00b7le\u00b7ne", "Ves\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVINF", "KON", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Im Geh'n erkl\u00e4rt ihm Protas des Breiten und des Langen,", "tokens": ["Im", "Geh'n", "er\u00b7kl\u00e4rt", "ihm", "Pro\u00b7tas", "des", "Brei\u00b7ten", "und", "des", "Lan\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "NN", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Warum er sich die Befehle zu \u00e4ndern unterfangen:", "tokens": ["Wa\u00b7rum", "er", "sich", "die", "Be\u00b7feh\u00b7le", "zu", "\u00e4n\u00b7dern", "un\u00b7ter\u00b7fan\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "ART", "NN", "PTKZU", "VVINF", "VVINF", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Es ist im Hause kein gen\u00fcgend gro\u00dfer Saal", "tokens": ["Es", "ist", "im", "Hau\u00b7se", "kein", "ge\u00b7n\u00fc\u00b7gend", "gro\u00b7\u00dfer", "Saal"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "PIAT", "ADJD", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "F\u00fcr G\u00e4ste von solchem Range und von solcher Zahl;", "tokens": ["F\u00fcr", "G\u00e4s\u00b7te", "von", "sol\u00b7chem", "Ran\u00b7ge", "und", "von", "sol\u00b7cher", "Zahl", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PIAT", "NN", "KON", "APPR", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Im Schlo\u00df giebt's eine Halle, recht gro\u00df und wohlerhalten,", "tokens": ["Im", "Schlo\u00df", "giebt's", "ei\u00b7ne", "Hal\u00b7le", ",", "recht", "gro\u00df", "und", "woh\u00b7ler\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "ART", "NN", "$,", "ADV", "ADJD", "KON", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Die W\u00f6lbung ganz \u2013 es ist zwar eine Wand gespalten,", "tokens": ["Die", "W\u00f6l\u00b7bung", "ganz", "\u2013", "es", "ist", "zwar", "ei\u00b7ne", "Wand", "ge\u00b7spal\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$(", "PPER", "VAFIN", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Die Fenster ohne Scheiben, doch ist's ja Sommerzeit,", "tokens": ["Die", "Fens\u00b7ter", "oh\u00b7ne", "Schei\u00b7ben", ",", "doch", "ist's", "ja", "Som\u00b7mer\u00b7zeit", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,", "ADV", "VAFIN", "ADV", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "So spricht er und blinzelt ihm zu \u2013 und seine Miene zeigt,", "tokens": ["So", "spricht", "er", "und", "blin\u00b7zelt", "ihm", "zu", "\u2013", "und", "sei\u00b7ne", "Mie\u00b7ne", "zeigt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "PPER", "PTKZU", "$(", "KON", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.19": {"text": "Er hat noch andre Gr\u00fcnde, die er klug verschweigt.", "tokens": ["Er", "hat", "noch", "and\u00b7re", "Gr\u00fcn\u00b7de", ",", "die", "er", "klug", "ver\u00b7schweigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJA", "NN", "$,", "PRELS", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.66": {"line.1": {"text": "Zweitausend Schritt vom Hause sah man das Schlo\u00df nun ragen:", "tokens": ["Zweit\u00b7au\u00b7send", "Schritt", "vom", "Hau\u00b7se", "sah", "man", "das", "Schlo\u00df", "nun", "ra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPRART", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein stolzer, m\u00e4cht'ger Bau. Hier hauste in fr\u00fchern Tagen", "tokens": ["Ein", "stol\u00b7zer", ",", "m\u00e4cht'\u00b7ger", "Bau", ".", "Hier", "haus\u00b7te", "in", "fr\u00fc\u00b7hern", "Ta\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "$.", "ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Das alte Geschlecht der Horeszko; der Schlo\u00dfherr war gefallen", "tokens": ["Das", "al\u00b7te", "Ge\u00b7schlecht", "der", "Hor\u00b7esz\u00b7ko", ";", "der", "Schlo\u00df\u00b7herr", "war", "ge\u00b7fal\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "ART", "NE", "$.", "ART", "NN", "VAFIN", "VVPP"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Zur Zeit der innern Wirren; und von den G\u00fctern allen", "tokens": ["Zur", "Zeit", "der", "in\u00b7nern", "Wir\u00b7ren", ";", "und", "von", "den", "G\u00fc\u00b7tern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$.", "KON", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "War Nichts geblieben; schlecht verwaltet und gepflegt,", "tokens": ["War", "Nichts", "ge\u00b7blie\u00b7ben", ";", "schlecht", "ver\u00b7wal\u00b7tet", "und", "ge\u00b7pflegt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "VVPP", "$.", "ADJD", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Theils durch Processe zerrieben, theils mit Beschlag belegt,", "tokens": ["Theils", "durch", "Pro\u00b7ces\u00b7se", "zer\u00b7rie\u00b7ben", ",", "theils", "mit", "Be\u00b7schlag", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "VVPP", "$,", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.7": {"text": "Ward endlich, was nicht Verwandte von Mutterseite bekommen,", "tokens": ["Ward", "end\u00b7lich", ",", "was", "nicht", "Ver\u00b7wand\u00b7te", "von", "Mut\u00b7ter\u00b7sei\u00b7te", "be\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PRELS", "PTKNEG", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-++-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Von Gl\u00e4ubigern getheilt. Das Schlo\u00df hat Niemand genommen;", "tokens": ["Von", "Gl\u00e4u\u00b7bi\u00b7gern", "ge\u00b7theilt", ".", "Das", "Schlo\u00df", "hat", "Nie\u00b7mand", "ge\u00b7nom\u00b7men", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Denn es zu erhalten, fiel bei m\u00e4\u00dfigen Mitteln nicht leicht.", "tokens": ["Denn", "es", "zu", "er\u00b7hal\u00b7ten", ",", "fiel", "bei", "m\u00e4\u00b7\u00dfi\u00b7gen", "Mit\u00b7teln", "nicht", "leicht", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKZU", "VVINF", "$,", "VVFIN", "APPR", "ADJA", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+--+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Als aber der Graf die Jahre der M\u00fcndigkeit erreicht \u2013", "tokens": ["Als", "a\u00b7ber", "der", "Graf", "die", "Jah\u00b7re", "der", "M\u00fcn\u00b7dig\u00b7keit", "er\u00b7reicht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ART", "NN", "ART", "NN", "VVPP", "$("], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Ein naher Nachbar, entfernt mit den Horeszko verwandt, \u2013", "tokens": ["Ein", "na\u00b7her", "Nach\u00b7bar", ",", "ent\u00b7fernt", "mit", "den", "Hor\u00b7esz\u00b7ko", "ver\u00b7wandt", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ADJD", "APPR", "ART", "NE", "VVPP", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Kam er, ein reicher Junker, heim aus fremdem Land,", "tokens": ["Kam", "er", ",", "ein", "rei\u00b7cher", "Jun\u00b7ker", ",", "heim", "aus", "frem\u00b7dem", "Land", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "$,", "ART", "ADJA", "NN", "$,", "PTKVZ", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Und ihm gefiel das Nest. Warum es ihm gefiel?", "tokens": ["Und", "ihm", "ge\u00b7fiel", "das", "Nest", ".", "Wa\u00b7rum", "es", "ihm", "ge\u00b7fiel", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "ART", "NN", "$.", "PWAV", "PPER", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Wer sagt es? Er erkl\u00e4rte, es w\u00e4r' in gothischem Stil \u2013", "tokens": ["Wer", "sagt", "es", "?", "Er", "er\u00b7kl\u00e4r\u00b7te", ",", "es", "w\u00e4r'", "in", "go\u00b7thi\u00b7schem", "Stil", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "$,", "PPER", "VAFIN", "APPR", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Und standen doch dem Richter die Akten zu Gebote,", "tokens": ["Und", "stan\u00b7den", "doch", "dem", "Rich\u00b7ter", "die", "Ak\u00b7ten", "zu", "Ge\u00b7bo\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Da\u00df der Erbauer aus Wilna gewesen, und kein Gothe.", "tokens": ["Da\u00df", "der", "Er\u00b7bau\u00b7er", "aus", "Wil\u00b7na", "ge\u00b7we\u00b7sen", ",", "und", "kein", "Go\u00b7the", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "APPR", "NE", "VAPP", "$,", "KON", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.17": {"text": "Genug, den Grafen gel\u00fcstet's nach dem Schlo\u00df \u2013 und just", "tokens": ["Ge\u00b7nug", ",", "den", "Gra\u00b7fen", "ge\u00b7l\u00fcs\u00b7tet's", "nach", "dem", "Schlo\u00df", "\u2013", "und", "just"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "ART", "NN", "NE", "APPR", "ART", "NN", "$(", "KON", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Bef\u00e4llt, Gott wei\u00df warum, den Richter dieselbe Lust.", "tokens": ["Be\u00b7f\u00e4llt", ",", "Gott", "wei\u00df", "wa\u00b7rum", ",", "den", "Rich\u00b7ter", "die\u00b7sel\u00b7be", "Lust", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "VVFIN", "PWAV", "$,", "ART", "NN", "PDAT", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Nun stritt man im Grundgericht, im Obergericht, im Senat,", "tokens": ["Nun", "stritt", "man", "im", "Grund\u00b7ge\u00b7richt", ",", "im", "O\u00b7ber\u00b7ge\u00b7richt", ",", "im", "Se\u00b7nat", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "$,", "APPRART", "NN", "$,", "APPRART", "NN", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Und wieder im Grundgericht und dann im Regierungsrath;", "tokens": ["Und", "wie\u00b7der", "im", "Grund\u00b7ge\u00b7richt", "und", "dann", "im", "Re\u00b7gie\u00b7rungs\u00b7rath", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPRART", "NN", "KON", "ADV", "APPRART", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Endlich, nachdem man viel Geld und viel Papier verthan,", "tokens": ["End\u00b7lich", ",", "nach\u00b7dem", "man", "viel", "Geld", "und", "viel", "Pa\u00b7pier", "ver\u00b7than", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PIS", "PIAT", "NN", "KON", "PIAT", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.22": {"text": "Langt nun die Sache wieder beim Grenzgerichte an.", "tokens": ["Langt", "nun", "die", "Sa\u00b7che", "wie\u00b7der", "beim", "Grenz\u00b7ge\u00b7rich\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.67": {"line.1": {"text": "Protasius hatte Recht; es fa\u00dfte bequem die Halle", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "hat\u00b7te", "Recht", ";", "es", "fa\u00df\u00b7te", "be\u00b7quem", "die", "Hal\u00b7le"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VAFIN", "NN", "$.", "PPER", "VVFIN", "ADJD", "ART", "NN"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Die Leute vom Gericht und auch die G\u00e4ste alle, \u2013", "tokens": ["Die", "Leu\u00b7te", "vom", "Ge\u00b7richt", "und", "auch", "die", "G\u00e4s\u00b7te", "al\u00b7le", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "KON", "ADV", "ART", "NN", "PIS", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Gro\u00df wie ein Refectorium: die W\u00f6lbung hochgestreckt,", "tokens": ["Gro\u00df", "wie", "ein", "Re\u00b7fec\u00b7to\u00b7ri\u00b7um", ":", "die", "W\u00f6l\u00b7bung", "hoch\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$.", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Auf Pfeilern ruhend, der Estrich ganz mit Stein gedeckt.", "tokens": ["Auf", "Pfei\u00b7lern", "ru\u00b7hend", ",", "der", "Est\u00b7rich", "ganz", "mit", "Stein", "ge\u00b7deckt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$,", "PRELS", "PPER", "ADV", "APPR", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Schmucklose, nackte W\u00e4nde, doch war die Mauer rein \u2013", "tokens": ["Schmuck\u00b7lo\u00b7se", ",", "nack\u00b7te", "W\u00e4n\u00b7de", ",", "doch", "war", "die", "Mau\u00b7er", "rein", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,", "ADV", "VAFIN", "ART", "NN", "ADJD", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.6": {"text": "Rings eine gro\u00dfe Menge von Reh- und Hirschgeweih'n", "tokens": ["Rings", "ei\u00b7ne", "gro\u00b7\u00dfe", "Men\u00b7ge", "von", "Reh", "und", "Hirschge\u00b7weih'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "ADJA", "NN", "APPR", "TRUNC", "KON", "NN"], "meter": "-+-+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Mit Aufschriften, wann und wo die Beute ward erlegt,", "tokens": ["Mit", "Auf\u00b7schrif\u00b7ten", ",", "wann", "und", "wo", "die", "Beu\u00b7te", "ward", "er\u00b7legt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PWAV", "KON", "PWAV", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.8": {"text": "Der J\u00e4ger Wappenbilder \u00fcberall eingepr\u00e4gt,", "tokens": ["Der", "J\u00e4\u00b7ger", "Wap\u00b7pen\u00b7bil\u00b7der", "\u00fc\u00b7be\u00b7rall", "ein\u00b7ge\u00b7pr\u00e4gt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Und Jeder mit Namen genannt; und \u00fcber alle erhoben,", "tokens": ["Und", "Je\u00b7der", "mit", "Na\u00b7men", "ge\u00b7nannt", ";", "und", "\u00fc\u00b7ber", "al\u00b7le", "er\u00b7ho\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "NN", "VVPP", "$.", "KON", "APPR", "PIS", "VVPP", "$,"], "meter": "-+--+--+-+-+--+-", "measure": "amphibrach.tri.plus"}, "line.10": {"text": "Prangt der Horeszko Halbbock an der W\u00f6lbung droben.", "tokens": ["Prangt", "der", "Hor\u00b7esz\u00b7ko", "Halb\u00b7bock", "an", "der", "W\u00f6l\u00b7bung", "dro\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NE", "NE", "APPR", "ART", "NN", "ADV", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.11": {"text": "Ringsum im Kreise auf; der K\u00e4mm'rer obenan.", "tokens": ["Ring\u00b7sum", "im", "Krei\u00b7se", "auf", ";", "der", "K\u00e4m\u00b7m'\u00b7rer", "o\u00b7be\u00b7nan", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PTKVZ", "$.", "ART", "NN", "ADV", "$."], "meter": "+--+-+-+--+-+", "measure": "iambic.hexa.invert"}, "line.12": {"text": "Seinem Alter und Amt ertheilt man die Ehre gern;", "tokens": ["Sei\u00b7nem", "Al\u00b7ter", "und", "Amt", "er\u00b7theilt", "man", "die", "Eh\u00b7re", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.13": {"text": "Im Gehen gr\u00fc\u00dft er die Damen, die \u00e4ltern und j\u00fcngern Herrn.", "tokens": ["Im", "Ge\u00b7hen", "gr\u00fc\u00dft", "er", "die", "Da\u00b7men", ",", "die", "\u00e4l\u00b7tern", "und", "j\u00fcn\u00b7gern", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Daneben der Almosenier, bei dem der Richter steht;", "tokens": ["Da\u00b7ne\u00b7ben", "der", "Al\u00b7mo\u00b7se\u00b7nier", ",", "bei", "dem", "der", "Rich\u00b7ter", "steht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "$,", "APPR", "PRELS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.15": {"text": "Der Priester spricht ein kurzes lateinisches Gebet;", "tokens": ["Der", "Pries\u00b7ter", "spricht", "ein", "kur\u00b7zes", "la\u00b7tei\u00b7ni\u00b7sches", "Ge\u00b7bet", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Man giebt den M\u00e4nnern Branntwein; dann setzen sich Alle in Ruh'", "tokens": ["Man", "giebt", "den", "M\u00e4n\u00b7nern", "Brannt\u00b7wein", ";", "dann", "set\u00b7zen", "sich", "Al\u00b7le", "in", "Ruh'"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VVFIN", "ART", "NN", "NN", "$.", "ADV", "VVFIN", "PRF", "PIS", "APPR", "NN"], "meter": "-+-+-++-+--+--+", "measure": "iambic.septa.relaxed"}, "line.17": {"text": "Und sprechen der Lithauersuppe schweigend und tapfer zu.", "tokens": ["Und", "spre\u00b7chen", "der", "Lit\u00b7hau\u00b7er\u00b7sup\u00b7pe", "schwei\u00b7gend", "und", "tap\u00b7fer", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+-+", "measure": "iambic.septa.relaxed"}}, "stanza.68": {"line.1": {"text": "Thadd\u00e4us geh\u00f6rt wohl zur Jugend, doch sitzt er nach Gastesrecht", "tokens": ["Thad\u00b7d\u00e4us", "ge\u00b7h\u00f6rt", "wohl", "zur", "Ju\u00b7gend", ",", "doch", "sitzt", "er", "nach", "Gas\u00b7tes\u00b7recht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "ADV", "APPRART", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Heut' oben, nah' dem Hausherrn, beim weiblichen Geschlecht.", "tokens": ["Heut'", "o\u00b7ben", ",", "nah'", "dem", "Haus\u00b7herrn", ",", "beim", "weib\u00b7li\u00b7chen", "Ge\u00b7schlecht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "$,", "APPR", "ART", "NN", "$,", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Zwischen dem Onkel und ihm ist aber ein Sitz noch leer,", "tokens": ["Zwi\u00b7schen", "dem", "On\u00b7kel", "und", "ihm", "ist", "a\u00b7ber", "ein", "Sitz", "noch", "leer", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "KON", "PPER", "VAFIN", "ADV", "ART", "NN", "ADV", "ADJD", "$,"], "meter": "+--+-+-+---+-+", "measure": "iambic.hexa.invert"}, "line.4": {"text": "Als sollt' noch Jemand kommen. Oft sieht der Onkel her", "tokens": ["Als", "sollt'", "noch", "Je\u00b7mand", "kom\u00b7men", ".", "Oft", "sieht", "der", "On\u00b7kel", "her"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "VMFIN", "ADV", "PIS", "VVINF", "$.", "ADV", "VVFIN", "ART", "NN", "APZR"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und wendet sich dann wieder zur Th\u00fcr, erwartungsvoll, \u2013", "tokens": ["Und", "wen\u00b7det", "sich", "dann", "wie\u00b7der", "zur", "Th\u00fcr", ",", "er\u00b7war\u00b7tungs\u00b7voll", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "ADV", "APPRART", "NN", "$,", "ADJD", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Als wollt' er und w\u00fc\u00dfte sicher, da\u00df Jemand erscheinen soll.", "tokens": ["Als", "wollt'", "er", "und", "w\u00fc\u00df\u00b7te", "si\u00b7cher", ",", "da\u00df", "Je\u00b7mand", "er\u00b7schei\u00b7nen", "soll", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VMFIN", "PPER", "KON", "VVFIN", "ADJD", "$,", "KOUS", "PIS", "VVINF", "VMFIN", "$."], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Zur Th\u00fcr begleitet Thadd\u00e4us seinen suchenden Blick", "tokens": ["Zur", "Th\u00fcr", "be\u00b7glei\u00b7tet", "Thad\u00b7d\u00e4us", "sei\u00b7nen", "su\u00b7chen\u00b7den", "Blick"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VVFIN", "NE", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Und kehrt mit ihm dann wieder zum leeren Sitz zur\u00fcck.", "tokens": ["Und", "kehrt", "mit", "ihm", "dann", "wie\u00b7der", "zum", "lee\u00b7ren", "Sitz", "zu\u00b7r\u00fcck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPER", "ADV", "ADV", "APPRART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Seltsam, da sitzt ja rings ein ganzer M\u00e4dchenreigen, \u2013", "tokens": ["Selt\u00b7sam", ",", "da", "sitzt", "ja", "rings", "ein", "gan\u00b7zer", "M\u00e4d\u00b7chen\u00b7rei\u00b7gen", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "$,", "ADV", "VVFIN", "ADV", "ADV", "ART", "ADJA", "NN", "$,", "$("], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.10": {"text": "Er d\u00fcrft' sich vor den Augen eines Prinzen zeigen, \u2013", "tokens": ["Er", "d\u00fcrft'", "sich", "vor", "den", "Au\u00b7gen", "ei\u00b7nes", "Prin\u00b7zen", "zei\u00b7gen", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "PRF", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Lauter Edelgeborene, Junge, Sch\u00f6ne, Feine:", "tokens": ["Lau\u00b7ter", "E\u00b7del\u00b7ge\u00b7bo\u00b7re\u00b7ne", ",", "Jun\u00b7ge", ",", "Sch\u00f6\u00b7ne", ",", "Fei\u00b7ne", ":"], "token_info": ["word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADJA", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.12": {"text": "Wo aber Thadd\u00e4us hinschaut, da sitzt ja g'rade keine!", "tokens": ["Wo", "a\u00b7ber", "Thad\u00b7d\u00e4us", "hin\u00b7schaut", ",", "da", "sitzt", "ja", "g'\u00b7ra\u00b7de", "kei\u00b7ne", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "NE", "VVPP", "$,", "ADV", "VVFIN", "ADV", "ADV", "PIAT", "$."], "meter": "-+-+-++-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "Die Jugend liebt die R\u00e4thsel, und r\u00e4thselhaft ist der Ort.", "tokens": ["Die", "Ju\u00b7gend", "liebt", "die", "R\u00e4th\u00b7sel", ",", "und", "r\u00e4th\u00b7sel\u00b7haft", "ist", "der", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "$,", "KON", "ADJD", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Zerstreut spricht er nur hin und wieder kaum ein Wort", "tokens": ["Zer\u00b7streut", "spricht", "er", "nur", "hin", "und", "wie\u00b7der", "kaum", "ein", "Wort"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "VVFIN", "PPER", "ADV", "PTKVZ", "KON", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Zur holden Nachbarin, zu K\u00e4mmerer's T\u00f6chterlein,", "tokens": ["Zur", "hol\u00b7den", "Nach\u00b7ba\u00b7rin", ",", "zu", "K\u00e4m\u00b7me\u00b7rer's", "T\u00f6ch\u00b7ter\u00b7lein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "$,", "APPR", "NE", "NN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Er wechselt ihr nicht die Teller, gie\u00dft nichts in's Glas ihr ein,", "tokens": ["Er", "wech\u00b7selt", "ihr", "nicht", "die", "Tel\u00b7ler", ",", "gie\u00dft", "nichts", "in's", "Glas", "ihr", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKNEG", "ART", "NN", "$,", "VVFIN", "PIS", "APPRART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Denkt nicht daran, den Damen artige Reden zu bieten,", "tokens": ["Denkt", "nicht", "da\u00b7ran", ",", "den", "Da\u00b7men", "ar\u00b7ti\u00b7ge", "Re\u00b7den", "zu", "bie\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "PAV", "$,", "ART", "NN", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Die da an ihm der Hauptstadt feine Erziehung verriethen, \u2013", "tokens": ["Die", "da", "an", "ihm", "der", "Haupt\u00b7stadt", "fei\u00b7ne", "Er\u00b7zie\u00b7hung", "ver\u00b7rie\u00b7then", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADV", "APPR", "PPER", "ART", "NN", "ADJA", "NN", "VVINF", "$,", "$("], "meter": "--+--+-+--+--+-", "measure": "anapaest.di.plus"}, "line.19": {"text": "Zu jenem leeren Platz lockt es ihn einzig hin:", "tokens": ["Zu", "je\u00b7nem", "lee\u00b7ren", "Platz", "lockt", "es", "ihn", "ein\u00b7zig", "hin", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "VVFIN", "PPER", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.20": {"text": "Nun nicht mehr leer, \u2013 es f\u00fcllen seine Gedanken ihn, \u2013", "tokens": ["Nun", "nicht", "mehr", "leer", ",", "\u2013", "es", "f\u00fcl\u00b7len", "sei\u00b7ne", "Ge\u00b7dan\u00b7ken", "ihn", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "PTKNEG", "ADV", "ADJD", "$,", "$(", "PPER", "VVFIN", "PPOSAT", "NN", "PPER", "$,", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Vermuthungen, unz\u00e4hlige, l\u00e4\u00dft er dar\u00fcber laufen,", "tokens": ["Ver\u00b7mu\u00b7thun\u00b7gen", ",", "un\u00b7z\u00e4h\u00b7li\u00b7ge", ",", "l\u00e4\u00dft", "er", "da\u00b7r\u00fc\u00b7ber", "lau\u00b7fen", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "$,", "VVFIN", "PPER", "PAV", "VVINF", "$,"], "meter": "-+--++--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Wie nach dem Regen im Feld der muntern Fr\u00f6schlein Haufen;", "tokens": ["Wie", "nach", "dem", "Re\u00b7gen", "im", "Feld", "der", "mun\u00b7tern", "Fr\u00f6schlein", "Hau\u00b7fen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPR", "ART", "NN", "APPRART", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "+--+--+-+--+-", "measure": "dactylic.di.plus"}, "line.23": {"text": "Doch k\u00f6niglich ob Allem ein trautes Bildni\u00df schwebt,", "tokens": ["Doch", "k\u00f6\u00b7nig\u00b7lich", "ob", "Al\u00b7lem", "ein", "trau\u00b7tes", "Bild\u00b7ni\u00df", "schwebt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "KOUS", "PIS", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Der Wasserlilie gleich, die aus der Fluth sich hebt.", "tokens": ["Der", "Was\u00b7ser\u00b7li\u00b7lie", "gleich", ",", "die", "aus", "der", "Fluth", "sich", "hebt", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "APPR", "ART", "NN", "PRF", "VVFIN", "$."], "meter": "-+-+---+-+-+", "measure": "unknown.measure.penta"}}, "stanza.69": {"line.1": {"text": "Man war beim dritten Gang. Da go\u00df ein Tr\u00f6pfchen Wein", "tokens": ["Man", "war", "beim", "drit\u00b7ten", "Gang", ".", "Da", "go\u00df", "ein", "Tr\u00f6pf\u00b7chen", "Wein"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIS", "VAFIN", "APPRART", "ADJA", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Der K\u00e4mm'rer in das Gl\u00e4schen des Fr\u00e4uleins Rosa ein,", "tokens": ["Der", "K\u00e4m\u00b7m'\u00b7rer", "in", "das", "Gl\u00e4s\u00b7chen", "des", "Fr\u00e4u\u00b7leins", "Ro\u00b7sa", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "ART", "NN", "NE", "PTKVZ", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und schob der j\u00fcngern Tochter den Gurkenteller hin", "tokens": ["Und", "schob", "der", "j\u00fcn\u00b7gern", "Toch\u00b7ter", "den", "Gur\u00b7ken\u00b7tel\u00b7ler", "hin"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "PTKVZ"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Mu\u00df ich euch heut' bedenken.\u00ab \u2013 Da st\u00fcrzen rasch zu ihnen", "tokens": ["Mu\u00df", "ich", "euch", "heut'", "be\u00b7den\u00b7ken", ".", "\u00ab", "\u2013", "Da", "st\u00fcr\u00b7zen", "rasch", "zu", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$.", "$(", "$(", "ADV", "VVFIN", "ADJD", "APPR", "PPER"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ein paar der jungen Herrn, die Damen zu bedienen.", "tokens": ["Ein", "paar", "der", "jun\u00b7gen", "Herrn", ",", "die", "Da\u00b7men", "zu", "be\u00b7die\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ART", "ADJA", "NN", "$,", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Richter warf auf Thadd\u00e4us einen Seitenblick,", "tokens": ["Der", "Rich\u00b7ter", "warf", "auf", "Thad\u00b7d\u00e4us", "ei\u00b7nen", "Sei\u00b7ten\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Schob sich die \u00c4rmel des Kontusz erst ein wenig zur\u00fcck,", "tokens": ["Schob", "sich", "die", "\u00c4r\u00b7mel", "des", "Kon\u00b7tusz", "erst", "ein", "we\u00b7nig", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ART", "NN", "ART", "NN", "ADV", "ART", "PIS", "PTKVZ", "$,"], "meter": "+--+---+--+--+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Go\u00df dann Tokaier ein und sprach: \u00bbWir schicken heute", "tokens": ["Go\u00df", "dann", "To\u00b7kai\u00b7er", "ein", "und", "sprach", ":", "\u00bb", "Wir", "schi\u00b7cken", "heu\u00b7te"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "ADV", "NN", "PTKVZ", "KON", "VVFIN", "$.", "$(", "PPER", "VVFIN", "ADV"], "meter": "+-+--+-+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Zur Schule in die Hauptstadt unsre jungen Leute,", "tokens": ["Zur", "Schu\u00b7le", "in", "die", "Haupt\u00b7stadt", "uns\u00b7re", "jun\u00b7gen", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ART", "NN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So will's die neue Mode. Und wir r\u00e4umen ein:", "tokens": ["So", "will's", "die", "neu\u00b7e", "Mo\u00b7de", ".", "Und", "wir", "r\u00e4u\u00b7men", "ein", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "$.", "KON", "PPER", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Sie m\u00f6gen an B\u00fccherweisheit uns \u00fcberlegen sein.", "tokens": ["Sie", "m\u00f6\u00b7gen", "an", "B\u00fc\u00b7cher\u00b7weis\u00b7heit", "uns", "\u00fc\u00b7berl\u00b7e\u00b7gen", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "NN", "PPER", "VVPP", "VAINF", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Doch t\u00e4glich mu\u00df ich die Jugend daran kranken seh'n,", "tokens": ["Doch", "t\u00e4g\u00b7lich", "mu\u00df", "ich", "die", "Ju\u00b7gend", "da\u00b7ran", "kran\u00b7ken", "seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VMFIN", "PPER", "ART", "NN", "PAV", "VVINF", "VVINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Da\u00df keine Schule lehrt mit Menschen umzugeh'n.", "tokens": ["Da\u00df", "kei\u00b7ne", "Schu\u00b7le", "lehrt", "mit", "Men\u00b7schen", "um\u00b7zu\u00b7geh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["KOUS", "PIAT", "NN", "VVFIN", "APPR", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Vor Zeiten pflegte der Junker an einen Hof zu fahren,", "tokens": ["Vor", "Zei\u00b7ten", "pfleg\u00b7te", "der", "Jun\u00b7ker", "an", "ei\u00b7nen", "Hof", "zu", "fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Ich selber diente einen Zeitraum von zehn Jahren,", "tokens": ["Ich", "sel\u00b7ber", "dien\u00b7te", "ei\u00b7nen", "Zeit\u00b7raum", "von", "zehn", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "NN", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Beim Wojewoden, unsres verehrten K\u00e4mm'rers Vater;", "tokens": ["Beim", "Wo\u00b7je\u00b7wo\u00b7den", ",", "uns\u00b7res", "ver\u00b7ehr\u00b7ten", "K\u00e4m\u00b7m'\u00b7rers", "Va\u00b7ter", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PPOSAT", "ADJA", "NN", "NN", "$."], "meter": "+-+--+--+--+-+-", "measure": "trochaic.hexa.relaxed"}, "line.17": {"text": "(hier dr\u00fcckt' er den K\u00e4mm'rer am Knie), der war mein treuer Berather,", "tokens": ["(", "hier", "dr\u00fcckt'", "er", "den", "K\u00e4m\u00b7m'\u00b7rer", "am", "Knie", ")", ",", "der", "war", "mein", "treu\u00b7er", "Be\u00b7ra\u00b7ther", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "ART", "NN", "APPRART", "NN", "$(", "$,", "PRELS", "VAFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--++--+-+-+--+-", "measure": "iambic.septa.relaxed"}, "line.18": {"text": "Als ich den Staatsdienst lernte \u2013 und hielt mich lang' in Acht,", "tokens": ["Als", "ich", "den", "Staats\u00b7dienst", "lern\u00b7te", "\u2013", "und", "hielt", "mich", "lang'", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVFIN", "$(", "KON", "VVFIN", "PPER", "ADV", "APPR", "CARD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und hat dann endlich aus Einem einen Menschen gemacht.", "tokens": ["Und", "hat", "dann", "end\u00b7lich", "aus", "Ei\u00b7nem", "ei\u00b7nen", "Men\u00b7schen", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADV", "APPR", "PIS", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sein Name bleibt uns theuer, so lang' mein Haus besteht,", "tokens": ["Sein", "Na\u00b7me", "bleibt", "uns", "theu\u00b7er", ",", "so", "lang'", "mein", "Haus", "be\u00b7steht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "$,", "ADV", "ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+---+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.21": {"text": "Und seiner Seele gedenk' ich t\u00e4glich im Gebet.", "tokens": ["Und", "sei\u00b7ner", "See\u00b7le", "ge\u00b7denk'", "ich", "t\u00e4g\u00b7lich", "im", "Ge\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+--+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Und hat mir's weniger Nutzen als Anderen gew\u00e4hrt,", "tokens": ["Und", "hat", "mir's", "we\u00b7ni\u00b7ger", "Nut\u00b7zen", "als", "An\u00b7de\u00b7ren", "ge\u00b7w\u00e4hrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "NE", "PIAT", "NN", "KOUS", "ADJA", "VVPP", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Bin ich vom Hofe wieder zum Acker zur\u00fcckgekehrt.", "tokens": ["Bin", "ich", "vom", "Ho\u00b7fe", "wie\u00b7der", "zum", "A\u00b7cker", "zu\u00b7r\u00fcck\u00b7ge\u00b7kehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Inde\u00df die Andern, die wohl w\u00fcrdiger erschienen,", "tokens": ["In\u00b7de\u00df", "die", "An\u00b7dern", ",", "die", "wohl", "w\u00fcr\u00b7di\u00b7ger", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "$,", "PRELS", "ADV", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Hernach in h\u00f6chsten \u00c4mtern dem Staate durften dienen:", "tokens": ["Her\u00b7nach", "in", "h\u00f6chs\u00b7ten", "\u00c4m\u00b7tern", "dem", "Staa\u00b7te", "durf\u00b7ten", "die\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Hab' ich doch so viel gewonnen, da\u00df Jeder mu\u00df gesteh'n:", "tokens": ["Hab'", "ich", "doch", "so", "viel", "ge\u00b7won\u00b7nen", ",", "da\u00df", "Je\u00b7der", "mu\u00df", "ge\u00b7steh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADV", "ADV", "VVPP", "$,", "KOUS", "PIS", "VMFIN", "VVINF", "$."], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.27": {"text": "Bei mir ist nie was wider die Artigkeit gescheh'n,", "tokens": ["Bei", "mir", "ist", "nie", "was", "wi\u00b7der", "die", "Ar\u00b7tig\u00b7keit", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VAFIN", "ADV", "PIS", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Noch gegen das rechte Benehmen. Und ein Benehmen, ein feines, \u2013", "tokens": ["Noch", "ge\u00b7gen", "das", "rech\u00b7te", "Be\u00b7neh\u00b7men", ".", "Und", "ein", "Be\u00b7neh\u00b7men", ",", "ein", "fei\u00b7nes", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "$.", "KON", "ART", "NN", "$,", "ART", "ADJA", "$,", "$("], "meter": "-+--+--+--+-+--+-", "measure": "amphibrach.tetra.plus"}, "line.29": {"text": "Das sag' ich k\u00fchn, ist weder was Leichtes noch Kleines.", "tokens": ["Das", "sag'", "ich", "k\u00fchn", ",", "ist", "we\u00b7der", "was", "Leich\u00b7tes", "noch", "Klei\u00b7nes", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "KON", "PWS", "ADJA", "ADV", "NE", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.30": {"text": "Nichts Leichtes \u2013 denn mit dem Kratzfu\u00df ist es nicht gethan,", "tokens": ["Nichts", "Leich\u00b7tes", "\u2013", "denn", "mit", "dem", "Kratz\u00b7fu\u00df", "ist", "es", "nicht", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "NN", "$(", "KON", "APPR", "ART", "NN", "VAFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Anl\u00e4cheln, den Ersten Besten, das lernt ein Jeder an,", "tokens": ["An\u00b7l\u00e4\u00b7cheln", ",", "den", "Ers\u00b7ten", "Bes\u00b7ten", ",", "das", "lernt", "ein", "Je\u00b7der", "an", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "ADJA", "NN", "$,", "PDS", "VVFIN", "ART", "PIS", "PTKVZ", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Das ist die Artigkeit des Kr\u00e4mers, das ist modern,", "tokens": ["Das", "ist", "die", "Ar\u00b7tig\u00b7keit", "des", "Kr\u00e4\u00b7mers", ",", "das", "ist", "mo\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "ART", "NN", "$,", "PDS", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Doch nicht altpolnisch, nicht die Art der edlen Herrn.", "tokens": ["Doch", "nicht", "alt\u00b7pol\u00b7nisch", ",", "nicht", "die", "Art", "der", "ed\u00b7len", "Herrn", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "$,", "PTKNEG", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Artigkeit schuldet man Jedem, doch Jedem auf andre Art,", "tokens": ["Ar\u00b7tig\u00b7keit", "schul\u00b7det", "man", "Je\u00b7dem", ",", "doch", "Je\u00b7dem", "auf", "and\u00b7re", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "PIAT", "$,", "ADV", "PIAT", "APPR", "ADJA", "NN", "$,"], "meter": "+--+--+--+--+-+", "measure": "diphilius"}, "line.35": {"text": "Denn Kindesliebe mu\u00df auch sein mit Artigkeit gepaart,", "tokens": ["Denn", "Kin\u00b7des\u00b7lie\u00b7be", "mu\u00df", "auch", "sein", "mit", "Ar\u00b7tig\u00b7keit", "ge\u00b7paart", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VMFIN", "ADV", "PPOSAT", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.36": {"text": "Auch das Verhalten des Mannes zum Weibe \u2013 vor der Welt, \u2013", "tokens": ["Auch", "das", "Ver\u00b7hal\u00b7ten", "des", "Man\u00b7nes", "zum", "Wei\u00b7be", "\u2013", "vor", "der", "Welt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "ART", "NN", "ART", "NN", "APPRART", "NN", "$(", "APPR", "ART", "NN", "$,", "$("], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.37": {"text": "Des Herrn zur Dienerschaft: und nirgends ist's gleich bestellt.", "tokens": ["Des", "Herrn", "zur", "Die\u00b7ner\u00b7schaft", ":", "und", "nir\u00b7gends", "ist's", "gleich", "be\u00b7stellt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$.", "KON", "ADV", "VAFIN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Da mu\u00df man lange lernen, um wirklich nie zu fehlen", "tokens": ["Da", "mu\u00df", "man", "lan\u00b7ge", "ler\u00b7nen", ",", "um", "wirk\u00b7lich", "nie", "zu", "feh\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "ADV", "VVINF", "$,", "KOUI", "ADJD", "ADV", "PTKZU", "VVINF"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.39": {"text": "Und Jedem die schuldige Achtung richtig zuzuw\u00e4h len. \u2013", "tokens": ["Und", "Je\u00b7dem", "die", "schul\u00b7di\u00b7ge", "Ach\u00b7tung", "rich\u00b7tig", "zu\u00b7zu\u00b7w\u00e4h", "len", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PIAT", "ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "$.", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.40": {"text": "Die polnische Zeitgeschichte \u2013 die Schlachta redete gern", "tokens": ["Die", "pol\u00b7ni\u00b7sche", "Zeit\u00b7ge\u00b7schich\u00b7te", "\u2013", "die", "Schlach\u00b7ta", "re\u00b7de\u00b7te", "gern"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$(", "ART", "NN", "VVFIN", "ADV"], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.41": {"text": "Von Allem, was im engeren Bezirk geschehen;", "tokens": ["Von", "Al\u00b7lem", ",", "was", "im", "en\u00b7ge\u00b7ren", "Be\u00b7zirk", "ge\u00b7sche\u00b7hen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "$,", "PRELS", "APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.42": {"text": "So gab man denn dem Bruder Schlachcic zu verstehen,", "tokens": ["So", "gab", "man", "denn", "dem", "Bru\u00b7der", "Schlach\u00b7cic", "zu", "ver\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.43": {"text": "Da\u00df Alles ihn kennt, ihn nicht zu \u00fcbersehen vermag;", "tokens": ["Da\u00df", "Al\u00b7les", "ihn", "kennt", ",", "ihn", "nicht", "zu", "\u00fc\u00b7ber\u00b7se\u00b7hen", "ver\u00b7mag", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "PPER", "VVFIN", "$,", "PPER", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.44": {"text": "Drum lie\u00df sich auch der Schlachcic nicht gehen. \u2013 Heutzutag,", "tokens": ["Drum", "lie\u00df", "sich", "auch", "der", "Schlach\u00b7cic", "nicht", "ge\u00b7hen", ".", "\u2013", "Heut\u00b7zu\u00b7tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct"], "pos": ["PAV", "VVFIN", "PRF", "ADV", "ART", "NN", "PTKNEG", "VVINF", "$.", "$(", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.45": {"text": "Heut' fr\u00e4gt man Keinen: wer bist du? welcher Eltern Sohn?", "tokens": ["Heut'", "fr\u00e4gt", "man", "Kei\u00b7nen", ":", "wer", "bist", "du", "?", "wel\u00b7cher", "El\u00b7tern", "Sohn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "NN", "$.", "PWS", "VAFIN", "PPER", "$.", "PWAT", "NN", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.46": {"text": "Mit wem hast du gelebt? Und wie? Nein, nichts davon \u2013", "tokens": ["Mit", "wem", "hast", "du", "ge\u00b7lebt", "?", "Und", "wie", "?", "Nein", ",", "nichts", "da\u00b7von", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "PWS", "VAFIN", "PPER", "VVPP", "$.", "KON", "PWAV", "$.", "PTKANT", "$,", "PIS", "PAV", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.47": {"text": "Ist Einer nur kein Bettler oder gar ein Spion,", "tokens": ["Ist", "Ei\u00b7ner", "nur", "kein", "Bett\u00b7ler", "o\u00b7der", "gar", "ein", "Spi\u00b7on", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "ADV", "PIAT", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.48": {"text": "So wird in jedem Haus gleich k\u00fchnlich vorgesprochen.", "tokens": ["So", "wird", "in", "je\u00b7dem", "Haus", "gleich", "k\u00fchn\u00b7lich", "vor\u00b7ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "PIAT", "NN", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.49": {"text": "Wie jener Vespasian, der nie zum Geld gerochen,", "tokens": ["Wie", "je\u00b7ner", "Ves\u00b7pa\u00b7si\u00b7an", ",", "der", "nie", "zum", "Geld", "ge\u00b7ro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PDAT", "NE", "$,", "PRELS", "ADV", "APPRART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.50": {"text": "Und nie nach seinem Ursprung und Wege mochte fragen:", "tokens": ["Und", "nie", "nach", "sei\u00b7nem", "Ur\u00b7sprung", "und", "We\u00b7ge", "moch\u00b7te", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "PPOSAT", "NN", "KON", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.51": {"text": "So scheert man heut' sich nicht um Abkunft und Betragen;", "tokens": ["So", "scheert", "man", "heut'", "sich", "nicht", "um", "Ab\u00b7kunft", "und", "Be\u00b7tra\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "PRF", "PTKNEG", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.52": {"text": "Hat Einer Gewicht und Stempel, so gilt er in der Welt:", "tokens": ["Hat", "Ei\u00b7ner", "Ge\u00b7wicht", "und", "Stem\u00b7pel", ",", "so", "gilt", "er", "in", "der", "Welt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "KON", "NN", "$,", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.53": {"text": "So sch\u00e4tzt man denn die Freunde, wie die Juden das Geld.\u00ab", "tokens": ["So", "sch\u00e4tzt", "man", "denn", "die", "Freun\u00b7de", ",", "wie", "die", "Ju\u00b7den", "das", "Geld", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "$,", "PWAV", "ART", "NN", "ART", "NN", "$.", "$("], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.70": {"line.1": {"text": "So sprach der Richter und pr\u00fcfend blickt er umher im Kreis.", "tokens": ["So", "sprach", "der", "Rich\u00b7ter", "und", "pr\u00fc\u00b7fend", "blickt", "er", "um\u00b7her", "im", "Kreis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "ADJD", "VVFIN", "PPER", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn ob er gel\u00e4ufig redet und mit Verstand: er wei\u00df,", "tokens": ["Denn", "ob", "er", "ge\u00b7l\u00e4u\u00b7fig", "re\u00b7det", "und", "mit", "Ver\u00b7stand", ":", "er", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADJD", "VVFIN", "KON", "APPR", "NN", "$.", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Da\u00df ungeduldig die Jugend sei in unsren Tagen,", "tokens": ["Da\u00df", "un\u00b7ge\u00b7dul\u00b7dig", "die", "Ju\u00b7gend", "sei", "in", "un\u00b7sren", "Ta\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "VAFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Und langes Er\u00f6rtern sie langweilt, wie gut auch vorgetragen.", "tokens": ["Und", "lan\u00b7ges", "Er\u00b7\u00f6r\u00b7tern", "sie", "lang\u00b7weilt", ",", "wie", "gut", "auch", "vor\u00b7ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PPER", "VVFIN", "$,", "PWAV", "ADJD", "ADV", "VVPP", "$."], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Allein in tiefem Schweigen sitzen und horchen Alle.", "tokens": ["Al\u00b7lein", "in", "tie\u00b7fem", "Schwei\u00b7gen", "sit\u00b7zen", "und", "hor\u00b7chen", "Al\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ADJA", "NN", "VVINF", "KON", "VVFIN", "PIS", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Nun blickt er auf den K\u00e4mm'rer, wie das wohl ", "tokens": ["Nun", "blickt", "er", "auf", "den", "K\u00e4m\u00b7m'\u00b7rer", ",", "wie", "das", "wohl"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PWAV", "PDS", "ADV"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Der hat zwar nie mit Worten des Lobes unterbrochen,", "tokens": ["Der", "hat", "zwar", "nie", "mit", "Wor\u00b7ten", "des", "Lo\u00b7bes", "un\u00b7ter\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "ADV", "APPR", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Doch \u00f6fter Beifall genickt, inde\u00df der Richter gesprochen.", "tokens": ["Doch", "\u00f6f\u00b7ter", "Bei\u00b7fall", "ge\u00b7nickt", ",", "in\u00b7de\u00df", "der", "Rich\u00b7ter", "ge\u00b7spro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "NN", "VVPP", "$,", "ADV", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Der Redner schweigt. Der K\u00e4mm'rer nickt noch immerfort;", "tokens": ["Der", "Red\u00b7ner", "schweigt", ".", "Der", "K\u00e4m\u00b7m'\u00b7rer", "nickt", "noch", "im\u00b7mer\u00b7fort", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "VVFIN", "ADV", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "So f\u00fcllt er denn Beider Becher und nimmt auf's Neu' das Wort:", "tokens": ["So", "f\u00fcllt", "er", "denn", "Bei\u00b7der", "Be\u00b7cher", "und", "nimmt", "auf's", "Neu'", "das", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "PIAT", "NN", "KON", "VVFIN", "APPRART", "NN", "ART", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "\u00bbdie Artigkeit ist auch von nicht geringem Werth:", "tokens": ["\u00bb", "die", "Ar\u00b7tig\u00b7keit", "ist", "auch", "von", "nicht", "ge\u00b7rin\u00b7gem", "Werth", ":"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "VAFIN", "ADV", "APPR", "PTKNEG", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hat Einer Andre sch\u00e4tzen gelernt, wie sich geh\u00f6rt,", "tokens": ["Hat", "Ei\u00b7ner", "And\u00b7re", "sch\u00e4t\u00b7zen", "ge\u00b7lernt", ",", "wie", "sich", "ge\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PIS", "VVINF", "VVPP", "$,", "PWAV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Nach Alter und Geburt, nach Tugend und Gebahren,", "tokens": ["Nach", "Al\u00b7ter", "und", "Ge\u00b7burt", ",", "nach", "Tu\u00b7gend", "und", "Ge\u00b7bah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "So mag er auch ", "tokens": ["So", "mag", "er", "auch"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.15": {"text": "Wie wir auch bei der Wage, um unser Gewicht zu wissen,", "tokens": ["Wie", "wir", "auch", "bei", "der", "Wa\u00b7ge", ",", "um", "un\u00b7ser", "Ge\u00b7wicht", "zu", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "APPR", "ART", "NN", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "---+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Ein Gegengewicht an's andre Ende setzen m\u00fcssen.", "tokens": ["Ein", "Ge\u00b7gen\u00b7ge\u00b7wicht", "an's", "and\u00b7re", "En\u00b7de", "set\u00b7zen", "m\u00fcs\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "ADJA", "NN", "VVINF", "VMINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Werth aber ist, ihr Herren, besonderer Beachtung,", "tokens": ["Werth", "a\u00b7ber", "ist", ",", "ihr", "Her\u00b7ren", ",", "be\u00b7son\u00b7de\u00b7rer", "Be\u00b7ach\u00b7tung", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "VAFIN", "$,", "PPOSAT", "NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Wie J\u00fcnglinge den Damen erweisen schuld'ge Achtung.", "tokens": ["Wie", "J\u00fcng\u00b7lin\u00b7ge", "den", "Da\u00b7men", "er\u00b7wei\u00b7sen", "schuld'\u00b7ge", "Ach\u00b7tung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NN", "ART", "NN", "VVINF", "ADJA", "NN", "$."], "meter": "-+---+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.19": {"text": "Zumal wenn Gl\u00fcckesg\u00fcter und hoher Stand noch heben", "tokens": ["Zu\u00b7mal", "wenn", "Gl\u00fc\u00b7ckes\u00b7g\u00fc\u00b7ter", "und", "ho\u00b7her", "Stand", "noch", "he\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOUS", "NN", "KON", "ADJA", "NN", "ADV", "VVINF"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Die Tugenden und Reize, die Natur gegeben.", "tokens": ["Die", "Tu\u00b7gen\u00b7den", "und", "Rei\u00b7ze", ",", "die", "Na\u00b7tur", "ge\u00b7ge\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Da finden sich die Herzen, \u2013 da sah man sich gestalten", "tokens": ["Da", "fin\u00b7den", "sich", "die", "Her\u00b7zen", ",", "\u2013", "da", "sah", "man", "sich", "ge\u00b7stal\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF", "ART", "NN", "$,", "$(", "ADV", "VVFIN", "PIS", "PRF", "VVPP"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und drum\u00ab \u2013 hier wandt' er rasch den Kopf zur Seite hin,", "tokens": ["Und", "drum", "\u00ab", "\u2013", "hier", "wandt'", "er", "rasch", "den", "Kopf", "zur", "Sei\u00b7te", "hin", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PAV", "$(", "$(", "ADV", "VVFIN", "PPER", "ADJD", "ART", "NN", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Winkt' zu Thadd\u00e4us hin\u00fcber und blickte streng' auf ihn \u2013", "tokens": ["Winkt'", "zu", "Thad\u00b7d\u00e4us", "hin\u00b7\u00fc\u00b7ber", "und", "blick\u00b7te", "streng'", "auf", "ihn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "NE", "ADV", "KON", "VVFIN", "ADV", "APPR", "PPER", "$("], "meter": "+-+--+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.24": {"text": "Man sah, jetzt werd' er gleich die Nutzanwendung zieh'n.", "tokens": ["Man", "sah", ",", "jetzt", "werd'", "er", "gleich", "die", "Nut\u00b7zan\u00b7wen\u00b7dung", "zieh'", "n."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["PIS", "VVFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.71": {"line.1": {"text": "Da schlug der K\u00e4mm'rer klimpernd auf die goldne Dose", "tokens": ["Da", "schlug", "der", "K\u00e4m\u00b7m'\u00b7rer", "klim\u00b7pernd", "auf", "die", "gold\u00b7ne", "Do\u00b7se"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "VVPP", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und sprach: \u00bbEs mag schon sein, jetzt geht es etwas lose, \u2013", "tokens": ["Und", "sprach", ":", "\u00bb", "Es", "mag", "schon", "sein", ",", "jetzt", "geht", "es", "et\u00b7was", "lo\u00b7se", ",", "\u2013"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PPER", "VMFIN", "ADV", "VAINF", "$,", "ADV", "VVFIN", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Doch einst, mein lieber Richter, war's schlechter noch als heut!", "tokens": ["Doch", "einst", ",", "mein", "lie\u00b7ber", "Rich\u00b7ter", ",", "wa\u00b7r's", "schlech\u00b7ter", "noch", "als", "heut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$,", "VAFIN", "ADJD", "ADV", "KOKOM", "ADV", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.4": {"text": "Hat nun die neue Mode uns Alte auch erneut,", "tokens": ["Hat", "nun", "die", "neu\u00b7e", "Mo\u00b7de", "uns", "Al\u00b7te", "auch", "er\u00b7neut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN", "PPER", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Oder ist's wirklich besser, genug, so scheint es mir. \u2013", "tokens": ["O\u00b7der", "ist's", "wirk\u00b7lich", "bes\u00b7ser", ",", "ge\u00b7nug", ",", "so", "scheint", "es", "mir", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "VAFIN", "ADJD", "ADJD", "$,", "ADV", "$,", "ADV", "VVFIN", "PPER", "PPER", "$.", "$("], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "Ach, ich gedenke der Tage, da die Franzosenmanier", "tokens": ["Ach", ",", "ich", "ge\u00b7den\u00b7ke", "der", "Ta\u00b7ge", ",", "da", "die", "Fran\u00b7zo\u00b7sen\u00b7ma\u00b7nier"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ITJ", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+--+-++-+--+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Zum ersten Mal in's Land kam. Herrchen str\u00f6mten in Schaaren", "tokens": ["Zum", "ers\u00b7ten", "Mal", "in's", "Land", "kam", ".", "Herr\u00b7chen", "str\u00f6m\u00b7ten", "in", "Schaa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "APPRART", "NN", "VVFIN", "$.", "NN", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Aus fremden L\u00e4ndern her\u00fcber, \u00e4rger als Tataren,", "tokens": ["Aus", "frem\u00b7den", "L\u00e4n\u00b7dern", "her\u00b7\u00fc\u00b7ber", ",", "\u00e4r\u00b7ger", "als", "Ta\u00b7ta\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "$,", "ADJD", "KOKOM", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Die Gott und Glauben verfolgten und was uns die V\u00e4ter vermacht,", "tokens": ["Die", "Gott", "und", "Glau\u00b7ben", "ver\u00b7folg\u00b7ten", "und", "was", "uns", "die", "V\u00e4\u00b7ter", "ver\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "NN", "VVFIN", "KON", "PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+--+", "measure": "iambic.septa.relaxed"}, "line.10": {"text": "Gesetz und Recht und Sitten und selbst die alte Tracht!", "tokens": ["Ge\u00b7setz", "und", "Recht", "und", "Sit\u00b7ten", "und", "selbst", "die", "al\u00b7te", "Tracht", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Milchb\u00e4rte, vergilbt und n\u00e4selnd, oft auch nasenlos, \u2013", "tokens": ["Milch\u00b7b\u00e4r\u00b7te", ",", "ver\u00b7gilbt", "und", "n\u00e4\u00b7selnd", ",", "oft", "auch", "na\u00b7sen\u00b7los", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "$,", "VVPP", "KON", "VVPP", "$,", "ADV", "ADV", "ADJD", "$,", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Es war ein Jammer zu sehen, \u2013 die kamen und thaten gro\u00df,", "tokens": ["Es", "war", "ein", "Jam\u00b7mer", "zu", "se\u00b7hen", ",", "\u2013", "die", "ka\u00b7men", "und", "tha\u00b7ten", "gro\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "PTKZU", "VVINF", "$,", "$(", "ART", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Hatten Brochuren in H\u00e4nden und allerlei Zeitungsbl\u00e4tter,", "tokens": ["Hat\u00b7ten", "Broc\u00b7hu\u00b7ren", "in", "H\u00e4n\u00b7den", "und", "al\u00b7ler\u00b7lei", "Zei\u00b7tungs\u00b7bl\u00e4t\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "NN", "KON", "PIAT", "NN", "$,"], "meter": "+--+--+--+-++-+-", "measure": "dactylic.tri.plus"}, "line.14": {"text": "Verk\u00fcndeten neue Moden, neue Gesetze und G\u00f6tter;", "tokens": ["Ver\u00b7k\u00fcn\u00b7de\u00b7ten", "neu\u00b7e", "Mo\u00b7den", ",", "neu\u00b7e", "Ge\u00b7set\u00b7ze", "und", "G\u00f6t\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "$,", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Die Rotte nahm die Geister gefangen in kurzer Zeit;", "tokens": ["Die", "Rot\u00b7te", "nahm", "die", "Geis\u00b7ter", "ge\u00b7fan\u00b7gen", "in", "kur\u00b7zer", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "ADJD", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Denn wenn der Herr einmal ein Volk der Strafe geweiht,", "tokens": ["Denn", "wenn", "der", "Herr", "ein\u00b7mal", "ein", "Volk", "der", "Stra\u00b7fe", "ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "ART", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.17": {"text": "Dann pflegt er zuerst die K\u00f6pfe der B\u00fcrger zu verkehren.", "tokens": ["Dann", "pflegt", "er", "zu\u00b7erst", "die", "K\u00f6p\u00b7fe", "der", "B\u00fcr\u00b7ger", "zu", "ver\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "So wagten denn die Vern\u00fcnft'gen den Stutzern nicht zu wehren;", "tokens": ["So", "wag\u00b7ten", "denn", "die", "Ver\u00b7n\u00fcnft'\u00b7gen", "den", "Stut\u00b7zern", "nicht", "zu", "weh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "ART", "NN", "ART", "NN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Es f\u00fcrchtete sich vor ihnen das Volk, wie vor der Pest,", "tokens": ["Es", "f\u00fcrch\u00b7te\u00b7te", "sich", "vor", "ih\u00b7nen", "das", "Volk", ",", "wie", "vor", "der", "Pest", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "APPR", "PPER", "ART", "NN", "$,", "PWAV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Sa\u00df ja der Keim der Krankheit schon in den Herzen fest.", "tokens": ["Sa\u00df", "ja", "der", "Keim", "der", "Krank\u00b7heit", "schon", "in", "den", "Her\u00b7zen", "fest", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ART", "NN", "ADV", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Man schrie wol \u00fcber die Gecken, doch that man, wie sie thaten, \u2013", "tokens": ["Man", "schrie", "wol", "\u00fc\u00b7ber", "die", "Ge\u00b7cken", ",", "doch", "that", "man", ",", "wie", "sie", "tha\u00b7ten", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["PIS", "VVFIN", "ADV", "APPR", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "$,", "PWAV", "PPER", "VVFIN", "$,", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Gesetz und Glauben und Sprache \u2013 Alles wurde verrathen!", "tokens": ["Ge\u00b7setz", "und", "Glau\u00b7ben", "und", "Spra\u00b7che", "\u2013", "Al\u00b7les", "wur\u00b7de", "ver\u00b7ra\u00b7then", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "$(", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Es war ein Faschingspossen, voll Tollheit und voll Schmach,", "tokens": ["Es", "war", "ein", "Fa\u00b7schings\u00b7pos\u00b7sen", ",", "voll", "Toll\u00b7heit", "und", "voll", "Schmach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$,", "ADJD", "NN", "KON", "ADJD", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Dem bald das gro\u00dfe Fasten, die Knechtschaft, folgte nach!", "tokens": ["Dem", "bald", "das", "gro\u00b7\u00dfe", "Fas\u00b7ten", ",", "die", "Knecht\u00b7schaft", ",", "folg\u00b7te", "nach", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PDS", "ADV", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.72": {"line.1": {"text": "Wie ich aus meiner Kindheit mich zu erinnern wei\u00df,", "tokens": ["Wie", "ich", "aus", "mei\u00b7ner", "Kind\u00b7heit", "mich", "zu", "e\u00b7rin\u00b7nern", "wei\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PPOSAT", "NN", "PPER", "PTKZU", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.2": {"text": "Da kam zu meinem Vater in den Oszmianer Kreis", "tokens": ["Da", "kam", "zu", "mei\u00b7nem", "Va\u00b7ter", "in", "den", "Osz\u00b7mi\u00b7a\u00b7ner", "Kreis"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "PPOSAT", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.3": {"text": "Der Herr Podczaszyc", "tokens": ["Der", "Herr", "Pod\u00b7czas\u00b7zyc"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NE"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.4": {"text": "Der Erste, der in Lithau'n franz\u00f6sische Kleider getragen.", "tokens": ["Der", "Ers\u00b7te", ",", "der", "in", "Lit\u00b7hau'n", "fran\u00b7z\u00f6\u00b7si\u00b7sche", "Klei\u00b7der", "ge\u00b7tra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "PRELS", "APPR", "NN", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+--+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Als w\u00e4r's ein Wunderthier, so lief man hinter ihm her;", "tokens": ["Als", "w\u00e4r's", "ein", "Wun\u00b7der\u00b7thier", ",", "so", "lief", "man", "hin\u00b7ter", "ihm", "her", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "ART", "NN", "$,", "ADV", "VVFIN", "PIS", "APPR", "PPER", "PTKVZ", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Beneidet wurde das Haus, das da geno\u00df die Ehr',", "tokens": ["Be\u00b7nei\u00b7det", "wur\u00b7de", "das", "Haus", ",", "das", "da", "ge\u00b7no\u00df", "die", "Ehr'", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ART", "NN", "$,", "PRELS", "ADV", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das W\u00e4gelein mit den zwei R\u00e4dlein zu seh'n vor seiner Schwelle,", "tokens": ["Das", "W\u00e4\u00b7ge\u00b7lein", "mit", "den", "zwei", "R\u00e4d\u00b7lein", "zu", "seh'n", "vor", "sei\u00b7ner", "Schwel\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "CARD", "NN", "PTKZU", "VVINF", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.8": {"text": "Sah man im Wagenkasten zwei H\u00fcndchen auf dem Lager,", "tokens": ["Sah", "man", "im", "Wa\u00b7gen\u00b7kas\u00b7ten", "zwei", "H\u00fcnd\u00b7chen", "auf", "dem", "La\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPRART", "NN", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Auf dem Bock ein deutscher Kerl, als wie ein Brett, so mager,", "tokens": ["Auf", "dem", "Bock", "ein", "deut\u00b7scher", "Kerl", ",", "als", "wie", "ein", "Brett", ",", "so", "ma\u00b7ger", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NE", "ART", "ADJA", "NN", "$,", "KOUS", "KOKOM", "ART", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.10": {"text": "Mit langen, d\u00fcrren Beinen, wie die Hopfenstangen", "tokens": ["Mit", "lan\u00b7gen", ",", "d\u00fcr\u00b7ren", "Bei\u00b7nen", ",", "wie", "die", "Hop\u00b7fen\u00b7stan\u00b7gen"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ADJA", "$,", "ADJA", "NN", "$,", "PWAV", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit Str\u00fcmpfen daran, die Schuhe geziert mit silbernen Spangen.", "tokens": ["Mit", "Str\u00fcmp\u00b7fen", "da\u00b7ran", ",", "die", "Schu\u00b7he", "ge\u00b7ziert", "mit", "sil\u00b7ber\u00b7nen", "Span\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PAV", "$,", "ART", "NN", "VVPP", "APPR", "ADJA", "NN", "$."], "meter": "-+-++-+--+-+--+-", "measure": "iambic.septa.relaxed"}, "line.12": {"text": "Der Zopf an der Perr\u00fccke von einem Beutel gehalten \u2013", "tokens": ["Der", "Zopf", "an", "der", "Per\u00b7r\u00fc\u00b7cke", "von", "ei\u00b7nem", "Beu\u00b7tel", "ge\u00b7hal\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVPP", "$("], "meter": "-+--+---+-+--+-", "measure": "iambic.penta.relaxed"}, "line.13": {"text": "Wie sie das seh'n: vor Lachen bersten fast die Alten;", "tokens": ["Wie", "sie", "das", "seh'n", ":", "vor", "La\u00b7chen", "bers\u00b7ten", "fast", "die", "Al\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDS", "VVINF", "$.", "APPR", "NN", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die Bauersleute aber bekreuzen sich und sagen:", "tokens": ["Die", "Bau\u00b7ers\u00b7leu\u00b7te", "a\u00b7ber", "be\u00b7kreu\u00b7zen", "sich", "und", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PRF", "KON", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Der venetianische Teufel fahre im deutschen Wagen.", "tokens": ["Der", "ve\u00b7ne\u00b7ti\u00b7a\u00b7ni\u00b7sche", "Teu\u00b7fel", "fah\u00b7re", "im", "deut\u00b7schen", "Wa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+---+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Lang' aber w\u00e4r's, zu geben des Herrchens Konterfei:", "tokens": ["Lang'", "a\u00b7ber", "w\u00e4r's", ",", "zu", "ge\u00b7ben", "des", "Herr\u00b7chens", "Kon\u00b7ter\u00b7fei", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VAFIN", "$,", "PTKZU", "VVINF", "ART", "NN", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Uns kam er vor, wie ein Affe oder ein Papagei,", "tokens": ["Uns", "kam", "er", "vor", ",", "wie", "ein", "Af\u00b7fe", "o\u00b7der", "ein", "Pa\u00b7pa\u00b7gei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PTKVZ", "$,", "PWAV", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+----+-+-+--+", "measure": "iambic.penta.chol"}, "line.18": {"text": "In seiner gro\u00dfen Perr\u00fccke, die der n\u00e4rrische Tropf", "tokens": ["In", "sei\u00b7ner", "gro\u00b7\u00dfen", "Per\u00b7r\u00fc\u00b7cke", ",", "die", "der", "n\u00e4r\u00b7ri\u00b7sche", "Tropf"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "PRELS", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Dem goldnen Vlie\u00df verglich, \u2013 wir einem Weichselzopf.", "tokens": ["Dem", "gold\u00b7nen", "Vlie\u00df", "ver\u00b7glich", ",", "\u2013", "wir", "ei\u00b7nem", "Weich\u00b7sel\u00b7zopf", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJD", "$,", "$(", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wenn damals auch Mancher f\u00fchlte, da\u00df unsre polnische Tracht", "tokens": ["Wenn", "da\u00b7mals", "auch", "Man\u00b7cher", "f\u00fchl\u00b7te", ",", "da\u00df", "uns\u00b7re", "pol\u00b7ni\u00b7sche", "Tracht"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "PIS", "VVFIN", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Viel sch\u00f6ner sei, als das Fremde, das wir nachgemacht,", "tokens": ["Viel", "sch\u00f6\u00b7ner", "sei", ",", "als", "das", "Frem\u00b7de", ",", "das", "wir", "nach\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "$,", "KOUS", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "So schwieg er. Sonst h\u00e4tte \u203aVerrath!\u2039 geschrie'n die gr\u00fcne Schaar,", "tokens": ["So", "schwieg", "er", ".", "Sonst", "h\u00e4t\u00b7te", "\u203a", "Ver\u00b7rath", "!", "\u2039", "ge\u00b7schrie'n", "die", "gr\u00fc\u00b7ne", "Schaar", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "ADV", "VAFIN", "CARD", "NN", "$.", "$(", "VVPP", "ART", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "\u203averrath an der Cultur! Der Fortschritt in Gefahr!\u2039 \u2013", "tokens": ["\u203a", "ver\u00b7rath", "an", "der", "Cul\u00b7tur", "!", "Der", "Fort\u00b7schritt", "in", "Ge\u00b7fahr", "!", "\u2039", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["$(", "ADJD", "APPR", "ART", "NN", "$.", "ART", "NN", "APPR", "NN", "$.", "$(", "$("], "meter": "-+---+-+-+-+", "measure": "dactylic.init"}, "line.24": {"text": "Also beherrschte die Narrheit die K\u00f6pfe ganz und gar.", "tokens": ["Al\u00b7so", "be\u00b7herrschte", "die", "Nar\u00b7rheit", "die", "K\u00f6p\u00b7fe", "ganz", "und", "gar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "KON", "ADV", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}}, "stanza.73": {"line.1": {"text": "Der Ank\u00f6mmling versprach, er wolle uns reformiren,", "tokens": ["Der", "An\u00b7k\u00f6mm\u00b7ling", "ver\u00b7sprach", ",", "er", "wol\u00b7le", "uns", "re\u00b7for\u00b7mi\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "PPER", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Uns konstituiren und civilisiren \u2013", "tokens": ["Uns", "kons\u00b7ti\u00b7tu\u00b7i\u00b7ren", "und", "ci\u00b7vi\u00b7li\u00b7si\u00b7ren", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "KON", "VVINF", "$("], "meter": "-+--+-+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Erkl\u00e4rt' uns, da\u00df welche Redner im Franzosenreich", "tokens": ["Er\u00b7kl\u00e4rt'", "uns", ",", "da\u00df", "wel\u00b7che", "Red\u00b7ner", "im", "Fran\u00b7zo\u00b7sen\u00b7reich"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "$,", "KOUS", "PWAT", "NN", "APPRART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die neue Erfindung gemacht: die Menschen w\u00e4ren gleich.", "tokens": ["Die", "neu\u00b7e", "Er\u00b7fin\u00b7dung", "ge\u00b7macht", ":", "die", "Men\u00b7schen", "w\u00e4\u00b7ren", "gleich", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVPP", "$.", "ART", "NN", "VAFIN", "ADV", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Wiewohl doch diesen Punkt die Bibel l\u00e4ngst erledigt,", "tokens": ["Wie\u00b7wohl", "doch", "die\u00b7sen", "Punkt", "die", "Bi\u00b7bel", "l\u00e4ngst", "er\u00b7le\u00b7digt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PDAT", "NN", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Und jeder Geistliche das von der Kanzel predigt.", "tokens": ["Und", "je\u00b7der", "Geist\u00b7li\u00b7che", "das", "von", "der", "Kan\u00b7zel", "pre\u00b7digt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ART", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Satz war alt; es galt nur, da\u00df man ihn erf\u00fcllt!", "tokens": ["Der", "Satz", "war", "alt", ";", "es", "galt", "nur", ",", "da\u00df", "man", "ihn", "er\u00b7f\u00fcllt", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$.", "PPER", "VVFIN", "ADV", "$,", "KOUS", "PIS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Doch damals hat alle K\u00f6pfe solche Blindheit umh\u00fcllt,", "tokens": ["Doch", "da\u00b7mals", "hat", "al\u00b7le", "K\u00f6p\u00b7fe", "sol\u00b7che", "Blind\u00b7heit", "um\u00b7h\u00fcllt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIAT", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Da\u00df selbst die \u00e4lteste Sache keinen Glauben fand,", "tokens": ["Da\u00df", "selbst", "die", "\u00e4l\u00b7tes\u00b7te", "Sa\u00b7che", "kei\u00b7nen", "Glau\u00b7ben", "fand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "ADJA", "NN", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wenn's in franz\u00f6sischen Bl\u00e4ttern nicht zu lesen stand.", "tokens": ["Wenn's", "in", "fran\u00b7z\u00f6\u00b7si\u00b7schen", "Bl\u00e4t\u00b7tern", "nicht", "zu", "le\u00b7sen", "stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ADJA", "NN", "PTKNEG", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df sich der Herr Podczaszyc Marquis benennen lie\u00df,", "tokens": ["Da\u00df", "sich", "der", "Herr", "Pod\u00b7czas\u00b7zyc", "Mar\u00b7quis", "be\u00b7nen\u00b7nen", "lie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "NE", "NE", "VVINF", "VVFIN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Verschlug nicht gegen die Gleichheit. Die Titel sind aus Paris \u2013", "tokens": ["Ver\u00b7schlug", "nicht", "ge\u00b7gen", "die", "Gleich\u00b7heit", ".", "Die", "Ti\u00b7tel", "sind", "aus", "Pa\u00b7ris", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "ART", "NN", "$.", "ART", "NN", "VAFIN", "APPR", "NE", "$("], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Und damals waren sie dort modern, die \u203aHerrn Marquis.\u2039", "tokens": ["Und", "da\u00b7mals", "wa\u00b7ren", "sie", "dort", "mo\u00b7dern", ",", "die", "\u203a", "Herrn", "Mar\u00b7quis", ".", "\u2039"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "ADV", "VVINF", "$,", "ART", "ADJA", "NN", "NE", "$.", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Als aber sp\u00e4ter die Mode in andre Geleise trat,", "tokens": ["Als", "a\u00b7ber", "sp\u00e4\u00b7ter", "die", "Mo\u00b7de", "in", "and\u00b7re", "Ge\u00b7lei\u00b7se", "trat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ADJD", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Da f\u00fchrte derselbe Marquis den Titel Demokrat;", "tokens": ["Da", "f\u00fchr\u00b7te", "der\u00b7sel\u00b7be", "Mar\u00b7quis", "den", "Ti\u00b7tel", "De\u00b7mo\u00b7krat", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PDAT", "NN", "ART", "NN", "NN", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Zuletzt, bei der neuen Mode, unter Napoleon,", "tokens": ["Zu\u00b7letzt", ",", "bei", "der", "neu\u00b7en", "Mo\u00b7de", ",", "un\u00b7ter", "Na\u00b7po\u00b7le\u00b7on", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "$,", "APPR", "ART", "ADJA", "NN", "$,", "APPR", "NE", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Kam unser Demokrat zur\u00fcck aus Paris: als Baron;", "tokens": ["Kam", "un\u00b7ser", "De\u00b7mo\u00b7krat", "zu\u00b7r\u00fcck", "aus", "Pa\u00b7ris", ":", "als", "Ba\u00b7ron", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "PPOSAT", "NN", "PTKVZ", "APPR", "NE", "$.", "KOUS", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Vielleicht, im Lauf der Zeit, h\u00e4tt' sich bei l\u00e4ng'rem Leben", "tokens": ["Viel\u00b7leicht", ",", "im", "Lauf", "der", "Zeit", ",", "h\u00e4tt'", "sich", "bei", "l\u00e4ng'\u00b7rem", "Le\u00b7ben"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "$,", "APPRART", "NN", "ART", "NN", "$,", "VAFIN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Paris lebt ja am liebsten nach immer neuem Schnitt,", "tokens": ["Pa\u00b7ris", "lebt", "ja", "am", "liebs\u00b7ten", "nach", "im\u00b7mer", "neu\u00b7em", "Schnitt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PTKA", "ADJD", "APPR", "ADV", "ADJA", "NN", "$,"], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.20": {"text": "Und was der Franzmann aufbringt, das macht der Pole mit.", "tokens": ["Und", "was", "der", "Franz\u00b7mann", "auf\u00b7bringt", ",", "das", "macht", "der", "Po\u00b7le", "mit", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ART", "NN", "VVFIN", "$,", "PDS", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.74": {"line.1": {"text": "Gottlob, da\u00df wenn die Jugend jetzt in's Ausland zieht,", "tokens": ["Gott\u00b7lob", ",", "da\u00df", "wenn", "die", "Ju\u00b7gend", "jetzt", "in's", "Aus\u00b7land", "zieht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "KOUS", "ART", "NN", "ADV", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Es nicht mehr so, wie fr\u00fcher, der Kleider wegen geschieht, \u2013", "tokens": ["Es", "nicht", "mehr", "so", ",", "wie", "fr\u00fc\u00b7her", ",", "der", "Klei\u00b7der", "we\u00b7gen", "ge\u00b7schieht", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADV", "$,", "PWAV", "ADJD", "$,", "ART", "NN", "APPR", "VVFIN", "$,", "$("], "meter": "--+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Nicht um in gedrucktem Kram nach neuen Gesetzen zu sp\u00fcren,", "tokens": ["Nicht", "um", "in", "ge\u00b7druck\u00b7tem", "Kram", "nach", "neu\u00b7en", "Ge\u00b7set\u00b7zen", "zu", "sp\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "KOUI", "APPR", "ADJA", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Oder Beredtsamkeit im Caf\u00e9 zu studiren.", "tokens": ["O\u00b7der", "Be\u00b7redt\u00b7sam\u00b7keit", "im", "Ca\u00b7f\u00e9", "zu", "stu\u00b7di\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.5": {"text": "Denn der Napoleon, ein energischer Mann und gescheidt,", "tokens": ["Denn", "der", "Na\u00b7po\u00b7le\u00b7on", ",", "ein", "e\u00b7ner\u00b7gi\u00b7scher", "Mann", "und", "ge\u00b7scheidt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NE", "$,", "ART", "ADJA", "NN", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.6": {"text": "Der l\u00e4\u00dft f\u00fcr Plaudereien und Moden keine Zeit;", "tokens": ["Der", "l\u00e4\u00dft", "f\u00fcr", "Plau\u00b7de\u00b7rei\u00b7en", "und", "Mo\u00b7den", "kei\u00b7ne", "Zeit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "NE", "KON", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Jetzt dr\u00f6hnen die Waffen; da schwillt uns alten Leuten das Herz,", "tokens": ["Jetzt", "dr\u00f6h\u00b7nen", "die", "Waf\u00b7fen", ";", "da", "schwillt", "uns", "al\u00b7ten", "Leu\u00b7ten", "das", "Herz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADJA", "NN", "ART", "NN", "$,"], "meter": "-+--+--+-+-+--+", "measure": "amphibrach.tri.plus"}, "line.8": {"text": "Da\u00df wieder man von den Polen h\u00f6rt reden allerw\u00e4rts.", "tokens": ["Da\u00df", "wie\u00b7der", "man", "von", "den", "Po\u00b7len", "h\u00f6rt", "re\u00b7den", "al\u00b7ler\u00b7w\u00e4rts", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIS", "APPR", "ART", "NN", "VVFIN", "VVFIN", "ADV", "$."], "meter": "-+----+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Der Ruhm ist da \u2013 so ist auch die Republik nicht fern!", "tokens": ["Der", "Ruhm", "ist", "da", "\u2013", "so", "ist", "auch", "die", "Re\u00b7pub\u00b7lik", "nicht", "fern", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "$(", "ADV", "VAFIN", "ADV", "ART", "NN", "PTKNEG", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Der Baum der Freiheit sprie\u00dft ja aus dem Lorbeer gern; \u2013", "tokens": ["Der", "Baum", "der", "Frei\u00b7heit", "sprie\u00dft", "ja", "aus", "dem", "Lor\u00b7beer", "gern", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "ADV", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Nur traurig, da\u00df sich uns so ohne Th\u00e4tigkeit", "tokens": ["Nur", "trau\u00b7rig", ",", "da\u00df", "sich", "uns", "so", "oh\u00b7ne", "Th\u00e4\u00b7tig\u00b7keit"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "$,", "KOUS", "PRF", "PPER", "ADV", "APPR", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Die Jahre schleppen! Und Jene so ferne allezeit, \u2013", "tokens": ["Die", "Jah\u00b7re", "schlep\u00b7pen", "!", "Und", "Je\u00b7ne", "so", "fer\u00b7ne", "al\u00b7le\u00b7zeit", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVINF", "$.", "KON", "PDS", "ADV", "ADV", "ADV", "$,", "$("], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "So lange warten! Und selten kommt eine Nachricht sogar!", "tokens": ["So", "lan\u00b7ge", "war\u00b7ten", "!", "Und", "sel\u00b7ten", "kommt", "ei\u00b7ne", "Nach\u00b7richt", "so\u00b7gar", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVINF", "$.", "KON", "ADJD", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "H\u00f6rt,\u00ab \u2013 sprach er leise zum M\u00f6nch, \u2013 \u00bbh\u00f6rt, Pater Robak, ist's wahr,", "tokens": ["H\u00f6rt", ",", "\u00ab", "\u2013", "sprach", "er", "lei\u00b7se", "zum", "M\u00f6nch", ",", "\u2013", "\u00bb", "h\u00f6rt", ",", "Pa\u00b7ter", "Ro\u00b7bak", ",", "ist's", "wahr", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "$(", "$(", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$,", "$(", "$(", "VVFIN", "$,", "NN", "NE", "$,", "VAFIN", "ADJD", "$,"], "meter": "-+-+--+-+----+", "measure": "iambic.penta.relaxed"}, "line.15": {"text": "Da\u00df ihr von jenseits des Niemen Briefe habt bekommen?", "tokens": ["Da\u00df", "ihr", "von", "jen\u00b7seits", "des", "Nie\u00b7men", "Brie\u00b7fe", "habt", "be\u00b7kom\u00b7men", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "APPR", "ART", "ADJA", "NN", "VAFIN", "VVINF", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Habt ihr nicht etwas auch von unsrem Heer vernommen?\u00ab", "tokens": ["Habt", "ihr", "nicht", "et\u00b7was", "auch", "von", "uns\u00b7rem", "Heer", "ver\u00b7nom\u00b7men", "?", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ADV", "APPR", "PPOSAT", "NN", "VVPP", "$.", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u00bbgar nichts,\u00ab warf k\u00fchlen Tons der Bernhardiner hin,", "tokens": ["\u00bb", "gar", "nichts", ",", "\u00ab", "warf", "k\u00fch\u00b7len", "Tons", "der", "Bern\u00b7har\u00b7di\u00b7ner", "hin", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PIS", "$,", "$(", "VVFIN", "ADJA", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Das ganze Gespr\u00e4ch war sichtlich nicht nach seinem Sinn \u2013", "tokens": ["Das", "gan\u00b7ze", "Ge\u00b7spr\u00e4ch", "war", "sicht\u00b7lich", "nicht", "nach", "sei\u00b7nem", "Sinn", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PRF", "PTKNEG", "APPR", "PPOSAT", "NN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "\u00bbwas scheert's mich auch? Mich langweilt das politische Treiben;", "tokens": ["\u00bb", "was", "scheert's", "mich", "auch", "?", "Mich", "lang\u00b7weilt", "das", "po\u00b7li\u00b7ti\u00b7sche", "Trei\u00b7ben", ";"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "PPER", "ADV", "$.", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Hab' ich auch was aus Warschau, so betrifft das Schreiben", "tokens": ["Hab'", "ich", "auch", "was", "aus", "Warsc\u00b7hau", ",", "so", "be\u00b7tr\u00b7ifft", "das", "Schrei\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "ADV", "PRELS", "APPR", "NE", "$,", "ADV", "VVFIN", "ART", "NN"], "meter": "+-+-+-+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.21": {"text": "Nur Ordenssachen. Wer f\u00e4ngt davon beim Nachtmahl an?", "tokens": ["Nur", "Or\u00b7dens\u00b7sa\u00b7chen", ".", "Wer", "f\u00e4ngt", "da\u00b7von", "beim", "Nacht\u00b7mahl", "an", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "$.", "PWS", "VVFIN", "PAV", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Hier giebt es Laien, f\u00fcr die das nicht geh\u00f6ren kann.\u00ab", "tokens": ["Hier", "giebt", "es", "Lai\u00b7en", ",", "f\u00fcr", "die", "das", "nicht", "ge\u00b7h\u00f6\u00b7ren", "kann", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NE", "$,", "APPR", "PRELS", "PDS", "PTKNEG", "VVINF", "VMFIN", "$.", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.75": {"line.1": {"text": "So sprach der M\u00f6nch und schielte zur Seite bei dem Wort.", "tokens": ["So", "sprach", "der", "M\u00f6nch", "und", "schiel\u00b7te", "zur", "Sei\u00b7te", "bei", "dem", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "KON", "VVFIN", "APPRART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Ein Russe, der Hauptmann Rykow, sa\u00df unter den G\u00e4sten dort,", "tokens": ["Ein", "Rus\u00b7se", ",", "der", "Haupt\u00b7mann", "Ry\u00b7kow", ",", "sa\u00df", "un\u00b7ter", "den", "G\u00e4s\u00b7ten", "dort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ART", "NN", "NE", "$,", "VVFIN", "APPR", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Ein alter Kriegsmann, im nahen D\u00f6rfchen einquartiert,", "tokens": ["Ein", "al\u00b7ter", "Kriegs\u00b7mann", ",", "im", "na\u00b7hen", "D\u00f6rf\u00b7chen", "ein\u00b7quar\u00b7tiert", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "APPRART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Aus H\u00f6flichkeit geladen. Der hatte nur wenig gesp\u00fcrt", "tokens": ["Aus", "H\u00f6f\u00b7lich\u00b7keit", "ge\u00b7la\u00b7den", ".", "Der", "hat\u00b7te", "nur", "we\u00b7nig", "ge\u00b7sp\u00fcrt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "VVPP", "$.", "PDS", "VAFIN", "ADV", "PIS", "VVPP"], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Von allen den Reden; in's Essen war er versunken tief.", "tokens": ["Von", "al\u00b7len", "den", "Re\u00b7den", ";", "in's", "Es\u00b7sen", "war", "er", "ver\u00b7sun\u00b7ken", "tief", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$.", "APPRART", "NN", "VAFIN", "PPER", "VVFIN", "ADJD", "$."], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Doch nun er von Warschau h\u00f6rte, erhob er den Kopf und rief:", "tokens": ["Doch", "nun", "er", "von", "Warsc\u00b7hau", "h\u00f6r\u00b7te", ",", "er\u00b7hob", "er", "den", "Kopf", "und", "rief", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PPER", "APPR", "NE", "VVFIN", "$,", "VVFIN", "PPER", "ART", "NN", "KON", "VVFIN", "$."], "meter": "-+--+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "\u00bbherr K\u00e4mmerer! O, ihr! Ihr wollt nur allerhand", "tokens": ["\u00bb", "herr", "K\u00e4m\u00b7me\u00b7rer", "!", "O", ",", "ihr", "!", "Ihr", "wollt", "nur", "al\u00b7ler\u00b7hand"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["$(", "NN", "NN", "$.", "NE", "$,", "PPER", "$.", "PPER", "VMFIN", "ADV", "PIAT"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Von Bonaparte! von Warschau! Ja, das Vaterland!", "tokens": ["Von", "Bo\u00b7na\u00b7par\u00b7te", "!", "von", "Warsc\u00b7hau", "!", "Ja", ",", "das", "Va\u00b7ter\u00b7land", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "APPR", "NE", "$.", "PTKANT", "$,", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Ich bin kein Spion \u2013 kann polnisch kann Das wohl versteh'n,", "tokens": ["Ich", "bin", "kein", "Spi\u00b7on", "\u2013", "kann", "pol\u00b7nisch", "kann", "Das", "wohl", "ver\u00b7steh'n", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$(", "VMFIN", "ADJD", "VMFIN", "PDS", "ADV", "VVINF", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Ja, Vaterland! ja wohl! kann mir zu Herzen geh'n!", "tokens": ["Ja", ",", "Va\u00b7ter\u00b7land", "!", "ja", "wohl", "!", "kann", "mir", "zu", "Her\u00b7zen", "geh'n", "!"], "token_info": ["word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$.", "ADV", "ADV", "$.", "VMFIN", "PPER", "APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Jetzt ist ja Waffenstillstand, drum br\u00fcderlich essen, saufen!", "tokens": ["Jetzt", "ist", "ja", "Waf\u00b7fen\u00b7still\u00b7stand", ",", "drum", "br\u00fc\u00b7der\u00b7lich", "es\u00b7sen", ",", "sau\u00b7fen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "NN", "$,", "PAV", "ADJD", "VVINF", "$,", "VVFIN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Thun oft so mit dem Franzmann auf den Posten schwatzen,", "tokens": ["Thun", "oft", "so", "mit", "dem", "Franz\u00b7mann", "auf", "den", "Pos\u00b7ten", "schwat\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "APPR", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Schnaps trinken, \u2013 dann hei\u00dft's: Hurrah! und die Kart\u00e4tschen platzen.", "tokens": ["Schnaps", "trin\u00b7ken", ",", "\u2013", "dann", "hei\u00dft's", ":", "Hur\u00b7rah", "!", "und", "die", "Kar\u00b7t\u00e4t\u00b7schen", "plat\u00b7zen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVINF", "$,", "$(", "ADV", "NE", "$.", "NN", "$.", "KON", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Ein russisches Sprichwort: Geliebt, geklopft! \u2013 wie mit den Frauen:", "tokens": ["Ein", "rus\u00b7si\u00b7sches", "Sprich\u00b7wort", ":", "Ge\u00b7liebt", ",", "ge\u00b7klopft", "!", "\u2013", "wie", "mit", "den", "Frau\u00b7en", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "VVPP", "$,", "VVPP", "$.", "$(", "KOKOM", "APPR", "ART", "NN", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.15": {"text": "Gestreichelt, wie mit der Pl\u00e4tte, wie einen Pelz gehauen!", "tokens": ["Ge\u00b7strei\u00b7chelt", ",", "wie", "mit", "der", "Pl\u00e4t\u00b7te", ",", "wie", "ei\u00b7nen", "Pelz", "ge\u00b7hau\u00b7en", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PWAV", "APPR", "ART", "NN", "$,", "PWAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Ich sag': 'S wird Krieg! \u2013 Vorgestern kam die Ordre herab,", "tokens": ["Ich", "sag'", ":", "'s", "wird", "Krieg", "!", "\u2013", "Vor\u00b7ges\u00b7tern", "kam", "die", "Ord\u00b7re", "her\u00b7ab", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NE", "VAFIN", "NN", "$.", "$(", "NN", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Es brachte sie dem Major der Adjutant vom Stab:", "tokens": ["Es", "brach\u00b7te", "sie", "dem", "Ma\u00b7jor", "der", "Ad\u00b7ju\u00b7tant", "vom", "Stab", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NE", "ART", "NN", "APPRART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Marschfertig stehen! Gilt's nun dem T\u00fcrken oder Franzen; \u2013", "tokens": ["Marschfer\u00b7tig", "ste\u00b7hen", "!", "Gilt's", "nun", "dem", "T\u00fcr\u00b7ken", "o\u00b7der", "Fran\u00b7zen", ";", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVINF", "$.", "NE", "ADV", "ART", "NN", "KON", "NN", "$.", "$("], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.19": {"text": "He! dieser Bonaparte! der k\u00f6nnt' uns kuranzen!", "tokens": ["He", "!", "die\u00b7ser", "Bo\u00b7na\u00b7par\u00b7te", "!", "der", "k\u00f6nnt'", "uns", "ku\u00b7ran\u00b7zen", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$.", "PDAT", "NN", "$.", "ART", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Ohne Suwarow n\u00e4hm's vielleicht ein b\u00f6ses End'; \u2013", "tokens": ["Oh\u00b7ne", "Su\u00b7wa\u00b7row", "n\u00e4hm's", "viel\u00b7leicht", "ein", "b\u00f6\u00b7ses", "End'", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NE", "ADV", "ART", "ADJA", "NN", "$.", "$("], "meter": "+----+-+-+-+", "measure": "dactylic.init"}, "line.21": {"text": "Wie's mit dem Franzmann losging, da hie\u00df es im Regiment:", "tokens": ["Wie's", "mit", "dem", "Franz\u00b7mann", "los\u00b7ging", ",", "da", "hie\u00df", "es", "im", "Re\u00b7gi\u00b7ment", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PPER", "APPRART", "NN", "$."], "meter": "+--+-+--+--+-+", "measure": "iambic.hexa.invert"}, "line.22": {"text": "Der Bonaparte hext.", "tokens": ["Der", "Bo\u00b7na\u00b7par\u00b7te", "hext", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.23": {"text": "Denn Suwarow hext auch. Einst, in der Schlacht, verschwand er:", "tokens": ["Denn", "Su\u00b7wa\u00b7row", "hext", "auch", ".", "Einst", ",", "in", "der", "Schlacht", ",", "ver\u00b7schwand", "er", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NE", "VVFIN", "ADV", "$.", "ADV", "$,", "APPR", "ART", "NN", "$,", "VVFIN", "PPER", "$."], "meter": "-+-+--+--+-+-", "measure": "iambic.penta.relaxed"}, "line.24": {"text": "Wohin? Sucht Bonaparten; nun aber ging's euch bunt,", "tokens": ["Wo\u00b7hin", "?", "Sucht", "Bo\u00b7na\u00b7par\u00b7ten", ";", "nun", "a\u00b7ber", "ging's", "euch", "bunt", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$.", "VVFIN", "NN", "$.", "ADV", "ADV", "VVFIN", "PPER", "ADJD", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Der Franzmann wird zum Fuchs \u2013 und Suwarow zum Hund,", "tokens": ["Der", "Franz\u00b7mann", "wird", "zum", "Fuchs", "\u2013", "und", "Su\u00b7wa\u00b7row", "zum", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPRART", "NE", "$(", "KON", "NE", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Drauf Bonaparte zum Kater und kratzt' euch mit den Krallen \u2013", "tokens": ["Drauf", "Bo\u00b7na\u00b7par\u00b7te", "zum", "Ka\u00b7ter", "und", "kratzt'", "euch", "mit", "den", "Kral\u00b7len", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "NN", "APPRART", "NN", "KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und Suwarow zum Fohlen. \u2013 Was weiter vorgefallen,", "tokens": ["Und", "Su\u00b7wa\u00b7row", "zum", "Foh\u00b7len", ".", "\u2013", "Was", "wei\u00b7ter", "vor\u00b7ge\u00b7fal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NE", "APPRART", "NN", "$.", "$(", "PWS", "ADV", "VVPP", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.28": {"text": "Mit unsern Hexenmeistern \u2013 nun, da gebt nur Acht \u2013\u00ab", "tokens": ["Mit", "un\u00b7sern", "He\u00b7xen\u00b7meis\u00b7tern", "\u2013", "nun", ",", "da", "gebt", "nur", "Acht", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$(", "ADV", "$,", "ADV", "VVFIN", "ADV", "CARD", "$(", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Hier schwieg er und a\u00df. Es wurde der vierte Gang gebracht,", "tokens": ["Hier", "schwieg", "er", "und", "a\u00df", ".", "Es", "wur\u00b7de", "der", "vier\u00b7te", "Gang", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "KON", "VVFIN", "$.", "PPER", "VAFIN", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Als pl\u00f6tzlich die Seitenth\u00fcre rasch ward aufgemacht.", "tokens": ["Als", "pl\u00f6tz\u00b7lich", "die", "Sei\u00b7tent\u00b7h\u00fc\u00b7re", "rasch", "ward", "auf\u00b7ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJD", "ART", "NN", "ADJD", "VAFIN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.76": {"line.1": {"text": "Eintrat ein weiblich Wesen, jung und wohlgestaltet;", "tokens": ["Ein\u00b7trat", "ein", "weib\u00b7lich", "We\u00b7sen", ",", "jung", "und", "wohl\u00b7ge\u00b7stal\u00b7tet", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "ADJD", "NN", "$,", "ADJD", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr pl\u00f6tzlich Kommen, ihr Reiz, der Putz, den sie entfaltet,", "tokens": ["Ihr", "pl\u00f6tz\u00b7lich", "Kom\u00b7men", ",", "ihr", "Reiz", ",", "der", "Putz", ",", "den", "sie", "ent\u00b7fal\u00b7tet", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "NN", "$,", "PPOSAT", "NN", "$,", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Lenkt Aller Blick auf sie; man hei\u00dft sie froh willkommen,", "tokens": ["Lenkt", "Al\u00b7ler", "Blick", "auf", "sie", ";", "man", "hei\u00dft", "sie", "froh", "will\u00b7kom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJA", "NN", "APPR", "PPER", "$.", "PIS", "VVFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Offenbar kennen sie Alle, Thadd\u00e4us ausgenommen; \u2013", "tokens": ["Of\u00b7fen\u00b7bar", "ken\u00b7nen", "sie", "Al\u00b7le", ",", "Thad\u00b7d\u00e4us", "aus\u00b7ge\u00b7nom\u00b7men", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["ADJD", "VVFIN", "PPER", "PIS", "$,", "NE", "VVPP", "$.", "$("], "meter": "+-----+-+-+-+-", "measure": "dactylic.init"}, "line.5": {"text": "Von schwerem rosafarbnem Seidengewand umflossen", "tokens": ["Von", "schwe\u00b7rem", "ro\u00b7sa\u00b7farb\u00b7nem", "Sei\u00b7den\u00b7ge\u00b7wand", "um\u00b7flos\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "ADJA", "NN", "VVINF"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Der schlanke Leib, der Hals von Spitzen rund umschlossen;", "tokens": ["Der", "schlan\u00b7ke", "Leib", ",", "der", "Hals", "von", "Spit\u00b7zen", "rund", "um\u00b7schlos\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Krause ausgeschnitten an der holden Brust,", "tokens": ["Die", "Krau\u00b7se", "aus\u00b7ge\u00b7schnit\u00b7ten", "an", "der", "hol\u00b7den", "Brust", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die \u00c4rmel kurz, \u2013 den F\u00e4cher h\u00e4lt sie nur zur Lust,", "tokens": ["Die", "\u00c4r\u00b7mel", "kurz", ",", "\u2013", "den", "F\u00e4\u00b7cher", "h\u00e4lt", "sie", "nur", "zur", "Lust", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "$,", "$(", "ART", "NN", "VVFIN", "PPER", "ADV", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Es ist ja gar nicht hei\u00df \u2013 der F\u00e4cher, mit Gold belegt,", "tokens": ["Es", "ist", "ja", "gar", "nicht", "hei\u00df", "\u2013", "der", "F\u00e4\u00b7cher", ",", "mit", "Gold", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PTKNEG", "ADJD", "$(", "ART", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Spr\u00fcht Funken rings umher, wie sie ihn spielend bewegt.", "tokens": ["Spr\u00fcht", "Fun\u00b7ken", "rings", "um\u00b7her", ",", "wie", "sie", "ihn", "spie\u00b7lend", "be\u00b7wegt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ADV", "PTKVZ", "$,", "PWAV", "PPER", "PPER", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Der Kopf, wie ein Haubenstock: das Haar in Locken gebunden,", "tokens": ["Der", "Kopf", ",", "wie", "ein", "Hau\u00b7ben\u00b7stock", ":", "das", "Haar", "in", "Lo\u00b7cken", "ge\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "NN", "$.", "ART", "NN", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Von rosafarbnen B\u00e4ndern \u00fcberall durchwunden \u2013", "tokens": ["Von", "ro\u00b7sa\u00b7farb\u00b7nen", "B\u00e4n\u00b7dern", "\u00fc\u00b7be\u00b7rall", "durch\u00b7wun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVINF", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Inmitten, dem Aug' zur Folie, gl\u00e4nzt ein Edelstein,", "tokens": ["In\u00b7mit\u00b7ten", ",", "dem", "Aug'", "zur", "Fo\u00b7lie", ",", "gl\u00e4nzt", "ein", "E\u00b7del\u00b7stein", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Wie im Kometenschweife eines Sternes Schein.", "tokens": ["Wie", "im", "Ko\u00b7me\u00b7ten\u00b7schwei\u00b7fe", "ei\u00b7nes", "Ster\u00b7nes", "Schein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Kurz, eine Galatracht; und Manche fl\u00fcstern still,", "tokens": ["Kurz", ",", "ei\u00b7ne", "Ga\u00b7la\u00b7tracht", ";", "und", "Man\u00b7che", "fl\u00fcs\u00b7tern", "still", ","], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ART", "NN", "$.", "KON", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Das Kleid ist kurz, und doch entdeckt man die F\u00fc\u00dfchen schwer \u2013", "tokens": ["Das", "Kleid", "ist", "kurz", ",", "und", "doch", "ent\u00b7deckt", "man", "die", "F\u00fc\u00df\u00b7chen", "schwer", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADJD", "$,", "KON", "ADV", "VVFIN", "PIS", "ART", "NN", "ADJD", "$("], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Wie sie so schnell dahinl\u00e4uft oder sich schiebt vielmehr,", "tokens": ["Wie", "sie", "so", "schnell", "da\u00b7hin\u00b7l\u00e4uft", "o\u00b7der", "sich", "schiebt", "viel\u00b7mehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADJD", "VVFIN", "KON", "PRF", "VVFIN", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Gleich den Pers\u00f6nchen, die man am Dreik\u00f6nigsfest", "tokens": ["Gleich", "den", "Per\u00b7s\u00f6n\u00b7chen", ",", "die", "man", "am", "Drei\u00b7k\u00f6\u00b7nigs\u00b7fest"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "$,", "PRELS", "PIS", "APPRART", "NN"], "meter": "+-++-+-+-+-+", "measure": "unknown.measure.septa"}, "line.19": {"text": "Im Krippenspiel von versteckten Knaben schieben l\u00e4\u00dft.", "tokens": ["Im", "Krip\u00b7pen\u00b7spiel", "von", "ver\u00b7steck\u00b7ten", "Kna\u00b7ben", "schie\u00b7ben", "l\u00e4\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "VVINF", "VVFIN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Mit leichtem Neigen gr\u00fc\u00dft sie im Laufen der G\u00e4ste Schaar,", "tokens": ["Mit", "leich\u00b7tem", "Nei\u00b7gen", "gr\u00fc\u00dft", "sie", "im", "Lau\u00b7fen", "der", "G\u00e4s\u00b7te", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Und will zum Sitz gelangen, der ihr bereitet war.", "tokens": ["Und", "will", "zum", "Sitz", "ge\u00b7lan\u00b7gen", ",", "der", "ihr", "be\u00b7rei\u00b7tet", "war", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "APPRART", "NN", "VVINF", "$,", "PRELS", "PPER", "VVPP", "VAFIN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Das war nicht leicht. Es mochte an St\u00fchlen Mangel sein,", "tokens": ["Das", "war", "nicht", "leicht", ".", "Es", "moch\u00b7te", "an", "St\u00fch\u00b7len", "Man\u00b7gel", "sein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PTKNEG", "ADJD", "$.", "PPER", "VVFIN", "APPR", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "So sa\u00dfen auf vier B\u00e4nken die G\u00e4ste in vier Reih'n;", "tokens": ["So", "sa\u00b7\u00dfen", "auf", "vier", "B\u00e4n\u00b7ken", "die", "G\u00e4s\u00b7te", "in", "vier", "Reih'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "CARD", "NN", "ART", "NN", "APPR", "CARD", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Man mu\u00dfte sie st\u00f6ren, wollt' man \u00fcber die Bank nicht springen;", "tokens": ["Man", "mu\u00df\u00b7te", "sie", "st\u00f6\u00b7ren", ",", "wollt'", "man", "\u00fc\u00b7ber", "die", "Bank", "nicht", "sprin\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "PPER", "VVINF", "$,", "VMFIN", "PIS", "APPR", "ART", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Sie aber wei\u00df behende zwischen die B\u00e4nke zu dringen,", "tokens": ["Sie", "a\u00b7ber", "wei\u00df", "be\u00b7hen\u00b7de", "zwi\u00b7schen", "die", "B\u00e4n\u00b7ke", "zu", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADJA", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und dreht sich dann zwischen den Sitzenden und dem Tische fort,", "tokens": ["Und", "dreht", "sich", "dann", "zwi\u00b7schen", "den", "Sit\u00b7zen\u00b7den", "und", "dem", "Ti\u00b7sche", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PRF", "ADV", "APPR", "ART", "NN", "KON", "ART", "NN", "PTKVZ", "$,"], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.27": {"text": "Wie eine Billardkugel, bis zu ihrem Ort.", "tokens": ["Wie", "ei\u00b7ne", "Bil\u00b7lard\u00b7ku\u00b7gel", ",", "bis", "zu", "ih\u00b7rem", "Ort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "KOUS", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Und unsern J\u00fcngling ber\u00fchrt sie ganz nah' im Weiterschieben, \u2013", "tokens": ["Und", "un\u00b7sern", "J\u00fcng\u00b7ling", "be\u00b7r\u00fchrt", "sie", "ganz", "nah'", "im", "Wei\u00b7ter\u00b7schie\u00b7ben", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "ADJD", "APPRART", "NN", "$,", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Sie war mit einer Falbel an Jemand h\u00e4ngen geblieben,", "tokens": ["Sie", "war", "mit", "ei\u00b7ner", "Fal\u00b7bel", "an", "Je\u00b7mand", "h\u00e4n\u00b7gen", "ge\u00b7blie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "APPR", "PIS", "VVINF", "VVPP", "$,"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und gleitet ein wenig \u2013 und ehe sie sich fassen kann,", "tokens": ["Und", "glei\u00b7tet", "ein", "we\u00b7nig", "\u2013", "und", "e\u00b7he", "sie", "sich", "fas\u00b7sen", "kann", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "PIS", "$(", "KON", "KOUS", "PPER", "PRF", "VVINF", "VMFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.31": {"text": "H\u00e4lt sie sich fest am Arm des Herrn Thadd\u00e4us an.", "tokens": ["H\u00e4lt", "sie", "sich", "fest", "am", "Arm", "des", "Herrn", "Thad\u00b7d\u00e4us", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "APPRART", "NN", "ART", "NN", "NE", "PTKVZ", "$."], "meter": "---+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.32": {"text": "Und nun, nachdem sie sich bei ihm entschuldigt fein,", "tokens": ["Und", "nun", ",", "nach\u00b7dem", "sie", "sich", "bei", "ihm", "ent\u00b7schul\u00b7digt", "fein", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "KOUS", "PPER", "PRF", "APPR", "PPER", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.33": {"text": "Nimmt zwischen ihm und dem Richter sie ihre Stelle ein \u2013", "tokens": ["Nimmt", "zwi\u00b7schen", "ihm", "und", "dem", "Rich\u00b7ter", "sie", "ih\u00b7re", "Stel\u00b7le", "ein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "KON", "ART", "NN", "PPER", "PPOSAT", "NN", "ART", "$("], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch i\u00dft sie gar nichts \u2013 f\u00e4chelt sich nur ohne Ruh',", "tokens": ["Doch", "i\u00dft", "sie", "gar", "nichts", "\u2013", "f\u00e4\u00b7chelt", "sich", "nur", "oh\u00b7ne", "Ruh'", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "PIS", "$(", "VVFIN", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Dreht an dem Heft des F\u00e4chers, \u2013 legt sich ab und zu", "tokens": ["Dreht", "an", "dem", "Heft", "des", "F\u00e4\u00b7chers", ",", "\u2013", "legt", "sich", "ab", "und", "zu"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ART", "NN", "$,", "$(", "VVFIN", "PRF", "PTKVZ", "KON", "APPR"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Den Spitzenkragen zurecht und streift mit leichter Hand", "tokens": ["Den", "Spit\u00b7zen\u00b7kra\u00b7gen", "zu\u00b7recht", "und", "streift", "mit", "leich\u00b7ter", "Hand"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKVZ", "KON", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.37": {"text": "Bald \u00fcber eine Locke, bald \u00fcber ein Rosenband.", "tokens": ["Bald", "\u00fc\u00b7ber", "ei\u00b7ne", "Lo\u00b7cke", ",", "bald", "\u00fc\u00b7ber", "ein", "Ro\u00b7sen\u00b7band", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "$,", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.77": {"line.1": {"text": "So war wohl vier Minuten das Reden unterbrochen.", "tokens": ["So", "war", "wohl", "vier", "Mi\u00b7nu\u00b7ten", "das", "Re\u00b7den", "un\u00b7ter\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "CARD", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Inde\u00df wird unten am Tisch, erst fl\u00fcsternd nur gesprochen,", "tokens": ["In\u00b7de\u00df", "wird", "un\u00b7ten", "am", "Tisch", ",", "erst", "fl\u00fcs\u00b7ternd", "nur", "ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ADV", "APPRART", "NN", "$,", "ADV", "ADJD", "ADV", "VVPP", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Dann zwischen den M\u00e4nnern halblaut ein Gespr\u00e4ch gef\u00fchrt:", "tokens": ["Dann", "zwi\u00b7schen", "den", "M\u00e4n\u00b7nern", "hal\u00b7blaut", "ein", "Ge\u00b7spr\u00e4ch", "ge\u00b7f\u00fchrt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "VVFIN", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Es ist das heutige Jagen, das man discutirt:", "tokens": ["Es", "ist", "das", "heu\u00b7ti\u00b7ge", "Ja\u00b7gen", ",", "das", "man", "dis\u00b7cu\u00b7tirt", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Notar und Assessor", "tokens": ["No\u00b7tar", "und", "As\u00b7ses\u00b7sor"], "token_info": ["word", "word", "word"], "pos": ["NN", "KON", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Um einen gestutzten Hund, ein Windspiel, Mutz genannt;", "tokens": ["Um", "ei\u00b7nen", "ge\u00b7stutz\u00b7ten", "Hund", ",", "ein", "Wind\u00b7spiel", ",", "Mutz", "ge\u00b7nannt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUI", "ART", "ADJA", "NN", "$,", "ART", "NN", "$,", "NN", "VVPP", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das der Notar mit Stolz sein theures Eigen hei\u00dft,", "tokens": ["Das", "der", "No\u00b7tar", "mit", "Stolz", "sein", "theu\u00b7res", "Ei\u00b7gen", "hei\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "ART", "NN", "APPR", "NN", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Und das auch den Hasen gefangen, wie er jetzt beweist.", "tokens": ["Und", "das", "auch", "den", "Ha\u00b7sen", "ge\u00b7fan\u00b7gen", ",", "wie", "er", "jetzt", "be\u00b7weist", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDS", "ADV", "ART", "NN", "PTKVZ", "$,", "PWAV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Worauf der Assessor zeigt, dem Herrn Notar zum Trutz,", "tokens": ["Wo\u00b7rauf", "der", "As\u00b7ses\u00b7sor", "zeigt", ",", "dem", "Herrn", "No\u00b7tar", "zum", "Trutz", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "VVFIN", "$,", "ART", "NN", "NN", "APPRART", "NN", "$,"], "meter": "-+----+-+-+-+", "measure": "dactylic.init"}, "line.10": {"text": "Dies Lob geb\u00fchre dem Falk und keineswegs dem Mutz.", "tokens": ["Dies", "Lob", "ge\u00b7b\u00fch\u00b7re", "dem", "Falk", "und", "kei\u00b7nes\u00b7wegs", "dem", "Mutz", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "NN", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die Anderen alle befragt, was ihre Meinung sei,", "tokens": ["Die", "An\u00b7de\u00b7ren", "al\u00b7le", "be\u00b7fragt", ",", "was", "ih\u00b7re", "Mei\u00b7nung", "sei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "PIS", "VVPP", "$,", "PRELS", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+--+--+-+-+-+", "measure": "amphibrach.tri.plus"}, "line.12": {"text": "Ergriffen theils f\u00fcr Mutzen, theils f\u00fcr Falken Partei,", "tokens": ["Er\u00b7grif\u00b7fen", "theils", "f\u00fcr", "Mut\u00b7zen", ",", "theils", "f\u00fcr", "Fal\u00b7ken", "Par\u00b7tei", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "APPR", "NN", "$,", "ADV", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.13": {"text": "Als Augenzeuge der, und der nach Kennersinn. \u2013", "tokens": ["Als", "Au\u00b7gen\u00b7zeu\u00b7ge", "der", ",", "und", "der", "nach", "Ken\u00b7ner\u00b7sinn", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "NN", "ART", "$,", "KON", "ART", "APPR", "NN", "$.", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Halblaut der Richter: \u00bbVergieb, es war nicht zu verschieben;", "tokens": ["Hal\u00b7blaut", "der", "Rich\u00b7ter", ":", "\u00bb", "Ver\u00b7gieb", ",", "es", "war", "nicht", "zu", "ver\u00b7schie\u00b7ben", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "$(", "VVIMP", "$,", "PPER", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+--+--+-+-+-+-", "measure": "elegiambus"}, "line.15": {"text": "Die G\u00e4ste hatten sich lang im Freien herumgetrieben \u2013", "tokens": ["Die", "G\u00e4s\u00b7te", "hat\u00b7ten", "sich", "lang", "im", "Frei\u00b7en", "her\u00b7um\u00b7ge\u00b7trie\u00b7ben", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PRF", "ADJD", "APPRART", "NN", "VVPP", "$("], "meter": "-+-+--+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Und Alle bekamen Hunger nach dem vielen Geh'n;", "tokens": ["Und", "Al\u00b7le", "be\u00b7ka\u00b7men", "Hun\u00b7ger", "nach", "dem", "vie\u00b7len", "Geh'n", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "NN", "APPR", "ART", "PIAT", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Auch dacht' ich nicht, dich heute bei uns zu Tisch zu seh'n.\u00ab", "tokens": ["Auch", "dacht'", "ich", "nicht", ",", "dich", "heu\u00b7te", "bei", "uns", "zu", "Tisch", "zu", "seh'", "n.", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PTKNEG", "$,", "PPER", "ADV", "APPR", "PPER", "APPR", "NN", "PTKZU", "VVFIN", "NE", "$("], "meter": "-+--++-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Drauf wandt' er, die Becher f\u00fcllend, zum K\u00e4mm'rer sich zur\u00fcck,", "tokens": ["Drauf", "wandt'", "er", ",", "die", "Be\u00b7cher", "f\u00fcl\u00b7lend", ",", "zum", "K\u00e4m\u00b7m'\u00b7rer", "sich", "zu\u00b7r\u00fcck", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "$,", "ART", "NN", "VVPP", "$,", "APPRART", "NN", "PRF", "PTKVZ", "$,"], "meter": "-+--+-+--++-+-+", "measure": "iambic.septa.relaxed"}, "line.19": {"text": "Und leise besprachen beide die neuste Politik.", "tokens": ["Und", "lei\u00b7se", "be\u00b7spra\u00b7chen", "bei\u00b7de", "die", "neus\u00b7te", "Po\u00b7li\u00b7tik", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PIS", "ART", "ADJA", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.78": {"line.1": {"text": "Wie rechts und links sich so besch\u00e4ftigt Jedermann,", "tokens": ["Wie", "rechts", "und", "links", "sich", "so", "be\u00b7sch\u00e4f\u00b7tigt", "Je\u00b7der\u00b7mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "KON", "ADV", "PRF", "ADV", "VVFIN", "PIS", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blickt Herr Thadd\u00e4us n\u00e4her die Unbekannte an.", "tokens": ["Blickt", "Herr", "Thad\u00b7d\u00e4us", "n\u00e4\u00b7her", "die", "Un\u00b7be\u00b7kann\u00b7te", "an", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "NE", "ADJD", "ART", "NN", "PTKVZ", "$."], "meter": "-++-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Er denkt, wie er doch fr\u00fcher errathen hab' sofort,", "tokens": ["Er", "denkt", ",", "wie", "er", "doch", "fr\u00fc\u00b7her", "er\u00b7ra\u00b7then", "hab'", "so\u00b7fort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "PPER", "ADV", "ADJD", "VVINF", "VAFIN", "ADV", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "F\u00fcr wen bestimmt gewesen der leergelass'ne Ort.", "tokens": ["F\u00fcr", "wen", "be\u00b7stimmt", "ge\u00b7we\u00b7sen", "der", "leer\u00b7ge\u00b7lass'\u00b7ne", "Ort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PWS", "VVPP", "VAPP", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Laut klopft sein Herz \u2013 err\u00f6thend gl\u00fcht sein Wangenpaar:", "tokens": ["Laut", "klopft", "sein", "Herz", "\u2013", "er\u00b7r\u00f6\u00b7thend", "gl\u00fcht", "sein", "Wan\u00b7gen\u00b7paar", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "PPOSAT", "NN", "$(", "VVPP", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Was er im Stillen vermuthet, so sah er's offenbar!", "tokens": ["Was", "er", "im", "Stil\u00b7len", "ver\u00b7mu\u00b7thet", ",", "so", "sah", "er's", "of\u00b7fen\u00b7bar", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "APPRART", "NN", "VVFIN", "$,", "ADV", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.7": {"text": "So war's bestimmt, da\u00df sitzen sollt' bei ihm so traut", "tokens": ["So", "wa\u00b7r's", "be\u00b7stimmt", ",", "da\u00df", "sit\u00b7zen", "sollt'", "bei", "ihm", "so", "traut"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "VVPP", "$,", "KOUS", "VVINF", "VMFIN", "APPR", "PPER", "ADV", "VVFIN"], "meter": "----+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.8": {"text": "Die Sch\u00f6ne, die er heut' im D\u00e4mmerlicht erschaut!", "tokens": ["Die", "Sch\u00f6\u00b7ne", ",", "die", "er", "heut'", "im", "D\u00e4m\u00b7mer\u00b7licht", "er\u00b7schaut", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Zwar die Gestalt \u2013 sie schien ihm schlanker jetzt zu sein:", "tokens": ["Zwar", "die", "Ge\u00b7stalt", "\u2013", "sie", "schien", "ihm", "schlan\u00b7ker", "jetzt", "zu", "sein", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "PPER", "VVFIN", "PPER", "ADJD", "ADV", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Weil sie im Anzug war, und der macht gro\u00df und klein.", "tokens": ["Weil", "sie", "im", "An\u00b7zug", "war", ",", "und", "der", "macht", "gro\u00df", "und", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPRART", "NN", "VAFIN", "$,", "KON", "ART", "VVFIN", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Dort hatt' er kurz das Haar und goldig-hell gefunden,", "tokens": ["Dort", "hatt'", "er", "kurz", "das", "Haar", "und", "gol\u00b7dig\u00b7hell", "ge\u00b7fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "ART", "NN", "KON", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Hier ist es rabenschwarz, in lange Locken gewunden;", "tokens": ["Hier", "ist", "es", "ra\u00b7ben\u00b7schwarz", ",", "in", "lan\u00b7ge", "Lo\u00b7cken", "ge\u00b7wun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADJD", "$,", "APPR", "ADJA", "NN", "VAPP", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Gewi\u00df, die Farbe kam wohl von den Sonnenstrahlen,", "tokens": ["Ge\u00b7wi\u00df", ",", "die", "Far\u00b7be", "kam", "wohl", "von", "den", "Son\u00b7nen\u00b7strah\u00b7len", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ART", "NN", "VVFIN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Die ja des Abends Alles r\u00f6thlich golden malen.", "tokens": ["Die", "ja", "des", "A\u00b7bends", "Al\u00b7les", "r\u00f6th\u00b7lich", "gol\u00b7den", "ma\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "PIS", "ADJD", "ADJA", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Nicht hatt' er das Antlitz geseh'n, \u2013 sie war zu rasch entschwunden \u2013", "tokens": ["Nicht", "hatt'", "er", "das", "Ant\u00b7litz", "ge\u00b7seh'n", ",", "\u2013", "sie", "war", "zu", "rasch", "ent\u00b7schwun\u00b7den", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VAFIN", "PPER", "ART", "NN", "VVPP", "$,", "$(", "PPER", "VAFIN", "PTKA", "ADJD", "VVPP", "$("], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Doch war's ein sch\u00f6nes Bildni\u00df, was sich sein Sinn erfunden;", "tokens": ["Doch", "wa\u00b7r's", "ein", "sch\u00f6\u00b7nes", "Bild\u00b7ni\u00df", ",", "was", "sich", "sein", "Sinn", "er\u00b7fun\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PRF", "PPOSAT", "NN", "VVPP", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Schwarz\u00e4ugig, wei\u00df an Wangen \u2013 so stellte sich's ihm dar \u2013", "tokens": ["Schwarz\u00b7\u00e4u\u00b7gig", ",", "wei\u00df", "an", "Wan\u00b7gen", "\u2013", "so", "stell\u00b7te", "sich's", "ihm", "dar", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "VVFIN", "APPR", "NN", "$(", "ADV", "VVFIN", "PIS", "PPER", "PTKVZ", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Die Lippen, wie ein prangend Kirschenzwillingspaar,", "tokens": ["Die", "Lip\u00b7pen", ",", "wie", "ein", "pran\u00b7gend", "Kir\u00b7schenz\u00b7wil\u00b7lings\u00b7paar", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PWAV", "ART", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und Mund und Aug' und Wangen \u2013 hier war's, wie er gedacht.", "tokens": ["Und", "Mund", "und", "Aug'", "und", "Wan\u00b7gen", "\u2013", "hier", "wa\u00b7r's", ",", "wie", "er", "ge\u00b7dacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "KON", "NN", "$(", "ADV", "VAFIN", "$,", "PWAV", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.20": {"text": "Das Alter ist's, was noch am meisten denken macht:", "tokens": ["Das", "Al\u00b7ter", "ist's", ",", "was", "noch", "am", "meis\u00b7ten", "den\u00b7ken", "macht", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "$,", "PRELS", "ADV", "PTKA", "PIS", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Ein junges M\u00e4dchen glaubt' er im Garten zu gewahren,", "tokens": ["Ein", "jun\u00b7ges", "M\u00e4d\u00b7chen", "glaubt'", "er", "im", "Gar\u00b7ten", "zu", "ge\u00b7wah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PPER", "APPRART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und diese Dame war ein Weib in reifern Jahren.", "tokens": ["Und", "die\u00b7se", "Da\u00b7me", "war", "ein", "Weib", "in", "rei\u00b7fern", "Jah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PDAT", "NN", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Doch Jugend fr\u00e4gt die Sch\u00f6nheit nach dem Taufschein nicht,", "tokens": ["Doch", "Ju\u00b7gend", "fr\u00e4gt", "die", "Sch\u00f6n\u00b7heit", "nach", "dem", "Tauf\u00b7schein", "nicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "PTKNEG", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Jung ist dem jungen Manne jedes Frauengesicht,", "tokens": ["Jung", "ist", "dem", "jun\u00b7gen", "Man\u00b7ne", "je\u00b7des", "Frau\u00b7en\u00b7ge\u00b7sicht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ART", "ADJA", "NN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.25": {"text": "Gleichaltrig d\u00fcnkt dem Burschen, was nur in Sch\u00f6nheit bl\u00fcht,", "tokens": ["Gleich\u00b7alt\u00b7rig", "d\u00fcnkt", "dem", "Bur\u00b7schen", ",", "was", "nur", "in", "Sch\u00f6n\u00b7heit", "bl\u00fcht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und jedes Lieb jungfr\u00e4ulich dem schuldlosen Gem\u00fcth.", "tokens": ["Und", "je\u00b7des", "Lieb", "jung\u00b7fr\u00e4u\u00b7lich", "dem", "schuld\u00b7lo\u00b7sen", "Ge\u00b7m\u00fcth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "ADJD", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}}, "stanza.79": {"line.1": {"text": "Thadd\u00e4us war wohl schon fast zwanzig Jahre alt,", "tokens": ["Thad\u00b7d\u00e4us", "war", "wohl", "schon", "fast", "zwan\u00b7zig", "Jah\u00b7re", "alt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ADV", "CARD", "NN", "ADJD", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Und Wilno, die gro\u00dfe Stadt, seit Jahren sein Aufenthalt;", "tokens": ["Und", "Wil\u00b7no", ",", "die", "gro\u00b7\u00dfe", "Stadt", ",", "seit", "Jah\u00b7ren", "sein", "Auf\u00b7ent\u00b7halt", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "$,", "ART", "ADJA", "NN", "$,", "APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Gar streng erzogen worden in der V\u00e4ter Art.", "tokens": ["Gar", "streng", "er\u00b7zo\u00b7gen", "wor\u00b7den", "in", "der", "V\u00e4\u00b7ter", "Art", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "VAPP", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So bracht' er denn nach Hause der herben Zucht Gewinn:", "tokens": ["So", "bracht'", "er", "denn", "nach", "Hau\u00b7se", "der", "her\u00b7ben", "Zucht", "Ge\u00b7winn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Ein schuldlos-reines Herz und einen lebendigen Sinn;", "tokens": ["Ein", "schuld\u00b7los\u00b7rei\u00b7nes", "Herz", "und", "ei\u00b7nen", "le\u00b7ben\u00b7di\u00b7gen", "Sinn", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "KON", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Doch auch nicht wenig Neigung, \u00fcber die Schnur zu hauen.", "tokens": ["Doch", "auch", "nicht", "we\u00b7nig", "Nei\u00b7gung", ",", "\u00fc\u00b7ber", "die", "Schnur", "zu", "hau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKNEG", "PIAT", "NN", "$,", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Im Voraus plant' er schon in fr\u00f6hlichem Selbstvertrauen:", "tokens": ["Im", "Vo\u00b7raus", "plant'", "er", "schon", "in", "fr\u00f6h\u00b7li\u00b7chem", "Selbst\u00b7ver\u00b7trau\u00b7en", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Die langentbehrte Freiheit nun zu genie\u00dfen nach Lust;", "tokens": ["Die", "lan\u00b7gent\u00b7behr\u00b7te", "Frei\u00b7heit", "nun", "zu", "ge\u00b7nie\u00b7\u00dfen", "nach", "Lust", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "PTKZU", "VVINF", "APPR", "NN", "$."], "meter": "-+-+-+-+--+--+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Jung war er, flink und stattlich, und war sich auch dessen bewu\u00dft:", "tokens": ["Jung", "war", "er", ",", "flink", "und", "statt\u00b7lich", ",", "und", "war", "sich", "auch", "des\u00b7sen", "be\u00b7wu\u00dft", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "$,", "ADJD", "KON", "ADJD", "$,", "KON", "VAFIN", "PRF", "ADV", "PDS", "ADJD", "$."], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "An Kraft und Frische war er seiner Eltern Kind \u2013", "tokens": ["An", "Kraft", "und", "Fri\u00b7sche", "war", "er", "sei\u00b7ner", "El\u00b7tern", "Kind", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VAFIN", "PPER", "PPOSAT", "NN", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Er hie\u00df Soplica, \u2013 und alle die Soplica's sind", "tokens": ["Er", "hie\u00df", "Sop\u00b7li\u00b7ca", ",", "\u2013", "und", "al\u00b7le", "die", "Sop\u00b7li\u00b7ca's", "sind"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NE", "$,", "$(", "KON", "PIS", "ART", "NE", "VAFIN"], "meter": "-+--+-+--+-+-", "measure": "iambic.penta.relaxed"}, "line.12": {"text": "Bekanntlich gut bei Leibe und voll gesunder Kraft,", "tokens": ["Be\u00b7kannt\u00b7lich", "gut", "bei", "Lei\u00b7be", "und", "voll", "ge\u00b7sun\u00b7der", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "KON", "ADJD", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Zum Waffenhandwerk einzig, nicht so zur Wissenschaft.", "tokens": ["Zum", "Waf\u00b7fen\u00b7hand\u00b7werk", "ein\u00b7zig", ",", "nicht", "so", "zur", "Wis\u00b7sen\u00b7schaft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$,", "PTKNEG", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.80": {"line.1": {"text": "Thadd\u00e4us war in Allem der Ahnen rechter Spro\u00df.", "tokens": ["Thad\u00b7d\u00e4us", "war", "in", "Al\u00b7lem", "der", "Ah\u00b7nen", "rech\u00b7ter", "Spro\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PIS", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Er war vortrefflich zu Fu\u00df, auch recht geschickt zu Ro\u00df;", "tokens": ["Er", "war", "vor\u00b7treff\u00b7lich", "zu", "Fu\u00df", ",", "auch", "recht", "ge\u00b7schickt", "zu", "Ro\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "APPR", "NN", "$,", "ADV", "ADJD", "VVPP", "APPR", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Nicht dumm, jedoch im Wissen nicht gar weit gedieh'n \u2013", "tokens": ["Nicht", "dumm", ",", "je\u00b7doch", "im", "Wis\u00b7sen", "nicht", "gar", "weit", "ge\u00b7dieh'n", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "$,", "ADV", "APPRART", "NN", "PTKNEG", "ADV", "ADJD", "VVPP", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wiewohl der Ohm nichts sparte, ihn w\u00fcrdig zu erzieh'n \u2013", "tokens": ["Wie\u00b7wohl", "der", "Ohm", "nichts", "spar\u00b7te", ",", "ihn", "w\u00fcr\u00b7dig", "zu", "er\u00b7zieh'n", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVFIN", "$,", "PPER", "ADJD", "PTKZU", "VVINF", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Er hantirte lieber mit S\u00e4bel und Schie\u00dfgewehr:", "tokens": ["Er", "han\u00b7tir\u00b7te", "lie\u00b7ber", "mit", "S\u00e4\u00b7bel", "und", "Schie\u00df\u00b7ge\u00b7wehr", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+--+--+--+-+", "measure": "amphibrach.tetra.plus"}, "line.6": {"text": "Er wu\u00dfte, da\u00df man ihn bestimmt zum Milit\u00e4r,", "tokens": ["Er", "wu\u00df\u00b7te", ",", "da\u00df", "man", "ihn", "be\u00b7stimmt", "zum", "Mi\u00b7li\u00b7t\u00e4r", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wie es sein seliger Vater im Testament gewollt \u2013", "tokens": ["Wie", "es", "sein", "se\u00b7li\u00b7ger", "Va\u00b7ter", "im", "Tes\u00b7ta\u00b7ment", "ge\u00b7wollt", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPOSAT", "ADJA", "NN", "APPRART", "NN", "VMPP", "$("], "meter": "+-+---+--+-+-+", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Und seufzte nach der Trommel, wenn er studiren sollt'.", "tokens": ["Und", "seufz\u00b7te", "nach", "der", "Trom\u00b7mel", ",", "wenn", "er", "stu\u00b7di\u00b7ren", "sollt'", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$,", "KOUS", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Doch pl\u00f6tzlich gefiel's dem Onkel, anders f\u00fcr ihn zu w\u00e4hlen,", "tokens": ["Doch", "pl\u00f6tz\u00b7lich", "ge\u00b7fiel's", "dem", "On\u00b7kel", ",", "an\u00b7ders", "f\u00fcr", "ihn", "zu", "w\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJA", "ART", "NN", "$,", "ADV", "APPR", "PPER", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Er hie\u00df ihn nach Hause kommen, sich m\u00f6glichst bald verm\u00e4hlen,", "tokens": ["Er", "hie\u00df", "ihn", "nach", "Hau\u00b7se", "kom\u00b7men", ",", "sich", "m\u00f6g\u00b7lichst", "bald", "ver\u00b7m\u00e4h\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "NN", "VVINF", "$,", "PRF", "ADV", "ADV", "VVINF", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Und dann die Wirthschaft f\u00fchren; versprach, ihm als erste Gabe", "tokens": ["Und", "dann", "die", "Wirth\u00b7schaft", "f\u00fch\u00b7ren", ";", "ver\u00b7sprach", ",", "ihm", "als", "ers\u00b7te", "Ga\u00b7be"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ART", "NN", "VVINF", "$.", "VVFIN", "$,", "PPER", "KOUS", "ADJA", "NN"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Ein kleines Gut zu geben, \u2013 dann seine ganze Habe.", "tokens": ["Ein", "klei\u00b7nes", "Gut", "zu", "ge\u00b7ben", ",", "\u2013", "dann", "sei\u00b7ne", "gan\u00b7ze", "Ha\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKZU", "VVINF", "$,", "$(", "ADV", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+----+-+-+-", "measure": "unknown.measure.penta"}}, "stanza.81": {"line.1": {"text": "All' diese Tugenden, die Herrn Thadd\u00e4us schm\u00fccken,", "tokens": ["All'", "die\u00b7se", "Tu\u00b7gen\u00b7den", ",", "die", "Herrn", "Thad\u00b7d\u00e4us", "schm\u00fc\u00b7cken", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,", "ART", "NN", "NE", "VVINF", "$,"], "meter": "+--+--+-+-+-", "measure": "dactylic.di.plus"}, "line.2": {"text": "Bemerkt die Nachbarin, ein Weib von scharfen Blicken, \u2013", "tokens": ["Be\u00b7merkt", "die", "Nach\u00b7ba\u00b7rin", ",", "ein", "Weib", "von", "schar\u00b7fen", "Bli\u00b7cken", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "ART", "NN", "APPR", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die hohe, sch\u00f6ne Gestalt betrachtet sie mit Lust,", "tokens": ["Die", "ho\u00b7he", ",", "sch\u00f6\u00b7ne", "Ge\u00b7stalt", "be\u00b7trach\u00b7tet", "sie", "mit", "Lust", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "$,", "ADJA", "NN", "VVFIN", "PPER", "APPR", "NN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die kraftgeschwellten Arme, die m\u00e4nnlich-breite Brust, \u2013", "tokens": ["Die", "kraft\u00b7ge\u00b7schwell\u00b7ten", "Ar\u00b7me", ",", "die", "m\u00e4nn\u00b7lich\u00b7brei\u00b7te", "Brust", ",", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Die Wangen auch, die immer ergl\u00fch'n in rothen Flammen,", "tokens": ["Die", "Wan\u00b7gen", "auch", ",", "die", "im\u00b7mer", "er\u00b7gl\u00fch'n", "in", "ro\u00b7then", "Flam\u00b7men", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "PRELS", "ADV", "VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+---+-+-+-", "measure": "iambic.penta.relaxed"}, "line.6": {"text": "So oft mit ihrem Blick der seine trifft zusammen;", "tokens": ["So", "oft", "mit", "ih\u00b7rem", "Blick", "der", "sei\u00b7ne", "trifft", "zu\u00b7sam\u00b7men", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPOSAT", "NN", "ART", "PPOSAT", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Denn seine Bl\u00f6digkeit war nun verschwunden ganz,", "tokens": ["Denn", "sei\u00b7ne", "Bl\u00f6\u00b7dig\u00b7keit", "war", "nun", "ver\u00b7schwun\u00b7den", "ganz", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAFIN", "ADV", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "K\u00fchn blickte jetzt sein Auge, voller Glut und Glanz \u2013", "tokens": ["K\u00fchn", "blick\u00b7te", "jetzt", "sein", "Au\u00b7ge", ",", "vol\u00b7ler", "Glut", "und", "Glanz", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADV", "PPOSAT", "NN", "$,", "ADJA", "NN", "KON", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und sie gleich ihm \u2013 und wie die Kerzen am Altare,", "tokens": ["Und", "sie", "gleich", "ihm", "\u2013", "und", "wie", "die", "Ker\u00b7zen", "am", "Al\u00b7ta\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "PPER", "$(", "KON", "PWAV", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.10": {"text": "So gl\u00fchten gen einander zwei helle Augenpaare.", "tokens": ["So", "gl\u00fch\u00b7ten", "gen", "ein\u00b7an\u00b7der", "zwei", "hel\u00b7le", "Au\u00b7gen\u00b7paa\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "APPR", "PRF", "CARD", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.82": {"line.1": {"text": "Er kam aus der Stadt, vom Studium \u2013 weshalb sie von B\u00fcchern begann,", "tokens": ["Er", "kam", "aus", "der", "Stadt", ",", "vom", "Stu\u00b7di\u00b7um", "\u2013", "we\u00b7shalb", "sie", "von", "B\u00fc\u00b7chern", "be\u00b7gann", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$,", "APPRART", "NN", "$(", "PWAV", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+--+-+--+---+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und was seine Meinung w\u00e4re von der und jener Erscheinung \u2013", "tokens": ["Und", "was", "sei\u00b7ne", "Mei\u00b7nung", "w\u00e4\u00b7re", "von", "der", "und", "je\u00b7ner", "Er\u00b7schei\u00b7nung", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPOSAT", "NN", "VAFIN", "APPR", "ART", "KON", "PDAT", "NN", "$("], "meter": "-+--+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und neue Fragen erzeugte jede gegebene Meinung.", "tokens": ["Und", "neu\u00b7e", "Fra\u00b7gen", "er\u00b7zeug\u00b7te", "je\u00b7de", "ge\u00b7ge\u00b7be\u00b7ne", "Mei\u00b7nung", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Und wie sie nun gar anf\u00e4ngt von der Malerei,", "tokens": ["Und", "wie", "sie", "nun", "gar", "an\u00b7f\u00e4ngt", "von", "der", "Ma\u00b7le\u00b7rei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ADV", "ADV", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Von Tanzkunst, von Musik, ja von der Bildhauerei \u2013", "tokens": ["Von", "Tanz\u00b7kunst", ",", "von", "Mu\u00b7sik", ",", "ja", "von", "der", "Bild\u00b7hau\u00b7e\u00b7rei", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "ADV", "APPR", "ART", "NN", "$("], "meter": "-+--+-+--++-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Zeigt sie in Farben und Noten und B\u00fccher sich eingeweiht,", "tokens": ["Zeigt", "sie", "in", "Far\u00b7ben", "und", "No\u00b7ten", "und", "B\u00fc\u00b7cher", "sich", "ein\u00b7ge\u00b7weiht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "KON", "NN", "KON", "NN", "PRF", "VVPP", "$,"], "meter": "+--+--+--+--+-+", "measure": "diphilius"}, "line.7": {"text": "Da\u00df fast Thadd\u00e4us versteinert vor so viel Gelehrsamkeit!", "tokens": ["Da\u00df", "fast", "Thad\u00b7d\u00e4us", "ver\u00b7stei\u00b7nert", "vor", "so", "viel", "Ge\u00b7lehr\u00b7sam\u00b7keit", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "NE", "VVFIN", "APPR", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.8": {"text": "Er f\u00fcrchtet, Schand' und Spott zum Schlu\u00df davonzutragen,", "tokens": ["Er", "f\u00fcrch\u00b7tet", ",", "Schand'", "und", "Spott", "zum", "Schlu\u00df", "da\u00b7von\u00b7zu\u00b7tra\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "NN", "KON", "NN", "APPRART", "NN", "PAV", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und stottert, wie ein Schulbub vor des Lehrers Fragen.", "tokens": ["Und", "stot\u00b7tert", ",", "wie", "ein", "Schul\u00b7bub", "vor", "des", "Leh\u00b7rers", "Fra\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "PWAV", "ART", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Zum Gl\u00fcck ist der Lehrer h\u00fcbsch und h\u00e4lt kein streng Gericht.", "tokens": ["Zum", "Gl\u00fcck", "ist", "der", "Leh\u00b7rer", "h\u00fcbsch", "und", "h\u00e4lt", "kein", "streng", "Ge\u00b7richt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VAFIN", "ART", "NN", "ADJD", "KON", "VVFIN", "PIAT", "ADJD", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die holde Nachbarin err\u00e4th, woran's gebricht,", "tokens": ["Die", "hol\u00b7de", "Nach\u00b7ba\u00b7rin", "er\u00b7r\u00e4\u00b7th", ",", "wor\u00b7an's", "ge\u00b7bricht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PWAV", "VVFIN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Und bringt die Sprache auf leicht're und minder weise Dinge:", "tokens": ["Und", "bringt", "die", "Spra\u00b7che", "auf", "leicht'\u00b7re", "und", "min\u00b7der", "wei\u00b7se", "Din\u00b7ge", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "ADJA", "KON", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.13": {"text": "Auf's Landleben, \u2013 wie viel Langweil' und M\u00fch'n es mit sich bringe,", "tokens": ["Auf's", "Land\u00b7le\u00b7ben", ",", "\u2013", "wie", "viel", "Lang\u00b7weil'", "und", "M\u00fch'n", "es", "mit", "sich", "brin\u00b7ge", ","], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "$(", "KOKOM", "PIAT", "NN", "KON", "NN", "PPER", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.14": {"text": "Wie man die Zeit mu\u00df n\u00fctzen, wie sich unterhalten,", "tokens": ["Wie", "man", "die", "Zeit", "mu\u00df", "n\u00fct\u00b7zen", ",", "wie", "sich", "un\u00b7ter\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VMFIN", "VVINF", "$,", "PWAV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Das Leben fr\u00f6hlicher und sch\u00f6ner zu gestalten.", "tokens": ["Das", "Le\u00b7ben", "fr\u00f6h\u00b7li\u00b7cher", "und", "sch\u00f6\u00b7ner", "zu", "ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "KON", "ADJD", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Thadd\u00e4us erwidert k\u00fchner, nun geht es glatt vom Munde:", "tokens": ["Thad\u00b7d\u00e4us", "er\u00b7wi\u00b7dert", "k\u00fch\u00b7ner", ",", "nun", "geht", "es", "glatt", "vom", "Mun\u00b7de", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "$,", "ADV", "VVFIN", "PPER", "ADJD", "APPRART", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Man war auf vertrautem Fu\u00df nach einer halben Stunde,", "tokens": ["Man", "war", "auf", "ver\u00b7trau\u00b7tem", "Fu\u00df", "nach", "ei\u00b7ner", "hal\u00b7ben", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "ADJA", "NN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "+---+-+-+-+-+-", "measure": "dactylic.init"}, "line.18": {"text": "Beginnt selbst kleine Sp\u00e4\u00dfe, neckt und zankt und droht;", "tokens": ["Be\u00b7ginnt", "selbst", "klei\u00b7ne", "Sp\u00e4\u00b7\u00dfe", ",", "neckt", "und", "zankt", "und", "droht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADJA", "NN", "$,", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Zum Schlu\u00df stellt sie vor ihn drei K\u00fcgelchen aus Brod,", "tokens": ["Zum", "Schlu\u00df", "stellt", "sie", "vor", "ihn", "drei", "K\u00fc\u00b7gel\u00b7chen", "aus", "Brod", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "APPR", "PPER", "CARD", "NN", "APPR", "NN", "$,"], "meter": "--+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.20": {"text": "Als drei Personen zur Wahl: er w\u00e4hlt die N\u00e4chste aus;", "tokens": ["Als", "drei", "Per\u00b7so\u00b7nen", "zur", "Wahl", ":", "er", "w\u00e4hlt", "die", "N\u00e4chs\u00b7te", "aus", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "CARD", "NN", "APPRART", "NN", "$.", "PPER", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Die beiden K\u00e4mm'rerst\u00f6chter zieh'n die Stirne kraus,", "tokens": ["Die", "bei\u00b7den", "K\u00e4m\u00b7m'\u00b7rer\u00b7st\u00f6ch\u00b7ter", "zieh'n", "die", "Stir\u00b7ne", "kraus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Die Nachbarin lacht auf, aber sie verschweigt,", "tokens": ["Die", "Nach\u00b7ba\u00b7rin", "lacht", "auf", ",", "a\u00b7ber", "sie", "ver\u00b7schweigt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "$,", "KON", "PPER", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Wen jene gl\u00fccklichere Kugel angezeigt.", "tokens": ["Wen", "je\u00b7ne", "gl\u00fcck\u00b7li\u00b7che\u00b7re", "Ku\u00b7gel", "an\u00b7ge\u00b7zeigt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.83": {"line.1": {"text": "Ganz anders unterhielt man sich auf der andern Seite:", "tokens": ["Ganz", "an\u00b7ders", "un\u00b7ter\u00b7hielt", "man", "sich", "auf", "der", "an\u00b7dern", "Sei\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PIS", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Denn Falk's Partei hat pl\u00f6tzlich sich aufgerafft zum Streite,", "tokens": ["Denn", "Fal\u00b7k's", "Par\u00b7tei", "hat", "pl\u00f6tz\u00b7lich", "sich", "auf\u00b7ge\u00b7rafft", "zum", "Strei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NE", "NE", "VAFIN", "ADJD", "PRF", "VVFIN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und \u00fcber Mutzens Freunde ging's unbarmherzig her.", "tokens": ["Und", "\u00fc\u00b7ber", "Mut\u00b7zens", "Freun\u00b7de", "ging's", "un\u00b7barm\u00b7her\u00b7zig", "her", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Gro\u00df war der Kampf, \u2013 man a\u00df die letzten Speisen nicht mehr,", "tokens": ["Gro\u00df", "war", "der", "Kampf", ",", "\u2013", "man", "a\u00df", "die", "letz\u00b7ten", "Spei\u00b7sen", "nicht", "mehr", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "VAFIN", "ART", "NN", "$,", "$(", "PIS", "VVFIN", "ART", "ADJA", "NN", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Man stritt nur, stehend und trinkend; am schrecklichsten aber war,", "tokens": ["Man", "stritt", "nur", ",", "ste\u00b7hend", "und", "trin\u00b7kend", ";", "am", "schreck\u00b7lichs\u00b7ten", "a\u00b7ber", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ADV", "$,", "ADJD", "KON", "VVPP", "$.", "APPRART", "ADJA", "ADV", "VAFIN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Gleich wie ein Birkhahn zu schauen, der hitzige Notar.", "tokens": ["Gleich", "wie", "ein", "Birk\u00b7hahn", "zu", "schau\u00b7en", ",", "der", "hit\u00b7zi\u00b7ge", "No\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "PTKZU", "VVINF", "$,", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wenn er einmal begonnen, so sprach er in Einem fort,", "tokens": ["Wenn", "er", "ein\u00b7mal", "be\u00b7gon\u00b7nen", ",", "so", "sprach", "er", "in", "Ei\u00b7nem", "fort", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "$,", "ADV", "VVFIN", "PPER", "APPR", "PIS", "PTKVZ", "$,"], "meter": "--+--+--+--+-+", "measure": "anapaest.tetra.plus"}, "line.8": {"text": "Eindringlich mit Geberden malend jedes Wort.", "tokens": ["Ein\u00b7dring\u00b7lich", "mit", "Ge\u00b7ber\u00b7den", "ma\u00b7lend", "je\u00b7des", "Wort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "ADJD", "PIAT", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.9": {"text": "Der Herr Notar Bolesta war fr\u00fcher Advokat,", "tokens": ["Der", "Herr", "No\u00b7tar", "Bo\u00b7les\u00b7ta", "war", "fr\u00fc\u00b7her", "Ad\u00b7vo\u00b7kat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "NE", "VAFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-+-+-+-+", "measure": "trochaic.septa"}, "line.10": {"text": "Man nennt ihn Prediger, weil er so rege Gesten hat.", "tokens": ["Man", "nennt", "ihn", "Pre\u00b7di\u00b7ger", ",", "weil", "er", "so", "re\u00b7ge", "Ges\u00b7ten", "hat", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "NN", "$,", "KOUS", "PPER", "ADV", "ADJA", "NN", "VAFIN", "$."], "meter": "-+----+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Die H\u00e4nde an der Seite, nach hinten die Ellenbogen,", "tokens": ["Die", "H\u00e4n\u00b7de", "an", "der", "Sei\u00b7te", ",", "nach", "hin\u00b7ten", "die", "El\u00b7len\u00b7bo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,", "APPR", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die Finger mit den langen N\u00e4geln vorgezogen,", "tokens": ["Die", "Fin\u00b7ger", "mit", "den", "lan\u00b7gen", "N\u00e4\u00b7geln", "vor\u00b7ge\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Nun schlie\u00dft er: \u00bbHussah! Wir lassen in Einem Augenblick", "tokens": ["Nun", "schlie\u00dft", "er", ":", "\u00bb", "Hus\u00b7sah", "!", "Wir", "las\u00b7sen", "in", "Ei\u00b7nem", "Au\u00b7gen\u00b7blick"], "token_info": ["word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$.", "$(", "ITJ", "$.", "PPER", "VVFIN", "APPR", "ART", "NN"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Ich und der Assessor, auf Einmal, unsre Hunde los,", "tokens": ["Ich", "und", "der", "As\u00b7ses\u00b7sor", ",", "auf", "Ein\u00b7mal", ",", "uns\u00b7re", "Hun\u00b7de", "los", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "ART", "NN", "$,", "APPR", "ADV", "$,", "PPOSAT", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.15": {"text": "Als wie mit Einem Finger zwei H\u00e4hne am Doppelgescho\u00df \u2013", "tokens": ["Als", "wie", "mit", "Ei\u00b7nem", "Fin\u00b7ger", "zwei", "H\u00e4h\u00b7ne", "am", "Dop\u00b7pel\u00b7ge\u00b7scho\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "KOKOM", "APPR", "ART", "NN", "CARD", "NN", "APPRART", "NN", "$("], "meter": "-+-+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Hussah! Sie liefen \u2013 der Hase, ripps! in's Feld, \u2013 sie nach \u2013\u00ab", "tokens": ["Hus\u00b7sah", "!", "Sie", "lie\u00b7fen", "\u2013", "der", "Ha\u00b7se", ",", "ripps", "!", "in's", "Feld", ",", "\u2013", "sie", "nach", "\u2013", "\u00ab"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["NE", "$.", "PPER", "VVFIN", "$(", "ART", "NN", "$,", "VVFIN", "$.", "APPRART", "NN", "$,", "$(", "PPER", "APPR", "$(", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Hier fuhr er \u00fcber den Tisch und stellte, w\u00e4hrend er sprach,", "tokens": ["Hier", "fuhr", "er", "\u00fc\u00b7ber", "den", "Tisch", "und", "stell\u00b7te", ",", "w\u00e4h\u00b7rend", "er", "sprach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "KON", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Den Lauf mit den Fingern dar, mit wunderbarem Geschick;", "tokens": ["Den", "Lauf", "mit", "den", "Fin\u00b7gern", "dar", ",", "mit", "wun\u00b7der\u00b7ba\u00b7rem", "Ge\u00b7schick", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,", "APPR", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "\u00bbsie nach \u2013 und waren vom Wald schon weg ein gutes St\u00fcck.", "tokens": ["\u00bb", "sie", "nach", "\u2013", "und", "wa\u00b7ren", "vom", "Wald", "schon", "weg", "ein", "gu\u00b7tes", "St\u00fcck", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "APPR", "$(", "KON", "VAFIN", "APPRART", "NN", "ADV", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Falk ripps! voran \u2013 ein Hitzkopf, obzwar ein flinker Springer,", "tokens": ["Falk", "ripps", "!", "vo\u00b7ran", "\u2013", "ein", "Hitz\u00b7kopf", ",", "ob\u00b7zwar", "ein", "flin\u00b7ker", "Sprin\u00b7ger", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "PTKVZ", "$(", "ART", "NN", "$,", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Er rannte Mutzen vor \u2013 um ", "tokens": ["Er", "rann\u00b7te", "Mut\u00b7zen", "vor", "\u2013", "um"], "token_info": ["word", "word", "word", "word", "punct", "word"], "pos": ["PPER", "VVFIN", "NN", "APPR", "$(", "KOUI"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.22": {"text": "Ich wu\u00dft' es: er blamirt sich! \u2013 Der Graue, pfiffig und fein,", "tokens": ["Ich", "wu\u00dft'", "es", ":", "er", "bla\u00b7mirt", "sich", "!", "\u2013", "Der", "Grau\u00b7e", ",", "pfif\u00b7fig", "und", "fein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$.", "PPER", "VVFIN", "PRF", "$.", "$(", "ART", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Schie\u00dft scheinbar g'rad in's Feld, \u2013 die Hunde hinterdrein \u2013", "tokens": ["Schie\u00dft", "schein\u00b7bar", "g'\u00b7rad", "in's", "Feld", ",", "\u2013", "die", "Hun\u00b7de", "hin\u00b7ter\u00b7drein", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "ADJD", "APPRART", "NN", "$,", "$(", "ART", "NN", "ADV", "$("], "meter": "+---+-+-+-+-+", "measure": "dactylic.init"}, "line.24": {"text": "Ein Schlaukopf! Wie er die Meute beisammen wei\u00df, \u2013 bums! ging's", "tokens": ["Ein", "Schlau\u00b7kopf", "!", "Wie", "er", "die", "Meu\u00b7te", "bei\u00b7sam\u00b7men", "wei\u00df", ",", "\u2013", "bums", "!", "ging's"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word"], "pos": ["ART", "NN", "$.", "PWAV", "PPER", "ART", "NN", "VVIZU", "VVFIN", "$,", "$(", "NE", "$.", "VVFIN"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Nach rechts \u2013 ein Purzelbaum \u2013 sie nach \u2013 er wieder links:", "tokens": ["Nach", "rechts", "\u2013", "ein", "Pur\u00b7zel\u00b7baum", "\u2013", "sie", "nach", "\u2013", "er", "wie\u00b7der", "links", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "$(", "ART", "NN", "$(", "PPER", "APPR", "$(", "PPER", "ADV", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Flink in zwei S\u00e4tzen, \u2013 er macht sich die Dummheit der Hunde zu Nutz \u2013", "tokens": ["Flink", "in", "zwei", "S\u00e4t\u00b7zen", ",", "\u2013", "er", "macht", "sich", "die", "Dumm\u00b7heit", "der", "Hun\u00b7de", "zu", "Nutz", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "CARD", "NN", "$,", "$(", "PPER", "VVFIN", "PRF", "ART", "NN", "ART", "NN", "APPR", "NN", "$("], "meter": "+--+--+--+--+--+", "measure": "dactylic.tetra.plus"}, "line.27": {"text": "Sie flugs nach links ihm nach: er in den Wald, und mein Mutz:", "tokens": ["Sie", "flugs", "nach", "links", "ihm", "nach", ":", "er", "in", "den", "Wald", ",", "und", "mein", "Mutz", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPR", "ADV", "PPER", "PTKVZ", "$.", "PPER", "APPR", "ART", "NN", "$,", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.28": {"text": "Rapps!\u00ab \u2013 Also schreiend war er, \u00fcber den Tisch gebogen,", "tokens": ["Rapps", "!", "\u00ab", "\u2013", "Al\u00b7so", "schrei\u00b7end", "war", "er", ",", "\u00fc\u00b7ber", "den", "Tisch", "ge\u00b7bo\u00b7gen", ","], "token_info": ["word", "punct", "punct", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$.", "$(", "$(", "ADV", "ADJD", "VAFIN", "PPER", "$,", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Bis auf die andre Seite mit seinen Fingern geflogen \u2013", "tokens": ["Bis", "auf", "die", "and\u00b7re", "Sei\u00b7te", "mit", "sei\u00b7nen", "Fin\u00b7gern", "ge\u00b7flo\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$("], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und \u00bbRapps!\u00ab so schrie er m\u00e4chtig Thadd\u00e4us dicht in's Ohr \u2013", "tokens": ["Und", "\u00bb", "Rapps", "!", "\u00ab", "so", "schrie", "er", "m\u00e4ch\u00b7tig", "Thad\u00b7d\u00e4us", "dicht", "in's", "Ohr", "\u2013"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$(", "NE", "$.", "$(", "ADV", "VVFIN", "PPER", "ADJD", "NE", "ADJD", "APPRART", "NN", "$("], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Thadd\u00e4us und seine Dame schrecken j\u00e4h empor,", "tokens": ["Thad\u00b7d\u00e4us", "und", "sei\u00b7ne", "Da\u00b7me", "schre\u00b7cken", "j\u00e4h", "em\u00b7por", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "VVFIN", "ADJD", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Aus traulichem Gespr\u00e4ch. Es fliehen wider Willen", "tokens": ["Aus", "trau\u00b7li\u00b7chem", "Ge\u00b7spr\u00e4ch", ".", "Es", "flie\u00b7hen", "wi\u00b7der", "Wil\u00b7len"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "$.", "PPER", "VVFIN", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Die Stirnen von einander vor dem lauten Br\u00fcllen:", "tokens": ["Die", "Stir\u00b7nen", "von", "ein\u00b7an\u00b7der", "vor", "dem", "lau\u00b7ten", "Br\u00fcl\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PRF", "APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Gleich zwei verbund'nen Wipfeln, die der Wirbelwind", "tokens": ["Gleich", "zwei", "ver\u00b7bun\u00b7d'\u00b7nen", "Wip\u00b7feln", ",", "die", "der", "Wir\u00b7bel\u00b7wind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "CARD", "ADJA", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Mit j\u00e4hem Sto\u00dfe scheidet. Es trennen sich auch geschwind", "tokens": ["Mit", "j\u00e4\u00b7hem", "Sto\u00b7\u00dfe", "schei\u00b7det", ".", "Es", "tren\u00b7nen", "sich", "auch", "ge\u00b7schwind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$.", "PPER", "VVFIN", "PRF", "ADV", "ADJD"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.36": {"text": "Die H\u00e4nde, die unter'm Tisch nah' bei einander lagen \u2013", "tokens": ["Die", "H\u00e4n\u00b7de", ",", "die", "un\u00b7ter'm", "Tisch", "nah'", "bei", "ein\u00b7an\u00b7der", "la\u00b7gen", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPRART", "NN", "VVFIN", "APPR", "PRF", "VVFIN", "$("], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.37": {"text": "Und Eine R\u00f6the sieht man aus zwei Gesichtern schlagen.", "tokens": ["Und", "Ei\u00b7ne", "R\u00f6\u00b7the", "sieht", "man", "aus", "zwei", "Ge\u00b7sich\u00b7tern", "schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PIS", "APPR", "CARD", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.84": {"line.1": {"text": "Thadd\u00e4us wollt' verbergen, wie zerstreut er war,", "tokens": ["Thad\u00b7d\u00e4us", "wollt'", "ver\u00b7ber\u00b7gen", ",", "wie", "zer\u00b7streut", "er", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "VVINF", "$,", "PWAV", "VVFIN", "PPER", "VAFIN", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und meinte: \u00bbJa, ohne Zweifel, ja, mein lieber Notar,", "tokens": ["Und", "mein\u00b7te", ":", "\u00bb", "Ja", ",", "oh\u00b7ne", "Zwei\u00b7fel", ",", "ja", ",", "mein", "lie\u00b7ber", "No\u00b7tar", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$.", "$(", "PTKANT", "$,", "KOUI", "NN", "$,", "PTKANT", "$,", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Sch\u00f6n ist der Mutz, ist er nur auch ein t\u00fcchtiger Packer \u2013\u00ab", "tokens": ["Sch\u00f6n", "ist", "der", "Mutz", ",", "ist", "er", "nur", "auch", "ein", "t\u00fcch\u00b7ti\u00b7ger", "Pa\u00b7cker", "\u2013", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NE", "VAFIN", "ART", "NN", "$,", "VAFIN", "PPER", "ADV", "ADV", "ART", "ADJA", "NN", "$(", "$("], "meter": "+--+--+--+--+-", "measure": "dactylic.penta"}, "line.4": {"text": "\u00bbein Packer\u00ab? schrie der Notar, \u00bbmein Lieblingshund, so wacker,", "tokens": ["\u00bb", "ein", "Pa\u00b7cker", "\u00ab", "?", "schrie", "der", "No\u00b7tar", ",", "\u00bb", "mein", "Lieb\u00b7lings\u00b7hund", ",", "so", "wa\u00b7cker", ","], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "punct", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$(", "$.", "VVFIN", "ART", "NN", "$,", "$(", "PPOSAT", "NN", "$,", "ADV", "ADJD", "$,"], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Der w\u00e4r' vielleicht kein Packer?\u00ab Thadd\u00e4us freut sich nun sehr,", "tokens": ["Der", "w\u00e4r'", "viel\u00b7leicht", "kein", "Pa\u00b7cker", "?", "\u00ab", "Thad\u00b7d\u00e4us", "freut", "sich", "nun", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ADV", "PIAT", "NN", "$.", "$(", "NE", "VVFIN", "PRF", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.6": {"text": "Da\u00df ein so sch\u00f6ner Hund ganz ohne Tadel w\u00e4r',", "tokens": ["Da\u00df", "ein", "so", "sch\u00f6\u00b7ner", "Hund", "ganz", "oh\u00b7ne", "Ta\u00b7del", "w\u00e4r'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADV", "ADJA", "NN", "ADV", "APPR", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Bedauert, ihn nur beim Gang vom Wald geseh'n zu haben,", "tokens": ["Be\u00b7dau\u00b7ert", ",", "ihn", "nur", "beim", "Gang", "vom", "Wald", "ge\u00b7seh'n", "zu", "ha\u00b7ben", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "$,", "PPER", "ADV", "APPRART", "NN", "APPRART", "NN", "VVPP", "PTKZU", "VAINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Und ihn nicht n\u00e4her zu kennen nach allen seinen Gaben.", "tokens": ["Und", "ihn", "nicht", "n\u00e4\u00b7her", "zu", "ken\u00b7nen", "nach", "al\u00b7len", "sei\u00b7nen", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "PTKNEG", "ADJD", "PTKZU", "VVINF", "APPR", "PIAT", "PPOSAT", "NN", "$."], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Mit Basiliskenblicken durchbohrt er den jungen Sprecher \u2013", "tokens": ["Mit", "Ba\u00b7si\u00b7lis\u00b7ken\u00b7bli\u00b7cken", "durch\u00b7bohrt", "er", "den", "jun\u00b7gen", "Spre\u00b7cher", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Er war nicht so beweglich, konnt auch nicht so schrei'n,", "tokens": ["Er", "war", "nicht", "so", "be\u00b7weg\u00b7lich", ",", "konnt", "auch", "nicht", "so", "schrei'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "ADJD", "$,", "VMFIN", "ADV", "PTKNEG", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Wie der Notar, er war viel schm\u00e4chtiger und klein,", "tokens": ["Wie", "der", "No\u00b7tar", ",", "er", "war", "viel", "schm\u00e4ch\u00b7ti\u00b7ger", "und", "klein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "$,", "PPER", "VAFIN", "ADV", "ADJD", "KON", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Doch Kreistag, Ball und Redoute kannten seine Schrecken:", "tokens": ["Doch", "Kreis\u00b7tag", ",", "Ball", "und", "Re\u00b7dou\u00b7te", "kann\u00b7ten", "sei\u00b7ne", "Schre\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "NN", "KON", "NN", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Der Mann hat einen Stachel in der Zunge stecken,", "tokens": ["Der", "Mann", "hat", "ei\u00b7nen", "Sta\u00b7chel", "in", "der", "Zun\u00b7ge", "ste\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ART", "NN", "APPR", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Hie\u00df es von ihm; so witzig wu\u00dfte er zu spa\u00dfen,", "tokens": ["Hie\u00df", "es", "von", "ihm", ";", "so", "wit\u00b7zig", "wu\u00df\u00b7te", "er", "zu", "spa\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPER", "$.", "ADV", "ADJD", "VVFIN", "PPER", "PTKZU", "VVINF", "$,"], "meter": "+--+-+-+-+-+-", "measure": "iambic.hexa.invert"}, "line.15": {"text": "Man h\u00e4tt' es im Kalender k\u00f6nnen drucken lassen \u2013", "tokens": ["Man", "h\u00e4tt'", "es", "im", "Ka\u00b7len\u00b7der", "k\u00f6n\u00b7nen", "dru\u00b7cken", "las\u00b7sen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "PPER", "APPRART", "NN", "VMFIN", "VVINF", "VVINF", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}, "line.16": {"text": "Und immer scharf und bissig. \u2013 Fr\u00fcher ziemlich reich,", "tokens": ["Und", "im\u00b7mer", "scharf", "und", "bis\u00b7sig", ".", "\u2013", "Fr\u00fc\u00b7her", "ziem\u00b7lich", "reich", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ADJD", "KON", "ADJD", "$.", "$(", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Verputzt' er sein eigenes Erbtheil und das des Bruders zugleich,", "tokens": ["Ver\u00b7putzt'", "er", "sein", "ei\u00b7ge\u00b7nes", "E\u00b7rbtheil", "und", "das", "des", "Bru\u00b7ders", "zu\u00b7gleich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "ADJA", "NN", "KON", "PDS", "ART", "NN", "ADV", "$,"], "meter": "-+--+---+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Um in der gro\u00dfen Welt nur recht viel Pomp zu entfalten;", "tokens": ["Um", "in", "der", "gro\u00b7\u00dfen", "Welt", "nur", "recht", "viel", "Pomp", "zu", "ent\u00b7fal\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "ADJA", "NN", "ADV", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Drauf trat er in den Staatsdienst, um im Bezirk zu schalten.", "tokens": ["Drauf", "trat", "er", "in", "den", "Staats\u00b7dienst", ",", "um", "im", "Be\u00b7zirk", "zu", "schal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "KOUI", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.20": {"text": "Er jagt f\u00fcr's Leben gerne, theils der Kurzweil wegen,", "tokens": ["Er", "jagt", "f\u00fcr's", "Le\u00b7ben", "ger\u00b7ne", ",", "theils", "der", "Kurz\u00b7weil", "we\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPRART", "NN", "ADV", "$,", "ADV", "ART", "NN", "APPR", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Theils, weil ihm Horn und Treibjagd Erinn'rungen erregen", "tokens": ["Theils", ",", "weil", "ihm", "Horn", "und", "Treib\u00b7jagd", "Er\u00b7inn'\u00b7run\u00b7gen", "er\u00b7re\u00b7gen"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "PPER", "NE", "KON", "NN", "NN", "VVINF"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.22": {"text": "An seine jungen Jahre, da er noch sein genannt", "tokens": ["An", "sei\u00b7ne", "jun\u00b7gen", "Jah\u00b7re", ",", "da", "er", "noch", "sein", "ge\u00b7nannt"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,", "KOUS", "PPER", "ADV", "PPOSAT", "VVPP"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.23": {"text": "Viel J\u00e4gersleute und Meuten, weit und breit bekannt.", "tokens": ["Viel", "J\u00e4\u00b7gers\u00b7leu\u00b7te", "und", "Meu\u00b7ten", ",", "weit", "und", "breit", "be\u00b7kannt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "KON", "NN", "$,", "ADJD", "KON", "ADJD", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Zwei Windspiele besa\u00df er noch aus jenen Zeiten,", "tokens": ["Zwei", "Wind\u00b7spie\u00b7le", "be\u00b7sa\u00df", "er", "noch", "aus", "je\u00b7nen", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+---+-+-+-+-", "measure": "dactylic.init"}, "line.25": {"text": "Und Einem von diesen wollt' man noch den Ruhm bestreiten!", "tokens": ["Und", "Ei\u00b7nem", "von", "die\u00b7sen", "wollt'", "man", "noch", "den", "Ruhm", "be\u00b7strei\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "APPR", "PDAT", "VMFIN", "PIS", "ADV", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "So r\u00fcckt er denn n\u00e4her, streichelt langsam den Backenbart,", "tokens": ["So", "r\u00fcckt", "er", "denn", "n\u00e4\u00b7her", ",", "strei\u00b7chelt", "lang\u00b7sam", "den", "Ba\u00b7cken\u00b7bart", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "ADJD", "$,", "VVFIN", "ADJD", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.27": {"text": "Und l\u00e4chelnd beginnt er (es war ein L\u00e4cheln giftiger Art):", "tokens": ["Und", "l\u00e4\u00b7chelnd", "be\u00b7ginnt", "er", "(", "es", "war", "ein", "L\u00e4\u00b7cheln", "gif\u00b7ti\u00b7ger", "Art", ")", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "$(", "PPER", "VAFIN", "ART", "NN", "ADJA", "NN", "$(", "$."], "meter": "-+--+--+-+-+--+", "measure": "amphibrach.tri.plus"}, "line.28": {"text": "\u00bbein Hund ohne Schwanz, das ist ein Schlachcic ohne Amt \u2013", "tokens": ["\u00bb", "ein", "Hund", "oh\u00b7ne", "Schwanz", ",", "das", "ist", "ein", "Schlach\u00b7cic", "oh\u00b7ne", "Amt", "\u2013"], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "APPR", "NN", "$,", "PDS", "VAFIN", "ART", "NN", "APPR", "NN", "$("], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Der Schwanz macht ihn behender: woher auch das Sprichwort stammt,", "tokens": ["Der", "Schwanz", "macht", "ihn", "be\u00b7hen\u00b7der", ":", "wo\u00b7her", "auch", "das", "Sprich\u00b7wort", "stammt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKVZ", "$.", "PWAV", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.30": {"text": "Ihr scheint euch aber den Stutzschwanz als Vorzug vorzustellen?", "tokens": ["Ihr", "scheint", "euch", "a\u00b7ber", "den", "Stutz\u00b7schwanz", "als", "Vor\u00b7zug", "vor\u00b7zu\u00b7stel\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ADV", "ART", "NN", "KOUS", "NN", "VVIZU", "$."], "meter": "-+-+--++-+-+-+-", "measure": "iambic.septa.relaxed"}, "line.31": {"text": "\u00dcbrigens mag eure Tante hier das Urtheil f\u00e4llen,", "tokens": ["\u00dcb\u00b7ri\u00b7gens", "mag", "eu\u00b7re", "Tan\u00b7te", "hier", "das", "Ur\u00b7theil", "f\u00e4l\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.32": {"text": "Ob auch Frau Telimene in der Hauptstadt geweilt", "tokens": ["Ob", "auch", "Frau", "Te\u00b7li\u00b7me\u00b7ne", "in", "der", "Haupt\u00b7stadt", "ge\u00b7weilt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "NN", "NN", "APPR", "ART", "NN", "VVPP"], "meter": "---+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.33": {"text": "Und unser l\u00e4ndliches Leben erst seit Kurzem theilt,", "tokens": ["Und", "un\u00b7ser", "l\u00e4nd\u00b7li\u00b7ches", "Le\u00b7ben", "erst", "seit", "Kur\u00b7zem", "theilt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "ADJA", "NN", "ADV", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Doch wei\u00df sie im Jagen besser, als junge J\u00e4ger, Bescheid, \u2013", "tokens": ["Doch", "wei\u00df", "sie", "im", "Ja\u00b7gen", "bes\u00b7ser", ",", "als", "jun\u00b7ge", "J\u00e4\u00b7ger", ",", "Be\u00b7scheid", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "NN", "ADJD", "$,", "KOUS", "ADJA", "NN", "$,", "NN", "$,", "$("], "meter": "-+--+-+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Seht ihr: So kommt die Einsicht von selber mit der Zeit.\u00ab", "tokens": ["Seht", "ihr", ":", "So", "kommt", "die", "Ein\u00b7sicht", "von", "sel\u00b7ber", "mit", "der", "Zeit", ".", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "$.", "ADV", "VVFIN", "ART", "NN", "APPR", "ADV", "APPR", "ART", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.85": {"line.1": {"text": "Thadd\u00e4us, so angedonnert, er wu\u00dfte kaum, warum, \u2013", "tokens": ["Thad\u00b7d\u00e4us", ",", "so", "an\u00b7ge\u00b7don\u00b7nert", ",", "er", "wu\u00df\u00b7te", "kaum", ",", "wa\u00b7rum", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["NE", "$,", "ADV", "VVPP", "$,", "PPER", "VVFIN", "ADV", "$,", "PWAV", "$,", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Erhebt sich ganz verwirrt, bleibt eine Weile stumm,", "tokens": ["Er\u00b7hebt", "sich", "ganz", "ver\u00b7wirrt", ",", "bleibt", "ei\u00b7ne", "Wei\u00b7le", "stumm", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "ADV", "ADJD", "$,", "VVFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Mi\u00dft aber den Assessor mit immer wild'rem Blick:", "tokens": ["Mi\u00dft", "a\u00b7ber", "den", "As\u00b7ses\u00b7sor", "mit", "im\u00b7mer", "wild'\u00b7rem", "Blick", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "APPR", "ADV", "ADJA", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Da niest der K\u00e4mmerer zweimal, es war ein gro\u00dfes Gl\u00fcck \u2013", "tokens": ["Da", "niest", "der", "K\u00e4m\u00b7me\u00b7rer", "zwei\u00b7mal", ",", "es", "war", "ein", "gro\u00b7\u00dfes", "Gl\u00fcck", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,", "PPER", "VAFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-----+-+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "Helfgott! ruft Alles \u2013 er neigt sich dankend im ganzen Kreise", "tokens": ["Helf\u00b7gott", "!", "ruft", "Al\u00b7les", "\u2013", "er", "neigt", "sich", "dan\u00b7kend", "im", "gan\u00b7zen", "Krei\u00b7se"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "$.", "VVFIN", "PIS", "$(", "PPER", "VVFIN", "PRF", "ADJD", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-+--+-+-", "measure": "trochaic.septa.relaxed"}, "line.6": {"text": "Und an die Dose klopft er mit den Fingern leise.", "tokens": ["Und", "an", "die", "Do\u00b7se", "klopft", "er", "mit", "den", "Fin\u00b7gern", "lei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "APPR", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die Dose war von Gold, mit Edelsteinen belegt,", "tokens": ["Die", "Do\u00b7se", "war", "von", "Gold", ",", "mit", "E\u00b7del\u00b7stei\u00b7nen", "be\u00b7legt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Das Bild des K\u00f6nigs Stanislaus mitten eingepr\u00e4gt;", "tokens": ["Das", "Bild", "des", "K\u00f6\u00b7nigs", "Sta\u00b7nis\u00b7laus", "mit\u00b7ten", "ein\u00b7ge\u00b7pr\u00e4gt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "In Ehren hielt sie nun der Sohn sein ganzes Leben.", "tokens": ["In", "Eh\u00b7ren", "hielt", "sie", "nun", "der", "Sohn", "sein", "gan\u00b7zes", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "PPER", "ADV", "ART", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Klopft er an diese Dose, so hei\u00dft das: er will sprechen.", "tokens": ["Klopft", "er", "an", "die\u00b7se", "Do\u00b7se", ",", "so", "hei\u00dft", "das", ":", "er", "will", "spre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PDAT", "NN", "$,", "ADV", "VVFIN", "PDS", "$.", "PPER", "VMFIN", "VVINF", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.11": {"text": "Da schweigen Alle und Keiner wagt ihn zu unterbrechen. \u2013", "tokens": ["Da", "schwei\u00b7gen", "Al\u00b7le", "und", "Kei\u00b7ner", "wagt", "ihn", "zu", "un\u00b7ter\u00b7bre\u00b7chen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "KON", "PIS", "VVFIN", "PPER", "PTKZU", "VVINF", "$.", "$("], "meter": "-+-+--+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Er sprach: \u00bbGro\u00dfm\u00e4chtige Herrn und Br\u00fcder allzumal!", "tokens": ["Er", "sprach", ":", "\u00bb", "Gro\u00df\u00b7m\u00e4ch\u00b7ti\u00b7ge", "Herrn", "und", "Br\u00fc\u00b7der", "all\u00b7zu\u00b7mal", "!"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "$(", "ADJA", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Nur Forst und Felder sind des J\u00e4gers Tribunal,", "tokens": ["Nur", "Forst", "und", "Fel\u00b7der", "sind", "des", "J\u00e4\u00b7gers", "Tri\u00b7bu\u00b7nal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "KON", "NN", "VAFIN", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Weshalb ich in solchen Dingen zu Haus kein Urtheil k\u00fcnde,", "tokens": ["We\u00b7shalb", "ich", "in", "sol\u00b7chen", "Din\u00b7gen", "zu", "Haus", "kein", "Ur\u00b7theil", "k\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PIAT", "NN", "APPR", "NN", "PIAT", "NN", "ADJA", "$,"], "meter": "+-+-+-+--+-+-+-", "measure": "trochaic.septa.relaxed"}, "line.15": {"text": "Und unsere Sitzung f\u00fcr morgen anzuberaumen finde,", "tokens": ["Und", "un\u00b7se\u00b7re", "Sit\u00b7zung", "f\u00fcr", "mor\u00b7gen", "an\u00b7zu\u00b7be\u00b7rau\u00b7men", "fin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "APPR", "ADV", "VVIZU", "VVFIN", "$,"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.16": {"text": "Und weitere Repliken den Streitenden untersage.", "tokens": ["Und", "wei\u00b7te\u00b7re", "Re\u00b7pli\u00b7ken", "den", "Strei\u00b7ten\u00b7den", "un\u00b7ter\u00b7sa\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.17": {"text": "Frohnbote, f\u00fcr morgen, f\u00fcr's Feld, vertage du die Frage!", "tokens": ["Frohn\u00b7bo\u00b7te", ",", "f\u00fcr", "mor\u00b7gen", ",", "f\u00fcr's", "Feld", ",", "ver\u00b7ta\u00b7ge", "du", "die", "Fra\u00b7ge", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "APPR", "ADV", "$,", "APPRART", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+--+--+-+-+-+-", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Der Graf mit seinem Jagdtro\u00df trifft hier morgen ein,", "tokens": ["Der", "Graf", "mit", "sei\u00b7nem", "Jagd\u00b7tro\u00df", "trifft", "hier", "mor\u00b7gen", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "ADV", "ADV", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Und ihr auch, Nachbar Richter, werdet mit uns sein,", "tokens": ["Und", "ihr", "auch", ",", "Nach\u00b7bar", "Rich\u00b7ter", ",", "wer\u00b7det", "mit", "uns", "sein", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "ADV", "$,", "NN", "NN", "$,", "VAFIN", "APPR", "PPER", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Frau Telimene auch, die Fr\u00e4ulein und die Frauen \u2013", "tokens": ["Frau", "Te\u00b7li\u00b7me\u00b7ne", "auch", ",", "die", "Fr\u00e4u\u00b7lein", "und", "die", "Frau\u00b7en", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "ADV", "$,", "ART", "NN", "KON", "ART", "NN", "$("], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Kurz, morgen kriegen wir ein wacker Jagen zu schauen \u2013", "tokens": ["Kurz", ",", "mor\u00b7gen", "krie\u00b7gen", "wir", "ein", "wa\u00b7cker", "Ja\u00b7gen", "zu", "schau\u00b7en", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Und unser Wojski auch wird sich uns nicht entzieh'n.\u00ab", "tokens": ["Und", "un\u00b7ser", "Wojs\u00b7ki", "auch", "wird", "sich", "uns", "nicht", "ent\u00b7zieh'", "n.", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation", "punct"], "pos": ["KON", "PPOSAT", "NN", "ADV", "VAFIN", "PRF", "PPER", "PTKNEG", "VVFIN", "NE", "$("], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Mit diesen Worten reicht er dem Greis die Dose hin.", "tokens": ["Mit", "die\u00b7sen", "Wor\u00b7ten", "reicht", "er", "dem", "Greis", "die", "Do\u00b7se", "hin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "NN", "VVFIN", "PPER", "ART", "NN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.86": {"line.1": {"text": "Der sa\u00df an der Ecke mitten unter den J\u00e4gersleuten,", "tokens": ["Der", "sa\u00df", "an", "der", "E\u00b7cke", "mit\u00b7ten", "un\u00b7ter", "den", "J\u00e4\u00b7gers\u00b7leu\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Geschlossenen Auges h\u00f6rt' er all' das Reden und Streiten,", "tokens": ["Ge\u00b7schlos\u00b7se\u00b7nen", "Au\u00b7ges", "h\u00f6rt'", "er", "all'", "das", "Re\u00b7den", "und", "Strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "PPER", "PIS", "ART", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Doch ohne ein Wort zu sprechen, wiewohl man ihn \u00f6fter fragt, \u2013", "tokens": ["Doch", "oh\u00b7ne", "ein", "Wort", "zu", "spre\u00b7chen", ",", "wie\u00b7wohl", "man", "ihn", "\u00f6f\u00b7ter", "fragt", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$,", "KOUS", "PIS", "PPER", "ADV", "VVFIN", "$,", "$("], "meter": "-+--+-+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.4": {"text": "Denn Keiner wei\u00df, wie er, Bescheid in Sachen der Jagd.", "tokens": ["Denn", "Kei\u00b7ner", "wei\u00df", ",", "wie", "er", ",", "Be\u00b7scheid", "in", "Sa\u00b7chen", "der", "Jagd", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$,", "PWAV", "PPER", "$,", "NN", "APPR", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.5": {"text": "Er schwieg; die Prise, die er zwischen die Finger schlo\u00df,", "tokens": ["Er", "schwieg", ";", "die", "Pri\u00b7se", ",", "die", "er", "zwi\u00b7schen", "die", "Fin\u00b7ger", "schlo\u00df", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ART", "NN", "$,", "PRELS", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Wog er in langem Sinnen, bis er sie endlich geno\u00df \u2013", "tokens": ["Wog", "er", "in", "lan\u00b7gem", "Sin\u00b7nen", ",", "bis", "er", "sie", "end\u00b7lich", "ge\u00b7no\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "KOUS", "PPER", "PPER", "ADV", "VVFIN", "$("], "meter": "+--+-+-+--+--+", "measure": "iambic.hexa.invert"}, "line.7": {"text": "Er niest: da\u00df es gewaltig hallt im ganzen Gemach;", "tokens": ["Er", "niest", ":", "da\u00df", "es", "ge\u00b7wal\u00b7tig", "hallt", "im", "gan\u00b7zen", "Ge\u00b7mach", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "KOUS", "PPER", "ADJD", "VVFIN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.8": {"text": "Kopfsch\u00fcttelnd und bitter l\u00e4chelnd begann er drauf und sprach:", "tokens": ["Kopf\u00b7sch\u00fct\u00b7telnd", "und", "bit\u00b7ter", "l\u00e4\u00b7chelnd", "be\u00b7gann", "er", "drauf", "und", "sprach", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "KON", "ADJD", "ADJD", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "\u00bbo! Wie mich alten Mann das wundern mu\u00df und gr\u00e4men!", "tokens": ["\u00bb", "o", "!", "Wie", "mich", "al\u00b7ten", "Mann", "das", "wun\u00b7dern", "mu\u00df", "und", "gr\u00e4\u00b7men", "!"], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "FM", "$.", "PWAV", "PPER", "ADJA", "NN", "ART", "VVINF", "VMFIN", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Was sagten die alten J\u00e4ger, wenn sie das vern\u00e4hmen,", "tokens": ["Was", "sag\u00b7ten", "die", "al\u00b7ten", "J\u00e4\u00b7ger", ",", "wenn", "sie", "das", "ver\u00b7n\u00e4h\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$,", "KOUS", "PPER", "PDS", "VVINF", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Da\u00df mitten in so vieler edler Herren Kranz", "tokens": ["Da\u00df", "mit\u00b7ten", "in", "so", "vie\u00b7ler", "ed\u00b7ler", "Her\u00b7ren", "Kranz"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "APPR", "ADV", "PIAT", "ADJA", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Processe verhandelt werden um eines Windspiels Schwanz?", "tokens": ["Pro\u00b7ces\u00b7se", "ver\u00b7han\u00b7delt", "wer\u00b7den", "um", "ei\u00b7nes", "Wind\u00b7spiels", "Schwanz", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "VAINF", "APPR", "ART", "NN", "NN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Was sagte der alte Rejtan, k\u00e4m' er zur Erde wieder?", "tokens": ["Was", "sag\u00b7te", "der", "al\u00b7te", "Rej\u00b7tan", ",", "k\u00e4m'", "er", "zur", "Er\u00b7de", "wie\u00b7der", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "APPRART", "NN", "ADV", "$."], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Er gienge nach Lachowicze und legt' auf's neu' sich nieder.", "tokens": ["Er", "gien\u00b7ge", "nach", "La\u00b7cho\u00b7wic\u00b7ze", "und", "legt'", "auf's", "neu'", "sich", "nie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "NN", "KON", "VVFIN", "APPRART", "ADJA", "PRF", "PTKVZ", "$."], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Was d\u00e4cht' sich der Wojewode Niesiolowski", "tokens": ["Was", "d\u00e4cht'", "sich", "der", "Wo\u00b7je\u00b7wo\u00b7de", "Nie\u00b7si\u00b7o\u00b7lo\u00b7wski"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "ART", "NN", "NE"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Er, der jetzt in der Welt besitzt die erste Meute,", "tokens": ["Er", ",", "der", "jetzt", "in", "der", "Welt", "be\u00b7sitzt", "die", "ers\u00b7te", "Meu\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "PRELS", "ADV", "APPR", "ART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und h\u00e4lt zweihundert J\u00e4ger, nach gro\u00dfer Herren Art,", "tokens": ["Und", "h\u00e4lt", "zwei\u00b7hun\u00b7dert", "J\u00e4\u00b7ger", ",", "nach", "gro\u00b7\u00dfer", "Her\u00b7ren", "Art", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "CARD", "NN", "$,", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Und hundert Wagen Netze in seinem Schlo\u00df bewahrt,", "tokens": ["Und", "hun\u00b7dert", "Wa\u00b7gen", "Net\u00b7ze", "in", "sei\u00b7nem", "Schlo\u00df", "be\u00b7wahrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "CARD", "NN", "NN", "APPR", "PPOSAT", "NN", "VVPP", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Und doch, wie ein M\u00f6nch, seit Jahren sitzt in seinem Nest,", "tokens": ["Und", "doch", ",", "wie", "ein", "M\u00f6nch", ",", "seit", "Jah\u00b7ren", "sitzt", "in", "sei\u00b7nem", "Nest", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "$,", "PWAV", "ART", "NN", "$,", "APPR", "NN", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+-+-+-+-+-+", "measure": "anapaest.init"}, "line.20": {"text": "Und sich um keinen Preis zur Jagd erbitten l\u00e4\u00dft,", "tokens": ["Und", "sich", "um", "kei\u00b7nen", "Preis", "zur", "Jagd", "er\u00b7bit\u00b7ten", "l\u00e4\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "APPR", "PIAT", "NN", "APPRART", "NN", "VVINF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Denn was auch soll der Alte auf euren Jagden jagen?", "tokens": ["Denn", "was", "auch", "soll", "der", "Al\u00b7te", "auf", "eu\u00b7ren", "Jag\u00b7den", "ja\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "ADV", "VMFIN", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Das w\u00e4r' ein sch\u00f6ner Ruhm, den solch ein Herr erstritte,", "tokens": ["Das", "w\u00e4r'", "ein", "sch\u00f6\u00b7ner", "Ruhm", ",", "den", "solch", "ein", "Herr", "er\u00b7strit\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "ART", "PIAT", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "Wenn er, nach heut'ger Mode, auf Hasenf\u00e4hrten ritte!", "tokens": ["Wenn", "er", ",", "nach", "heut'\u00b7ger", "Mo\u00b7de", ",", "auf", "Ha\u00b7sen\u00b7f\u00e4hr\u00b7ten", "rit\u00b7te", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "$,", "APPR", "ADJA", "NN", "$,", "APPR", "NN", "VVFIN", "$."], "meter": "--+--+--+-+-+-", "measure": "anapaest.tri.plus"}, "line.24": {"text": "Zu meinen Zeiten, ihr Herrn, da hie\u00dfen wir J\u00e4gersleute", "tokens": ["Zu", "mei\u00b7nen", "Zei\u00b7ten", ",", "ihr", "Herrn", ",", "da", "hie\u00b7\u00dfen", "wir", "J\u00e4\u00b7gers\u00b7leu\u00b7te"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "$,", "PPOSAT", "NN", "$,", "ADV", "VVFIN", "PPER", "NN"], "meter": "-+-+--+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Wolf, Elenn, B\u00e4r und Eber edelm\u00e4nnische Beute,", "tokens": ["Wolf", ",", "E\u00b7lenn", ",", "B\u00e4r", "und", "E\u00b7ber", "e\u00b7del\u00b7m\u00e4n\u00b7ni\u00b7sche", "Beu\u00b7te", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NN", "KON", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Und was nicht Klauen, Hauer oder H\u00f6rner trug,", "tokens": ["Und", "was", "nicht", "Klau\u00b7en", ",", "Hau\u00b7er", "o\u00b7der", "H\u00f6r\u00b7ner", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PTKNEG", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Lie\u00df man f\u00fcr Bursch und Tro\u00dfknecht mit gutem Recht und Fug.", "tokens": ["Lie\u00df", "man", "f\u00fcr", "Bursch", "und", "Tro\u00df\u00b7knecht", "mit", "gu\u00b7tem", "Recht", "und", "Fug", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "APPR", "NN", "KON", "NN", "APPR", "ADJA", "NN", "KON", "NN", "$."], "meter": "---+-+--+-+-+", "measure": "iambic.penta.relaxed"}, "line.28": {"text": "Es h\u00e4tte ja jeder Herr mit Grau'n sich weggewendet", "tokens": ["Es", "h\u00e4t\u00b7te", "ja", "je\u00b7der", "Herr", "mit", "Grau'n", "sich", "weg\u00b7ge\u00b7wen\u00b7det"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "APPR", "NN", "PRF", "VVPP"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Von einer Flinte, die jemals d\u00fcnnes Schrot gesch\u00e4ndet!", "tokens": ["Von", "ei\u00b7ner", "Flin\u00b7te", ",", "die", "je\u00b7mals", "d\u00fcn\u00b7nes", "Schrot", "ge\u00b7sch\u00e4n\u00b7det", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "PRELS", "ADV", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+--+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Windspiele hielt man wohl, denn bei der Heimkehr geschah's,", "tokens": ["Wind\u00b7spie\u00b7le", "hielt", "man", "wohl", ",", "denn", "bei", "der", "Heim\u00b7kehr", "ge\u00b7scha\u00b7h's", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PIS", "ADV", "$,", "KON", "APPR", "ART", "NN", "NE", "$,"], "meter": "++-+-+-+-+-+-+", "measure": "unknown.measure.octa.plus"}, "line.31": {"text": "Da\u00df unter dem Ro\u00df hervorglitt so ein armer Has',", "tokens": ["Da\u00df", "un\u00b7ter", "dem", "Ro\u00df", "her\u00b7vor\u00b7glitt", "so", "ein", "ar\u00b7mer", "Has'", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Da mochte man zur Kurzweil auf ihn die Hunde hetzen,", "tokens": ["Da", "moch\u00b7te", "man", "zur", "Kurz\u00b7weil", "auf", "ihn", "die", "Hun\u00b7de", "het\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "APPRART", "NN", "APPR", "PPER", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.33": {"text": "Und B\u00fcrschlein auf kleinen R\u00f6\u00dflein pflegten ihm nachzusetzen,", "tokens": ["Und", "B\u00fcr\u00b7schlein", "auf", "klei\u00b7nen", "R\u00f6\u00df\u00b7lein", "pfleg\u00b7ten", "ihm", "nach\u00b7zu\u00b7set\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "ADJA", "NN", "VVFIN", "PPER", "VVIZU", "$,"], "meter": "-+--+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.34": {"text": "Vor ihrer Eltern Augen, die solche Lustbarkeiten", "tokens": ["Vor", "ih\u00b7rer", "El\u00b7tern", "Au\u00b7gen", ",", "die", "sol\u00b7che", "Lust\u00b7bar\u00b7kei\u00b7ten"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$,", "PRELS", "PIAT", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.35": {"text": "Kaum w\u00fcrdigten anzuschauen, geschweige dr\u00fcber zu streiten.", "tokens": ["Kaum", "w\u00fcr\u00b7dig\u00b7ten", "an\u00b7zu\u00b7schau\u00b7en", ",", "ge\u00b7schwei\u00b7ge", "dr\u00fc\u00b7ber", "zu", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "VVIZU", "$,", "ADJA", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+--+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.36": {"text": "Drum, gn\u00e4digster Herr K\u00e4mm'rer, m\u00f6g's euch gef\u00e4llig sein,", "tokens": ["Drum", ",", "gn\u00e4\u00b7digs\u00b7ter", "Herr", "K\u00e4m\u00b7m'\u00b7rer", ",", "m\u00f6g's", "euch", "ge\u00b7f\u00e4l\u00b7lig", "sein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "ADJA", "NN", "NN", "$,", "VMFIN", "PPER", "ADJD", "VAINF", "$,"], "meter": "-+---+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.37": {"text": "Die Ordre zur\u00fcckzunehmen, mir aber zu verzeih'n,", "tokens": ["Die", "Ord\u00b7re", "zu\u00b7r\u00fcck\u00b7zu\u00b7neh\u00b7men", ",", "mir", "a\u00b7ber", "zu", "ver\u00b7zeih'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,", "PPER", "ADV", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.38": {"text": "Da\u00df ich auf solch ein Jagen mich keineswegs begebe,", "tokens": ["Da\u00df", "ich", "auf", "solch", "ein", "Ja\u00b7gen", "mich", "kei\u00b7nes\u00b7wegs", "be\u00b7ge\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PIAT", "ART", "NN", "PPER", "ADV", "VVFIN", "$,"], "meter": "---+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.39": {"text": "Und nie begeben werde, so lange ich noch lebe.", "tokens": ["Und", "nie", "be\u00b7ge\u00b7ben", "wer\u00b7de", ",", "so", "lan\u00b7ge", "ich", "noch", "le\u00b7be", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAFIN", "$,", "ADV", "ADV", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.40": {"text": "Hreczecha hei\u00df' ich und seit Lech's, des K\u00f6nigs Zeiten,", "tokens": ["Hre\u00b7cze\u00b7cha", "hei\u00df'", "ich", "und", "seit", "Lech's", ",", "des", "K\u00f6\u00b7nigs", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "KON", "APPR", "NE", "$,", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.41": {"text": "That niemals ein Hreczecha wider Hasen reiten.\u00ab", "tokens": ["That", "nie\u00b7mals", "ein", "Hre\u00b7cze\u00b7cha", "wi\u00b7der", "Ha\u00b7sen", "rei\u00b7ten", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "ADV", "ART", "NE", "APPR", "NE", "VVFIN", "$.", "$("], "meter": "-+--+--+-+-+-", "measure": "amphibrach.tri.plus"}}, "stanza.87": {"line.1": {"text": "Hier fingen die jungen Leute laut zu lachen an;", "tokens": ["Hier", "fin\u00b7gen", "die", "jun\u00b7gen", "Leu\u00b7te", "laut", "zu", "la\u00b7chen", "an", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "ADJD", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Man stand vom Tische auf, der K\u00e4mmerer schritt voran,", "tokens": ["Man", "stand", "vom", "Ti\u00b7sche", "auf", ",", "der", "K\u00e4m\u00b7me\u00b7rer", "schritt", "vo\u00b7ran", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPRART", "NN", "PTKVZ", "$,", "ART", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Seinem Alter und Amt ertheilt man die Ehre gern;", "tokens": ["Sei\u00b7nem", "Al\u00b7ter", "und", "Amt", "er\u00b7theilt", "man", "die", "Eh\u00b7re", "gern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "KON", "NN", "VVFIN", "PIS", "ART", "NN", "ADV", "$."], "meter": "--+--+-+--+-+", "measure": "anapaest.di.plus"}, "line.4": {"text": "Im Gehen gr\u00fc\u00dft er die Damen, die \u00e4ltern und j\u00fcngern Herrn.", "tokens": ["Im", "Ge\u00b7hen", "gr\u00fc\u00dft", "er", "die", "Da\u00b7men", ",", "die", "\u00e4l\u00b7tern", "und", "j\u00fcn\u00b7gern", "Herrn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "PPER", "ART", "NN", "$,", "PRELS", "ADJD", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Drauf folgt der M\u00f6nch, der Richter schlie\u00dft sich dicht an ihn,", "tokens": ["Drauf", "folgt", "der", "M\u00f6nch", ",", "der", "Rich\u00b7ter", "schlie\u00dft", "sich", "dicht", "an", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "$,", "ART", "NN", "VVFIN", "PRF", "ADJD", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Richter giebt an der Th\u00fcr den Arm der K\u00e4mm'rerin,", "tokens": ["Der", "Rich\u00b7ter", "giebt", "an", "der", "Th\u00fcr", "den", "Arm", "der", "K\u00e4m\u00b7m'\u00b7re\u00b7rin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "APPR", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Thadd\u00e4us bietet ihn Frau Telimenen dar,", "tokens": ["Thad\u00b7d\u00e4us", "bie\u00b7tet", "ihn", "Frau", "Te\u00b7li\u00b7me\u00b7nen", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "NN", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.8": {"text": "Assessor und Krajczanka bilden das n\u00e4chste Paar,", "tokens": ["As\u00b7ses\u00b7sor", "und", "Kraj\u00b7czan\u00b7ka", "bil\u00b7den", "das", "n\u00e4chs\u00b7te", "Paar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+--+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.9": {"text": "Zum Schlu\u00df des Wojski Tochter mit dem Herrn Notar.", "tokens": ["Zum", "Schlu\u00df", "des", "Wojs\u00b7ki", "Toch\u00b7ter", "mit", "dem", "Herrn", "No\u00b7tar", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.88": {"line.1": {"text": "Thadd\u00e4us f\u00fchrt einige G\u00e4ste zur Scheuer; \u2013 er ist verstimmt,", "tokens": ["Thad\u00b7d\u00e4us", "f\u00fchrt", "ei\u00b7ni\u00b7ge", "G\u00e4s\u00b7te", "zur", "Scheu\u00b7er", ";", "\u2013", "er", "ist", "ver\u00b7stimmt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PIAT", "NN", "APPRART", "NN", "$.", "$(", "PPER", "VAFIN", "VVPP", "$,"], "meter": "---+--+--+--+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Durchaus nicht guter Laune, verwirrt, sogar ergrimmt;", "tokens": ["Durc\u00b7haus", "nicht", "gu\u00b7ter", "Lau\u00b7ne", ",", "ver\u00b7wirrt", ",", "so\u00b7gar", "er\u00b7grimmt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "ADJA", "NN", "$,", "ADJD", "$,", "ADV", "VVPP", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Und alles, was heut' geschehen, zergliedert er im Sinn,", "tokens": ["Und", "al\u00b7les", ",", "was", "heut'", "ge\u00b7sche\u00b7hen", ",", "zer\u00b7glie\u00b7dert", "er", "im", "Sinn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "$,", "PRELS", "ADV", "VVPP", "$,", "VVFIN", "PPER", "APPRART", "NN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Die erste Begegnung, die Mahlzeit neben der Nachbarin;", "tokens": ["Die", "ers\u00b7te", "Be\u00b7geg\u00b7nung", ",", "die", "Mahl\u00b7zeit", "ne\u00b7ben", "der", "Nach\u00b7ba\u00b7rin", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+--+--+--+-+-+", "measure": "amphibrach.tetra.plus"}, "line.5": {"text": "Wie eine l\u00e4stige Fliege, umsummt's ihn immerfort", "tokens": ["Wie", "ei\u00b7ne", "l\u00e4s\u00b7ti\u00b7ge", "Flie\u00b7ge", ",", "um\u00b7summt's", "ihn", "im\u00b7mer\u00b7fort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWAV", "ART", "ADJA", "NN", "$,", "VVFIN", "PPER", "ADV"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Gern m\u00f6cht' er vom Gerichtsfrohn sich n\u00e4her berichten lassen,", "tokens": ["Gern", "m\u00f6cht'", "er", "vom", "Ge\u00b7richts\u00b7frohn", "sich", "n\u00e4\u00b7her", "be\u00b7rich\u00b7ten", "las\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "APPRART", "NN", "PRF", "ADJD", "VVINF", "VVINF", "$,"], "meter": "-+-+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "\u00dcber Frau Telimene, \u2013 doch der war nicht zu fassen;", "tokens": ["\u00dc\u00b7ber", "Frau", "Te\u00b7li\u00b7me\u00b7ne", ",", "\u2013", "doch", "der", "war", "nicht", "zu", "fas\u00b7sen", ";"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,", "$(", "ADV", "ART", "VAFIN", "PTKNEG", "PTKZU", "VVINF", "$."], "meter": "+-+--+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.8": {"text": "Auch der Wojski war fort. Sie waren allesammt", "tokens": ["Auch", "der", "Wojs\u00b7ki", "war", "fort", ".", "Sie", "wa\u00b7ren", "al\u00b7le\u00b7sammt"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VAFIN", "PTKVZ", "$.", "PPER", "VAFIN", "ADJD"], "meter": "--+--+-+-+-+", "measure": "anapaest.di.plus"}, "line.9": {"text": "Den G\u00e4sten gleich gefolgt, wie's des Gesindes Amt,", "tokens": ["Den", "G\u00e4s\u00b7ten", "gleich", "ge\u00b7folgt", ",", "wie's", "des", "Ge\u00b7sin\u00b7des", "Amt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVPP", "$,", "VVFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die Stuben herzurichten. Die Damen und die Alten", "tokens": ["Die", "Stu\u00b7ben", "her\u00b7zu\u00b7rich\u00b7ten", ".", "Die", "Da\u00b7men", "und", "die", "Al\u00b7ten"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "$.", "ART", "NN", "KON", "ART", "NN"], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Sollten im Herrengeb\u00e4ude ihre Nachtruh' halten,", "tokens": ["Soll\u00b7ten", "im", "Her\u00b7ren\u00b7ge\u00b7b\u00e4u\u00b7de", "ih\u00b7re", "Nachtruh'", "hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPRART", "NN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "+--+--+-+-++-", "measure": "dactylic.di.plus"}, "line.12": {"text": "Indessen, an Stelle des Hausherrn, Thadd\u00e4us die jungen Leute", "tokens": ["In\u00b7des\u00b7sen", ",", "an", "Stel\u00b7le", "des", "Haus\u00b7herrn", ",", "Thad\u00b7d\u00e4us", "die", "jun\u00b7gen", "Leu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "APPR", "NN", "ART", "NN", "$,", "NE", "ART", "ADJA", "NN"], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.13": {"text": "Zur Scheuer f\u00fchrt, aufs Heu; dort \u00fcbernachten sie heute.", "tokens": ["Zur", "Scheu\u00b7er", "f\u00fchrt", ",", "aufs", "Heu", ";", "dort", "\u00fc\u00b7bern\u00b7ach\u00b7ten", "sie", "heu\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$,", "APPRART", "NN", "$.", "ADV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}}, "stanza.89": {"line.1": {"text": "Bald drauf lag tiefe Stille \u00fcber das Haus gebreitet,", "tokens": ["Bald", "drauf", "lag", "tie\u00b7fe", "Stil\u00b7le", "\u00fc\u00b7ber", "das", "Haus", "ge\u00b7brei\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "VVFIN", "ADJA", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Gleichwie in Klosterhallen, wenn man zur Hora gel\u00e4utet.", "tokens": ["Gleich\u00b7wie", "in", "Klos\u00b7ter\u00b7hal\u00b7len", ",", "wenn", "man", "zur", "Ho\u00b7ra", "ge\u00b7l\u00e4u\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "$,", "KOUS", "PIS", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+--+--+-", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Des W\u00e4chters Stimme nur durcht\u00f6nt die Ruh' der Nacht.", "tokens": ["Des", "W\u00e4ch\u00b7ters", "Stim\u00b7me", "nur", "durch\u00b7t\u00f6nt", "die", "Ruh'", "der", "Nacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVFIN", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Entschlummert sind schon Alle. Nur der Richter wacht;", "tokens": ["Ent\u00b7schlum\u00b7mert", "sind", "schon", "Al\u00b7le", ".", "Nur", "der", "Rich\u00b7ter", "wacht", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "ADV", "PIS", "$.", "ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als Oberhaupt des Hauses durchdenkt er nun den Zug", "tokens": ["Als", "O\u00b7ber\u00b7haupt", "des", "Hau\u00b7ses", "durch\u00b7denkt", "er", "nun", "den", "Zug"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "NN", "ART", "NN", "VVFIN", "PPER", "ADV", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "In's Feld \u2013 und ordnet auch die ferneren Spiele klug;", "tokens": ["In's", "Feld", "\u2013", "und", "ord\u00b7net", "auch", "die", "fer\u00b7ne\u00b7ren", "Spie\u00b7le", "klug", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$(", "KON", "VVFIN", "ADV", "ART", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Aufseher, Verwalter, V\u00f6gte erhalten Befehle genau,", "tokens": ["Auf\u00b7se\u00b7her", ",", "Ver\u00b7wal\u00b7ter", ",", "V\u00f6g\u00b7te", "er\u00b7hal\u00b7ten", "Be\u00b7feh\u00b7le", "ge\u00b7nau", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "$,", "NN", "ADJA", "NN", "ADJD", "$,"], "meter": "+-+-+-+--+--+--+", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "Stallknechte, Schreiber und J\u00e4ger, und auch die Wirthschaftsfrau,", "tokens": ["Stall\u00b7knech\u00b7te", ",", "Schrei\u00b7ber", "und", "J\u00e4\u00b7ger", ",", "und", "auch", "die", "Wirth\u00b7schafts\u00b7frau", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "KON", "NN", "$,", "KON", "ADV", "ART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Auch alle Rechnungen vom Tag sind durchzuseh'n.", "tokens": ["Auch", "al\u00b7le", "Rech\u00b7nun\u00b7gen", "vom", "Tag", "sind", "durch\u00b7zu\u00b7seh'", "n."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "PIAT", "NN", "APPRART", "NN", "VAFIN", "XY", "XY"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nun sagt er dem Gerichtsfrohn, er wolle zu Bette geh'n.", "tokens": ["Nun", "sagt", "er", "dem", "Ge\u00b7richts\u00b7frohn", ",", "er", "wol\u00b7le", "zu", "Bet\u00b7te", "geh'", "n."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPER", "VMFIN", "APPR", "NN", "VVFIN", "NE"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der bindet ihm den Gurt ab \u2013 ein Slucker Gurt und gediegen", "tokens": ["Der", "bin\u00b7det", "ihm", "den", "Gurt", "ab", "\u2013", "ein", "Slu\u00b7cker", "Gurt", "und", "ge\u00b7die\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "PPER", "ART", "NN", "PTKVZ", "$(", "ART", "NN", "NE", "KON", "NN"], "meter": "-+-+-+--+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Mit strahlenden dichten Quasten, die wie ein Helmbusch fliegen; \u2013", "tokens": ["Mit", "strah\u00b7len\u00b7den", "dich\u00b7ten", "Quas\u00b7ten", ",", "die", "wie", "ein", "Helm\u00b7busch", "flie\u00b7gen", ";", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["APPR", "ADJA", "ADJA", "NN", "$,", "PRELS", "KOKOM", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die eine Seite aus Goldstoff, mit Purpurblumen geschm\u00fcckt,", "tokens": ["Die", "ei\u00b7ne", "Sei\u00b7te", "aus", "Gold\u00b7stoff", ",", "mit", "Pur\u00b7pur\u00b7blu\u00b7men", "ge\u00b7schm\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+--+--+-+--+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Die andre aus schwarzer Seide, mit Streifen, in Silber gestickt;", "tokens": ["Die", "and\u00b7re", "aus", "schwar\u00b7zer", "Sei\u00b7de", ",", "mit", "Strei\u00b7fen", ",", "in", "Sil\u00b7ber", "ge\u00b7stickt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "APPR", "ADJA", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "VVPP", "$."], "meter": "-+--+-+--+--+--+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Man kann einen solchen Gurt auf beiden Seiten tragen,", "tokens": ["Man", "kann", "ei\u00b7nen", "sol\u00b7chen", "Gurt", "auf", "bei\u00b7den", "Sei\u00b7ten", "tra\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "PIAT", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "+-+-+-+-+-+-+-", "measure": "trochaic.septa"}, "line.16": {"text": "Die goldne an festlichen, die schwarze an Trauertagen.", "tokens": ["Die", "gold\u00b7ne", "an", "fest\u00b7li\u00b7chen", ",", "die", "schwar\u00b7ze", "an", "Trau\u00b7er\u00b7ta\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "APPR", "ADJA", "$,", "PRELS", "VVFIN", "APPR", "NN", "$."], "meter": "-+--+---+--+-+-", "measure": "iambic.penta.relaxed"}, "line.17": {"text": "Der Frohn nur wei\u00df es, wie man ihn l\u00f6sen und falten mu\u00df \u2013", "tokens": ["Der", "Frohn", "nur", "wei\u00df", "es", ",", "wie", "man", "ihn", "l\u00f6\u00b7sen", "und", "fal\u00b7ten", "mu\u00df", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VVFIN", "PPER", "$,", "PWAV", "PIS", "PPER", "VVINF", "KON", "VVINF", "VMFIN", "$("], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.18": {"text": "Jetzt ist er eben daran, und sagt noch dies zum Schlu\u00df:", "tokens": ["Jetzt", "ist", "er", "e\u00b7ben", "da\u00b7ran", ",", "und", "sagt", "noch", "dies", "zum", "Schlu\u00df", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "PAV", "$,", "KON", "VVFIN", "ADV", "PDS", "APPRART", "NN", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.90": {"line.1": {"text": "\u00bbwas macht's, da\u00df ich die Tische geschafft zum Schlo\u00df hinein?", "tokens": ["\u00bb", "was", "macht's", ",", "da\u00df", "ich", "die", "Ti\u00b7sche", "ge\u00b7schafft", "zum", "Schlo\u00df", "hin\u00b7ein", "?"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWS", "VVFIN", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "APPRART", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Geschadet hat es Niemand \u2013 und Euch kann's n\u00fctzlich sein.", "tokens": ["Ge\u00b7scha\u00b7det", "hat", "es", "Nie\u00b7mand", "\u2013", "und", "Euch", "kann's", "n\u00fctz\u00b7lich", "sein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "VAFIN", "PPER", "PIS", "$(", "KON", "PPER", "VMFIN", "ADJD", "VAINF", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.3": {"text": "Hat doch um dieses Schlo\u00df sich der Proce\u00df entsponnen,", "tokens": ["Hat", "doch", "um", "die\u00b7ses", "Schlo\u00df", "sich", "der", "Pro\u00b7ce\u00df", "ent\u00b7spon\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "APPR", "PDAT", "NN", "PRF", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und heute haben wir darauf ein Recht gewonnen.", "tokens": ["Und", "heu\u00b7te", "ha\u00b7ben", "wir", "da\u00b7rauf", "ein", "Recht", "ge\u00b7won\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "PAV", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Da m\u00f6gen unsre Gegner noch so viel Ingrimm zeigen:", "tokens": ["Da", "m\u00f6\u00b7gen", "uns\u00b7re", "Geg\u00b7ner", "noch", "so", "viel", "In\u00b7grimm", "zei\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ADV", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-++-+-", "measure": "unknown.measure.septa"}, "line.6": {"text": "Ich weise nach, wir nahmen das alte Nest zu Eigen.", "tokens": ["Ich", "wei\u00b7se", "nach", ",", "wir", "nah\u00b7men", "das", "al\u00b7te", "Nest", "zu", "Ei\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "ART", "ADJA", "NN", "APPR", "NN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Wer auf ein Schlo\u00df zur Mahlzeit l\u00e4dt eine ganze Schaar,", "tokens": ["Wer", "auf", "ein", "Schlo\u00df", "zur", "Mahl\u00b7zeit", "l\u00e4dt", "ei\u00b7ne", "gan\u00b7ze", "Schaar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Sogar die Gegner selber sollen uns Zeugni\u00df geben:", "tokens": ["So\u00b7gar", "die", "Geg\u00b7ner", "sel\u00b7ber", "sol\u00b7len", "uns", "Zeug\u00b7ni\u00df", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VMFIN", "PPER", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Ich wei\u00df dergleichen F\u00e4lle genug aus meinem Leben.\u00ab", "tokens": ["Ich", "wei\u00df", "derg\u00b7lei\u00b7chen", "F\u00e4l\u00b7le", "ge\u00b7nug", "aus", "mei\u00b7nem", "Le\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "PIS", "NN", "ADV", "APPR", "PPOSAT", "NN", "$.", "$("], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}}, "stanza.91": {"line.1": {"text": "Schon schlief der Richter. Der Frohn geht sacht in's Vorhaus hinein,", "tokens": ["Schon", "schlief", "der", "Rich\u00b7ter", ".", "Der", "Frohn", "geht", "sacht", "in's", "Vor\u00b7haus", "hin\u00b7ein", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "$.", "ART", "NN", "VVFIN", "ADJD", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Setzt sich und zieht aus der Tasche bei einer Kerze Schein", "tokens": ["Setzt", "sich", "und", "zieht", "aus", "der", "Ta\u00b7sche", "bei", "ei\u00b7ner", "Ker\u00b7ze", "Schein"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "KON", "VVFIN", "APPR", "ART", "NN", "APPR", "ART", "ADJA", "NN"], "meter": "+--+--+--+-+-+", "measure": "dactylic.tri.plus"}, "line.3": {"text": "Ein B\u00fcchlein, das er immer und \u00fcberall mit sich tr\u00e4gt,", "tokens": ["Ein", "B\u00fcch\u00b7lein", ",", "das", "er", "im\u00b7mer", "und", "\u00fc\u00b7be\u00b7rall", "mit", "sich", "tr\u00e4gt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "ADV", "KON", "ADV", "APPR", "PRF", "VVFIN", "$,"], "meter": "-+-+-+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Zu Haus und auf der Reise, und wie ein Gebetbuch hegt.", "tokens": ["Zu", "Haus", "und", "auf", "der", "Rei\u00b7se", ",", "und", "wie", "ein", "Ge\u00b7bet\u00b7buch", "hegt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "APPR", "ART", "NN", "$,", "KON", "PWAV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+--++-+-+", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Es war die Gerichtsvocanda;", "tokens": ["Es", "war", "die", "Ge\u00b7richts\u00b7vo\u00b7can\u00b7da", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Die F\u00e4lle all' verzeichnet, die vor dem Tribunal", "tokens": ["Die", "F\u00e4l\u00b7le", "all'", "ver\u00b7zeich\u00b7net", ",", "die", "vor", "dem", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PIS", "VVFIN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Protasius selbst verk\u00fcndigt mit eignem Mund vor Jahren,", "tokens": ["Pro\u00b7ta\u00b7si\u00b7us", "selbst", "ver\u00b7k\u00fcn\u00b7digt", "mit", "eig\u00b7nem", "Mund", "vor", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVPP", "APPR", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Oder von denen er sp\u00e4ter N\u00e4heres mocht' erfahren.", "tokens": ["O\u00b7der", "von", "de\u00b7nen", "er", "sp\u00e4\u00b7ter", "N\u00e4\u00b7he\u00b7res", "mocht'", "er\u00b7fah\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PRELS", "PPER", "ADJD", "NN", "VMFIN", "VVINF", "$."], "meter": "+--+--+-+--+-+-", "measure": "dactylic.di.plus"}, "line.9": {"text": "Andern scheint die Liste nur Namen zu enthalten,", "tokens": ["An\u00b7dern", "scheint", "die", "Lis\u00b7te", "nur", "Na\u00b7men", "zu", "ent\u00b7hal\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "VVFIN", "ART", "NN", "ADV", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+--+-+-+-", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Ihm ist sie ein Gem\u00e4lde voll herrlicher Gestalten.", "tokens": ["Ihm", "ist", "sie", "ein", "Ge\u00b7m\u00e4l\u00b7de", "voll", "herr\u00b7li\u00b7cher", "Ge\u00b7stal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ART", "NN", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-++-+-+-", "measure": "unknown.measure.septa"}, "line.11": {"text": "In Sinnen versunken, las er: Oginski mit Wizgird,", "tokens": ["In", "Sin\u00b7nen", "ver\u00b7sun\u00b7ken", ",", "las", "er", ":", "O\u00b7gins\u00b7ki", "mit", "Wiz\u00b7gird", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,", "VVFIN", "PPER", "$.", "NE", "APPR", "NN", "$,"], "meter": "-+--+-+--+-++-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die Dominikaner mit Rymsza, Rymsza mit Wyzogird,", "tokens": ["Die", "Do\u00b7mi\u00b7ni\u00b7ka\u00b7ner", "mit", "Ryms\u00b7za", ",", "Ryms\u00b7za", "mit", "Wy\u00b7zo\u00b7gird", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,", "NE", "APPR", "NE", "$,"], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.13": {"text": "Radziwill mit Wereszczaka, Giedroic mit Rdultowski,", "tokens": ["Rad\u00b7zi\u00b7will", "mit", "We\u00b7resz\u00b7cza\u00b7ka", ",", "Gied\u00b7roic", "mit", "Rdul\u00b7tows\u00b7ki", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "NE", "$,", "NE", "APPR", "NN", "$,"], "meter": "+-+-+-+-+--+--", "measure": "trochaic.hexa.relaxed"}, "line.14": {"text": "Obuchowicz mit dem Kahal, Juraha mit Piotrowski,", "tokens": ["O\u00b7buc\u00b7ho\u00b7wicz", "mit", "dem", "Ka\u00b7hal", ",", "Ju\u00b7ra\u00b7ha", "mit", "Pio\u00b7trows\u00b7ki", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,", "NE", "APPR", "NN", "$,"], "meter": "++-+--+-+-+-+-+", "measure": "trochaic.octa.plus.relaxed"}, "line.15": {"text": "Malewski mit Mickiewicz, und zum Schlu\u00df der Graf", "tokens": ["Ma\u00b7lews\u00b7ki", "mit", "Mic\u00b7kie\u00b7wicz", ",", "und", "zum", "Schlu\u00df", "der", "Graf"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "APPR", "NE", "$,", "KON", "APPRART", "NN", "ART", "NN"], "meter": "-+--+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.16": {"text": "Mit Richter Soplica; \u2013 und jeder Name, auf den er traf,", "tokens": ["Mit", "Rich\u00b7ter", "Sop\u00b7li\u00b7ca", ";", "\u2013", "und", "je\u00b7der", "Na\u00b7me", ",", "auf", "den", "er", "traf", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$.", "$(", "KON", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+--+", "measure": "iambic.septa.chol"}, "line.17": {"text": "Mahnt ihn an gro\u00dfe H\u00e4ndel, an alle Einzelheiten,", "tokens": ["Mahnt", "ihn", "an", "gro\u00b7\u00dfe", "H\u00e4n\u00b7del", ",", "an", "al\u00b7le", "Ein\u00b7zel\u00b7hei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ADJA", "NN", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.18": {"text": "Er sieht Gericht und Zeugen, h\u00f6rt die Parteien streiten,", "tokens": ["Er", "sieht", "Ge\u00b7richt", "und", "Zeu\u00b7gen", ",", "h\u00f6rt", "die", "Par\u00b7tei\u00b7en", "strei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "$,", "VVFIN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Er sieht sich selbst, wie er im wei\u00dfen Zupan stand,", "tokens": ["Er", "sieht", "sich", "selbst", ",", "wie", "er", "im", "wei\u00b7\u00dfen", "Zu\u00b7pan", "stand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "ADV", "$,", "PWAV", "PPER", "APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Den blauen Kontusz dar\u00fcber, am S\u00e4bel die eine Hand,", "tokens": ["Den", "blau\u00b7en", "Kon\u00b7tusz", "da\u00b7r\u00fc\u00b7ber", ",", "am", "S\u00e4\u00b7bel", "die", "ei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PAV", "$,", "APPRART", "NN", "ART", "ART", "NN", "$,"], "meter": "-+-+--+--+--+-+", "measure": "iambic.hexa.relaxed"}, "line.21": {"text": "Die andre auf dem Tisch \u2013 und vor dem Tribunal", "tokens": ["Die", "and\u00b7re", "auf", "dem", "Tisch", "\u2013", "und", "vor", "dem", "Tri\u00b7bu\u00b7nal"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "PIS", "APPR", "ART", "NN", "$(", "KON", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "Beide Parteien aufrief, und \u00bbRuhe!\u00ab laut befahl \u2013", "tokens": ["Bei\u00b7de", "Par\u00b7tei\u00b7en", "auf\u00b7rief", ",", "und", "\u00bb", "Ru\u00b7he", "!", "\u00ab", "laut", "be\u00b7fahl", "\u2013"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$,", "KON", "$(", "NN", "$.", "$(", "ADJD", "VVFIN", "$("], "meter": "+--+-+--+-+-+", "measure": "iambic.hexa.invert"}, "line.23": {"text": "So tr\u00e4umend und leise betend schlo\u00df sodann zur Ruh'", "tokens": ["So", "tr\u00e4u\u00b7mend", "und", "lei\u00b7se", "be\u00b7tend", "schlo\u00df", "so\u00b7dann", "zur", "Ruh'"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "KON", "ADJD", "VVPP", "VVFIN", "ADV", "APPRART", "NN"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Lithauens letzter Gerichtsfrohn sacht die Augen zu.", "tokens": ["Lit\u00b7hau\u00b7ens", "letz\u00b7ter", "Ge\u00b7richts\u00b7frohn", "sacht", "die", "Au\u00b7gen", "zu", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "VVFIN", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.92": {"line.1": {"text": "Also war Spiel und Streit zu jener Zeit bestellt", "tokens": ["Al\u00b7so", "war", "Spiel", "und", "Streit", "zu", "je\u00b7ner", "Zeit", "be\u00b7stellt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "NN", "KON", "NN", "APPR", "PDAT", "NN", "VVFIN"], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "Im stillen Lithauerdorf, da rings die \u00fcbrige Welt", "tokens": ["Im", "stil\u00b7len", "Lit\u00b7hau\u00b7er\u00b7dorf", ",", "da", "rings", "die", "\u00fcb\u00b7ri\u00b7ge", "Welt"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "ADJA", "NN", "$,", "KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-++-+-+-+--+", "measure": "iambic.septa.chol"}, "line.3": {"text": "In Blut und Thr\u00e4nen schwamm; als jener Gott der Schlacht,", "tokens": ["In", "Blut", "und", "Thr\u00e4\u00b7nen", "schwamm", ";", "als", "je\u00b7ner", "Gott", "der", "Schlacht", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "$.", "KOUS", "PDAT", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mit tausend Geschossen bewehrt, mit brausender Heeresmacht,", "tokens": ["Mit", "tau\u00b7send", "Ge\u00b7schos\u00b7sen", "be\u00b7wehrt", ",", "mit", "brau\u00b7sen\u00b7der", "Hee\u00b7res\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "CARD", "NN", "VVPP", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+--+-+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Zum silbernen Adler den goldnen gespannt an den Siegeswagen,", "tokens": ["Zum", "sil\u00b7ber\u00b7nen", "Ad\u00b7ler", "den", "gold\u00b7nen", "ge\u00b7spannt", "an", "den", "Sie\u00b7ges\u00b7wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "ART", "ADJA", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+--+--+-+-", "measure": "amphibrach.penta.plus"}, "line.6": {"text": "Vom lybischen Sand dahinflog bis wo die Alpen ragen \u2013", "tokens": ["Vom", "ly\u00b7bi\u00b7schen", "Sand", "da\u00b7hin\u00b7flog", "bis", "wo", "die", "Al\u00b7pen", "ra\u00b7gen", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "APPR", "PWAV", "ART", "NN", "VVFIN", "$("], "meter": "-+--+-+--+-++-+", "measure": "iambic.septa.relaxed"}, "line.7": {"text": "Blitz schleudernd um Blitz: so sahen die Pyramiden ihn,", "tokens": ["Blitz", "schleu\u00b7dernd", "um", "Blitz", ":", "so", "sa\u00b7hen", "die", "Py\u00b7ra\u00b7mi\u00b7den", "ihn", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "APPR", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "PPER", "$,"], "meter": "++--+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.8": {"text": "Marengo, Austerlitz, Ulm; Sieg und Erob'rung zieh'n", "tokens": ["Ma\u00b7ren\u00b7go", ",", "Aus\u00b7ter\u00b7litz", ",", "Ulm", ";", "Sieg", "und", "Er\u00b7ob'\u00b7rung", "zieh'n"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "NN", "$,", "NE", "$.", "NN", "KON", "NN", "VVFIN"], "meter": "+--+---+--+-+", "measure": "dactylic.di.plus"}, "line.9": {"text": "Mit allen den Heldennamen, die durch die Welt er trug,", "tokens": ["Mit", "al\u00b7len", "den", "Hel\u00b7den\u00b7na\u00b7men", ",", "die", "durch", "die", "Welt", "er", "trug", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Vom Nil gen Norden hin \u2013 bis an des Niemens Strand", "tokens": ["Vom", "Nil", "gen", "Nor\u00b7den", "hin", "\u2013", "bis", "an", "des", "Nie\u00b7mens", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "APPR", "NN", "PTKVZ", "$(", "KON", "APPR", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Gleich einer ehernen Mauer, ihn Moskau's Heerschaar bannt,", "tokens": ["Gleich", "ei\u00b7ner", "e\u00b7her\u00b7nen", "Mau\u00b7er", ",", "ihn", "Mos\u00b7kau's", "Heer\u00b7schaar", "bannt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PPER", "NE", "NN", "ADJD", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Die da von Lithauens Grenzen abwehrt stark und fest", "tokens": ["Die", "da", "von", "Lit\u00b7hau\u00b7ens", "Gren\u00b7zen", "ab\u00b7wehrt", "stark", "und", "fest"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADV", "APPR", "NE", "NN", "VVFIN", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.13": {"text": "Die Botschaft, die f\u00fcr Ru\u00dfland schrecklich, wie die Pest.", "tokens": ["Die", "Bot\u00b7schaft", ",", "die", "f\u00fcr", "Ru\u00df\u00b7land", "schreck\u00b7lich", ",", "wie", "die", "Pest", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "APPR", "NE", "ADJD", "$,", "PWAV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.93": {"line.1": {"text": "Und doch: wie ein Stein vom Himmel, kam Kunde dann und wann", "tokens": ["Und", "doch", ":", "wie", "ein", "Stein", "vom", "Him\u00b7mel", ",", "kam", "Kun\u00b7de", "dann", "und", "wann"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "$.", "PWAV", "ART", "NN", "APPRART", "NN", "$,", "VVFIN", "NN", "ADV", "KON", "PWAV"], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Nach Lithauen. Manchmal bettelt um Brod ein alter Mann,", "tokens": ["Nach", "Lit\u00b7hau\u00b7en", ".", "Manch\u00b7mal", "bet\u00b7telt", "um", "Brod", "ein", "al\u00b7ter", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$.", "ADV", "VVFIN", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+--+-+-+", "measure": "trochaic.septa.relaxed"}, "line.3": {"text": "Ohne Fu\u00df oder Hand \u2013 der, wenn ihm die Gabe gespendet,", "tokens": ["Oh\u00b7ne", "Fu\u00df", "o\u00b7der", "Hand", "\u2013", "der", ",", "wenn", "ihm", "die", "Ga\u00b7be", "ge\u00b7spen\u00b7det", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$(", "ART", "$,", "KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "+-+--+-+--+--+-", "measure": "hexameter"}, "line.4": {"text": "Steh'n bleibt, und scheu die Blicke nach allen Seiten wendet.", "tokens": ["Steh'n", "bleibt", ",", "und", "scheu", "die", "Bli\u00b7cke", "nach", "al\u00b7len", "Sei\u00b7ten", "wen\u00b7det", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "KON", "ADJD", "ART", "NN", "APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Und sieht er, da\u00df der Kreis von russischen S\u00f6ldnern frei,", "tokens": ["Und", "sieht", "er", ",", "da\u00df", "der", "Kreis", "von", "rus\u00b7si\u00b7schen", "S\u00f6ld\u00b7nern", "frei", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "ART", "NN", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Von K\u00e4ppchen und rothen Kragen: dann sagt er, wer er sei:", "tokens": ["Von", "K\u00e4pp\u00b7chen", "und", "ro\u00b7then", "Kra\u00b7gen", ":", "dann", "sagt", "er", ",", "wer", "er", "sei", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "ADJA", "NN", "$.", "ADV", "VVFIN", "PPER", "$,", "PWS", "PPER", "VAFIN", "$."], "meter": "-+--+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Er ist ein Legionist. Zur Heimat, die er nicht mehr", "tokens": ["Er", "ist", "ein", "Le\u00b7gi\u00b7o\u00b7nist", ".", "Zur", "Hei\u00b7mat", ",", "die", "er", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ART", "NN", "$.", "APPRART", "NN", "$,", "PRELS", "PPER", "PTKNEG", "ADV"], "meter": "-+-+--+-+-+--+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Vertheidigen kann, bringt er die alten Knochen her.", "tokens": ["Ver\u00b7thei\u00b7di\u00b7gen", "kann", ",", "bringt", "er", "die", "al\u00b7ten", "Kno\u00b7chen", "her", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "O wie ihn dann die Herrschaft, wie ihn das ganze Gesind'", "tokens": ["O", "wie", "ihn", "dann", "die", "Herr\u00b7schaft", ",", "wie", "ihn", "das", "gan\u00b7ze", "Ge\u00b7sind'"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "PWAV", "PPER", "ADV", "ART", "NN", "$,", "PWAV", "PPER", "ART", "ADJA", "NN"], "meter": "+-+--+--+-+--+", "measure": "trochaic.hexa.relaxed"}, "line.10": {"text": "Hei\u00df in die Arme schlie\u00dft und laut zu schluchzen beginnt!", "tokens": ["Hei\u00df", "in", "die", "Ar\u00b7me", "schlie\u00dft", "und", "laut", "zu", "schluch\u00b7zen", "be\u00b7ginnt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "VVFIN", "KON", "ADJD", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.11": {"text": "Dann setzt er sich an den Tisch, und seltsame Geschichten,", "tokens": ["Dann", "setzt", "er", "sich", "an", "den", "Tisch", ",", "und", "selt\u00b7sa\u00b7me", "Ge\u00b7schich\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "APPR", "ART", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.12": {"text": "Erstaunlicher, als M\u00e4rchen, wei\u00df er zu berichten:", "tokens": ["Er\u00b7staun\u00b7li\u00b7cher", ",", "als", "M\u00e4r\u00b7chen", ",", "wei\u00df", "er", "zu", "be\u00b7rich\u00b7ten", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "$,", "KOUS", "NN", "$,", "VVFIN", "PPER", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wie General Dombrowski", "tokens": ["Wie", "Ge\u00b7ne\u00b7ral", "Dom\u00b7brow\u00b7ski"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "NN", "NN"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.14": {"text": "Nach Polen vorzudringen, wie er fern im S\u00fcd", "tokens": ["Nach", "Po\u00b7len", "vor\u00b7zu\u00b7drin\u00b7gen", ",", "wie", "er", "fern", "im", "S\u00fcd"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "NE", "VVPP", "$,", "PWAV", "PPER", "ADJD", "APPRART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Um sich die Br\u00fcder sammelt, auf dem lombardischen Feld, \u2013", "tokens": ["Um", "sich", "die", "Br\u00fc\u00b7der", "sam\u00b7melt", ",", "auf", "dem", "lom\u00b7bar\u00b7di\u00b7schen", "Feld", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUI", "PRF", "ART", "NN", "VVFIN", "$,", "APPR", "ART", "ADJA", "NN", "$,", "$("], "meter": "-+-+-+-+-+-+-+", "measure": "iambic.septa"}, "line.16": {"text": "Wie vom Kapitol Kniaziewicz befiehlt, der m\u00e4cht'ge Held,", "tokens": ["Wie", "vom", "Ka\u00b7pi\u00b7tol", "Knia\u00b7zie\u00b7wicz", "be\u00b7fiehlt", ",", "der", "m\u00e4cht'\u00b7ge", "Held", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "APPRART", "NN", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "$,"], "meter": "--+--+-+-+-+-+", "measure": "anapaest.di.plus"}, "line.17": {"text": "Und hundert blutige Fahnen", "tokens": ["Und", "hun\u00b7dert", "blu\u00b7ti\u00b7ge", "Fah\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "CARD", "ADJA", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.18": {"text": "Hinwarf, entwunden alle den S\u00f6hnen der C\u00e4saren, \u2013", "tokens": ["Hin\u00b7warf", ",", "ent\u00b7wun\u00b7den", "al\u00b7le", "den", "S\u00f6h\u00b7nen", "der", "C\u00e4\u00b7sa\u00b7ren", ",", "\u2013"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$,", "VVFIN", "PIS", "ART", "NN", "ART", "NN", "$,", "$("], "meter": "+--+-+--+-+-+-", "measure": "iambic.hexa.invert"}, "line.19": {"text": "Wie Jablonowski gar dahin sich aufgemacht,", "tokens": ["Wie", "Ja\u00b7blo\u00b7nows\u00b7ki", "gar", "da\u00b7hin", "sich", "auf\u00b7ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "ADV", "PAV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Wo man den Zucker ausschmilzt,", "tokens": ["Wo", "man", "den", "Zu\u00b7cker", "aus\u00b7schmilzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PIS", "ART", "NN", "VVPP", "$,"], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.21": {"text": "Die w\u00fcrzigen W\u00e4lder bl\u00fch'n \u2013 die Mohren schl\u00e4gt er dort", "tokens": ["Die", "w\u00fcr\u00b7zi\u00b7gen", "W\u00e4l\u00b7der", "bl\u00fch'n", "\u2013", "die", "Moh\u00b7ren", "schl\u00e4gt", "er", "dort"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$(", "ART", "NN", "VVFIN", "PPER", "ADV"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.22": {"text": "Mit der Donaulegion \u2013 und m\u00f6cht' nach Polen fort.", "tokens": ["Mit", "der", "Do\u00b7nau\u00b7le\u00b7gi\u00b7on", "\u2013", "und", "m\u00f6cht'", "nach", "Po\u00b7len", "fort", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$(", "KON", "VMFIN", "APPR", "NE", "PTKVZ", "$."], "meter": "+--+--+-+-+-+", "measure": "dactylic.di.plus"}, "line.23": {"text": "Die Reden des Alten kreisen dann im Dorf geheim,", "tokens": ["Die", "Re\u00b7den", "des", "Al\u00b7ten", "krei\u00b7sen", "dann", "im", "Dorf", "ge\u00b7heim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VVFIN", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.24": {"text": "Der Bursch, der sie vernommen, ist pl\u00f6tzlich nicht daheim \u2013", "tokens": ["Der", "Bursch", ",", "der", "sie", "ver\u00b7nom\u00b7men", ",", "ist", "pl\u00f6tz\u00b7lich", "nicht", "da\u00b7heim", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVPP", "$,", "VAFIN", "ADJD", "PTKNEG", "ADV", "$("], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Durch W\u00e4lder und Mor\u00e4ste stiehlt er sich unverzagt,", "tokens": ["Durch", "W\u00e4l\u00b7der", "und", "Mo\u00b7r\u00e4s\u00b7te", "stiehlt", "er", "sich", "un\u00b7ver\u00b7zagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "VVFIN", "PPER", "PRF", "ADJD", "$,"], "meter": "-+-+-+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.26": {"text": "Der Niemen rettet ihn, wenn ihn der Russe jagt,", "tokens": ["Der", "Nie\u00b7men", "ret\u00b7tet", "ihn", ",", "wenn", "ihn", "der", "Rus\u00b7se", "jagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "KOUS", "PPER", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Bis er unter den Wellen an's Herzogthum Warschau geschwommen,", "tokens": ["Bis", "er", "un\u00b7ter", "den", "Wel\u00b7len", "an's", "Her\u00b7zog\u00b7thum", "Warsc\u00b7hau", "ge\u00b7schwom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "ART", "NN", "APPRART", "NN", "NN", "VVPP", "$,"], "meter": "+-+--+--+--++-+-", "measure": "trochaic.septa.relaxed"}, "line.28": {"text": "Wo liebe Stimmen ihn gr\u00fc\u00dfen: \u00bbKamerad, sei willkommen!\u00ab", "tokens": ["Wo", "lie\u00b7be", "Stim\u00b7men", "ihn", "gr\u00fc\u00b7\u00dfen", ":", "\u00bb", "Ka\u00b7me\u00b7rad", ",", "sei", "will\u00b7kom\u00b7men", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct"], "pos": ["PWAV", "VVFIN", "NN", "PPER", "VVINF", "$.", "$(", "NN", "$,", "VAFIN", "ADJD", "$.", "$("], "meter": "-+-+--+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.29": {"text": "Dann springt er auf einen H\u00fcgel vor dem Weitergehen,", "tokens": ["Dann", "springt", "er", "auf", "ei\u00b7nen", "H\u00fc\u00b7gel", "vor", "dem", "Wei\u00b7ter\u00b7ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.30": {"text": "Und \u00fcber den Niemen ruft er den Russen: \u00bbAuf Wiedersehen!\u00ab", "tokens": ["Und", "\u00fc\u00b7ber", "den", "Nie\u00b7men", "ruft", "er", "den", "Rus\u00b7sen", ":", "\u00bb", "Auf", "Wie\u00b7der\u00b7se\u00b7hen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VVFIN", "PPER", "ART", "NN", "$.", "$(", "APPR", "NN", "$.", "$("], "meter": "-+--+-+--+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.31": {"text": "Piotrowski, Obolewski, Rozycki, Janowicz,", "tokens": ["Pio\u00b7trows\u00b7ki", ",", "O\u00b7bo\u00b7lews\u00b7ki", ",", "Ro\u00b7zy\u00b7cki", ",", "Ja\u00b7no\u00b7wicz", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["NE", "$,", "NE", "$,", "NE", "$,", "NE", "$,"], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.32": {"text": "Brochocki, die Mierzejewski's und die Bernatowicz,", "tokens": ["Broc\u00b7ho\u00b7cki", ",", "die", "Mier\u00b7ze\u00b7jew\u00b7ski's", "und", "die", "Ber\u00b7na\u00b7to\u00b7wicz", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ART", "NN", "KON", "ART", "NN", "$,"], "meter": "-+--+--+--++-+", "measure": "amphibrach.tri.plus"}, "line.33": {"text": "Kupsc, Gedymin und Andre \u2013 wer z\u00e4hlte alle die Schaaren,", "tokens": ["Kupsc", ",", "Ge\u00b7dy\u00b7min", "und", "And\u00b7re", "\u2013", "wer", "z\u00e4hl\u00b7te", "al\u00b7le", "die", "Schaa\u00b7ren", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "KON", "PIS", "$(", "PWS", "VVFIN", "PIS", "ART", "NN", "$,"], "meter": "+-+--+--+-+--+-", "measure": "hexameter"}, "line.34": {"text": "Sie lie\u00dfen das Land und die Lieben, sie lie\u00dfen Alles fahren, \u2013", "tokens": ["Sie", "lie\u00b7\u00dfen", "das", "Land", "und", "die", "Lie\u00b7ben", ",", "sie", "lie\u00b7\u00dfen", "Al\u00b7les", "fah\u00b7ren", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ART", "ADJA", "$,", "PPER", "VVFIN", "PIS", "VVINF", "$,", "$("], "meter": "-+--+--+--+-+-+-", "measure": "amphibrach.tetra.plus"}, "line.35": {"text": "Und ihre G\u00fcter nahm der lange Arm des Czaren.", "tokens": ["Und", "ih\u00b7re", "G\u00fc\u00b7ter", "nahm", "der", "lan\u00b7ge", "Arm", "des", "Cza\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "ART", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.94": {"line.1": {"text": "Zu Zeiten kam auch ein fremder Almosenier in's Land,", "tokens": ["Zu", "Zei\u00b7ten", "kam", "auch", "ein", "frem\u00b7der", "Al\u00b7mo\u00b7se\u00b7nier", "in's", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "ADV", "ART", "ADJA", "NN", "APPRART", "NN", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Und wenn er mit den Schlo\u00dfherrn n\u00e4her ward bekannt,", "tokens": ["Und", "wenn", "er", "mit", "den", "Schlo\u00df\u00b7herrn", "n\u00e4\u00b7her", "ward", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "APPR", "ART", "NN", "ADJD", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "So trennt' er eine Zeitung aus dem Skapulier.", "tokens": ["So", "trennt'", "er", "ei\u00b7ne", "Zei\u00b7tung", "aus", "dem", "Ska\u00b7pu\u00b7lier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Die Anzahl der Soldaten war verzeichnet hier,", "tokens": ["Die", "An\u00b7zahl", "der", "Sol\u00b7da\u00b7ten", "war", "ver\u00b7zeich\u00b7net", "hier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAFIN", "VVPP", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Legionenf\u00fchrer alle genannt \u2013 von allen", "tokens": ["Die", "Le\u00b7gi\u00b7o\u00b7nen\u00b7f\u00fch\u00b7rer", "al\u00b7le", "ge\u00b7nannt", "\u2013", "von", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ART", "NN", "PIS", "VVPP", "$(", "APPR", "PIAT"], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.6": {"text": "Erz\u00e4hlt, wie sie gesiegt oder im Kampf gefallen.", "tokens": ["Er\u00b7z\u00e4hlt", ",", "wie", "sie", "ge\u00b7siegt", "o\u00b7der", "im", "Kampf", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "PPER", "VVPP", "KON", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So mochte die Familie zum ersten Mal seit Jahren", "tokens": ["So", "moch\u00b7te", "die", "Fa\u00b7mi\u00b7lie", "zum", "ers\u00b7ten", "Mal", "seit", "Jah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPRART", "ADJA", "NN", "APPR", "NN"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Vom Leben, Ruhm und Tod des theuren Sohns erfahren;", "tokens": ["Vom", "Le\u00b7ben", ",", "Ruhm", "und", "Tod", "des", "theu\u00b7ren", "Sohns", "er\u00b7fah\u00b7ren", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Man legte Trauer an. Doch scheu verschwieg der Mund,", "tokens": ["Man", "leg\u00b7te", "Trau\u00b7er", "an", ".", "Doch", "scheu", "ver\u00b7schwieg", "der", "Mund", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "NN", "PTKVZ", "$.", "KON", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Um wen; in der Umgebung errieth man nur den Grund.", "tokens": ["Um", "wen", ";", "in", "der", "Um\u00b7ge\u00b7bung", "er\u00b7rieth", "man", "nur", "den", "Grund", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "VVIZU", "$.", "APPR", "ART", "NN", "VVFIN", "PIS", "ADV", "ART", "NN", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Der Herrschaft stille Freude oder stiller Gram,", "tokens": ["Der", "Herr\u00b7schaft", "stil\u00b7le", "Freu\u00b7de", "o\u00b7der", "stil\u00b7ler", "Gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Das war die einzige Zeitung, die ihr zu Augen kam.", "tokens": ["Das", "war", "die", "ein\u00b7zi\u00b7ge", "Zei\u00b7tung", ",", "die", "ihr", "zu", "Au\u00b7gen", "kam", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.95": {"line.1": {"text": "Ein solcher geheimer Bote mocht' auch Robak sein:", "tokens": ["Ein", "sol\u00b7cher", "ge\u00b7hei\u00b7mer", "Bo\u00b7te", "mocht'", "auch", "Ro\u00b7bak", "sein", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "VVFIN", "ADV", "NN", "VAINF", "$."], "meter": "-+--+-+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.2": {"text": "Mit dem Richter besprach er sich oftmals ganz allein;", "tokens": ["Mit", "dem", "Rich\u00b7ter", "be\u00b7sprach", "er", "sich", "oft\u00b7mals", "ganz", "al\u00b7lein", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PRF", "ADV", "ADV", "ADV", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.3": {"text": "Nach einem solchen Gespr\u00e4ch war in der Nachbarschaft", "tokens": ["Nach", "ei\u00b7nem", "sol\u00b7chen", "Ge\u00b7spr\u00e4ch", "war", "in", "der", "Nach\u00b7bar\u00b7schaft"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "PIAT", "NN", "VAFIN", "APPR", "ART", "NN"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Stets etwas Neues verbreitet. Auch die Gestalt voll Kraft", "tokens": ["Stets", "et\u00b7was", "Neu\u00b7es", "ver\u00b7brei\u00b7tet", ".", "Auch", "die", "Ge\u00b7stalt", "voll", "Kraft"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PIAT", "NN", "VVPP", "$.", "ADV", "ART", "NN", "ADJD", "NN"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.5": {"text": "Zeigt, da\u00df der M\u00f6nch nicht immer die Kapuze getragen,", "tokens": ["Zeigt", ",", "da\u00df", "der", "M\u00f6nch", "nicht", "im\u00b7mer", "die", "Ka\u00b7pu\u00b7ze", "ge\u00b7tra\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "ART", "NN", "PTKNEG", "ADV", "ART", "NN", "VVPP", "$,"], "meter": "+--+-+-+-+--+-", "measure": "hexameter"}, "line.6": {"text": "Und schwerlich sich von jeher im Kloster mocht' behagen.", "tokens": ["Und", "schwer\u00b7lich", "sich", "von", "je\u00b7her", "im", "Klos\u00b7ter", "mocht'", "be\u00b7ha\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PRF", "APPR", "ADV", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Ein wenig ober der Schl\u00e4fe, \u00fcber dem rechten Ohr,", "tokens": ["Ein", "we\u00b7nig", "o\u00b7ber", "der", "Schl\u00e4\u00b7fe", ",", "\u00fc\u00b7ber", "dem", "rech\u00b7ten", "Ohr", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ART", "NN", "$,", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+--+-+", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Tritt handbreit eine L\u00fccke in der Haut hervor,", "tokens": ["Tritt", "hand\u00b7breit", "ei\u00b7ne", "L\u00fc\u00b7cke", "in", "der", "Haut", "her\u00b7vor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NN", "ART", "NN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Von einem Schu\u00df oder Stich ist eine Spur zu seh'n", "tokens": ["Von", "ei\u00b7nem", "Schu\u00df", "o\u00b7der", "Stich", "ist", "ei\u00b7ne", "Spur", "zu", "seh'n"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "KON", "NN", "VAFIN", "ART", "NN", "PTKZU", "VVINF"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Am Kinn, \u2013 das ist ihm sicher nicht bei der Messe gescheh'n.", "tokens": ["Am", "Kinn", ",", "\u2013", "das", "ist", "ihm", "si\u00b7cher", "nicht", "bei", "der", "Mes\u00b7se", "ge\u00b7scheh'", "n."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "abbreviation"], "pos": ["APPRART", "NN", "$,", "$(", "PDS", "VAFIN", "PPER", "ADJD", "PTKNEG", "APPR", "ART", "NN", "VVFIN", "NE"], "meter": "-+-+-+-++-+--+", "measure": "iambic.septa.chol"}, "line.11": {"text": "Doch nicht blos in den Narben und in des Blickes Droh'n:", "tokens": ["Doch", "nicht", "blos", "in", "den", "Nar\u00b7ben", "und", "in", "des", "Bli\u00b7ckes", "Droh'n", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "NN", "$."], "meter": "--+--+--+-+-+", "measure": "anapaest.tri.plus"}, "line.12": {"text": "Er hatte was vom Kriegsmann in Gang und Stimme schon.", "tokens": ["Er", "hat\u00b7te", "was", "vom", "Kriegs\u00b7mann", "in", "Gang", "und", "Stim\u00b7me", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "APPRART", "NN", "APPR", "NN", "KON", "NN", "ADV", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}}, "stanza.96": {"line.1": {"text": "Wenn er sich vom Altar mit aufgehob'nen H\u00e4nden", "tokens": ["Wenn", "er", "sich", "vom", "Al\u00b7tar", "mit", "auf\u00b7ge\u00b7hob'\u00b7nen", "H\u00e4n\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "APPRART", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Beim \u00bbDominus Vobiscum!\u00ab sollt' zum Volke wenden,", "tokens": ["Beim", "\u00bb", "Do\u00b7mi\u00b7nus", "Vo\u00b7bis\u00b7cum", "!", "\u00ab", "sollt'", "zum", "Vol\u00b7ke", "wen\u00b7den", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "$(", "FM.la", "FM.la", "$.", "$(", "VMFIN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Da konnt' er sich so flink umdreh'n mit einem Mal,", "tokens": ["Da", "konnt'", "er", "sich", "so", "flink", "um\u00b7dreh'n", "mit", "ei\u00b7nem", "Mal", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADV", "ADJD", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als w\u00e4r' ihm commandirt: \u00bbRechtsum!\u00ab vom General.", "tokens": ["Als", "w\u00e4r'", "ihm", "com\u00b7man\u00b7dirt", ":", "\u00bb", "Recht\u00b7sum", "!", "\u00ab", "vom", "Ge\u00b7ne\u00b7ral", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KOUS", "VAFIN", "PPER", "VVPP", "$.", "$(", "ADV", "$.", "$(", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Als redete ein Hauptmann vor der Escadron.", "tokens": ["Als", "re\u00b7de\u00b7te", "ein", "Haupt\u00b7mann", "vor", "der", "E\u00b7sca\u00b7dron", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Die Me\u00dfnerbuben bemerkten das mit klugem Blick. \u2013", "tokens": ["Die", "Me\u00df\u00b7ner\u00b7bu\u00b7ben", "be\u00b7merk\u00b7ten", "das", "mit", "klu\u00b7gem", "Blick", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "APPR", "ADJA", "NN", "$.", "$("], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Auch war er viel vertrauter mit der Politik,", "tokens": ["Auch", "war", "er", "viel", "ver\u00b7trau\u00b7ter", "mit", "der", "Po\u00b7li\u00b7tik", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Als mit den Heil'gen. Fuhr er nach Almosen herum,", "tokens": ["Als", "mit", "den", "Heil'\u00b7gen", ".", "Fuhr", "er", "nach", "Al\u00b7mo\u00b7sen", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$.", "VVFIN", "PPER", "APPR", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.9": {"text": "So that er sich gar h\u00e4ufig in der Kreisstadt um.", "tokens": ["So", "that", "er", "sich", "gar", "h\u00e4u\u00b7fig", "in", "der", "Kreis\u00b7stadt", "um", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "PRF", "ADV", "ADJD", "APPR", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Er steckte voller Gesch\u00e4fte; bald kommen Briefe an,", "tokens": ["Er", "steck\u00b7te", "vol\u00b7ler", "Ge\u00b7sch\u00e4f\u00b7te", ";", "bald", "kom\u00b7men", "Brie\u00b7fe", "an", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$.", "ADV", "VVINF", "NN", "PTKVZ", "$,"], "meter": "-+-+--+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.11": {"text": "Die er vor fremden Zeugen nicht er\u00f6ffnen kann,", "tokens": ["Die", "er", "vor", "frem\u00b7den", "Zeu\u00b7gen", "nicht", "er\u00b7\u00f6ff\u00b7nen", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "PTKNEG", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Bald schickt er Boten aus, doch sagt er nie ein Wort,", "tokens": ["Bald", "schickt", "er", "Bo\u00b7ten", "aus", ",", "doch", "sagt", "er", "nie", "ein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "PTKVZ", "$,", "ADV", "VVFIN", "PPER", "ADV", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Wohin und wozu; oft schl\u00fcpft er in die Schl\u00f6sser fort", "tokens": ["Wo\u00b7hin", "und", "wo\u00b7zu", ";", "oft", "schl\u00fcpft", "er", "in", "die", "Schl\u00f6s\u00b7ser", "fort"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "KON", "PWAV", "$.", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PTKVZ"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Bei Nacht \u2013 hat mit der Schlachta zu fl\u00fcstern allezeit,", "tokens": ["Bei", "Nacht", "\u2013", "hat", "mit", "der", "Schlach\u00b7ta", "zu", "fl\u00fcs\u00b7tern", "al\u00b7le\u00b7zeit", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$(", "VAFIN", "APPR", "ART", "NN", "PTKZU", "VVINF", "ADV", "$,"], "meter": "-+-+--+-+-+-+", "measure": "iambic.hexa.relaxed"}, "line.15": {"text": "Die D\u00f6rfer in der N\u00e4he durchstreift er weit und breit;", "tokens": ["Die", "D\u00f6r\u00b7fer", "in", "der", "N\u00e4\u00b7he", "durch\u00b7streift", "er", "weit", "und", "breit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "VVFIN", "PPER", "ADJD", "KON", "ADJD", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.16": {"text": "Verhandelt mit den Bauern \u00f6fters in den Schenken", "tokens": ["Ver\u00b7han\u00b7delt", "mit", "den", "Bau\u00b7ern", "\u00f6f\u00b7ters", "in", "den", "Schen\u00b7ken"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "ART", "NN", "ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Und mag die Rede immer nur auf's Ausland lenken.", "tokens": ["Und", "mag", "die", "Re\u00b7de", "im\u00b7mer", "nur", "auf's", "Aus\u00b7land", "len\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Jetzt will er den Richter wecken, der schon seit einer Stunde", "tokens": ["Jetzt", "will", "er", "den", "Rich\u00b7ter", "we\u00b7cken", ",", "der", "schon", "seit", "ei\u00b7ner", "Stun\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VVINF", "$,", "PRELS", "ADV", "APPR", "ART", "NN"], "meter": "-+--+-+--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.19": {"text": "Im Schlafe liegt; gewi\u00df kommt er mit neuer Kunde.", "tokens": ["Im", "Schla\u00b7fe", "liegt", ";", "ge\u00b7wi\u00df", "kommt", "er", "mit", "neu\u00b7er", "Kun\u00b7de", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVFIN", "$.", "ADV", "VVFIN", "PPER", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}