{"textgrid.poem.44106": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Was ist das beste Buch? Des Heilands Lehr und Leben.", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Was ist das beste Buch? Des Heilands Lehr und Leben.", "tokens": ["Was", "ist", "das", "bes\u00b7te", "Buch", "?", "Des", "Hei\u00b7lands", "Lehr", "und", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was macht denn einen Christ? Der Trieb, ihm nachzustreben.", "tokens": ["Was", "macht", "denn", "ei\u00b7nen", "Christ", "?", "Der", "Trieb", ",", "ihm", "nach\u00b7zu\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "$.", "ART", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer hat die Seeligkeit? Wer Gott recht ehrt und liebt.", "tokens": ["Wer", "hat", "die", "See\u00b7lig\u00b7keit", "?", "Wer", "Gott", "recht", "ehrt", "und", "liebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "PWS", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ehrt und liebt ihn recht? Der, so sich eifrig \u00fcbt,", "tokens": ["Wer", "ehrt", "und", "liebt", "ihn", "recht", "?", "Der", ",", "so", "sich", "eif\u00b7rig", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "$.", "ART", "$,", "ADV", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihn aus Vernunft und Licht und aus der Welt zu kennen.", "tokens": ["Ihn", "aus", "Ver\u00b7nunft", "und", "Licht", "und", "aus", "der", "Welt", "zu", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer aber ist denn wohl ein weiser Mann zu nennen?", "tokens": ["Wer", "a\u00b7ber", "ist", "denn", "wohl", "ein", "wei\u00b7ser", "Mann", "zu", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer nichts bewundern darf, nicht alles eitel macht,", "tokens": ["Wer", "nichts", "be\u00b7wun\u00b7dern", "darf", ",", "nicht", "al\u00b7les", "ei\u00b7tel", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVINF", "VMFIN", "$,", "PTKNEG", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf kein Verh\u00e4ngn\u00fc\u00df flucht und weder weint noch lacht.", "tokens": ["Auf", "kein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "flucht", "und", "we\u00b7der", "weint", "noch", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "KON", "KON", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo liegt das h\u00f6chste Gut? Im ruhigen Gewi\u00dfen.", "tokens": ["Wo", "liegt", "das", "h\u00f6chs\u00b7te", "Gut", "?", "Im", "ru\u00b7hi\u00b7gen", "Ge\u00b7wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$.", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wer ist auf unsren Fall am eifrigsten befli\u00dfen?", "tokens": ["Wer", "ist", "auf", "un\u00b7sren", "Fall", "am", "eif\u00b7rigs\u00b7ten", "be\u00b7fli\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPOSAT", "NN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Der Mensch. Wer heist denn reich? Der, welcher nichts begehrt.", "tokens": ["Der", "Mensch", ".", "Wer", "heist", "denn", "reich", "?", "Der", ",", "wel\u00b7cher", "nichts", "be\u00b7gehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWS", "VAFIN", "ADV", "ADJD", "$.", "ART", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wer arm? Der d\u00fcrre Geiz, der von sich selber zehrt.", "tokens": ["Wer", "arm", "?", "Der", "d\u00fcr\u00b7re", "Geiz", ",", "der", "von", "sich", "sel\u00b7ber", "zehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$.", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was kan wohl unsrer Eh die reichste Mitgift geben?", "tokens": ["Was", "kan", "wohl", "uns\u00b7rer", "Eh", "die", "reichs\u00b7te", "Mit\u00b7gift", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Kind von Ehrligkeit und unschuldsvollem Leben.", "tokens": ["Ein", "Kind", "von", "Ehr\u00b7lig\u00b7keit", "und", "un\u00b7schulds\u00b7vol\u00b7lem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Welch M\u00e4gdgen ist denn keusch? Von der sogar der Neid", "tokens": ["Welch", "M\u00e4gd\u00b7gen", "ist", "denn", "keusch", "?", "Von", "der", "so\u00b7gar", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$.", "APPR", "ART", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So still als \u00f6fentlich sich was zu l\u00fcgen scheut.", "tokens": ["So", "still", "als", "\u00f6\u00b7fent\u00b7lich", "sich", "was", "zu", "l\u00fc\u00b7gen", "scheut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "PRF", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was heist nun wohl gelehrt? Das, was man sagt, beweisen.", "tokens": ["Was", "heist", "nun", "wohl", "ge\u00b7lehrt", "?", "Das", ",", "was", "man", "sagt", ",", "be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "VVPP", "$.", "PDS", "$,", "PRELS", "PIS", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie wird ein Mensch ein Mensch? Durch Einsicht und durch Reisen.", "tokens": ["Wie", "wird", "ein", "Mensch", "ein", "Mensch", "?", "Durch", "Ein\u00b7sicht", "und", "durch", "Rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ART", "NN", "$.", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wo m\u00f6gen Heerden seyn, in die kein Miedling lauft?", "tokens": ["Wo", "m\u00f6\u00b7gen", "Heer\u00b7den", "seyn", ",", "in", "die", "kein", "Mied\u00b7ling", "lauft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "VAINF", "$,", "APPR", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vielleicht in Schlesien, da werden sie gekauft.", "tokens": ["Viel\u00b7leicht", "in", "Schle\u00b7si\u00b7en", ",", "da", "wer\u00b7den", "sie", "ge\u00b7kauft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Was macht der Orthodox? Zanck, Kezer, Atheisten.", "tokens": ["Was", "macht", "der", "Or\u00b7tho\u00b7dox", "?", "Zanck", ",", "Ke\u00b7zer", ",", "A\u00b7theis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Wer mehrt der Heuchler Schwarm? Die tummen Pietisten.", "tokens": ["Wer", "mehrt", "der", "Heuch\u00b7ler", "Schwarm", "?", "Die", "tum\u00b7men", "Pie\u00b7tis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Was ist in unsrer Zeit das gr\u00f6ste Wunderwerck?", "tokens": ["Was", "ist", "in", "uns\u00b7rer", "Zeit", "das", "gr\u00f6s\u00b7te", "Wun\u00b7der\u00b7werck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zween \u00d6rter: erstlich Wien, hernach auch Wittenberg;", "tokens": ["Zween", "\u00d6r\u00b7ter", ":", "erst\u00b7lich", "Wi\u00b7en", ",", "her\u00b7nach", "auch", "Wit\u00b7ten\u00b7berg", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADJD", "NE", "$,", "ADV", "ADV", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Dort herrscht nunmehr Trajan zum andern Mahl auf Erden,", "tokens": ["Dort", "herrscht", "nun\u00b7mehr", "Tra\u00b7jan", "zum", "an\u00b7dern", "Mahl", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "APPRART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Hier will der Pabst nun gar zum Lutheraner werden.", "tokens": ["Hier", "will", "der", "Pabst", "nun", "gar", "zum", "Lu\u00b7the\u00b7ra\u00b7ner", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Sezt noch das dritte zu! Was? Jena. Wie? Warum?", "tokens": ["Sezt", "noch", "das", "drit\u00b7te", "zu", "!", "Was", "?", "Je\u00b7na", ".", "Wie", "?", "Wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "PTKVZ", "$.", "PWS", "$.", "NE", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Hier ist die g\u00fcldne Zeit ein eisern Seculum:", "tokens": ["Hier", "ist", "die", "g\u00fcld\u00b7ne", "Zeit", "ein", "ei\u00b7sern", "Se\u00b7cu\u00b7lum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Was ist die ganze Lust der meisten Purschentage?", "tokens": ["Was", "ist", "die", "gan\u00b7ze", "Lust", "der", "meis\u00b7ten", "Pur\u00b7schen\u00b7ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ein Wirthshaus breiter Bahn, ein Buch voll Schuld und Klage.", "tokens": ["Ein", "Wirths\u00b7haus", "brei\u00b7ter", "Bahn", ",", "ein", "Buch", "voll", "Schuld", "und", "Kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Was mag ihr Wahlspruch seyn? Als fl\u00f6gen wir davon.", "tokens": ["Was", "mag", "ihr", "Wahl\u00b7spruch", "seyn", "?", "Als", "fl\u00f6\u00b7gen", "wir", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VAINF", "$.", "KOUS", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Was bringt sie endlich ein? Viel Nachreu, wenig Lohn.", "tokens": ["Was", "bringt", "sie", "end\u00b7lich", "ein", "?", "Viel", "Nach\u00b7reu", ",", "we\u00b7nig", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wo aber ist nun auch ein wahrer Freund zu finden?", "tokens": ["Wo", "a\u00b7ber", "ist", "nun", "auch", "ein", "wah\u00b7rer", "Freund", "zu", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ja, Bruder, lehre mich die Antwort selbst ergr\u00fcnden;", "tokens": ["Ja", ",", "Bru\u00b7der", ",", "leh\u00b7re", "mich", "die", "Ant\u00b7wort", "selbst", "er\u00b7gr\u00fcn\u00b7den", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "VVFIN", "PRF", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ich habe mich darum viel Jahr umsonst bem\u00fcht,", "tokens": ["Ich", "ha\u00b7be", "mich", "da\u00b7rum", "viel", "Jahr", "um\u00b7sonst", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PAV", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Versuch, ob dir darin das Gl\u00fcck einst fr\u00fcher bl\u00fcht.", "tokens": ["Ver\u00b7such", ",", "ob", "dir", "da\u00b7rin", "das", "Gl\u00fcck", "einst", "fr\u00fc\u00b7her", "bl\u00fcht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PAV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Was ist das beste Buch? Des Heilands Lehr und Leben.", "tokens": ["Was", "ist", "das", "bes\u00b7te", "Buch", "?", "Des", "Hei\u00b7lands", "Lehr", "und", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "$.", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Was macht denn einen Christ? Der Trieb, ihm nachzustreben.", "tokens": ["Was", "macht", "denn", "ei\u00b7nen", "Christ", "?", "Der", "Trieb", ",", "ihm", "nach\u00b7zu\u00b7stre\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ART", "NN", "$.", "ART", "NN", "$,", "PPER", "VVIZU", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Wer hat die Seeligkeit? Wer Gott recht ehrt und liebt.", "tokens": ["Wer", "hat", "die", "See\u00b7lig\u00b7keit", "?", "Wer", "Gott", "recht", "ehrt", "und", "liebt", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "NN", "$.", "PWS", "NN", "ADJD", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer ehrt und liebt ihn recht? Der, so sich eifrig \u00fcbt,", "tokens": ["Wer", "ehrt", "und", "liebt", "ihn", "recht", "?", "Der", ",", "so", "sich", "eif\u00b7rig", "\u00fcbt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "KON", "VVFIN", "PPER", "ADJD", "$.", "ART", "$,", "ADV", "PRF", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Ihn aus Vernunft und Licht und aus der Welt zu kennen.", "tokens": ["Ihn", "aus", "Ver\u00b7nunft", "und", "Licht", "und", "aus", "der", "Welt", "zu", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "APPR", "NN", "KON", "NN", "KON", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wer aber ist denn wohl ein weiser Mann zu nennen?", "tokens": ["Wer", "a\u00b7ber", "ist", "denn", "wohl", "ein", "wei\u00b7ser", "Mann", "zu", "nen\u00b7nen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer nichts bewundern darf, nicht alles eitel macht,", "tokens": ["Wer", "nichts", "be\u00b7wun\u00b7dern", "darf", ",", "nicht", "al\u00b7les", "ei\u00b7tel", "macht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIS", "VVINF", "VMFIN", "$,", "PTKNEG", "PIS", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Auf kein Verh\u00e4ngn\u00fc\u00df flucht und weder weint noch lacht.", "tokens": ["Auf", "kein", "Ver\u00b7h\u00e4ng\u00b7n\u00fc\u00df", "flucht", "und", "we\u00b7der", "weint", "noch", "lacht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "KON", "KON", "VVFIN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Wo liegt das h\u00f6chste Gut? Im ruhigen Gewi\u00dfen.", "tokens": ["Wo", "liegt", "das", "h\u00f6chs\u00b7te", "Gut", "?", "Im", "ru\u00b7hi\u00b7gen", "Ge\u00b7wi\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "ADJA", "NN", "$.", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-++--+-", "measure": "iambic.hexa.relaxed"}, "line.10": {"text": "Wer ist auf unsren Fall am eifrigsten befli\u00dfen?", "tokens": ["Wer", "ist", "auf", "un\u00b7sren", "Fall", "am", "eif\u00b7rigs\u00b7ten", "be\u00b7fli\u00b7\u00dfen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPOSAT", "NN", "APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.11": {"text": "Der Mensch. Wer heist denn reich? Der, welcher nichts begehrt.", "tokens": ["Der", "Mensch", ".", "Wer", "heist", "denn", "reich", "?", "Der", ",", "wel\u00b7cher", "nichts", "be\u00b7gehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$.", "PWS", "VAFIN", "ADV", "ADJD", "$.", "ART", "$,", "PRELS", "PIS", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wer arm? Der d\u00fcrre Geiz, der von sich selber zehrt.", "tokens": ["Wer", "arm", "?", "Der", "d\u00fcr\u00b7re", "Geiz", ",", "der", "von", "sich", "sel\u00b7ber", "zehrt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADJD", "$.", "ART", "ADJA", "NN", "$,", "PRELS", "APPR", "PRF", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Was kan wohl unsrer Eh die reichste Mitgift geben?", "tokens": ["Was", "kan", "wohl", "uns\u00b7rer", "Eh", "die", "reichs\u00b7te", "Mit\u00b7gift", "ge\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "ADV", "PPOSAT", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Ein Kind von Ehrligkeit und unschuldsvollem Leben.", "tokens": ["Ein", "Kind", "von", "Ehr\u00b7lig\u00b7keit", "und", "un\u00b7schulds\u00b7vol\u00b7lem", "Le\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Welch M\u00e4gdgen ist denn keusch? Von der sogar der Neid", "tokens": ["Welch", "M\u00e4gd\u00b7gen", "ist", "denn", "keusch", "?", "Von", "der", "so\u00b7gar", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "ADJD", "$.", "APPR", "ART", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "So still als \u00f6fentlich sich was zu l\u00fcgen scheut.", "tokens": ["So", "still", "als", "\u00f6\u00b7fent\u00b7lich", "sich", "was", "zu", "l\u00fc\u00b7gen", "scheut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KOKOM", "ADJD", "PRF", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "Was heist nun wohl gelehrt? Das, was man sagt, beweisen.", "tokens": ["Was", "heist", "nun", "wohl", "ge\u00b7lehrt", "?", "Das", ",", "was", "man", "sagt", ",", "be\u00b7wei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "VVPP", "$.", "PDS", "$,", "PRELS", "PIS", "VVFIN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "Wie wird ein Mensch ein Mensch? Durch Einsicht und durch Reisen.", "tokens": ["Wie", "wird", "ein", "Mensch", "ein", "Mensch", "?", "Durch", "Ein\u00b7sicht", "und", "durch", "Rei\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "ART", "NN", "ART", "NN", "$.", "APPR", "NN", "KON", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "Wo m\u00f6gen Heerden seyn, in die kein Miedling lauft?", "tokens": ["Wo", "m\u00f6\u00b7gen", "Heer\u00b7den", "seyn", ",", "in", "die", "kein", "Mied\u00b7ling", "lauft", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "NN", "VAINF", "$,", "APPR", "ART", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Vielleicht in Schlesien, da werden sie gekauft.", "tokens": ["Viel\u00b7leicht", "in", "Schle\u00b7si\u00b7en", ",", "da", "wer\u00b7den", "sie", "ge\u00b7kauft", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "ADV", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Was macht der Orthodox? Zanck, Kezer, Atheisten.", "tokens": ["Was", "macht", "der", "Or\u00b7tho\u00b7dox", "?", "Zanck", ",", "Ke\u00b7zer", ",", "A\u00b7theis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "$.", "NN", "$,", "NN", "$,", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.22": {"text": "Wer mehrt der Heuchler Schwarm? Die tummen Pietisten.", "tokens": ["Wer", "mehrt", "der", "Heuch\u00b7ler", "Schwarm", "?", "Die", "tum\u00b7men", "Pie\u00b7tis\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "NN", "$.", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.23": {"text": "Was ist in unsrer Zeit das gr\u00f6ste Wunderwerck?", "tokens": ["Was", "ist", "in", "uns\u00b7rer", "Zeit", "das", "gr\u00f6s\u00b7te", "Wun\u00b7der\u00b7werck", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "APPR", "PPOSAT", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Zween \u00d6rter: erstlich Wien, hernach auch Wittenberg;", "tokens": ["Zween", "\u00d6r\u00b7ter", ":", "erst\u00b7lich", "Wi\u00b7en", ",", "her\u00b7nach", "auch", "Wit\u00b7ten\u00b7berg", ";"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "NN", "$.", "ADJD", "NE", "$,", "ADV", "ADV", "NE", "$."], "meter": "-+-+-+--+-+-+", "measure": "iambic.hexa.relaxed"}, "line.25": {"text": "Dort herrscht nunmehr Trajan zum andern Mahl auf Erden,", "tokens": ["Dort", "herrscht", "nun\u00b7mehr", "Tra\u00b7jan", "zum", "an\u00b7dern", "Mahl", "auf", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "NN", "APPRART", "ADJA", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.26": {"text": "Hier will der Pabst nun gar zum Lutheraner werden.", "tokens": ["Hier", "will", "der", "Pabst", "nun", "gar", "zum", "Lu\u00b7the\u00b7ra\u00b7ner", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.27": {"text": "Sezt noch das dritte zu! Was? Jena. Wie? Warum?", "tokens": ["Sezt", "noch", "das", "drit\u00b7te", "zu", "!", "Was", "?", "Je\u00b7na", ".", "Wie", "?", "Wa\u00b7rum", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "ART", "ADJA", "PTKVZ", "$.", "PWS", "$.", "NE", "$.", "PWAV", "$.", "PWAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.28": {"text": "Hier ist die g\u00fcldne Zeit ein eisern Seculum:", "tokens": ["Hier", "ist", "die", "g\u00fcld\u00b7ne", "Zeit", "ein", "ei\u00b7sern", "Se\u00b7cu\u00b7lum", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.29": {"text": "Was ist die ganze Lust der meisten Purschentage?", "tokens": ["Was", "ist", "die", "gan\u00b7ze", "Lust", "der", "meis\u00b7ten", "Pur\u00b7schen\u00b7ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "ADJA", "NN", "ART", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.30": {"text": "Ein Wirthshaus breiter Bahn, ein Buch voll Schuld und Klage.", "tokens": ["Ein", "Wirths\u00b7haus", "brei\u00b7ter", "Bahn", ",", "ein", "Buch", "voll", "Schuld", "und", "Kla\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$,", "ART", "NN", "ADJD", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.31": {"text": "Was mag ihr Wahlspruch seyn? Als fl\u00f6gen wir davon.", "tokens": ["Was", "mag", "ihr", "Wahl\u00b7spruch", "seyn", "?", "Als", "fl\u00f6\u00b7gen", "wir", "da\u00b7von", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PPOSAT", "NN", "VAINF", "$.", "KOUS", "VVFIN", "PPER", "PAV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.32": {"text": "Was bringt sie endlich ein? Viel Nachreu, wenig Lohn.", "tokens": ["Was", "bringt", "sie", "end\u00b7lich", "ein", "?", "Viel", "Nach\u00b7reu", ",", "we\u00b7nig", "Lohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "PTKVZ", "$.", "PIAT", "NN", "$,", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.33": {"text": "Wo aber ist nun auch ein wahrer Freund zu finden?", "tokens": ["Wo", "a\u00b7ber", "ist", "nun", "auch", "ein", "wah\u00b7rer", "Freund", "zu", "fin\u00b7den", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "VAFIN", "ADV", "ADV", "ART", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.34": {"text": "Ja, Bruder, lehre mich die Antwort selbst ergr\u00fcnden;", "tokens": ["Ja", ",", "Bru\u00b7der", ",", "leh\u00b7re", "mich", "die", "Ant\u00b7wort", "selbst", "er\u00b7gr\u00fcn\u00b7den", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "VVFIN", "PRF", "ART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.35": {"text": "Ich habe mich darum viel Jahr umsonst bem\u00fcht,", "tokens": ["Ich", "ha\u00b7be", "mich", "da\u00b7rum", "viel", "Jahr", "um\u00b7sonst", "be\u00b7m\u00fcht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PRF", "PAV", "PIAT", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.36": {"text": "Versuch, ob dir darin das Gl\u00fcck einst fr\u00fcher bl\u00fcht.", "tokens": ["Ver\u00b7such", ",", "ob", "dir", "da\u00b7rin", "das", "Gl\u00fcck", "einst", "fr\u00fc\u00b7her", "bl\u00fcht", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPER", "PAV", "ART", "NN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}