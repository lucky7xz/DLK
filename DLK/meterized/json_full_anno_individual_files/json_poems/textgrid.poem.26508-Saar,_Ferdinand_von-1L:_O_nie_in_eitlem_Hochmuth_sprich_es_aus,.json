{"textgrid.poem.26508": {"metadata": {"author": {"name": "Saar, Ferdinand von", "birth": "N.A.", "death": "N.A."}, "title": "1L: O nie in eitlem Hochmuth sprich es aus,", "genre": "verse", "period": "N.A.", "pub_year": 1869, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O nie in eitlem Hochmuth sprich es aus,", "tokens": ["O", "nie", "in", "eit\u00b7lem", "Hoch\u00b7muth", "sprich", "es", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df Dieser oder Jener nichts bedeute;", "tokens": ["Da\u00df", "Die\u00b7ser", "o\u00b7der", "Je\u00b7ner", "nichts", "be\u00b7deu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "KON", "PDAT", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit deinem letzten Urtheil halte Haus:", "tokens": ["Mit", "dei\u00b7nem", "letz\u00b7ten", "Ur\u00b7theil", "hal\u00b7te", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn nicht so leicht ergr\u00fcndest du die Leute.", "tokens": ["Denn", "nicht", "so", "leicht", "er\u00b7gr\u00fcn\u00b7dest", "du", "die", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "In Jedem schlummert eine sond're Kraft,", "tokens": ["In", "Je\u00b7dem", "schlum\u00b7mert", "ei\u00b7ne", "son\u00b7d'\u00b7re", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Vielleicht noch von ihm selber unbeachtet,", "tokens": ["Viel\u00b7leicht", "noch", "von", "ihm", "sel\u00b7ber", "un\u00b7be\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die pl\u00f6tzlich sich emporhebt, geisterhaft,", "tokens": ["Die", "pl\u00f6tz\u00b7lich", "sich", "em\u00b7por\u00b7hebt", ",", "geis\u00b7ter\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und nimmer duldet, da\u00df man sie verachtet.", "tokens": ["Und", "nim\u00b7mer", "dul\u00b7det", ",", "da\u00df", "man", "sie", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Und so geschieht es, da\u00df oft Weisheit spricht", "tokens": ["Und", "so", "ge\u00b7schieht", "es", ",", "da\u00df", "oft", "Weis\u00b7heit", "spricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aus Solchen, die wie Thoren stets erschienen,", "tokens": ["Aus", "Sol\u00b7chen", ",", "die", "wie", "Tho\u00b7ren", "stets", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "KOKOM", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df heil'ger Muth aus schwachen Seelen bricht \u2013", "tokens": ["Da\u00df", "heil'\u00b7ger", "Muth", "aus", "schwa\u00b7chen", "See\u00b7len", "bricht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Du aber stehst sodann besch\u00e4mt vor ihnen.", "tokens": ["Du", "a\u00b7ber", "stehst", "so\u00b7dann", "be\u00b7sch\u00e4mt", "vor", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Das hei\u00dft, wenn du nicht ganz verh\u00e4rtet bist", "tokens": ["Das", "hei\u00dft", ",", "wenn", "du", "nicht", "ganz", "ver\u00b7h\u00e4r\u00b7tet", "bist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und f\u00e4hig noch, in Reue zu entbrennen;", "tokens": ["Und", "f\u00e4\u00b7hig", "noch", ",", "in", "Reu\u00b7e", "zu", "ent\u00b7bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer vor der Wahrheit gerne sich verschlie\u00dft,", "tokens": ["Wer", "vor", "der", "Wahr\u00b7heit", "ger\u00b7ne", "sich", "ver\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wird sie zuletzt auch gar nicht mehr erkennen.", "tokens": ["Wird", "sie", "zu\u00b7letzt", "auch", "gar", "nicht", "mehr", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "O nie in eitlem Hochmuth sprich es aus,", "tokens": ["O", "nie", "in", "eit\u00b7lem", "Hoch\u00b7muth", "sprich", "es", "aus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ADV", "APPR", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Da\u00df Dieser oder Jener nichts bedeute;", "tokens": ["Da\u00df", "Die\u00b7ser", "o\u00b7der", "Je\u00b7ner", "nichts", "be\u00b7deu\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDAT", "KON", "PDAT", "PIS", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mit deinem letzten Urtheil halte Haus:", "tokens": ["Mit", "dei\u00b7nem", "letz\u00b7ten", "Ur\u00b7theil", "hal\u00b7te", "Haus", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Denn nicht so leicht ergr\u00fcndest du die Leute.", "tokens": ["Denn", "nicht", "so", "leicht", "er\u00b7gr\u00fcn\u00b7dest", "du", "die", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADV", "ADJD", "VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "In Jedem schlummert eine sond're Kraft,", "tokens": ["In", "Je\u00b7dem", "schlum\u00b7mert", "ei\u00b7ne", "son\u00b7d'\u00b7re", "Kraft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "VVFIN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+--+", "measure": "iambic.penta.chol"}, "line.2": {"text": "Vielleicht noch von ihm selber unbeachtet,", "tokens": ["Viel\u00b7leicht", "noch", "von", "ihm", "sel\u00b7ber", "un\u00b7be\u00b7ach\u00b7tet", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die pl\u00f6tzlich sich emporhebt, geisterhaft,", "tokens": ["Die", "pl\u00f6tz\u00b7lich", "sich", "em\u00b7por\u00b7hebt", ",", "geis\u00b7ter\u00b7haft", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "ADJD", "PRF", "VVFIN", "$,", "ADJD", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Und nimmer duldet, da\u00df man sie verachtet.", "tokens": ["Und", "nim\u00b7mer", "dul\u00b7det", ",", "da\u00df", "man", "sie", "ver\u00b7ach\u00b7tet", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "$,", "KOUS", "PIS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Und so geschieht es, da\u00df oft Weisheit spricht", "tokens": ["Und", "so", "ge\u00b7schieht", "es", ",", "da\u00df", "oft", "Weis\u00b7heit", "spricht"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$,", "KOUS", "ADV", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Aus Solchen, die wie Thoren stets erschienen,", "tokens": ["Aus", "Sol\u00b7chen", ",", "die", "wie", "Tho\u00b7ren", "stets", "er\u00b7schie\u00b7nen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "PRELS", "KOKOM", "NN", "ADV", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da\u00df heil'ger Muth aus schwachen Seelen bricht \u2013", "tokens": ["Da\u00df", "heil'\u00b7ger", "Muth", "aus", "schwa\u00b7chen", "See\u00b7len", "bricht", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "APPR", "ADJA", "NN", "VVFIN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Du aber stehst sodann besch\u00e4mt vor ihnen.", "tokens": ["Du", "a\u00b7ber", "stehst", "so\u00b7dann", "be\u00b7sch\u00e4mt", "vor", "ih\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "ADJD", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.8": {"line.1": {"text": "Das hei\u00dft, wenn du nicht ganz verh\u00e4rtet bist", "tokens": ["Das", "hei\u00dft", ",", "wenn", "du", "nicht", "ganz", "ver\u00b7h\u00e4r\u00b7tet", "bist"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["PDS", "VVFIN", "$,", "KOUS", "PPER", "PTKNEG", "ADV", "VVPP", "VAFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und f\u00e4hig noch, in Reue zu entbrennen;", "tokens": ["Und", "f\u00e4\u00b7hig", "noch", ",", "in", "Reu\u00b7e", "zu", "ent\u00b7bren\u00b7nen", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADV", "$,", "APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wer vor der Wahrheit gerne sich verschlie\u00dft,", "tokens": ["Wer", "vor", "der", "Wahr\u00b7heit", "ger\u00b7ne", "sich", "ver\u00b7schlie\u00dft", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "ART", "NN", "ADV", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "Wird sie zuletzt auch gar nicht mehr erkennen.", "tokens": ["Wird", "sie", "zu\u00b7letzt", "auch", "gar", "nicht", "mehr", "er\u00b7ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ADV", "ADV", "PTKNEG", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}}}}