{"textgrid.poem.56803": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: Vor dem Abendhimmel gehen", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Vor dem Abendhimmel gehen", "tokens": ["Vor", "dem", "A\u00b7bend\u00b7him\u00b7mel", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "l\u00e4ngs der Felsen sch\u00e4rfsten Kanten", "tokens": ["l\u00e4ngs", "der", "Fel\u00b7sen", "sch\u00e4rfs\u00b7ten", "Kan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ein \u2013 (da bin ich schon gesehen!)", "tokens": ["ein", "\u2013", "(", "da", "bin", "ich", "schon", "ge\u00b7se\u00b7hen", "!", ")"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "$(", "$(", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bock und seine Gei\u00dftrabanten.", "tokens": ["Bock", "und", "sei\u00b7ne", "Gei\u00df\u00b7tra\u00b7ban\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Und nun sp\u00e4hen sie herunter,", "tokens": ["Und", "nun", "sp\u00e4\u00b7hen", "sie", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "stehen, wie aus Stein geschnitten ...", "tokens": ["ste\u00b7hen", ",", "wie", "aus", "Stein", "ge\u00b7schnit\u00b7ten", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber blitzschnell sind sie munter,", "tokens": ["A\u00b7ber", "blitz\u00b7schnell", "sind", "sie", "mun\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bin ich meines Wegs geschritten!", "tokens": ["bin", "ich", "mei\u00b7nes", "Wegs", "ge\u00b7schrit\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Und in weiten S\u00e4tzen eilt die", "tokens": ["Und", "in", "wei\u00b7ten", "S\u00e4t\u00b7zen", "eilt", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herde, mich ins Dorf zu bringen;", "tokens": ["Her\u00b7de", ",", "mich", "ins", "Dorf", "zu", "brin\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "blick ich r\u00fcckw\u00e4rts, so verweilt sie,", "tokens": ["blick", "ich", "r\u00fcck\u00b7w\u00e4rts", ",", "so", "ver\u00b7weilt", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schreit' ich, h\u00f6r ichs wieder springen.", "tokens": ["schreit'", "ich", ",", "h\u00f6r", "ichs", "wie\u00b7der", "sprin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Endlich sprech ich Donnerstrophen,", "tokens": ["End\u00b7lich", "sprech", "ich", "Don\u00b7ner\u00b7stro\u00b7phen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "wende mich an ihre B\u00e4rte:", "tokens": ["wen\u00b7de", "mich", "an", "ih\u00b7re", "B\u00e4r\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft des Philosophen F\u00e4hrte!", "tokens": ["La\u00dft", "des", "Phi\u00b7lo\u00b7so\u00b7phen", "F\u00e4hr\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seid doch selber Philosophen.", "tokens": ["Seid", "doch", "sel\u00b7ber", "Phi\u00b7lo\u00b7so\u00b7phen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADV", "ADV", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.5": {"line.1": {"text": "Feierlich und fragend schauen", "tokens": ["Fei\u00b7er\u00b7lich", "und", "fra\u00b7gend", "schau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lang wir einer auf den andern ...", "tokens": ["lang", "wir", "ei\u00b7ner", "auf", "den", "an\u00b7dern", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "APPR", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit hochgezognen Brauen", "tokens": ["Und", "mit", "hoch\u00b7ge\u00b7zog\u00b7nen", "Brau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lassen sie mich schlie\u00dflich wandern.", "tokens": ["las\u00b7sen", "sie", "mich", "schlie\u00df\u00b7lich", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Vor dem Abendhimmel gehen", "tokens": ["Vor", "dem", "A\u00b7bend\u00b7him\u00b7mel", "ge\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "l\u00e4ngs der Felsen sch\u00e4rfsten Kanten", "tokens": ["l\u00e4ngs", "der", "Fel\u00b7sen", "sch\u00e4rfs\u00b7ten", "Kan\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "ein \u2013 (da bin ich schon gesehen!)", "tokens": ["ein", "\u2013", "(", "da", "bin", "ich", "schon", "ge\u00b7se\u00b7hen", "!", ")"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "$(", "$(", "ADV", "VAFIN", "PPER", "ADV", "VVPP", "$.", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Bock und seine Gei\u00dftrabanten.", "tokens": ["Bock", "und", "sei\u00b7ne", "Gei\u00df\u00b7tra\u00b7ban\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und nun sp\u00e4hen sie herunter,", "tokens": ["Und", "nun", "sp\u00e4\u00b7hen", "sie", "her\u00b7un\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "stehen, wie aus Stein geschnitten ...", "tokens": ["ste\u00b7hen", ",", "wie", "aus", "Stein", "ge\u00b7schnit\u00b7ten", "..."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PWAV", "APPR", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber blitzschnell sind sie munter,", "tokens": ["A\u00b7ber", "blitz\u00b7schnell", "sind", "sie", "mun\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "bin ich meines Wegs geschritten!", "tokens": ["bin", "ich", "mei\u00b7nes", "Wegs", "ge\u00b7schrit\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PPOSAT", "NN", "VVPP", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Und in weiten S\u00e4tzen eilt die", "tokens": ["Und", "in", "wei\u00b7ten", "S\u00e4t\u00b7zen", "eilt", "die"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN", "VVFIN", "ART"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Herde, mich ins Dorf zu bringen;", "tokens": ["Her\u00b7de", ",", "mich", "ins", "Dorf", "zu", "brin\u00b7gen", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PRF", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "blick ich r\u00fcckw\u00e4rts, so verweilt sie,", "tokens": ["blick", "ich", "r\u00fcck\u00b7w\u00e4rts", ",", "so", "ver\u00b7weilt", "sie", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "ADV", "$,", "ADV", "VVFIN", "PPER", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "schreit' ich, h\u00f6r ichs wieder springen.", "tokens": ["schreit'", "ich", ",", "h\u00f6r", "ichs", "wie\u00b7der", "sprin\u00b7gen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "VVFIN", "PIS", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Endlich sprech ich Donnerstrophen,", "tokens": ["End\u00b7lich", "sprech", "ich", "Don\u00b7ner\u00b7stro\u00b7phen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "NN", "$,"], "meter": "+-+-+---", "measure": "unknown.measure.tri"}, "line.2": {"text": "wende mich an ihre B\u00e4rte:", "tokens": ["wen\u00b7de", "mich", "an", "ih\u00b7re", "B\u00e4r\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "La\u00dft des Philosophen F\u00e4hrte!", "tokens": ["La\u00dft", "des", "Phi\u00b7lo\u00b7so\u00b7phen", "F\u00e4hr\u00b7te", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Seid doch selber Philosophen.", "tokens": ["Seid", "doch", "sel\u00b7ber", "Phi\u00b7lo\u00b7so\u00b7phen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAIMP", "ADV", "ADV", "NN", "$."], "meter": "+-+--+-+", "measure": "glykoneus"}}, "stanza.10": {"line.1": {"text": "Feierlich und fragend schauen", "tokens": ["Fei\u00b7er\u00b7lich", "und", "fra\u00b7gend", "schau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "KON", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "lang wir einer auf den andern ...", "tokens": ["lang", "wir", "ei\u00b7ner", "auf", "den", "an\u00b7dern", "..."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PPER", "ART", "APPR", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und mit hochgezognen Brauen", "tokens": ["Und", "mit", "hoch\u00b7ge\u00b7zog\u00b7nen", "Brau\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "lassen sie mich schlie\u00dflich wandern.", "tokens": ["las\u00b7sen", "sie", "mich", "schlie\u00df\u00b7lich", "wan\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PRF", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}