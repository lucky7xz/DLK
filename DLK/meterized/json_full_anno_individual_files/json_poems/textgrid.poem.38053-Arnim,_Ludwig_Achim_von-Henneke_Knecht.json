{"textgrid.poem.38053": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Henneke Knecht", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Henneke Knecht, was willst du thun,", "tokens": ["Hen\u00b7ne\u00b7ke", "Knecht", ",", "was", "willst", "du", "thun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Willst du verdienen dein alten Lohn,", "tokens": ["Willst", "du", "ver\u00b7die\u00b7nen", "dein", "al\u00b7ten", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ueber Sommer bey mir bleiben?", "tokens": ["Ue\u00b7ber", "Som\u00b7mer", "bey", "mir", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich geb dir ein Paar neue Schuh,", "tokens": ["Ich", "geb", "dir", "ein", "Paar", "neu\u00b7e", "Schuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Den Pflug kannst du wohl treiben.", "tokens": ["Den", "Pflug", "kannst", "du", "wohl", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Henneke sprach ein trozig Wort,", "tokens": ["Hen\u00b7ne\u00b7ke", "sprach", "ein", "tro\u00b7zig", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich will keim Bauern dienen fort,", "tokens": ["Ich", "will", "keim", "Bau\u00b7ern", "die\u00b7nen", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Solcher Arbeit will ich trutzen,", "tokens": ["Sol\u00b7cher", "Ar\u00b7beit", "will", "ich", "trut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich will mich geben auf die See,", "tokens": ["Ich", "will", "mich", "ge\u00b7ben", "auf", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des hab ich gr\u00f6ssern Nutzen.", "tokens": ["Des", "hab", "ich", "gr\u00f6s\u00b7sern", "Nut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Das Weib sprach auch ein hastig Wort:", "tokens": ["Das", "Weib", "sprach", "auch", "ein", "has\u00b7tig", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie bist du Karl auch so beth\u00f6rt,", "tokens": ["Wie", "bist", "du", "Karl", "auch", "so", "be\u00b7th\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NE", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Willst du ein Schiffmann werden,", "tokens": ["Willst", "du", "ein", "Schiff\u00b7mann", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hakken, reuten ist dein Art", "tokens": ["Hak\u00b7ken", ",", "reu\u00b7ten", "ist", "dein", "Art"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und pfl\u00fcgen in der Erden.", "tokens": ["Und", "pfl\u00fc\u00b7gen", "in", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Henneke ward bey sich selbst zu Rath,", "tokens": ["Hen\u00b7ne\u00b7ke", "ward", "bey", "sich", "selbst", "zu", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er kauft f\u00fcr seinen Habersack", "tokens": ["Er", "kauft", "f\u00fcr", "sei\u00b7nen", "Ha\u00b7ber\u00b7sack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Armbrust, gut von Preise,", "tokens": ["Ein", "Arm\u00b7brust", ",", "gut", "von", "Prei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kurz Kleider l\u00e4\u00dft sich messen an,", "tokens": ["Kurz", "Klei\u00b7der", "l\u00e4\u00dft", "sich", "mes\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VVFIN", "PRF", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Recht nach der Krieger Weise.", "tokens": ["Recht", "nach", "der", "Krie\u00b7ger", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Er nahm die Armbrust auf den Nack,", "tokens": ["Er", "nahm", "die", "Arm\u00b7brust", "auf", "den", "Nack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den K\u00f6cher er im G\u00fcrtel stach,", "tokens": ["Den", "K\u00f6\u00b7cher", "er", "im", "G\u00fcr\u00b7tel", "stach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Schwerdt an seine Seite,", "tokens": ["Das", "Schwerdt", "an", "sei\u00b7ne", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So ging er dann mit Sack und Pack,", "tokens": ["So", "ging", "er", "dann", "mit", "Sack", "und", "Pack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Bremen th\u00e4t er schreiten.", "tokens": ["Nach", "Bre\u00b7men", "th\u00e4t", "er", "schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Als Henneke nach Bremen kam,", "tokens": ["Als", "Hen\u00b7ne\u00b7ke", "nach", "Bre\u00b7men", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Th\u00e4t er vor einem Schiffer stahn,", "tokens": ["Th\u00e4t", "er", "vor", "ei\u00b7nem", "Schif\u00b7fer", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sprach: Schiffer lieber Herre,", "tokens": ["Sprach", ":", "Schif\u00b7fer", "lie\u00b7ber", "Her\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wollt ihr mich wohl zum Schiffmann han,", "tokens": ["Wollt", "ihr", "mich", "wohl", "zum", "Schiff\u00b7mann", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr einen Ruderere?", "tokens": ["F\u00fcr", "ei\u00b7nen", "Ru\u00b7de\u00b7re\u00b7re", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ich will dich gerne nehmen an,", "tokens": ["Ich", "will", "dich", "ger\u00b7ne", "neh\u00b7men", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst du als Schiffknecht mir bestahn,", "tokens": ["Kannst", "du", "als", "Schiff\u00b7knecht", "mir", "be\u00b7stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl recht an Schiffes Borde,", "tokens": ["Wohl", "recht", "an", "Schif\u00b7fes", "Bor\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich h\u00f6r an deinen Worten wohl,", "tokens": ["Ich", "h\u00f6r", "an", "dei\u00b7nen", "Wor\u00b7ten", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist von Bauern Arte.", "tokens": ["Du", "bist", "von", "Bau\u00b7ern", "Ar\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Henneke schwor einen theuren Eid:", "tokens": ["Hen\u00b7ne\u00b7ke", "schwor", "ei\u00b7nen", "theu\u00b7ren", "Eid", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Kein anderer Kerl ist weit und breit", "tokens": ["Kein", "an\u00b7de\u00b7rer", "Kerl", "ist", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu allem Thun und Sachen;", "tokens": ["Zu", "al\u00b7lem", "Thun", "und", "Sa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin in meinem Muth so frey,", "tokens": ["Ich", "bin", "in", "mei\u00b7nem", "Muth", "so", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Recht als ein wilder Drachen.", "tokens": ["Recht", "als", "ein", "wil\u00b7der", "Dra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Da Henneke Knecht kam auf die See,", "tokens": ["Da", "Hen\u00b7ne\u00b7ke", "Knecht", "kam", "auf", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stand er als ein verzagtes Reh,", "tokens": ["Stand", "er", "als", "ein", "ver\u00b7zag\u00b7tes", "Reh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Wort konnt er nicht sprechen,", "tokens": ["Kein", "Wort", "konnt", "er", "nicht", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er dachte hin, er dachte her,", "tokens": ["Er", "dach\u00b7te", "hin", ",", "er", "dach\u00b7te", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein Herz wollt ihm zerbrechen.", "tokens": ["Sein", "Herz", "wollt", "ihm", "zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Er lehnt sein Haupt an Schiffesbord,", "tokens": ["Er", "lehnt", "sein", "Haupt", "an", "Schif\u00b7fes\u00b7bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Armes lang sprach er kein Wort,", "tokens": ["Ein", "Ar\u00b7mes", "lang", "sprach", "er", "kein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wohl zu derselben Stunden:", "tokens": ["Wohl", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was mir das Weib vorhergesagt,", "tokens": ["Was", "mir", "das", "Weib", "vor\u00b7her\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das hab ich nun gefunden.", "tokens": ["Das", "hab", "ich", "nun", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Der Wind, der weht, der Hahn, der kr\u00e4ht,", "tokens": ["Der", "Wind", ",", "der", "weht", ",", "der", "Hahn", ",", "der", "kr\u00e4ht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wetter, das war gar unst\u00e4t,", "tokens": ["Das", "Wet\u00b7ter", ",", "das", "war", "gar", "un\u00b7st\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Meer ganz ungeheure,", "tokens": ["Das", "Meer", "ganz", "un\u00b7ge\u00b7heu\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "H\u00e4tt ich den Pflug in meiner Hand,", "tokens": ["H\u00e4tt", "ich", "den", "Pflug", "in", "mei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem wollt ich wohl bald steuren.", "tokens": ["Dem", "wollt", "ich", "wohl", "bald", "steu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Ist denn nun niemand hier bekannt,", "tokens": ["Ist", "denn", "nun", "nie\u00b7mand", "hier", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der mich bringt in das Sachsenland,", "tokens": ["Der", "mich", "bringt", "in", "das", "Sach\u00b7sen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wohl zwischen Dister und Leine,", "tokens": ["Wohl", "zwi\u00b7schen", "Dis\u00b7ter", "und", "Lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Wohl zu des edlen F\u00fcrsten Haus,", "tokens": ["Wohl", "zu", "des", "ed\u00b7len", "F\u00fcrs\u00b7ten", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Haus zum Lauensteine?", "tokens": ["Das", "Haus", "zum", "Lau\u00b7en\u00b7stei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Auch ist nun hier niemand bekannt,", "tokens": ["Auch", "ist", "nun", "hier", "nie\u00b7mand", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIS", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Der mich bringt ins Braunschweiger Land,", "tokens": ["Der", "mich", "bringt", "ins", "Braun\u00b7schwei\u00b7ger", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich will ihn wohl belohnen,", "tokens": ["Ich", "will", "ihn", "wohl", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich will ihm geben mein Habersack,", "tokens": ["Ich", "will", "ihm", "ge\u00b7ben", "mein", "Ha\u00b7ber\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dazu ein Scheffel Bohnen.", "tokens": ["Da\u00b7zu", "ein", "Schef\u00b7fel", "Boh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Der uns das Liedchen hat erdacht,", "tokens": ["Der", "uns", "das", "Lied\u00b7chen", "hat", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Henneken von der See gebracht,", "tokens": ["Hat", "Hen\u00b7ne\u00b7ken", "von", "der", "See", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da\u00df ihn die L\u00e4us nicht fressen,", "tokens": ["Da\u00df", "ihn", "die", "L\u00e4us", "nicht", "fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er warnt auch all Gesellen gut,", "tokens": ["Er", "warnt", "auch", "all", "Ge\u00b7sel\u00b7len", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihr nicht seid vermessen.", "tokens": ["Da\u00df", "ihr", "nicht", "seid", "ver\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Henneke Knecht, was willst du thun,", "tokens": ["Hen\u00b7ne\u00b7ke", "Knecht", ",", "was", "willst", "du", "thun", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$,", "PWS", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Willst du verdienen dein alten Lohn,", "tokens": ["Willst", "du", "ver\u00b7die\u00b7nen", "dein", "al\u00b7ten", "Lohn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Ueber Sommer bey mir bleiben?", "tokens": ["Ue\u00b7ber", "Som\u00b7mer", "bey", "mir", "blei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich geb dir ein Paar neue Schuh,", "tokens": ["Ich", "geb", "dir", "ein", "Paar", "neu\u00b7e", "Schuh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+--++-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Den Pflug kannst du wohl treiben.", "tokens": ["Den", "Pflug", "kannst", "du", "wohl", "trei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Henneke sprach ein trozig Wort,", "tokens": ["Hen\u00b7ne\u00b7ke", "sprach", "ein", "tro\u00b7zig", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJD", "NN", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ich will keim Bauern dienen fort,", "tokens": ["Ich", "will", "keim", "Bau\u00b7ern", "die\u00b7nen", "fort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIAT", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Solcher Arbeit will ich trutzen,", "tokens": ["Sol\u00b7cher", "Ar\u00b7beit", "will", "ich", "trut\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ich will mich geben auf die See,", "tokens": ["Ich", "will", "mich", "ge\u00b7ben", "auf", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Des hab ich gr\u00f6ssern Nutzen.", "tokens": ["Des", "hab", "ich", "gr\u00f6s\u00b7sern", "Nut\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Das Weib sprach auch ein hastig Wort:", "tokens": ["Das", "Weib", "sprach", "auch", "ein", "has\u00b7tig", "Wort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "ADJD", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wie bist du Karl auch so beth\u00f6rt,", "tokens": ["Wie", "bist", "du", "Karl", "auch", "so", "be\u00b7th\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NE", "ADV", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Willst du ein Schiffmann werden,", "tokens": ["Willst", "du", "ein", "Schiff\u00b7mann", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hakken, reuten ist dein Art", "tokens": ["Hak\u00b7ken", ",", "reu\u00b7ten", "ist", "dein", "Art"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["NN", "$,", "VVFIN", "VAFIN", "PPOSAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und pfl\u00fcgen in der Erden.", "tokens": ["Und", "pfl\u00fc\u00b7gen", "in", "der", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Henneke ward bey sich selbst zu Rath,", "tokens": ["Hen\u00b7ne\u00b7ke", "ward", "bey", "sich", "selbst", "zu", "Rath", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "APPR", "PRF", "ADV", "APPR", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er kauft f\u00fcr seinen Habersack", "tokens": ["Er", "kauft", "f\u00fcr", "sei\u00b7nen", "Ha\u00b7ber\u00b7sack"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ein Armbrust, gut von Preise,", "tokens": ["Ein", "Arm\u00b7brust", ",", "gut", "von", "Prei\u00b7se", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kurz Kleider l\u00e4\u00dft sich messen an,", "tokens": ["Kurz", "Klei\u00b7der", "l\u00e4\u00dft", "sich", "mes\u00b7sen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "VVFIN", "PRF", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Recht nach der Krieger Weise.", "tokens": ["Recht", "nach", "der", "Krie\u00b7ger", "Wei\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Er nahm die Armbrust auf den Nack,", "tokens": ["Er", "nahm", "die", "Arm\u00b7brust", "auf", "den", "Nack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den K\u00f6cher er im G\u00fcrtel stach,", "tokens": ["Den", "K\u00f6\u00b7cher", "er", "im", "G\u00fcr\u00b7tel", "stach", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Schwerdt an seine Seite,", "tokens": ["Das", "Schwerdt", "an", "sei\u00b7ne", "Sei\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So ging er dann mit Sack und Pack,", "tokens": ["So", "ging", "er", "dann", "mit", "Sack", "und", "Pack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Nach Bremen th\u00e4t er schreiten.", "tokens": ["Nach", "Bre\u00b7men", "th\u00e4t", "er", "schrei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VVFIN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Als Henneke nach Bremen kam,", "tokens": ["Als", "Hen\u00b7ne\u00b7ke", "nach", "Bre\u00b7men", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Th\u00e4t er vor einem Schiffer stahn,", "tokens": ["Th\u00e4t", "er", "vor", "ei\u00b7nem", "Schif\u00b7fer", "stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sprach: Schiffer lieber Herre,", "tokens": ["Sprach", ":", "Schif\u00b7fer", "lie\u00b7ber", "Her\u00b7re", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$.", "NN", "ADV", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wollt ihr mich wohl zum Schiffmann han,", "tokens": ["Wollt", "ihr", "mich", "wohl", "zum", "Schiff\u00b7mann", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "APPRART", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "F\u00fcr einen Ruderere?", "tokens": ["F\u00fcr", "ei\u00b7nen", "Ru\u00b7de\u00b7re\u00b7re", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Ich will dich gerne nehmen an,", "tokens": ["Ich", "will", "dich", "ger\u00b7ne", "neh\u00b7men", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Kannst du als Schiffknecht mir bestahn,", "tokens": ["Kannst", "du", "als", "Schiff\u00b7knecht", "mir", "be\u00b7stahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "KOUS", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wohl recht an Schiffes Borde,", "tokens": ["Wohl", "recht", "an", "Schif\u00b7fes", "Bor\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich h\u00f6r an deinen Worten wohl,", "tokens": ["Ich", "h\u00f6r", "an", "dei\u00b7nen", "Wor\u00b7ten", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du bist von Bauern Arte.", "tokens": ["Du", "bist", "von", "Bau\u00b7ern", "Ar\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Henneke schwor einen theuren Eid:", "tokens": ["Hen\u00b7ne\u00b7ke", "schwor", "ei\u00b7nen", "theu\u00b7ren", "Eid", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Kein anderer Kerl ist weit und breit", "tokens": ["Kein", "an\u00b7de\u00b7rer", "Kerl", "ist", "weit", "und", "breit"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PIAT", "ADJA", "NN", "VAFIN", "ADJD", "KON", "ADJD"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Zu allem Thun und Sachen;", "tokens": ["Zu", "al\u00b7lem", "Thun", "und", "Sa\u00b7chen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich bin in meinem Muth so frey,", "tokens": ["Ich", "bin", "in", "mei\u00b7nem", "Muth", "so", "frey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Recht als ein wilder Drachen.", "tokens": ["Recht", "als", "ein", "wil\u00b7der", "Dra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Da Henneke Knecht kam auf die See,", "tokens": ["Da", "Hen\u00b7ne\u00b7ke", "Knecht", "kam", "auf", "die", "See", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NE", "NE", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Stand er als ein verzagtes Reh,", "tokens": ["Stand", "er", "als", "ein", "ver\u00b7zag\u00b7tes", "Reh", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "KOUS", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Kein Wort konnt er nicht sprechen,", "tokens": ["Kein", "Wort", "konnt", "er", "nicht", "spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VMFIN", "PPER", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er dachte hin, er dachte her,", "tokens": ["Er", "dach\u00b7te", "hin", ",", "er", "dach\u00b7te", "her", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKVZ", "$,", "PPER", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein Herz wollt ihm zerbrechen.", "tokens": ["Sein", "Herz", "wollt", "ihm", "zer\u00b7bre\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Er lehnt sein Haupt an Schiffesbord,", "tokens": ["Er", "lehnt", "sein", "Haupt", "an", "Schif\u00b7fes\u00b7bord", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Armes lang sprach er kein Wort,", "tokens": ["Ein", "Ar\u00b7mes", "lang", "sprach", "er", "kein", "Wort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJD", "VVFIN", "PPER", "PIAT", "NN", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "Wohl zu derselben Stunden:", "tokens": ["Wohl", "zu", "der\u00b7sel\u00b7ben", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PDAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Was mir das Weib vorhergesagt,", "tokens": ["Was", "mir", "das", "Weib", "vor\u00b7her\u00b7ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das hab ich nun gefunden.", "tokens": ["Das", "hab", "ich", "nun", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "Der Wind, der weht, der Hahn, der kr\u00e4ht,", "tokens": ["Der", "Wind", ",", "der", "weht", ",", "der", "Hahn", ",", "der", "kr\u00e4ht", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "VVFIN", "$,", "ART", "NN", "$,", "PRELS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Wetter, das war gar unst\u00e4t,", "tokens": ["Das", "Wet\u00b7ter", ",", "das", "war", "gar", "un\u00b7st\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PDS", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Das Meer ganz ungeheure,", "tokens": ["Das", "Meer", "ganz", "un\u00b7ge\u00b7heu\u00b7re", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "H\u00e4tt ich den Pflug in meiner Hand,", "tokens": ["H\u00e4tt", "ich", "den", "Pflug", "in", "mei\u00b7ner", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dem wollt ich wohl bald steuren.", "tokens": ["Dem", "wollt", "ich", "wohl", "bald", "steu\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Ist denn nun niemand hier bekannt,", "tokens": ["Ist", "denn", "nun", "nie\u00b7mand", "hier", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "PIS", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der mich bringt in das Sachsenland,", "tokens": ["Der", "mich", "bringt", "in", "das", "Sach\u00b7sen\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "-++--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Wohl zwischen Dister und Leine,", "tokens": ["Wohl", "zwi\u00b7schen", "Dis\u00b7ter", "und", "Lei\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Wohl zu des edlen F\u00fcrsten Haus,", "tokens": ["Wohl", "zu", "des", "ed\u00b7len", "F\u00fcrs\u00b7ten", "Haus", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das Haus zum Lauensteine?", "tokens": ["Das", "Haus", "zum", "Lau\u00b7en\u00b7stei\u00b7ne", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Auch ist nun hier niemand bekannt,", "tokens": ["Auch", "ist", "nun", "hier", "nie\u00b7mand", "be\u00b7kannt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "PIS", "ADJD", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Der mich bringt ins Braunschweiger Land,", "tokens": ["Der", "mich", "bringt", "ins", "Braun\u00b7schwei\u00b7ger", "Land", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "--+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Ich will ihn wohl belohnen,", "tokens": ["Ich", "will", "ihn", "wohl", "be\u00b7loh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich will ihm geben mein Habersack,", "tokens": ["Ich", "will", "ihm", "ge\u00b7ben", "mein", "Ha\u00b7ber\u00b7sack", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Dazu ein Scheffel Bohnen.", "tokens": ["Da\u00b7zu", "ein", "Schef\u00b7fel", "Boh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Der uns das Liedchen hat erdacht,", "tokens": ["Der", "uns", "das", "Lied\u00b7chen", "hat", "er\u00b7dacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Hat Henneken von der See gebracht,", "tokens": ["Hat", "Hen\u00b7ne\u00b7ken", "von", "der", "See", "ge\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "APPR", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Da\u00df ihn die L\u00e4us nicht fressen,", "tokens": ["Da\u00df", "ihn", "die", "L\u00e4us", "nicht", "fres\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er warnt auch all Gesellen gut,", "tokens": ["Er", "warnt", "auch", "all", "Ge\u00b7sel\u00b7len", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PIAT", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df ihr nicht seid vermessen.", "tokens": ["Da\u00df", "ihr", "nicht", "seid", "ver\u00b7mes\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}