{"dta.poem.13249": {"metadata": {"author": {"name": "Scheyb, Franz Christoph von", "birth": "N.A.", "death": "N.A."}, "title": "E ilftes  B uch.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1746", "urn": "urn:nbn:de:kobv:b4-20535-5", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "\u201eder Stab, den ich zum Schuz stets pflege mit zu f\u00fchren,", "tokens": ["\u201e", "der", "Stab", ",", "den", "ich", "zum", "Schuz", "stets", "pfle\u00b7ge", "mit", "zu", "f\u00fch\u00b7ren", ","], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "NN", "$,", "PRELS", "PPER", "APPRART", "NN", "ADV", "VVFIN", "APPR", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "\u201esoll deine Faust, Gemahl! als ein Befehls-Stab zieren;", "tokens": ["\u201e", "soll", "dei\u00b7ne", "Faust", ",", "Ge\u00b7mahl", "!", "als", "ein", "Be\u00b7fehls\u00b7Stab", "zie\u00b7ren", ";"], "token_info": ["punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "VMFIN", "PPOSAT", "NN", "$,", "NN", "$.", "KOUS", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "\u201eer stammt von dem Gericht, das Tugend, Macht und Recht", "tokens": ["\u201e", "er", "stammt", "von", "dem", "Ge\u00b7richt", ",", "das", "Tu\u00b7gend", ",", "Macht", "und", "Recht"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "APPR", "ART", "NN", "$,", "ART", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "\u201emit Wuth verdammet hat, jedoch an nichts geschw\u00e4cht.", "tokens": ["\u201e", "mit", "Wuth", "ver\u00b7dam\u00b7met", "hat", ",", "je\u00b7doch", "an", "nichts", "ge\u00b7schw\u00e4cht", "."], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "NN", "VVFIN", "VAFIN", "$,", "ADV", "APPR", "PIS", "VVPP", "$."], "meter": "-+-+-+---+-+", "measure": "unknown.measure.penta"}, "line.5": {"text": "215Da sie die Worte sprach, lie\u00df sie ein frohes Wesen", "tokens": ["sie", "die", "Wor\u00b7te", "sprach", ",", "lie\u00df", "sie", "ein", "fro\u00b7hes", "We\u00b7sen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "ART", "NN", "VVFIN", "$,", "VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.6": {"text": "Jm Reden, in dem Aug und in der Regung lesen.", "tokens": ["Jm", "Re\u00b7den", ",", "in", "dem", "Aug", "und", "in", "der", "Re\u00b7gung", "le\u00b7sen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "ART", "NN", "KON", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wir sahn die Fr\u00f6mmigkeit, die sich bey diesem Saz", "tokens": ["Wir", "sahn", "die", "Fr\u00f6m\u00b7mig\u00b7keit", ",", "die", "sich", "bey", "die\u00b7sem", "Saz"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PRF", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Erreget wies und sprach: \u201eDer Stab ist jener Schaz", "tokens": ["Er\u00b7re\u00b7get", "wies", "und", "sprach", ":", "\u201e", "Der", "Stab", "ist", "je\u00b7ner", "Schaz"], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "VVFIN", "KON", "VVFIN", "$.", "$(", "ART", "NN", "VAFIN", "PDAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "\u201ean welchem Gl\u00fcck und Heil der ganzen Menschheit hangen.", "tokens": ["\u201e", "an", "wel\u00b7chem", "Gl\u00fcck", "und", "Heil", "der", "gan\u00b7zen", "Menschheit", "han\u00b7gen", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PWAT", "NN", "KON", "NN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "220Theresia fuhr fort: \u201ddu wirst ihn gleich empfangen.", "tokens": ["fuhr", "fort", ":", "\"", "du", "wirst", "ihn", "gleich", "emp\u00b7fan\u00b7gen", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKVZ", "$.", "$(", "PPER", "VAFIN", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.11": {"text": "\u201eer hat mich der Gefahr des Untergangs befreyt;", "tokens": ["\u201e", "er", "hat", "mich", "der", "Ge\u00b7fahr", "des", "Un\u00b7ter\u00b7gangs", "be\u00b7freyt", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "\u201eich hab ihm Kron und Thron und selbsten mich geweiht.", "tokens": ["\u201e", "ich", "hab", "ihm", "Kron", "und", "Thron", "und", "selbs\u00b7ten", "mich", "ge\u00b7weiht", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "NN", "KON", "NN", "KON", "VVFIN", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "\u201eer ists, den ich weit mehr als K\u00f6nigreiche sch\u00e4ze;", "tokens": ["\u201e", "er", "ists", ",", "den", "ich", "weit", "mehr", "als", "K\u00f6\u00b7nig\u00b7rei\u00b7che", "sch\u00e4\u00b7ze", ";"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "$,", "PRELS", "PPER", "ADJD", "PIAT", "KOKOM", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "\u201ein den ich mein Vertraun und Wunsch und Hoffen seze.", "tokens": ["\u201e", "in", "den", "ich", "mein", "Ver\u00b7traun", "und", "Wunsch", "und", "Hof\u00b7fen", "se\u00b7ze", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "APPR", "PRELS", "PPER", "PPOSAT", "NN", "KON", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "225\u201dO mehr als irrdischer zum Heil geschickter Stab!", "tokens": ["\"", "O", "mehr", "als", "irr\u00b7di\u00b7scher", "zum", "Heil", "ge\u00b7schick\u00b7ter", "Stab", "!"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "PIAT", "KOKOM", "ADV", "APPRART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "\u201eden ich die Lebens-Zeit zum Raths-Gef\u00e4rten hab;", "tokens": ["\u201e", "den", "ich", "die", "Le\u00b7bens\u00b7Zeit", "zum", "Raths\u00b7Ge\u00b7f\u00e4r\u00b7ten", "hab", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PRELS", "PPER", "ART", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.17": {"text": "\u201emein Ober-Ur-Ahn ists, der ihn zum Schuz erkohre,", "tokens": ["\u201e", "mein", "O\u00b7ber\u00b7Ur\u00b7Ahn", "ists", ",", "der", "ihn", "zum", "Schuz", "er\u00b7koh\u00b7re", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPOSAT", "NN", "VAFIN", "$,", "PRELS", "PPER", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.18": {"text": "\u201eda seiner Feinde Bund sich wieder ihn verschwore.", "tokens": ["\u201e", "da", "sei\u00b7ner", "Fein\u00b7de", "Bund", "sich", "wie\u00b7der", "ihn", "ver\u00b7schwo\u00b7re", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "PPOSAT", "NN", "NN", "PRF", "ADV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.19": {"text": "\u201eer war damahls dem Haus zur allerst\u00e4rcksten Wehr.", "tokens": ["\u201e", "er", "war", "da\u00b7mahls", "dem", "Haus", "zur", "al\u00b7ler\u00b7st\u00e4rcks\u00b7ten", "Wehr", "."], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "ADV", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "230\u201dGeh, Fr\u00f6mmigkeit! geh gleich! bring uns denselben her!", "tokens": ["\"", "Geh", ",", "Fr\u00f6m\u00b7mig\u00b7keit", "!", "geh", "gleich", "!", "bring", "uns", "den\u00b7sel\u00b7ben", "her", "!"], "token_info": ["punct", "word", "punct", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "NE", "$,", "NN", "$.", "VVFIN", "ADV", "$.", "VVFIN", "PPER", "PDS", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "\u201edu wei\u00dft das Ruh-Gemach, in dem ich mich verschliesse,", "tokens": ["\u201e", "du", "wei\u00dft", "das", "Ruh\u00b7Ge\u00b7mach", ",", "in", "dem", "ich", "mich", "ver\u00b7schlies\u00b7se", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "ART", "NN", "$,", "APPR", "PRELS", "PPER", "PRF", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.22": {"text": "\u201ewann ich um Trost und Hilff das Herz zu GOtt ergiesse;", "tokens": ["\u201e", "wann", "ich", "um", "Trost", "und", "Hilff", "das", "Herz", "zu", "Gott", "er\u00b7gies\u00b7se", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PWAV", "PPER", "APPR", "NN", "KON", "NN", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.23": {"text": "\u201edu wirst ihn auf dem Tisch bey meinen Schriften sehn;", "tokens": ["\u201e", "du", "wirst", "ihn", "auf", "dem", "Tisch", "bey", "mei\u00b7nen", "Schrif\u00b7ten", "sehn", ";"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "PPER", "APPR", "ART", "NN", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "\u201edu wei\u00dft, an welchem Ort er sonsten pflegt zu stehn.", "tokens": ["\u201e", "du", "wei\u00dft", ",", "an", "wel\u00b7chem", "Ort", "er", "sons\u00b7ten", "pflegt", "zu", "stehn", "."], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VVFIN", "$,", "APPR", "PWAT", "NN", "PPER", "ADV", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}}}}