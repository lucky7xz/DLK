{"textgrid.poem.53042": {"metadata": {"author": {"name": "Lohenstein, Daniel Casper von", "birth": "N.A.", "death": "N.A."}, "title": "1L: Weh! weh mir Asien! ach weh!", "genre": "verse", "period": "N.A.", "pub_year": 1659, "urn": "N.A.", "language": ["de:0.85", "en:0.14"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Weh! weh mir Asien! ach weh!", "tokens": ["Weh", "!", "weh", "mir", "A\u00b7sien", "!", "ach", "weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "PPER", "NE", "$.", "XY", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Weh mir! \u2013 Ach! wo ich mich vermaledeien,", "tokens": ["Weh", "mir", "!", "\u2013", "Ach", "!", "wo", "ich", "mich", "ver\u00b7ma\u00b7le\u00b7dei\u00b7en", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "$(", "ITJ", "$.", "PWAV", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo ich bei dieser Schwermuthssee,", "tokens": ["Wo", "ich", "bei", "die\u00b7ser", "Schwer\u00b7muths\u00b7see", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bei so viel Ach selbst mein bethr\u00e4nt Gesicht verspeien,", "tokens": ["Bei", "so", "viel", "Ach", "selbst", "mein", "be\u00b7thr\u00e4nt", "Ge\u00b7sicht", "ver\u00b7spei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo ich mich selbst mit Heul'n und Zeterrufen", "tokens": ["Wo", "ich", "mich", "selbst", "mit", "Heul'n", "und", "Ze\u00b7ter\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Durch strengen Urtheilsspruch verdammen kann,", "tokens": ["Durch", "stren\u00b7gen", "Ur\u00b7theils\u00b7spruch", "ver\u00b7dam\u00b7men", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So nimm dies lechzend Ach, best\u00fcrzter Abgrund, an!", "tokens": ["So", "nimm", "dies", "lech\u00b7zend", "Ach", ",", "be\u00b7st\u00fcrz\u00b7ter", "Ab\u00b7grund", ",", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVIMP", "PDS", "ADJD", "ITJ", "$,", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Best\u00fcrzter Abgrund! \u2013 O die Glieder triefen", "tokens": ["Be\u00b7st\u00fcrz\u00b7ter", "Ab\u00b7grund", "!", "\u2013", "O", "die", "Glie\u00b7der", "trie\u00b7fen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "$(", "NE", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Voll Angstschwei\u00df! \u2013 Ach, des Achs! \u2013 der laue Brunn der d\u00fcrren Adern schwellt", "tokens": ["Voll", "A\u00b7ngstschwei\u00df", "!", "\u2013", "Ach", ",", "des", "Achs", "!", "\u2013", "der", "lau\u00b7e", "Brunn", "der", "d\u00fcr\u00b7ren", "A\u00b7dern", "schwellt"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "$.", "$(", "ITJ", "$,", "ART", "NN", "$.", "$(", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.10": {"text": "Den Gischt der Purpurfluth! Mein Blutschaum schreibt mein Elend in den Sand!", "tokens": ["Den", "Gischt", "der", "Pur\u00b7pur\u00b7fluth", "!", "Mein", "Blut\u00b7schaum", "schreibt", "mein", "E\u00b7lend", "in", "den", "Sand", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.11": {"text": "Entthronte K\u00f6niginn! entzepterte Beherrscherinn der Welt!", "tokens": ["Ent\u00b7thron\u00b7te", "K\u00f6\u00b7ni\u00b7ginn", "!", "ent\u00b7zep\u00b7ter\u00b7te", "Be\u00b7herr\u00b7sche\u00b7rinn", "der", "Welt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.12": {"text": "Gest\u00fcrztes Asien! aus Ichts in Nichts und Staub verstobnes Land!", "tokens": ["Ge\u00b7st\u00fcrz\u00b7tes", "A\u00b7sien", "!", "aus", "Ichts", "in", "Nichts", "und", "Staub", "ver\u00b7stob\u00b7nes", "Land", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "APPR", "PIS", "APPR", "PIS", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "Ja wohl, aus Ichts, als mein gekr\u00f6ntes Haupt", "tokens": ["Ja", "wohl", ",", "aus", "Ichts", ",", "als", "mein", "ge\u00b7kr\u00f6n\u00b7tes", "Haupt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "APPR", "PIS", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ein Haupt so viel gekr\u00f6nter H\u00e4upter war,", "tokens": ["Ein", "Haupt", "so", "viel", "ge\u00b7kr\u00f6n\u00b7ter", "H\u00e4up\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Als ich noch mit Siegspalmen war belaubt", "tokens": ["Als", "ich", "noch", "mit", "Siegs\u00b7pal\u00b7men", "war", "be\u00b7laubt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Und aller Welt Gesetze reichte dar,", "tokens": ["Und", "al\u00b7ler", "Welt", "Ge\u00b7set\u00b7ze", "reich\u00b7te", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Als noch, gesenkt zu diesen F\u00fc\u00dfen,", "tokens": ["Als", "noch", ",", "ge\u00b7senkt", "zu", "die\u00b7sen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "VVPP", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Europens Haupt und Afrika mein Zepter mu\u00dfte k\u00fcssen,", "tokens": ["Eu\u00b7ro\u00b7pens", "Haupt", "und", "Af\u00b7ri\u00b7ka", "mein", "Zep\u00b7ter", "mu\u00df\u00b7te", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NE", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.19": {"text": "Als mein Gebot, wie Stahl und Gluth, durchdrang", "tokens": ["Als", "mein", "Ge\u00b7bot", ",", "wie", "Stahl", "und", "Gluth", ",", "durch\u00b7drang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PWAV", "NN", "KON", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und L\u00e4nder zwang.", "tokens": ["Und", "L\u00e4n\u00b7der", "zwang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.2": {"line.1": {"text": "Ach, aber ach! \u2013 So hoch als ich beim Tugendgipfel", "tokens": ["Ach", ",", "a\u00b7ber", "ach", "!", "\u2013", "So", "hoch", "als", "ich", "beim", "Tu\u00b7gend\u00b7gip\u00b7fel"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "ADV", "$.", "$(", "ADV", "ADJD", "KOKOM", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In goldgestickten Kleidern stand,", "tokens": ["In", "gold\u00b7ge\u00b7stick\u00b7ten", "Klei\u00b7dern", "stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So tief hat sich das Spiel verwandt.", "tokens": ["So", "tief", "hat", "sich", "das", "Spiel", "ver\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So starb mein Ruhm! so schl\u00e4gt die Zeit die gr\u00fcnen Wipfel", "tokens": ["So", "starb", "mein", "Ruhm", "!", "so", "schl\u00e4gt", "die", "Zeit", "die", "gr\u00fc\u00b7nen", "Wip\u00b7fel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von den bejahrten Cedern ab.", "tokens": ["Von", "den", "be\u00b7jahr\u00b7ten", "Ce\u00b7dern", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Man schm\u00fcckt mich je noch wohl mit diesem Purpurrocke,", "tokens": ["Man", "schm\u00fcckt", "mich", "je", "noch", "wohl", "mit", "die\u00b7sem", "Pur\u00b7pur\u00b7ro\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Infuln, Kron' und K\u00f6nigsstab", "tokens": ["Mit", "In\u00b7fuln", ",", "Kron'", "und", "K\u00f6\u00b7nigs\u00b7stab"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hals, Achseln, H\u00e4nd' und Haupt, wo man mit solcher Schminke", "tokens": ["Hals", ",", "Ach\u00b7seln", ",", "H\u00e4nd'", "und", "Haupt", ",", "wo", "man", "mit", "sol\u00b7cher", "Schmin\u00b7ke"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "PWAV", "PIS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mich nicht blos sp\u00f6ttisch schminkt und \u00e4ffet und geheiht.", "tokens": ["Mich", "nicht", "blos", "sp\u00f6t\u00b7tisch", "schminkt", "und", "\u00e4f\u00b7fet", "und", "ge\u00b7heiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADJD", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch auch gesetzt, da\u00df dies Besch\u00f6nungskleid", "tokens": ["Doch", "auch", "ge\u00b7setzt", ",", "da\u00df", "dies", "Be\u00b7sch\u00f6\u00b7nungs\u00b7kleid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "$,", "KOUS", "PDS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mich nicht beschimpft,", "tokens": ["Mich", "nicht", "be\u00b7schimpft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "So trag' ich's doch nur zur Vermummung meiner Flecke,", "tokens": ["So", "trag'", "ich's", "doch", "nur", "zur", "Ver\u00b7mum\u00b7mung", "mei\u00b7ner", "Fle\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Zur Brand- und Schandmals-Schmink' und meiner Schalkheitsdecke,", "tokens": ["Zur", "Bran\u00b7d", "und", "Schand\u00b7mals\u00b7Schmink'", "und", "mei\u00b7ner", "Schalk\u00b7heits\u00b7de\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "TRUNC", "KON", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Wiewohl ich wei\u00df, da\u00df man die Nase r\u00fcmpft", "tokens": ["Wie\u00b7wohl", "ich", "wei\u00df", ",", "da\u00df", "man", "die", "Na\u00b7se", "r\u00fcmpft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und M\u00e4uler auf mich flennet,", "tokens": ["Und", "M\u00e4u\u00b7ler", "auf", "mich", "flen\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ich wei\u00df nicht, wie? mich nennet.", "tokens": ["Ich", "wei\u00df", "nicht", ",", "wie", "?", "mich", "nen\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "$.", "PPER", "VVFIN", "$."], "meter": "-+-++--", "measure": "unknown.measure.tri"}, "line.12": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.13": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.4": {"line.1": {"text": "Mich schmerzt's, und ich beschmerz' es auch mit diesem langen Seufzergalme,", "tokens": ["Mich", "schmerzt's", ",", "und", "ich", "be\u00b7schmer\u00b7z'", "es", "auch", "mit", "die\u00b7sem", "lan\u00b7gen", "Seuf\u00b7zer\u00b7gal\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Wenn ich mich, wie aus einem Traum' und Qualme,", "tokens": ["Wenn", "ich", "mich", ",", "wie", "aus", "ei\u00b7nem", "Traum'", "und", "Qual\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PWAV", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf mich, als ich noch in der Bl\u00fcthe war, besinne.", "tokens": ["Auf", "mich", ",", "als", "ich", "noch", "in", "der", "Bl\u00fc\u00b7the", "war", ",", "be\u00b7sin\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VAFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "War ich nicht, Asien, die gr\u00f6\u00dft' und \u00e4ltst' und sch\u00f6nste meiner Schwestern?", "tokens": ["War", "ich", "nicht", ",", "A\u00b7sien", ",", "die", "gr\u00f6\u00dft'", "und", "\u00e4lt\u00b7st'", "und", "sch\u00f6ns\u00b7te", "mei\u00b7ner", "Schwes\u00b7tern", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "$,", "NE", "$,", "PRELS", "ADJD", "KON", "ADJD", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Hat Neid und Geifersucht mich vor der Themis Richtsthul k\u00f6nnen l\u00e4stern?", "tokens": ["Hat", "Neid", "und", "Gei\u00b7fer\u00b7sucht", "mich", "vor", "der", "The\u00b7mis", "Richtst\u00b7hul", "k\u00f6n\u00b7nen", "l\u00e4s\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.6": {"text": "Der Menschen Ahnherr hielt mich erblich inne.", "tokens": ["Der", "Men\u00b7schen", "Ahn\u00b7herr", "hielt", "mich", "er\u00b7blich", "in\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Hat alles All, das Ost und West und S\u00fcd und Nord nicht schlie\u00dfen,", "tokens": ["Hat", "al\u00b7les", "All", ",", "das", "Ost", "und", "West", "und", "S\u00fcd", "und", "Nord", "nicht", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "ART", "NN", "KON", "NN", "KON", "NN", "KON", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "Mich selbst nicht oft mit seinem Glanz erf\u00fcllt", "tokens": ["Mich", "selbst", "nicht", "oft", "mit", "sei\u00b7nem", "Glanz", "er\u00b7f\u00fcllt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und sich selbst\u00e4ndig in mich eingeh\u00fcllt?", "tokens": ["Und", "sich", "selb\u00b7st\u00e4n\u00b7dig", "in", "mich", "ein\u00b7ge\u00b7h\u00fcllt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Luft, Himmel, Erde, Meer, Gluth, Felder, W\u00e4lder, Klippen wissen", "tokens": ["Luft", ",", "Him\u00b7mel", ",", "Er\u00b7de", ",", "Meer", ",", "Gluth", ",", "Fel\u00b7der", ",", "W\u00e4l\u00b7der", ",", "Klip\u00b7pen", "wis\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.11": {"text": "Mit stummer Zunge nachzusprechen,", "tokens": ["Mit", "stum\u00b7mer", "Zun\u00b7ge", "nach\u00b7zu\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df sie gesehn die Sonne stehn,", "tokens": ["Da\u00df", "sie", "ge\u00b7sehn", "die", "Son\u00b7ne", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Gew\u00f6lkte Feuers\u00e4ulen gehn,", "tokens": ["Ge\u00b7w\u00f6lk\u00b7te", "Feu\u00b7er\u00b7s\u00e4u\u00b7len", "gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Felsen bersten, Klippen brechen,", "tokens": ["Die", "Fel\u00b7sen", "bers\u00b7ten", ",", "Klip\u00b7pen", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Den Regen Brot, die Wellen Mauern werden.", "tokens": ["Den", "Re\u00b7gen", "Brot", ",", "die", "Wel\u00b7len", "Mau\u00b7ern", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Weh! weh mir Asien! ach weh!", "tokens": ["Weh", "!", "weh", "mir", "A\u00b7sien", "!", "ach", "weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "PPER", "NE", "$.", "XY", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Stand Jemand auf dem Schauplatz dieser Erden", "tokens": ["Stand", "Je\u00b7mand", "auf", "dem", "Schau\u00b7platz", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So hoch gepflanzt zur Ehrenh\u00f6h'?", "tokens": ["So", "hoch", "ge\u00b7pflanzt", "zur", "Eh\u00b7ren\u00b7h\u00f6h'", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Mund hat Kirch' und Volk den Gottesdienst gelehrt;", "tokens": ["Mein", "Mund", "hat", "Kirch'", "und", "Volk", "den", "Got\u00b7tes\u00b7dienst", "ge\u00b7lehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "KON", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Welt hat unsern Arm als Kronenherrn verehrt.", "tokens": ["Die", "Welt", "hat", "un\u00b7sern", "Arm", "als", "Kro\u00b7nen\u00b7herrn", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Das zw\u00f6lfbekr\u00f6nte Haupt, des Halses Alabaster", "tokens": ["Das", "zw\u00f6lf\u00b7be\u00b7kr\u00f6n\u00b7te", "Haupt", ",", "des", "Hal\u00b7ses", "A\u00b7la\u00b7bas\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Pfl\u00fcgt unter Gogs und Magogs Joch;", "tokens": ["Pfl\u00fcgt", "un\u00b7ter", "Gogs", "und", "Ma\u00b7gogs", "Joch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "KON", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der freie Nacken ist verkoppelt an die Laster,", "tokens": ["Der", "frei\u00b7e", "Na\u00b7cken", "ist", "ver\u00b7kop\u00b7pelt", "an", "die", "Las\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor denen ich kaum athme noch.", "tokens": ["Vor", "de\u00b7nen", "ich", "kaum", "ath\u00b7me", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Zepter und die Hand, die sonst nicht m\u00f6rderisch mi\u00dfhandelt,", "tokens": ["Der", "Zep\u00b7ter", "und", "die", "Hand", ",", "die", "sonst", "nicht", "m\u00f6r\u00b7de\u00b7risch", "mi\u00df\u00b7han\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PRELS", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Hat sich mir in Metall, blutdurstig Erz verwandelt;", "tokens": ["Hat", "sich", "mir", "in", "Me\u00b7tall", ",", "blut\u00b7durs\u00b7tig", "Erz", "ver\u00b7wan\u00b7delt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PPER", "APPR", "NN", "$,", "ADJD", "NN", "VVPP", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das d\u00fcrre Herze schwimmt in Flamm' und Gl\u00fcth;", "tokens": ["Das", "d\u00fcr\u00b7re", "Her\u00b7ze", "schwimmt", "in", "Flamm'", "und", "Gl\u00fcth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Glieder Ketten schwirr'n, die st\u00e4hlernen Gelenk' erzittern,", "tokens": ["Der", "Glie\u00b7der", "Ket\u00b7ten", "schwirr'n", ",", "die", "st\u00e4h\u00b7ler\u00b7nen", "Ge\u00b7lenk'", "er\u00b7zit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.9": {"text": "Der steinern-schwere Fu\u00df tritt und zerknickt durch sein Erbittern;", "tokens": ["Der", "stei\u00b7nern\u00b7schwe\u00b7re", "Fu\u00df", "tritt", "und", "zer\u00b7knickt", "durch", "sein", "Er\u00b7bit\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Die treuge Zunge leckt geliefert Blut.", "tokens": ["Die", "treu\u00b7ge", "Zun\u00b7ge", "leckt", "ge\u00b7lie\u00b7fert", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.7": {"line.1": {"text": "Fragt, Sterbliche, nach Kind- und Elternm\u00f6rdern,", "tokens": ["Fragt", ",", "Sterb\u00b7li\u00b7che", ",", "nach", "Kin\u00b7d", "und", "El\u00b7tern\u00b7m\u00f6r\u00b7dern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und die durch Dolch und Gift und Strang und Schwert", "tokens": ["Und", "die", "durch", "Dolch", "und", "Gift", "und", "Strang", "und", "Schwert"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Freunde Reih' und Br\u00fcderschaar begehrt,", "tokens": ["Der", "Freun\u00b7de", "Reih'", "und", "Br\u00fc\u00b7der\u00b7schaar", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In's Beinhaus f\u00fcr bestimmte Zeit zu f\u00f6rdern!", "tokens": ["In's", "Be\u00b7in\u00b7haus", "f\u00fcr", "be\u00b7stimm\u00b7te", "Zeit", "zu", "f\u00f6r\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Fragt, F\u00fcrsten, fraget nach nach denen, die die Klauen", "tokens": ["Fragt", ",", "F\u00fcrs\u00b7ten", ",", "fra\u00b7get", "nach", "nach", "de\u00b7nen", ",", "die", "die", "Klau\u00b7en"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "APPR", "APPR", "PRELS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um Lust, zu herrschen, durch des Herrschers Brust gehauen!", "tokens": ["Um", "Lust", ",", "zu", "herr\u00b7schen", ",", "durch", "des", "Herr\u00b7schers", "Brust", "ge\u00b7hau\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PTKZU", "VVINF", "$,", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ach, tausend W\u00fcrmer wohl, die also sich vergangen,", "tokens": ["Ach", ",", "tau\u00b7send", "W\u00fcr\u00b7mer", "wohl", ",", "die", "al\u00b7so", "sich", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "CARD", "NN", "ADV", "$,", "PRELS", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Aus meinem Schoo\u00df' entsprangen!", "tokens": ["Aus", "mei\u00b7nem", "Schoo\u00df'", "ent\u00b7spran\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.10": {"text": "Blitzet! ach, blitzet! ach, Wolken und machet von den umfesselnden Lastern mich los!", "tokens": ["Blit\u00b7zet", "!", "ach", ",", "blit\u00b7zet", "!", "ach", ",", "Wol\u00b7ken", "und", "ma\u00b7chet", "von", "den", "um\u00b7fes\u00b7seln\u00b7den", "Las\u00b7tern", "mich", "los", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "XY", "$,", "VVFIN", "$.", "XY", "$,", "NN", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "+--+--+--+-+--+--+--+", "measure": "dactylic.tri.plus"}, "line.11": {"text": "Donner! ach, Donner! zerschlag' und zersplittre jedes in einen zetr\u00fcmmerten Klo\u00df!", "tokens": ["Don\u00b7ner", "!", "ach", ",", "Don\u00b7ner", "!", "zer\u00b7schlag'", "und", "zer\u00b7splitt\u00b7re", "je\u00b7des", "in", "ei\u00b7nen", "ze\u00b7tr\u00fcm\u00b7mer\u00b7ten", "Klo\u00df", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "XY", "$,", "NN", "$.", "VVFIN", "KON", "VVFIN", "PIAT", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+-+--+--+--+", "measure": "dactylic.tri.plus"}}, "stanza.8": {"line.1": {"text": "Weh! weh mir Asien! ach weh!", "tokens": ["Weh", "!", "weh", "mir", "A\u00b7sien", "!", "ach", "weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "PPER", "NE", "$.", "XY", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Weh mir! \u2013 Ach! wo ich mich vermaledeien,", "tokens": ["Weh", "mir", "!", "\u2013", "Ach", "!", "wo", "ich", "mich", "ver\u00b7ma\u00b7le\u00b7dei\u00b7en", ","], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$.", "$(", "ITJ", "$.", "PWAV", "PPER", "PRF", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wo ich bei dieser Schwermuthssee,", "tokens": ["Wo", "ich", "bei", "die\u00b7ser", "Schwer\u00b7muths\u00b7see", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Bei so viel Ach selbst mein bethr\u00e4nt Gesicht verspeien,", "tokens": ["Bei", "so", "viel", "Ach", "selbst", "mein", "be\u00b7thr\u00e4nt", "Ge\u00b7sicht", "ver\u00b7spei\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "PIAT", "NN", "ADV", "PPOSAT", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Wo ich mich selbst mit Heul'n und Zeterrufen", "tokens": ["Wo", "ich", "mich", "selbst", "mit", "Heul'n", "und", "Ze\u00b7ter\u00b7ru\u00b7fen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "PRF", "ADV", "APPR", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Durch strengen Urtheilsspruch verdammen kann,", "tokens": ["Durch", "stren\u00b7gen", "Ur\u00b7theils\u00b7spruch", "ver\u00b7dam\u00b7men", "kann", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.7": {"text": "So nimm dies lechzend Ach, best\u00fcrzter Abgrund, an!", "tokens": ["So", "nimm", "dies", "lech\u00b7zend", "Ach", ",", "be\u00b7st\u00fcrz\u00b7ter", "Ab\u00b7grund", ",", "an", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VVIMP", "PDS", "ADJD", "ITJ", "$,", "ADJA", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Best\u00fcrzter Abgrund! \u2013 O die Glieder triefen", "tokens": ["Be\u00b7st\u00fcrz\u00b7ter", "Ab\u00b7grund", "!", "\u2013", "O", "die", "Glie\u00b7der", "trie\u00b7fen"], "token_info": ["word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "$(", "NE", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Voll Angstschwei\u00df! \u2013 Ach, des Achs! \u2013 der laue Brunn der d\u00fcrren Adern schwellt", "tokens": ["Voll", "A\u00b7ngstschwei\u00df", "!", "\u2013", "Ach", ",", "des", "Achs", "!", "\u2013", "der", "lau\u00b7e", "Brunn", "der", "d\u00fcr\u00b7ren", "A\u00b7dern", "schwellt"], "token_info": ["word", "word", "punct", "punct", "word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADJD", "NN", "$.", "$(", "ITJ", "$,", "ART", "NN", "$.", "$(", "ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.10": {"text": "Den Gischt der Purpurfluth! Mein Blutschaum schreibt mein Elend in den Sand!", "tokens": ["Den", "Gischt", "der", "Pur\u00b7pur\u00b7fluth", "!", "Mein", "Blut\u00b7schaum", "schreibt", "mein", "E\u00b7lend", "in", "den", "Sand", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$.", "PPOSAT", "NN", "VVFIN", "PPOSAT", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.11": {"text": "Entthronte K\u00f6niginn! entzepterte Beherrscherinn der Welt!", "tokens": ["Ent\u00b7thron\u00b7te", "K\u00f6\u00b7ni\u00b7ginn", "!", "ent\u00b7zep\u00b7ter\u00b7te", "Be\u00b7herr\u00b7sche\u00b7rinn", "der", "Welt", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "ADJA", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+-+-+", "measure": "iambic.octa.plus"}, "line.12": {"text": "Gest\u00fcrztes Asien! aus Ichts in Nichts und Staub verstobnes Land!", "tokens": ["Ge\u00b7st\u00fcrz\u00b7tes", "A\u00b7sien", "!", "aus", "Ichts", "in", "Nichts", "und", "Staub", "ver\u00b7stob\u00b7nes", "Land", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$.", "APPR", "PIS", "APPR", "PIS", "KON", "NN", "ADJA", "NN", "$."], "meter": "-+-+--+-+-+-+-+", "measure": "iambic.septa.relaxed"}, "line.13": {"text": "Ja wohl, aus Ichts, als mein gekr\u00f6ntes Haupt", "tokens": ["Ja", "wohl", ",", "aus", "Ichts", ",", "als", "mein", "ge\u00b7kr\u00f6n\u00b7tes", "Haupt"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$,", "APPR", "PIS", "$,", "KOUS", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.14": {"text": "Ein Haupt so viel gekr\u00f6nter H\u00e4upter war,", "tokens": ["Ein", "Haupt", "so", "viel", "ge\u00b7kr\u00f6n\u00b7ter", "H\u00e4up\u00b7ter", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "ADJA", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.15": {"text": "Als ich noch mit Siegspalmen war belaubt", "tokens": ["Als", "ich", "noch", "mit", "Siegs\u00b7pal\u00b7men", "war", "be\u00b7laubt"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "APPR", "NN", "VAFIN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.16": {"text": "Und aller Welt Gesetze reichte dar,", "tokens": ["Und", "al\u00b7ler", "Welt", "Ge\u00b7set\u00b7ze", "reich\u00b7te", "dar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "VVFIN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.17": {"text": "Als noch, gesenkt zu diesen F\u00fc\u00dfen,", "tokens": ["Als", "noch", ",", "ge\u00b7senkt", "zu", "die\u00b7sen", "F\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "$,", "VVPP", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.18": {"text": "Europens Haupt und Afrika mein Zepter mu\u00dfte k\u00fcssen,", "tokens": ["Eu\u00b7ro\u00b7pens", "Haupt", "und", "Af\u00b7ri\u00b7ka", "mein", "Zep\u00b7ter", "mu\u00df\u00b7te", "k\u00fcs\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "KON", "NE", "PPOSAT", "NN", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.19": {"text": "Als mein Gebot, wie Stahl und Gluth, durchdrang", "tokens": ["Als", "mein", "Ge\u00b7bot", ",", "wie", "Stahl", "und", "Gluth", ",", "durch\u00b7drang"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct", "word"], "pos": ["KOUS", "PPOSAT", "NN", "$,", "PWAV", "NN", "KON", "NN", "$,", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.20": {"text": "Und L\u00e4nder zwang.", "tokens": ["Und", "L\u00e4n\u00b7der", "zwang", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "NN", "VVFIN", "$."], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.9": {"line.1": {"text": "Ach, aber ach! \u2013 So hoch als ich beim Tugendgipfel", "tokens": ["Ach", ",", "a\u00b7ber", "ach", "!", "\u2013", "So", "hoch", "als", "ich", "beim", "Tu\u00b7gend\u00b7gip\u00b7fel"], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ADV", "ADV", "$.", "$(", "ADV", "ADJD", "KOKOM", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "In goldgestickten Kleidern stand,", "tokens": ["In", "gold\u00b7ge\u00b7stick\u00b7ten", "Klei\u00b7dern", "stand", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So tief hat sich das Spiel verwandt.", "tokens": ["So", "tief", "hat", "sich", "das", "Spiel", "ver\u00b7wandt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VAFIN", "PRF", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "So starb mein Ruhm! so schl\u00e4gt die Zeit die gr\u00fcnen Wipfel", "tokens": ["So", "starb", "mein", "Ruhm", "!", "so", "schl\u00e4gt", "die", "Zeit", "die", "gr\u00fc\u00b7nen", "Wip\u00b7fel"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPOSAT", "NN", "$.", "ADV", "VVFIN", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Von den bejahrten Cedern ab.", "tokens": ["Von", "den", "be\u00b7jahr\u00b7ten", "Ce\u00b7dern", "ab", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Man schm\u00fcckt mich je noch wohl mit diesem Purpurrocke,", "tokens": ["Man", "schm\u00fcckt", "mich", "je", "noch", "wohl", "mit", "die\u00b7sem", "Pur\u00b7pur\u00b7ro\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "ADV", "ADV", "ADV", "APPR", "PDAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Mit Infuln, Kron' und K\u00f6nigsstab", "tokens": ["Mit", "In\u00b7fuln", ",", "Kron'", "und", "K\u00f6\u00b7nigs\u00b7stab"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Hals, Achseln, H\u00e4nd' und Haupt, wo man mit solcher Schminke", "tokens": ["Hals", ",", "Ach\u00b7seln", ",", "H\u00e4nd'", "und", "Haupt", ",", "wo", "man", "mit", "sol\u00b7cher", "Schmin\u00b7ke"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "KON", "NN", "$,", "PWAV", "PIS", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Mich nicht blos sp\u00f6ttisch schminkt und \u00e4ffet und geheiht.", "tokens": ["Mich", "nicht", "blos", "sp\u00f6t\u00b7tisch", "schminkt", "und", "\u00e4f\u00b7fet", "und", "ge\u00b7heiht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "ADV", "ADJD", "VVFIN", "KON", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch auch gesetzt, da\u00df dies Besch\u00f6nungskleid", "tokens": ["Doch", "auch", "ge\u00b7setzt", ",", "da\u00df", "dies", "Be\u00b7sch\u00f6\u00b7nungs\u00b7kleid"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "ADV", "VVPP", "$,", "KOUS", "PDS", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Mich nicht beschimpft,", "tokens": ["Mich", "nicht", "be\u00b7schimpft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "So trag' ich's doch nur zur Vermummung meiner Flecke,", "tokens": ["So", "trag'", "ich's", "doch", "nur", "zur", "Ver\u00b7mum\u00b7mung", "mei\u00b7ner", "Fle\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ADV", "APPRART", "NN", "PPOSAT", "NN", "$,"], "meter": "-+-++--+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.8": {"text": "Zur Brand- und Schandmals-Schmink' und meiner Schalkheitsdecke,", "tokens": ["Zur", "Bran\u00b7d", "und", "Schand\u00b7mals\u00b7Schmink'", "und", "mei\u00b7ner", "Schalk\u00b7heits\u00b7de\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "TRUNC", "KON", "NN", "KON", "PPOSAT", "NN", "$,"], "meter": "-+--+-+-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.9": {"text": "Wiewohl ich wei\u00df, da\u00df man die Nase r\u00fcmpft", "tokens": ["Wie\u00b7wohl", "ich", "wei\u00df", ",", "da\u00df", "man", "die", "Na\u00b7se", "r\u00fcmpft"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "$,", "KOUS", "PIS", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Und M\u00e4uler auf mich flennet,", "tokens": ["Und", "M\u00e4u\u00b7ler", "auf", "mich", "flen\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "APPR", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.11": {"text": "Ich wei\u00df nicht, wie? mich nennet.", "tokens": ["Ich", "wei\u00df", "nicht", ",", "wie", "?", "mich", "nen\u00b7net", "."], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "$,", "PWAV", "$.", "PPER", "VVFIN", "$."], "meter": "-+-++--", "measure": "unknown.measure.tri"}, "line.12": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.13": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}}, "stanza.11": {"line.1": {"text": "Mich schmerzt's, und ich beschmerz' es auch mit diesem langen Seufzergalme,", "tokens": ["Mich", "schmerzt's", ",", "und", "ich", "be\u00b7schmer\u00b7z'", "es", "auch", "mit", "die\u00b7sem", "lan\u00b7gen", "Seuf\u00b7zer\u00b7gal\u00b7me", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "KON", "PPER", "VVFIN", "PPER", "ADV", "APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-+-+-+-", "measure": "iambic.octa.plus.relaxed"}, "line.2": {"text": "Wenn ich mich, wie aus einem Traum' und Qualme,", "tokens": ["Wenn", "ich", "mich", ",", "wie", "aus", "ei\u00b7nem", "Traum'", "und", "Qual\u00b7me", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "$,", "PWAV", "APPR", "ART", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Auf mich, als ich noch in der Bl\u00fcthe war, besinne.", "tokens": ["Auf", "mich", ",", "als", "ich", "noch", "in", "der", "Bl\u00fc\u00b7the", "war", ",", "be\u00b7sin\u00b7ne", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "PPER", "$,", "KOUS", "PPER", "ADV", "APPR", "ART", "NN", "VAFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "War ich nicht, Asien, die gr\u00f6\u00dft' und \u00e4ltst' und sch\u00f6nste meiner Schwestern?", "tokens": ["War", "ich", "nicht", ",", "A\u00b7sien", ",", "die", "gr\u00f6\u00dft'", "und", "\u00e4lt\u00b7st'", "und", "sch\u00f6ns\u00b7te", "mei\u00b7ner", "Schwes\u00b7tern", "?"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "$,", "NE", "$,", "PRELS", "ADJD", "KON", "ADJD", "KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "--+-+-+-+--+-+-+-", "measure": "iambic.septa.relaxed"}, "line.5": {"text": "Hat Neid und Geifersucht mich vor der Themis Richtsthul k\u00f6nnen l\u00e4stern?", "tokens": ["Hat", "Neid", "und", "Gei\u00b7fer\u00b7sucht", "mich", "vor", "der", "The\u00b7mis", "Richtst\u00b7hul", "k\u00f6n\u00b7nen", "l\u00e4s\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PRF", "APPR", "ART", "ADJA", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-+-+-", "measure": "iambic.octa.plus"}, "line.6": {"text": "Der Menschen Ahnherr hielt mich erblich inne.", "tokens": ["Der", "Men\u00b7schen", "Ahn\u00b7herr", "hielt", "mich", "er\u00b7blich", "in\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "PPER", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+--+--", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Hat alles All, das Ost und West und S\u00fcd und Nord nicht schlie\u00dfen,", "tokens": ["Hat", "al\u00b7les", "All", ",", "das", "Ost", "und", "West", "und", "S\u00fcd", "und", "Nord", "nicht", "schlie\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,", "ART", "NN", "KON", "NN", "KON", "NN", "KON", "NE", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.8": {"text": "Mich selbst nicht oft mit seinem Glanz erf\u00fcllt", "tokens": ["Mich", "selbst", "nicht", "oft", "mit", "sei\u00b7nem", "Glanz", "er\u00b7f\u00fcllt"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "ADV", "PTKNEG", "ADV", "APPR", "PPOSAT", "NN", "VVPP"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.9": {"text": "Und sich selbst\u00e4ndig in mich eingeh\u00fcllt?", "tokens": ["Und", "sich", "selb\u00b7st\u00e4n\u00b7dig", "in", "mich", "ein\u00b7ge\u00b7h\u00fcllt", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRF", "ADJD", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.10": {"text": "Luft, Himmel, Erde, Meer, Gluth, Felder, W\u00e4lder, Klippen wissen", "tokens": ["Luft", ",", "Him\u00b7mel", ",", "Er\u00b7de", ",", "Meer", ",", "Gluth", ",", "Fel\u00b7der", ",", "W\u00e4l\u00b7der", ",", "Klip\u00b7pen", "wis\u00b7sen"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "$,", "NN", "VVINF"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.11": {"text": "Mit stummer Zunge nachzusprechen,", "tokens": ["Mit", "stum\u00b7mer", "Zun\u00b7ge", "nach\u00b7zu\u00b7spre\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVIZU", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df sie gesehn die Sonne stehn,", "tokens": ["Da\u00df", "sie", "ge\u00b7sehn", "die", "Son\u00b7ne", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VVPP", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "Gew\u00f6lkte Feuers\u00e4ulen gehn,", "tokens": ["Ge\u00b7w\u00f6lk\u00b7te", "Feu\u00b7er\u00b7s\u00e4u\u00b7len", "gehn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.14": {"text": "Die Felsen bersten, Klippen brechen,", "tokens": ["Die", "Fel\u00b7sen", "bers\u00b7ten", ",", "Klip\u00b7pen", "bre\u00b7chen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.15": {"text": "Den Regen Brot, die Wellen Mauern werden.", "tokens": ["Den", "Re\u00b7gen", "Brot", ",", "die", "Wel\u00b7len", "Mau\u00b7ern", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.12": {"line.1": {"text": "Weh! weh mir Asien! ach weh!", "tokens": ["Weh", "!", "weh", "mir", "A\u00b7sien", "!", "ach", "weh", "!"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$.", "ADV", "PPER", "NE", "$.", "XY", "PTKVZ", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Stand Jemand auf dem Schauplatz dieser Erden", "tokens": ["Stand", "Je\u00b7mand", "auf", "dem", "Schau\u00b7platz", "die\u00b7ser", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PIS", "APPR", "ART", "NN", "PDAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "So hoch gepflanzt zur Ehrenh\u00f6h'?", "tokens": ["So", "hoch", "ge\u00b7pflanzt", "zur", "Eh\u00b7ren\u00b7h\u00f6h'", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVPP", "APPRART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mein Mund hat Kirch' und Volk den Gottesdienst gelehrt;", "tokens": ["Mein", "Mund", "hat", "Kirch'", "und", "Volk", "den", "Got\u00b7tes\u00b7dienst", "ge\u00b7lehrt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "NN", "KON", "NN", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Die Welt hat unsern Arm als Kronenherrn verehrt.", "tokens": ["Die", "Welt", "hat", "un\u00b7sern", "Arm", "als", "Kro\u00b7nen\u00b7herrn", "ver\u00b7ehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPOSAT", "NN", "KOUS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.13": {"line.1": {"text": "Das zw\u00f6lfbekr\u00f6nte Haupt, des Halses Alabaster", "tokens": ["Das", "zw\u00f6lf\u00b7be\u00b7kr\u00f6n\u00b7te", "Haupt", ",", "des", "Hal\u00b7ses", "A\u00b7la\u00b7bas\u00b7ter"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "ART", "NN", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Pfl\u00fcgt unter Gogs und Magogs Joch;", "tokens": ["Pfl\u00fcgt", "un\u00b7ter", "Gogs", "und", "Ma\u00b7gogs", "Joch", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NE", "KON", "NE", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der freie Nacken ist verkoppelt an die Laster,", "tokens": ["Der", "frei\u00b7e", "Na\u00b7cken", "ist", "ver\u00b7kop\u00b7pelt", "an", "die", "Las\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "VVPP", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vor denen ich kaum athme noch.", "tokens": ["Vor", "de\u00b7nen", "ich", "kaum", "ath\u00b7me", "noch", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PPER", "ADV", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Zepter und die Hand, die sonst nicht m\u00f6rderisch mi\u00dfhandelt,", "tokens": ["Der", "Zep\u00b7ter", "und", "die", "Hand", ",", "die", "sonst", "nicht", "m\u00f6r\u00b7de\u00b7risch", "mi\u00df\u00b7han\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "KON", "ART", "NN", "$,", "PRELS", "ADV", "PTKNEG", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.6": {"text": "Hat sich mir in Metall, blutdurstig Erz verwandelt;", "tokens": ["Hat", "sich", "mir", "in", "Me\u00b7tall", ",", "blut\u00b7durs\u00b7tig", "Erz", "ver\u00b7wan\u00b7delt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "PRF", "PPER", "APPR", "NN", "$,", "ADJD", "NN", "VVPP", "$."], "meter": "-+--++-+-+-+-", "measure": "iambic.hexa.relaxed"}, "line.7": {"text": "Das d\u00fcrre Herze schwimmt in Flamm' und Gl\u00fcth;", "tokens": ["Das", "d\u00fcr\u00b7re", "Her\u00b7ze", "schwimmt", "in", "Flamm'", "und", "Gl\u00fcth", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.8": {"text": "Der Glieder Ketten schwirr'n, die st\u00e4hlernen Gelenk' erzittern,", "tokens": ["Der", "Glie\u00b7der", "Ket\u00b7ten", "schwirr'n", ",", "die", "st\u00e4h\u00b7ler\u00b7nen", "Ge\u00b7lenk'", "er\u00b7zit\u00b7tern", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.9": {"text": "Der steinern-schwere Fu\u00df tritt und zerknickt durch sein Erbittern;", "tokens": ["Der", "stei\u00b7nern\u00b7schwe\u00b7re", "Fu\u00df", "tritt", "und", "zer\u00b7knickt", "durch", "sein", "Er\u00b7bit\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "KON", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-+-", "measure": "iambic.septa"}, "line.10": {"text": "Die treuge Zunge leckt geliefert Blut.", "tokens": ["Die", "treu\u00b7ge", "Zun\u00b7ge", "leckt", "ge\u00b7lie\u00b7fert", "Blut", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "VVPP", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.14": {"line.1": {"text": "Fragt, Sterbliche, nach Kind- und Elternm\u00f6rdern,", "tokens": ["Fragt", ",", "Sterb\u00b7li\u00b7che", ",", "nach", "Kin\u00b7d", "und", "El\u00b7tern\u00b7m\u00f6r\u00b7dern", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "NN", "$,", "APPR", "TRUNC", "KON", "NN", "$,"], "meter": "-+---+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Und die durch Dolch und Gift und Strang und Schwert", "tokens": ["Und", "die", "durch", "Dolch", "und", "Gift", "und", "Strang", "und", "Schwert"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "APPR", "NN", "KON", "NN", "KON", "NN", "KON", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.3": {"text": "Der Freunde Reih' und Br\u00fcderschaar begehrt,", "tokens": ["Der", "Freun\u00b7de", "Reih'", "und", "Br\u00fc\u00b7der\u00b7schaar", "be\u00b7gehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "KON", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.4": {"text": "In's Beinhaus f\u00fcr bestimmte Zeit zu f\u00f6rdern!", "tokens": ["In's", "Be\u00b7in\u00b7haus", "f\u00fcr", "be\u00b7stimm\u00b7te", "Zeit", "zu", "f\u00f6r\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "ADJA", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-+-+-", "measure": "trochaic.hexa"}, "line.5": {"text": "Fragt, F\u00fcrsten, fraget nach nach denen, die die Klauen", "tokens": ["Fragt", ",", "F\u00fcrs\u00b7ten", ",", "fra\u00b7get", "nach", "nach", "de\u00b7nen", ",", "die", "die", "Klau\u00b7en"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$,", "VVFIN", "APPR", "APPR", "PRELS", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Um Lust, zu herrschen, durch des Herrschers Brust gehauen!", "tokens": ["Um", "Lust", ",", "zu", "herr\u00b7schen", ",", "durch", "des", "Herr\u00b7schers", "Brust", "ge\u00b7hau\u00b7en", "!"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "NN", "$,", "PTKZU", "VVINF", "$,", "APPR", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ach, tausend W\u00fcrmer wohl, die also sich vergangen,", "tokens": ["Ach", ",", "tau\u00b7send", "W\u00fcr\u00b7mer", "wohl", ",", "die", "al\u00b7so", "sich", "ver\u00b7gan\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "CARD", "NN", "ADV", "$,", "PRELS", "ADV", "PRF", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Aus meinem Schoo\u00df' entsprangen!", "tokens": ["Aus", "mei\u00b7nem", "Schoo\u00df'", "ent\u00b7spran\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.9": {"text": "\u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013", "tokens": ["\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013", "\u2013"], "token_info": ["punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct", "punct"], "pos": ["$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$(", "$("]}, "line.10": {"text": "Blitzet! ach, blitzet! ach, Wolken und machet von den umfesselnden Lastern mich los!", "tokens": ["Blit\u00b7zet", "!", "ach", ",", "blit\u00b7zet", "!", "ach", ",", "Wol\u00b7ken", "und", "ma\u00b7chet", "von", "den", "um\u00b7fes\u00b7seln\u00b7den", "Las\u00b7tern", "mich", "los", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "XY", "$,", "VVFIN", "$.", "XY", "$,", "NN", "KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "PPER", "PTKVZ", "$."], "meter": "+--+--+--+-+--+--+--+", "measure": "dactylic.tri.plus"}, "line.11": {"text": "Donner! ach, Donner! zerschlag' und zersplittre jedes in einen zetr\u00fcmmerten Klo\u00df!", "tokens": ["Don\u00b7ner", "!", "ach", ",", "Don\u00b7ner", "!", "zer\u00b7schlag'", "und", "zer\u00b7splitt\u00b7re", "je\u00b7des", "in", "ei\u00b7nen", "ze\u00b7tr\u00fcm\u00b7mer\u00b7ten", "Klo\u00df", "!"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "XY", "$,", "NN", "$.", "VVFIN", "KON", "VVFIN", "PIAT", "APPR", "ART", "ADJA", "NN", "$."], "meter": "+--+--+--+-+--+--+--+", "measure": "dactylic.tri.plus"}}}}}