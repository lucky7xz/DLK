{"dta.poem.2673": {"metadata": {"author": {"name": "M\u00fchlpfort, Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Trauer-Ode/  \n  Auf Hn. A. O. j\u00fcngsten S\u00f6hnlein A. Leich-  \n beg\u00e4ngnus/ den 9. Junii 1675.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1686", "urn": "urn:nbn:de:kobv:b4-20414-7", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es laufft der Natur zuwieder", "tokens": ["Es", "laufft", "der", "Na\u00b7tur", "zu\u00b7wie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "Ja/ ", "tokens": ["Ja", "/"], "token_info": ["word", "punct"], "pos": ["PTKANT", "$("], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Wenn wir unsrer Kinder Glieder", "tokens": ["Wenn", "wir", "uns\u00b7rer", "Kin\u00b7der", "Glie\u00b7der"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mit der Erden decken zu:", "tokens": ["Mit", "der", "Er\u00b7den", "de\u00b7cken", "zu", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Wenn gleich einem Regen-Bogen", "tokens": ["Wenn", "gleich", "ei\u00b7nem", "Re\u00b7gen\u00b7Bo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unser Hoffen mu\u00df vergehn/", "tokens": ["Un\u00b7ser", "Hof\u00b7fen", "mu\u00df", "ver\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und die Lust so man gepflogen", "tokens": ["Und", "die", "Lust", "so", "man", "ge\u00b7pflo\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADV", "PIS", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wir sehn auf der Bahre stehn.", "tokens": ["Wir", "sehn", "auf", "der", "Bah\u00b7re", "stehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Da\u00df sie uns die Augen schliessen", "tokens": ["Da\u00df", "sie", "uns", "die", "Au\u00b7gen", "schlies\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "PRF", "ART", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Ist der w\u00fcnschte Ziel und Zweck.", "tokens": ["Ist", "der", "w\u00fcnschte", "Ziel", "und", "Zweck", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wenn hingegen wir sie m\u00fcssen", "tokens": ["Wenn", "hin\u00b7ge\u00b7gen", "wir", "sie", "m\u00fcs\u00b7sen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "PPER", "PPER", "VMFIN"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Au\u00df den Augen tragen weg/", "tokens": ["Au\u00df", "den", "Au\u00b7gen", "tra\u00b7gen", "weg", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PTKVZ", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Scheint es der Vernunfft zwar bitter/", "tokens": ["Scheint", "es", "der", "Ver\u00b7nunfft", "zwar", "bit\u00b7ter", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "ADV", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und dem Hertzen schwer zu seyn/", "tokens": ["Und", "dem", "Hert\u00b7zen", "schwer", "zu", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "PTKZU", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df de\u00df Todes Ungewitter", "tokens": ["Da\u00df", "de\u00df", "To\u00b7des", "Un\u00b7ge\u00b7wit\u00b7ter"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Reist Gesetz und Ordnung ein.", "tokens": ["Reist", "Ge\u00b7setz", "und", "Ord\u00b7nung", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NN", "KON", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Aber wie auff gleich Gewichte", "tokens": ["A\u00b7ber", "wie", "auff", "gleich", "Ge\u00b7wich\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "APPR", "ADV", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Tod und Leben ist gelegt/", "tokens": ["Tod", "und", "Le\u00b7ben", "ist", "ge\u00b7legt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und das G\u00f6ttliche Gerichte", "tokens": ["Und", "das", "G\u00f6tt\u00b7li\u00b7che", "Ge\u00b7rich\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Nicht zu unterscheiden pflegt/", "tokens": ["Nicht", "zu", "un\u00b7ter\u00b7schei\u00b7den", "pflegt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Ob es an begrauten Haaren", "tokens": ["Ob", "es", "an", "be\u00b7grau\u00b7ten", "Haa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Seinenletzten Schlu\u00df vollzieht?", "tokens": ["Sei\u00b7nen\u00b7letz\u00b7ten", "Schlu\u00df", "voll\u00b7zieht", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Oder die wirfft auff die Bahren", "tokens": ["O\u00b7der", "die", "wirfft", "auff", "die", "Bah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PDS", "VVFIN", "APPR", "ART", "NN"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "So in ihrer ersten Bl\u00fcth?", "tokens": ["So", "in", "ih\u00b7rer", "ers\u00b7ten", "Bl\u00fcth", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Also m\u00fcssen wir auch dencken/", "tokens": ["Al\u00b7so", "m\u00fcs\u00b7sen", "wir", "auch", "den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df beym Eintrit in die Welt/", "tokens": ["Da\u00df", "beym", "Ein\u00b7trit", "in", "die", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "APPR", "ART", "NN", "$("], "meter": "+--+--+", "measure": "dactylic.tri"}, "line.3": {"text": "Ab- und Hinzug uns umbschrencken", "tokens": ["Ab", "und", "Hin\u00b7zug", "uns", "umbschren\u00b7cken"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["TRUNC", "KON", "NN", "PPER", "VVINF"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Und der Tod gefangen helt.", "tokens": ["Und", "der", "Tod", "ge\u00b7fan\u00b7gen", "helt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Es sind bald die Windel-Binden/", "tokens": ["Es", "sind", "bald", "die", "Win\u00b7del\u00b7Bin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "Fessel unsrer Sterbligkeit/", "tokens": ["Fes\u00b7sel", "uns\u00b7rer", "Ster\u00b7blig\u00b7keit", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und der Vorrath den wir finden/", "tokens": ["Und", "der", "Vor\u00b7rath", "den", "wir", "fin\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ART", "PPER", "VVINF", "$("], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.8": {"text": "Ist geh\u00e4ufftes Hertzeleid.", "tokens": ["Ist", "ge\u00b7h\u00e4uff\u00b7tes", "Hert\u00b7ze\u00b7leid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Thr\u00e4nen sind die ersten Wahren", "tokens": ["Thr\u00e4\u00b7nen", "sind", "die", "ers\u00b7ten", "Wah\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Und der letzte Sterbens-Zoll/", "tokens": ["Und", "der", "letz\u00b7te", "Ster\u00b7bens\u00b7Zoll", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Kummer w\u00e4chset mit den Jahren/", "tokens": ["Kum\u00b7mer", "w\u00e4ch\u00b7set", "mit", "den", "Jah\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Elend macht das Leben voll.", "tokens": ["E\u00b7lend", "macht", "das", "Le\u00b7ben", "voll", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ART", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So da\u00df man mu\u00df Beyfall geben/", "tokens": ["So", "da\u00df", "man", "mu\u00df", "Bey\u00b7fall", "ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "PIS", "VMFIN", "NN", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Was der Weisen Mund gelehrt/", "tokens": ["Was", "der", "Wei\u00b7sen", "Mund", "ge\u00b7lehrt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ART", "NN", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Da\u00df es besser gar nicht leben", "tokens": ["Da\u00df", "es", "bes\u00b7ser", "gar", "nicht", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD", "ADV", "PTKNEG", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Oder da\u00df es bald auffh\u00f6rt.", "tokens": ["O\u00b7der", "da\u00df", "es", "bald", "auff\u00b7h\u00f6rt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Denn die Freuden so wir haben/", "tokens": ["Denn", "die", "Freu\u00b7den", "so", "wir", "ha\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "ADV", "PPER", "VAFIN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Sind nur ein Sardinisch Gra\u00df/", "tokens": ["Sind", "nur", "ein", "Sar\u00b7di\u00b7nisch", "Gra\u00df", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ART", "NN", "NN", "$("], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.3": {"text": "Und de\u00df Gl\u00fcckes Gut und ", "tokens": ["Und", "de\u00df", "Gl\u00fc\u00b7ckes", "Gut", "und"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "ADJD", "KON"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Noch gebrechlicher als ", "tokens": ["Noch", "ge\u00b7brech\u00b7li\u00b7cher", "als"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ADJD", "KOKOM"], "meter": "+-+-++", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Auch der ", "tokens": ["Auch", "der"], "token_info": ["word", "word"], "pos": ["ADV", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.6": {"text": "Ist ein falscher Jrrwisch-Schein/", "tokens": ["Ist", "ein", "fal\u00b7scher", "Jrr\u00b7wischSchein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.7": {"text": "Der die Sinnen wird beth\u00f6ren", "tokens": ["Der", "die", "Sin\u00b7nen", "wird", "be\u00b7th\u00f6\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ART", "NN", "VAFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und in Laster sencken ein.", "tokens": ["Und", "in", "Las\u00b7ter", "sen\u00b7cken", "ein", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "NN", "VVFIN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Zwar ", "tokens": ["Zwar"], "token_info": ["word"], "pos": ["ADV"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "S\u00f6hne bauen das ", "tokens": ["S\u00f6h\u00b7ne", "bau\u00b7en", "das"], "token_info": ["word", "word", "word"], "pos": ["NN", "VVFIN", "ART"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Lassen uns viel Ruhm geniessen/", "tokens": ["Las\u00b7sen", "uns", "viel", "Ruhm", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PIAT", "NN", "VVPP", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Treten in der Eltern Recht/", "tokens": ["Tre\u00b7ten", "in", "der", "El\u00b7tern", "Recht", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sind nach h\u00e4uffigem Bem\u00fchen", "tokens": ["Sind", "nach", "h\u00e4uf\u00b7fi\u00b7gem", "Be\u00b7m\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Unsers m\u00fcden Alters Stab/", "tokens": ["Un\u00b7sers", "m\u00fc\u00b7den", "Al\u00b7ters", "Stab", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Heissen Ruhm und Namen bl\u00fchen", "tokens": ["Heis\u00b7sen", "Ruhm", "und", "Na\u00b7men", "bl\u00fc\u00b7hen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADJA", "NN", "KON", "NN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Wenn wir faulen in dem ", "tokens": ["Wenn", "wir", "fau\u00b7len", "in", "dem"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "VVFIN", "APPR", "ART"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Di\u00df sind irrdische ", "tokens": ["Di\u00df", "sind", "irr\u00b7di\u00b7sche"], "token_info": ["word", "word", "word"], "pos": ["PDS", "VAFIN", "ADJA"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.2": {"text": "Die auff keinen ", "tokens": ["Die", "auff", "kei\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["ART", "APPR", "PIAT"], "meter": "+-+-", "measure": "trochaic.di"}, "line.3": {"text": "Hoffnung/ so gar leicht kan wancken", "tokens": ["Hoff\u00b7nung", "/", "so", "gar", "leicht", "kan", "wan\u00b7cken"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "ADV", "ADV", "ADJD", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Die man offt verlassen schaut.", "tokens": ["Die", "man", "offt", "ver\u00b7las\u00b7sen", "schaut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Aber wenn sie au\u00df ber Wiegen", "tokens": ["A\u00b7ber", "wenn", "sie", "au\u00df", "ber", "Wie\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPER", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Gott in seine Armen nimmt/", "tokens": ["Gott", "in", "sei\u00b7ne", "Ar\u00b7men", "nimmt", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPOSAT", "NN", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Welch ein seeliges Vergn\u00fcgen", "tokens": ["Welch", "ein", "see\u00b7li\u00b7ges", "Ver\u00b7gn\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Ist den Eltern da bestimmt!", "tokens": ["Ist", "den", "El\u00b7tern", "da", "be\u00b7stimmt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ART", "NN", "ADV", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Niemand kan den ", "tokens": ["Nie\u00b7mand", "kan", "den"], "token_info": ["word", "word", "word"], "pos": ["PIS", "VMFIN", "ART"], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "Wenn der Himmel blitzt und kracht/", "tokens": ["Wenn", "der", "Him\u00b7mel", "blitzt", "und", "kracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df er Blumen/ die recht selten/", "tokens": ["Da\u00df", "er", "Blu\u00b7men", "/", "die", "recht", "sel\u00b7ten", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "$(", "ART", "ADJD", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Vor den andern nimmt in acht.", "tokens": ["Vor", "den", "an\u00b7dern", "nimmt", "in", "acht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "VVFIN", "APPR", "CARD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Sollen wir nicht GOttes Gnaden", "tokens": ["Sol\u00b7len", "wir", "nicht", "Got\u00b7tes", "Gna\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "PTKNEG", "NN", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Und grundlose G\u00fctigkeit", "tokens": ["Und", "grund\u00b7lo\u00b7se", "G\u00fc\u00b7tig\u00b7keit"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJA", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.7": {"text": "R\u00fchmen/ wenn vor Qual und Schaden", "tokens": ["R\u00fch\u00b7men", "/", "wenn", "vor", "Qual", "und", "Scha\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$(", "KOUS", "APPR", "NN", "KON", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Seine Hand uns fr\u00fch\u2019 befreyt?", "tokens": ["Sei\u00b7ne", "Hand", "uns", "fr\u00fch'", "be\u00b7freyt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "ADJD", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Eltern ihr d\u00fcrfft euch nicht k\u00fcmmern", "tokens": ["El\u00b7tern", "ihr", "d\u00fcrfft", "euch", "nicht", "k\u00fcm\u00b7mern"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.2": {"text": "Weiter f\u00fcr sein Wohlergehn/", "tokens": ["Wei\u00b7ter", "f\u00fcr", "sein", "Woh\u00b7ler\u00b7gehn", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wril nun in de\u00df Himmels-Zimmern", "tokens": ["Wril", "nun", "in", "de\u00df", "Him\u00b7mels\u00b7Zim\u00b7mern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Engel ihm zur Seiten stehn/", "tokens": ["En\u00b7gel", "ihm", "zur", "Sei\u00b7ten", "stehn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPRART", "NN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Au\u00df der Wiegen in die Erden", "tokens": ["Au\u00df", "der", "Wie\u00b7gen", "in", "die", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "APPR", "ART", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Hat er fr\u00fch\u2019 den Lauff vollbracht/", "tokens": ["Hat", "er", "fr\u00fch'", "den", "Lauff", "voll\u00b7bracht", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ART", "NN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Und soll einst verkl\u00e4ret werden", "tokens": ["Und", "soll", "einst", "ver\u00b7kl\u00e4\u00b7ret", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VMFIN", "ADV", "VVPP", "VAINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.8": {"text": "In der sch\u00f6nsten Sternen-Pracht.", "tokens": ["In", "der", "sch\u00f6ns\u00b7ten", "Ster\u00b7nen\u00b7Pracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Last die Thr\u00e4nen minder fliessen/", "tokens": ["Last", "die", "Thr\u00e4\u00b7nen", "min\u00b7der", "flies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Nennt den Tod ja nicht Verlust/", "tokens": ["Nennt", "den", "Tod", "ja", "nicht", "Ver\u00b7lust", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "PTKNEG", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Weil er jetzund kan geniessen/", "tokens": ["Weil", "er", "je\u00b7tzund", "kan", "ge\u00b7nies\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Statt der s\u00fcssen Mutter-Brust/", "tokens": ["Statt", "der", "s\u00fcs\u00b7sen", "Mut\u00b7ter\u00b7Brust", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Jsraels beliebte Quellen/", "tokens": ["Js\u00b7raels", "be\u00b7lieb\u00b7te", "Quel\u00b7len", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Die sein h\u00f6chstes Labsall seyn/", "tokens": ["Die", "sein", "h\u00f6chs\u00b7tes", "Lab\u00b7sall", "seyn", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "ADJA", "NN", "VAINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Die sein Unschulds-Kleid erhellen/", "tokens": ["Die", "sein", "Un\u00b7schulds\u00b7Kleid", "er\u00b7hel\u00b7len", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df es wie die Lilgen rein.", "tokens": ["Da\u00df", "es", "wie", "die", "Lil\u00b7gen", "rein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Gleich wie nur au\u00df schlechter Erden", "tokens": ["Gleich", "wie", "nur", "au\u00df", "schlech\u00b7ter", "Er\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KOKOM", "ADV", "APPR", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unser Anherr war erbaut/", "tokens": ["Un\u00b7ser", "An\u00b7herr", "war", "er\u00b7baut", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "VVPP", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und durch S\u00fcnde muste werden", "tokens": ["Und", "durch", "S\u00fcn\u00b7de", "mus\u00b7te", "wer\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "NN", "VMFIN", "VAINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wieder ihrer Scho\u00df vertraut:", "tokens": ["Wie\u00b7der", "ih\u00b7rer", "Scho\u00df", "ver\u00b7traut", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "So soll auch/ was Mensch ist/ sterben/", "tokens": ["So", "soll", "auch", "/", "was", "Mensch", "ist", "/", "ster\u00b7ben", "/"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "VMFIN", "ADV", "$(", "PWS", "NN", "VAFIN", "$(", "VVINF", "$("], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Doch nicht ewig untergehn;", "tokens": ["Doch", "nicht", "e\u00b7wig", "un\u00b7ter\u00b7gehn", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Denn es wird mit Christo erben", "tokens": ["Denn", "es", "wird", "mit", "Chris\u00b7to", "er\u00b7ben"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "VAFIN", "APPR", "NE", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und lebendig aufferstehn.", "tokens": ["Und", "le\u00b7ben\u00b7dig", "auf\u00b7fer\u00b7stehn", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVINF", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}}}}