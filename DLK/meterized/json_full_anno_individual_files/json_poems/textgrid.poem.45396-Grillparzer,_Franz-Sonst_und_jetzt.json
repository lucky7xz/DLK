{"textgrid.poem.45396": {"metadata": {"author": {"name": "Grillparzer, Franz", "birth": "N.A.", "death": "N.A."}, "title": "Sonst und jetzt", "genre": "verse", "period": "N.A.", "pub_year": 1831, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Solang die Ideen geordnet und st\u00e4t,", "tokens": ["So\u00b7lang", "die", "I\u00b7deen", "ge\u00b7ord\u00b7net", "und", "st\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zeugt von Kraft wohl die Originalit\u00e4t,", "tokens": ["Zeugt", "von", "Kraft", "wohl", "die", "O\u00b7rig\u00b7i\u00b7na\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Doch sind sie einmal gest\u00f6rt und im Flu\u00df,", "tokens": ["Doch", "sind", "sie", "ein\u00b7mal", "ge\u00b7st\u00f6rt", "und", "im", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "KON", "APPRART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist orginell jeder Hasenfu\u00df.", "tokens": ["Ist", "or\u00b7gi\u00b7nell", "je\u00b7der", "Ha\u00b7sen\u00b7fu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PIAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.2": {"line.1": {"text": "Solang die Ideen geordnet und st\u00e4t,", "tokens": ["So\u00b7lang", "die", "I\u00b7deen", "ge\u00b7ord\u00b7net", "und", "st\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVPP", "KON", "VVFIN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zeugt von Kraft wohl die Originalit\u00e4t,", "tokens": ["Zeugt", "von", "Kraft", "wohl", "die", "O\u00b7rig\u00b7i\u00b7na\u00b7li\u00b7t\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+--+--+-+", "measure": "trochaic.penta.relaxed"}, "line.3": {"text": "Doch sind sie einmal gest\u00f6rt und im Flu\u00df,", "tokens": ["Doch", "sind", "sie", "ein\u00b7mal", "ge\u00b7st\u00f6rt", "und", "im", "Flu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PPER", "ADV", "VVPP", "KON", "APPRART", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Ist orginell jeder Hasenfu\u00df.", "tokens": ["Ist", "or\u00b7gi\u00b7nell", "je\u00b7der", "Ha\u00b7sen\u00b7fu\u00df", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PIAT", "NN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}}}}