{"textgrid.poem.56257": {"metadata": {"author": {"name": "Chamisso, Adelbert von", "birth": "N.A.", "death": "N.A."}, "title": "Die goldene Zeit", "genre": "verse", "period": "N.A.", "pub_year": 1822, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "F\u00fcllt die Becher bis zum Rand,", "tokens": ["F\u00fcllt", "die", "Be\u00b7cher", "bis", "zum", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut, ihr Freunde, mir Bescheid:", "tokens": ["Tut", ",", "ihr", "Freun\u00b7de", ",", "mir", "Be\u00b7scheid", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das befreite Vaterland,", "tokens": ["Das", "be\u00b7frei\u00b7te", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die gute goldne Zeit!", "tokens": ["Und", "die", "gu\u00b7te", "gold\u00b7ne", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann der B\u00fcrger denkt und glaubt,", "tokens": ["Dann", "der", "B\u00fcr\u00b7ger", "denkt", "und", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Spricht und schreibt nun alles frei,", "tokens": ["Spricht", "und", "schreibt", "nun", "al\u00b7les", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Was die hohe Polizei", "tokens": ["Was", "die", "ho\u00b7he", "Po\u00b7li\u00b7zei"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Erst gepr\u00fcft hat und erlaubt.", "tokens": ["Erst", "ge\u00b7pr\u00fcft", "hat", "und", "er\u00b7laubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Du er\u00f6ffnest mir den Mund,", "tokens": ["Du", "er\u00b7\u00f6ff\u00b7nest", "mir", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du geschw\u00e4tz'ger Traubensaft,", "tokens": ["Du", "ge\u00b7schw\u00e4tz'\u00b7ger", "Trau\u00b7ben\u00b7saft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Wahrheit mach ich kund,", "tokens": ["Und", "die", "Wahr\u00b7heit", "mach", "ich", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "R\u00fccksichtslos mit freud'ger Kraft.", "tokens": ["R\u00fcck\u00b7sichts\u00b7los", "mit", "freu\u00b7d'\u00b7ger", "Kraft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Steigt die Sonne, wird es Tag,", "tokens": ["Steigt", "die", "Son\u00b7ne", ",", "wird", "es", "Tag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sinkt sie unter, wird es Nacht.", "tokens": ["Sinkt", "sie", "un\u00b7ter", ",", "wird", "es", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nehm vor Feuer sich in Acht,", "tokens": ["Nehm", "vor", "Feu\u00b7er", "sich", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PRF", "APPR", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wer sich nicht verbrennen mag.", "tokens": ["Wer", "sich", "nicht", "ver\u00b7bren\u00b7nen", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PWS", "PRF", "PTKNEG", "VVINF", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "Ungeschickt zum L\u00f6schen ist,", "tokens": ["Un\u00b7ge\u00b7schickt", "zum", "L\u00f6\u00b7schen", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer da \u00d6l gie\u00dft, wo es brennt;", "tokens": ["Wer", "da", "\u00d6l", "gie\u00dft", ",", "wo", "es", "brennt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NE", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Noch ist drum kein guter Christ,", "tokens": ["Noch", "ist", "drum", "kein", "gu\u00b7ter", "Christ", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "PIAT", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Der zu Mahom sich bekennt.", "tokens": ["Der", "zu", "Ma\u00b7hom", "sich", "be\u00b7kennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Scheut die Eule gleich das Licht,", "tokens": ["Scheut", "die", "Eu\u00b7le", "gleich", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00e4hrt sich's doch vorm Winde gut,", "tokens": ["F\u00e4hrt", "sich's", "doch", "vorm", "Win\u00b7de", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Besser noch mit Wind und Flut,", "tokens": ["Bes\u00b7ser", "noch", "mit", "Wind", "und", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Aber gegen beide nicht.", "tokens": ["A\u00b7ber", "ge\u00b7gen", "bei\u00b7de", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Wer nicht sehen kann, ist blind,", "tokens": ["Wer", "nicht", "se\u00b7hen", "kann", ",", "ist", "blind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVINF", "VMFIN", "$,", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer auf Kr\u00fccken geht, ist lahm;", "tokens": ["Wer", "auf", "Kr\u00fc\u00b7cken", "geht", ",", "ist", "lahm", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVFIN", "$,", "VAFIN", "PTKVZ", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Mancher redet in den Wind,", "tokens": ["Man\u00b7cher", "re\u00b7det", "in", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mancher geht, so wie er kam.", "tokens": ["Man\u00b7cher", "geht", ",", "so", "wie", "er", "kam", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gr\u00fcnt die Erde weit und breit,", "tokens": ["Gr\u00fcnt", "die", "Er\u00b7de", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Glaube nicht den Fr\u00fchling fern;", "tokens": ["Glau\u00b7be", "nicht", "den", "Fr\u00fch\u00b7ling", "fern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "R\u00fcckw\u00e4rts gehn die Krebse gern,", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "gehn", "die", "Kreb\u00b7se", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Aber vorw\u00e4rts eilt die Zeit.", "tokens": ["A\u00b7ber", "vor\u00b7w\u00e4rts", "eilt", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Zwar ist nicht das Dunkle klar,", "tokens": ["Zwar", "ist", "nicht", "das", "Dunk\u00b7le", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ist nicht, was gut ist, schlecht;", "tokens": ["Doch", "ist", "nicht", ",", "was", "gut", "ist", ",", "schlecht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn, was wahr ist, bleibt doch wahr,", "tokens": ["Denn", ",", "was", "wahr", "ist", ",", "bleibt", "doch", "wahr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und, was recht ist, bleibt doch recht.", "tokens": ["Und", ",", "was", "recht", "ist", ",", "bleibt", "doch", "recht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Goldes-\u00dcberflu\u00df macht reich,", "tokens": ["Gol\u00b7des\u00b7\u00dcber\u00b7flu\u00df", "macht", "reich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Aber Lumpen sind kein Geld.", "tokens": ["A\u00b7ber", "Lum\u00b7pen", "sind", "kein", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wer mit Steinen d\u00fcngt sein Feld,", "tokens": ["Wer", "mit", "Stei\u00b7nen", "d\u00fcngt", "sein", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Macht gar einen dummen Streich.", "tokens": ["Macht", "gar", "ei\u00b7nen", "dum\u00b7men", "Streich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "An der Zeit, ist nicht zu sp\u00e4t,", "tokens": ["An", "der", "Zeit", ",", "ist", "nicht", "zu", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VAFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch Geschehnes ist geschehn,", "tokens": ["Doch", "Ge\u00b7scheh\u00b7nes", "ist", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wer Disteln hat ges\u00e4t,", "tokens": ["Und", "wer", "Dis\u00b7teln", "hat", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird nicht Weizen reifen sehn.", "tokens": ["Wird", "nicht", "Wei\u00b7zen", "rei\u00b7fen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gestern war's, nun ist es heut,", "tokens": ["Ge\u00b7stern", "wa\u00b7r's", ",", "nun", "ist", "es", "heut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Morgen bringt auch seinen Lohn;", "tokens": ["Mor\u00b7gen", "bringt", "auch", "sei\u00b7nen", "Lohn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Kluge Leute wissen's schon,", "tokens": ["Klu\u00b7ge", "Leu\u00b7te", "wis\u00b7sen's", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nur sind Narren nicht gescheut.", "tokens": ["Nur", "sind", "Nar\u00b7ren", "nicht", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Und am besten wei\u00df, wer klagt,", "tokens": ["Und", "am", "bes\u00b7ten", "wei\u00df", ",", "wer", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PTKA", "ADJD", "VVFIN", "$,", "PWS", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Wo ihn dr\u00fcckt der eigne Schuh;", "tokens": ["Wo", "ihn", "dr\u00fcckt", "der", "eig\u00b7ne", "Schuh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer zuerst nur A gesagt,", "tokens": ["Wer", "zu\u00b7erst", "nur", "A", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Setzt vielleicht noch B hinzu;", "tokens": ["Setzt", "viel\u00b7leicht", "noch", "B", "hin\u00b7zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn, wie Adam Riese spricht,", "tokens": ["Denn", ",", "wie", "A\u00b7dam", "Rie\u00b7se", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zwei und zwei sind eben vier \u2013 \u2013 \u2013", "tokens": ["Zwei", "und", "zwei", "sind", "e\u00b7ben", "vier", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["CARD", "KON", "CARD", "VAFIN", "ADV", "CARD", "$(", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott! wer pocht an unsre T\u00fcr?", "tokens": ["Gott", "!", "wer", "pocht", "an", "uns\u00b7re", "T\u00fcr", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ihr, verratet mich nur nicht!", "tokens": ["Ihr", ",", "ver\u00b7ra\u00b7tet", "mich", "nur", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbhebt auf das verruchte Nest,", "tokens": ["\u00bb", "hebt", "auf", "das", "ver\u00b7ruch\u00b7te", "Nest", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Sie mi\u00dfbrauchen die Geduld.", "tokens": ["Sie", "mi\u00df\u00b7brau\u00b7chen", "die", "Ge\u00b7duld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setzt den Jakobiner fest,", "tokens": ["Setzt", "den", "Ja\u00b7ko\u00b7bi\u00b7ner", "fest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir sind Zeugen seiner Schuld;", "tokens": ["Wir", "sind", "Zeu\u00b7gen", "sei\u00b7ner", "Schuld", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er hat \u00f6ffentlich gelehrt:", "tokens": ["Er", "hat", "\u00f6f\u00b7fent\u00b7lich", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Zwei und zwei sind eben vier.\u00ab \u2013", "tokens": ["Zwei", "und", "zwei", "sind", "e\u00b7ben", "vier", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["CARD", "KON", "CARD", "VAFIN", "ADV", "CARD", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nein, ich sagte... \u00bbFort mit dir,", "tokens": ["Nein", ",", "ich", "sag\u00b7te", "...", "\u00bb", "Fort", "mit", "dir", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "$(", "$(", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df die Lehre keiner h\u00f6rt!\u00ab", "tokens": ["Da\u00df", "die", "Leh\u00b7re", "kei\u00b7ner", "h\u00f6rt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "F\u00fcllt die Becher bis zum Rand,", "tokens": ["F\u00fcllt", "die", "Be\u00b7cher", "bis", "zum", "Rand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "APPRART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Tut, ihr Freunde, mir Bescheid:", "tokens": ["Tut", ",", "ihr", "Freun\u00b7de", ",", "mir", "Be\u00b7scheid", ":"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Das befreite Vaterland,", "tokens": ["Das", "be\u00b7frei\u00b7te", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und die gute goldne Zeit!", "tokens": ["Und", "die", "gu\u00b7te", "gold\u00b7ne", "Zeit", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dann der B\u00fcrger denkt und glaubt,", "tokens": ["Dann", "der", "B\u00fcr\u00b7ger", "denkt", "und", "glaubt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "KON", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.6": {"text": "Spricht und schreibt nun alles frei,", "tokens": ["Spricht", "und", "schreibt", "nun", "al\u00b7les", "frei", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "VVFIN", "ADV", "PIS", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Was die hohe Polizei", "tokens": ["Was", "die", "ho\u00b7he", "Po\u00b7li\u00b7zei"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Erst gepr\u00fcft hat und erlaubt.", "tokens": ["Erst", "ge\u00b7pr\u00fcft", "hat", "und", "er\u00b7laubt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVPP", "VAFIN", "KON", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.10": {"line.1": {"text": "Du er\u00f6ffnest mir den Mund,", "tokens": ["Du", "er\u00b7\u00f6ff\u00b7nest", "mir", "den", "Mund", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Du geschw\u00e4tz'ger Traubensaft,", "tokens": ["Du", "ge\u00b7schw\u00e4tz'\u00b7ger", "Trau\u00b7ben\u00b7saft", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und die Wahrheit mach ich kund,", "tokens": ["Und", "die", "Wahr\u00b7heit", "mach", "ich", "kund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "R\u00fccksichtslos mit freud'ger Kraft.", "tokens": ["R\u00fcck\u00b7sichts\u00b7los", "mit", "freu\u00b7d'\u00b7ger", "Kraft", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ADJA", "NN", "$."], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.5": {"text": "Steigt die Sonne, wird es Tag,", "tokens": ["Steigt", "die", "Son\u00b7ne", ",", "wird", "es", "Tag", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "$,", "VAFIN", "PPER", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Sinkt sie unter, wird es Nacht.", "tokens": ["Sinkt", "sie", "un\u00b7ter", ",", "wird", "es", "Nacht", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "$,", "VAFIN", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nehm vor Feuer sich in Acht,", "tokens": ["Nehm", "vor", "Feu\u00b7er", "sich", "in", "Acht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "PRF", "APPR", "CARD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Wer sich nicht verbrennen mag.", "tokens": ["Wer", "sich", "nicht", "ver\u00b7bren\u00b7nen", "mag."], "token_info": ["word", "word", "word", "word", "abbreviation"], "pos": ["PWS", "PRF", "PTKNEG", "VVINF", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Ungeschickt zum L\u00f6schen ist,", "tokens": ["Un\u00b7ge\u00b7schickt", "zum", "L\u00f6\u00b7schen", "ist", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "VAFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer da \u00d6l gie\u00dft, wo es brennt;", "tokens": ["Wer", "da", "\u00d6l", "gie\u00dft", ",", "wo", "es", "brennt", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "NE", "VVFIN", "$,", "PWAV", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Noch ist drum kein guter Christ,", "tokens": ["Noch", "ist", "drum", "kein", "gu\u00b7ter", "Christ", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PAV", "PIAT", "ADJA", "NN", "$,"], "meter": "----+-+", "measure": "unknown.measure.di"}, "line.4": {"text": "Der zu Mahom sich bekennt.", "tokens": ["Der", "zu", "Ma\u00b7hom", "sich", "be\u00b7kennt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "NE", "PRF", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Scheut die Eule gleich das Licht,", "tokens": ["Scheut", "die", "Eu\u00b7le", "gleich", "das", "Licht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADV", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "F\u00e4hrt sich's doch vorm Winde gut,", "tokens": ["F\u00e4hrt", "sich's", "doch", "vorm", "Win\u00b7de", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Besser noch mit Wind und Flut,", "tokens": ["Bes\u00b7ser", "noch", "mit", "Wind", "und", "Flut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "ADV", "APPR", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Aber gegen beide nicht.", "tokens": ["A\u00b7ber", "ge\u00b7gen", "bei\u00b7de", "nicht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PIS", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Wer nicht sehen kann, ist blind,", "tokens": ["Wer", "nicht", "se\u00b7hen", "kann", ",", "ist", "blind", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "PTKNEG", "VVINF", "VMFIN", "$,", "VAFIN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wer auf Kr\u00fccken geht, ist lahm;", "tokens": ["Wer", "auf", "Kr\u00fc\u00b7cken", "geht", ",", "ist", "lahm", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVFIN", "$,", "VAFIN", "PTKVZ", "$."], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.3": {"text": "Mancher redet in den Wind,", "tokens": ["Man\u00b7cher", "re\u00b7det", "in", "den", "Wind", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Mancher geht, so wie er kam.", "tokens": ["Man\u00b7cher", "geht", ",", "so", "wie", "er", "kam", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "ADV", "KOKOM", "PPER", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gr\u00fcnt die Erde weit und breit,", "tokens": ["Gr\u00fcnt", "die", "Er\u00b7de", "weit", "und", "breit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Glaube nicht den Fr\u00fchling fern;", "tokens": ["Glau\u00b7be", "nicht", "den", "Fr\u00fch\u00b7ling", "fern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKNEG", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "R\u00fcckw\u00e4rts gehn die Krebse gern,", "tokens": ["R\u00fcck\u00b7w\u00e4rts", "gehn", "die", "Kreb\u00b7se", "gern", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Aber vorw\u00e4rts eilt die Zeit.", "tokens": ["A\u00b7ber", "vor\u00b7w\u00e4rts", "eilt", "die", "Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Zwar ist nicht das Dunkle klar,", "tokens": ["Zwar", "ist", "nicht", "das", "Dunk\u00b7le", "klar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PTKNEG", "ART", "NN", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch ist nicht, was gut ist, schlecht;", "tokens": ["Doch", "ist", "nicht", ",", "was", "gut", "ist", ",", "schlecht", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VAFIN", "PTKNEG", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn, was wahr ist, bleibt doch wahr,", "tokens": ["Denn", ",", "was", "wahr", "ist", ",", "bleibt", "doch", "wahr", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWS", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Und, was recht ist, bleibt doch recht.", "tokens": ["Und", ",", "was", "recht", "ist", ",", "bleibt", "doch", "recht", "."], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PRELS", "ADJD", "VAFIN", "$,", "VVFIN", "ADV", "ADJD", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Goldes-\u00dcberflu\u00df macht reich,", "tokens": ["Gol\u00b7des\u00b7\u00dcber\u00b7flu\u00df", "macht", "reich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.6": {"text": "Aber Lumpen sind kein Geld.", "tokens": ["A\u00b7ber", "Lum\u00b7pen", "sind", "kein", "Geld", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "PIAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Wer mit Steinen d\u00fcngt sein Feld,", "tokens": ["Wer", "mit", "Stei\u00b7nen", "d\u00fcngt", "sein", "Feld", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "APPR", "NN", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Macht gar einen dummen Streich.", "tokens": ["Macht", "gar", "ei\u00b7nen", "dum\u00b7men", "Streich", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "An der Zeit, ist nicht zu sp\u00e4t,", "tokens": ["An", "der", "Zeit", ",", "ist", "nicht", "zu", "sp\u00e4t", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "VAFIN", "PTKNEG", "PTKA", "ADJD", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Doch Geschehnes ist geschehn,", "tokens": ["Doch", "Ge\u00b7scheh\u00b7nes", "ist", "ge\u00b7schehn", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wer Disteln hat ges\u00e4t,", "tokens": ["Und", "wer", "Dis\u00b7teln", "hat", "ge\u00b7s\u00e4t", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "NN", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wird nicht Weizen reifen sehn.", "tokens": ["Wird", "nicht", "Wei\u00b7zen", "rei\u00b7fen", "sehn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PTKNEG", "NN", "VVFIN", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Gestern war's, nun ist es heut,", "tokens": ["Ge\u00b7stern", "wa\u00b7r's", ",", "nun", "ist", "es", "heut", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "$,", "ADV", "VAFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Morgen bringt auch seinen Lohn;", "tokens": ["Mor\u00b7gen", "bringt", "auch", "sei\u00b7nen", "Lohn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "ADV", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Kluge Leute wissen's schon,", "tokens": ["Klu\u00b7ge", "Leu\u00b7te", "wis\u00b7sen's", "schon", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Nur sind Narren nicht gescheut.", "tokens": ["Nur", "sind", "Nar\u00b7ren", "nicht", "ge\u00b7scheut", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "NN", "PTKNEG", "VVPP", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Und am besten wei\u00df, wer klagt,", "tokens": ["Und", "am", "bes\u00b7ten", "wei\u00df", ",", "wer", "klagt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "PTKA", "ADJD", "VVFIN", "$,", "PWS", "VVFIN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Wo ihn dr\u00fcckt der eigne Schuh;", "tokens": ["Wo", "ihn", "dr\u00fcckt", "der", "eig\u00b7ne", "Schuh", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wer zuerst nur A gesagt,", "tokens": ["Wer", "zu\u00b7erst", "nur", "A", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "ADV", "NE", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Setzt vielleicht noch B hinzu;", "tokens": ["Setzt", "viel\u00b7leicht", "noch", "B", "hin\u00b7zu", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ADV", "NN", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Denn, wie Adam Riese spricht,", "tokens": ["Denn", ",", "wie", "A\u00b7dam", "Rie\u00b7se", "spricht", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "NN", "NN", "VVFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Zwei und zwei sind eben vier \u2013 \u2013 \u2013", "tokens": ["Zwei", "und", "zwei", "sind", "e\u00b7ben", "vier", "\u2013", "\u2013", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["CARD", "KON", "CARD", "VAFIN", "ADV", "CARD", "$(", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Gott! wer pocht an unsre T\u00fcr?", "tokens": ["Gott", "!", "wer", "pocht", "an", "uns\u00b7re", "T\u00fcr", "?"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$.", "PWS", "VVFIN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Ihr, verratet mich nur nicht!", "tokens": ["Ihr", ",", "ver\u00b7ra\u00b7tet", "mich", "nur", "nicht", "!"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "$,", "VVFIN", "PPER", "ADV", "PTKNEG", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "\u00bbhebt auf das verruchte Nest,", "tokens": ["\u00bb", "hebt", "auf", "das", "ver\u00b7ruch\u00b7te", "Nest", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "--+-+-+", "measure": "anapaest.init"}, "line.2": {"text": "Sie mi\u00dfbrauchen die Geduld.", "tokens": ["Sie", "mi\u00df\u00b7brau\u00b7chen", "die", "Ge\u00b7duld", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Setzt den Jakobiner fest,", "tokens": ["Setzt", "den", "Ja\u00b7ko\u00b7bi\u00b7ner", "fest", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wir sind Zeugen seiner Schuld;", "tokens": ["Wir", "sind", "Zeu\u00b7gen", "sei\u00b7ner", "Schuld", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Er hat \u00f6ffentlich gelehrt:", "tokens": ["Er", "hat", "\u00f6f\u00b7fent\u00b7lich", "ge\u00b7lehrt", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADJD", "VVPP", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.6": {"text": "Zwei und zwei sind eben vier.\u00ab \u2013", "tokens": ["Zwei", "und", "zwei", "sind", "e\u00b7ben", "vier", ".", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["CARD", "KON", "CARD", "VAFIN", "ADV", "CARD", "$.", "$(", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.7": {"text": "Nein, ich sagte... \u00bbFort mit dir,", "tokens": ["Nein", ",", "ich", "sag\u00b7te", "...", "\u00bb", "Fort", "mit", "dir", ","], "token_info": ["word", "punct", "word", "word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "$(", "$(", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.8": {"text": "Da\u00df die Lehre keiner h\u00f6rt!\u00ab", "tokens": ["Da\u00df", "die", "Leh\u00b7re", "kei\u00b7ner", "h\u00f6rt", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "ART", "NN", "PIS", "VVFIN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}}}}