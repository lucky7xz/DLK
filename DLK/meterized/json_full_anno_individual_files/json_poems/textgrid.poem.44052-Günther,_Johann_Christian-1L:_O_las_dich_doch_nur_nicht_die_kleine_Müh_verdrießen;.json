{"textgrid.poem.44052": {"metadata": {"author": {"name": "G\u00fcnther, Johann Christian", "birth": "N.A.", "death": "N.A."}, "title": "1L: O las dich doch nur nicht die kleine M\u00fch verdrie\u00dfen;", "genre": "verse", "period": "N.A.", "pub_year": 1709, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O las dich doch nur nicht die kleine M\u00fch verdrie\u00dfen;", "tokens": ["O", "las", "dich", "doch", "nur", "nicht", "die", "klei\u00b7ne", "M\u00fch", "ver\u00b7drie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Zeilen, so von mir durch deine Feder flie\u00dfen,", "tokens": ["Die", "Zei\u00b7len", ",", "so", "von", "mir", "durch", "dei\u00b7ne", "Fe\u00b7der", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verhindern den Begrif der allzuschweren Noth.", "tokens": ["Ver\u00b7hin\u00b7dern", "den", "Be\u00b7grif", "der", "all\u00b7zu\u00b7schwe\u00b7ren", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst kan ich doch nichts thun als Klagelieder schreiben,", "tokens": ["Sonst", "kan", "ich", "doch", "nichts", "thun", "als", "Kla\u00b7ge\u00b7lie\u00b7der", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sonsten stillt mich auch kein ander Zeitvertreiben,", "tokens": ["Und", "sons\u00b7ten", "stillt", "mich", "auch", "kein", "an\u00b7der", "Zeit\u00b7ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es w\u00e4re denn der Tod.", "tokens": ["Es", "w\u00e4\u00b7re", "denn", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Ich bin schon reif dazu, sowohl an Creuz als Jahren,", "tokens": ["Ich", "bin", "schon", "reif", "da\u00b7zu", ",", "so\u00b7wohl", "an", "Creuz", "als", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PAV", "$,", "KON", "APPR", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und kaum der zehnte Grei\u00df kan so viel M\u00fch erfahren,", "tokens": ["Und", "kaum", "der", "zehn\u00b7te", "Grei\u00df", "kan", "so", "viel", "M\u00fch", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als mir schon um den Lenz des Lebens Ha\u00df gebiehrt.", "tokens": ["Als", "mir", "schon", "um", "den", "Lenz", "des", "Le\u00b7bens", "Ha\u00df", "ge\u00b7biehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich leugne nicht die Schuld der oft verdienten Schl\u00e4ge;", "tokens": ["Ich", "leug\u00b7ne", "nicht", "die", "Schuld", "der", "oft", "ver\u00b7dien\u00b7ten", "Schl\u00e4\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedoch wo lebt ein Mensch, den auf dem Tugendwege", "tokens": ["Je\u00b7doch", "wo", "lebt", "ein", "Mensch", ",", "den", "auf", "dem", "Tu\u00b7gend\u00b7we\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nicht Fleisch und Blut verf\u00fchrt?", "tokens": ["Nicht", "Fleisch", "und", "Blut", "ver\u00b7f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Ein jeder, heist's, vermag sein Gl\u00fccke selbst zu machen;", "tokens": ["Ein", "je\u00b7der", ",", "heist's", ",", "ver\u00b7mag", "sein", "Gl\u00fc\u00b7cke", "selbst", "zu", "ma\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "NE", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer Welt und Ursprung kennt, der wird des Sprichworts lachen.", "tokens": ["Wer", "Welt", "und", "Ur\u00b7sprung", "kennt", ",", "der", "wird", "des", "Sprich\u00b7worts", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$,", "PRELS", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ordnung der Natur sezt jedem Maas und Zeit,", "tokens": ["Die", "Ord\u00b7nung", "der", "Na\u00b7tur", "sezt", "je\u00b7dem", "Maas", "und", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie lenckt Gem\u00fcth und Herz so wie Verstand und Wollen", "tokens": ["Sie", "lenckt", "Ge\u00b7m\u00fcth", "und", "Herz", "so", "wie", "Ver\u00b7stand", "und", "Wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "ADV", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und macht, wenn Gl\u00fcck und Fall das Schauspiel \u00e4ndern sollen,", "tokens": ["Und", "macht", ",", "wenn", "Gl\u00fcck", "und", "Fall", "das", "Schau\u00b7spiel", "\u00e4n\u00b7dern", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Sitten Unterscheid.", "tokens": ["Der", "Sit\u00b7ten", "Un\u00b7ter\u00b7scheid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Drum, Thoren, h\u00f6rt doch auf, mein Leben zu verh\u00f6hnen;", "tokens": ["Drum", ",", "Tho\u00b7ren", ",", "h\u00f6rt", "doch", "auf", ",", "mein", "Le\u00b7ben", "zu", "ver\u00b7h\u00f6h\u00b7nen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,", "VVFIN", "ADV", "PTKVZ", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich such an mir ja nicht die Fehler zu besch\u00f6nen,", "tokens": ["Ich", "such", "an", "mir", "ja", "nicht", "die", "Feh\u00b7ler", "zu", "be\u00b7sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "PPER", "ADV", "PTKNEG", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie bleiben, was sie sind, an allen wie an mir.", "tokens": ["Sie", "blei\u00b7ben", ",", "was", "sie", "sind", ",", "an", "al\u00b7len", "wie", "an", "mir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "PRELS", "PPER", "VAFIN", "$,", "APPR", "PIAT", "KOKOM", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur dies verlangt mein Herz: Ihr sollt nicht sp\u00f6ttisch richten", "tokens": ["Nur", "dies", "ver\u00b7langt", "mein", "Herz", ":", "Ihr", "sollt", "nicht", "sp\u00f6t\u00b7tisch", "rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und \u00fcber meinen Schmerz ein h\u00f6hnisch Liedchen dichten;", "tokens": ["Und", "\u00fc\u00b7ber", "mei\u00b7nen", "Schmerz", "ein", "h\u00f6h\u00b7nisch", "Lied\u00b7chen", "dich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ART", "ADJD", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich bin ein Mensch wie ihr.", "tokens": ["Ich", "bin", "ein", "Mensch", "wie", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KOKOM", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Mein Hofen hat nunmehr nicht einen Funcken Zunder,", "tokens": ["Mein", "Ho\u00b7fen", "hat", "nun\u00b7mehr", "nicht", "ei\u00b7nen", "Fun\u00b7cken", "Zun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und was mich retten soll, das braucht kein schlechtes Wunder;", "tokens": ["Und", "was", "mich", "ret\u00b7ten", "soll", ",", "das", "braucht", "kein", "schlech\u00b7tes", "Wun\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "PDS", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier ist kein Weg zur Flucht, es sey denn aus der Welt.", "tokens": ["Hier", "ist", "kein", "Weg", "zur", "Flucht", ",", "es", "sey", "denn", "aus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "NN", "$,", "PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer noch was \u00e4ndern kann, der mag die Gro\u00dfmuth n\u00fczen;", "tokens": ["Wer", "noch", "was", "\u00e4n\u00b7dern", "kann", ",", "der", "mag", "die", "Gro\u00df\u00b7muth", "n\u00fc\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "VVINF", "VMFIN", "$,", "PRELS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sind Arm und H\u00e4nde weg, den C\u00f6rper zu besch\u00fczen,", "tokens": ["Sind", "Arm", "und", "H\u00e4n\u00b7de", "weg", ",", "den", "C\u00f6r\u00b7per", "zu", "be\u00b7sch\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So gilt nunmehr kein Held.", "tokens": ["So", "gilt", "nun\u00b7mehr", "kein", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Ich weiche vor der Last der eu\u00dfersten Beschwerden", "tokens": ["Ich", "wei\u00b7che", "vor", "der", "Last", "der", "eu\u00b7\u00dfers\u00b7ten", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und m\u00fch mich auch nicht mehr um Mittel los zu werden,", "tokens": ["Und", "m\u00fch", "mich", "auch", "nicht", "mehr", "um", "Mit\u00b7tel", "los", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "PTKVZ", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem ich wie ein Schif mir selbst gefehrlich bin.", "tokens": ["In\u00b7dem", "ich", "wie", "ein", "Schif", "mir", "selbst", "ge\u00b7fehr\u00b7lich", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wirft ein Steuermann, weil Mast und Ancker springet", "tokens": ["So", "wirft", "ein", "Steu\u00b7er\u00b7mann", ",", "weil", "Mast", "und", "An\u00b7cker", "sprin\u00b7get"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Salz und Schaum bereits durch tausend Spalten dringet,", "tokens": ["Und", "Salz", "und", "Schaum", "be\u00b7reits", "durch", "tau\u00b7send", "Spal\u00b7ten", "drin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ADV", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Compa\u00df und Hofnung hin.", "tokens": ["Com\u00b7pa\u00df", "und", "Hof\u00b7nung", "hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Ver\u00fcbelt mir mein Freund die Zagheit bl\u00f6der Sinnen,", "tokens": ["Ver\u00b7\u00fc\u00b7belt", "mir", "mein", "Freund", "die", "Zag\u00b7heit", "bl\u00f6\u00b7der", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So such er einen Trost, mein Herze zu gewinnen;", "tokens": ["So", "such", "er", "ei\u00b7nen", "Trost", ",", "mein", "Her\u00b7ze", "zu", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Unruh, so es f\u00fchlt, ist fast nicht auszustehn.", "tokens": ["Die", "Un\u00b7ruh", ",", "so", "es", "f\u00fchlt", ",", "ist", "fast", "nicht", "aus\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich w\u00e4re seiner Kunst ich weis nicht was verbunden,", "tokens": ["Ich", "w\u00e4\u00b7re", "sei\u00b7ner", "Kunst", "ich", "weis", "nicht", "was", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beredt er mich nur dies von diesen b\u00f6sen Stunden:", "tokens": ["Be\u00b7redt", "er", "mich", "nur", "dies", "von", "die\u00b7sen", "b\u00f6\u00b7sen", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "ADV", "PDS", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie werden auch vergehn.", "tokens": ["Sie", "wer\u00b7den", "auch", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "O las dich doch nur nicht die kleine M\u00fch verdrie\u00dfen;", "tokens": ["O", "las", "dich", "doch", "nur", "nicht", "die", "klei\u00b7ne", "M\u00fch", "ver\u00b7drie\u00b7\u00dfen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "ADV", "ADV", "PTKNEG", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Zeilen, so von mir durch deine Feder flie\u00dfen,", "tokens": ["Die", "Zei\u00b7len", ",", "so", "von", "mir", "durch", "dei\u00b7ne", "Fe\u00b7der", "flie\u00b7\u00dfen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "APPR", "PPER", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Verhindern den Begrif der allzuschweren Noth.", "tokens": ["Ver\u00b7hin\u00b7dern", "den", "Be\u00b7grif", "der", "all\u00b7zu\u00b7schwe\u00b7ren", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sonst kan ich doch nichts thun als Klagelieder schreiben,", "tokens": ["Sonst", "kan", "ich", "doch", "nichts", "thun", "als", "Kla\u00b7ge\u00b7lie\u00b7der", "schrei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ADV", "PIS", "VVINF", "KOKOM", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und sonsten stillt mich auch kein ander Zeitvertreiben,", "tokens": ["Und", "sons\u00b7ten", "stillt", "mich", "auch", "kein", "an\u00b7der", "Zeit\u00b7ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ADV", "PIAT", "ADJD", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Es w\u00e4re denn der Tod.", "tokens": ["Es", "w\u00e4\u00b7re", "denn", "der", "Tod", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Ich bin schon reif dazu, sowohl an Creuz als Jahren,", "tokens": ["Ich", "bin", "schon", "reif", "da\u00b7zu", ",", "so\u00b7wohl", "an", "Creuz", "als", "Jah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADJD", "PAV", "$,", "KON", "APPR", "NN", "KOUS", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und kaum der zehnte Grei\u00df kan so viel M\u00fch erfahren,", "tokens": ["Und", "kaum", "der", "zehn\u00b7te", "Grei\u00df", "kan", "so", "viel", "M\u00fch", "er\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "VMFIN", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Als mir schon um den Lenz des Lebens Ha\u00df gebiehrt.", "tokens": ["Als", "mir", "schon", "um", "den", "Lenz", "des", "Le\u00b7bens", "Ha\u00df", "ge\u00b7biehrt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "APPR", "ART", "NN", "ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich leugne nicht die Schuld der oft verdienten Schl\u00e4ge;", "tokens": ["Ich", "leug\u00b7ne", "nicht", "die", "Schuld", "der", "oft", "ver\u00b7dien\u00b7ten", "Schl\u00e4\u00b7ge", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "ART", "NN", "ART", "ADV", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Jedoch wo lebt ein Mensch, den auf dem Tugendwege", "tokens": ["Je\u00b7doch", "wo", "lebt", "ein", "Mensch", ",", "den", "auf", "dem", "Tu\u00b7gend\u00b7we\u00b7ge"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "PWAV", "VVFIN", "ART", "NN", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Nicht Fleisch und Blut verf\u00fchrt?", "tokens": ["Nicht", "Fleisch", "und", "Blut", "ver\u00b7f\u00fchrt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Ein jeder, heist's, vermag sein Gl\u00fccke selbst zu machen;", "tokens": ["Ein", "je\u00b7der", ",", "heist's", ",", "ver\u00b7mag", "sein", "Gl\u00fc\u00b7cke", "selbst", "zu", "ma\u00b7chen", ";"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "$,", "NE", "$,", "VVFIN", "PPOSAT", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wer Welt und Ursprung kennt, der wird des Sprichworts lachen.", "tokens": ["Wer", "Welt", "und", "Ur\u00b7sprung", "kennt", ",", "der", "wird", "des", "Sprich\u00b7worts", "la\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NN", "KON", "NN", "VVFIN", "$,", "PRELS", "VAFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Ordnung der Natur sezt jedem Maas und Zeit,", "tokens": ["Die", "Ord\u00b7nung", "der", "Na\u00b7tur", "sezt", "je\u00b7dem", "Maas", "und", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "ADV", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie lenckt Gem\u00fcth und Herz so wie Verstand und Wollen", "tokens": ["Sie", "lenckt", "Ge\u00b7m\u00fcth", "und", "Herz", "so", "wie", "Ver\u00b7stand", "und", "Wol\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "KON", "NN", "ADV", "KOKOM", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und macht, wenn Gl\u00fcck und Fall das Schauspiel \u00e4ndern sollen,", "tokens": ["Und", "macht", ",", "wenn", "Gl\u00fcck", "und", "Fall", "das", "Schau\u00b7spiel", "\u00e4n\u00b7dern", "sol\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "$,", "KOUS", "NN", "KON", "NN", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Der Sitten Unterscheid.", "tokens": ["Der", "Sit\u00b7ten", "Un\u00b7ter\u00b7scheid", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Drum, Thoren, h\u00f6rt doch auf, mein Leben zu verh\u00f6hnen;", "tokens": ["Drum", ",", "Tho\u00b7ren", ",", "h\u00f6rt", "doch", "auf", ",", "mein", "Le\u00b7ben", "zu", "ver\u00b7h\u00f6h\u00b7nen", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "$,", "NN", "$,", "VVFIN", "ADV", "PTKVZ", "$,", "PPOSAT", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ich such an mir ja nicht die Fehler zu besch\u00f6nen,", "tokens": ["Ich", "such", "an", "mir", "ja", "nicht", "die", "Feh\u00b7ler", "zu", "be\u00b7sch\u00f6\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PRF", "APPR", "PPER", "ADV", "PTKNEG", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie bleiben, was sie sind, an allen wie an mir.", "tokens": ["Sie", "blei\u00b7ben", ",", "was", "sie", "sind", ",", "an", "al\u00b7len", "wie", "an", "mir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVINF", "$,", "PRELS", "PPER", "VAFIN", "$,", "APPR", "PIAT", "KOKOM", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nur dies verlangt mein Herz: Ihr sollt nicht sp\u00f6ttisch richten", "tokens": ["Nur", "dies", "ver\u00b7langt", "mein", "Herz", ":", "Ihr", "sollt", "nicht", "sp\u00f6t\u00b7tisch", "rich\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "PDS", "VVFIN", "PPOSAT", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "ADJD", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und \u00fcber meinen Schmerz ein h\u00f6hnisch Liedchen dichten;", "tokens": ["Und", "\u00fc\u00b7ber", "mei\u00b7nen", "Schmerz", "ein", "h\u00f6h\u00b7nisch", "Lied\u00b7chen", "dich\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "NN", "ART", "ADJD", "NN", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Ich bin ein Mensch wie ihr.", "tokens": ["Ich", "bin", "ein", "Mensch", "wie", "ihr", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "KOKOM", "PPER", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Mein Hofen hat nunmehr nicht einen Funcken Zunder,", "tokens": ["Mein", "Ho\u00b7fen", "hat", "nun\u00b7mehr", "nicht", "ei\u00b7nen", "Fun\u00b7cken", "Zun\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "PTKNEG", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und was mich retten soll, das braucht kein schlechtes Wunder;", "tokens": ["Und", "was", "mich", "ret\u00b7ten", "soll", ",", "das", "braucht", "kein", "schlech\u00b7tes", "Wun\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "VVINF", "VMFIN", "$,", "PDS", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Hier ist kein Weg zur Flucht, es sey denn aus der Welt.", "tokens": ["Hier", "ist", "kein", "Weg", "zur", "Flucht", ",", "es", "sey", "denn", "aus", "der", "Welt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "APPRART", "NN", "$,", "PPER", "VAFIN", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wer noch was \u00e4ndern kann, der mag die Gro\u00dfmuth n\u00fczen;", "tokens": ["Wer", "noch", "was", "\u00e4n\u00b7dern", "kann", ",", "der", "mag", "die", "Gro\u00df\u00b7muth", "n\u00fc\u00b7zen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "ADV", "PIS", "VVINF", "VMFIN", "$,", "PRELS", "VMFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Sind Arm und H\u00e4nde weg, den C\u00f6rper zu besch\u00fczen,", "tokens": ["Sind", "Arm", "und", "H\u00e4n\u00b7de", "weg", ",", "den", "C\u00f6r\u00b7per", "zu", "be\u00b7sch\u00fc\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "KON", "NN", "PTKVZ", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So gilt nunmehr kein Held.", "tokens": ["So", "gilt", "nun\u00b7mehr", "kein", "Held", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Ich weiche vor der Last der eu\u00dfersten Beschwerden", "tokens": ["Ich", "wei\u00b7che", "vor", "der", "Last", "der", "eu\u00b7\u00dfers\u00b7ten", "Be\u00b7schwer\u00b7den"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "ART", "ADJA", "NN"], "meter": "-+-+-+--+--+-", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Und m\u00fch mich auch nicht mehr um Mittel los zu werden,", "tokens": ["Und", "m\u00fch", "mich", "auch", "nicht", "mehr", "um", "Mit\u00b7tel", "los", "zu", "wer\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "PPER", "ADV", "PTKNEG", "ADV", "APPR", "NN", "PTKVZ", "PTKZU", "VAINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Indem ich wie ein Schif mir selbst gefehrlich bin.", "tokens": ["In\u00b7dem", "ich", "wie", "ein", "Schif", "mir", "selbst", "ge\u00b7fehr\u00b7lich", "bin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "KOKOM", "ART", "NN", "PPER", "ADV", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wirft ein Steuermann, weil Mast und Ancker springet", "tokens": ["So", "wirft", "ein", "Steu\u00b7er\u00b7mann", ",", "weil", "Mast", "und", "An\u00b7cker", "sprin\u00b7get"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KOUS", "NN", "KON", "NN", "VVFIN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Und Salz und Schaum bereits durch tausend Spalten dringet,", "tokens": ["Und", "Salz", "und", "Schaum", "be\u00b7reits", "durch", "tau\u00b7send", "Spal\u00b7ten", "drin\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "ADV", "APPR", "CARD", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Compa\u00df und Hofnung hin.", "tokens": ["Com\u00b7pa\u00df", "und", "Hof\u00b7nung", "hin", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Ver\u00fcbelt mir mein Freund die Zagheit bl\u00f6der Sinnen,", "tokens": ["Ver\u00b7\u00fc\u00b7belt", "mir", "mein", "Freund", "die", "Zag\u00b7heit", "bl\u00f6\u00b7der", "Sin\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "So such er einen Trost, mein Herze zu gewinnen;", "tokens": ["So", "such", "er", "ei\u00b7nen", "Trost", ",", "mein", "Her\u00b7ze", "zu", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "$,", "PPOSAT", "VVFIN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die Unruh, so es f\u00fchlt, ist fast nicht auszustehn.", "tokens": ["Die", "Un\u00b7ruh", ",", "so", "es", "f\u00fchlt", ",", "ist", "fast", "nicht", "aus\u00b7zu\u00b7stehn", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "PPER", "VVFIN", "$,", "VAFIN", "ADV", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Ich w\u00e4re seiner Kunst ich weis nicht was verbunden,", "tokens": ["Ich", "w\u00e4\u00b7re", "sei\u00b7ner", "Kunst", "ich", "weis", "nicht", "was", "ver\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPOSAT", "NN", "PPER", "PTKVZ", "PTKNEG", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Beredt er mich nur dies von diesen b\u00f6sen Stunden:", "tokens": ["Be\u00b7redt", "er", "mich", "nur", "dies", "von", "die\u00b7sen", "b\u00f6\u00b7sen", "Stun\u00b7den", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "PRF", "ADV", "PDS", "APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Sie werden auch vergehn.", "tokens": ["Sie", "wer\u00b7den", "auch", "ver\u00b7gehn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "VVINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}