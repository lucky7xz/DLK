{"dta.poem.5292": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "Das unverhofte Gr\u00fcn.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1736", "urn": "urn:nbn:de:kobv:b4-200905198582", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "J\u00fcngst gieng ich nebst Fabricius,", "tokens": ["J\u00fcngst", "gieng", "ich", "nebst", "Fab\u00b7ri\u00b7ci\u00b7us", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NE", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Den, ohne Neid fast, selbst der Neid bewundern", "tokens": ["Den", ",", "oh\u00b7ne", "Neid", "fast", ",", "selbst", "der", "Neid", "be\u00b7wun\u00b7dern"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NE", "$,", "KOUI", "NN", "ADV", "$,", "ADV", "ART", "NN", "VVINF"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "In einem zierlichen, am klaren Alster-Flu\u00df", "tokens": ["In", "ei\u00b7nem", "zier\u00b7li\u00b7chen", ",", "am", "kla\u00b7ren", "Als\u00b7ter\u00b7Flu\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "$,", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Belegnen, grossen Blumen-Garten,", "tokens": ["Be\u00b7leg\u00b7nen", ",", "gros\u00b7sen", "Blu\u00b7men\u00b7Gar\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Worin, von mehr als tausend Arten,", "tokens": ["Wo\u00b7rin", ",", "von", "mehr", "als", "tau\u00b7send", "Ar\u00b7ten", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "$,", "APPR", "PIAT", "KOKOM", "CARD", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Viel hundert tausend Blumen stunden,", "tokens": ["Viel", "hun\u00b7dert", "tau\u00b7send", "Blu\u00b7men", "stun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "CARD", "CARD", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Die wir durch ihre Meng\u2019 in solchem Glantze funden,", "tokens": ["Die", "wir", "durch", "ih\u00b7re", "Meng'", "in", "sol\u00b7chem", "Glant\u00b7ze", "fun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "PPOSAT", "NN", "APPR", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Da\u00df, durch den Ubeflu\u00df der Lust", "tokens": ["Da\u00df", ",", "durch", "den", "U\u00b7be\u00b7flu\u00df", "der", "Lust"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KOUS", "$,", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der uns fast mehr erf\u00fcllt\u2019 und drengt\u2019, als r\u00fchrte,", "tokens": ["Der", "uns", "fast", "mehr", "er\u00b7f\u00fcllt'", "und", "drengt'", ",", "als", "r\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADV", "VVFIN", "KON", "VVFIN", "$,", "KOUS", "VVFIN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.10": {"text": "Das Hertz in unsrer Beyder Brust", "tokens": ["Das", "Hertz", "in", "uns\u00b7rer", "Bey\u00b7der", "Brust"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.11": {"text": "Sich gleichsam echt gedruckt, und sanft-gepre\u00dft versp\u00fchrte.", "tokens": ["Sich", "gleich\u00b7sam", "echt", "ge\u00b7druckt", ",", "und", "sanft\u00b7ge\u00b7pre\u00dft", "ver\u00b7sp\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PRF", "ADJD", "ADJD", "VVPP", "$,", "KON", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.12": {"text": "Wir stutzten erst vor \u00fcbermachter Freude", "tokens": ["Wir", "stutz\u00b7ten", "erst", "vor", "\u00fc\u00b7ber\u00b7mach\u00b7ter", "Freu\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Und, durch die bunte Gluth der Blumen angeflammt,", "tokens": ["Und", ",", "durch", "die", "bun\u00b7te", "Gluth", "der", "Blu\u00b7men", "an\u00b7ge\u00b7flammt", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "APPR", "ART", "ADJA", "NN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Gedachten wir mit Lust und Ehrfurcht alle beide", "tokens": ["Ge\u00b7dach\u00b7ten", "wir", "mit", "Lust", "und", "Ehr\u00b7furcht", "al\u00b7le", "bei\u00b7de"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "PPER", "APPR", "NN", "KON", "NN", "PIAT", "PIS"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "An den, aus dessen Kraft, Luft, Erd\u2019 und Himmel stammt.", "tokens": ["An", "den", ",", "aus", "des\u00b7sen", "Kraft", ",", "Luft", ",", "Erd'", "und", "Him\u00b7mel", "stammt", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "$,", "APPR", "PRELAT", "NN", "$,", "NN", "$,", "NN", "KON", "NN", "VVFIN", "$."], "meter": "---+-+-+-+-+", "measure": "unknown.measure.penta"}, "line.16": {"text": "Es brach ein froh ", "tokens": ["Es", "brach", "ein", "froh"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJD"], "meter": "-+-+", "measure": "iambic.di"}, "line.17": {"text": "Gott Lob! der sich bey uns in solcher Sch\u00f6nheit kund", "tokens": ["Gott", "Lob", "!", "der", "sich", "bey", "uns", "in", "sol\u00b7cher", "Sch\u00f6n\u00b7heit", "kund"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "PRELS", "PRF", "APPR", "PPER", "APPR", "PIAT", "NN", "PTKVZ"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.18": {"text": "Und gleichsam sichtbar macht!", "tokens": ["Und", "gleich\u00b7sam", "sicht\u00b7bar", "macht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "ADJD", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.19": {"text": "Le Fevre, welcher sich zugleich bey uns befand", "tokens": ["Le", "Fev\u00b7re", ",", "wel\u00b7cher", "sich", "zu\u00b7gleich", "bey", "uns", "be\u00b7fand"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["NE", "NE", "$,", "PRELS", "PRF", "ADV", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.20": {"text": "Le Fevre eine Zier von seiner Vater-Stadt,", "tokens": ["Le", "Fev\u00b7re", "ei\u00b7ne", "Zier", "von", "sei\u00b7ner", "Va\u00b7ter\u00b7Stadt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "ART", "NN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.21": {"text": "Und der, zu meiner Ehr, mit mir verwandt,", "tokens": ["Und", "der", ",", "zu", "mei\u00b7ner", "Ehr", ",", "mit", "mir", "ver\u00b7wandt", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ART", "$,", "APPR", "PPOSAT", "NN", "$,", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.22": {"text": "Bewunderte nebst uns und ehrt\u2019 in ihrer Pracht", "tokens": ["Be\u00b7wun\u00b7der\u00b7te", "nebst", "uns", "und", "ehrt'", "in", "ih\u00b7rer", "Pracht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "APPR", "PPER", "KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.23": {"text": "Die GOttheit ebenfals. Als eben B\u00f6ckelmann,", "tokens": ["Die", "Got\u00b7theit", "e\u00b7ben\u00b7fals", ".", "Als", "e\u00b7ben", "B\u00f6\u00b7ckel\u00b7mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$.", "KOUS", "ADV", "NE", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.24": {"text": "Des sch\u00f6nen Gartens Herr und Pfleger, zu uns trat", "tokens": ["Des", "sch\u00f6\u00b7nen", "Gar\u00b7tens", "Herr", "und", "Pfle\u00b7ger", ",", "zu", "uns", "trat"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "KON", "NN", "$,", "APPR", "PPER", "VVFIN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.25": {"text": "Und, wie er uns sehr h\u00f6flich angesprochen,", "tokens": ["Und", ",", "wie", "er", "uns", "sehr", "h\u00f6f\u00b7lich", "an\u00b7ge\u00b7spro\u00b7chen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "PPER", "PPER", "ADV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.26": {"text": "Auch f\u00fcr uns eine gute Zahl", "tokens": ["Auch", "f\u00fcr", "uns", "ei\u00b7ne", "gu\u00b7te", "Zahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "APPR", "PPER", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.27": {"text": "Erlesner Blumen agebrochen,", "tokens": ["Er\u00b7les\u00b7ner", "Blu\u00b7men", "a\u00b7ge\u00b7bro\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.28": {"text": "Kam er von ungefehr auf seine Morgen-Zeit.", "tokens": ["Kam", "er", "von", "un\u00b7ge\u00b7fehr", "auf", "sei\u00b7ne", "Mor\u00b7gen\u00b7Zeit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "PPER", "APPR", "ADJD", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Nicht auszudr\u00fccken ist die Lust, die ich versp\u00fchre,", "tokens": ["Nicht", "aus\u00b7zu\u00b7dr\u00fc\u00b7cken", "ist", "die", "Lust", ",", "die", "ich", "ver\u00b7sp\u00fch\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKNEG", "VVIZU", "VAFIN", "ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Sprach er, wenn ich, schon fr\u00fch\u2019 um viere", "tokens": ["Sprach", "er", ",", "wenn", "ich", ",", "schon", "fr\u00fch'", "um", "vie\u00b7re"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "PPER", "$,", "KOUS", "PPER", "$,", "ADV", "ADJD", "APPR", "PIS"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Der Blumen ungezehlte Zahl", "tokens": ["Der", "Blu\u00b7men", "un\u00b7ge\u00b7zehl\u00b7te", "Zahl"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Jm von der f\u00fchen Sonnen Strahl", "tokens": ["Jm", "von", "der", "f\u00fc\u00b7hen", "Son\u00b7nen", "Strahl"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPRART", "APPR", "ART", "ADJA", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Gef\u00e4rbt- und gantz durchdrungnen Thau", "tokens": ["Ge\u00b7f\u00e4rb\u00b7t", "und", "gantz", "durch\u00b7drung\u00b7nen", "Thau"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["TRUNC", "KON", "ADV", "ADJA", "NN"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "In einem himmlischen, nicht ird\u2019schen, Firni\u00df schau.", "tokens": ["In", "ei\u00b7nem", "himm\u00b7li\u00b7schen", ",", "nicht", "ird'\u00b7schen", ",", "Fir\u00b7ni\u00df", "schau", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "$,", "PTKNEG", "VVINF", "$,", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ich f\u00fchle, wie so denn die allgemeine Stille,", "tokens": ["Ich", "f\u00fch\u00b7le", ",", "wie", "so", "denn", "die", "all\u00b7ge\u00b7mei\u00b7ne", "Stil\u00b7le", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PWAV", "ADV", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Die dann die Welt beherrscht, auch mein Gem\u00fcth erf\u00fclle.", "tokens": ["Die", "dann", "die", "Welt", "be\u00b7herrscht", ",", "auch", "mein", "Ge\u00b7m\u00fcth", "er\u00b7f\u00fcl\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "ART", "NN", "VVFIN", "$,", "ADV", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Die\u00df ist die sch\u00f6nste Zeit, di\u00df sind die sch\u00f6nsten Stunden!", "tokens": ["Die\u00df", "ist", "die", "sch\u00f6ns\u00b7te", "Zeit", ",", "di\u00df", "sind", "die", "sch\u00f6ns\u00b7ten", "Stun\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "ADJA", "NN", "$,", "PDS", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nur dauret mich, da\u00df sie von Menschen auf der Erden", "tokens": ["Nur", "dau\u00b7ret", "mich", ",", "da\u00df", "sie", "von", "Men\u00b7schen", "auf", "der", "Er\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "$,", "KOUS", "PPER", "APPR", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "So wenig nur empfunden", "tokens": ["So", "we\u00b7nig", "nur", "emp\u00b7fun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ADV", "ADV", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.12": {"text": "Und mehrentheils verschlaffen werden.", "tokens": ["Und", "meh\u00b7ren\u00b7theils", "ver\u00b7schlaf\u00b7fen", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.13": {"text": "Wir traureten und freuten uns mit ihm.", "tokens": ["Wir", "trau\u00b7re\u00b7ten", "und", "freu\u00b7ten", "uns", "mit", "ihm", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+---+-+-+", "measure": "dactylic.init"}}, "stanza.3": {"line.1": {"text": "Hierauf kan man von ungefehr", "tokens": ["Hier\u00b7auf", "kan", "man", "von", "un\u00b7ge\u00b7fehr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PAV", "VMFIN", "PIS", "APPR", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von neuem auf der Blumen-Heer:", "tokens": ["Von", "neu\u00b7em", "auf", "der", "Blu\u00b7men\u00b7Heer", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man sprach: Bewunderns wehrt ist, da der Blumen", "tokens": ["Man", "sprach", ":", "Be\u00b7wun\u00b7derns", "wehrt", "ist", ",", "da", "der", "Blu\u00b7men"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "$.", "NN", "VVFIN", "VAFIN", "$,", "KOUS", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.4": {"text": "In allen Farben glimmt, da\u00df die Natur von ihnen", "tokens": ["In", "al\u00b7len", "Far\u00b7ben", "glimmt", ",", "da\u00df", "die", "Na\u00b7tur", "von", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$,", "KOUS", "ART", "NN", "APPR", "PPER"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Doch keine gr\u00fcn gemacht.", "tokens": ["Doch", "kei\u00b7ne", "gr\u00fcn", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "ADJD", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.6": {"text": "Wir andern stimmten bey", "tokens": ["Wir", "an\u00b7dern", "stimm\u00b7ten", "bey"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "PIS", "VVFIN", "APPR"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.7": {"text": "Und dachten, da\u00df dem Laub\u2019 und Gras\u2019 allein im Gr\u00fcnen", "tokens": ["Und", "dach\u00b7ten", ",", "da\u00df", "dem", "Laub'", "und", "Gras'", "al\u00b7lein", "im", "Gr\u00fc\u00b7nen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "$,", "KOUS", "ART", "NN", "KON", "NN", "ADV", "APPRART", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Zu gl\u00e4ntzen vorbehalten sey.", "tokens": ["Zu", "gl\u00e4nt\u00b7zen", "vor\u00b7be\u00b7hal\u00b7ten", "sey", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Drauf ging, mit sanften Schritten,", "tokens": ["Drauf", "ging", ",", "mit", "sanf\u00b7ten", "Schrit\u00b7ten", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.10": {"text": "Herr B\u00f6ckelmann von uns, kam aber bald hernach,", "tokens": ["Herr", "B\u00f6\u00b7ckel\u00b7mann", "von", "uns", ",", "kam", "a\u00b7ber", "bald", "her\u00b7nach", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "APPR", "PPER", "$,", "VVFIN", "ADV", "ADV", "ADV", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Mit ja so sanften Schritten, wieder;", "tokens": ["Mit", "ja", "so", "sanf\u00b7ten", "Schrit\u00b7ten", ",", "wie\u00b7der", ";"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADV", "ADV", "ADJA", "NN", "$,", "ADV", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Und, sonder da\u00df er etwas sprach,", "tokens": ["Und", ",", "son\u00b7der", "da\u00df", "er", "et\u00b7was", "sprach", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "KON", "KOUS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.13": {"text": "So legt\u2019 er in der Mitten", "tokens": ["So", "legt'", "er", "in", "der", "Mit\u00b7ten"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.14": {"text": "Auf unsern Tisch drey gr\u00fcne Blumen nieder,", "tokens": ["Auf", "un\u00b7sern", "Tisch", "drey", "gr\u00fc\u00b7ne", "Blu\u00b7men", "nie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "CARD", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.15": {"text": "Wodurch er, da\u00df wir uns geirrt", "tokens": ["Wo\u00b7durch", "er", ",", "da\u00df", "wir", "uns", "ge\u00b7irrt"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "$,", "KOUS", "PPER", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.16": {"text": "Uns \u00fcberzeuglich \u00fcberf\u00fchrte.", "tokens": ["Uns", "\u00fc\u00b7berz\u00b7eug\u00b7lich", "\u00fc\u00b7berf\u00b7\u00fchr\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Wir sahn einander an. Halb l\u00e4chelnd, halb verwirrt,", "tokens": ["Wir", "sahn", "ein\u00b7an\u00b7der", "an", ".", "Halb", "l\u00e4\u00b7chelnd", ",", "halb", "ver\u00b7wirrt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "PTKVZ", "$.", "NN", "ADJD", "$,", "ADJD", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gestunden wir, zu seiner Ehr,", "tokens": ["Ge\u00b7stun\u00b7den", "wir", ",", "zu", "sei\u00b7ner", "Ehr", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "$,", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Da\u00df die\u00df die beste Art zu \u00fcberzeugen w\u00e4r.", "tokens": ["Da\u00df", "die\u00df", "die", "bes\u00b7te", "Art", "zu", "\u00fc\u00b7berz\u00b7eu\u00b7gen", "w\u00e4r", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PDS", "ART", "ADJA", "NN", "PTKZU", "VVINF", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Nachhero nahmen wir der gr\u00fcnen Blumen Pracht,", "tokens": ["Nach\u00b7he\u00b7ro", "nah\u00b7men", "wir", "der", "gr\u00fc\u00b7nen", "Blu\u00b7men", "Pracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+--+-+-+-+-+", "measure": "iambic.hexa.invert"}, "line.5": {"text": "So ein\u2019 Anemone, bewundrungs-voll in acht,", "tokens": ["So", "ein'", "A\u00b7ne\u00b7mo\u00b7ne", ",", "be\u00b7wun\u00b7drungs\u00b7voll", "in", "acht", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$,", "ADJD", "APPR", "CARD", "$,"], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.6": {"text": "Da jeder dann, nachdem wir sie recht wol beschaut,", "tokens": ["Da", "je\u00b7der", "dann", ",", "nach\u00b7dem", "wir", "sie", "recht", "wol", "be\u00b7schaut", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "$,", "KOUS", "PPER", "PPER", "ADV", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Gestand, da\u00df auch das sch\u00f6nste Kraut", "tokens": ["Ge\u00b7stand", ",", "da\u00df", "auch", "das", "sch\u00f6ns\u00b7te", "Kraut"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["NN", "$,", "KOUS", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Kein sch\u00f6ner Gr\u00fcn fast zeigen kann.", "tokens": ["Kein", "sch\u00f6\u00b7ner", "Gr\u00fcn", "fast", "zei\u00b7gen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "NN", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Hier\u00fcber stimmten wir zuletzt der Meynung bey,", "tokens": ["Hier\u00b7\u00fc\u00b7ber", "stimm\u00b7ten", "wir", "zu\u00b7letzt", "der", "Mey\u00b7nung", "bey", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "ADV", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da\u00df alles, was in der Natur", "tokens": ["Da\u00df", "al\u00b7les", ",", "was", "in", "der", "Na\u00b7tur"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "$,", "PRELS", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So wol an Farben als Figur", "tokens": ["So", "wol", "an", "Far\u00b7ben", "als", "Fi\u00b7gur"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "APPR", "NN", "KOUS", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nur m\u00f6glich, auch vermuhtlich wircklich sey.", "tokens": ["Nur", "m\u00f6g\u00b7lich", ",", "auch", "ver\u00b7muht\u00b7lich", "wir\u00b7ck\u00b7lich", "sey", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADJD", "ADJD", "VAFIN", "$."], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.6": {"line.1": {"text": "Herr, meine Lust sind deine Wercke.", "tokens": ["Herr", ",", "mei\u00b7ne", "Lust", "sind", "dei\u00b7ne", "Wer\u00b7cke", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "PPOSAT", "NN", "VAFIN", "PPOSAT", "NN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Ach, gieb, da\u00df mancher auch mit mir,", "tokens": ["Ach", ",", "gieb", ",", "da\u00df", "man\u00b7cher", "auch", "mit", "mir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "VVIMP", "$,", "KOUS", "PIS", "ADV", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "O aller Dinge Quell, sie, dir", "tokens": ["O", "al\u00b7ler", "Din\u00b7ge", "Quell", ",", "sie", ",", "dir"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word"], "pos": ["NE", "PIAT", "NN", "NN", "$,", "PPER", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Zum Ruhm, mit Lust und danck, bemercke!", "tokens": ["Zum", "Ruhm", ",", "mit", "Lust", "und", "danck", ",", "be\u00b7mer\u00b7cke", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPR", "NN", "KON", "ADJD", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}