{"textgrid.poem.26411": {"metadata": {"author": {"name": "Dauthendey, Max", "birth": "N.A.", "death": "N.A."}, "title": "Venusinens Romfahrt im D-Zug mit den Bernhardinern", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbeckehardt, mein Lieber,", "tokens": ["\u00bb", "ec\u00b7ke\u00b7hardt", ",", "mein", "Lie\u00b7ber", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Liebst du nie das Fesche?", "tokens": ["Liebst", "du", "nie", "das", "Fe\u00b7sche", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schrecklich ist dein Wollkleid", "tokens": ["Schreck\u00b7lich", "ist", "dein", "Woll\u00b7kleid"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und die J\u00e4gerw\u00e4sche!", "tokens": ["Und", "die", "J\u00e4\u00b7ger\u00b7w\u00e4\u00b7sche", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Trag doch nicht so lose,", "tokens": ["Trag", "doch", "nicht", "so", "lo\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Amor, lieber Junge,", "tokens": ["A\u00b7mor", ",", "lie\u00b7ber", "Jun\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Deinen Knopf der Hose!\u00ab", "tokens": ["Dei\u00b7nen", "Knopf", "der", "Ho\u00b7se", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "So sprach Venusine,", "tokens": ["So", "sprach", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,"], "meter": "-+----", "measure": "dactylic.init"}, "line.2": {"text": "Als man in D-Z\u00fcgen", "tokens": ["Als", "man", "in", "D\u00b7\u00b7Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sa\u00df und nach Italien", "tokens": ["Sa\u00df", "und", "nach", "I\u00b7ta\u00b7li\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KON", "APPR", "NE"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Flog in Rasselfl\u00fcgen.", "tokens": ["Flog", "in", "Ras\u00b7sel\u00b7fl\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Aus dem Berge drau\u00dfen", "tokens": ["Aus", "dem", "Ber\u00b7ge", "drau\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hielt sie mehr als drinnen", "tokens": ["Hielt", "sie", "mehr", "als", "drin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "KOKOM", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf den Takt nach au\u00dfen.", "tokens": ["Auf", "den", "Takt", "nach", "au\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "Aber nichts konnt' hindern,", "tokens": ["A\u00b7ber", "nichts", "konnt'", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df in frohen Stunden", "tokens": ["Da\u00df", "in", "fro\u00b7hen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sie und ihr Gefolge,", "tokens": ["Sie", "und", "ihr", "Ge\u00b7fol\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ganz kulturentbunden,", "tokens": ["Ganz", "kul\u00b7tu\u00b7rent\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "In die L\u00fcfte wollten,", "tokens": ["In", "die", "L\u00fcf\u00b7te", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Aus den Fenstern flogen,", "tokens": ["Aus", "den", "Fens\u00b7tern", "flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hinter Wolken tollten.", "tokens": ["Hin\u00b7ter", "Wol\u00b7ken", "toll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "Und im Zug bemerken", "tokens": ["Und", "im", "Zug", "be\u00b7mer\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Manche Passagiere:", "tokens": ["Man\u00b7che", "Pas\u00b7sa\u00b7gie\u00b7re", ":"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Im Maschinendampfe,", "tokens": ["Im", "Ma\u00b7schi\u00b7nen\u00b7damp\u00b7fe", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nackt ein Weib spaziere.", "tokens": ["Nackt", "ein", "Weib", "spa\u00b7zie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Konnt' durch L\u00fcfte jagen,", "tokens": ["Konnt'", "durch", "L\u00fcf\u00b7te", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit dem Vollmond spielen,", "tokens": ["Mit", "dem", "Voll\u00b7mond", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wald und Berge tragen. \u2013", "tokens": ["Wald", "und", "Ber\u00b7ge", "tra\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.9": {"line.1": {"text": "Sa\u00df da h\u00fcbsch ein Bursche", "tokens": ["Sa\u00df", "da", "h\u00fcbsch", "ein", "Bur\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In der ersten Klasse.", "tokens": ["In", "der", "ers\u00b7ten", "Klas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Halbtot war er leider,", "tokens": ["Halb\u00b7tot", "war", "er", "lei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Halb Tuberkelmasse.", "tokens": ["Halb", "Tu\u00b7ber\u00b7kel\u00b7mas\u00b7se", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.10": {"line.1": {"text": "Sollte nach dem S\u00fcden.", "tokens": ["Soll\u00b7te", "nach", "dem", "S\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ihn sah Venusine", "tokens": ["Ihn", "sah", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Und behext den M\u00fcden.", "tokens": ["Und", "be\u00b7hext", "den", "M\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.11": {"line.1": {"text": "Denkt: Sollst Dich nicht qu\u00e4len", "tokens": ["Denkt", ":", "Sollst", "Dich", "nicht", "qu\u00e4\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00fcbschester Geselle?", "tokens": ["H\u00fcb\u00b7sches\u00b7ter", "Ge\u00b7sel\u00b7le", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Stehst mit einem Fu\u00dfe", "tokens": ["Stehst", "mit", "ei\u00b7nem", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auf der Beinhausschwelle.", "tokens": ["Auf", "der", "Be\u00b7in\u00b7haus\u00b7schwel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.12": {"line.1": {"text": "Dir den Tod vers\u00fc\u00dfen,", "tokens": ["Dir", "den", "Tod", "ver\u00b7s\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Soll mich heut zerstreuen,", "tokens": ["Soll", "mich", "heut", "zer\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Komm und la\u00df dich k\u00fcssen!", "tokens": ["Komm", "und", "la\u00df", "dich", "k\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Leis spricht sie zu Amor:", "tokens": ["Leis", "spricht", "sie", "zu", "A\u00b7mor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bbliebstes S\u00f6hnchen, gehe,", "tokens": ["\u00bb", "liebs\u00b7tes", "S\u00f6hn\u00b7chen", ",", "ge\u00b7he", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df dem h\u00fcbschen Menschen", "tokens": ["Da\u00df", "dem", "h\u00fcb\u00b7schen", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Liebes bald geschehe!", "tokens": ["Lie\u00b7bes", "bald", "ge\u00b7sche\u00b7he", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Geh auf fester Sohle,", "tokens": ["Geh", "auf", "fes\u00b7ter", "Soh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dicht ihm an das Herze,", "tokens": ["Dicht", "ihm", "an", "das", "Her\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PDS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Setz' ihm die Pistole!\u00ab", "tokens": ["Setz'", "ihm", "die", "Pis\u00b7to\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.15": {"line.1": {"text": "Amor zielt voll Eifer,", "tokens": ["A\u00b7mor", "zielt", "voll", "Ei\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schie\u00dft auf Wunsch der Mutter,", "tokens": ["Schie\u00dft", "auf", "Wunsch", "der", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trifft den jungen Menschen", "tokens": ["Trifft", "den", "jun\u00b7gen", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durch das Westenfutter.", "tokens": ["Durch", "das", "Wes\u00b7ten\u00b7fut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Doch, ach, nie bedachten", "tokens": ["Doch", ",", "ach", ",", "nie", "be\u00b7dach\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ITJ", "$,", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "G\u00f6tter fehllos handelnd,", "tokens": ["G\u00f6t\u00b7ter", "fehl\u00b7los", "han\u00b7delnd", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ob sie's richtig machten!", "tokens": ["Ob", "sie's", "rich\u00b7tig", "mach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.17": {"line.1": {"text": "Kaum ging die Pistole", "tokens": ["Kaum", "ging", "die", "Pis\u00b7to\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Los mit frohem Knalle,", "tokens": ["Los", "mit", "fro\u00b7hem", "Knal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sa\u00df der kleine Amor", "tokens": ["Sa\u00df", "der", "klei\u00b7ne", "A\u00b7mor"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In der Mausefalle.", "tokens": ["In", "der", "Mau\u00b7se\u00b7fal\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Denn der Herr springt pfauchend", "tokens": ["Denn", "der", "Herr", "springt", "pfau\u00b7chend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nach der Angstnotleine,", "tokens": ["Nach", "der", "Angst\u00b7not\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "B\u00f6se Worte brauchend.", "tokens": ["B\u00f6\u00b7se", "Wor\u00b7te", "brau\u00b7chend", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.19": {"line.1": {"text": "Schaffner und die F\u00fchrer", "tokens": ["Schaff\u00b7ner", "und", "die", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eilen an die T\u00fcren,", "tokens": ["Ei\u00b7len", "an", "die", "T\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man will den Amor", "tokens": ["Und", "man", "will", "den", "A\u00b7mor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ART", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Strafen mit Geb\u00fchren.", "tokens": ["Stra\u00b7fen", "mit", "Ge\u00b7b\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Nichts half, da\u00df er meinte,", "tokens": ["Nichts", "half", ",", "da\u00df", "er", "mein\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Er hab nicht get\u00f6tet", "tokens": ["Er", "hab", "nicht", "ge\u00b7t\u00f6\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und wie Kinder weinte.", "tokens": ["Und", "wie", "Kin\u00b7der", "wein\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "VVFIN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.21": {"line.1": {"text": "Jener h\u00fcbsche Kranke", "tokens": ["Je\u00b7ner", "h\u00fcb\u00b7sche", "Kran\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flucht nach allen Noten:", "tokens": ["Flucht", "nach", "al\u00b7len", "No\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbschu\u00dfwaffen zu tragen,\u00ab", "tokens": ["\u00bb", "schu\u00df\u00b7waf\u00b7fen", "zu", "tra\u00b7gen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVINF", "PTKZU", "VVINF", "$,", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sagt er, \u00bbsei verboten.", "tokens": ["Sagt", "er", ",", "\u00bb", "sei", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Schwer kann man beweisen,", "tokens": ["Schwer", "kann", "man", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ob sie blind geladen, \u2013", "tokens": ["Ob", "sie", "blind", "ge\u00b7la\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich will friedlich reisen!\u00ab", "tokens": ["Ich", "will", "fried\u00b7lich", "rei\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.23": {"line.1": {"text": "Nichts auch wollten helfen", "tokens": ["Nichts", "auch", "woll\u00b7ten", "hel\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ADV", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusinens Augen,", "tokens": ["Ve\u00b7nu\u00b7si\u00b7nens", "Au\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und der Schaffner meinte,", "tokens": ["Und", "der", "Schaff\u00b7ner", "mein\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie gar nichts taugen.", "tokens": ["Da\u00df", "sie", "gar", "nichts", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Menschen gut erzogen,", "tokens": ["Men\u00b7schen", "gut", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00e4re er der Ordnung", "tokens": ["W\u00e4\u00b7re", "er", "der", "Ord\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Halber mehr gewogen.", "tokens": ["Hal\u00b7ber", "mehr", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.25": {"line.1": {"text": "Strafgeb\u00fchren zahlte", "tokens": ["Straf\u00b7ge\u00b7b\u00fch\u00b7ren", "zahl\u00b7te"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusin erschrocken.", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7schro\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sucht nicht mehr mit Augen", "tokens": ["Sucht", "nicht", "mehr", "mit", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Reisende zu locken.", "tokens": ["Rei\u00b7sen\u00b7de", "zu", "lo\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.26": {"line.1": {"text": "In dem Mund, dem roten,", "tokens": ["In", "dem", "Mund", ",", "dem", "ro\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Knirschen ihre Z\u00e4hne:", "tokens": ["Knir\u00b7schen", "ih\u00b7re", "Z\u00e4h\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bballes scheint verboten!\u00ab", "tokens": ["\u00bb", "al\u00b7les", "scheint", "ver\u00b7bo\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.27": {"line.1": {"text": "Doch der h\u00fcbsche Kranke", "tokens": ["Doch", "der", "h\u00fcb\u00b7sche", "Kran\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00df sie starr besehen,", "tokens": ["Mu\u00df", "sie", "starr", "be\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "R\u00fcckt ihr leise n\u00e4her,", "tokens": ["R\u00fcckt", "ihr", "lei\u00b7se", "n\u00e4\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spricht: \u00bbIch mu\u00df gestehen,", "tokens": ["Spricht", ":", "\u00bb", "Ich", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.28": {"line.1": {"text": "Wundersch\u00f6ne Holde,", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7ne", "Hol\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ich lungenleidend", "tokens": ["Da\u00df", "ich", "lun\u00b7gen\u00b7lei\u00b7dend"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und nicht kr\u00e4nken wollte.", "tokens": ["Und", "nicht", "kr\u00e4n\u00b7ken", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.29": {"line.1": {"text": "Schmerzlich sch\u00f6n ist Ihre", "tokens": ["Schmerz\u00b7lich", "sch\u00f6n", "ist", "Ih\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VAFIN", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trauer um die Lippen.", "tokens": ["Trau\u00b7er", "um", "die", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seh ich Damen leiden,", "tokens": ["Seh", "ich", "Da\u00b7men", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mu\u00df mein Herz mir kippen.", "tokens": ["Mu\u00df", "mein", "Herz", "mir", "kip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.30": {"line.1": {"text": "Herrliche, erh\u00f6re!", "tokens": ["Herr\u00b7li\u00b7che", ",", "er\u00b7h\u00f6\u00b7re", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Kannst Du mir verzeihen?", "tokens": ["Kannst", "Du", "mir", "ver\u00b7zei\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sag' nicht, da\u00df ich st\u00f6re!\u00ab", "tokens": ["Sag'", "nicht", ",", "da\u00df", "ich", "st\u00f6\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.31": {"line.1": {"text": "Venus mu\u00df von Sinnen", "tokens": ["Ve\u00b7nus", "mu\u00df", "von", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Diesen Menschen w\u00e4hnen.", "tokens": ["Die\u00b7sen", "Men\u00b7schen", "w\u00e4h\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vorhin, als sie lachte,", "tokens": ["Vor\u00b7hin", ",", "als", "sie", "lach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Bracht' man sie zu Tr\u00e4nen.", "tokens": ["Bracht'", "man", "sie", "zu", "Tr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.32": {"line.1": {"text": "Jetzt erst soll sie lieben,", "tokens": ["Jetzt", "erst", "soll", "sie", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo die Lust verschwunden,", "tokens": ["Wo", "die", "Lust", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Leid geblieben.", "tokens": ["Und", "das", "Leid", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.33": {"line.1": {"text": "Venus kann nicht finden,", "tokens": ["Ve\u00b7nus", "kann", "nicht", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df die Lust sie beizte", "tokens": ["Da\u00df", "die", "Lust", "sie", "beiz\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jenen Herrn zu lieben,", "tokens": ["Je\u00b7nen", "Herrn", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Weil ihr Leid ihn reizte.", "tokens": ["Weil", "ihr", "Leid", "ihn", "reiz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.34": {"line.1": {"text": "Dieser aber lachte", "tokens": ["Die\u00b7ser", "a\u00b7ber", "lach\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber ihr Bedenken,", "tokens": ["\u00dc\u00b7ber", "ihr", "Be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil er anders dachte.", "tokens": ["Weil", "er", "an\u00b7ders", "dach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.35": {"line.1": {"text": "Und er r\u00fcckt ihr n\u00e4her,", "tokens": ["Und", "er", "r\u00fcckt", "ihr", "n\u00e4\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ganz auf sie versessen,", "tokens": ["Ganz", "auf", "sie", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will die G\u00f6ttin einfach", "tokens": ["Will", "die", "G\u00f6t\u00b7tin", "ein\u00b7fach"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Um die Taille pressen.", "tokens": ["Um", "die", "Tail\u00b7le", "pres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.36": {"line.1": {"text": "Gute Miene machend,", "tokens": ["Gu\u00b7te", "Mie\u00b7ne", "ma\u00b7chend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Denkt die G\u00f6ttin scherzend:", "tokens": ["Denkt", "die", "G\u00f6t\u00b7tin", "scher\u00b7zend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich nehm Alles lachend.", "tokens": ["Ich", "nehm", "Al\u00b7les", "la\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.37": {"line.1": {"text": "Zum Sankt Gotthard eben", "tokens": ["Zum", "Sankt", "Got\u00b7thard", "e\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "VVFIN", "NE", "ADV"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Dampft der Zug von Fluelen", "tokens": ["Dampft", "der", "Zug", "von", "Flue\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "H\u00f6her in die L\u00fcfte,", "tokens": ["H\u00f6\u00b7her", "in", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die sich d\u00fcnner f\u00fchlen.", "tokens": ["Die", "sich", "d\u00fcn\u00b7ner", "f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.38": {"line.1": {"text": "Hohle Echos krachen,", "tokens": ["Hoh\u00b7le", "E\u00b7chos", "kra\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und die Tunnell\u00f6cher", "tokens": ["Und", "die", "Tun\u00b7nel\u00b7l\u00f6\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dampfen gleich den Rachen.", "tokens": ["Damp\u00b7fen", "gleich", "den", "Ra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.39": {"line.1": {"text": "Hier im Schnee ward Mancher", "tokens": ["Hier", "im", "Schnee", "ward", "Man\u00b7cher"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VAFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von Sankt Gotthards Hunden,", "tokens": ["Von", "Sankt", "Got\u00b7thards", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "NE", "NN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Denkt sich Venusine,", "tokens": ["Denkt", "sich", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Liebend aufgefunden.", "tokens": ["Lie\u00b7bend", "auf\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.40": {"line.1": {"text": "Ach, ein Hund w\u00e4r heute", "tokens": ["Ach", ",", "ein", "Hund", "w\u00e4r", "heu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ehrlicher dem Herzen,", "tokens": ["Ehr\u00b7li\u00b7cher", "dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Als im Zug die Leute.", "tokens": ["Als", "im", "Zug", "die", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.41": {"line.1": {"text": "Will mal hier als G\u00f6ttin", "tokens": ["Will", "mal", "hier", "als", "G\u00f6t\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nach Belieben handeln,", "tokens": ["Nach", "Be\u00b7lie\u00b7ben", "han\u00b7deln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alle Herrn und Damen", "tokens": ["Al\u00b7le", "Herrn", "und", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00fcndisch mal verwandeln.", "tokens": ["H\u00fcn\u00b7disch", "mal", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.42": {"line.1": {"text": "Dieses soll mich r\u00e4chen \u2013", "tokens": ["Die\u00b7ses", "soll", "mich", "r\u00e4\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zu viel ist verboten \u2013", "tokens": ["Zu", "viel", "ist", "ver\u00b7bo\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "VVPP", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Lieb soll Fesseln brechen!", "tokens": ["Lieb", "soll", "Fes\u00b7seln", "bre\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.43": {"line.1": {"text": "Seht, und in dem Zuge,", "tokens": ["Seht", ",", "und", "in", "dem", "Zu\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kaum tat sie's bestellen,", "tokens": ["Kaum", "tat", "sie's", "be\u00b7stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Wurden Alle Hunde,", "tokens": ["Wur\u00b7den", "Al\u00b7le", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gr\u00fc\u00dften sich mit Bellen.", "tokens": ["Gr\u00fc\u00df\u00b7ten", "sich", "mit", "Bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.44": {"line.1": {"text": "Alles lief auf Vieren,", "tokens": ["Al\u00b7les", "lief", "auf", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wedelt, sich beriechend.", "tokens": ["We\u00b7delt", ",", "sich", "be\u00b7ri\u00b7e\u00b7chend", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRF", "VVPP", "$."], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Keinen tut's genieren.", "tokens": ["Kei\u00b7nen", "tut's", "ge\u00b7nie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.45": {"line.1": {"text": "Eh noch zur Besinnung", "tokens": ["Eh", "noch", "zur", "Be\u00b7sin\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Einer konnte kommen,", "tokens": ["Ei\u00b7ner", "konn\u00b7te", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ihm das Besinnen", "tokens": ["War", "ihm", "das", "Be\u00b7sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auch schon fortgenommen.", "tokens": ["Auch", "schon", "fort\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.46": {"line.1": {"text": "Bayern und Berliner,", "tokens": ["Bay\u00b7ern", "und", "Ber\u00b7li\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJA", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Herren und auch Damen", "tokens": ["Her\u00b7ren", "und", "auch", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wurden Bernhardiner.", "tokens": ["Wur\u00b7den", "Bern\u00b7har\u00b7di\u00b7ner", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.47": {"line.1": {"text": "Alle diese Menschen,", "tokens": ["Al\u00b7le", "die\u00b7se", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die verlogen sch\u00fcchtern", "tokens": ["Die", "ver\u00b7lo\u00b7gen", "sch\u00fcch\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sich nach Liebe sehnten,", "tokens": ["Sich", "nach", "Lie\u00b7be", "sehn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fordern sie jetzt n\u00fcchtern.", "tokens": ["For\u00b7dern", "sie", "jetzt", "n\u00fcch\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.48": {"line.1": {"text": "Jenem Herrn von Allen,", "tokens": ["Je\u00b7nem", "Herrn", "von", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Den das Leid nur reizte,", "tokens": ["Den", "das", "Leid", "nur", "reiz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will die Lust gefallen.", "tokens": ["Will", "die", "Lust", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.49": {"line.1": {"text": "Sprang und leckt und wedelt", "tokens": ["Sprang", "und", "leckt", "und", "we\u00b7delt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hinter andern Hunden,", "tokens": ["Hin\u00b7ter", "an\u00b7dern", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat in Lebensfrohsinn", "tokens": ["Hat", "in", "Le\u00b7bens\u00b7froh\u00b7sinn"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich gar schnell gefunden.", "tokens": ["Sich", "gar", "schnell", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.50": {"line.1": {"text": "Liebte Hundedamen,", "tokens": ["Lieb\u00b7te", "Hun\u00b7de\u00b7da\u00b7men", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die sich unter Bellen", "tokens": ["Die", "sich", "un\u00b7ter", "Bel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schwanzwedelnd benahmen.", "tokens": ["Schwanz\u00b7we\u00b7delnd", "be\u00b7nah\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.51": {"line.1": {"text": "Das war ein Bespringen,", "tokens": ["Das", "war", "ein", "Be\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Selig ein Begatten!", "tokens": ["Se\u00b7lig", "ein", "Be\u00b7gat\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man liebt vor Allen,", "tokens": ["Und", "man", "liebt", "vor", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die die Laufzeit hatten.", "tokens": ["Die", "die", "Lauf\u00b7zeit", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.52": {"line.1": {"text": "Schnell sich Alle kannten,", "tokens": ["Schnell", "sich", "Al\u00b7le", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "PIS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und in allen Klassen", "tokens": ["Und", "in", "al\u00b7len", "Klas\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ward man zu Verwandten.", "tokens": ["Ward", "man", "zu", "Ver\u00b7wand\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.53": {"line.1": {"text": "Amor lag auf Kissen", "tokens": ["A\u00b7mor", "lag", "auf", "Kis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und mu\u00df g\u00f6ttlich lachen:", "tokens": ["Und", "mu\u00df", "g\u00f6tt\u00b7lich", "la\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbmama Venusine,", "tokens": ["\u00bb", "ma\u00b7ma", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "FM.la", "FM.la", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Du machst tolle Sachen!", "tokens": ["Du", "machst", "tol\u00b7le", "Sa\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-++-+-", "measure": "unknown.measure.tri"}}, "stanza.54": {"line.1": {"text": "Du erl\u00f6st die Leute", "tokens": ["Du", "er\u00b7l\u00f6st", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf besondre Weise!", "tokens": ["Auf", "be\u00b7sond\u00b7re", "Wei\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Endlich liebt man heute!\u00ab \u2013", "tokens": ["End\u00b7lich", "liebt", "man", "heu\u00b7te", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$.", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.55": {"line.1": {"text": "Hell voll Gl\u00fchlichtlampen", "tokens": ["Hell", "voll", "Gl\u00fch\u00b7licht\u00b7lam\u00b7pen"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eilen Luxuswagen;", "tokens": ["Ei\u00b7len", "Lu\u00b7xus\u00b7wa\u00b7gen", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Niemand ahnt von drau\u00dfen,", "tokens": ["Nie\u00b7mand", "ahnt", "von", "drau\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie Hunde tragen.", "tokens": ["Da\u00df", "sie", "Hun\u00b7de", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.56": {"line.1": {"text": "Und der Gotthard lachte", "tokens": ["Und", "der", "Got\u00b7thard", "lach\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NE", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "\u00dcber Venusine,", "tokens": ["\u00dc\u00b7ber", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die das fertig brachte.", "tokens": ["Die", "das", "fer\u00b7tig", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.57": {"line.1": {"text": "Als der Zug den letzten", "tokens": ["Als", "der", "Zug", "den", "letz\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tunnel just passierte,", "tokens": ["Tun\u00b7nel", "just", "pas\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lagen tausend kleine", "tokens": ["La\u00b7gen", "tau\u00b7send", "klei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "CARD", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "V\u00f6gel, schneeverirrte,", "tokens": ["V\u00f6\u00b7gel", ",", "schnee\u00b7ver\u00b7irr\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.58": {"line.1": {"text": "Im Gefild, im kalten.", "tokens": ["Im", "Ge\u00b7fild", ",", "im", "kal\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbhalt!\u00ab rief Venusine.", "tokens": ["\u00bb", "halt", "!", "\u00ab", "rief", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "NE", "$."], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Und der Zug mu\u00df halten.", "tokens": ["Und", "der", "Zug", "mu\u00df", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.59": {"line.1": {"text": "Alle Bernhardiner", "tokens": ["Al\u00b7le", "Bern\u00b7har\u00b7di\u00b7ner"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind hinausbefohlen,", "tokens": ["Sind", "hin\u00b7aus\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ein Jeder mu\u00dfte", "tokens": ["Und", "ein", "Je\u00b7der", "mu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PIS", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Von den V\u00f6geln holen.", "tokens": ["Von", "den", "V\u00f6\u00b7geln", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.60": {"line.1": {"text": "Und sie apportieren", "tokens": ["Und", "sie", "ap\u00b7por\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Vorsichtig im Maule,", "tokens": ["Vor\u00b7sich\u00b7tig", "im", "Mau\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "V\u00f6gel, die erfrieren.", "tokens": ["V\u00f6\u00b7gel", ",", "die", "er\u00b7frie\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.61": {"line.1": {"text": "In den warmen Wagen", "tokens": ["In", "den", "war\u00b7men", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind bald neugeboren", "tokens": ["Sind", "bald", "neu\u00b7ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Diese. Und kaum lebend", "tokens": ["Die\u00b7se", ".", "Und", "kaum", "le\u00b7bend"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDAT", "$.", "KON", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Danken sie den Ohren.", "tokens": ["Dan\u00b7ken", "sie", "den", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.62": {"line.1": {"text": "Nachtigallen, Meisen", "tokens": ["Nach\u00b7ti\u00b7gal\u00b7len", ",", "Mei\u00b7sen"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Danken Venusine,", "tokens": ["Dan\u00b7ken", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-----", "measure": "dactylic.init"}, "line.3": {"text": "Singend ihre Weisen.", "tokens": ["Sin\u00b7gend", "ih\u00b7re", "Wei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.63": {"line.1": {"text": "Alle V\u00f6gel kannten", "tokens": ["Al\u00b7le", "V\u00f6\u00b7gel", "kann\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich die G\u00f6ttin wieder.", "tokens": ["Gleich", "die", "G\u00f6t\u00b7tin", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf dem H\u00f6rselberge", "tokens": ["Auf", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Lehrt' sie j\u00e4hrlich Lieder,", "tokens": ["Lehrt'", "sie", "j\u00e4hr\u00b7lich", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.64": {"line.1": {"text": "Jedem M\u00e4nnchen neue,", "tokens": ["Je\u00b7dem", "M\u00e4nn\u00b7chen", "neu\u00b7e", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df der Wald erbl\u00fche", "tokens": ["Da\u00df", "der", "Wald", "er\u00b7bl\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sich's Weibchen freue.", "tokens": ["Und", "sich's", "Weib\u00b7chen", "freu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.65": {"line.1": {"text": "Auch die Hunde liegen", "tokens": ["Auch", "die", "Hun\u00b7de", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Horchend auf den Kissen.", "tokens": ["Hor\u00b7chend", "auf", "den", "Kis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil sie jetzt die N\u00e4he", "tokens": ["Weil", "sie", "jetzt", "die", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einer G\u00f6ttin wissen,", "tokens": ["Ei\u00b7ner", "G\u00f6t\u00b7tin", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.66": {"line.1": {"text": "Zeigen sie die Spuren,", "tokens": ["Zei\u00b7gen", "sie", "die", "Spu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heute \u00fcberwundner,", "tokens": ["Heu\u00b7te", "\u00fc\u00b7berw\u00b7und\u00b7ner", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Menschlicher Kulturen.", "tokens": ["Menschli\u00b7cher", "Kul\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.67": {"line.1": {"text": "Nach Chiasso senken", "tokens": ["Nach", "Chi\u00b7as\u00b7so", "sen\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sich die Berggel\u00e4nde,", "tokens": ["Sich", "die", "Berg\u00b7ge\u00b7l\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hundertschluchtig gr\u00fc\u00dfen", "tokens": ["Hun\u00b7dertsc\u00b7hluch\u00b7tig", "gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word"], "pos": ["ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dort Italiens W\u00e4nde.", "tokens": ["Dort", "I\u00b7ta\u00b7li\u00b7ens", "W\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.68": {"line.1": {"text": "So kam Venusine", "tokens": ["So", "kam", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Zu des S\u00fcdens Grenze,", "tokens": ["Zu", "des", "S\u00fc\u00b7dens", "Gren\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schalk in jeder Miene.", "tokens": ["Schalk", "in", "je\u00b7der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.69": {"line.1": {"text": "\u00bbeckehardt, mein Lieber,", "tokens": ["\u00bb", "ec\u00b7ke\u00b7hardt", ",", "mein", "Lie\u00b7ber", ","], "token_info": ["punct", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ADJD", "$,", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Liebst du nie das Fesche?", "tokens": ["Liebst", "du", "nie", "das", "Fe\u00b7sche", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schrecklich ist dein Wollkleid", "tokens": ["Schreck\u00b7lich", "ist", "dein", "Woll\u00b7kleid"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "VAFIN", "PPOSAT", "NN"], "meter": "+--+-+", "measure": "iambic.tri.invert"}, "line.4": {"text": "Und die J\u00e4gerw\u00e4sche!", "tokens": ["Und", "die", "J\u00e4\u00b7ger\u00b7w\u00e4\u00b7sche", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.70": {"line.1": {"text": "Trag doch nicht so lose,", "tokens": ["Trag", "doch", "nicht", "so", "lo\u00b7se", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKNEG", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Amor, lieber Junge,", "tokens": ["A\u00b7mor", ",", "lie\u00b7ber", "Jun\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Deinen Knopf der Hose!\u00ab", "tokens": ["Dei\u00b7nen", "Knopf", "der", "Ho\u00b7se", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "ART", "NN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.71": {"line.1": {"text": "So sprach Venusine,", "tokens": ["So", "sprach", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NE", "$,"], "meter": "-+----", "measure": "dactylic.init"}, "line.2": {"text": "Als man in D-Z\u00fcgen", "tokens": ["Als", "man", "in", "D\u00b7\u00b7Z\u00fc\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "PIS", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sa\u00df und nach Italien", "tokens": ["Sa\u00df", "und", "nach", "I\u00b7ta\u00b7li\u00b7en"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "KON", "APPR", "NE"], "meter": "+-+-+--", "measure": "unknown.measure.tri"}, "line.4": {"text": "Flog in Rasselfl\u00fcgen.", "tokens": ["Flog", "in", "Ras\u00b7sel\u00b7fl\u00fc\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.72": {"line.1": {"text": "Aus dem Berge drau\u00dfen", "tokens": ["Aus", "dem", "Ber\u00b7ge", "drau\u00b7\u00dfen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "NN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hielt sie mehr als drinnen", "tokens": ["Hielt", "sie", "mehr", "als", "drin\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PIAT", "KOKOM", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf den Takt nach au\u00dfen.", "tokens": ["Auf", "den", "Takt", "nach", "au\u00b7\u00dfen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "APPR", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.73": {"line.1": {"text": "Aber nichts konnt' hindern,", "tokens": ["A\u00b7ber", "nichts", "konnt'", "hin\u00b7dern", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df in frohen Stunden", "tokens": ["Da\u00df", "in", "fro\u00b7hen", "Stun\u00b7den"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "APPR", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sie und ihr Gefolge,", "tokens": ["Sie", "und", "ihr", "Ge\u00b7fol\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "KON", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ganz kulturentbunden,", "tokens": ["Ganz", "kul\u00b7tu\u00b7rent\u00b7bun\u00b7den", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.74": {"line.1": {"text": "In die L\u00fcfte wollten,", "tokens": ["In", "die", "L\u00fcf\u00b7te", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Aus den Fenstern flogen,", "tokens": ["Aus", "den", "Fens\u00b7tern", "flo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hinter Wolken tollten.", "tokens": ["Hin\u00b7ter", "Wol\u00b7ken", "toll\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.75": {"line.1": {"text": "Und im Zug bemerken", "tokens": ["Und", "im", "Zug", "be\u00b7mer\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPRART", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Manche Passagiere:", "tokens": ["Man\u00b7che", "Pas\u00b7sa\u00b7gie\u00b7re", ":"], "token_info": ["word", "word", "punct"], "pos": ["PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Im Maschinendampfe,", "tokens": ["Im", "Ma\u00b7schi\u00b7nen\u00b7damp\u00b7fe", ","], "token_info": ["word", "word", "punct"], "pos": ["APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nackt ein Weib spaziere.", "tokens": ["Nackt", "ein", "Weib", "spa\u00b7zie\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.76": {"line.1": {"text": "Konnt' durch L\u00fcfte jagen,", "tokens": ["Konnt'", "durch", "L\u00fcf\u00b7te", "ja\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mit dem Vollmond spielen,", "tokens": ["Mit", "dem", "Voll\u00b7mond", "spie\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wald und Berge tragen. \u2013", "tokens": ["Wald", "und", "Ber\u00b7ge", "tra\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "KON", "NN", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.77": {"line.1": {"text": "Sa\u00df da h\u00fcbsch ein Bursche", "tokens": ["Sa\u00df", "da", "h\u00fcbsch", "ein", "Bur\u00b7sche"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "ADV", "ADJD", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "In der ersten Klasse.", "tokens": ["In", "der", "ers\u00b7ten", "Klas\u00b7se", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Halbtot war er leider,", "tokens": ["Halb\u00b7tot", "war", "er", "lei\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "PPER", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Halb Tuberkelmasse.", "tokens": ["Halb", "Tu\u00b7ber\u00b7kel\u00b7mas\u00b7se", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.78": {"line.1": {"text": "Sollte nach dem S\u00fcden.", "tokens": ["Soll\u00b7te", "nach", "dem", "S\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ihn sah Venusine", "tokens": ["Ihn", "sah", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.3": {"text": "Und behext den M\u00fcden.", "tokens": ["Und", "be\u00b7hext", "den", "M\u00fc\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.79": {"line.1": {"text": "Denkt: Sollst Dich nicht qu\u00e4len", "tokens": ["Denkt", ":", "Sollst", "Dich", "nicht", "qu\u00e4\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$.", "VMFIN", "PPER", "PTKNEG", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "H\u00fcbschester Geselle?", "tokens": ["H\u00fcb\u00b7sches\u00b7ter", "Ge\u00b7sel\u00b7le", "?"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Stehst mit einem Fu\u00dfe", "tokens": ["Stehst", "mit", "ei\u00b7nem", "Fu\u00b7\u00dfe"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auf der Beinhausschwelle.", "tokens": ["Auf", "der", "Be\u00b7in\u00b7haus\u00b7schwel\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.80": {"line.1": {"text": "Dir den Tod vers\u00fc\u00dfen,", "tokens": ["Dir", "den", "Tod", "ver\u00b7s\u00fc\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Soll mich heut zerstreuen,", "tokens": ["Soll", "mich", "heut", "zer\u00b7streu\u00b7en", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Komm und la\u00df dich k\u00fcssen!", "tokens": ["Komm", "und", "la\u00df", "dich", "k\u00fcs\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "KON", "VVIMP", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.81": {"line.1": {"text": "Leis spricht sie zu Amor:", "tokens": ["Leis", "spricht", "sie", "zu", "A\u00b7mor", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "NE", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "\u00bbliebstes S\u00f6hnchen, gehe,", "tokens": ["\u00bb", "liebs\u00b7tes", "S\u00f6hn\u00b7chen", ",", "ge\u00b7he", ","], "token_info": ["punct", "word", "word", "punct", "word", "punct"], "pos": ["$(", "ADJA", "NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Da\u00df dem h\u00fcbschen Menschen", "tokens": ["Da\u00df", "dem", "h\u00fcb\u00b7schen", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Liebes bald geschehe!", "tokens": ["Lie\u00b7bes", "bald", "ge\u00b7sche\u00b7he", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.82": {"line.1": {"text": "Geh auf fester Sohle,", "tokens": ["Geh", "auf", "fes\u00b7ter", "Soh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Dicht ihm an das Herze,", "tokens": ["Dicht", "ihm", "an", "das", "Her\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "APPR", "PDS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Setz' ihm die Pistole!\u00ab", "tokens": ["Setz'", "ihm", "die", "Pis\u00b7to\u00b7le", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$.", "$("], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.83": {"line.1": {"text": "Amor zielt voll Eifer,", "tokens": ["A\u00b7mor", "zielt", "voll", "Ei\u00b7fer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Schie\u00dft auf Wunsch der Mutter,", "tokens": ["Schie\u00dft", "auf", "Wunsch", "der", "Mut\u00b7ter", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "NN", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Trifft den jungen Menschen", "tokens": ["Trifft", "den", "jun\u00b7gen", "Men\u00b7schen"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Durch das Westenfutter.", "tokens": ["Durch", "das", "Wes\u00b7ten\u00b7fut\u00b7ter", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.84": {"line.1": {"text": "Doch, ach, nie bedachten", "tokens": ["Doch", ",", "ach", ",", "nie", "be\u00b7dach\u00b7ten"], "token_info": ["word", "punct", "word", "punct", "word", "word"], "pos": ["KON", "$,", "ITJ", "$,", "ADV", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "G\u00f6tter fehllos handelnd,", "tokens": ["G\u00f6t\u00b7ter", "fehl\u00b7los", "han\u00b7delnd", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ob sie's richtig machten!", "tokens": ["Ob", "sie's", "rich\u00b7tig", "mach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.85": {"line.1": {"text": "Kaum ging die Pistole", "tokens": ["Kaum", "ging", "die", "Pis\u00b7to\u00b7le"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Los mit frohem Knalle,", "tokens": ["Los", "mit", "fro\u00b7hem", "Knal\u00b7le", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sa\u00df der kleine Amor", "tokens": ["Sa\u00df", "der", "klei\u00b7ne", "A\u00b7mor"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "In der Mausefalle.", "tokens": ["In", "der", "Mau\u00b7se\u00b7fal\u00b7le", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.86": {"line.1": {"text": "Denn der Herr springt pfauchend", "tokens": ["Denn", "der", "Herr", "springt", "pfau\u00b7chend"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "VVFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nach der Angstnotleine,", "tokens": ["Nach", "der", "Angst\u00b7not\u00b7lei\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "B\u00f6se Worte brauchend.", "tokens": ["B\u00f6\u00b7se", "Wor\u00b7te", "brau\u00b7chend", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.87": {"line.1": {"text": "Schaffner und die F\u00fchrer", "tokens": ["Schaff\u00b7ner", "und", "die", "F\u00fch\u00b7rer"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eilen an die T\u00fcren,", "tokens": ["Ei\u00b7len", "an", "die", "T\u00fc\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man will den Amor", "tokens": ["Und", "man", "will", "den", "A\u00b7mor"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PIS", "VMFIN", "ART", "NE"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Strafen mit Geb\u00fchren.", "tokens": ["Stra\u00b7fen", "mit", "Ge\u00b7b\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.88": {"line.1": {"text": "Nichts half, da\u00df er meinte,", "tokens": ["Nichts", "half", ",", "da\u00df", "er", "mein\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Er hab nicht get\u00f6tet", "tokens": ["Er", "hab", "nicht", "ge\u00b7t\u00f6\u00b7tet"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PTKNEG", "VVPP"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und wie Kinder weinte.", "tokens": ["Und", "wie", "Kin\u00b7der", "wein\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "NN", "VVFIN", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.89": {"line.1": {"text": "Jener h\u00fcbsche Kranke", "tokens": ["Je\u00b7ner", "h\u00fcb\u00b7sche", "Kran\u00b7ke"], "token_info": ["word", "word", "word"], "pos": ["PDAT", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Flucht nach allen Noten:", "tokens": ["Flucht", "nach", "al\u00b7len", "No\u00b7ten", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbschu\u00dfwaffen zu tragen,\u00ab", "tokens": ["\u00bb", "schu\u00df\u00b7waf\u00b7fen", "zu", "tra\u00b7gen", ",", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "VVINF", "PTKZU", "VVINF", "$,", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Sagt er, \u00bbsei verboten.", "tokens": ["Sagt", "er", ",", "\u00bb", "sei", "ver\u00b7bo\u00b7ten", "."], "token_info": ["word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "$(", "VAFIN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.90": {"line.1": {"text": "Schwer kann man beweisen,", "tokens": ["Schwer", "kann", "man", "be\u00b7wei\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "VMFIN", "PIS", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ob sie blind geladen, \u2013", "tokens": ["Ob", "sie", "blind", "ge\u00b7la\u00b7den", ",", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "$,", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich will friedlich reisen!\u00ab", "tokens": ["Ich", "will", "fried\u00b7lich", "rei\u00b7sen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VMFIN", "ADJD", "VVINF", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.91": {"line.1": {"text": "Nichts auch wollten helfen", "tokens": ["Nichts", "auch", "woll\u00b7ten", "hel\u00b7fen"], "token_info": ["word", "word", "word", "word"], "pos": ["PIS", "ADV", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusinens Augen,", "tokens": ["Ve\u00b7nu\u00b7si\u00b7nens", "Au\u00b7gen", ","], "token_info": ["word", "word", "punct"], "pos": ["NE", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Und der Schaffner meinte,", "tokens": ["Und", "der", "Schaff\u00b7ner", "mein\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie gar nichts taugen.", "tokens": ["Da\u00df", "sie", "gar", "nichts", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "PIS", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.92": {"line.1": {"text": "Menschen gut erzogen,", "tokens": ["Men\u00b7schen", "gut", "er\u00b7zo\u00b7gen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "W\u00e4re er der Ordnung", "tokens": ["W\u00e4\u00b7re", "er", "der", "Ord\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Halber mehr gewogen.", "tokens": ["Hal\u00b7ber", "mehr", "ge\u00b7wo\u00b7gen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.93": {"line.1": {"text": "Strafgeb\u00fchren zahlte", "tokens": ["Straf\u00b7ge\u00b7b\u00fch\u00b7ren", "zahl\u00b7te"], "token_info": ["word", "word"], "pos": ["NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Venusin erschrocken.", "tokens": ["Ve\u00b7nu\u00b7sin", "er\u00b7schro\u00b7cken", "."], "token_info": ["word", "word", "punct"], "pos": ["NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sucht nicht mehr mit Augen", "tokens": ["Sucht", "nicht", "mehr", "mit", "Au\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PTKNEG", "ADV", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Reisende zu locken.", "tokens": ["Rei\u00b7sen\u00b7de", "zu", "lo\u00b7cken", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PTKZU", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.94": {"line.1": {"text": "In dem Mund, dem roten,", "tokens": ["In", "dem", "Mund", ",", "dem", "ro\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$,", "ART", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Knirschen ihre Z\u00e4hne:", "tokens": ["Knir\u00b7schen", "ih\u00b7re", "Z\u00e4h\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bballes scheint verboten!\u00ab", "tokens": ["\u00bb", "al\u00b7les", "scheint", "ver\u00b7bo\u00b7ten", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "punct", "punct"], "pos": ["$(", "PIS", "VVFIN", "VVPP", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.95": {"line.1": {"text": "Doch der h\u00fcbsche Kranke", "tokens": ["Doch", "der", "h\u00fcb\u00b7sche", "Kran\u00b7ke"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Mu\u00df sie starr besehen,", "tokens": ["Mu\u00df", "sie", "starr", "be\u00b7se\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADJD", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "R\u00fcckt ihr leise n\u00e4her,", "tokens": ["R\u00fcckt", "ihr", "lei\u00b7se", "n\u00e4\u00b7her", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Spricht: \u00bbIch mu\u00df gestehen,", "tokens": ["Spricht", ":", "\u00bb", "Ich", "mu\u00df", "ge\u00b7ste\u00b7hen", ","], "token_info": ["word", "punct", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "$.", "$(", "PPER", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.96": {"line.1": {"text": "Wundersch\u00f6ne Holde,", "tokens": ["Wun\u00b7der\u00b7sch\u00f6\u00b7ne", "Hol\u00b7de", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df ich lungenleidend", "tokens": ["Da\u00df", "ich", "lun\u00b7gen\u00b7lei\u00b7dend"], "token_info": ["word", "word", "word"], "pos": ["KOUS", "PPER", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und nicht kr\u00e4nken wollte.", "tokens": ["Und", "nicht", "kr\u00e4n\u00b7ken", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PTKNEG", "VVINF", "VMFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.97": {"line.1": {"text": "Schmerzlich sch\u00f6n ist Ihre", "tokens": ["Schmerz\u00b7lich", "sch\u00f6n", "ist", "Ih\u00b7re"], "token_info": ["word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "VAFIN", "PPOSAT"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Trauer um die Lippen.", "tokens": ["Trau\u00b7er", "um", "die", "Lip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Seh ich Damen leiden,", "tokens": ["Seh", "ich", "Da\u00b7men", "lei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mu\u00df mein Herz mir kippen.", "tokens": ["Mu\u00df", "mein", "Herz", "mir", "kip\u00b7pen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.98": {"line.1": {"text": "Herrliche, erh\u00f6re!", "tokens": ["Herr\u00b7li\u00b7che", ",", "er\u00b7h\u00f6\u00b7re", "!"], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$."], "meter": "+---+-", "measure": "dactylic.init"}, "line.2": {"text": "Kannst Du mir verzeihen?", "tokens": ["Kannst", "Du", "mir", "ver\u00b7zei\u00b7hen", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sag' nicht, da\u00df ich st\u00f6re!\u00ab", "tokens": ["Sag'", "nicht", ",", "da\u00df", "ich", "st\u00f6\u00b7re", "!", "\u00ab"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "punct"], "pos": ["NN", "PTKNEG", "$,", "KOUS", "PPER", "VVFIN", "$.", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.99": {"line.1": {"text": "Venus mu\u00df von Sinnen", "tokens": ["Ve\u00b7nus", "mu\u00df", "von", "Sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VMFIN", "APPR", "NN"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Diesen Menschen w\u00e4hnen.", "tokens": ["Die\u00b7sen", "Men\u00b7schen", "w\u00e4h\u00b7nen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PDAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Vorhin, als sie lachte,", "tokens": ["Vor\u00b7hin", ",", "als", "sie", "lach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Bracht' man sie zu Tr\u00e4nen.", "tokens": ["Bracht'", "man", "sie", "zu", "Tr\u00e4\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PIS", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.100": {"line.1": {"text": "Jetzt erst soll sie lieben,", "tokens": ["Jetzt", "erst", "soll", "sie", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Wo die Lust verschwunden,", "tokens": ["Wo", "die", "Lust", "ver\u00b7schwun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und das Leid geblieben.", "tokens": ["Und", "das", "Leid", "ge\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.101": {"line.1": {"text": "Venus kann nicht finden,", "tokens": ["Ve\u00b7nus", "kann", "nicht", "fin\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PTKNEG", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df die Lust sie beizte", "tokens": ["Da\u00df", "die", "Lust", "sie", "beiz\u00b7te"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "PPER", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Jenen Herrn zu lieben,", "tokens": ["Je\u00b7nen", "Herrn", "zu", "lie\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Weil ihr Leid ihn reizte.", "tokens": ["Weil", "ihr", "Leid", "ihn", "reiz\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.102": {"line.1": {"text": "Dieser aber lachte", "tokens": ["Die\u00b7ser", "a\u00b7ber", "lach\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00dcber ihr Bedenken,", "tokens": ["\u00dc\u00b7ber", "ihr", "Be\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil er anders dachte.", "tokens": ["Weil", "er", "an\u00b7ders", "dach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.103": {"line.1": {"text": "Und er r\u00fcckt ihr n\u00e4her,", "tokens": ["Und", "er", "r\u00fcckt", "ihr", "n\u00e4\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "PPER", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ganz auf sie versessen,", "tokens": ["Ganz", "auf", "sie", "ver\u00b7ses\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will die G\u00f6ttin einfach", "tokens": ["Will", "die", "G\u00f6t\u00b7tin", "ein\u00b7fach"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "ART", "NN", "ADV"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.4": {"text": "Um die Taille pressen.", "tokens": ["Um", "die", "Tail\u00b7le", "pres\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUI", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.104": {"line.1": {"text": "Gute Miene machend,", "tokens": ["Gu\u00b7te", "Mie\u00b7ne", "ma\u00b7chend", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVPP", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Denkt die G\u00f6ttin scherzend:", "tokens": ["Denkt", "die", "G\u00f6t\u00b7tin", "scher\u00b7zend", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ich nehm Alles lachend.", "tokens": ["Ich", "nehm", "Al\u00b7les", "la\u00b7chend", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.105": {"line.1": {"text": "Zum Sankt Gotthard eben", "tokens": ["Zum", "Sankt", "Got\u00b7thard", "e\u00b7ben"], "token_info": ["word", "word", "word", "word"], "pos": ["APPRART", "VVFIN", "NE", "ADV"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Dampft der Zug von Fluelen", "tokens": ["Dampft", "der", "Zug", "von", "Flue\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "H\u00f6her in die L\u00fcfte,", "tokens": ["H\u00f6\u00b7her", "in", "die", "L\u00fcf\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die sich d\u00fcnner f\u00fchlen.", "tokens": ["Die", "sich", "d\u00fcn\u00b7ner", "f\u00fch\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.106": {"line.1": {"text": "Hohle Echos krachen,", "tokens": ["Hoh\u00b7le", "E\u00b7chos", "kra\u00b7chen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und die Tunnell\u00f6cher", "tokens": ["Und", "die", "Tun\u00b7nel\u00b7l\u00f6\u00b7cher"], "token_info": ["word", "word", "word"], "pos": ["KON", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Dampfen gleich den Rachen.", "tokens": ["Damp\u00b7fen", "gleich", "den", "Ra\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.107": {"line.1": {"text": "Hier im Schnee ward Mancher", "tokens": ["Hier", "im", "Schnee", "ward", "Man\u00b7cher"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "APPRART", "NN", "VAFIN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Von Sankt Gotthards Hunden,", "tokens": ["Von", "Sankt", "Got\u00b7thards", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "VVFIN", "NE", "NN", "$,"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.3": {"text": "Denkt sich Venusine,", "tokens": ["Denkt", "sich", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Liebend aufgefunden.", "tokens": ["Lie\u00b7bend", "auf\u00b7ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.108": {"line.1": {"text": "Ach, ein Hund w\u00e4r heute", "tokens": ["Ach", ",", "ein", "Hund", "w\u00e4r", "heu\u00b7te"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["ITJ", "$,", "ART", "NN", "VAFIN", "ADV"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Ehrlicher dem Herzen,", "tokens": ["Ehr\u00b7li\u00b7cher", "dem", "Her\u00b7zen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "Als im Zug die Leute.", "tokens": ["Als", "im", "Zug", "die", "Leu\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPRART", "NN", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.109": {"line.1": {"text": "Will mal hier als G\u00f6ttin", "tokens": ["Will", "mal", "hier", "als", "G\u00f6t\u00b7tin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VMFIN", "ADV", "ADV", "KOUS", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Nach Belieben handeln,", "tokens": ["Nach", "Be\u00b7lie\u00b7ben", "han\u00b7deln", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Alle Herrn und Damen", "tokens": ["Al\u00b7le", "Herrn", "und", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["PIAT", "NN", "KON", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "H\u00fcndisch mal verwandeln.", "tokens": ["H\u00fcn\u00b7disch", "mal", "ver\u00b7wan\u00b7deln", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "ADV", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.110": {"line.1": {"text": "Dieses soll mich r\u00e4chen \u2013", "tokens": ["Die\u00b7ses", "soll", "mich", "r\u00e4\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Zu viel ist verboten \u2013", "tokens": ["Zu", "viel", "ist", "ver\u00b7bo\u00b7ten", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIS", "VAFIN", "VVPP", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Lieb soll Fesseln brechen!", "tokens": ["Lieb", "soll", "Fes\u00b7seln", "bre\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.111": {"line.1": {"text": "Seht, und in dem Zuge,", "tokens": ["Seht", ",", "und", "in", "dem", "Zu\u00b7ge", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KON", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Kaum tat sie's bestellen,", "tokens": ["Kaum", "tat", "sie's", "be\u00b7stel\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.3": {"text": "Wurden Alle Hunde,", "tokens": ["Wur\u00b7den", "Al\u00b7le", "Hun\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Gr\u00fc\u00dften sich mit Bellen.", "tokens": ["Gr\u00fc\u00df\u00b7ten", "sich", "mit", "Bel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PRF", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.112": {"line.1": {"text": "Alles lief auf Vieren,", "tokens": ["Al\u00b7les", "lief", "auf", "Vie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Wedelt, sich beriechend.", "tokens": ["We\u00b7delt", ",", "sich", "be\u00b7ri\u00b7e\u00b7chend", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["VVFIN", "$,", "PRF", "VVPP", "$."], "meter": "+-++-+-", "measure": "unknown.measure.tetra"}, "line.3": {"text": "Keinen tut's genieren.", "tokens": ["Kei\u00b7nen", "tut's", "ge\u00b7nie\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.113": {"line.1": {"text": "Eh noch zur Besinnung", "tokens": ["Eh", "noch", "zur", "Be\u00b7sin\u00b7nung"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "ADV", "APPRART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Einer konnte kommen,", "tokens": ["Ei\u00b7ner", "konn\u00b7te", "kom\u00b7men", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "War ihm das Besinnen", "tokens": ["War", "ihm", "das", "Be\u00b7sin\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Auch schon fortgenommen.", "tokens": ["Auch", "schon", "fort\u00b7ge\u00b7nom\u00b7men", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.114": {"line.1": {"text": "Bayern und Berliner,", "tokens": ["Bay\u00b7ern", "und", "Ber\u00b7li\u00b7ner", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "ADJA", "$,"], "meter": "+--+--", "measure": "dactylic.di.plus"}, "line.2": {"text": "Herren und auch Damen", "tokens": ["Her\u00b7ren", "und", "auch", "Da\u00b7men"], "token_info": ["word", "word", "word", "word"], "pos": ["NN", "KON", "ADV", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Wurden Bernhardiner.", "tokens": ["Wur\u00b7den", "Bern\u00b7har\u00b7di\u00b7ner", "."], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.115": {"line.1": {"text": "Alle diese Menschen,", "tokens": ["Al\u00b7le", "die\u00b7se", "Men\u00b7schen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "PDAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die verlogen sch\u00fcchtern", "tokens": ["Die", "ver\u00b7lo\u00b7gen", "sch\u00fcch\u00b7tern"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Sich nach Liebe sehnten,", "tokens": ["Sich", "nach", "Lie\u00b7be", "sehn\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "APPR", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Fordern sie jetzt n\u00fcchtern.", "tokens": ["For\u00b7dern", "sie", "jetzt", "n\u00fcch\u00b7tern", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.116": {"line.1": {"text": "Jenem Herrn von Allen,", "tokens": ["Je\u00b7nem", "Herrn", "von", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDAT", "NN", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Den das Leid nur reizte,", "tokens": ["Den", "das", "Leid", "nur", "reiz\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Will die Lust gefallen.", "tokens": ["Will", "die", "Lust", "ge\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ART", "NN", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.117": {"line.1": {"text": "Sprang und leckt und wedelt", "tokens": ["Sprang", "und", "leckt", "und", "we\u00b7delt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "KON", "VVFIN", "KON", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Hinter andern Hunden,", "tokens": ["Hin\u00b7ter", "an\u00b7dern", "Hun\u00b7den", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hat in Lebensfrohsinn", "tokens": ["Hat", "in", "Le\u00b7bens\u00b7froh\u00b7sinn"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Sich gar schnell gefunden.", "tokens": ["Sich", "gar", "schnell", "ge\u00b7fun\u00b7den", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PRF", "ADV", "ADJD", "VVPP", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.118": {"line.1": {"text": "Liebte Hundedamen,", "tokens": ["Lieb\u00b7te", "Hun\u00b7de\u00b7da\u00b7men", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Die sich unter Bellen", "tokens": ["Die", "sich", "un\u00b7ter", "Bel\u00b7len"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "PRF", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schwanzwedelnd benahmen.", "tokens": ["Schwanz\u00b7we\u00b7delnd", "be\u00b7nah\u00b7men", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJD", "VVINF", "$."], "meter": "+---+-", "measure": "dactylic.init"}}, "stanza.119": {"line.1": {"text": "Das war ein Bespringen,", "tokens": ["Das", "war", "ein", "Be\u00b7sprin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.2": {"text": "Selig ein Begatten!", "tokens": ["Se\u00b7lig", "ein", "Be\u00b7gat\u00b7ten", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und man liebt vor Allen,", "tokens": ["Und", "man", "liebt", "vor", "Al\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Die die Laufzeit hatten.", "tokens": ["Die", "die", "Lauf\u00b7zeit", "hat\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "VAFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.120": {"line.1": {"text": "Schnell sich Alle kannten,", "tokens": ["Schnell", "sich", "Al\u00b7le", "kann\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "PIS", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und in allen Klassen", "tokens": ["Und", "in", "al\u00b7len", "Klas\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "APPR", "PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ward man zu Verwandten.", "tokens": ["Ward", "man", "zu", "Ver\u00b7wand\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.121": {"line.1": {"text": "Amor lag auf Kissen", "tokens": ["A\u00b7mor", "lag", "auf", "Kis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "VVFIN", "APPR", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Und mu\u00df g\u00f6ttlich lachen:", "tokens": ["Und", "mu\u00df", "g\u00f6tt\u00b7lich", "la\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ADJD", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "\u00bbmama Venusine,", "tokens": ["\u00bb", "ma\u00b7ma", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["punct", "word", "word", "punct"], "pos": ["$(", "FM.la", "FM.la", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.4": {"text": "Du machst tolle Sachen!", "tokens": ["Du", "machst", "tol\u00b7le", "Sa\u00b7chen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADJA", "NN", "$."], "meter": "-++-+-", "measure": "unknown.measure.tri"}}, "stanza.122": {"line.1": {"text": "Du erl\u00f6st die Leute", "tokens": ["Du", "er\u00b7l\u00f6st", "die", "Leu\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Auf besondre Weise!", "tokens": ["Auf", "be\u00b7sond\u00b7re", "Wei\u00b7se", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Endlich liebt man heute!\u00ab \u2013", "tokens": ["End\u00b7lich", "liebt", "man", "heu\u00b7te", "!", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "$.", "$(", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.123": {"line.1": {"text": "Hell voll Gl\u00fchlichtlampen", "tokens": ["Hell", "voll", "Gl\u00fch\u00b7licht\u00b7lam\u00b7pen"], "token_info": ["word", "word", "word"], "pos": ["NE", "ADJD", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Eilen Luxuswagen;", "tokens": ["Ei\u00b7len", "Lu\u00b7xus\u00b7wa\u00b7gen", ";"], "token_info": ["word", "word", "punct"], "pos": ["NN", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Niemand ahnt von drau\u00dfen,", "tokens": ["Nie\u00b7mand", "ahnt", "von", "drau\u00b7\u00dfen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "ADV", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Da\u00df sie Hunde tragen.", "tokens": ["Da\u00df", "sie", "Hun\u00b7de", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.124": {"line.1": {"text": "Und der Gotthard lachte", "tokens": ["Und", "der", "Got\u00b7thard", "lach\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "NE", "VVFIN"], "meter": "--+-+-", "measure": "anapaest.init"}, "line.2": {"text": "\u00dcber Venusine,", "tokens": ["\u00dc\u00b7ber", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NE", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Die das fertig brachte.", "tokens": ["Die", "das", "fer\u00b7tig", "brach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "ADJD", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.125": {"line.1": {"text": "Als der Zug den letzten", "tokens": ["Als", "der", "Zug", "den", "letz\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "ART", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Tunnel just passierte,", "tokens": ["Tun\u00b7nel", "just", "pas\u00b7sier\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADV", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Lagen tausend kleine", "tokens": ["La\u00b7gen", "tau\u00b7send", "klei\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["NN", "CARD", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "V\u00f6gel, schneeverirrte,", "tokens": ["V\u00f6\u00b7gel", ",", "schnee\u00b7ver\u00b7irr\u00b7te", ","], "token_info": ["word", "punct", "word", "punct"], "pos": ["NN", "$,", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.126": {"line.1": {"text": "Im Gefild, im kalten.", "tokens": ["Im", "Ge\u00b7fild", ",", "im", "kal\u00b7ten", "."], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "APPRART", "ADJA", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "\u00bbhalt!\u00ab rief Venusine.", "tokens": ["\u00bb", "halt", "!", "\u00ab", "rief", "Ve\u00b7nu\u00b7si\u00b7ne", "."], "token_info": ["punct", "word", "punct", "punct", "word", "word", "punct"], "pos": ["$(", "VVFIN", "$.", "$(", "VVFIN", "NE", "$."], "meter": "++--+-", "measure": "trochaic.tri.relaxed"}, "line.3": {"text": "Und der Zug mu\u00df halten.", "tokens": ["Und", "der", "Zug", "mu\u00df", "hal\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VMFIN", "VVINF", "$."], "meter": "--+-+-", "measure": "anapaest.init"}}, "stanza.127": {"line.1": {"text": "Alle Bernhardiner", "tokens": ["Al\u00b7le", "Bern\u00b7har\u00b7di\u00b7ner"], "token_info": ["word", "word"], "pos": ["PIAT", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind hinausbefohlen,", "tokens": ["Sind", "hin\u00b7aus\u00b7be\u00b7foh\u00b7len", ","], "token_info": ["word", "word", "punct"], "pos": ["VAFIN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ein Jeder mu\u00dfte", "tokens": ["Und", "ein", "Je\u00b7der", "mu\u00df\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "PIS", "VMFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Von den V\u00f6geln holen.", "tokens": ["Von", "den", "V\u00f6\u00b7geln", "ho\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.128": {"line.1": {"text": "Und sie apportieren", "tokens": ["Und", "sie", "ap\u00b7por\u00b7tie\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["KON", "PPER", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Vorsichtig im Maule,", "tokens": ["Vor\u00b7sich\u00b7tig", "im", "Mau\u00b7le", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+---+-", "measure": "dactylic.init"}, "line.3": {"text": "V\u00f6gel, die erfrieren.", "tokens": ["V\u00f6\u00b7gel", ",", "die", "er\u00b7frie\u00b7ren", "."], "token_info": ["word", "punct", "word", "word", "punct"], "pos": ["NN", "$,", "PRELS", "VVINF", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.129": {"line.1": {"text": "In den warmen Wagen", "tokens": ["In", "den", "war\u00b7men", "Wa\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sind bald neugeboren", "tokens": ["Sind", "bald", "neu\u00b7ge\u00b7bo\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "ADV", "ADJA"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Diese. Und kaum lebend", "tokens": ["Die\u00b7se", ".", "Und", "kaum", "le\u00b7bend"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["PDAT", "$.", "KON", "ADV", "ADJD"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Danken sie den Ohren.", "tokens": ["Dan\u00b7ken", "sie", "den", "Oh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.130": {"line.1": {"text": "Nachtigallen, Meisen", "tokens": ["Nach\u00b7ti\u00b7gal\u00b7len", ",", "Mei\u00b7sen"], "token_info": ["word", "punct", "word"], "pos": ["NN", "$,", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Danken Venusine,", "tokens": ["Dan\u00b7ken", "Ve\u00b7nu\u00b7si\u00b7ne", ","], "token_info": ["word", "word", "punct"], "pos": ["NN", "NE", "$,"], "meter": "+-----", "measure": "dactylic.init"}, "line.3": {"text": "Singend ihre Weisen.", "tokens": ["Sin\u00b7gend", "ih\u00b7re", "Wei\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.131": {"line.1": {"text": "Alle V\u00f6gel kannten", "tokens": ["Al\u00b7le", "V\u00f6\u00b7gel", "kann\u00b7ten"], "token_info": ["word", "word", "word"], "pos": ["PIAT", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Gleich die G\u00f6ttin wieder.", "tokens": ["Gleich", "die", "G\u00f6t\u00b7tin", "wie\u00b7der", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "ADV", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Auf dem H\u00f6rselberge", "tokens": ["Auf", "dem", "H\u00f6r\u00b7sel\u00b7ber\u00b7ge"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-++-+", "measure": "unknown.measure.tetra"}, "line.4": {"text": "Lehrt' sie j\u00e4hrlich Lieder,", "tokens": ["Lehrt'", "sie", "j\u00e4hr\u00b7lich", "Lie\u00b7der", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJD", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.132": {"line.1": {"text": "Jedem M\u00e4nnchen neue,", "tokens": ["Je\u00b7dem", "M\u00e4nn\u00b7chen", "neu\u00b7e", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "ADJA", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Da\u00df der Wald erbl\u00fche", "tokens": ["Da\u00df", "der", "Wald", "er\u00b7bl\u00fc\u00b7he"], "token_info": ["word", "word", "word", "word"], "pos": ["KOUS", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und sich's Weibchen freue.", "tokens": ["Und", "sich's", "Weib\u00b7chen", "freu\u00b7e", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "VVFIN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.133": {"line.1": {"text": "Auch die Hunde liegen", "tokens": ["Auch", "die", "Hun\u00b7de", "lie\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "ART", "NN", "VVFIN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Horchend auf den Kissen.", "tokens": ["Hor\u00b7chend", "auf", "den", "Kis\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Weil sie jetzt die N\u00e4he", "tokens": ["Weil", "sie", "jetzt", "die", "N\u00e4\u00b7he"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "ART", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Einer G\u00f6ttin wissen,", "tokens": ["Ei\u00b7ner", "G\u00f6t\u00b7tin", "wis\u00b7sen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVINF", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.134": {"line.1": {"text": "Zeigen sie die Spuren,", "tokens": ["Zei\u00b7gen", "sie", "die", "Spu\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Heute \u00fcberwundner,", "tokens": ["Heu\u00b7te", "\u00fc\u00b7berw\u00b7und\u00b7ner", ","], "token_info": ["word", "word", "punct"], "pos": ["ADV", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Menschlicher Kulturen.", "tokens": ["Menschli\u00b7cher", "Kul\u00b7tu\u00b7ren", "."], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.135": {"line.1": {"text": "Nach Chiasso senken", "tokens": ["Nach", "Chi\u00b7as\u00b7so", "sen\u00b7ken"], "token_info": ["word", "word", "word"], "pos": ["APPR", "NE", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Sich die Berggel\u00e4nde,", "tokens": ["Sich", "die", "Berg\u00b7ge\u00b7l\u00e4n\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Hundertschluchtig gr\u00fc\u00dfen", "tokens": ["Hun\u00b7dertsc\u00b7hluch\u00b7tig", "gr\u00fc\u00b7\u00dfen"], "token_info": ["word", "word"], "pos": ["ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Dort Italiens W\u00e4nde.", "tokens": ["Dort", "I\u00b7ta\u00b7li\u00b7ens", "W\u00e4n\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "NE", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.136": {"line.1": {"text": "So kam Venusine", "tokens": ["So", "kam", "Ve\u00b7nu\u00b7si\u00b7ne"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "NE"], "meter": "-+-+--", "measure": "unknown.measure.di"}, "line.2": {"text": "Zu des S\u00fcdens Grenze,", "tokens": ["Zu", "des", "S\u00fc\u00b7dens", "Gren\u00b7ze", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schalk in jeder Miene.", "tokens": ["Schalk", "in", "je\u00b7der", "Mie\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}