{"textgrid.poem.54127": {"metadata": {"author": {"name": "Tucholsky, Kurt", "birth": "N.A.", "death": "N.A."}, "title": "An das Publikum", "genre": "verse", "period": "N.A.", "pub_year": 1912, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "O hochverehrtes Publikum,", "tokens": ["O", "hoch\u00b7ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag mal: bist du wirklich so dumm,", "tokens": ["sag", "mal", ":", "bist", "du", "wirk\u00b7lich", "so", "dumm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "wie uns das an allen Tagen", "tokens": ["wie", "uns", "das", "an", "al\u00b7len", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "APPR", "PIAT", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "alle Unternehmer sagen?", "tokens": ["al\u00b7le", "Un\u00b7ter\u00b7neh\u00b7mer", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jeder Direktor mit dickem Popo", "tokens": ["Je\u00b7der", "Di\u00b7rek\u00b7tor", "mit", "di\u00b7ckem", "Po\u00b7po"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "spricht: \u00bbDas Publikum will es so!\u00ab", "tokens": ["spricht", ":", "\u00bb", "Das", "Pub\u00b7li\u00b7kum", "will", "es", "so", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "ART", "NN", "VMFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+----+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Jeder Filmfritze sagt: \u00bbWas soll ich machen?", "tokens": ["Je\u00b7der", "Film\u00b7frit\u00b7ze", "sagt", ":", "\u00bb", "Was", "soll", "ich", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das Publikum w\u00fcnscht diese zuckrigen Sachen!\u00ab", "tokens": ["Das", "Pub\u00b7li\u00b7kum", "w\u00fcnscht", "die\u00b7se", "zuck\u00b7ri\u00b7gen", "Sa\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Jeder Verleger zuckt die Achseln und spricht:", "tokens": ["Je\u00b7der", "Ver\u00b7le\u00b7ger", "zuckt", "die", "Ach\u00b7seln", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.10": {"text": "\u00bbgute B\u00fccher gehn eben nicht!\u00ab", "tokens": ["\u00bb", "gu\u00b7te", "B\u00fc\u00b7cher", "gehn", "e\u00b7ben", "nicht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "VVFIN", "ADV", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "Sag mal, verehrtes Publikum:", "tokens": ["Sag", "mal", ",", "ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "bist du wirklich so dumm?", "tokens": ["bist", "du", "wirk\u00b7lich", "so", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.2": {"line.1": {"text": "So dumm, da\u00df in Zeitungen, fr\u00fch und sp\u00e4t,", "tokens": ["So", "dumm", ",", "da\u00df", "in", "Zei\u00b7tun\u00b7gen", ",", "fr\u00fch", "und", "sp\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "immer weniger zu lesen steht?", "tokens": ["im\u00b7mer", "we\u00b7ni\u00b7ger", "zu", "le\u00b7sen", "steht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Aus lauter Furcht, du k\u00f6nntest verletzt sein;", "tokens": ["Aus", "lau\u00b7ter", "Furcht", ",", "du", "k\u00f6nn\u00b7test", "ver\u00b7letzt", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "aus lauter Angst, es soll niemand verhetzt sein;", "tokens": ["aus", "lau\u00b7ter", "Angst", ",", "es", "soll", "nie\u00b7mand", "ver\u00b7hetzt", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PPER", "VMFIN", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "aus lauter Besorgnis, M\u00fcller und Cohn", "tokens": ["aus", "lau\u00b7ter", "Be\u00b7sorg\u00b7nis", ",", "M\u00fcl\u00b7ler", "und", "Cohn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "NE", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "k\u00f6nnten mit Abbestellung drohn?", "tokens": ["k\u00f6nn\u00b7ten", "mit", "Ab\u00b7be\u00b7stel\u00b7lung", "drohn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Aus Bangigkeit, es k\u00e4me am Ende", "tokens": ["Aus", "Ban\u00b7gig\u00b7keit", ",", "es", "k\u00e4\u00b7me", "am", "En\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "einer der zahllosen Reichsverb\u00e4nde", "tokens": ["ei\u00b7ner", "der", "zahl\u00b7lo\u00b7sen", "Reichs\u00b7ver\u00b7b\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "und protestierte und denunzierte", "tokens": ["und", "pro\u00b7tes\u00b7tier\u00b7te", "und", "de\u00b7nun\u00b7zier\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "und demonstrierte und prozessierte . . .", "tokens": ["und", "de\u00b7monst\u00b7rier\u00b7te", "und", "pro\u00b7zes\u00b7sier\u00b7te", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$.", "$.", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.11": {"text": "Sag mal, verehrtes Publikum:", "tokens": ["Sag", "mal", ",", "ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "bist du wirklich so dumm?", "tokens": ["bist", "du", "wirk\u00b7lich", "so", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.3": {"line.1": {"text": "Ja, dann . . .", "tokens": ["Ja", ",", "dann", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.2": {"text": "Es lastet auf dieser Zeit", "tokens": ["Es", "las\u00b7tet", "auf", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "der Fluch der Mittelm\u00e4\u00dfigkeit.", "tokens": ["der", "Fluch", "der", "Mit\u00b7tel\u00b7m\u00e4\u00b7\u00dfig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hast du so einen schwachen Magen?", "tokens": ["Hast", "du", "so", "ei\u00b7nen", "schwa\u00b7chen", "Ma\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kannst du keine Wahrheit vertragen?", "tokens": ["Kannst", "du", "kei\u00b7ne", "Wahr\u00b7heit", "ver\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Bist also nur ein Grie\u00dfbrei-Fresser \u2013?", "tokens": ["Bist", "al\u00b7so", "nur", "ein", "Grie\u00df\u00b7brei\u00b7Fres\u00b7ser", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ja, dann . . .", "tokens": ["Ja", ",", "dann", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.8": {"text": "Ja, dann verdienst dus nicht besser.", "tokens": ["Ja", ",", "dann", "ver\u00b7dienst", "dus", "nicht", "bes\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "NE", "PTKNEG", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.4": {"line.1": {"text": "O hochverehrtes Publikum,", "tokens": ["O", "hoch\u00b7ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "sag mal: bist du wirklich so dumm,", "tokens": ["sag", "mal", ":", "bist", "du", "wirk\u00b7lich", "so", "dumm", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADV", "$.", "VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$,"], "meter": "+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "wie uns das an allen Tagen", "tokens": ["wie", "uns", "das", "an", "al\u00b7len", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPER", "ART", "APPR", "PIAT", "NN"], "meter": "+---+-+-", "measure": "dactylic.init"}, "line.4": {"text": "alle Unternehmer sagen?", "tokens": ["al\u00b7le", "Un\u00b7ter\u00b7neh\u00b7mer", "sa\u00b7gen", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.5": {"text": "Jeder Direktor mit dickem Popo", "tokens": ["Je\u00b7der", "Di\u00b7rek\u00b7tor", "mit", "di\u00b7ckem", "Po\u00b7po"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIAT", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "spricht: \u00bbDas Publikum will es so!\u00ab", "tokens": ["spricht", ":", "\u00bb", "Das", "Pub\u00b7li\u00b7kum", "will", "es", "so", "!", "\u00ab"], "token_info": ["word", "punct", "punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VVFIN", "$.", "$(", "ART", "NN", "VMFIN", "PPER", "ADV", "$.", "$("], "meter": "+-+----+", "measure": "unknown.measure.tri"}, "line.7": {"text": "Jeder Filmfritze sagt: \u00bbWas soll ich machen?", "tokens": ["Je\u00b7der", "Film\u00b7frit\u00b7ze", "sagt", ":", "\u00bb", "Was", "soll", "ich", "ma\u00b7chen", "?"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "$.", "$(", "PWS", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Das Publikum w\u00fcnscht diese zuckrigen Sachen!\u00ab", "tokens": ["Das", "Pub\u00b7li\u00b7kum", "w\u00fcnscht", "die\u00b7se", "zuck\u00b7ri\u00b7gen", "Sa\u00b7chen", "!", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VVFIN", "PDAT", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.9": {"text": "Jeder Verleger zuckt die Achseln und spricht:", "tokens": ["Je\u00b7der", "Ver\u00b7le\u00b7ger", "zuckt", "die", "Ach\u00b7seln", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VVFIN", "ART", "NN", "KON", "VVFIN", "$."], "meter": "+--+-+-+--+", "measure": "iambic.penta.invert"}, "line.10": {"text": "\u00bbgute B\u00fccher gehn eben nicht!\u00ab", "tokens": ["\u00bb", "gu\u00b7te", "B\u00fc\u00b7cher", "gehn", "e\u00b7ben", "nicht", "!", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "ADJA", "NN", "VVFIN", "ADV", "PTKNEG", "$.", "$("], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.11": {"text": "Sag mal, verehrtes Publikum:", "tokens": ["Sag", "mal", ",", "ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "bist du wirklich so dumm?", "tokens": ["bist", "du", "wirk\u00b7lich", "so", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.5": {"line.1": {"text": "So dumm, da\u00df in Zeitungen, fr\u00fch und sp\u00e4t,", "tokens": ["So", "dumm", ",", "da\u00df", "in", "Zei\u00b7tun\u00b7gen", ",", "fr\u00fch", "und", "sp\u00e4t", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "KOUS", "APPR", "NN", "$,", "ADJD", "KON", "ADJD", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "immer weniger zu lesen steht?", "tokens": ["im\u00b7mer", "we\u00b7ni\u00b7ger", "zu", "le\u00b7sen", "steht", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "PTKZU", "VVINF", "VVFIN", "$."], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Aus lauter Furcht, du k\u00f6nntest verletzt sein;", "tokens": ["Aus", "lau\u00b7ter", "Furcht", ",", "du", "k\u00f6nn\u00b7test", "ver\u00b7letzt", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PPER", "VMFIN", "VVPP", "VAINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "aus lauter Angst, es soll niemand verhetzt sein;", "tokens": ["aus", "lau\u00b7ter", "Angst", ",", "es", "soll", "nie\u00b7mand", "ver\u00b7hetzt", "sein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "$,", "PPER", "VMFIN", "PIS", "VVPP", "VAINF", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "aus lauter Besorgnis, M\u00fcller und Cohn", "tokens": ["aus", "lau\u00b7ter", "Be\u00b7sorg\u00b7nis", ",", "M\u00fcl\u00b7ler", "und", "Cohn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "$,", "NE", "KON", "NN"], "meter": "-+--+-+--+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "k\u00f6nnten mit Abbestellung drohn?", "tokens": ["k\u00f6nn\u00b7ten", "mit", "Ab\u00b7be\u00b7stel\u00b7lung", "drohn", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VMFIN", "APPR", "NN", "VVFIN", "$."], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.7": {"text": "Aus Bangigkeit, es k\u00e4me am Ende", "tokens": ["Aus", "Ban\u00b7gig\u00b7keit", ",", "es", "k\u00e4\u00b7me", "am", "En\u00b7de"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["APPR", "NN", "$,", "PPER", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "einer der zahllosen Reichsverb\u00e4nde", "tokens": ["ei\u00b7ner", "der", "zahl\u00b7lo\u00b7sen", "Reichs\u00b7ver\u00b7b\u00e4n\u00b7de"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "ART", "ADJA", "NN"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.9": {"text": "und protestierte und denunzierte", "tokens": ["und", "pro\u00b7tes\u00b7tier\u00b7te", "und", "de\u00b7nun\u00b7zier\u00b7te"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "VVFIN", "KON", "VVFIN"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.10": {"text": "und demonstrierte und prozessierte . . .", "tokens": ["und", "de\u00b7monst\u00b7rier\u00b7te", "und", "pro\u00b7zes\u00b7sier\u00b7te", ".", ".", "."], "token_info": ["word", "word", "word", "word", "punct", "punct", "punct"], "pos": ["KON", "VVFIN", "KON", "VVFIN", "$.", "$.", "$."], "meter": "+--+--+-+-", "measure": "dactylic.di.plus"}, "line.11": {"text": "Sag mal, verehrtes Publikum:", "tokens": ["Sag", "mal", ",", "ver\u00b7ehr\u00b7tes", "Pub\u00b7li\u00b7kum", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "ADV", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "bist du wirklich so dumm?", "tokens": ["bist", "du", "wirk\u00b7lich", "so", "dumm", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADJD", "ADV", "ADJD", "$."], "meter": "+-+--+", "measure": "iambic.tri.chol"}}, "stanza.6": {"line.1": {"text": "Ja, dann . . .", "tokens": ["Ja", ",", "dann", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.2": {"text": "Es lastet auf dieser Zeit", "tokens": ["Es", "las\u00b7tet", "auf", "die\u00b7ser", "Zeit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "APPR", "PDAT", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "der Fluch der Mittelm\u00e4\u00dfigkeit.", "tokens": ["der", "Fluch", "der", "Mit\u00b7tel\u00b7m\u00e4\u00b7\u00dfig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hast du so einen schwachen Magen?", "tokens": ["Hast", "du", "so", "ei\u00b7nen", "schwa\u00b7chen", "Ma\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Kannst du keine Wahrheit vertragen?", "tokens": ["Kannst", "du", "kei\u00b7ne", "Wahr\u00b7heit", "ver\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PIAT", "NN", "VVFIN", "$."], "meter": "+-+-+--+-", "measure": "trochaic.tetra.relaxed"}, "line.6": {"text": "Bist also nur ein Grie\u00dfbrei-Fresser \u2013?", "tokens": ["Bist", "al\u00b7so", "nur", "ein", "Grie\u00df\u00b7brei\u00b7Fres\u00b7ser", "\u2013", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN", "$(", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.7": {"text": "Ja, dann . . .", "tokens": ["Ja", ",", "dann", ".", ".", "."], "token_info": ["word", "punct", "word", "punct", "punct", "punct"], "pos": ["PTKANT", "$,", "ADV", "$.", "$.", "$."], "meter": "--", "measure": "unknown.measure.zero"}, "line.8": {"text": "Ja, dann verdienst dus nicht besser.", "tokens": ["Ja", ",", "dann", "ver\u00b7dienst", "dus", "nicht", "bes\u00b7ser", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "ADV", "VVFIN", "NE", "PTKNEG", "ADJD", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}