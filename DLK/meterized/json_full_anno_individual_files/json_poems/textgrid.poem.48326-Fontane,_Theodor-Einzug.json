{"textgrid.poem.48326": {"metadata": {"author": {"name": "Fontane, Theodor", "birth": "N.A.", "death": "N.A."}, "title": "Einzug", "genre": "verse", "period": "N.A.", "pub_year": 1858, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u203a", "tokens": ["\u203a"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Pa\u00dfkart' oder Steuerschein,", "tokens": ["Pa\u00df\u00b7kart'", "o\u00b7der", "Steu\u00b7er\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "++--+-+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Eins von beiden mu\u00df es sein.\u00ab", "tokens": ["Eins", "von", "bei\u00b7den", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PIS", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "\u00bballes in Ordnung. Jedenfalls", "tokens": ["\u00bb", "al\u00b7les", "in", "Ord\u00b7nung", ".", "Je\u00b7den\u00b7falls"], "token_info": ["punct", "word", "word", "word", "punct", "word"], "pos": ["$(", "PIS", "APPR", "NN", "$.", "NE"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zahlten wir Steuer bei Langensalz,", "tokens": ["Zahl\u00b7ten", "wir", "Steu\u00b7er", "bei", "Lan\u00b7gen\u00b7salz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wir zahlten die Steuer mit Blut und Schwei\u00df\u00ab \u2013", "tokens": ["Wir", "zahl\u00b7ten", "die", "Steu\u00b7er", "mit", "Blut", "und", "Schwei\u00df", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$(", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.3": {"line.1": {"text": "\u00bblandwehr passier', ich wei\u00df, ich wei\u00df.\u00ab", "tokens": ["\u00bb", "land\u00b7wehr", "pas\u00b7sier'", ",", "ich", "wei\u00df", ",", "ich", "wei\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Pa\u00dfkart' oder Steuerschein;", "tokens": ["Pa\u00df\u00b7kart'", "o\u00b7der", "Steu\u00b7er\u00b7schein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "++--+-+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}, "stanza.5": {"line.1": {"text": "\u00bbwir haben P\u00e4sse die H\u00e4nde voll,", "tokens": ["\u00bb", "wir", "ha\u00b7ben", "P\u00e4s\u00b7se", "die", "H\u00e4n\u00b7de", "voll", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zuerst den Br\u00fcckenpa\u00df bei Pod\u00f2ll,", "tokens": ["Zu\u00b7erst", "den", "Br\u00fc\u00b7cken\u00b7pa\u00df", "bei", "Po\u00b7d\u00f2ll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dann Felsenp\u00e4sse aus West und Ost:", "tokens": ["Dann", "Fel\u00b7sen\u00b7p\u00e4s\u00b7se", "aus", "West", "und", "Ost", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nachod, Skalitz und Podk\u00f2st,", "tokens": ["Na\u00b7chod", ",", "Ska\u00b7litz", "und", "Pod\u00b7k\u00f2st", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Und wenn die Felsenp\u00e4sse nicht ziehn,", "tokens": ["Und", "wenn", "die", "Fel\u00b7sen\u00b7p\u00e4s\u00b7se", "nicht", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "So nimm noch den Doppelpa\u00df von Gitschin,", "tokens": ["So", "nimm", "noch", "den", "Dop\u00b7pel\u00b7pa\u00df", "von", "Git\u00b7schin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Sind allesamt geschrieben mit Blut\u00ab \u2013", "tokens": ["Sind", "al\u00b7le\u00b7samt", "ge\u00b7schrie\u00b7ben", "mit", "Blut", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "APPR", "NN", "$(", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.6": {"line.1": {"text": "\u00bblinie passier', is gut, is gut.\u00ab", "tokens": ["\u00bb", "li\u00b7nie", "pas\u00b7sier'", ",", "is", "gut", ",", "is", "gut", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "FM", "ADJD", "$,", "FM", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u203a", "tokens": ["\u203a"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Preu\u00dfische Garde, willkommen am Ort,", "tokens": ["Preu\u00b7\u00dfi\u00b7sche", "Gar\u00b7de", ",", "will\u00b7kom\u00b7men", "am", "Ort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Aber erst das Losungswort.\u00ab", "tokens": ["A\u00b7ber", "erst", "das", "Lo\u00b7sungs\u00b7wort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "\u00bbwir bringen gute Losung heim", "tokens": ["\u00bb", "wir", "brin\u00b7gen", "gu\u00b7te", "Lo\u00b7sung", "heim"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als Parole 'nen neuen Reim,", "tokens": ["Und", "als", "Pa\u00b7ro\u00b7le", "'nen", "neu\u00b7en", "Reim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Einen neuen preu\u00dfischen Reim auf ", "tokens": ["Ei\u00b7nen", "neu\u00b7en", "preu\u00b7\u00dfi\u00b7schen", "Reim", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPR"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.9": {"line.1": {"text": "\u00bbnenn' ihn, Garde!\u00ab", "tokens": ["\u00bb", "nenn'", "ihn", ",", "Gar\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "\u00bbdie H\u00f6he von ", "tokens": ["\u00bb", "die", "H\u00f6\u00b7he", "von"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.10": {"line.1": {"text": "\u00bbein guter Reim, ich salutier',", "tokens": ["\u00bb", "ein", "gu\u00b7ter", "Reim", ",", "ich", "sa\u00b7lu\u00b7tier'", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Preu\u00dfische Garde passier', passier'.\u00ab", "tokens": ["Preu\u00b7\u00dfi\u00b7sche", "Gar\u00b7de", "pas\u00b7sier'", ",", "pas\u00b7sier'", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "VVFIN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.11": {"line.1": {"text": "Glocken l\u00e4uten, Fahnen wehn,", "tokens": ["Glo\u00b7cken", "l\u00e4u\u00b7ten", ",", "Fah\u00b7nen", "wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Sieger drinnen am Tore stehn,", "tokens": ["Die", "Sie\u00b7ger", "drin\u00b7nen", "am", "To\u00b7re", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Eine Siegesgasse ist aufgemacht:", "tokens": ["Ei\u00b7ne", "Sie\u00b7ges\u00b7gas\u00b7se", "ist", "auf\u00b7ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u00d6streich'sche Kanonen ", "tokens": ["\u00d6\u00b7streich'\u00b7sche", "Ka\u00b7no\u00b7nen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und durch die Gasse die Sieger ziehn. \u2013", "tokens": ["Und", "durch", "die", "Gas\u00b7se", "die", "Sie\u00b7ger", "ziehn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das war der Einzug in Berlin.", "tokens": ["Das", "war", "der", "Ein\u00b7zug", "in", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.12": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u203a", "tokens": ["\u203a"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Pa\u00dfkart' oder Steuerschein,", "tokens": ["Pa\u00df\u00b7kart'", "o\u00b7der", "Steu\u00b7er\u00b7schein", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$,"], "meter": "++--+-+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Eins von beiden mu\u00df es sein.\u00ab", "tokens": ["Eins", "von", "bei\u00b7den", "mu\u00df", "es", "sein", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["NN", "APPR", "PIS", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "\u00bballes in Ordnung. Jedenfalls", "tokens": ["\u00bb", "al\u00b7les", "in", "Ord\u00b7nung", ".", "Je\u00b7den\u00b7falls"], "token_info": ["punct", "word", "word", "word", "punct", "word"], "pos": ["$(", "PIS", "APPR", "NN", "$.", "NE"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.2": {"text": "Zahlten wir Steuer bei Langensalz,", "tokens": ["Zahl\u00b7ten", "wir", "Steu\u00b7er", "bei", "Lan\u00b7gen\u00b7salz", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "NN", "APPR", "NE", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Wir zahlten die Steuer mit Blut und Schwei\u00df\u00ab \u2013", "tokens": ["Wir", "zahl\u00b7ten", "die", "Steu\u00b7er", "mit", "Blut", "und", "Schwei\u00df", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "NN", "KON", "NN", "$(", "$("], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}}, "stanza.14": {"line.1": {"text": "\u00bblandwehr passier', ich wei\u00df, ich wei\u00df.\u00ab", "tokens": ["\u00bb", "land\u00b7wehr", "pas\u00b7sier'", ",", "ich", "wei\u00df", ",", "ich", "wei\u00df", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "PPER", "VVFIN", "$,", "PPER", "VVFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u00bb", "tokens": ["\u00bb"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Pa\u00dfkart' oder Steuerschein;", "tokens": ["Pa\u00df\u00b7kart'", "o\u00b7der", "Steu\u00b7er\u00b7schein", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "$."], "meter": "++--+-+", "measure": "trochaic.tetra.relaxed"}, "line.4": {"text": "Ein ", "tokens": ["Ein"], "token_info": ["word"], "pos": ["ART"], "meter": "+", "measure": "single.up"}}, "stanza.16": {"line.1": {"text": "\u00bbwir haben P\u00e4sse die H\u00e4nde voll,", "tokens": ["\u00bb", "wir", "ha\u00b7ben", "P\u00e4s\u00b7se", "die", "H\u00e4n\u00b7de", "voll", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "PPER", "VAFIN", "NN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Zuerst den Br\u00fcckenpa\u00df bei Pod\u00f2ll,", "tokens": ["Zu\u00b7erst", "den", "Br\u00fc\u00b7cken\u00b7pa\u00df", "bei", "Po\u00b7d\u00f2ll", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.3": {"text": "Dann Felsenp\u00e4sse aus West und Ost:", "tokens": ["Dann", "Fel\u00b7sen\u00b7p\u00e4s\u00b7se", "aus", "West", "und", "Ost", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.4": {"text": "Nachod, Skalitz und Podk\u00f2st,", "tokens": ["Na\u00b7chod", ",", "Ska\u00b7litz", "und", "Pod\u00b7k\u00f2st", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "$,"], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.5": {"text": "Und wenn die Felsenp\u00e4sse nicht ziehn,", "tokens": ["Und", "wenn", "die", "Fel\u00b7sen\u00b7p\u00e4s\u00b7se", "nicht", "ziehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "PTKNEG", "VVINF", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "So nimm noch den Doppelpa\u00df von Gitschin,", "tokens": ["So", "nimm", "noch", "den", "Dop\u00b7pel\u00b7pa\u00df", "von", "Git\u00b7schin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "ADV", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.7": {"text": "Sind allesamt geschrieben mit Blut\u00ab \u2013", "tokens": ["Sind", "al\u00b7le\u00b7samt", "ge\u00b7schrie\u00b7ben", "mit", "Blut", "\u00ab", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["VAFIN", "ADJD", "VVPP", "APPR", "NN", "$(", "$("], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.17": {"line.1": {"text": "\u00bblinie passier', is gut, is gut.\u00ab", "tokens": ["\u00bb", "li\u00b7nie", "pas\u00b7sier'", ",", "is", "gut", ",", "is", "gut", ".", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "punct"], "pos": ["$(", "ADV", "VVFIN", "$,", "FM", "ADJD", "$,", "FM", "ADJD", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Viktoria hat heute Dienst am Tor:", "tokens": ["Vik\u00b7to\u00b7ria", "hat", "heu\u00b7te", "Dienst", "am", "Tor", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "\u203a", "tokens": ["\u203a"], "token_info": ["punct"], "pos": ["$("]}, "line.3": {"text": "Preu\u00dfische Garde, willkommen am Ort,", "tokens": ["Preu\u00b7\u00dfi\u00b7sche", "Gar\u00b7de", ",", "will\u00b7kom\u00b7men", "am", "Ort", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "ADJD", "APPRART", "NN", "$,"], "meter": "+--+--+--+", "measure": "dactylic.tetra"}, "line.4": {"text": "Aber erst das Losungswort.\u00ab", "tokens": ["A\u00b7ber", "erst", "das", "Lo\u00b7sungs\u00b7wort", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$.", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "\u00bbwir bringen gute Losung heim", "tokens": ["\u00bb", "wir", "brin\u00b7gen", "gu\u00b7te", "Lo\u00b7sung", "heim"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "PPER", "VVFIN", "ADJA", "NN", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als Parole 'nen neuen Reim,", "tokens": ["Und", "als", "Pa\u00b7ro\u00b7le", "'nen", "neu\u00b7en", "Reim", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "NN", "ART", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.3": {"text": "Einen neuen preu\u00dfischen Reim auf ", "tokens": ["Ei\u00b7nen", "neu\u00b7en", "preu\u00b7\u00dfi\u00b7schen", "Reim", "auf"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ADJA", "NN", "APPR"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}}, "stanza.20": {"line.1": {"text": "\u00bbnenn' ihn, Garde!\u00ab", "tokens": ["\u00bb", "nenn'", "ihn", ",", "Gar\u00b7de", "!", "\u00ab"], "token_info": ["punct", "word", "word", "punct", "word", "punct", "punct"], "pos": ["$(", "VVFIN", "PPER", "$,", "NN", "$.", "$("], "meter": "+-+-", "measure": "trochaic.di"}, "line.2": {"text": "\u00bbdie H\u00f6he von ", "tokens": ["\u00bb", "die", "H\u00f6\u00b7he", "von"], "token_info": ["punct", "word", "word", "word"], "pos": ["$(", "ART", "NN", "APPR"], "meter": "-+-+", "measure": "iambic.di"}}, "stanza.21": {"line.1": {"text": "\u00bbein guter Reim, ich salutier',", "tokens": ["\u00bb", "ein", "gu\u00b7ter", "Reim", ",", "ich", "sa\u00b7lu\u00b7tier'", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "$,", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Preu\u00dfische Garde passier', passier'.\u00ab", "tokens": ["Preu\u00b7\u00dfi\u00b7sche", "Gar\u00b7de", "pas\u00b7sier'", ",", "pas\u00b7sier'", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct"], "pos": ["ADJA", "NN", "VVFIN", "$,", "VVFIN", "$.", "$("], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}}, "stanza.22": {"line.1": {"text": "Glocken l\u00e4uten, Fahnen wehn,", "tokens": ["Glo\u00b7cken", "l\u00e4u\u00b7ten", ",", "Fah\u00b7nen", "wehn", ","], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "VVFIN", "$,", "NN", "VVINF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die Sieger drinnen am Tore stehn,", "tokens": ["Die", "Sie\u00b7ger", "drin\u00b7nen", "am", "To\u00b7re", "stehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Eine Siegesgasse ist aufgemacht:", "tokens": ["Ei\u00b7ne", "Sie\u00b7ges\u00b7gas\u00b7se", "ist", "auf\u00b7ge\u00b7macht", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "VVPP", "$."], "meter": "+-+-+--+-+", "measure": "trochaic.penta.relaxed"}, "line.4": {"text": "\u00d6streich'sche Kanonen ", "tokens": ["\u00d6\u00b7streich'\u00b7sche", "Ka\u00b7no\u00b7nen"], "token_info": ["word", "word"], "pos": ["ADJA", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.5": {"text": "Und durch die Gasse die Sieger ziehn. \u2013", "tokens": ["Und", "durch", "die", "Gas\u00b7se", "die", "Sie\u00b7ger", "ziehn", ".", "\u2013"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "APPR", "ART", "NN", "ART", "NN", "VVINF", "$.", "$("], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Das war der Einzug in Berlin.", "tokens": ["Das", "war", "der", "Ein\u00b7zug", "in", "Ber\u00b7lin", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "ART", "NN", "APPR", "NE", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}}}}