{"textgrid.poem.52132": {"metadata": {"author": {"name": "Czepko von Reigersfeld, Daniel", "birth": "N.A.", "death": "N.A."}, "title": "2.", "genre": "verse", "period": "N.A.", "pub_year": 1632, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich wil dir lieber Freund was in das Ohre sagen:", "tokens": ["Ich", "wil", "dir", "lie\u00b7ber", "Freund", "was", "in", "das", "Oh\u00b7re", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "NN", "PRELS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dis bitt' ich, halt es nur geheim als wie du thust:", "tokens": ["Dis", "bitt'", "ich", ",", "halt", "es", "nur", "ge\u00b7heim", "als", "wie", "du", "thust", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ADJD", "KOKOM", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der gro\u00dfe Mann, daran der B\u00fcrger seine Lust", "tokens": ["Der", "gro\u00b7\u00dfe", "Mann", ",", "da\u00b7ran", "der", "B\u00fcr\u00b7ger", "sei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PAV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seinen Trost gehabt, ist aus der Art geschlagen.", "tokens": ["Und", "sei\u00b7nen", "Trost", "ge\u00b7habt", ",", "ist", "aus", "der", "Art", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAPP", "$,", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.2": {"line.1": {"text": "Er l\u00e4\u00dfet sich Gestreng auff allen Ga\u00dfen nennen,", "tokens": ["Er", "l\u00e4\u00b7\u00dfet", "sich", "Ge\u00b7streng", "auff", "al\u00b7len", "Ga\u00b7\u00dfen", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wil ein Edel Mann, ja Rath und Raths Herr seyn,", "tokens": ["Und", "wil", "ein", "E\u00b7del", "Mann", ",", "ja", "Rath", "und", "Raths", "Herr", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "$,", "ADV", "NN", "KON", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und zeucht den Kegel nicht von langen Tituln ein,", "tokens": ["Und", "zeucht", "den", "Ke\u00b7gel", "nicht", "von", "lan\u00b7gen", "Ti\u00b7tuln", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey welchem man noch kan den Treber F\u00fcrsten kennen.", "tokens": ["Bey", "wel\u00b7chem", "man", "noch", "kan", "den", "Tre\u00b7ber", "F\u00fcrs\u00b7ten", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "ADV", "VMFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Fragstu, was er bey uns sonst l\u00f6blichs vorgenommen,", "tokens": ["Frags\u00b7tu", ",", "was", "er", "bey", "uns", "sonst", "l\u00f6b\u00b7lichs", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "APPR", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lie\u00df seine Hand, mit der er als ein Bieder Mann,", "tokens": ["Lie\u00df", "sei\u00b7ne", "Hand", ",", "mit", "der", "er", "als", "ein", "Bie\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "KOUS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In das gemeine Gutt so manchen Griff gethan,", "tokens": ["In", "das", "ge\u00b7mei\u00b7ne", "Gutt", "so", "man\u00b7chen", "Griff", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wirstu alsobald auff seine Thaten kommen.", "tokens": ["So", "wirs\u00b7tu", "al\u00b7so\u00b7bald", "auff", "sei\u00b7ne", "Tha\u00b7ten", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.4": {"line.1": {"text": "Das blo\u00df gef\u00e4llt mir nicht, da\u00df er vor andern allen", "tokens": ["Das", "blo\u00df", "ge\u00b7f\u00e4llt", "mir", "nicht", ",", "da\u00df", "er", "vor", "an\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "PIS", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Offt unsern Burg geleckt zu seinem Nutzen hat,", "tokens": ["Offt", "un\u00b7sern", "Burg", "ge\u00b7leckt", "zu", "sei\u00b7nem", "Nut\u00b7zen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich seh es, du f\u00e4ngst an? Wie heist er, der dis that?", "tokens": ["Ich", "seh", "es", ",", "du", "f\u00e4ngst", "an", "?", "Wie", "heist", "er", ",", "der", "dis", "that", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKVZ", "$.", "PWAV", "VAFIN", "PPER", "$,", "PRELS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verzeih es mir, es ist sein Nahme mir entfallen.", "tokens": ["Ver\u00b7zeih", "es", "mir", ",", "es", "ist", "sein", "Nah\u00b7me", "mir", "ent\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.5": {"line.1": {"text": "Ich wil dir lieber Freund was in das Ohre sagen:", "tokens": ["Ich", "wil", "dir", "lie\u00b7ber", "Freund", "was", "in", "das", "Oh\u00b7re", "sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "ADV", "NN", "PRELS", "APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Dis bitt' ich, halt es nur geheim als wie du thust:", "tokens": ["Dis", "bitt'", "ich", ",", "halt", "es", "nur", "ge\u00b7heim", "als", "wie", "du", "thust", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "ADV", "ADJD", "KOKOM", "PWAV", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Der gro\u00dfe Mann, daran der B\u00fcrger seine Lust", "tokens": ["Der", "gro\u00b7\u00dfe", "Mann", ",", "da\u00b7ran", "der", "B\u00fcr\u00b7ger", "sei\u00b7ne", "Lust"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PAV", "ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und seinen Trost gehabt, ist aus der Art geschlagen.", "tokens": ["Und", "sei\u00b7nen", "Trost", "ge\u00b7habt", ",", "ist", "aus", "der", "Art", "ge\u00b7schla\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VAPP", "$,", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.6": {"line.1": {"text": "Er l\u00e4\u00dfet sich Gestreng auff allen Ga\u00dfen nennen,", "tokens": ["Er", "l\u00e4\u00b7\u00dfet", "sich", "Ge\u00b7streng", "auff", "al\u00b7len", "Ga\u00b7\u00dfen", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PRF", "NN", "APPR", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Und wil ein Edel Mann, ja Rath und Raths Herr seyn,", "tokens": ["Und", "wil", "ein", "E\u00b7del", "Mann", ",", "ja", "Rath", "und", "Raths", "Herr", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "NN", "$,", "ADV", "NN", "KON", "NN", "NN", "VAINF", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Und zeucht den Kegel nicht von langen Tituln ein,", "tokens": ["Und", "zeucht", "den", "Ke\u00b7gel", "nicht", "von", "lan\u00b7gen", "Ti\u00b7tuln", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PTKNEG", "APPR", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bey welchem man noch kan den Treber F\u00fcrsten kennen.", "tokens": ["Bey", "wel\u00b7chem", "man", "noch", "kan", "den", "Tre\u00b7ber", "F\u00fcrs\u00b7ten", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "PIS", "ADV", "VMFIN", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.7": {"line.1": {"text": "Fragstu, was er bey uns sonst l\u00f6blichs vorgenommen,", "tokens": ["Frags\u00b7tu", ",", "was", "er", "bey", "uns", "sonst", "l\u00f6b\u00b7lichs", "vor\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWS", "PPER", "APPR", "PPER", "ADV", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Lie\u00df seine Hand, mit der er als ein Bieder Mann,", "tokens": ["Lie\u00df", "sei\u00b7ne", "Hand", ",", "mit", "der", "er", "als", "ein", "Bie\u00b7der", "Mann", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$,", "APPR", "PRELS", "PPER", "KOUS", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "In das gemeine Gutt so manchen Griff gethan,", "tokens": ["In", "das", "ge\u00b7mei\u00b7ne", "Gutt", "so", "man\u00b7chen", "Griff", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "So wirstu alsobald auff seine Thaten kommen.", "tokens": ["So", "wirs\u00b7tu", "al\u00b7so\u00b7bald", "auff", "sei\u00b7ne", "Tha\u00b7ten", "kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "APPR", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.8": {"line.1": {"text": "Das blo\u00df gef\u00e4llt mir nicht, da\u00df er vor andern allen", "tokens": ["Das", "blo\u00df", "ge\u00b7f\u00e4llt", "mir", "nicht", ",", "da\u00df", "er", "vor", "an\u00b7dern", "al\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PDS", "ADV", "VVFIN", "PPER", "PTKNEG", "$,", "KOUS", "PPER", "APPR", "PIS", "PIAT"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Offt unsern Burg geleckt zu seinem Nutzen hat,", "tokens": ["Offt", "un\u00b7sern", "Burg", "ge\u00b7leckt", "zu", "sei\u00b7nem", "Nut\u00b7zen", "hat", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVPP", "APPR", "PPOSAT", "NN", "VAFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Ich seh es, du f\u00e4ngst an? Wie heist er, der dis that?", "tokens": ["Ich", "seh", "es", ",", "du", "f\u00e4ngst", "an", "?", "Wie", "heist", "er", ",", "der", "dis", "that", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "$,", "PPER", "VVFIN", "PTKVZ", "$.", "PWAV", "VAFIN", "PPER", "$,", "PRELS", "PDS", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Verzeih es mir, es ist sein Nahme mir entfallen.", "tokens": ["Ver\u00b7zeih", "es", "mir", ",", "es", "ist", "sein", "Nah\u00b7me", "mir", "ent\u00b7fal\u00b7len", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PPER", "$,", "PPER", "VAFIN", "PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}}}}