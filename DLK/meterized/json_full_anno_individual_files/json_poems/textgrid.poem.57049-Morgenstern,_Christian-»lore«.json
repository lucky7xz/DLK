{"textgrid.poem.57049": {"metadata": {"author": {"name": "Morgenstern, Christian", "birth": "N.A.", "death": "N.A."}, "title": "\u00bblore\u00ab", "genre": "verse", "period": "N.A.", "pub_year": 1892, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie hei\u00dft der Papagei? wird mancher fragen.", "tokens": ["Wie", "hei\u00dft", "der", "Pa\u00b7pa\u00b7gei", "?", "wird", "man\u00b7cher", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$.", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch nie wird jemand jemandem dies sagen.", "tokens": ["Doch", "nie", "wird", "je\u00b7mand", "je\u00b7man\u00b7dem", "dies", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIS", "PIS", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.2": {"line.1": {"text": "Er ward einmal mit \u00bbLore\u00ab angesprochen \u2013", "tokens": ["Er", "ward", "ein\u00b7mal", "mit", "\u00bb", "Lo\u00b7re", "\u00ab", "an\u00b7ge\u00b7spro\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "$(", "NE", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und fiel darauf in Wehmut viele Wochen.", "tokens": ["und", "fiel", "da\u00b7rauf", "in", "Weh\u00b7mut", "vie\u00b7le", "Wo\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.3": {"line.1": {"text": "Er ward erst wieder voll und ganz gesund", "tokens": ["Er", "ward", "erst", "wie\u00b7der", "voll", "und", "ganz", "ge\u00b7sund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "durch einen Freund: Fritz Kunkels jungen Hund.", "tokens": ["durch", "ei\u00b7nen", "Freund", ":", "Fritz", "Kun\u00b7kels", "jun\u00b7gen", "Hund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Wie hei\u00dft der Papagei? wird mancher fragen.", "tokens": ["Wie", "hei\u00dft", "der", "Pa\u00b7pa\u00b7gei", "?", "wird", "man\u00b7cher", "fra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ART", "NN", "$.", "VAFIN", "PIS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Doch nie wird jemand jemandem dies sagen.", "tokens": ["Doch", "nie", "wird", "je\u00b7mand", "je\u00b7man\u00b7dem", "dies", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PIS", "PIS", "PDS", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.5": {"line.1": {"text": "Er ward einmal mit \u00bbLore\u00ab angesprochen \u2013", "tokens": ["Er", "ward", "ein\u00b7mal", "mit", "\u00bb", "Lo\u00b7re", "\u00ab", "an\u00b7ge\u00b7spro\u00b7chen", "\u2013"], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "$(", "NE", "$(", "VVPP", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "und fiel darauf in Wehmut viele Wochen.", "tokens": ["und", "fiel", "da\u00b7rauf", "in", "Weh\u00b7mut", "vie\u00b7le", "Wo\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PAV", "APPR", "NN", "PIAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.6": {"line.1": {"text": "Er ward erst wieder voll und ganz gesund", "tokens": ["Er", "ward", "erst", "wie\u00b7der", "voll", "und", "ganz", "ge\u00b7sund"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "ADJD", "KON", "ADV", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "durch einen Freund: Fritz Kunkels jungen Hund.", "tokens": ["durch", "ei\u00b7nen", "Freund", ":", "Fritz", "Kun\u00b7kels", "jun\u00b7gen", "Hund", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$.", "NE", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}}}}}