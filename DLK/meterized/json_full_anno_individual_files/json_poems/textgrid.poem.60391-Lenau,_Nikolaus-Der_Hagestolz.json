{"textgrid.poem.60391": {"metadata": {"author": {"name": "Lenau, Nikolaus", "birth": "N.A.", "death": "N.A."}, "title": "Der Hagestolz", "genre": "verse", "period": "N.A.", "pub_year": 1837, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich hab kein Weib, ich hab kein Kind", "tokens": ["Ich", "hab", "kein", "Weib", ",", "ich", "hab", "kein", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meiner \u00f6den Stube,", "tokens": ["In", "mei\u00b7ner", "\u00f6\u00b7den", "Stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier t\u00f6nts nicht: \u00bbGuten Morgen!\u00ab lind,", "tokens": ["Hier", "t\u00f6nts", "nicht", ":", "\u00bb", "Gu\u00b7ten", "Mor\u00b7gen", "!", "\u00ab", "lind", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "$.", "$(", "ADJA", "NN", "$.", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier tobt kein muntrer Bube.", "tokens": ["Hier", "tobt", "kein", "mun\u00b7trer", "Bu\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und auch kein treuer Hund mir naht,", "tokens": ["Und", "auch", "kein", "treu\u00b7er", "Hund", "mir", "naht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit schmeichelndem Gewedel;", "tokens": ["Mit", "schmei\u00b7cheln\u00b7dem", "Ge\u00b7we\u00b7del", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Rauch nur ist mein Kamerad,", "tokens": ["Der", "Rauch", "nur", "ist", "mein", "Ka\u00b7me\u00b7rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dort der Totensch\u00e4del.", "tokens": ["Und", "dort", "der", "To\u00b7ten\u00b7sch\u00e4\u00b7del", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "In Ringlein blau der Rauch verweht;", "tokens": ["In", "Rin\u00b7glein", "blau", "der", "Rauch", "ver\u00b7weht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Hirnes leerer Tiegel", "tokens": ["Des", "Hir\u00b7nes", "lee\u00b7rer", "Tie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort auf dem Schrank am Spiegel steht,", "tokens": ["Dort", "auf", "dem", "Schrank", "am", "Spie\u00b7gel", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein fortgesetzter Spiegel.", "tokens": ["Ein", "fort\u00b7ge\u00b7setz\u00b7ter", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Ich habe weislich mir gepflanzt", "tokens": ["Ich", "ha\u00b7be", "weis\u00b7lich", "mir", "ge\u00b7pflanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Freund auf die Kommode,", "tokens": ["Den", "Freund", "auf", "die", "Kom\u00b7mo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vor allzu hei\u00dfem Wunsch verschanzt", "tokens": ["Vor", "all\u00b7zu", "hei\u00b7\u00dfem", "Wunsch", "ver\u00b7schanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PTKA", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich mich mit dem Tode.", "tokens": ["Hab", "ich", "mich", "mit", "dem", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}}, "stanza.5": {"line.1": {"text": "Den Rauch betrachtend, Rad an Rad,", "tokens": ["Den", "Rauch", "be\u00b7trach\u00b7tend", ",", "Rad", "an", "Rad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dort den bleichen Knochen,", "tokens": ["Und", "dort", "den", "blei\u00b7chen", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat noch ein dritter Kamerad", "tokens": ["Hat", "noch", "ein", "drit\u00b7ter", "Ka\u00b7me\u00b7rad"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wildkalt in mir gesprochen:", "tokens": ["Wild\u00b7kalt", "in", "mir", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Was ist es auch, was tut es auch,", "tokens": ["Was", "ist", "es", "auch", ",", "was", "tut", "es", "auch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "PWS", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Weib und Kind dir fehle,", "tokens": ["Da\u00df", "Weib", "und", "Kind", "dir", "feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald wird ja doch, wie dieser Rauch,", "tokens": ["Bald", "wird", "ja", "doch", ",", "wie", "die\u00b7ser", "Rauch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "$,", "PWAV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verblasen deine Seele!", "tokens": ["Ver\u00b7bla\u00b7sen", "dei\u00b7ne", "See\u00b7le", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Die Sch\u00e4delpfeif hat auch geraucht,", "tokens": ["Die", "Sch\u00e4\u00b7del\u00b7pfeif", "hat", "auch", "ge\u00b7raucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als drin das Leben brannte,", "tokens": ["Als", "drin", "das", "Le\u00b7ben", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als noch der Raucher drein gehaucht,", "tokens": ["Als", "noch", "der", "Rau\u00b7cher", "drein", "ge\u00b7haucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der gro\u00dfe Unbekannte.", "tokens": ["Der", "gro\u00b7\u00dfe", "Un\u00b7be\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Einst Wolken blies der alte Pan", "tokens": ["Einst", "Wol\u00b7ken", "blies", "der", "al\u00b7te", "Pan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus diesen schlechten Scherben;", "tokens": ["Aus", "die\u00b7sen", "schlech\u00b7ten", "Scher\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun hat ers Pfeiflein abgetan,", "tokens": ["Nun", "hat", "ers", "Pfei\u00b7flein", "ab\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Menschen hei\u00dfens Sterben.", "tokens": ["Die", "Men\u00b7schen", "hei\u00b7\u00dfens", "Ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Der Sch\u00e4del dort, so h\u00e4\u00dflich itzt,", "tokens": ["Der", "Sch\u00e4\u00b7del", "dort", ",", "so", "h\u00e4\u00df\u00b7lich", "itzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So kahl und hohl zur Stunde,", "tokens": ["So", "kahl", "und", "hohl", "zur", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "War einst, wer wei\u00df, wie sch\u00f6n geschnitzt,", "tokens": ["War", "einst", ",", "wer", "wei\u00df", ",", "wie", "sch\u00f6n", "ge\u00b7schnitzt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWS", "VVFIN", "$,", "PWAV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Pan ihn hielt am Munde.", "tokens": ["Als", "Pan", "ihn", "hielt", "am", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Das Bild am Kopf ist abgewischt;", "tokens": ["Das", "Bild", "am", "Kopf", "ist", "ab\u00b7ge\u00b7wischt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wars dumm, wars ein gescheites,", "tokens": ["Wars", "dumm", ",", "wars", "ein", "ge\u00b7schei\u00b7tes", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es wird nicht wieder aufgefrischt,", "tokens": ["Es", "wird", "nicht", "wie\u00b7der", "auf\u00b7ge\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s ist einerlei nun beides.", "tokens": ["'s", "ist", "ei\u00b7ner\u00b7lei", "nun", "bei\u00b7des", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Und ob es Gl\u00fcck, ob Ungl\u00fcck hie\u00df,", "tokens": ["Und", "ob", "es", "Gl\u00fcck", ",", "ob", "Un\u00b7gl\u00fcck", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Kummer oder Segen,", "tokens": ["Ob", "Kum\u00b7mer", "o\u00b7der", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was Pan hier in die L\u00fcfte blies,", "tokens": ["Was", "Pan", "hier", "in", "die", "L\u00fcf\u00b7te", "blies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist wenig dran gelegen.", "tokens": ["Ist", "we\u00b7nig", "dran", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Vom Rauche, den der Wind vertrieb,", "tokens": ["Vom", "Rau\u00b7che", ",", "den", "der", "Wind", "ver\u00b7trieb", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Feuer, windverschlungen,", "tokens": ["Vom", "Feu\u00b7er", ",", "wind\u00b7ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nichts als ein Bild erhalten blieb", "tokens": ["Nichts", "als", "ein", "Bild", "er\u00b7hal\u00b7ten", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Pans Erinnerungen. \u2013", "tokens": ["In", "Pans", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Das Lebensgl\u00fcck ist nicht gegl\u00fcckt,", "tokens": ["Das", "Le\u00b7bens\u00b7gl\u00fcck", "ist", "nicht", "ge\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschen mirs zertraten,", "tokens": ["Die", "Men\u00b7schen", "mirs", "zer\u00b7tra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun will ich, in mich selbst gedr\u00fcckt,", "tokens": ["Nun", "will", "ich", ",", "in", "mich", "selbst", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch einen Hund entraten.", "tokens": ["Auch", "ei\u00b7nen", "Hund", "ent\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Wenn sie mich unbeweint zuletzt,", "tokens": ["Wenn", "sie", "mich", "un\u00b7be\u00b7weint", "zu\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weib-, kinderlos, verscharren,", "tokens": ["Weib", ",", "kin\u00b7der\u00b7los", ",", "ver\u00b7schar\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["TRUNC", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich z\u00fcnde meinen Knaster jetzt,", "tokens": ["Ich", "z\u00fcn\u00b7de", "mei\u00b7nen", "Knas\u00b7ter", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Rauche nachzustarren.", "tokens": ["Dem", "Rau\u00b7che", "nach\u00b7zu\u00b7star\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Ich hab kein Weib, ich hab kein Kind", "tokens": ["Ich", "hab", "kein", "Weib", ",", "ich", "hab", "kein", "Kind"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "PIAT", "NN", "$,", "PPER", "VAFIN", "PIAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In meiner \u00f6den Stube,", "tokens": ["In", "mei\u00b7ner", "\u00f6\u00b7den", "Stu\u00b7be", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier t\u00f6nts nicht: \u00bbGuten Morgen!\u00ab lind,", "tokens": ["Hier", "t\u00f6nts", "nicht", ":", "\u00bb", "Gu\u00b7ten", "Mor\u00b7gen", "!", "\u00ab", "lind", ","], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "punct", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "PTKNEG", "$.", "$(", "ADJA", "NN", "$.", "$(", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hier tobt kein muntrer Bube.", "tokens": ["Hier", "tobt", "kein", "mun\u00b7trer", "Bu\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Und auch kein treuer Hund mir naht,", "tokens": ["Und", "auch", "kein", "treu\u00b7er", "Hund", "mir", "naht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "PIAT", "ADJA", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit schmeichelndem Gewedel;", "tokens": ["Mit", "schmei\u00b7cheln\u00b7dem", "Ge\u00b7we\u00b7del", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Der Rauch nur ist mein Kamerad,", "tokens": ["Der", "Rauch", "nur", "ist", "mein", "Ka\u00b7me\u00b7rad", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und dort der Totensch\u00e4del.", "tokens": ["Und", "dort", "der", "To\u00b7ten\u00b7sch\u00e4\u00b7del", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "In Ringlein blau der Rauch verweht;", "tokens": ["In", "Rin\u00b7glein", "blau", "der", "Rauch", "ver\u00b7weht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "ADJD", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des Hirnes leerer Tiegel", "tokens": ["Des", "Hir\u00b7nes", "lee\u00b7rer", "Tie\u00b7gel"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Dort auf dem Schrank am Spiegel steht,", "tokens": ["Dort", "auf", "dem", "Schrank", "am", "Spie\u00b7gel", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein fortgesetzter Spiegel.", "tokens": ["Ein", "fort\u00b7ge\u00b7setz\u00b7ter", "Spie\u00b7gel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Ich habe weislich mir gepflanzt", "tokens": ["Ich", "ha\u00b7be", "weis\u00b7lich", "mir", "ge\u00b7pflanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "VAFIN", "ADV", "PPER", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Freund auf die Kommode,", "tokens": ["Den", "Freund", "auf", "die", "Kom\u00b7mo\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Vor allzu hei\u00dfem Wunsch verschanzt", "tokens": ["Vor", "all\u00b7zu", "hei\u00b7\u00dfem", "Wunsch", "ver\u00b7schanzt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PTKA", "ADJA", "NN", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Hab ich mich mit dem Tode.", "tokens": ["Hab", "ich", "mich", "mit", "dem", "To\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ART", "NN", "$."], "meter": "---+-+-", "measure": "unknown.measure.di"}}, "stanza.19": {"line.1": {"text": "Den Rauch betrachtend, Rad an Rad,", "tokens": ["Den", "Rauch", "be\u00b7trach\u00b7tend", ",", "Rad", "an", "Rad", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVPP", "$,", "NN", "APPR", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und dort den bleichen Knochen,", "tokens": ["Und", "dort", "den", "blei\u00b7chen", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hat noch ein dritter Kamerad", "tokens": ["Hat", "noch", "ein", "drit\u00b7ter", "Ka\u00b7me\u00b7rad"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wildkalt in mir gesprochen:", "tokens": ["Wild\u00b7kalt", "in", "mir", "ge\u00b7spro\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Was ist es auch, was tut es auch,", "tokens": ["Was", "ist", "es", "auch", ",", "was", "tut", "es", "auch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "$,", "PWS", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df Weib und Kind dir fehle,", "tokens": ["Da\u00df", "Weib", "und", "Kind", "dir", "feh\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Bald wird ja doch, wie dieser Rauch,", "tokens": ["Bald", "wird", "ja", "doch", ",", "wie", "die\u00b7ser", "Rauch", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADV", "ADV", "$,", "PWAV", "PDAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Verblasen deine Seele!", "tokens": ["Ver\u00b7bla\u00b7sen", "dei\u00b7ne", "See\u00b7le", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Die Sch\u00e4delpfeif hat auch geraucht,", "tokens": ["Die", "Sch\u00e4\u00b7del\u00b7pfeif", "hat", "auch", "ge\u00b7raucht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Als drin das Leben brannte,", "tokens": ["Als", "drin", "das", "Le\u00b7ben", "brann\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Als noch der Raucher drein gehaucht,", "tokens": ["Als", "noch", "der", "Rau\u00b7cher", "drein", "ge\u00b7haucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "ART", "NN", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der gro\u00dfe Unbekannte.", "tokens": ["Der", "gro\u00b7\u00dfe", "Un\u00b7be\u00b7kann\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Einst Wolken blies der alte Pan", "tokens": ["Einst", "Wol\u00b7ken", "blies", "der", "al\u00b7te", "Pan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "NN", "VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Aus diesen schlechten Scherben;", "tokens": ["Aus", "die\u00b7sen", "schlech\u00b7ten", "Scher\u00b7ben", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun hat ers Pfeiflein abgetan,", "tokens": ["Nun", "hat", "ers", "Pfei\u00b7flein", "ab\u00b7ge\u00b7tan", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Die Menschen hei\u00dfens Sterben.", "tokens": ["Die", "Men\u00b7schen", "hei\u00b7\u00dfens", "Ster\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Der Sch\u00e4del dort, so h\u00e4\u00dflich itzt,", "tokens": ["Der", "Sch\u00e4\u00b7del", "dort", ",", "so", "h\u00e4\u00df\u00b7lich", "itzt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "$,", "ADV", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So kahl und hohl zur Stunde,", "tokens": ["So", "kahl", "und", "hohl", "zur", "Stun\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "KON", "ADJD", "APPRART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "War einst, wer wei\u00df, wie sch\u00f6n geschnitzt,", "tokens": ["War", "einst", ",", "wer", "wei\u00df", ",", "wie", "sch\u00f6n", "ge\u00b7schnitzt", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$,", "PWS", "VVFIN", "$,", "PWAV", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Als Pan ihn hielt am Munde.", "tokens": ["Als", "Pan", "ihn", "hielt", "am", "Mun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PPER", "VVFIN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Das Bild am Kopf ist abgewischt;", "tokens": ["Das", "Bild", "am", "Kopf", "ist", "ab\u00b7ge\u00b7wischt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPRART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Wars dumm, wars ein gescheites,", "tokens": ["Wars", "dumm", ",", "wars", "ein", "ge\u00b7schei\u00b7tes", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "$,", "VAFIN", "ART", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Es wird nicht wieder aufgefrischt,", "tokens": ["Es", "wird", "nicht", "wie\u00b7der", "auf\u00b7ge\u00b7frischt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PTKNEG", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "'s ist einerlei nun beides.", "tokens": ["'s", "ist", "ei\u00b7ner\u00b7lei", "nun", "bei\u00b7des", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "PIS", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.25": {"line.1": {"text": "Und ob es Gl\u00fcck, ob Ungl\u00fcck hie\u00df,", "tokens": ["Und", "ob", "es", "Gl\u00fcck", ",", "ob", "Un\u00b7gl\u00fcck", "hie\u00df", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "NN", "$,", "KOUS", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ob Kummer oder Segen,", "tokens": ["Ob", "Kum\u00b7mer", "o\u00b7der", "Se\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was Pan hier in die L\u00fcfte blies,", "tokens": ["Was", "Pan", "hier", "in", "die", "L\u00fcf\u00b7te", "blies", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "NE", "ADV", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ist wenig dran gelegen.", "tokens": ["Ist", "we\u00b7nig", "dran", "ge\u00b7le\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "PAV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Vom Rauche, den der Wind vertrieb,", "tokens": ["Vom", "Rau\u00b7che", ",", "den", "der", "Wind", "ver\u00b7trieb", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "$,", "PRELS", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Vom Feuer, windverschlungen,", "tokens": ["Vom", "Feu\u00b7er", ",", "wind\u00b7ver\u00b7schlun\u00b7gen", ","], "token_info": ["word", "word", "punct", "word", "punct"], "pos": ["APPRART", "NN", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nichts als ein Bild erhalten blieb", "tokens": ["Nichts", "als", "ein", "Bild", "er\u00b7hal\u00b7ten", "blieb"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "KOKOM", "ART", "NN", "VVINF", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In Pans Erinnerungen. \u2013", "tokens": ["In", "Pans", "E\u00b7rin\u00b7ne\u00b7run\u00b7gen", ".", "\u2013"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["APPR", "NE", "NN", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Das Lebensgl\u00fcck ist nicht gegl\u00fcckt,", "tokens": ["Das", "Le\u00b7bens\u00b7gl\u00fcck", "ist", "nicht", "ge\u00b7gl\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Menschen mirs zertraten,", "tokens": ["Die", "Men\u00b7schen", "mirs", "zer\u00b7tra\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NE", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Nun will ich, in mich selbst gedr\u00fcckt,", "tokens": ["Nun", "will", "ich", ",", "in", "mich", "selbst", "ge\u00b7dr\u00fcckt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "$,", "APPR", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Auch einen Hund entraten.", "tokens": ["Auch", "ei\u00b7nen", "Hund", "ent\u00b7ra\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Wenn sie mich unbeweint zuletzt,", "tokens": ["Wenn", "sie", "mich", "un\u00b7be\u00b7weint", "zu\u00b7letzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PRF", "ADJD", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Weib-, kinderlos, verscharren,", "tokens": ["Weib", ",", "kin\u00b7der\u00b7los", ",", "ver\u00b7schar\u00b7ren", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct"], "pos": ["TRUNC", "$,", "ADJD", "$,", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ich z\u00fcnde meinen Knaster jetzt,", "tokens": ["Ich", "z\u00fcn\u00b7de", "mei\u00b7nen", "Knas\u00b7ter", "jetzt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dem Rauche nachzustarren.", "tokens": ["Dem", "Rau\u00b7che", "nach\u00b7zu\u00b7star\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}