{"textgrid.poem.50347": {"metadata": {"author": {"name": "Wernicke, Christian", "birth": "N.A.", "death": "N.A."}, "title": "4. Auf die Frantz\u00f6sische Donnerworte", "genre": "verse", "period": "N.A.", "pub_year": 1693, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Zu Regenspurg ", "tokens": ["Zu", "Re\u00b7gen\u00b7spurg"], "token_info": ["word", "word"], "pos": ["APPR", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Auf welche ", "tokens": ["Auf", "wel\u00b7che"], "token_info": ["word", "word"], "pos": ["APPR", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und zu ", "tokens": ["Und", "zu"], "token_info": ["word", "word"], "pos": ["KON", "PTKZU"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Die machen, dass uns Franckreich dr\u00fccket,", "tokens": ["Die", "ma\u00b7chen", ",", "dass", "uns", "Fran\u00b7ck\u00b7reich", "dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "$,", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Bey uns heist's: ", "tokens": ["Bey", "uns", "heist's", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und dort in einem Zug: ", "tokens": ["Und", "dort", "in", "ei\u00b7nem", "Zug", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Zu Regenspurg ", "tokens": ["Zu", "Re\u00b7gen\u00b7spurg"], "token_info": ["word", "word"], "pos": ["APPR", "NE"], "meter": "-+-+", "measure": "iambic.di"}, "line.2": {"text": "Auf welche ", "tokens": ["Auf", "wel\u00b7che"], "token_info": ["word", "word"], "pos": ["APPR", "PRELS"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Und zu ", "tokens": ["Und", "zu"], "token_info": ["word", "word"], "pos": ["KON", "PTKZU"], "meter": "+-", "measure": "trochaic.single"}, "line.4": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.5": {"text": "Die machen, dass uns Franckreich dr\u00fccket,", "tokens": ["Die", "ma\u00b7chen", ",", "dass", "uns", "Fran\u00b7ck\u00b7reich", "dr\u00fc\u00b7cket", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "VVINF", "$,", "KOUS", "PPER", "NE", "VVFIN", "$,"], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Und die ", "tokens": ["Und", "die"], "token_info": ["word", "word"], "pos": ["KON", "ART"], "meter": "+-", "measure": "trochaic.single"}, "line.7": {"text": "Bey uns heist's: ", "tokens": ["Bey", "uns", "heist's", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPER", "VVFIN", "$."], "meter": "+-+", "measure": "trochaic.di"}, "line.8": {"text": "Und dort in einem Zug: ", "tokens": ["Und", "dort", "in", "ei\u00b7nem", "Zug", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}