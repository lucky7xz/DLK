{"textgrid.poem.42201": {"metadata": {"author": {"name": "Wedekind, Frank", "birth": "N.A.", "death": "N.A."}, "title": "Christine", "genre": "verse", "period": "N.A.", "pub_year": 1891, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Bessern soll ich mich? \u2013 O Himmel,", "tokens": ["Bes\u00b7sern", "soll", "ich", "mich", "?", "\u2013", "O", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PRF", "$.", "$(", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie werd ich wohl besser!", "tokens": ["Wie", "werd", "ich", "wohl", "bes\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eher reiten schwarze Schimmel", "tokens": ["E\u00b7her", "rei\u00b7ten", "schwar\u00b7ze", "Schim\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00dfe Menschenfresser,", "tokens": ["Wei\u00b7\u00dfe", "Men\u00b7schen\u00b7fres\u00b7ser", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "Eh da\u00df solch ein Kauz wie ich", "tokens": ["Eh", "da\u00df", "solch", "ein", "Kauz", "wie", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "PIAT", "ART", "NN", "KOKOM", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In sich geht und bessert sich.", "tokens": ["In", "sich", "geht", "und", "bes\u00b7sert", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "KON", "VVFIN", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Nein, mein Fr\u00e4ulein, ich verzichte", "tokens": ["Nein", ",", "mein", "Fr\u00e4u\u00b7lein", ",", "ich", "ver\u00b7zich\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf die Tugendpalme;", "tokens": ["Auf", "die", "Tu\u00b7gend\u00b7pal\u00b7me", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schreibe meine Mordgedichte", "tokens": ["Schrei\u00b7be", "mei\u00b7ne", "Mord\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tief im Tabaksqualme,", "tokens": ["Tief", "im", "Ta\u00b7baks\u00b7qual\u00b7me", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.4": {"line.1": {"text": "Bis der Satan kommt und spricht:", "tokens": ["Bis", "der", "Sa\u00b7tan", "kommt", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort mit dir, du B\u00f6sewicht!", "tokens": ["Fort", "mit", "dir", ",", "du", "B\u00f6\u00b7se\u00b7wicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja, der Teufel wird mich holen", "tokens": ["Ja", ",", "der", "Teu\u00b7fel", "wird", "mich", "ho\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fcher oder sp\u00e4ter,", "tokens": ["Fr\u00fc\u00b7her", "o\u00b7der", "sp\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich \u00c4rmster mu\u00df verkohlen", "tokens": ["Und", "ich", "\u00c4rms\u00b7ter", "mu\u00df", "ver\u00b7koh\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unter Schmerzgezeter;", "tokens": ["Un\u00b7ter", "Schmerz\u00b7ge\u00b7ze\u00b7ter", ";"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Haut und Haar und Fleisch und Bein,", "tokens": ["Haut", "und", "Haar", "und", "Fleisch", "und", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles mu\u00df gebraten sein.", "tokens": ["Al\u00b7les", "mu\u00df", "ge\u00b7bra\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Sie indessen wandeln lieblich", "tokens": ["Sie", "in\u00b7des\u00b7sen", "wan\u00b7deln", "lieb\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Engel Scharen,", "tokens": ["In", "der", "En\u00b7gel", "Scha\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Blumen tragend, wie dort \u00fcblich,", "tokens": ["Blu\u00b7men", "tra\u00b7gend", ",", "wie", "dort", "\u00fcb\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PWAV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In gelockten Haaren,", "tokens": ["In", "ge\u00b7lock\u00b7ten", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "Und das ganze Angesicht", "tokens": ["Und", "das", "gan\u00b7ze", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Angestrahlt vom Himmelslicht.", "tokens": ["An\u00b7ge\u00b7strahlt", "vom", "Him\u00b7mels\u00b7licht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "Sehn Sie nun, wie weit geschieden", "tokens": ["Sehn", "Sie", "nun", ",", "wie", "weit", "ge\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre beiden Pfade:", "tokens": ["Uns\u00b7re", "bei\u00b7den", "Pfa\u00b7de", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihnen eines Gartens Frieden,", "tokens": ["Ih\u00b7nen", "ei\u00b7nes", "Gar\u00b7tens", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir die Barrikade,", "tokens": ["Mir", "die", "Bar\u00b7ri\u00b7ka\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.10": {"line.1": {"text": "Wo man sich bei jedem Schritt", "tokens": ["Wo", "man", "sich", "bei", "je\u00b7dem", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PRF", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf die H\u00fchneraugen tritt.", "tokens": ["Auf", "die", "H\u00fch\u00b7ner\u00b7au\u00b7gen", "tritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Ihnen freundliche Erbarmung,", "tokens": ["Ih\u00b7nen", "freund\u00b7li\u00b7che", "Er\u00b7bar\u00b7mung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir der Waffen Blinken", "tokens": ["Mir", "der", "Waf\u00b7fen", "Blin\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und des wilden B\u00e4rs Umarmung,", "tokens": ["Und", "des", "wil\u00b7den", "B\u00e4rs", "Um\u00b7ar\u00b7mung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihnen seine Schinken,", "tokens": ["Ih\u00b7nen", "sei\u00b7ne", "Schin\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.12": {"line.1": {"text": "Mir des Feinds entmenschter Streit,", "tokens": ["Mir", "des", "Feinds", "ent\u00b7menschter", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ihnen seine Menschlichkeit!", "tokens": ["Ih\u00b7nen", "sei\u00b7ne", "Menschlich\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.13": {"line.1": {"text": "Bessern soll ich mich? \u2013 O Himmel,", "tokens": ["Bes\u00b7sern", "soll", "ich", "mich", "?", "\u2013", "O", "Him\u00b7mel", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["NN", "VMFIN", "PPER", "PRF", "$.", "$(", "NE", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Wie werd ich wohl besser!", "tokens": ["Wie", "werd", "ich", "wohl", "bes\u00b7ser", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "ADV", "ADJD", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Eher reiten schwarze Schimmel", "tokens": ["E\u00b7her", "rei\u00b7ten", "schwar\u00b7ze", "Schim\u00b7mel"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Wei\u00dfe Menschenfresser,", "tokens": ["Wei\u00b7\u00dfe", "Men\u00b7schen\u00b7fres\u00b7ser", ","], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.14": {"line.1": {"text": "Eh da\u00df solch ein Kauz wie ich", "tokens": ["Eh", "da\u00df", "solch", "ein", "Kauz", "wie", "ich"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["NN", "KOUS", "PIAT", "ART", "NN", "KOKOM", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "In sich geht und bessert sich.", "tokens": ["In", "sich", "geht", "und", "bes\u00b7sert", "sich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PRF", "VVFIN", "KON", "VVFIN", "PRF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Nein, mein Fr\u00e4ulein, ich verzichte", "tokens": ["Nein", ",", "mein", "Fr\u00e4u\u00b7lein", ",", "ich", "ver\u00b7zich\u00b7te"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PTKANT", "$,", "PPOSAT", "NN", "$,", "PPER", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf die Tugendpalme;", "tokens": ["Auf", "die", "Tu\u00b7gend\u00b7pal\u00b7me", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Schreibe meine Mordgedichte", "tokens": ["Schrei\u00b7be", "mei\u00b7ne", "Mord\u00b7ge\u00b7dich\u00b7te"], "token_info": ["word", "word", "word"], "pos": ["NN", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Tief im Tabaksqualme,", "tokens": ["Tief", "im", "Ta\u00b7baks\u00b7qual\u00b7me", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "APPRART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.16": {"line.1": {"text": "Bis der Satan kommt und spricht:", "tokens": ["Bis", "der", "Sa\u00b7tan", "kommt", "und", "spricht", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "KON", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Fort mit dir, du B\u00f6sewicht!", "tokens": ["Fort", "mit", "dir", ",", "du", "B\u00f6\u00b7se\u00b7wicht", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["NN", "APPR", "PPER", "$,", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Ja, der Teufel wird mich holen", "tokens": ["Ja", ",", "der", "Teu\u00b7fel", "wird", "mich", "ho\u00b7len"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "$,", "ART", "NN", "VAFIN", "PPER", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Fr\u00fcher oder sp\u00e4ter,", "tokens": ["Fr\u00fc\u00b7her", "o\u00b7der", "sp\u00e4\u00b7ter", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADJD", "KON", "ADJD", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und ich \u00c4rmster mu\u00df verkohlen", "tokens": ["Und", "ich", "\u00c4rms\u00b7ter", "mu\u00df", "ver\u00b7koh\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "PPER", "NN", "VMFIN", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Unter Schmerzgezeter;", "tokens": ["Un\u00b7ter", "Schmerz\u00b7ge\u00b7ze\u00b7ter", ";"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.18": {"line.1": {"text": "Haut und Haar und Fleisch und Bein,", "tokens": ["Haut", "und", "Haar", "und", "Fleisch", "und", "Bein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KON", "NN", "KON", "NN", "KON", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Alles mu\u00df gebraten sein.", "tokens": ["Al\u00b7les", "mu\u00df", "ge\u00b7bra\u00b7ten", "sein", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "VVPP", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.19": {"line.1": {"text": "Sie indessen wandeln lieblich", "tokens": ["Sie", "in\u00b7des\u00b7sen", "wan\u00b7deln", "lieb\u00b7lich"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "ADV", "VVFIN", "ADJD"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "In der Engel Scharen,", "tokens": ["In", "der", "En\u00b7gel", "Scha\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Blumen tragend, wie dort \u00fcblich,", "tokens": ["Blu\u00b7men", "tra\u00b7gend", ",", "wie", "dort", "\u00fcb\u00b7lich", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "VVPP", "$,", "PWAV", "ADV", "ADJD", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "In gelockten Haaren,", "tokens": ["In", "ge\u00b7lock\u00b7ten", "Haa\u00b7ren", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.20": {"line.1": {"text": "Und das ganze Angesicht", "tokens": ["Und", "das", "gan\u00b7ze", "An\u00b7ge\u00b7sicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ART", "ADJA", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Angestrahlt vom Himmelslicht.", "tokens": ["An\u00b7ge\u00b7strahlt", "vom", "Him\u00b7mels\u00b7licht", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["VVPP", "APPRART", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.21": {"line.1": {"text": "Sehn Sie nun, wie weit geschieden", "tokens": ["Sehn", "Sie", "nun", ",", "wie", "weit", "ge\u00b7schie\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ADV", "$,", "PWAV", "ADJD", "VVPP"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Unsre beiden Pfade:", "tokens": ["Uns\u00b7re", "bei\u00b7den", "Pfa\u00b7de", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "PIAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Ihnen eines Gartens Frieden,", "tokens": ["Ih\u00b7nen", "ei\u00b7nes", "Gar\u00b7tens", "Frie\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Mir die Barrikade,", "tokens": ["Mir", "die", "Bar\u00b7ri\u00b7ka\u00b7de", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.22": {"line.1": {"text": "Wo man sich bei jedem Schritt", "tokens": ["Wo", "man", "sich", "bei", "je\u00b7dem", "Schritt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "PRF", "APPR", "PIAT", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Auf die H\u00fchneraugen tritt.", "tokens": ["Auf", "die", "H\u00fch\u00b7ner\u00b7au\u00b7gen", "tritt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}}, "stanza.23": {"line.1": {"text": "Ihnen freundliche Erbarmung,", "tokens": ["Ih\u00b7nen", "freund\u00b7li\u00b7che", "Er\u00b7bar\u00b7mung", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "ADJA", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.2": {"text": "Mir der Waffen Blinken", "tokens": ["Mir", "der", "Waf\u00b7fen", "Blin\u00b7ken"], "token_info": ["word", "word", "word", "word"], "pos": ["NE", "ART", "NN", "NN"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.3": {"text": "Und des wilden B\u00e4rs Umarmung,", "tokens": ["Und", "des", "wil\u00b7den", "B\u00e4rs", "Um\u00b7ar\u00b7mung", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "NN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Ihnen seine Schinken,", "tokens": ["Ih\u00b7nen", "sei\u00b7ne", "Schin\u00b7ken", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.24": {"line.1": {"text": "Mir des Feinds entmenschter Streit,", "tokens": ["Mir", "des", "Feinds", "ent\u00b7menschter", "Streit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "ART", "NN", "ADJA", "NN", "$,"], "meter": "+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Ihnen seine Menschlichkeit!", "tokens": ["Ih\u00b7nen", "sei\u00b7ne", "Menschlich\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}}}}