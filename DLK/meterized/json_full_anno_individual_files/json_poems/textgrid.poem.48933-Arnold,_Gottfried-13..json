{"textgrid.poem.48933": {"metadata": {"author": {"name": "Arnold, Gottfried", "birth": "N.A.", "death": "N.A."}, "title": "13.", "genre": "verse", "period": "N.A.", "pub_year": 1690, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ich lebe noch in dieser Welt/", "tokens": ["Ich", "le\u00b7be", "noch", "in", "die\u00b7ser", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin doch schon zum Himmel auffgehoben.", "tokens": ["Ich", "bin", "doch", "schon", "zum", "Him\u00b7mel", "auff\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich trag ein Joch/ das mir gef\u00e4llt:", "tokens": ["Ich", "trag", "ein", "Joch", "/", "das", "mir", "ge\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich bin ein Engel/ und kan GOTT doch loben.", "tokens": ["Ich", "bin", "ein", "En\u00b7gel", "/", "und", "kan", "GoTT", "doch", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "KON", "VMFIN", "NE", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich hei\u00df ein mangelhafftes Kind/", "tokens": ["Ich", "hei\u00df", "ein", "man\u00b7gel\u00b7haff\u00b7tes", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bin doch werth/ denselben zu umfangen/", "tokens": ["Und", "bin", "doch", "werth", "/", "den\u00b7sel\u00b7ben", "zu", "um\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$(", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "An dem man nichts als heiligs find:", "tokens": ["An", "dem", "man", "nichts", "als", "hei\u00b7ligs", "find", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "PIS", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich hab ihn schon/ und mu\u00df ihn doch verlangen.", "tokens": ["Ich", "hab", "ihn", "schon", "/", "und", "mu\u00df", "ihn", "doch", "ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "$(", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sein Creutz wird leicht/ und doch auch schwer/", "tokens": ["Sein", "Creutz", "wird", "leicht", "/", "und", "doch", "auch", "schwer", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$(", "KON", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nachdem ich so genau mit ihm vereinet:", "tokens": ["Nach\u00b7dem", "ich", "so", "ge\u00b7nau", "mit", "ihm", "ver\u00b7ei\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Mein Hertz ist voll/ und dennoch leer:", "tokens": ["Mein", "Hertz", "ist", "voll", "/", "und", "den\u00b7noch", "leer", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$(", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Voll Liebe/ leer von dem/ was ich beweinet:", "tokens": ["Voll", "Lie\u00b7be", "/", "leer", "von", "dem", "/", "was", "ich", "be\u00b7wei\u00b7net", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$(", "ADJD", "APPR", "ART", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Ich bin ein Wunder-Mensch vor anderer Menschen Augen/", "tokens": ["Ich", "bin", "ein", "Wun\u00b7der\u00b7Mensch", "vor", "an\u00b7de\u00b7rer", "Men\u00b7schen", "Au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und wei\u00df nicht/ ob ich noch werd unter Menschen taugen.", "tokens": ["Und", "wei\u00df", "nicht", "/", "ob", "ich", "noch", "werd", "un\u00b7ter", "Men\u00b7schen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "ADV", "VAFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Des Creutzes Krafft hat mich zum Thoren l\u00e4ngst gemacht;", "tokens": ["Des", "Creut\u00b7zes", "Krafft", "hat", "mich", "zum", "Tho\u00b7ren", "l\u00e4ngst", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich wundert/ da\u00df man mich nicht ins Gesicht verlacht.", "tokens": ["Mich", "wun\u00b7dert", "/", "da\u00df", "man", "mich", "nicht", "ins", "Ge\u00b7sicht", "ver\u00b7lacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIS", "PRF", "PTKNEG", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}, "stanza.2": {"line.1": {"text": "Ich lebe noch in dieser Welt/", "tokens": ["Ich", "le\u00b7be", "noch", "in", "die\u00b7ser", "Welt", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "PDAT", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ich bin doch schon zum Himmel auffgehoben.", "tokens": ["Ich", "bin", "doch", "schon", "zum", "Him\u00b7mel", "auff\u00b7ge\u00b7ho\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Ich trag ein Joch/ das mir gef\u00e4llt:", "tokens": ["Ich", "trag", "ein", "Joch", "/", "das", "mir", "ge\u00b7f\u00e4llt", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$(", "PRELS", "PPER", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich bin ein Engel/ und kan GOTT doch loben.", "tokens": ["Ich", "bin", "ein", "En\u00b7gel", "/", "und", "kan", "GoTT", "doch", "lo\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "$(", "KON", "VMFIN", "NE", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Ich hei\u00df ein mangelhafftes Kind/", "tokens": ["Ich", "hei\u00df", "ein", "man\u00b7gel\u00b7haff\u00b7tes", "Kind", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NN", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Und bin doch werth/ denselben zu umfangen/", "tokens": ["Und", "bin", "doch", "werth", "/", "den\u00b7sel\u00b7ben", "zu", "um\u00b7fan\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "ADV", "ADJD", "$(", "PDS", "PTKZU", "VVINF", "$("], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "An dem man nichts als heiligs find:", "tokens": ["An", "dem", "man", "nichts", "als", "hei\u00b7ligs", "find", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "PIS", "PIS", "KOKOM", "NE", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Ich hab ihn schon/ und mu\u00df ihn doch verlangen.", "tokens": ["Ich", "hab", "ihn", "schon", "/", "und", "mu\u00df", "ihn", "doch", "ver\u00b7lan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "$(", "KON", "VMFIN", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Sein Creutz wird leicht/ und doch auch schwer/", "tokens": ["Sein", "Creutz", "wird", "leicht", "/", "und", "doch", "auch", "schwer", "/"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$(", "KON", "ADV", "ADV", "ADJD", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.10": {"text": "Nachdem ich so genau mit ihm vereinet:", "tokens": ["Nach\u00b7dem", "ich", "so", "ge\u00b7nau", "mit", "ihm", "ver\u00b7ei\u00b7net", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "APPR", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.11": {"text": "Mein Hertz ist voll/ und dennoch leer:", "tokens": ["Mein", "Hertz", "ist", "voll", "/", "und", "den\u00b7noch", "leer", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADJD", "$(", "KON", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.12": {"text": "Voll Liebe/ leer von dem/ was ich beweinet:", "tokens": ["Voll", "Lie\u00b7be", "/", "leer", "von", "dem", "/", "was", "ich", "be\u00b7wei\u00b7net", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "NN", "$(", "ADJD", "APPR", "ART", "$(", "PWS", "PPER", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.13": {"text": "Ich bin ein Wunder-Mensch vor anderer Menschen Augen/", "tokens": ["Ich", "bin", "ein", "Wun\u00b7der\u00b7Mensch", "vor", "an\u00b7de\u00b7rer", "Men\u00b7schen", "Au\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ART", "NN", "APPR", "ADJA", "NN", "NN", "$("], "meter": "-+-+-+-+--+-+-", "measure": "iambic.hexa.relaxed"}, "line.14": {"text": "Und wei\u00df nicht/ ob ich noch werd unter Menschen taugen.", "tokens": ["Und", "wei\u00df", "nicht", "/", "ob", "ich", "noch", "werd", "un\u00b7ter", "Men\u00b7schen", "tau\u00b7gen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PTKNEG", "$(", "KOUS", "PPER", "ADV", "VAFIN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.15": {"text": "Des Creutzes Krafft hat mich zum Thoren l\u00e4ngst gemacht;", "tokens": ["Des", "Creut\u00b7zes", "Krafft", "hat", "mich", "zum", "Tho\u00b7ren", "l\u00e4ngst", "ge\u00b7macht", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VAFIN", "PPER", "APPRART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.16": {"text": "Mich wundert/ da\u00df man mich nicht ins Gesicht verlacht.", "tokens": ["Mich", "wun\u00b7dert", "/", "da\u00df", "man", "mich", "nicht", "ins", "Ge\u00b7sicht", "ver\u00b7lacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$(", "KOUS", "PIS", "PRF", "PTKNEG", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+--+--+-+", "measure": "iambic.penta.relaxed"}}}}}