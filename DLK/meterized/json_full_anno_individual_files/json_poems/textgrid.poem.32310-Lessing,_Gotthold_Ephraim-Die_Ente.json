{"textgrid.poem.32310": {"metadata": {"author": {"name": "Lessing, Gotthold Ephraim", "birth": "N.A.", "death": "N.A."}, "title": "Die Ente", "genre": "verse", "period": "N.A.", "pub_year": 1755, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Ente, wahres Bild von mir,", "tokens": ["En\u00b7te", ",", "wah\u00b7res", "Bild", "von", "mir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wahres Bild von meinen Br\u00fcdern!", "tokens": ["Wah\u00b7res", "Bild", "von", "mei\u00b7nen", "Br\u00fc\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ente, jetzo schenk' ich dir", "tokens": ["En\u00b7te", ",", "jet\u00b7zo", "schenk'", "ich", "dir"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch ein Lied von meinen Liedern.", "tokens": ["Auch", "ein", "Lied", "von", "mei\u00b7nen", "Lie\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.2": {"line.1": {"text": "Oft und oft mu\u00df dich der Neid", "tokens": ["Oft", "und", "oft", "mu\u00df", "dich", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "VMFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zechend auf dem Teiche sehen.", "tokens": ["Ze\u00b7chend", "auf", "dem", "Tei\u00b7che", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oft sieht er aus Trunkenheit", "tokens": ["Oft", "sieht", "er", "aus", "Trun\u00b7ken\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Taumelnd dich in Pf\u00fctzen gehen.", "tokens": ["Tau\u00b7melnd", "dich", "in", "Pf\u00fct\u00b7zen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.3": {"line.1": {"text": "Auch ein Tier \u2013 \u2013 o das ist viel!", "tokens": ["Auch", "ein", "Tier", "\u2013", "\u2013", "o", "das", "ist", "viel", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "$(", "FM", "PDS", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4lt den Satz f\u00fcr wahr und s\u00fc\u00dfe,", "tokens": ["H\u00e4lt", "den", "Satz", "f\u00fcr", "wahr", "und", "s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df, wer gl\u00fccklich leben will,", "tokens": ["Da\u00df", ",", "wer", "gl\u00fcck\u00b7lich", "le\u00b7ben", "will", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fein das Trinken lieben m\u00fcsse.", "tokens": ["Fein", "das", "Trin\u00b7ken", "lie\u00b7ben", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.4": {"line.1": {"text": "Ente, ists nicht die Natur,", "tokens": ["En\u00b7te", ",", "ists", "nicht", "die", "Na\u00b7tur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VAFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die dich stets zum Teiche treibet?", "tokens": ["Die", "dich", "stets", "zum", "Tei\u00b7che", "trei\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, sie ists; drum folg' ihr nur.", "tokens": ["Ja", ",", "sie", "ists", ";", "drum", "fol\u00b7g'", "ihr", "nur", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "$.", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-----+", "measure": "dactylic.init"}, "line.4": {"text": "Trinke, bis nichts \u00fcbrig bleibet.", "tokens": ["Trin\u00b7ke", ",", "bis", "nichts", "\u00fcb\u00b7rig", "blei\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Ja, du trinkst und singst dazu.", "tokens": ["Ja", ",", "du", "trinkst", "und", "singst", "da\u00b7zu", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Neider nennen es zwar schnadern;", "tokens": ["Nei\u00b7der", "nen\u00b7nen", "es", "zwar", "schna\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber, Ente, ich und du", "tokens": ["A\u00b7ber", ",", "En\u00b7te", ",", "ich", "und", "du"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVFIN", "$,", "PPER", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollen nicht um Worte hadern.", "tokens": ["Wol\u00b7len", "nicht", "um", "Wor\u00b7te", "ha\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.6": {"line.1": {"text": "Wem mein Singen nicht gef\u00e4llt,", "tokens": ["Wem", "mein", "Sin\u00b7gen", "nicht", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mag es immer Schnadern nennen.", "tokens": ["Mag", "es", "im\u00b7mer", "Schna\u00b7dern", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Will uns nur die neid'sche Welt", "tokens": ["Will", "uns", "nur", "die", "nei\u00b7d'\u00b7sche", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Als versuchte Trinker kennen.", "tokens": ["Als", "ver\u00b7such\u00b7te", "Trin\u00b7ker", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.7": {"line.1": {"text": "Aber, wie betaur' ich dich,", "tokens": ["A\u00b7ber", ",", "wie", "be\u00b7taur'", "ich", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df du nur mu\u00dft Wasser trinken.", "tokens": ["Da\u00df", "du", "nur", "mu\u00dft", "Was\u00b7ser", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie gl\u00fccklich sch\u00e4tz' ich mich,", "tokens": ["Und", "wie", "gl\u00fcck\u00b7lich", "sch\u00e4tz'", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn mir Weine daf\u00fcr blinken!", "tokens": ["Wenn", "mir", "Wei\u00b7ne", "da\u00b7f\u00fcr", "blin\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.8": {"line.1": {"text": "Armes Tier, ergib dich drein.", "tokens": ["Ar\u00b7mes", "Tier", ",", "er\u00b7gib", "dich", "drein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df dich nicht den Neid verf\u00fchren.", "tokens": ["La\u00df", "dich", "nicht", "den", "Neid", "ver\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn des Weins Gebrauch allein", "tokens": ["Denn", "des", "Weins", "Ge\u00b7brauch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unterscheidet uns von Tieren.", "tokens": ["Un\u00b7ter\u00b7schei\u00b7det", "uns", "von", "Tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.9": {"line.1": {"text": "In der Welt mu\u00df Ordnung sein.", "tokens": ["In", "der", "Welt", "mu\u00df", "Ord\u00b7nung", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Menschen sind von edlern Gaben.", "tokens": ["Men\u00b7schen", "sind", "von", "ed\u00b7lern", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du trinkst Wasser, und ich Wein;", "tokens": ["Du", "trinkst", "Was\u00b7ser", ",", "und", "ich", "Wein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KON", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So will es die Ordnung haben.", "tokens": ["So", "will", "es", "die", "Ord\u00b7nung", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.10": {"line.1": {"text": "Ente, wahres Bild von mir,", "tokens": ["En\u00b7te", ",", "wah\u00b7res", "Bild", "von", "mir", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "ADJA", "NN", "APPR", "PPER", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Wahres Bild von meinen Br\u00fcdern!", "tokens": ["Wah\u00b7res", "Bild", "von", "mei\u00b7nen", "Br\u00fc\u00b7dern", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ente, jetzo schenk' ich dir", "tokens": ["En\u00b7te", ",", "jet\u00b7zo", "schenk'", "ich", "dir"], "token_info": ["word", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "ADV", "VVFIN", "PPER", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Auch ein Lied von meinen Liedern.", "tokens": ["Auch", "ein", "Lied", "von", "mei\u00b7nen", "Lie\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.11": {"line.1": {"text": "Oft und oft mu\u00df dich der Neid", "tokens": ["Oft", "und", "oft", "mu\u00df", "dich", "der", "Neid"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "KON", "ADV", "VMFIN", "PRF", "ART", "NN"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Zechend auf dem Teiche sehen.", "tokens": ["Ze\u00b7chend", "auf", "dem", "Tei\u00b7che", "se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVPP", "APPR", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Oft sieht er aus Trunkenheit", "tokens": ["Oft", "sieht", "er", "aus", "Trun\u00b7ken\u00b7heit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Taumelnd dich in Pf\u00fctzen gehen.", "tokens": ["Tau\u00b7melnd", "dich", "in", "Pf\u00fct\u00b7zen", "ge\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "PRF", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.12": {"line.1": {"text": "Auch ein Tier \u2013 \u2013 o das ist viel!", "tokens": ["Auch", "ein", "Tier", "\u2013", "\u2013", "o", "das", "ist", "viel", "!"], "token_info": ["word", "word", "word", "punct", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "$(", "$(", "FM", "PDS", "VAFIN", "ADV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "H\u00e4lt den Satz f\u00fcr wahr und s\u00fc\u00dfe,", "tokens": ["H\u00e4lt", "den", "Satz", "f\u00fcr", "wahr", "und", "s\u00fc\u00b7\u00dfe", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ART", "NN", "APPR", "ADJD", "KON", "VVFIN", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Da\u00df, wer gl\u00fccklich leben will,", "tokens": ["Da\u00df", ",", "wer", "gl\u00fcck\u00b7lich", "le\u00b7ben", "will", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "PWS", "ADJD", "VVINF", "VMFIN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Fein das Trinken lieben m\u00fcsse.", "tokens": ["Fein", "das", "Trin\u00b7ken", "lie\u00b7ben", "m\u00fcs\u00b7se", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.13": {"line.1": {"text": "Ente, ists nicht die Natur,", "tokens": ["En\u00b7te", ",", "ists", "nicht", "die", "Na\u00b7tur", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "VAFIN", "PTKNEG", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Die dich stets zum Teiche treibet?", "tokens": ["Die", "dich", "stets", "zum", "Tei\u00b7che", "trei\u00b7bet", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "APPRART", "NN", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Ja, sie ists; drum folg' ihr nur.", "tokens": ["Ja", ",", "sie", "ists", ";", "drum", "fol\u00b7g'", "ihr", "nur", "."], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VAFIN", "$.", "PAV", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-----+", "measure": "dactylic.init"}, "line.4": {"text": "Trinke, bis nichts \u00fcbrig bleibet.", "tokens": ["Trin\u00b7ke", ",", "bis", "nichts", "\u00fcb\u00b7rig", "blei\u00b7bet", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$,", "KOUS", "PIS", "ADJD", "VVFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.14": {"line.1": {"text": "Ja, du trinkst und singst dazu.", "tokens": ["Ja", ",", "du", "trinkst", "und", "singst", "da\u00b7zu", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PPER", "VVFIN", "KON", "VVFIN", "PAV", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Neider nennen es zwar schnadern;", "tokens": ["Nei\u00b7der", "nen\u00b7nen", "es", "zwar", "schna\u00b7dern", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "ADV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Aber, Ente, ich und du", "tokens": ["A\u00b7ber", ",", "En\u00b7te", ",", "ich", "und", "du"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word"], "pos": ["KON", "$,", "VVFIN", "$,", "PPER", "KON", "PPER"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wollen nicht um Worte hadern.", "tokens": ["Wol\u00b7len", "nicht", "um", "Wor\u00b7te", "ha\u00b7dern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "APPR", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.15": {"line.1": {"text": "Wem mein Singen nicht gef\u00e4llt,", "tokens": ["Wem", "mein", "Sin\u00b7gen", "nicht", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPOSAT", "NN", "PTKNEG", "VVPP", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Mag es immer Schnadern nennen.", "tokens": ["Mag", "es", "im\u00b7mer", "Schna\u00b7dern", "nen\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "ADV", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Will uns nur die neid'sche Welt", "tokens": ["Will", "uns", "nur", "die", "nei\u00b7d'\u00b7sche", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VMFIN", "PPER", "ADV", "ART", "ADJA", "NN"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.4": {"text": "Als versuchte Trinker kennen.", "tokens": ["Als", "ver\u00b7such\u00b7te", "Trin\u00b7ker", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADJA", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.16": {"line.1": {"text": "Aber, wie betaur' ich dich,", "tokens": ["A\u00b7ber", ",", "wie", "be\u00b7taur'", "ich", "dich", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "PWAV", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Da\u00df du nur mu\u00dft Wasser trinken.", "tokens": ["Da\u00df", "du", "nur", "mu\u00dft", "Was\u00b7ser", "trin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VMFIN", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Und wie gl\u00fccklich sch\u00e4tz' ich mich,", "tokens": ["Und", "wie", "gl\u00fcck\u00b7lich", "sch\u00e4tz'", "ich", "mich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "ADJD", "VVFIN", "PPER", "PRF", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Wenn mir Weine daf\u00fcr blinken!", "tokens": ["Wenn", "mir", "Wei\u00b7ne", "da\u00b7f\u00fcr", "blin\u00b7ken", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "PAV", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.17": {"line.1": {"text": "Armes Tier, ergib dich drein.", "tokens": ["Ar\u00b7mes", "Tier", ",", "er\u00b7gib", "dich", "drein", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJA", "NN", "$,", "VVIMP", "PPER", "PTKVZ", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "La\u00df dich nicht den Neid verf\u00fchren.", "tokens": ["La\u00df", "dich", "nicht", "den", "Neid", "ver\u00b7f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "PTKNEG", "ART", "NN", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Denn des Weins Gebrauch allein", "tokens": ["Denn", "des", "Weins", "Ge\u00b7brauch", "al\u00b7lein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ART", "NN", "NN", "ADV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "Unterscheidet uns von Tieren.", "tokens": ["Un\u00b7ter\u00b7schei\u00b7det", "uns", "von", "Tie\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.18": {"line.1": {"text": "In der Welt mu\u00df Ordnung sein.", "tokens": ["In", "der", "Welt", "mu\u00df", "Ord\u00b7nung", "sein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VMFIN", "NN", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Menschen sind von edlern Gaben.", "tokens": ["Men\u00b7schen", "sind", "von", "ed\u00b7lern", "Ga\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "APPR", "ADJA", "NN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.3": {"text": "Du trinkst Wasser, und ich Wein;", "tokens": ["Du", "trinkst", "Was\u00b7ser", ",", "und", "ich", "Wein", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "NN", "$,", "KON", "PPER", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.4": {"text": "So will es die Ordnung haben.", "tokens": ["So", "will", "es", "die", "Ord\u00b7nung", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "ART", "NN", "VAFIN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}}}}