{"dta.poem.19743": {"metadata": {"author": {"name": "Brentano, Clemens", "birth": "N.A.", "death": "N.A."}, "title": "Rosenkranz  \n Tritt an den Tanz .", "genre": "Lyrik", "period": "N.A.", "pub_year": "1808", "urn": "urn:nbn:de:kobv:b4-20090519168", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Es starben zwey Schwestern an einem Tag,               ", "tokens": ["Es", "star\u00b7ben", "zwey", "Schwes\u00b7tern", "an", "ei\u00b7nem", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "CARD", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Sie wurden an einem Tag begraben.", "tokens": ["Sie", "wur\u00b7den", "an", "ei\u00b7nem", "Tag", "be\u00b7gra\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "VVPP", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "Und als sie kamen vors himmlische Thor,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "vors", "himm\u00b7li\u00b7sche", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sanct Petrus sprach: Wer ist davor", "tokens": ["Sanct", "Pet\u00b7rus", "sprach", ":", "Wer", "ist", "da\u00b7vor"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["VVFIN", "FM", "VVFIN", "$.", "PWS", "VAFIN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Es sind davor zwey arme Seelen,", "tokens": ["Es", "sind", "da\u00b7vor", "zwey", "ar\u00b7me", "See\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Sie m\u00f6chten gern bei Gott einkehren.", "tokens": ["Sie", "m\u00f6ch\u00b7ten", "gern", "bei", "Gott", "ein\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Die erste die soll zu ihm gehn,", "tokens": ["Die", "ers\u00b7te", "die", "soll", "zu", "ihm", "gehn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "ART", "VMFIN", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die zweyte soll den breiten Weg gehn.", "tokens": ["Die", "zwey\u00b7te", "soll", "den", "brei\u00b7ten", "Weg", "gehn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Der breite Weg gar b\u00f6se steht,", "tokens": ["Der", "brei\u00b7te", "Weg", "gar", "b\u00f6\u00b7se", "steht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Der zu der leidigen H\u00f6ll eingeht.", "tokens": ["Der", "zu", "der", "lei\u00b7di\u00b7gen", "H\u00f6ll", "ein\u00b7geht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}}, "stanza.6": {"line.1": {"text": "Und da sie den breiten Weg auffe kam,", "tokens": ["Und", "da", "sie", "den", "brei\u00b7ten", "Weg", "auf\u00b7fe", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "ADJA", "NN", "VVFIN", "VVFIN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.2": {"text": "Begegnet ihr die heilige Frau.", "tokens": ["Be\u00b7geg\u00b7net", "ihr", "die", "hei\u00b7li\u00b7ge", "Frau", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}}, "stanza.7": {"line.1": {"text": "Wo'naus, wohin du arme Seele,", "tokens": ["Wo'\u00b7naus", ",", "wo\u00b7hin", "du", "ar\u00b7me", "See\u00b7le", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PWAV", "PPER", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir wollen jetzt bei Gott einkehren?", "tokens": ["Wir", "wol\u00b7len", "jetzt", "bei", "Gott", "ein\u00b7keh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Ich hab ja schon bei Gott eingekehrt,", "tokens": ["Ich", "hab", "ja", "schon", "bei", "Gott", "ein\u00b7ge\u00b7kehrt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Er hat mir hinausgewehrt.", "tokens": ["Er", "hat", "mir", "hin\u00b7aus\u00b7ge\u00b7wehrt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVPP", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}}, "stanza.9": {"line.1": {"text": "Was hast du dann f\u00fcr S\u00fcnd gethan,", "tokens": ["Was", "hast", "du", "dann", "f\u00fcr", "S\u00fcnd", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "PPER", "ADV", "APPR", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df du nicht darfst in Himmel gahn?", "tokens": ["Da\u00df", "du", "nicht", "darfst", "in", "Him\u00b7mel", "gahn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKNEG", "PAV", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Ich hab ja alle Samstag Nacht,", "tokens": ["Ich", "hab", "ja", "al\u00b7le", "Sams\u00b7tag", "Nacht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Rosen Kr\u00e4nzlein 'naus gemacht.", "tokens": ["Ein", "Ro\u00b7sen", "Kr\u00e4nz\u00b7lein", "'naus", "ge\u00b7macht", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.11": {"line.1": {"text": "Hast du sonst keine S\u00fcnd gethan,", "tokens": ["Hast", "du", "sonst", "kei\u00b7ne", "S\u00fcnd", "ge\u00b7than", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIAT", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Darfst du mit mir in Himmel gahn.", "tokens": ["Darfst", "du", "mit", "mir", "in", "Him\u00b7mel", "gahn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "APPR", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Und als sie kamen vors himmlische Thor,", "tokens": ["Und", "als", "sie", "ka\u00b7men", "vors", "himm\u00b7li\u00b7sche", "Thor", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "VVFIN", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Sanct Petrus sprach: Wer ist davor?", "tokens": ["Sanct", "Pet\u00b7rus", "sprach", ":", "Wer", "ist", "da\u00b7vor", "?"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "FM", "VVFIN", "$.", "PWS", "VAFIN", "PAV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "Es ist davor eine arme Seele,", "tokens": ["Es", "ist", "da\u00b7vor", "ei\u00b7ne", "ar\u00b7me", "See\u00b7le", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PAV", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.2": {"text": "Sie m\u00f6chte gern bei Gott einkehren.", "tokens": ["Sie", "m\u00f6ch\u00b7te", "gern", "bei", "Gott", "ein\u00b7keh\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Maria nahm sie bei der Hand,", "tokens": ["Ma\u00b7ria", "nahm", "sie", "bei", "der", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VVFIN", "PPER", "APPR", "ART", "NN", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Und f\u00fchrt sie ins gelobte Land.", "tokens": ["Und", "f\u00fchrt", "sie", "ins", "ge\u00b7lob\u00b7te", "Land", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.15": {"line.1": {"text": "Da ward ihr gleich ein Stuhl bereit't,", "tokens": ["Da", "ward", "ihr", "gleich", "ein", "Stuhl", "be\u00b7reit't", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von nun an bis in Ewigkeit.", "tokens": ["Von", "nun", "an", "bis", "in", "E\u00b7wig\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APPR", "KON", "APPR", "NN", "$."], "meter": "--+--+-+", "measure": "anapaest.di.plus"}}}}}