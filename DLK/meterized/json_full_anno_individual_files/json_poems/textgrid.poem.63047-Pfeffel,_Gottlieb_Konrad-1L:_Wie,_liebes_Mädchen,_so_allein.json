{"textgrid.poem.63047": {"metadata": {"author": {"name": "Pfeffel, Gottlieb Konrad", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wie, liebes M\u00e4dchen, so allein", "genre": "verse", "period": "N.A.", "pub_year": 1786, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wie, liebes M\u00e4dchen, so allein", "tokens": ["Wie", ",", "lie\u00b7bes", "M\u00e4d\u00b7chen", ",", "so", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "ADJA", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Versenkt in stille Klage!", "tokens": ["Ver\u00b7senkt", "in", "stil\u00b7le", "Kla\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was f\u00fchrt dich in den \u00f6den Hayn", "tokens": ["Was", "f\u00fchrt", "dich", "in", "den", "\u00f6\u00b7den", "Hayn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An Gottes Feyertage?", "tokens": ["An", "Got\u00b7tes", "Fe\u00b7yer\u00b7ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "O, fragt nicht, guter Pilgersmann!", "tokens": ["O", ",", "fragt", "nicht", ",", "gu\u00b7ter", "Pil\u00b7gers\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fragt nicht, warum ich weine,", "tokens": ["Fragt", "nicht", ",", "wa\u00b7rum", "ich", "wei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier nehmt ein kleines Opfer an,", "tokens": ["Hier", "nehmt", "ein", "klei\u00b7nes", "Op\u00b7fer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lasset mich alleine.", "tokens": ["Und", "las\u00b7set", "mich", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Nein, Kind, ich nehme nichts von dir,", "tokens": ["Nein", ",", "Kind", ",", "ich", "neh\u00b7me", "nichts", "von", "dir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PPER", "VVFIN", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch will ich dich nicht qu\u00e4len:", "tokens": ["Auch", "will", "ich", "dich", "nicht", "qu\u00e4\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein, bey Gott! du solltest mir", "tokens": ["Al\u00b7lein", ",", "bey", "Gott", "!", "du", "soll\u00b7test", "mir"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "NN", "$.", "PPER", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Leiden nicht verhehlen.", "tokens": ["Dein", "Lei\u00b7den", "nicht", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was seh ich? Alter! \u2013 wie? mein Schmerz", "tokens": ["Was", "seh", "ich", "?", "Al\u00b7ter", "!", "\u2013", "wie", "?", "mein", "Schmerz"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "NN", "$.", "$(", "PWAV", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entlockt euch stille Z\u00e4hren?", "tokens": ["Ent\u00b7lockt", "euch", "stil\u00b7le", "Z\u00e4h\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "O, Heil dir, Mann, du hast ein Herz;", "tokens": ["O", ",", "Heil", "dir", ",", "Mann", ",", "du", "hast", "ein", "Herz", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "PPER", "$,", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du sollst mein Ungl\u00fcck h\u00f6ren:", "tokens": ["Du", "sollst", "mein", "Un\u00b7gl\u00fcck", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ich liebte: sch\u00f6n war Leonhard,", "tokens": ["Ich", "lieb\u00b7te", ":", "sch\u00f6n", "war", "Le\u00b7on\u00b7hard", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADJD", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein F\u00fcrst von Wuchs und Gange,", "tokens": ["Ein", "F\u00fcrst", "von", "Wuchs", "und", "Gan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Stark wie ein Baum, und dennoch zart,", "tokens": ["Stark", "wie", "ein", "Baum", ",", "und", "den\u00b7noch", "zart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,", "KON", "ADV", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und wei\u00df und roth von Wange.", "tokens": ["Und", "wei\u00df", "und", "roth", "von", "Wan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "So war er \u2013 und sein Herz dabey", "tokens": ["So", "war", "er", "\u2013", "und", "sein", "Herz", "da\u00b7bey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$(", "KON", "PPOSAT", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So gut, so ganz mein eigen:", "tokens": ["So", "gut", ",", "so", "ganz", "mein", "ei\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So ganz .... o, lieber Greis! verzeih,", "tokens": ["So", "ganz", "....", "o", ",", "lie\u00b7ber", "Greis", "!", "ver\u00b7zeih", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$.", "FM", "$,", "ADV", "NN", "$.", "VVIMP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich mu\u00df ein wenig schweigen.", "tokens": ["Ich", "mu\u00df", "ein", "we\u00b7nig", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Schweig, Kind. \u2013 O m\u00f6chte deinen Gram", "tokens": ["Schweig", ",", "Kind", ".", "\u2013", "O", "m\u00f6ch\u00b7te", "dei\u00b7nen", "Gram"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$.", "$(", "NE", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Mitleid dir vers\u00fc\u00dfen!", "tokens": ["Mein", "Mit\u00b7leid", "dir", "ver\u00b7s\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mir ahnet schon, dein Br\u00e4utigam", "tokens": ["Mir", "ah\u00b7net", "schon", ",", "dein", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ward dir vom Arm gerissen.", "tokens": ["Ward", "dir", "vom", "Arm", "ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Ja wohl! hier, wo wir uns entz\u00fcckt", "tokens": ["Ja", "wohl", "!", "hier", ",", "wo", "wir", "uns", "ent\u00b7z\u00fcckt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$.", "ADV", "$,", "PWAV", "PPER", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An jedem Abend fanden;", "tokens": ["An", "je\u00b7dem", "A\u00b7bend", "fan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ward er von Werbern mir entr\u00fcckt,", "tokens": ["Ward", "er", "von", "Wer\u00b7bern", "mir", "ent\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott wei\u00df aus welchen Landen.", "tokens": ["Gott", "wei\u00df", "aus", "wel\u00b7chen", "Lan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Nun sieht der zweite Lenz mich hier", "tokens": ["Nun", "sieht", "der", "zwei\u00b7te", "Lenz", "mich", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm jeden Sonntag weinen;", "tokens": ["Ihm", "je\u00b7den", "Sonn\u00b7tag", "wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn todt ist er. Ach wehe mir!", "tokens": ["Denn", "todt", "ist", "er", ".", "Ach", "we\u00b7he", "mir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "$.", "ITJ", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann wird uns Gott vereinen?...", "tokens": ["Wann", "wird", "uns", "Gott", "ver\u00b7ei\u00b7nen", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Heut, Gretchen, heut! Dein Leonhard", "tokens": ["Heut", ",", "Gret\u00b7chen", ",", "heut", "!", "Dein", "Le\u00b7on\u00b7hard"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "NE", "$,", "ADV", "$.", "PPOSAT", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist hier! er ist erstanden.", "tokens": ["Ist", "hier", "!", "er", "ist", "er\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Pilgerkleid, ein falscher Bart", "tokens": ["Ein", "Pil\u00b7ger\u00b7kleid", ",", "ein", "fal\u00b7scher", "Bart"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Half ihm aus seinen Banden.", "tokens": ["Half", "ihm", "aus", "sei\u00b7nen", "Ban\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Er ists! ein Wonnestrom zerrei\u00dft", "tokens": ["Er", "ists", "!", "ein", "Won\u00b7nes\u00b7trom", "zer\u00b7rei\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Herz .... ich kann nicht reden \u2013", "tokens": ["Mein", "Herz", "....", "ich", "kann", "nicht", "re\u00b7den", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ach, Liebster! Halte meinen Geist;", "tokens": ["Ach", ",", "Liebs\u00b7ter", "!", "Hal\u00b7te", "mei\u00b7nen", "Geist", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst wird mein Gl\u00fcck mich t\u00f6dten.", "tokens": ["Sonst", "wird", "mein", "Gl\u00fcck", "mich", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Wie, liebes M\u00e4dchen, so allein", "tokens": ["Wie", ",", "lie\u00b7bes", "M\u00e4d\u00b7chen", ",", "so", "al\u00b7lein"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word"], "pos": ["PWAV", "$,", "ADJA", "NN", "$,", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Versenkt in stille Klage!", "tokens": ["Ver\u00b7senkt", "in", "stil\u00b7le", "Kla\u00b7ge", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Was f\u00fchrt dich in den \u00f6den Hayn", "tokens": ["Was", "f\u00fchrt", "dich", "in", "den", "\u00f6\u00b7den", "Hayn"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PRF", "APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "An Gottes Feyertage?", "tokens": ["An", "Got\u00b7tes", "Fe\u00b7yer\u00b7ta\u00b7ge", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "O, fragt nicht, guter Pilgersmann!", "tokens": ["O", ",", "fragt", "nicht", ",", "gu\u00b7ter", "Pil\u00b7gers\u00b7mann", "!"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["NE", "$,", "VVFIN", "PTKNEG", "$,", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fragt nicht, warum ich weine,", "tokens": ["Fragt", "nicht", ",", "wa\u00b7rum", "ich", "wei\u00b7ne", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "$,", "PWAV", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Hier nehmt ein kleines Opfer an,", "tokens": ["Hier", "nehmt", "ein", "klei\u00b7nes", "Op\u00b7fer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und lasset mich alleine.", "tokens": ["Und", "las\u00b7set", "mich", "al\u00b7lei\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Nein, Kind, ich nehme nichts von dir,", "tokens": ["Nein", ",", "Kind", ",", "ich", "neh\u00b7me", "nichts", "von", "dir", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "NN", "$,", "PPER", "VVFIN", "PIS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Auch will ich dich nicht qu\u00e4len:", "tokens": ["Auch", "will", "ich", "dich", "nicht", "qu\u00e4\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Allein, bey Gott! du solltest mir", "tokens": ["Al\u00b7lein", ",", "bey", "Gott", "!", "du", "soll\u00b7test", "mir"], "token_info": ["word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "$,", "APPR", "NN", "$.", "PPER", "VMFIN", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Dein Leiden nicht verhehlen.", "tokens": ["Dein", "Lei\u00b7den", "nicht", "ver\u00b7heh\u00b7len", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Was seh ich? Alter! \u2013 wie? mein Schmerz", "tokens": ["Was", "seh", "ich", "?", "Al\u00b7ter", "!", "\u2013", "wie", "?", "mein", "Schmerz"], "token_info": ["word", "word", "word", "punct", "word", "punct", "punct", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "$.", "NN", "$.", "$(", "PWAV", "$.", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Entlockt euch stille Z\u00e4hren?", "tokens": ["Ent\u00b7lockt", "euch", "stil\u00b7le", "Z\u00e4h\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "O, Heil dir, Mann, du hast ein Herz;", "tokens": ["O", ",", "Heil", "dir", ",", "Mann", ",", "du", "hast", "ein", "Herz", ";"], "token_info": ["word", "punct", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "PPER", "$,", "NN", "$,", "PPER", "VAFIN", "ART", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Du sollst mein Ungl\u00fcck h\u00f6ren:", "tokens": ["Du", "sollst", "mein", "Un\u00b7gl\u00fcck", "h\u00f6\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Ich liebte: sch\u00f6n war Leonhard,", "tokens": ["Ich", "lieb\u00b7te", ":", "sch\u00f6n", "war", "Le\u00b7on\u00b7hard", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "ADJD", "VAFIN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein F\u00fcrst von Wuchs und Gange,", "tokens": ["Ein", "F\u00fcrst", "von", "Wuchs", "und", "Gan\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Stark wie ein Baum, und dennoch zart,", "tokens": ["Stark", "wie", "ein", "Baum", ",", "und", "den\u00b7noch", "zart", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADJD", "KOKOM", "ART", "NN", "$,", "KON", "ADV", "ADJD", "$,"], "meter": "+--+-+-+", "measure": "iambic.tetra.invert"}, "line.4": {"text": "Und wei\u00df und roth von Wange.", "tokens": ["Und", "wei\u00df", "und", "roth", "von", "Wan\u00b7ge", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "KON", "ADJD", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "So war er \u2013 und sein Herz dabey", "tokens": ["So", "war", "er", "\u2013", "und", "sein", "Herz", "da\u00b7bey"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PPER", "$(", "KON", "PPOSAT", "NN", "PAV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So gut, so ganz mein eigen:", "tokens": ["So", "gut", ",", "so", "ganz", "mein", "ei\u00b7gen", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "$,", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "So ganz .... o, lieber Greis! verzeih,", "tokens": ["So", "ganz", "....", "o", ",", "lie\u00b7ber", "Greis", "!", "ver\u00b7zeih", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ADV", "ADV", "$.", "FM", "$,", "ADV", "NN", "$.", "VVIMP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ich mu\u00df ein wenig schweigen.", "tokens": ["Ich", "mu\u00df", "ein", "we\u00b7nig", "schwei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "PIS", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Schweig, Kind. \u2013 O m\u00f6chte deinen Gram", "tokens": ["Schweig", ",", "Kind", ".", "\u2013", "O", "m\u00f6ch\u00b7te", "dei\u00b7nen", "Gram"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["VVFIN", "$,", "NN", "$.", "$(", "NE", "VMFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Mitleid dir vers\u00fc\u00dfen!", "tokens": ["Mein", "Mit\u00b7leid", "dir", "ver\u00b7s\u00fc\u00b7\u00dfen", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Mir ahnet schon, dein Br\u00e4utigam", "tokens": ["Mir", "ah\u00b7net", "schon", ",", "dein", "Br\u00e4u\u00b7ti\u00b7gam"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ward dir vom Arm gerissen.", "tokens": ["Ward", "dir", "vom", "Arm", "ge\u00b7ris\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Ja wohl! hier, wo wir uns entz\u00fcckt", "tokens": ["Ja", "wohl", "!", "hier", ",", "wo", "wir", "uns", "ent\u00b7z\u00fcckt"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word"], "pos": ["PTKANT", "ADV", "$.", "ADV", "$,", "PWAV", "PPER", "PPER", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "An jedem Abend fanden;", "tokens": ["An", "je\u00b7dem", "A\u00b7bend", "fan\u00b7den", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ward er von Werbern mir entr\u00fcckt,", "tokens": ["Ward", "er", "von", "Wer\u00b7bern", "mir", "ent\u00b7r\u00fcckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "APPR", "NN", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Gott wei\u00df aus welchen Landen.", "tokens": ["Gott", "wei\u00df", "aus", "wel\u00b7chen", "Lan\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "APPR", "PWAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Nun sieht der zweite Lenz mich hier", "tokens": ["Nun", "sieht", "der", "zwei\u00b7te", "Lenz", "mich", "hier"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihm jeden Sonntag weinen;", "tokens": ["Ihm", "je\u00b7den", "Sonn\u00b7tag", "wei\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "PIAT", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Denn todt ist er. Ach wehe mir!", "tokens": ["Denn", "todt", "ist", "er", ".", "Ach", "we\u00b7he", "mir", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VAFIN", "PPER", "$.", "ITJ", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Wann wird uns Gott vereinen?...", "tokens": ["Wann", "wird", "uns", "Gott", "ver\u00b7ei\u00b7nen", "?", "..."], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PWAV", "VAFIN", "PPER", "NN", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Heut, Gretchen, heut! Dein Leonhard", "tokens": ["Heut", ",", "Gret\u00b7chen", ",", "heut", "!", "Dein", "Le\u00b7on\u00b7hard"], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word"], "pos": ["ADV", "$,", "NE", "$,", "ADV", "$.", "PPOSAT", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ist hier! er ist erstanden.", "tokens": ["Ist", "hier", "!", "er", "ist", "er\u00b7stan\u00b7den", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "$.", "PPER", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ein Pilgerkleid, ein falscher Bart", "tokens": ["Ein", "Pil\u00b7ger\u00b7kleid", ",", "ein", "fal\u00b7scher", "Bart"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["ART", "NN", "$,", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Half ihm aus seinen Banden.", "tokens": ["Half", "ihm", "aus", "sei\u00b7nen", "Ban\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.22": {"line.1": {"text": "Er ists! ein Wonnestrom zerrei\u00dft", "tokens": ["Er", "ists", "!", "ein", "Won\u00b7nes\u00b7trom", "zer\u00b7rei\u00dft"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VAFIN", "$.", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mein Herz .... ich kann nicht reden \u2013", "tokens": ["Mein", "Herz", "....", "ich", "kann", "nicht", "re\u00b7den", "\u2013"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "VMFIN", "PTKNEG", "VVINF", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Ach, Liebster! Halte meinen Geist;", "tokens": ["Ach", ",", "Liebs\u00b7ter", "!", "Hal\u00b7te", "mei\u00b7nen", "Geist", ";"], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["ITJ", "$,", "NN", "$.", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Sonst wird mein Gl\u00fcck mich t\u00f6dten.", "tokens": ["Sonst", "wird", "mein", "Gl\u00fcck", "mich", "t\u00f6d\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPOSAT", "NN", "PPER", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}