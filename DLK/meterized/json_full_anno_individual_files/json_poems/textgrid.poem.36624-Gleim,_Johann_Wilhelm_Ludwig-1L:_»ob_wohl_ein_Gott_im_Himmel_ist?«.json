{"textgrid.poem.36624": {"metadata": {"author": {"name": "Gleim, Johann Wilhelm Ludwig", "birth": "N.A.", "death": "N.A."}, "title": "1L: \u00bbob wohl ein Gott im Himmel ist?\u00ab", "genre": "verse", "period": "N.A.", "pub_year": 1761, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "\u00bbob wohl ein Gott im Himmel ist?\u00ab", "tokens": ["\u00bb", "ob", "wohl", "ein", "Gott", "im", "Him\u00b7mel", "ist", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dacht' ich in meinem Zelt;", "tokens": ["Dacht'", "ich", "in", "mei\u00b7nem", "Zelt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbkrieg hat der T\u00fcrke, hat der Christ,", "tokens": ["\u00bb", "krieg", "hat", "der", "T\u00fcr\u00b7ke", ",", "hat", "der", "Christ", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Krieg hat die ganze Welt!", "tokens": ["Krieg", "hat", "die", "gan\u00b7ze", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Und w\u00e4r ein Gott, so m\u00fc\u00dft' er wohl", "tokens": ["Und", "w\u00e4r", "ein", "Gott", ",", "so", "m\u00fc\u00dft'", "er", "wohl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Gott des Friedens seyn!", "tokens": ["Ein", "Gott", "des", "Frie\u00b7dens", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df all' das B\u00f6se gut seyn soll,", "tokens": ["Da\u00df", "all'", "das", "B\u00f6\u00b7se", "gut", "seyn", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADJD", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das will mir gar nicht ein!", "tokens": ["Das", "will", "mir", "gar", "nicht", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Darum so scheints, es ist kein Gott;", "tokens": ["Da\u00b7rum", "so", "scheints", ",", "es", "ist", "kein", "Gott", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Gott h\u00e4tt' alle Macht,", "tokens": ["Ein", "Gott", "h\u00e4tt'", "al\u00b7le", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu tilgen aller Sp\u00f6tter Spott,", "tokens": ["Zu", "til\u00b7gen", "al\u00b7ler", "Sp\u00f6t\u00b7ter", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aller F\u00fcrsten Schlacht!", "tokens": ["Und", "al\u00b7ler", "F\u00fcrs\u00b7ten", "Schlacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Was ists, da\u00df er sie nicht gebraucht?", "tokens": ["Was", "ists", ",", "da\u00df", "er", "sie", "nicht", "ge\u00b7braucht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "KOUS", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Frieden nicht gebeut?", "tokens": ["Den", "Frie\u00b7den", "nicht", "ge\u00b7beut", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und da\u00df noch manche St\u00e4te raucht,", "tokens": ["Und", "da\u00df", "noch", "man\u00b7che", "St\u00e4\u00b7te", "raucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Kriegesgrausamkeit?", "tokens": ["Von", "Krie\u00b7ges\u00b7grau\u00b7sam\u00b7keit", "?"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "Ein Wort, d\u00e4cht' ich, so w\u00e4r' in Ruh", "tokens": ["Ein", "Wort", ",", "d\u00e4cht'", "ich", ",", "so", "w\u00e4r'", "in", "Ruh"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ganze Erdenrund!\u00ab", "tokens": ["Das", "gan\u00b7ze", "Er\u00b7den\u00b7rund", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdu Maulwurf!\u00ab dacht ich gleich hinzu", "tokens": ["\u00bb", "du", "Maul\u00b7wurf", "!", "\u00ab", "dacht", "ich", "gleich", "hin\u00b7zu"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "NN", "$.", "$(", "VVFIN", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich schlagend auf den Mund!", "tokens": ["Mich", "schla\u00b7gend", "auf", "den", "Mund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "Das Erdenrund ist nun einmal", "tokens": ["Das", "Er\u00b7den\u00b7rund", "ist", "nun", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des B\u00f6sen Vaterland,", "tokens": ["Des", "B\u00f6\u00b7sen", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wird aber einst ein Wonnethal", "tokens": ["Wird", "a\u00b7ber", "einst", "ein", "Won\u00b7net\u00b7hal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In seines Sch\u00f6pfers Hand!", "tokens": ["In", "sei\u00b7nes", "Sch\u00f6p\u00b7fers", "Hand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "So dacht' ich! Und so denk' ich noch,", "tokens": ["So", "dacht'", "ich", "!", "Und", "so", "denk'", "ich", "noch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KON", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gehe meinen Pfad!", "tokens": ["Und", "ge\u00b7he", "mei\u00b7nen", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bin, denk' ich einsam, bin ich doch", "tokens": ["Bin", ",", "denk'", "ich", "ein\u00b7sam", ",", "bin", "ich", "doch"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ehrlicher Soldat!", "tokens": ["Ein", "ehr\u00b7li\u00b7cher", "Sol\u00b7dat", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Als solcher komm' ich doch einmal", "tokens": ["Als", "sol\u00b7cher", "komm'", "ich", "doch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dieser kurzen Zeit,", "tokens": ["Nach", "die\u00b7ser", "kur\u00b7zen", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu Gott dem Herrn ins Wonnethal", "tokens": ["Zu", "Gott", "dem", "Herrn", "ins", "Won\u00b7net\u00b7hal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der langen Ewigkeit!", "tokens": ["Der", "lan\u00b7gen", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und sing' auf einem sch\u00f6nen Stern,", "tokens": ["Und", "sing'", "auf", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein ehrlicher Soldat,", "tokens": ["Ein", "ehr\u00b7li\u00b7cher", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Loblied meinem Gott und Herrn,", "tokens": ["Ein", "Lob\u00b7lied", "mei\u00b7nem", "Gott", "und", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das sich gewaschen hat!", "tokens": ["Das", "sich", "ge\u00b7wa\u00b7schen", "hat", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "\u00bbob wohl ein Gott im Himmel ist?\u00ab", "tokens": ["\u00bb", "ob", "wohl", "ein", "Gott", "im", "Him\u00b7mel", "ist", "?", "\u00ab"], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["$(", "KOUS", "ADV", "ART", "NN", "APPRART", "NN", "VAFIN", "$.", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Dacht' ich in meinem Zelt;", "tokens": ["Dacht'", "ich", "in", "mei\u00b7nem", "Zelt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbkrieg hat der T\u00fcrke, hat der Christ,", "tokens": ["\u00bb", "krieg", "hat", "der", "T\u00fcr\u00b7ke", ",", "hat", "der", "Christ", ","], "token_info": ["punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["$(", "NN", "VAFIN", "ART", "NN", "$,", "VAFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Krieg hat die ganze Welt!", "tokens": ["Krieg", "hat", "die", "gan\u00b7ze", "Welt", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VAFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Und w\u00e4r ein Gott, so m\u00fc\u00dft' er wohl", "tokens": ["Und", "w\u00e4r", "ein", "Gott", ",", "so", "m\u00fc\u00dft'", "er", "wohl"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VAFIN", "ART", "NN", "$,", "ADV", "VMFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Gott des Friedens seyn!", "tokens": ["Ein", "Gott", "des", "Frie\u00b7dens", "seyn", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Da\u00df all' das B\u00f6se gut seyn soll,", "tokens": ["Da\u00df", "all'", "das", "B\u00f6\u00b7se", "gut", "seyn", "soll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ART", "NN", "ADJD", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das will mir gar nicht ein!", "tokens": ["Das", "will", "mir", "gar", "nicht", "ein", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "PTKNEG", "PTKVZ", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Darum so scheints, es ist kein Gott;", "tokens": ["Da\u00b7rum", "so", "scheints", ",", "es", "ist", "kein", "Gott", ";"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "$,", "PPER", "VAFIN", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein Gott h\u00e4tt' alle Macht,", "tokens": ["Ein", "Gott", "h\u00e4tt'", "al\u00b7le", "Macht", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu tilgen aller Sp\u00f6tter Spott,", "tokens": ["Zu", "til\u00b7gen", "al\u00b7ler", "Sp\u00f6t\u00b7ter", "Spott", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKZU", "VVINF", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Und aller F\u00fcrsten Schlacht!", "tokens": ["Und", "al\u00b7ler", "F\u00fcrs\u00b7ten", "Schlacht", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Was ists, da\u00df er sie nicht gebraucht?", "tokens": ["Was", "ists", ",", "da\u00df", "er", "sie", "nicht", "ge\u00b7braucht", "?"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "$,", "KOUS", "PPER", "PPER", "PTKNEG", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den Frieden nicht gebeut?", "tokens": ["Den", "Frie\u00b7den", "nicht", "ge\u00b7beut", "?"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Und da\u00df noch manche St\u00e4te raucht,", "tokens": ["Und", "da\u00df", "noch", "man\u00b7che", "St\u00e4\u00b7te", "raucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ADV", "PIAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Von Kriegesgrausamkeit?", "tokens": ["Von", "Krie\u00b7ges\u00b7grau\u00b7sam\u00b7keit", "?"], "token_info": ["word", "word", "punct"], "pos": ["APPR", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Ein Wort, d\u00e4cht' ich, so w\u00e4r' in Ruh", "tokens": ["Ein", "Wort", ",", "d\u00e4cht'", "ich", ",", "so", "w\u00e4r'", "in", "Ruh"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "VVFIN", "PPER", "$,", "ADV", "VAFIN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das ganze Erdenrund!\u00ab", "tokens": ["Das", "gan\u00b7ze", "Er\u00b7den\u00b7rund", "!", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "\u00bbdu Maulwurf!\u00ab dacht ich gleich hinzu", "tokens": ["\u00bb", "du", "Maul\u00b7wurf", "!", "\u00ab", "dacht", "ich", "gleich", "hin\u00b7zu"], "token_info": ["punct", "word", "word", "punct", "punct", "word", "word", "word", "word"], "pos": ["$(", "PPER", "NN", "$.", "$(", "VVFIN", "PPER", "ADV", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Mich schlagend auf den Mund!", "tokens": ["Mich", "schla\u00b7gend", "auf", "den", "Mund", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Das Erdenrund ist nun einmal", "tokens": ["Das", "Er\u00b7den\u00b7rund", "ist", "nun", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Des B\u00f6sen Vaterland,", "tokens": ["Des", "B\u00f6\u00b7sen", "Va\u00b7ter\u00b7land", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Wird aber einst ein Wonnethal", "tokens": ["Wird", "a\u00b7ber", "einst", "ein", "Won\u00b7net\u00b7hal"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "ADV", "ADV", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "In seines Sch\u00f6pfers Hand!", "tokens": ["In", "sei\u00b7nes", "Sch\u00f6p\u00b7fers", "Hand", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "So dacht' ich! Und so denk' ich noch,", "tokens": ["So", "dacht'", "ich", "!", "Und", "so", "denk'", "ich", "noch", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$.", "KON", "ADV", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und gehe meinen Pfad!", "tokens": ["Und", "ge\u00b7he", "mei\u00b7nen", "Pfad", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Bin, denk' ich einsam, bin ich doch", "tokens": ["Bin", ",", "denk'", "ich", "ein\u00b7sam", ",", "bin", "ich", "doch"], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["VAFIN", "$,", "VVFIN", "PPER", "ADJD", "$,", "VAFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Ein ehrlicher Soldat!", "tokens": ["Ein", "ehr\u00b7li\u00b7cher", "Sol\u00b7dat", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.17": {"line.1": {"text": "Als solcher komm' ich doch einmal", "tokens": ["Als", "sol\u00b7cher", "komm'", "ich", "doch", "ein\u00b7mal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "VVFIN", "PPER", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nach dieser kurzen Zeit,", "tokens": ["Nach", "die\u00b7ser", "kur\u00b7zen", "Zeit", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PDAT", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Zu Gott dem Herrn ins Wonnethal", "tokens": ["Zu", "Gott", "dem", "Herrn", "ins", "Won\u00b7net\u00b7hal"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "NN", "ART", "NN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Der langen Ewigkeit!", "tokens": ["Der", "lan\u00b7gen", "E\u00b7wig\u00b7keit", "!"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Und sing' auf einem sch\u00f6nen Stern,", "tokens": ["Und", "sing'", "auf", "ei\u00b7nem", "sch\u00f6\u00b7nen", "Stern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ein ehrlicher Soldat,", "tokens": ["Ein", "ehr\u00b7li\u00b7cher", "Sol\u00b7dat", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Ein Loblied meinem Gott und Herrn,", "tokens": ["Ein", "Lob\u00b7lied", "mei\u00b7nem", "Gott", "und", "Herrn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Das sich gewaschen hat!", "tokens": ["Das", "sich", "ge\u00b7wa\u00b7schen", "hat", "!"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PDS", "PRF", "VVPP", "VAFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}}}}}