{"dta.poem.9251": {"metadata": {"author": {"name": "Weise, Christian", "birth": "N.A.", "death": "N.A."}, "title": "Die vierdte Handlung.", "genre": "Lyrik; Drama; Prosa", "period": "N.A.", "pub_year": "1701", "urn": "urn:nbn:de:kobv:b4-25043-0", "language": ["de:0.99"], "booktitle": "Weise, Christian: \u00dcberfl\u00fc\u00dfige Gedancken Der gr\u00fcnenden jugend. Leipzig, 1701."}, "poem": {"stanza.1": {"line.1": {"text": "Wer sich wil entfernen", "tokens": ["Wer", "sich", "wil", "ent\u00b7fer\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["PWS", "PRF", "VMFIN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.2": {"text": "Weit von aller noth und pein/", "tokens": ["Weit", "von", "al\u00b7ler", "noth", "und", "pein", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PIAT", "NN", "KON", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Mu\u00df mein handwerck lernen", "tokens": ["Mu\u00df", "mein", "hand\u00b7werck", "ler\u00b7nen"], "token_info": ["word", "word", "word", "word"], "pos": ["VMFIN", "PPOSAT", "NN", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und mit mir ein h\u00e4scher seyn.", "tokens": ["Und", "mit", "mir", "ein", "h\u00e4\u00b7scher", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPER", "ART", "ADJD", "VAINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Dieses ist ein k\u00f6stlich leben", "tokens": ["Die\u00b7ses", "ist", "ein", "k\u00f6st\u00b7lich", "le\u00b7ben"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PDS", "VAFIN", "ART", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Voller herrlichkeit/", "tokens": ["Vol\u00b7ler", "herr\u00b7lich\u00b7keit", "/"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und die sich darein begeben/", "tokens": ["Und", "die", "sich", "da\u00b7rein", "be\u00b7ge\u00b7ben", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "PRF", "PAV", "VVPP", "$("], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Hats noch nie gereut.", "tokens": ["Hats", "noch", "nie", "ge\u00b7reut", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADV", "ADV", "VVPP", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.2": {"line.1": {"text": "2. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Nun so giebt es auch daf\u00fcr", "tokens": ["Nun", "so", "giebt", "es", "auch", "da\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "ADV", "PAV"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Wiederumb zu sauffen", "tokens": ["Wie\u00b7de\u00b7rumb", "zu", "sauf\u00b7fen"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Manches liebes k\u00e4nngen bier.", "tokens": ["Man\u00b7ches", "lie\u00b7bes", "k\u00e4nn\u00b7gen", "bier", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIAT", "ADJA", "ADJA", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und so lang es in der woche", "tokens": ["Und", "so", "lang", "es", "in", "der", "wo\u00b7che"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "ADJD", "PPER", "APPR", "ART", "ADJA"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Was zu naschen setzt/", "tokens": ["Was", "zu", "na\u00b7schen", "setzt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PTKZU", "VVINF", "VVFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Warten wir im h\u00e4scher loche", "tokens": ["War\u00b7ten", "wir", "im", "h\u00e4\u00b7scher", "lo\u00b7che"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VAFIN", "PPER", "APPRART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Selten auff die letzt.", "tokens": ["Sel\u00b7ten", "auff", "die", "letzt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "ADV", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.3": {"line.1": {"text": "3. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Sehn/ wo ihr geburts-brieff sey/", "tokens": ["Sehn", "/", "wo", "ihr", "ge\u00b7burts\u00b7brieff", "sey", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "$(", "PWAV", "PPOSAT", "NN", "VAFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Doch wir h\u00e4scher wissen", "tokens": ["Doch", "wir", "h\u00e4\u00b7scher", "wis\u00b7sen"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "PPER", "ADJD", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Nichts von dieser quackeley.", "tokens": ["Nichts", "von", "die\u00b7ser", "qua\u00b7cke\u00b7ley", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "APPR", "PDAT", "NN", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Vierzehn v\u00e4ter/ keinen rechten/", "tokens": ["Vier\u00b7zehn", "v\u00e4\u00b7ter", "/", "kei\u00b7nen", "rech\u00b7ten", "/"], "token_info": ["word", "word", "punct", "word", "word", "punct"], "pos": ["CARD", "NN", "$(", "PIAT", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Geht bey uns schon an/", "tokens": ["Geht", "bey", "uns", "schon", "an", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "ADV", "PTKVZ", "$("], "meter": "+---+", "measure": "dactylic.init"}, "line.7": {"text": "Wer nur sonsten wacker fechten", "tokens": ["Wer", "nur", "sons\u00b7ten", "wa\u00b7cker", "fech\u00b7ten"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWS", "ADV", "ADV", "ADJD", "VVINF"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Und seyn handwerck kan.", "tokens": ["Und", "seyn", "hand\u00b7werck", "kan", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VMFIN", "$."], "meter": "--+-+", "measure": "anapaest.init"}}, "stanza.4": {"line.1": {"text": "4. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "In die stadt zu marckte gehn/", "tokens": ["In", "die", "stadt", "zu", "marck\u00b7te", "gehn", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKZU", "VVFIN", "VVINF", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Warten wir und lauren/", "tokens": ["War\u00b7ten", "wir", "und", "lau\u00b7ren", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "KON", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Ob sie auch den zoll verstehn:", "tokens": ["Ob", "sie", "auch", "den", "zoll", "ver\u00b7stehn", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ART", "ADJD", "VVINF", "$."], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Alles ist in unsern h\u00e4nden/", "tokens": ["Al\u00b7les", "ist", "in", "un\u00b7sern", "h\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VAFIN", "APPR", "PPOSAT", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Ochsen/ kuh und kalb/", "tokens": ["Och\u00b7sen", "/", "kuh", "und", "kalb", "/"], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NN", "$(", "NN", "KON", "ADJD", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Und da geht es an ein pf\u00e4nden/", "tokens": ["Und", "da", "geht", "es", "an", "ein", "pf\u00e4n\u00b7den", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Alles zweimahl halb.", "tokens": ["Al\u00b7les", "zwei\u00b7mahl", "halb", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PIS", "ADV", "ADJD", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.5": {"line.1": {"text": "5. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Auff dem dorffe fremdes bier/", "tokens": ["Auff", "dem", "dorf\u00b7fe", "frem\u00b7des", "bier", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und eh sie es dencken/", "tokens": ["Und", "eh", "sie", "es", "den\u00b7cken", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVINF", "$("], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "Stellen wir uns an die th\u00fcr/", "tokens": ["Stel\u00b7len", "wir", "uns", "an", "die", "th\u00fcr", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PRF", "APPR", "ART", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und da schl\u00e4ppen wir die f\u00e4sser", "tokens": ["Und", "da", "schl\u00e4p\u00b7pen", "wir", "die", "f\u00e4s\u00b7ser"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VVFIN", "PPER", "ART", "NN"], "meter": "--+-+-+-", "measure": "anapaest.init"}, "line.6": {"text": "In die stadt hienein/", "tokens": ["In", "die", "stadt", "hien\u00b7ein", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADV", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Weil sie unserm magen besser/", "tokens": ["Weil", "sie", "un\u00b7serm", "ma\u00b7gen", "bes\u00b7ser", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "ADJD", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Als den bauren seyn.", "tokens": ["Als", "den", "bau\u00b7ren", "seyn", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VAINF", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "6. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Huren oder m\u00e4gde-pack/", "tokens": ["Hu\u00b7ren", "o\u00b7der", "m\u00e4g\u00b7de\u00b7pack", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "KON", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Ziehn wir sie zu paaren", "tokens": ["Ziehn", "wir", "sie", "zu", "paa\u00b7ren"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PTKZU", "VVINF"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "S\u00e4uberlich in unsern sack/", "tokens": ["S\u00e4u\u00b7ber\u00b7lich", "in", "un\u00b7sern", "sack", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADJD", "APPR", "PPOSAT", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und indem wir sie verhindern/", "tokens": ["Und", "in\u00b7dem", "wir", "sie", "ver\u00b7hin\u00b7dern", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "PPER", "VVINF", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Das kein ander kan/", "tokens": ["Das", "kein", "an\u00b7der", "kan", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJD", "VMFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Dresseln wir den kleinen kindern", "tokens": ["Dres\u00b7seln", "wir", "den", "klei\u00b7nen", "kin\u00b7dern"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Noch die ohren an.", "tokens": ["Noch", "die", "oh\u00b7ren", "an", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "NN", "PTKVZ", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.7": {"line.1": {"text": "7. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Seine grosse ritter-that/", "tokens": ["Sei\u00b7ne", "gros\u00b7se", "rit\u00b7ter\u00b7that", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Sind wir stahl und eisen/", "tokens": ["Sind", "wir", "stahl", "und", "ei\u00b7sen", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "VVFIN", "KON", "VVFIN", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und gesegnen ihm da\u00df bad/", "tokens": ["Und", "ge\u00b7seg\u00b7nen", "ihm", "da\u00df", "bad", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "KOUS", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Und wo er sich noch erz\u00fcrnen", "tokens": ["Und", "wo", "er", "sich", "noch", "er\u00b7z\u00fcr\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "PWAV", "PPER", "PRF", "ADV", "VVINF"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Und bravieren will/", "tokens": ["Und", "bra\u00b7vie\u00b7ren", "will", "/"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "VVINF", "VMFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "W\u00fcrtzen wir ihm unsre birnen", "tokens": ["W\u00fcrt\u00b7zen", "wir", "ihm", "uns\u00b7re", "bir\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "PPER", "PPOSAT", "NN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Mit den flegel-stiel.", "tokens": ["Mit", "den", "fle\u00b7gel\u00b7stiel", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}, "stanza.8": {"line.1": {"text": "8. ", "tokens": [], "token_info": [], "pos": []}, "line.2": {"text": "Sich/ nach ihrer guten lust/", "tokens": ["Sich", "/", "nach", "ih\u00b7rer", "gu\u00b7ten", "lust", "/"], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PRF", "$(", "APPR", "PPOSAT", "ADJA", "NN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Auff was bessers legen/", "tokens": ["Auff", "was", "bes\u00b7sers", "le\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PRELS", "ADV", "VVINF", "$("], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Mir ist gleichwohl di\u00df bewust/", "tokens": ["Mir", "ist", "gleich\u00b7wohl", "di\u00df", "be\u00b7wust", "/"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "PDS", "VVFIN", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.5": {"text": "Da\u00df ein h\u00e4scher vor neun zeugen", "tokens": ["Da\u00df", "ein", "h\u00e4\u00b7scher", "vor", "neun", "zeu\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "ART", "ADJA", "APPR", "CARD", "VVFIN"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.6": {"text": "Bey dem Richter gilt/", "tokens": ["Bey", "dem", "Rich\u00b7ter", "gilt", "/"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "$("], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.7": {"text": "Drum so wei\u00df ich dem die feigen/", "tokens": ["Drum", "so", "wei\u00df", "ich", "dem", "die", "fei\u00b7gen", "/"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ADV", "VVFIN", "PPER", "ART", "ART", "ADJA", "$("], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.8": {"text": "Der uns schelmen schilt.", "tokens": ["Der", "uns", "schel\u00b7men", "schilt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "VVINF", "VVFIN", "$."], "meter": "+-+-+", "measure": "trochaic.tri"}}}}}