{"textgrid.poem.57518": {"metadata": {"author": {"name": "Gottsched, Johann Christoph", "birth": "N.A.", "death": "N.A."}, "title": "Der Donaustrom", "genre": "verse", "period": "N.A.", "pub_year": 1733, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "So sey mir nun gegr\u00fc\u00dft, du deutscher Tyberstrom!", "tokens": ["So", "sey", "mir", "nun", "ge\u00b7gr\u00fc\u00dft", ",", "du", "deut\u00b7scher", "Ty\u00b7ber\u00b7strom", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Empfange mich, auf deinem breiten R\u00fccken!", "tokens": ["Emp\u00b7fan\u00b7ge", "mich", ",", "auf", "dei\u00b7nem", "brei\u00b7ten", "R\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fchre mich mit dir, und la\u00df mich bald erblicken", "tokens": ["Und", "f\u00fch\u00b7re", "mich", "mit", "dir", ",", "und", "la\u00df", "mich", "bald", "er\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "$,", "KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der neuen Zeit erhabnes Rom!", "tokens": ["Der", "neu\u00b7en", "Zeit", "er\u00b7hab\u00b7nes", "Rom", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich strebte l\u00e4ngst, die Kaiserstadt zu sehen,", "tokens": ["Ich", "streb\u00b7te", "l\u00e4ngst", ",", "die", "Kai\u00b7ser\u00b7stadt", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die aller Deutschen Haupt, der Fremden Wunder ist:", "tokens": ["Die", "al\u00b7ler", "Deut\u00b7schen", "Haupt", ",", "der", "Frem\u00b7den", "Wun\u00b7der", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt soll mein Wunsch, mein alter Wunsch geschehen,", "tokens": ["Itzt", "soll", "mein", "Wunsch", ",", "mein", "al\u00b7ter", "Wunsch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wo du der Absicht g\u00fcnstig bist;", "tokens": ["Wo", "du", "der", "Ab\u00b7sicht", "g\u00fcns\u00b7tig", "bist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wo deine Silberfluth mich nur in wenig Tagen", "tokens": ["Wo", "dei\u00b7ne", "Sil\u00b7ber\u00b7fluth", "mich", "nur", "in", "we\u00b7nig", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus Bayerland nach Wien will tragen.", "tokens": ["Aus", "Bay\u00b7er\u00b7land", "nach", "Wi\u00b7en", "will", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.2": {"line.1": {"text": "La\u00df ein verf\u00fchrtes Herz, das nur nach Frankreich lechzt,", "tokens": ["La\u00df", "ein", "ver\u00b7f\u00fchr\u00b7tes", "Herz", ",", "das", "nur", "nach", "Fran\u00b7kreich", "lechzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blo\u00df nach Paris, als seinem Himmel st\u00f6hnen.", "tokens": ["Blo\u00df", "nach", "Pa\u00b7ris", ",", "als", "sei\u00b7nem", "Him\u00b7mel", "st\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "La\u00df sich der Stutzer Schaar nach Modeschneidern sehnen,", "tokens": ["La\u00df", "sich", "der", "Stut\u00b7zer", "Schaar", "nach", "Mo\u00b7de\u00b7schnei\u00b7dern", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PRF", "ART", "NN", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie der nach deutschen Thalern \u00e4chzt!", "tokens": ["Wie", "der", "nach", "deut\u00b7schen", "Tha\u00b7lern", "\u00e4chzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schleppt immerhin die ungrischen Ducaten,", "tokens": ["Schleppt", "im\u00b7mer\u00b7hin", "die", "un\u00b7gri\u00b7schen", "Du\u00b7ca\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den Feinden Ungarlands, und aller Deutschen zu:", "tokens": ["Den", "Fein\u00b7den", "Un\u00b7gar\u00b7lands", ",", "und", "al\u00b7ler", "Deut\u00b7schen", "zu", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "La\u00dft Deutschlands Mark in fremde Faust gerathen,", "tokens": ["La\u00dft", "Deutschlands", "Mark", "in", "frem\u00b7de", "Faust", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "NN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Zu St\u00f6rung unsrer k\u00fcnftgen Ruh:", "tokens": ["Zu", "St\u00f6\u00b7rung", "uns\u00b7rer", "k\u00fcnft\u00b7gen", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mich soll der Kaisersitz, den so viel Thoren fliehen,", "tokens": ["Mich", "soll", "der", "Kai\u00b7ser\u00b7sitz", ",", "den", "so", "viel", "Tho\u00b7ren", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In die ber\u00fchmten Mauren ziehen.", "tokens": ["In", "die", "be\u00b7r\u00fchm\u00b7ten", "Mau\u00b7ren", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Mich d\u00fcnkt, du bist bereit, und lockest mich zu dir.", "tokens": ["Mich", "d\u00fcnkt", ",", "du", "bist", "be\u00b7reit", ",", "und", "lo\u00b7ckest", "mich", "zu", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier bin ich, komm! und la\u00df uns weiter eilen!", "tokens": ["Hier", "bin", "ich", ",", "komm", "!", "und", "la\u00df", "uns", "wei\u00b7ter", "ei\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "VVFIN", "$.", "KON", "VVIMP", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das Schiff st\u00f6\u00dft wirklich ab; du willst dich nicht verweilen:", "tokens": ["Das", "Schiff", "st\u00f6\u00dft", "wirk\u00b7lich", "ab", ";", "du", "willst", "dich", "nicht", "ver\u00b7wei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und beyde Br\u00fccken fliehn vor mir.", "tokens": ["Und", "bey\u00b7de", "Br\u00fc\u00b7cken", "fliehn", "vor", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich seh den ", "tokens": ["Ich", "seh", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Darein du dich zertheilt, umarmest und umringst.", "tokens": ["Da\u00b7rein", "du", "dich", "zer\u00b7theilt", ",", "um\u00b7ar\u00b7mest", "und", "um\u00b7ringst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nun kannst du dich gedoppelt breiter zeigen,", "tokens": ["Nun", "kannst", "du", "dich", "ge\u00b7dop\u00b7pelt", "brei\u00b7ter", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da du dein ganzes Wasser bringst;", "tokens": ["Da", "du", "dein", "gan\u00b7zes", "Was\u00b7ser", "bringst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und, desto sch\u00f6ner noch mit starker Fluth zu prangen,", "tokens": ["Und", ",", "des\u00b7to", "sch\u00f6\u00b7ner", "noch", "mit", "star\u00b7ker", "Fluth", "zu", "pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADJD", "ADV", "APPR", "ADJA", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.4": {"line.1": {"text": "Das gro\u00dfe ", "tokens": ["Das", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Der Th\u00fcrme Pracht scheint nach und nach zu sinken.", "tokens": ["Der", "Th\u00fcr\u00b7me", "Pracht", "scheint", "nach", "und", "nach", "zu", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "KON", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Wo mirs an Wollust nicht gebrach.", "tokens": ["Wo", "mirs", "an", "Wol\u00b7lust", "nicht", "ge\u00b7brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein B\u00fcchersaal ist des Pr\u00e4laten Ehre,", "tokens": ["Sein", "B\u00fc\u00b7cher\u00b7saal", "ist", "des", "Pr\u00e4\u00b7la\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der prangt mit altem Witz und neuer Sch\u00e4tze Pracht.", "tokens": ["Der", "prangt", "mit", "al\u00b7tem", "Witz", "und", "neu\u00b7er", "Sch\u00e4t\u00b7ze", "Pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein stolzer Bau giebt jeder Stadt die Lehre:", "tokens": ["Sein", "stol\u00b7zer", "Bau", "giebt", "je\u00b7der", "Stadt", "die", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df Bauen Glanz und Ansehn macht.", "tokens": ["Da\u00df", "Bau\u00b7en", "Glanz", "und", "An\u00b7sehn", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und wird die\u00df Stift vollf\u00fchrt, so wird die Nachwelt lesen,", "tokens": ["Und", "wird", "die\u00df", "Stift", "voll\u00b7f\u00fchrt", ",", "so", "wird", "die", "Nach\u00b7welt", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PDS", "NN", "VVPP", "$,", "ADV", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie gro\u00df sein Bauherr itzt gewesen.", "tokens": ["Wie", "gro\u00df", "sein", "Bau\u00b7herr", "itzt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Ich seh den alten ", "tokens": ["Ich", "seh", "den", "al\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Nach Gothenart, ein Wunderbau gehei\u00dfen.", "tokens": ["Nach", "Go\u00b7then\u00b7art", ",", "ein", "Wun\u00b7der\u00b7bau", "ge\u00b7hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Zeit, so stark sie ist, konnt ihn nicht niederrei\u00dfen;", "tokens": ["Die", "Zeit", ",", "so", "stark", "sie", "ist", ",", "konnt", "ihn", "nicht", "nie\u00b7der\u00b7rei\u00b7\u00dfen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil er zu fest gegr\u00fcndet war.", "tokens": ["Weil", "er", "zu", "fest", "ge\u00b7gr\u00fcn\u00b7det", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKA", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wo bleiben noch der andern Kl\u00f6ster Tempel;", "tokens": ["Wo", "blei\u00b7ben", "noch", "der", "an\u00b7dern", "Kl\u00f6s\u00b7ter", "Tem\u00b7pel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und die gedritte Zahl, wo unsre Br\u00fcder flehn?", "tokens": ["Und", "die", "ge\u00b7drit\u00b7te", "Zahl", ",", "wo", "uns\u00b7re", "Br\u00fc\u00b7der", "flehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die alle bl\u00fchn; zum deutlichen Exempel,", "tokens": ["Die", "al\u00b7le", "bl\u00fchn", ";", "zum", "deut\u00b7li\u00b7chen", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "$.", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Da\u00df beyder Andacht kann bestehn;", "tokens": ["Da\u00df", "bey\u00b7der", "An\u00b7dacht", "kann", "be\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df Christen beyder Art, beysammen friedlich bl\u00fchen,", "tokens": ["Da\u00df", "Chris\u00b7ten", "bey\u00b7der", "Art", ",", "bey\u00b7sam\u00b7men", "fried\u00b7lich", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIAT", "NN", "$,", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn sie der B\u00fcrger Pflicht vollziehen.", "tokens": ["Wenn", "sie", "der", "B\u00fcr\u00b7ger", "Pflicht", "voll\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Ihr habt mir noch die alte Gunst erwiesen.", "tokens": ["Ihr", "habt", "mir", "noch", "die", "al\u00b7te", "Gunst", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Freundschaft Eurer Brust wird stets von mir gepriesen,", "tokens": ["Die", "Freund\u00b7schaft", "Eu\u00b7rer", "Brust", "wird", "stets", "von", "mir", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ich ganz unver\u00e4ndert fand.", "tokens": ["Die", "ich", "ganz", "un\u00b7ver\u00b7\u00e4n\u00b7dert", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was sag ich Euch, ", "tokens": ["Was", "sag", "ich", "Euch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Ihr sch\u00fctzt das Recht des Volks der Protestanten,", "tokens": ["Ihr", "sch\u00fctzt", "das", "Recht", "des", "Volks", "der", "Pro\u00b7tes\u00b7tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die man so eifrig unterdr\u00fcckt.", "tokens": ["Die", "man", "so", "eif\u00b7rig", "un\u00b7ter\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Himmel f\u00f6rdre stets das Werk von Euren H\u00e4nden!", "tokens": ["Der", "Him\u00b7mel", "f\u00f6rd\u00b7re", "stets", "das", "Werk", "von", "Eu\u00b7ren", "H\u00e4n\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und helf es, uns zum Schutz, vollenden!", "tokens": ["Und", "helf", "es", ",", "uns", "zum", "Schutz", ",", "voll\u00b7en\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Was seh ich dort vor mir? Das hohe ", "tokens": ["Was", "seh", "ich", "dort", "vor", "mir", "?", "Das", "ho\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein festes Schlo\u00df, die ", "tokens": ["Ein", "fes\u00b7tes", "Schlo\u00df", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Es hatte vor der Zeit fast keines seines gleichen:", "tokens": ["Es", "hat\u00b7te", "vor", "der", "Zeit", "fast", "kei\u00b7nes", "sei\u00b7nes", "glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "PIS", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hub der Krieg die\u00df Vorrecht auf.", "tokens": ["Doch", "hub", "der", "Krieg", "die\u00df", "Vor\u00b7recht", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Und durch sein siegend Schwert das ganze Reich durchdrang,", "tokens": ["Und", "durch", "sein", "sie\u00b7gend", "Schwert", "das", "gan\u00b7ze", "Reich", "durch\u00b7drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "CARD", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zerbrach er das, was ihm nicht ferner n\u00fctzte.", "tokens": ["Zer\u00b7brach", "er", "das", ",", "was", "ihm", "nicht", "fer\u00b7ner", "n\u00fctz\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "$,", "PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "So spielt des harten Schicksals Zwang!", "tokens": ["So", "spielt", "des", "har\u00b7ten", "Schick\u00b7sals", "Zwang", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der, was der Menschen Hand seit langer Zeit verehret,", "tokens": ["Der", ",", "was", "der", "Men\u00b7schen", "Hand", "seit", "lan\u00b7ger", "Zeit", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn seine Stunde k\u00f6mmt, zerst\u00f6ret.", "tokens": ["Wenn", "sei\u00b7ne", "Stun\u00b7de", "k\u00f6mmt", ",", "zer\u00b7st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Du selbst ber\u00fchmter Strom, kannst hier ein Zeuge seyn:", "tokens": ["Du", "selbst", "be\u00b7r\u00fchm\u00b7ter", "Strom", ",", "kannst", "hier", "ein", "Zeu\u00b7ge", "seyn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$,", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Warst du nicht sonst die Brustwehr deutscher Lande?", "tokens": ["Warst", "du", "nicht", "sonst", "die", "Brust\u00b7wehr", "deut\u00b7scher", "Lan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und trugst du gleich einmal der Knechtschaft harte Bande,", "tokens": ["Und", "trugst", "du", "gleich", "ein\u00b7mal", "der", "Knecht\u00b7schaft", "har\u00b7te", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bliebst du doch freyer, als der Rhein.", "tokens": ["Bliebst", "du", "doch", "frey\u00b7er", ",", "als", "der", "Rhein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein siegend Volk von unbezwungnen Gothen", "tokens": ["Ein", "sie\u00b7gend", "Volk", "von", "un\u00b7be\u00b7zwung\u00b7nen", "Go\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "K\u00f6mmt vom Euxin herauf, und sch\u00fctzet deinen Strand,", "tokens": ["K\u00f6mmt", "vom", "Eu\u00b7xin", "her\u00b7auf", ",", "und", "sch\u00fct\u00b7zet", "dei\u00b7nen", "Strand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NE", "PTKVZ", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hat alle Macht des Nordens aufgebothen,", "tokens": ["Hat", "al\u00b7le", "Macht", "des", "Nor\u00b7dens", "auf\u00b7ge\u00b7bo\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00fcrzet in der R\u00f6mer Land;", "tokens": ["Und", "st\u00fcr\u00b7zet", "in", "der", "R\u00f6\u00b7mer", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und r\u00e4cht den bittern Schimpf, der Deutschland sonst beschweret,", "tokens": ["Und", "r\u00e4cht", "den", "bit\u00b7tern", "Schimpf", ",", "der", "Deutschland", "sonst", "be\u00b7schwe\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Indem es W\u00e4lschland selbst verheeret.", "tokens": ["In\u00b7dem", "es", "W\u00e4l\u00b7schland", "selbst", "ver\u00b7hee\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.9": {"line.1": {"text": "Was zeigt mir linkerhand die\u00df halb umschlo\u00dfne Thal?", "tokens": ["Was", "zeigt", "mir", "lin\u00b7ker\u00b7hand", "die\u00df", "halb", "um\u00b7schlo\u00df\u00b7ne", "Thal", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VVFIN", "PDS", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists ", "tokens": ["Ists"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Ja, ja, ich seh es schon, mit sehnlicher Begierde,", "tokens": ["Ja", ",", "ja", ",", "ich", "seh", "es", "schon", ",", "mit", "sehn\u00b7li\u00b7cher", "Be\u00b7gier\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lobe seiner Th\u00fcrme Zahl.", "tokens": ["Und", "lo\u00b7be", "sei\u00b7ner", "Th\u00fcr\u00b7me", "Zahl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Stra\u00dfen Bau, die Lebensart der Leute,", "tokens": ["Der", "Stra\u00b7\u00dfen", "Bau", ",", "die", "Le\u00b7ben\u00b7sart", "der", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verk\u00fcndigt mir gewi\u00df ein gutes Nachtquartier.", "tokens": ["Ver\u00b7k\u00fcn\u00b7digt", "mir", "ge\u00b7wi\u00df", "ein", "gu\u00b7tes", "Nacht\u00b7quar\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Ort ward nicht des letzten Krieges Beute,", "tokens": ["Der", "Ort", "ward", "nicht", "des", "letz\u00b7ten", "Krie\u00b7ges", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die tapfern Sch\u00fctzen fochten hier.", "tokens": ["Die", "tap\u00b7fern", "Sch\u00fct\u00b7zen", "foch\u00b7ten", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kein Haus ist hier versehrt, kein Tempel ward verletzet,", "tokens": ["Kein", "Haus", "ist", "hier", "ver\u00b7sehrt", ",", "kein", "Tem\u00b7pel", "ward", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,", "PIAT", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So sehr man Straubing zugesetzet.", "tokens": ["So", "sehr", "man", "Strau\u00b7bing", "zu\u00b7ge\u00b7set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Du armes ", "tokens": ["Du", "ar\u00b7mes"], "token_info": ["word", "word"], "pos": ["PPER", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Als sich der Krieg in Bayern angesponnen.", "tokens": ["Als", "sich", "der", "Krieg", "in", "Bay\u00b7ern", "an\u00b7ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Feind hat dich umringt, belagert und gewonnen,", "tokens": ["Der", "Feind", "hat", "dich", "um\u00b7ringt", ",", "be\u00b7la\u00b7gert", "und", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Land, Th\u00fcrm' und Tempel zeigens mir.", "tokens": ["Land", ",", "Th\u00fcrm'", "und", "Tem\u00b7pel", "zei\u00b7gens", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie kl\u00e4glich tobt der Menschen Lust zum Morden!", "tokens": ["Wie", "kl\u00e4g\u00b7lich", "tobt", "der", "Men\u00b7schen", "Lust", "zum", "Mor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was wirkt die Kriegswuth nicht, wenn sie einmal entbrannt?", "tokens": ["Was", "wirkt", "die", "Kriegs\u00b7wuth", "nicht", ",", "wenn", "sie", "ein\u00b7mal", "ent\u00b7brannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Sie schonet nichts, was kaum erbauet worden,", "tokens": ["Sie", "scho\u00b7net", "nichts", ",", "was", "kaum", "er\u00b7bau\u00b7et", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PRELS", "ADV", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00fcrzt das Volk in Jammerstand.", "tokens": ["Und", "st\u00fcrzt", "das", "Volk", "in", "Jam\u00b7mer\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Viel Jahre werden hier, ihr ungerechten Lilgen!", "tokens": ["Viel", "Jah\u00b7re", "wer\u00b7den", "hier", ",", "ihr", "un\u00b7ge\u00b7rech\u00b7ten", "Lil\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht eurer Herrschsucht Spuren tilgen.", "tokens": ["Nicht", "eu\u00b7rer", "Herrschsucht", "Spu\u00b7ren", "til\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.11": {"line.1": {"text": "Ber\u00fchmter ", "tokens": ["Be\u00b7r\u00fchm\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Du k\u00f6mmst herab von M\u00fcnchens edlen H\u00f6hen.", "tokens": ["Du", "k\u00f6mmst", "her\u00b7ab", "von", "M\u00fcn\u00b7chens", "ed\u00b7len", "H\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Durch deinen Freundschaftsbund mu\u00dft unsre Lust entstehen,", "tokens": ["Durch", "dei\u00b7nen", "Freund\u00b7schafts\u00b7bund", "mu\u00dft", "uns\u00b7re", "Lust", "ent\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermehrte deine Freude sich.", "tokens": ["Ver\u00b7mehr\u00b7te", "dei\u00b7ne", "Freu\u00b7de", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist Sachsens Augenlust und deines Ufers Preis!", "tokens": ["Ist", "Sach\u00b7sens", "Au\u00b7gen\u00b7lust", "und", "dei\u00b7nes", "U\u00b7fers", "Preis", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie huldreich ist die Gro\u00dfmuth Ihrer Jugend!", "tokens": ["Wie", "huld\u00b7reich", "ist", "die", "Gro\u00df\u00b7muth", "Ih\u00b7rer", "Ju\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wovon ich selbst die Proben weis;", "tokens": ["Wo\u00b7von", "ich", "selbst", "die", "Pro\u00b7ben", "weis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "Seit sie Dein Churf\u00fcrst heimgef\u00fchret?", "tokens": ["Seit", "sie", "Dein", "Chur\u00b7f\u00fcrst", "heim\u00b7ge\u00b7f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.12": {"line.1": {"text": "Verbrannter ", "tokens": ["Ver\u00b7brann\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Wie sehr der Krieg nicht l\u00e4ngst bey dir getobet.", "tokens": ["Wie", "sehr", "der", "Krieg", "nicht", "l\u00e4ngst", "bey", "dir", "ge\u00b7to\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Donau, seiner F\u00fcrstinn, ein.", "tokens": ["Der", "Do\u00b7nau", ",", "sei\u00b7ner", "F\u00fcrs\u00b7tinn", ",", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun th\u00fcrmen sich auf beyden Seiten Berge,", "tokens": ["Nun", "th\u00fcr\u00b7men", "sich", "auf", "bey\u00b7den", "Sei\u00b7ten", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Des breiten Stromes Fluth flie\u00dft eingeschr\u00e4nkter fort.", "tokens": ["Des", "brei\u00b7ten", "Stro\u00b7mes", "Fluth", "flie\u00dft", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ter", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So sah man sonst die Schl\u00f6sser kleiner Zwerge,", "tokens": ["So", "sah", "man", "sonst", "die", "Schl\u00f6s\u00b7ser", "klei\u00b7ner", "Zwer\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und dichtete so manchen Ort,", "tokens": ["Und", "dich\u00b7te\u00b7te", "so", "man\u00b7chen", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wo Ries' und Helden sich durch k\u00fchnes Unterfangen", "tokens": ["Wo", "Ries'", "und", "Hel\u00b7den", "sich", "durch", "k\u00fch\u00b7nes", "Un\u00b7ter\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "KON", "NN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im felsigten Gebirg vergangen.", "tokens": ["Im", "fel\u00b7sig\u00b7ten", "Ge\u00b7birg", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.13": {"line.1": {"text": "F\u00fcrst ", "tokens": ["F\u00fcrst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Beherrschten so der Alpen tiefste Gr\u00fcnde.", "tokens": ["Be\u00b7herrschten", "so", "der", "Al\u00b7pen", "tiefs\u00b7te", "Gr\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Tyrol und Steuermark bewahrten solche Schl\u00fcnde,", "tokens": ["Ty\u00b7rol", "und", "Steu\u00b7er\u00b7mark", "be\u00b7wahr\u00b7ten", "sol\u00b7che", "Schl\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als itzt kein Mensch zu finden weis.", "tokens": ["Als", "itzt", "kein", "Mensch", "zu", "fin\u00b7den", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weg Fabelwerk! an diesen rohen Felsen", "tokens": ["Weg", "Fa\u00b7bel\u00b7werk", "!", "an", "die\u00b7sen", "ro\u00b7hen", "Fel\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Stehn gleichwohl hin und her noch H\u00fctten angeklebt;", "tokens": ["Stehn", "gleich\u00b7wohl", "hin", "und", "her", "noch", "H\u00fct\u00b7ten", "an\u00b7ge\u00b7klebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "KON", "ADV", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Darinn ein Volk mit Kr\u00f6pfen an den H\u00e4lsen,", "tokens": ["Da\u00b7rinn", "ein", "Volk", "mit", "Kr\u00f6p\u00b7fen", "an", "den", "H\u00e4l\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Vergn\u00fcgt in seinem Jammer lebt.", "tokens": ["Ver\u00b7gn\u00fcgt", "in", "sei\u00b7nem", "Jam\u00b7mer", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es kennt den Rest der Welt auch kaum vom H\u00f6rensagen:", "tokens": ["Es", "kennt", "den", "Rest", "der", "Welt", "auch", "kaum", "vom", "H\u00f6\u00b7ren\u00b7sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie k\u00f6nnt es sonst sein Nest ertragen?", "tokens": ["Wie", "k\u00f6nnt", "es", "sonst", "sein", "Nest", "er\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.14": {"line.1": {"text": "Begl\u00fccktes Gemsenvolk! du weist nicht, was die Stadt", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Gem\u00b7sen\u00b7volk", "!", "du", "weist", "nicht", ",", "was", "die", "Stadt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr Noth und Angst, bey ihrer Sch\u00f6nheit heget:", "tokens": ["F\u00fcr", "Noth", "und", "Angst", ",", "bey", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", "he\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dir wird kein falsches Geld, zu deiner Quaal, gepr\u00e4get,", "tokens": ["Dir", "wird", "kein", "fal\u00b7sches", "Geld", ",", "zu", "dei\u00b7ner", "Qua\u00b7al", ",", "ge\u00b7pr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das weder Werth noch Ansehn hat.", "tokens": ["Das", "we\u00b7der", "Werth", "noch", "An\u00b7sehn", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich plagt kein Geiz, der Wucher ist verbannet;", "tokens": ["Dich", "plagt", "kein", "Geiz", ",", "der", "Wu\u00b7cher", "ist", "ver\u00b7ban\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Ehrsucht qu\u00e4lt dich nicht, bey Hofe gro\u00df zu seyn:", "tokens": ["Die", "Ehr\u00b7sucht", "qu\u00e4lt", "dich", "nicht", ",", "bey", "Ho\u00b7fe", "gro\u00df", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du wirst ins Joch der Gro\u00dfen nicht gespannet,", "tokens": ["Du", "wirst", "ins", "Joch", "der", "Gro\u00b7\u00dfen", "nicht", "ge\u00b7span\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und machst auch keinen Gro\u00dfen klein.", "tokens": ["Und", "machst", "auch", "kei\u00b7nen", "Gro\u00b7\u00dfen", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Berg verstecket dich. Was ist dein Weltget\u00fcmmel?", "tokens": ["Ein", "Berg", "ver\u00b7ste\u00b7cket", "dich", ".", "Was", "ist", "dein", "Welt\u00b7ge\u00b7t\u00fcm\u00b7mel", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PWS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dein Fels, die Donau und der Himmel.", "tokens": ["Dein", "Fels", ",", "die", "Do\u00b7nau", "und", "der", "Him\u00b7mel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "NE", "KON", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.15": {"line.1": {"text": "So scheints: doch scheints auch nur. Wie elend lebt ein Mann,", "tokens": ["So", "scheints", ":", "doch", "scheints", "auch", "nur", ".", "Wie", "e\u00b7lend", "lebt", "ein", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ADV", "VVFIN", "ADV", "ADV", "$.", "PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den die Gestalt kaum l\u00e4\u00dft zu Menschen z\u00e4hlen?", "tokens": ["Den", "die", "Ge\u00b7stalt", "kaum", "l\u00e4\u00dft", "zu", "Men\u00b7schen", "z\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie viel gebricht ihm nicht, was sonder Gram und Qu\u00e4len", "tokens": ["Wie", "viel", "ge\u00b7bricht", "ihm", "nicht", ",", "was", "son\u00b7der", "Gram", "und", "Qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns die Gesellschaft liefern kann?", "tokens": ["Uns", "die", "Ge\u00b7sell\u00b7schaft", "lie\u00b7fern", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lernt nicht sich, nicht andre Leute kennen.", "tokens": ["Er", "lernt", "nicht", "sich", ",", "nicht", "and\u00b7re", "Leu\u00b7te", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PRF", "$,", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sein Gott, wird jeder Klotz, vor dem er murmelnd kniet;", "tokens": ["Sein", "Gott", ",", "wird", "je\u00b7der", "Klotz", ",", "vor", "dem", "er", "mur\u00b7melnd", "kniet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Heiligen weis er oft nicht zu nennen,", "tokens": ["Den", "Hei\u00b7li\u00b7gen", "weis", "er", "oft", "nicht", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Den er mit dummer Ehrfurcht sieht.", "tokens": ["Den", "er", "mit", "dum\u00b7mer", "Ehr\u00b7furcht", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie will er, als ein Christ, das h\u00f6chste Wesen ehren,", "tokens": ["Wie", "will", "er", ",", "als", "ein", "Christ", ",", "das", "h\u00f6chs\u00b7te", "We\u00b7sen", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das niemand ihn will kennen lehren?", "tokens": ["Das", "nie\u00b7mand", "ihn", "will", "ken\u00b7nen", "leh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PPER", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.16": {"line.1": {"text": "Dort zeigt sich ", "tokens": ["Dort", "zeigt", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sein Cardinal verdient der B\u00fcrger Liebe.", "tokens": ["Sein", "Car\u00b7di\u00b7nal", "ver\u00b7dient", "der", "B\u00fcr\u00b7ger", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er dr\u00fcckt die Armen nicht, und folget keinem Triebe,", "tokens": ["Er", "dr\u00fcckt", "die", "Ar\u00b7men", "nicht", ",", "und", "fol\u00b7get", "kei\u00b7nem", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ihre Quaal zur Wirkung hat.", "tokens": ["Der", "ih\u00b7re", "Qua\u00b7al", "zur", "Wir\u00b7kung", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kein Schwelgen, Spiel, kein Jagen und Stolzieren,", "tokens": ["Kein", "Schwel\u00b7gen", ",", "Spiel", ",", "kein", "Ja\u00b7gen", "und", "Stol\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Kleidung und Gefolg, ersch\u00f6pft des Landes Mark.", "tokens": ["In", "Klei\u00b7dung", "und", "Ge\u00b7folg", ",", "er\u00b7sch\u00f6pft", "des", "Lan\u00b7des", "Mark", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein sch\u00f6ner Dom kann Aug und Herzen r\u00fchren,", "tokens": ["Sein", "sch\u00f6\u00b7ner", "Dom", "kann", "Aug", "und", "Her\u00b7zen", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und ist an alter Baukunst stark.", "tokens": ["Und", "ist", "an", "al\u00b7ter", "Bau\u00b7kunst", "stark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Um ihre Fluth mehr aufzuschwellen.", "tokens": ["Um", "ih\u00b7re", "Fluth", "mehr", "auf\u00b7zu\u00b7schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.17": {"line.1": {"text": "Wo bleibt der ", "tokens": ["Wo", "bleibt", "der"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ein seltner Schatz, den er dem Bischof reichet!", "tokens": ["Ein", "selt\u00b7ner", "Schatz", ",", "den", "er", "dem", "Bi\u00b7schof", "rei\u00b7chet", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Elster gleichet ihm, die Mei\u00dfens Flur durchstreichet,", "tokens": ["Die", "Els\u00b7ter", "glei\u00b7chet", "ihm", ",", "die", "Mei\u00b7\u00dfens", "Flur", "durch\u00b7strei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo sie bey Plauen sich ergeu\u00dft.", "tokens": ["Wo", "sie", "bey", "Plau\u00b7en", "sich", "er\u00b7geu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O Deutschland! sey auf deinen Reichthum st\u00f6lzer!", "tokens": ["O", "Deutschland", "!", "sey", "auf", "dei\u00b7nen", "Reicht\u00b7hum", "st\u00f6l\u00b7zer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "VAFIN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Was fehlt dir ferner noch an Gl\u00fcck und Ueberflu\u00df?", "tokens": ["Was", "fehlt", "dir", "fer\u00b7ner", "noch", "an", "Gl\u00fcck", "und", "Ue\u00b7berf\u00b7lu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Boden zinst Metalle, Marmor, H\u00f6lzer,", "tokens": ["Dein", "Bo\u00b7den", "zinst", "Me\u00b7tal\u00b7le", ",", "Mar\u00b7mor", ",", "H\u00f6l\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die manches Land erborgen mu\u00df;", "tokens": ["Die", "man\u00b7ches", "Land", "er\u00b7bor\u00b7gen", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wild, Viehzucht, Ackerbau, und reiche Fischereyen,", "tokens": ["Wild", ",", "Vieh\u00b7zucht", ",", "A\u00b7cker\u00b7bau", ",", "und", "rei\u00b7che", "Fi\u00b7sche\u00b7re\u00b7yen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "Die dich mit Perlen auch erfreuen.", "tokens": ["Die", "dich", "mit", "Per\u00b7len", "auch", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.18": {"line.1": {"text": "Nun fleu\u00dft die Donau schnell, und breitet ihren Strand", "tokens": ["Nun", "fleu\u00dft", "die", "Do\u00b7nau", "schnell", ",", "und", "brei\u00b7tet", "ih\u00b7ren", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NE", "ADJD", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gedoppelt aus, wenns Berg und Fels gestatten:", "tokens": ["Ge\u00b7dop\u00b7pelt", "aus", ",", "wenns", "Berg", "und", "Fels", "ge\u00b7stat\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zuweilen tritt sie auch in dichter W\u00e4lder Schatten,", "tokens": ["Zu\u00b7wei\u00b7len", "tritt", "sie", "auch", "in", "dich\u00b7ter", "W\u00e4l\u00b7der", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ihre Fluth den Durchgang fand.", "tokens": ["Wo", "ih\u00b7re", "Fluth", "den", "Durch\u00b7gang", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald schweift sie auch in angenehmen Auen,", "tokens": ["Bald", "schweift", "sie", "auch", "in", "an\u00b7ge\u00b7neh\u00b7men", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wo sich das Augenlicht an weiter Aussicht labt;", "tokens": ["Wo", "sich", "das", "Au\u00b7gen\u00b7licht", "an", "wei\u00b7ter", "Aus\u00b7sicht", "labt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Womit es die Natur begabt;", "tokens": ["Wo\u00b7mit", "es", "die", "Na\u00b7tur", "be\u00b7gabt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die ungeschmolzner Schnee das ganze Jahr bedecket,", "tokens": ["Die", "un\u00b7ge\u00b7schmolz\u00b7ner", "Schnee", "das", "gan\u00b7ze", "Jahr", "be\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und deren Anblick schon erschrecket.", "tokens": ["Und", "de\u00b7ren", "An\u00b7blick", "schon", "er\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.19": {"line.1": {"text": "Was mir die Donau wies, sind Zwerge gegen euch,", "tokens": ["Was", "mir", "die", "Do\u00b7nau", "wies", ",", "sind", "Zwer\u00b7ge", "ge\u00b7gen", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NE", "VVFIN", "$,", "VAFIN", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr aber gleicht den ungeheuren Riesen!", "tokens": ["Ihr", "a\u00b7ber", "gleicht", "den", "un\u00b7ge\u00b7heu\u00b7ren", "Rie\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da eure Gipfel sich zehn Meilen weit gewiesen,", "tokens": ["Da", "eu\u00b7re", "Gip\u00b7fel", "sich", "zehn", "Mei\u00b7len", "weit", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "CARD", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seyd ihr dem steilen Blocksberg gleich.", "tokens": ["Seyd", "ihr", "dem", "stei\u00b7len", "Blocks\u00b7berg", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch, da das Mark von euren Eingeweiden", "tokens": ["Doch", ",", "da", "das", "Mark", "von", "eu\u00b7ren", "Ein\u00b7ge\u00b7wei\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An Erzten, Zinn und Bley und Eisen fruchtbar ist;", "tokens": ["An", "Erz\u00b7ten", ",", "Zinn", "und", "Bley", "und", "Ei\u00b7sen", "frucht\u00b7bar", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So m\u00f6gt ihr euch von unsern Tiefen scheiden,", "tokens": ["So", "m\u00f6gt", "ihr", "euch", "von", "un\u00b7sern", "Tie\u00b7fen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bis euch die h\u00f6chste Wolke k\u00fc\u00dft!", "tokens": ["Bis", "euch", "die", "h\u00f6chs\u00b7te", "Wol\u00b7ke", "k\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mein Weg f\u00fchrt mich, Gottlob! nicht \u00fcber eure Spitzen,", "tokens": ["Mein", "Weg", "f\u00fchrt", "mich", ",", "Gott\u00b7lob", "!", "nicht", "\u00fc\u00b7ber", "eu\u00b7re", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "NN", "$.", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch nicht durch eurer Th\u00e4ler Ritzen.", "tokens": ["Auch", "nicht", "durch", "eu\u00b7rer", "Th\u00e4\u00b7ler", "Rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.20": {"line.1": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Man sieht der sch\u00f6nen Stadt erhabne Zinnen gl\u00e4nzen,", "tokens": ["Man", "sieht", "der", "sch\u00f6\u00b7nen", "Stadt", "er\u00b7hab\u00b7ne", "Zin\u00b7nen", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihre Br\u00fccke zeigt sich hier.", "tokens": ["Und", "ih\u00b7re", "Br\u00fc\u00b7cke", "zeigt", "sich", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein b\u00e4rtig Volk, nach Art der alten Zeiten,", "tokens": ["Ein", "b\u00e4r\u00b7tig", "Volk", ",", "nach", "Art", "der", "al\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Umringt mein volles Schiff an ihren Ufern schon.", "tokens": ["Um\u00b7ringt", "mein", "vol\u00b7les", "Schiff", "an", "ih\u00b7ren", "U\u00b7fern", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Mautner Schaar durchsuchts an allen Seiten,", "tokens": ["Der", "Maut\u00b7ner", "Schaar", "durch\u00b7suchts", "an", "al\u00b7len", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und spricht verbothnem Handel Hohn.", "tokens": ["Und", "spricht", "ver\u00b7both\u00b7nem", "Han\u00b7del", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So scheint die Donau mir, bey Inseln, Bergen, Schl\u00f6ssern,", "tokens": ["So", "scheint", "die", "Do\u00b7nau", "mir", ",", "bey", "In\u00b7seln", ",", "Ber\u00b7gen", ",", "Schl\u00f6s\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "PPER", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-----+-+-+-", "measure": "dactylic.init"}, "line.10": {"text": "Den Schauplatz immer zu vergr\u00f6\u00dfern.", "tokens": ["Den", "Schau\u00b7platz", "im\u00b7mer", "zu", "ver\u00b7gr\u00f6\u00b7\u00dfern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Man sieht die Stadt, der sie den Namen giebet.", "tokens": ["Man", "sieht", "die", "Stadt", ",", "der", "sie", "den", "Na\u00b7men", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Flur versch\u00f6nert sich, die auch der Adel liebet,", "tokens": ["Die", "Flur", "ver\u00b7sch\u00f6\u00b7nert", "sich", ",", "die", "auch", "der", "A\u00b7del", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem sie die sch\u00f6nsten Sitze gab.", "tokens": ["Dem", "sie", "die", "sch\u00f6ns\u00b7ten", "Sit\u00b7ze", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du ", "tokens": ["Du"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Dein Schlo\u00df liegt ungemein und \u00fcbersieht den Flu\u00df.", "tokens": ["Dein", "Schlo\u00df", "liegt", "un\u00b7ge\u00b7mein", "und", "\u00fc\u00b7ber\u00b7sieht", "den", "Flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Wirbel nur mit seinen schnellen Kreisen", "tokens": ["Der", "Wir\u00b7bel", "nur", "mit", "sei\u00b7nen", "schnel\u00b7len", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Macht, da\u00df man dich fast scheuen mu\u00df;", "tokens": ["Macht", ",", "da\u00df", "man", "dich", "fast", "scheu\u00b7en", "mu\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Indem der starke Strom auf deine Felsen sprudelt,", "tokens": ["In\u00b7dem", "der", "star\u00b7ke", "Strom", "auf", "dei\u00b7ne", "Fel\u00b7sen", "spru\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und seitw\u00e4rts in die Runde strudelt.", "tokens": ["Und", "seit\u00b7w\u00e4rts", "in", "die", "Run\u00b7de", "stru\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.22": {"line.1": {"text": "Der bl\u00f6de Schiffer zagt, sein Steuermann ist bleich,", "tokens": ["Der", "bl\u00f6\u00b7de", "Schif\u00b7fer", "zagt", ",", "sein", "Steu\u00b7er\u00b7mann", "ist", "bleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Reisenden bedroht der Wellen Sausen:", "tokens": ["Die", "Rei\u00b7sen\u00b7den", "be\u00b7droht", "der", "Wel\u00b7len", "Sau\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Man h\u00f6rt von weitem schon die Fluth auf Steinen brausen.", "tokens": ["Man", "h\u00f6rt", "von", "wei\u00b7tem", "schon", "die", "Fluth", "auf", "Stei\u00b7nen", "brau\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIS", "ADV", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und n\u00e4her schreckt der Blick zugleich.", "tokens": ["Und", "n\u00e4\u00b7her", "schreckt", "der", "Blick", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht ein Fels, um dessen scharfe Spitzen", "tokens": ["Hier", "steht", "ein", "Fels", ",", "um", "des\u00b7sen", "schar\u00b7fe", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KOUI", "PDS", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Strom jahraus jahrein mit wildem Strudel sch\u00e4umt.", "tokens": ["Der", "Strom", "ja\u00b7hraus", "ja\u00b7hrein", "mit", "wil\u00b7dem", "Stru\u00b7del", "sch\u00e4umt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der wei\u00dfe J\u00e4scht beginnt empor zu spr\u00fctzen,", "tokens": ["Der", "wei\u00b7\u00dfe", "J\u00e4scht", "be\u00b7ginnt", "em\u00b7por", "zu", "spr\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wenn sich die n\u00e4chste Welle b\u00e4umt:", "tokens": ["Wenn", "sich", "die", "n\u00e4chs\u00b7te", "Wel\u00b7le", "b\u00e4umt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Doch Klugheit und Geschick, entziehn uns den Gefahren,", "tokens": ["Doch", "Klug\u00b7heit", "und", "Ge\u00b7schick", ",", "ent\u00b7ziehn", "uns", "den", "Ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bevor wir recht erschrocken waren.", "tokens": ["Be\u00b7vor", "wir", "recht", "er\u00b7schro\u00b7cken", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.23": {"line.1": {"text": "Wer keine See gesehn, der f\u00fcrchtet hier den Tod;", "tokens": ["Wer", "kei\u00b7ne", "See", "ge\u00b7sehn", ",", "der", "f\u00fcrch\u00b7tet", "hier", "den", "Tod", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "VVPP", "$,", "PRELS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn Fluth und Schaum sich etwas lebhaft zeigen.", "tokens": ["Wenn", "Fluth", "und", "Schaum", "sich", "et\u00b7was", "leb\u00b7haft", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch wer dich, ", "tokens": ["Doch", "wer", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Der sieht allhier noch keine Noth.", "tokens": ["Der", "sieht", "all\u00b7hier", "noch", "kei\u00b7ne", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sollt ein Schiff, im Wirbel sich zerschmettern;", "tokens": ["Und", "sollt", "ein", "Schiff", ",", "im", "Wir\u00b7bel", "sich", "zer\u00b7schmet\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "$,", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Des nahen Ufers Rand erh\u00e4lt mein Leben schon.", "tokens": ["Des", "na\u00b7hen", "U\u00b7fers", "Rand", "er\u00b7h\u00e4lt", "mein", "Le\u00b7ben", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer rettet sich im Schiffbruch, als auf Brettern?", "tokens": ["Wer", "ret\u00b7tet", "sich", "im", "Schiff\u00b7bruch", ",", "als", "auf", "Bret\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPRART", "NN", "$,", "KOUS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wer spricht wohl da den St\u00fcrmen Hohn?", "tokens": ["Wer", "spricht", "wohl", "da", "den", "St\u00fcr\u00b7men", "Hohn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hier kann mein langer Kahn den Strudel leicht bezwingen:", "tokens": ["Hier", "kann", "mein", "lan\u00b7ger", "Kahn", "den", "Stru\u00b7del", "leicht", "be\u00b7zwin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dort mu\u00df das gr\u00f6\u00dfte Kriegsschiff springen.", "tokens": ["Dort", "mu\u00df", "das", "gr\u00f6\u00df\u00b7te", "Kriegs\u00b7schiff", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.24": {"line.1": {"text": "Was sag ich von dem Schlo\u00df, das die von", "tokens": ["Was", "sag", "ich", "von", "dem", "Schlo\u00df", ",", "das", "die", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "ART", "APPR"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und weiter her, ", "tokens": ["Und", "wei\u00b7ter", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wer diese Gegend sieht, der kann sie nicht vergessen,", "tokens": ["Wer", "die\u00b7se", "Ge\u00b7gend", "sieht", ",", "der", "kann", "sie", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "PRELS", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als aller Klugen Augenmerk.", "tokens": ["Als", "al\u00b7ler", "Klu\u00b7gen", "Au\u00b7gen\u00b7merk", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Kl\u00f6ster! ihr, die ihr an so viel Stellen,", "tokens": ["Ihr", "Kl\u00f6s\u00b7ter", "!", "ihr", ",", "die", "ihr", "an", "so", "viel", "Stel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "$,", "PRELS", "PPER", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Pall\u00e4sten \u00e4hnlich seht, und halbe Wunder zeigt!", "tokens": ["Pal\u00b7l\u00e4s\u00b7ten", "\u00e4hn\u00b7lich", "seht", ",", "und", "hal\u00b7be", "Wun\u00b7der", "zeigt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Besonders du, um das mit treuen Wellen,", "tokens": ["Be\u00b7son\u00b7ders", "du", ",", "um", "das", "mit", "treu\u00b7en", "Wel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "KOUI", "ART", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Donaustrom sich schmiegend beugt;", "tokens": ["Der", "Do\u00b7naus\u00b7trom", "sich", "schmie\u00b7gend", "beugt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "O M\u00f6lk! dein hoher Bau besch\u00e4met F\u00fcrstenh\u00e4user,", "tokens": ["O", "M\u00f6lk", "!", "dein", "ho\u00b7her", "Bau", "be\u00b7sch\u00e4\u00b7met", "F\u00fcrs\u00b7ten\u00b7h\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPOSAT", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und regt den Neid erhabner Kaiser.", "tokens": ["Und", "regt", "den", "Neid", "er\u00b7hab\u00b7ner", "Kai\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "O sollt ich dich doch auch mit eifriger Begier,", "tokens": ["O", "sollt", "ich", "dich", "doch", "auch", "mit", "eif\u00b7ri\u00b7ger", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von innen her durchwandern und betrachten!", "tokens": ["Von", "in\u00b7nen", "her", "durch\u00b7wan\u00b7dern", "und", "be\u00b7trach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie hoch w\u00fcrd ich den Schatz der Alterth\u00fcmer achten,", "tokens": ["Wie", "hoch", "w\u00fcrd", "ich", "den", "Schatz", "der", "Al\u00b7tert\u00b7h\u00fc\u00b7mer", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als deiner Mauren sch\u00f6nste Zier.", "tokens": ["Als", "dei\u00b7ner", "Mau\u00b7ren", "sch\u00f6ns\u00b7te", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Alten Witz lebt hier in tausend B\u00fcchern,", "tokens": ["Der", "Al\u00b7ten", "Witz", "lebt", "hier", "in", "tau\u00b7send", "B\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und k\u00f6nnte meinem Geist ein s\u00fc\u00dfes Labsal seyn.", "tokens": ["Und", "k\u00f6nn\u00b7te", "mei\u00b7nem", "Geist", "ein", "s\u00fc\u00b7\u00dfes", "Lab\u00b7sal", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein gleiches k\u00f6nnt ich mich von dir versichern,", "tokens": ["Ein", "glei\u00b7ches", "k\u00f6nnt", "ich", "mich", "von", "dir", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Allein der schnelle Flu\u00df, der mich vor\u00fcber f\u00fchret,", "tokens": ["Al\u00b7lein", "der", "schnel\u00b7le", "Flu\u00df", ",", "der", "mich", "vor\u00b7\u00fc\u00b7ber", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Macht, da\u00df mein Fu\u00df kein Land ber\u00fchret.", "tokens": ["Macht", ",", "da\u00df", "mein", "Fu\u00df", "kein", "Land", "be\u00b7r\u00fch\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.26": {"line.1": {"text": "Du weiser Antonin, desgleichen keine Zeit", "tokens": ["Du", "wei\u00b7ser", "An\u00b7to\u00b7nin", ",", "des\u00b7glei\u00b7chen", "kei\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch auf dem Thron als Herrscher hat gesehen.", "tokens": ["Noch", "auf", "dem", "Thron", "als", "Herr\u00b7scher", "hat", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich d\u00fcnkt, ich seh den Zug, der sonst von dir geschehen,", "tokens": ["Mich", "d\u00fcnkt", ",", "ich", "seh", "den", "Zug", ",", "der", "sonst", "von", "dir", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An Spuren deiner Menschlichkeit.", "tokens": ["An", "Spu\u00b7ren", "dei\u00b7ner", "Menschlich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Doch sah sie auch an dir die Weisheit, den Verstand;", "tokens": ["Doch", "sah", "sie", "auch", "an", "dir", "die", "Weis\u00b7heit", ",", "den", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPER", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Und ehrte stets bey fehlgeschlagnen Siegen,", "tokens": ["Und", "ehr\u00b7te", "stets", "bey", "fehl\u00b7ge\u00b7schlag\u00b7nen", "Sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den Kiel in deiner klugen Hand:", "tokens": ["Den", "Kiel", "in", "dei\u00b7ner", "klu\u00b7gen", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der, wenn der Krieg dich gleich in Zelt und Harnisch brachte,", "tokens": ["Der", ",", "wenn", "der", "Krieg", "dich", "gleich", "in", "Zelt", "und", "Har\u00b7nisch", "brach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "ART", "NN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Lager dich gesch\u00e4fftig machte.", "tokens": ["Im", "La\u00b7ger", "dich", "ge\u00b7sch\u00e4ff\u00b7tig", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.27": {"line.1": {"text": "Nun nimmt der Berge Grund des Bachus Leibtracht an,", "tokens": ["Nun", "nimmt", "der", "Ber\u00b7ge", "Grund", "des", "Ba\u00b7chus", "Leib\u00b7tracht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ART", "NE", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wo sich ", "tokens": ["Da", "wo", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PWAV", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der Reben s\u00fc\u00dfe Frucht h\u00e4ngt schon auf schweren Zweigen,", "tokens": ["Der", "Re\u00b7ben", "s\u00fc\u00b7\u00dfe", "Frucht", "h\u00e4ngt", "schon", "auf", "schwe\u00b7ren", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zeigt ein halbes Canaan.", "tokens": ["Und", "zeigt", "ein", "hal\u00b7bes", "Ca\u00b7naan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Der Boden sinkt und zeigt nun mildre Fl\u00e4chen,", "tokens": ["Der", "Bo\u00b7den", "sinkt", "und", "zeigt", "nun", "mild\u00b7re", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein ungemeines Land an Lag und Fruchtbarkeit;", "tokens": ["Ein", "un\u00b7ge\u00b7mei\u00b7nes", "Land", "an", "Lag", "und", "Frucht\u00b7bar\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Donaustrom, statt seinen Lauf zu schw\u00e4chen,", "tokens": ["Der", "Do\u00b7naus\u00b7trom", ",", "statt", "sei\u00b7nen", "Lauf", "zu", "schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verdoppelt seine L\u00fcsternheit:", "tokens": ["Ver\u00b7dop\u00b7pelt", "sei\u00b7ne", "L\u00fcs\u00b7tern\u00b7heit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und eilt viel schneller fort, auf meinem nassen Wagen,", "tokens": ["Und", "eilt", "viel", "schnel\u00b7ler", "fort", ",", "auf", "mei\u00b7nem", "nas\u00b7sen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mich in den ", "tokens": ["Mich", "in", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.28": {"line.1": {"text": "In einer Stunde geht mein Lauf zwo Meilen fort:", "tokens": ["In", "ei\u00b7ner", "Stun\u00b7de", "geht", "mein", "Lauf", "zwo", "Mei\u00b7len", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein schnelles Ro\u00df kann kaum geschwinder eilen.", "tokens": ["Ein", "schnel\u00b7les", "Ro\u00df", "kann", "kaum", "ge\u00b7schwin\u00b7der", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es zeigt sich ", "tokens": ["Es", "zeigt", "sich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wir suchen einen andern Port.", "tokens": ["Wir", "su\u00b7chen", "ei\u00b7nen", "an\u00b7dern", "Port", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was seh ich dort mit seinen Kronen prangen?", "tokens": ["Was", "seh", "ich", "dort", "mit", "sei\u00b7nen", "Kro\u00b7nen", "pran\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ach! ", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Mit was f\u00fcr Gegenden bist du, o ", "tokens": ["Mit", "was", "f\u00fcr", "Ge\u00b7gen\u00b7den", "bist", "du", ",", "o"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "VAFIN", "PPER", "$,", "FM"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Ich seh die Th\u00fcrme, die du hast!", "tokens": ["Ich", "seh", "die", "Th\u00fcr\u00b7me", ",", "die", "du", "hast", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Musen, itzt genug! Die Stadt will n\u00e4her r\u00fccken:", "tokens": ["Ihr", "Mu\u00b7sen", ",", "itzt", "ge\u00b7nug", "!", "Die", "Stadt", "will", "n\u00e4\u00b7her", "r\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "$.", "ART", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "La\u00dft k\u00fcnftig mir die Reime gl\u00fccken.", "tokens": ["La\u00dft", "k\u00fcnf\u00b7tig", "mir", "die", "Rei\u00b7me", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.29": {"line.1": {"text": "So sey mir nun gegr\u00fc\u00dft, du deutscher Tyberstrom!", "tokens": ["So", "sey", "mir", "nun", "ge\u00b7gr\u00fc\u00dft", ",", "du", "deut\u00b7scher", "Ty\u00b7ber\u00b7strom", "!"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "VVPP", "$,", "PPER", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Empfange mich, auf deinem breiten R\u00fccken!", "tokens": ["Emp\u00b7fan\u00b7ge", "mich", ",", "auf", "dei\u00b7nem", "brei\u00b7ten", "R\u00fc\u00b7cken", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und f\u00fchre mich mit dir, und la\u00df mich bald erblicken", "tokens": ["Und", "f\u00fch\u00b7re", "mich", "mit", "dir", ",", "und", "la\u00df", "mich", "bald", "er\u00b7bli\u00b7cken"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PRF", "APPR", "PPER", "$,", "KON", "VVIMP", "PPER", "ADV", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der neuen Zeit erhabnes Rom!", "tokens": ["Der", "neu\u00b7en", "Zeit", "er\u00b7hab\u00b7nes", "Rom", "!"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich strebte l\u00e4ngst, die Kaiserstadt zu sehen,", "tokens": ["Ich", "streb\u00b7te", "l\u00e4ngst", ",", "die", "Kai\u00b7ser\u00b7stadt", "zu", "se\u00b7hen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "ART", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die aller Deutschen Haupt, der Fremden Wunder ist:", "tokens": ["Die", "al\u00b7ler", "Deut\u00b7schen", "Haupt", ",", "der", "Frem\u00b7den", "Wun\u00b7der", "ist", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "ADJA", "NN", "$,", "ART", "NN", "NN", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Itzt soll mein Wunsch, mein alter Wunsch geschehen,", "tokens": ["Itzt", "soll", "mein", "Wunsch", ",", "mein", "al\u00b7ter", "Wunsch", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "$,", "PPOSAT", "ADJA", "NN", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wo du der Absicht g\u00fcnstig bist;", "tokens": ["Wo", "du", "der", "Ab\u00b7sicht", "g\u00fcns\u00b7tig", "bist", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wo deine Silberfluth mich nur in wenig Tagen", "tokens": ["Wo", "dei\u00b7ne", "Sil\u00b7ber\u00b7fluth", "mich", "nur", "in", "we\u00b7nig", "Ta\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PPOSAT", "NN", "PPER", "ADV", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Aus Bayerland nach Wien will tragen.", "tokens": ["Aus", "Bay\u00b7er\u00b7land", "nach", "Wi\u00b7en", "will", "tra\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "APPR", "NE", "VMFIN", "VVINF", "$."], "meter": "-+-+-+--+-", "measure": "iambic.tetra.relaxed"}}, "stanza.30": {"line.1": {"text": "La\u00df ein verf\u00fchrtes Herz, das nur nach Frankreich lechzt,", "tokens": ["La\u00df", "ein", "ver\u00b7f\u00fchr\u00b7tes", "Herz", ",", "das", "nur", "nach", "Fran\u00b7kreich", "lechzt", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ART", "ADJA", "NN", "$,", "PRELS", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Blo\u00df nach Paris, als seinem Himmel st\u00f6hnen.", "tokens": ["Blo\u00df", "nach", "Pa\u00b7ris", ",", "als", "sei\u00b7nem", "Him\u00b7mel", "st\u00f6h\u00b7nen", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "$,", "KOUS", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "La\u00df sich der Stutzer Schaar nach Modeschneidern sehnen,", "tokens": ["La\u00df", "sich", "der", "Stut\u00b7zer", "Schaar", "nach", "Mo\u00b7de\u00b7schnei\u00b7dern", "seh\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "PRF", "ART", "NN", "NN", "APPR", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wie der nach deutschen Thalern \u00e4chzt!", "tokens": ["Wie", "der", "nach", "deut\u00b7schen", "Tha\u00b7lern", "\u00e4chzt", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ART", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Schleppt immerhin die ungrischen Ducaten,", "tokens": ["Schleppt", "im\u00b7mer\u00b7hin", "die", "un\u00b7gri\u00b7schen", "Du\u00b7ca\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Den Feinden Ungarlands, und aller Deutschen zu:", "tokens": ["Den", "Fein\u00b7den", "Un\u00b7gar\u00b7lands", ",", "und", "al\u00b7ler", "Deut\u00b7schen", "zu", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "KON", "PIAT", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "La\u00dft Deutschlands Mark in fremde Faust gerathen,", "tokens": ["La\u00dft", "Deutschlands", "Mark", "in", "frem\u00b7de", "Faust", "ge\u00b7ra\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "NE", "NN", "APPR", "ADJA", "NN", "VVPP", "$,"], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.8": {"text": "Zu St\u00f6rung unsrer k\u00fcnftgen Ruh:", "tokens": ["Zu", "St\u00f6\u00b7rung", "uns\u00b7rer", "k\u00fcnft\u00b7gen", "Ruh", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mich soll der Kaisersitz, den so viel Thoren fliehen,", "tokens": ["Mich", "soll", "der", "Kai\u00b7ser\u00b7sitz", ",", "den", "so", "viel", "Tho\u00b7ren", "flie\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NN", "$,", "PRELS", "ADV", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "In die ber\u00fchmten Mauren ziehen.", "tokens": ["In", "die", "be\u00b7r\u00fchm\u00b7ten", "Mau\u00b7ren", "zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.31": {"line.1": {"text": "Mich d\u00fcnkt, du bist bereit, und lockest mich zu dir.", "tokens": ["Mich", "d\u00fcnkt", ",", "du", "bist", "be\u00b7reit", ",", "und", "lo\u00b7ckest", "mich", "zu", "dir", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VAFIN", "ADJD", "$,", "KON", "VVFIN", "PPER", "APPR", "PPER", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Hier bin ich, komm! und la\u00df uns weiter eilen!", "tokens": ["Hier", "bin", "ich", ",", "komm", "!", "und", "la\u00df", "uns", "wei\u00b7ter", "ei\u00b7len", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "$,", "VVFIN", "$.", "KON", "VVIMP", "PPER", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das Schiff st\u00f6\u00dft wirklich ab; du willst dich nicht verweilen:", "tokens": ["Das", "Schiff", "st\u00f6\u00dft", "wirk\u00b7lich", "ab", ";", "du", "willst", "dich", "nicht", "ver\u00b7wei\u00b7len", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADJD", "PTKVZ", "$.", "PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und beyde Br\u00fccken fliehn vor mir.", "tokens": ["Und", "bey\u00b7de", "Br\u00fc\u00b7cken", "fliehn", "vor", "mir", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "VVINF", "APPR", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ich seh den ", "tokens": ["Ich", "seh", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.6": {"text": "Darein du dich zertheilt, umarmest und umringst.", "tokens": ["Da\u00b7rein", "du", "dich", "zer\u00b7theilt", ",", "um\u00b7ar\u00b7mest", "und", "um\u00b7ringst", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PAV", "PPER", "PRF", "VVPP", "$,", "VVFIN", "KON", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Nun kannst du dich gedoppelt breiter zeigen,", "tokens": ["Nun", "kannst", "du", "dich", "ge\u00b7dop\u00b7pelt", "brei\u00b7ter", "zei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "ADJD", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da du dein ganzes Wasser bringst;", "tokens": ["Da", "du", "dein", "gan\u00b7zes", "Was\u00b7ser", "bringst", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und, desto sch\u00f6ner noch mit starker Fluth zu prangen,", "tokens": ["Und", ",", "des\u00b7to", "sch\u00f6\u00b7ner", "noch", "mit", "star\u00b7ker", "Fluth", "zu", "pran\u00b7gen", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "$,", "ADV", "ADJD", "ADV", "APPR", "ADJA", "NN", "PTKZU", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Des ", "tokens": ["Des"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}}, "stanza.32": {"line.1": {"text": "Das gro\u00dfe ", "tokens": ["Das", "gro\u00b7\u00dfe"], "token_info": ["word", "word"], "pos": ["ART", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Der Th\u00fcrme Pracht scheint nach und nach zu sinken.", "tokens": ["Der", "Th\u00fcr\u00b7me", "Pracht", "scheint", "nach", "und", "nach", "zu", "sin\u00b7ken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVFIN", "APPR", "KON", "APPR", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.4": {"text": "Wo mirs an Wollust nicht gebrach.", "tokens": ["Wo", "mirs", "an", "Wol\u00b7lust", "nicht", "ge\u00b7brach", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "NE", "APPR", "NN", "PTKNEG", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sein B\u00fcchersaal ist des Pr\u00e4laten Ehre,", "tokens": ["Sein", "B\u00fc\u00b7cher\u00b7saal", "ist", "des", "Pr\u00e4\u00b7la\u00b7ten", "Eh\u00b7re", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ART", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der prangt mit altem Witz und neuer Sch\u00e4tze Pracht.", "tokens": ["Der", "prangt", "mit", "al\u00b7tem", "Witz", "und", "neu\u00b7er", "Sch\u00e4t\u00b7ze", "Pracht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "APPR", "ADJA", "NN", "KON", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein stolzer Bau giebt jeder Stadt die Lehre:", "tokens": ["Sein", "stol\u00b7zer", "Bau", "giebt", "je\u00b7der", "Stadt", "die", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PIAT", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Da\u00df Bauen Glanz und Ansehn macht.", "tokens": ["Da\u00df", "Bau\u00b7en", "Glanz", "und", "An\u00b7sehn", "macht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "NN", "KON", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und wird die\u00df Stift vollf\u00fchrt, so wird die Nachwelt lesen,", "tokens": ["Und", "wird", "die\u00df", "Stift", "voll\u00b7f\u00fchrt", ",", "so", "wird", "die", "Nach\u00b7welt", "le\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "PDS", "NN", "VVPP", "$,", "ADV", "VAFIN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie gro\u00df sein Bauherr itzt gewesen.", "tokens": ["Wie", "gro\u00df", "sein", "Bau\u00b7herr", "itzt", "ge\u00b7we\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "PPOSAT", "NN", "ADV", "VAPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.33": {"line.1": {"text": "Ich seh den alten ", "tokens": ["Ich", "seh", "den", "al\u00b7ten"], "token_info": ["word", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ART", "ADJA"], "meter": "-+-+-", "measure": "iambic.di"}, "line.2": {"text": "Nach Gothenart, ein Wunderbau gehei\u00dfen.", "tokens": ["Nach", "Go\u00b7then\u00b7art", ",", "ein", "Wun\u00b7der\u00b7bau", "ge\u00b7hei\u00b7\u00dfen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "$,", "ART", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Zeit, so stark sie ist, konnt ihn nicht niederrei\u00dfen;", "tokens": ["Die", "Zeit", ",", "so", "stark", "sie", "ist", ",", "konnt", "ihn", "nicht", "nie\u00b7der\u00b7rei\u00b7\u00dfen", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "ADV", "ADJD", "PPER", "VAFIN", "$,", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Weil er zu fest gegr\u00fcndet war.", "tokens": ["Weil", "er", "zu", "fest", "ge\u00b7gr\u00fcn\u00b7det", "war", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PTKA", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wo bleiben noch der andern Kl\u00f6ster Tempel;", "tokens": ["Wo", "blei\u00b7ben", "noch", "der", "an\u00b7dern", "Kl\u00f6s\u00b7ter", "Tem\u00b7pel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "ADV", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und die gedritte Zahl, wo unsre Br\u00fcder flehn?", "tokens": ["Und", "die", "ge\u00b7drit\u00b7te", "Zahl", ",", "wo", "uns\u00b7re", "Br\u00fc\u00b7der", "flehn", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "ADJA", "NN", "$,", "PWAV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Die alle bl\u00fchn; zum deutlichen Exempel,", "tokens": ["Die", "al\u00b7le", "bl\u00fchn", ";", "zum", "deut\u00b7li\u00b7chen", "Ex\u00b7em\u00b7pel", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "VVINF", "$.", "APPRART", "ADJA", "NN", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.8": {"text": "Da\u00df beyder Andacht kann bestehn;", "tokens": ["Da\u00df", "bey\u00b7der", "An\u00b7dacht", "kann", "be\u00b7stehn", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Da\u00df Christen beyder Art, beysammen friedlich bl\u00fchen,", "tokens": ["Da\u00df", "Chris\u00b7ten", "bey\u00b7der", "Art", ",", "bey\u00b7sam\u00b7men", "fried\u00b7lich", "bl\u00fc\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "PIAT", "NN", "$,", "VVFIN", "ADJD", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn sie der B\u00fcrger Pflicht vollziehen.", "tokens": ["Wenn", "sie", "der", "B\u00fcr\u00b7ger", "Pflicht", "voll\u00b7zie\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.34": {"line.1": {"text": "Ihr habt mir noch die alte Gunst erwiesen.", "tokens": ["Ihr", "habt", "mir", "noch", "die", "al\u00b7te", "Gunst", "er\u00b7wie\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.2": {"text": "Die Freundschaft Eurer Brust wird stets von mir gepriesen,", "tokens": ["Die", "Freund\u00b7schaft", "Eu\u00b7rer", "Brust", "wird", "stets", "von", "mir", "ge\u00b7prie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PPOSAT", "NN", "VAFIN", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Die ich ganz unver\u00e4ndert fand.", "tokens": ["Die", "ich", "ganz", "un\u00b7ver\u00b7\u00e4n\u00b7dert", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Was sag ich Euch, ", "tokens": ["Was", "sag", "ich", "Euch", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Ihr sch\u00fctzt das Recht des Volks der Protestanten,", "tokens": ["Ihr", "sch\u00fctzt", "das", "Recht", "des", "Volks", "der", "Pro\u00b7tes\u00b7tan\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Die man so eifrig unterdr\u00fcckt.", "tokens": ["Die", "man", "so", "eif\u00b7rig", "un\u00b7ter\u00b7dr\u00fcckt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIS", "ADV", "ADJD", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Der Himmel f\u00f6rdre stets das Werk von Euren H\u00e4nden!", "tokens": ["Der", "Him\u00b7mel", "f\u00f6rd\u00b7re", "stets", "das", "Werk", "von", "Eu\u00b7ren", "H\u00e4n\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ART", "NN", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Und helf es, uns zum Schutz, vollenden!", "tokens": ["Und", "helf", "es", ",", "uns", "zum", "Schutz", ",", "voll\u00b7en\u00b7den", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "$,", "PPER", "APPRART", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Was seh ich dort vor mir? Das hohe ", "tokens": ["Was", "seh", "ich", "dort", "vor", "mir", "?", "Das", "ho\u00b7he"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPER", "$.", "ART", "ADJA"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Ein festes Schlo\u00df, die ", "tokens": ["Ein", "fes\u00b7tes", "Schlo\u00df", ",", "die"], "token_info": ["word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS"], "meter": "-+-+-", "measure": "iambic.di"}, "line.3": {"text": "Es hatte vor der Zeit fast keines seines gleichen:", "tokens": ["Es", "hat\u00b7te", "vor", "der", "Zeit", "fast", "kei\u00b7nes", "sei\u00b7nes", "glei\u00b7chen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "ART", "NN", "ADV", "PIS", "PPOSAT", "ADJA", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Doch hub der Krieg die\u00df Vorrecht auf.", "tokens": ["Doch", "hub", "der", "Krieg", "die\u00df", "Vor\u00b7recht", "auf", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "PDS", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Als ", "tokens": ["Als"], "token_info": ["word"], "pos": ["KOUS"], "meter": "+", "measure": "single.up"}, "line.6": {"text": "Und durch sein siegend Schwert das ganze Reich durchdrang,", "tokens": ["Und", "durch", "sein", "sie\u00b7gend", "Schwert", "das", "gan\u00b7ze", "Reich", "durch\u00b7drang", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "PPOSAT", "CARD", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Zerbrach er das, was ihm nicht ferner n\u00fctzte.", "tokens": ["Zer\u00b7brach", "er", "das", ",", "was", "ihm", "nicht", "fer\u00b7ner", "n\u00fctz\u00b7te", "."], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PDS", "$,", "PWS", "PPER", "PTKNEG", "ADV", "VVFIN", "$."], "meter": "-+-+---+-+-", "measure": "unknown.measure.tetra"}, "line.8": {"text": "So spielt des harten Schicksals Zwang!", "tokens": ["So", "spielt", "des", "har\u00b7ten", "Schick\u00b7sals", "Zwang", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der, was der Menschen Hand seit langer Zeit verehret,", "tokens": ["Der", ",", "was", "der", "Men\u00b7schen", "Hand", "seit", "lan\u00b7ger", "Zeit", "ver\u00b7eh\u00b7ret", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "PRELS", "ART", "NN", "NN", "APPR", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wenn seine Stunde k\u00f6mmt, zerst\u00f6ret.", "tokens": ["Wenn", "sei\u00b7ne", "Stun\u00b7de", "k\u00f6mmt", ",", "zer\u00b7st\u00f6\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "VVFIN", "$,", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.36": {"line.1": {"text": "Du selbst ber\u00fchmter Strom, kannst hier ein Zeuge seyn:", "tokens": ["Du", "selbst", "be\u00b7r\u00fchm\u00b7ter", "Strom", ",", "kannst", "hier", "ein", "Zeu\u00b7ge", "seyn", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADJA", "NN", "$,", "VMFIN", "ADV", "ART", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Warst du nicht sonst die Brustwehr deutscher Lande?", "tokens": ["Warst", "du", "nicht", "sonst", "die", "Brust\u00b7wehr", "deut\u00b7scher", "Lan\u00b7de", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "PTKNEG", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Und trugst du gleich einmal der Knechtschaft harte Bande,", "tokens": ["Und", "trugst", "du", "gleich", "ein\u00b7mal", "der", "Knecht\u00b7schaft", "har\u00b7te", "Ban\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Bliebst du doch freyer, als der Rhein.", "tokens": ["Bliebst", "du", "doch", "frey\u00b7er", ",", "als", "der", "Rhein", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ADJD", "$,", "KOUS", "ART", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein siegend Volk von unbezwungnen Gothen", "tokens": ["Ein", "sie\u00b7gend", "Volk", "von", "un\u00b7be\u00b7zwung\u00b7nen", "Go\u00b7then"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "CARD", "NN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "K\u00f6mmt vom Euxin herauf, und sch\u00fctzet deinen Strand,", "tokens": ["K\u00f6mmt", "vom", "Eu\u00b7xin", "her\u00b7auf", ",", "und", "sch\u00fct\u00b7zet", "dei\u00b7nen", "Strand", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPRART", "NE", "PTKVZ", "$,", "KON", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Hat alle Macht des Nordens aufgebothen,", "tokens": ["Hat", "al\u00b7le", "Macht", "des", "Nor\u00b7dens", "auf\u00b7ge\u00b7bo\u00b7then", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIAT", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00fcrzet in der R\u00f6mer Land;", "tokens": ["Und", "st\u00fcr\u00b7zet", "in", "der", "R\u00f6\u00b7mer", "Land", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und r\u00e4cht den bittern Schimpf, der Deutschland sonst beschweret,", "tokens": ["Und", "r\u00e4cht", "den", "bit\u00b7tern", "Schimpf", ",", "der", "Deutschland", "sonst", "be\u00b7schwe\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NN", "$,", "ART", "NN", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+--+-", "measure": "iambic.penta.relaxed"}, "line.10": {"text": "Indem es W\u00e4lschland selbst verheeret.", "tokens": ["In\u00b7dem", "es", "W\u00e4l\u00b7schland", "selbst", "ver\u00b7hee\u00b7ret", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.37": {"line.1": {"text": "Was zeigt mir linkerhand die\u00df halb umschlo\u00dfne Thal?", "tokens": ["Was", "zeigt", "mir", "lin\u00b7ker\u00b7hand", "die\u00df", "halb", "um\u00b7schlo\u00df\u00b7ne", "Thal", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "VVFIN", "PDS", "ADJD", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ists ", "tokens": ["Ists"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Ja, ja, ich seh es schon, mit sehnlicher Begierde,", "tokens": ["Ja", ",", "ja", ",", "ich", "seh", "es", "schon", ",", "mit", "sehn\u00b7li\u00b7cher", "Be\u00b7gier\u00b7de", ","], "token_info": ["word", "punct", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PTKANT", "$,", "PPER", "VVFIN", "PPER", "ADV", "$,", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und lobe seiner Th\u00fcrme Zahl.", "tokens": ["Und", "lo\u00b7be", "sei\u00b7ner", "Th\u00fcr\u00b7me", "Zahl", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Stra\u00dfen Bau, die Lebensart der Leute,", "tokens": ["Der", "Stra\u00b7\u00dfen", "Bau", ",", "die", "Le\u00b7ben\u00b7sart", "der", "Leu\u00b7te", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "$,", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Verk\u00fcndigt mir gewi\u00df ein gutes Nachtquartier.", "tokens": ["Ver\u00b7k\u00fcn\u00b7digt", "mir", "ge\u00b7wi\u00df", "ein", "gu\u00b7tes", "Nacht\u00b7quar\u00b7tier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Ort ward nicht des letzten Krieges Beute,", "tokens": ["Der", "Ort", "ward", "nicht", "des", "letz\u00b7ten", "Krie\u00b7ges", "Beu\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PTKNEG", "ART", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die tapfern Sch\u00fctzen fochten hier.", "tokens": ["Die", "tap\u00b7fern", "Sch\u00fct\u00b7zen", "foch\u00b7ten", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Kein Haus ist hier versehrt, kein Tempel ward verletzet,", "tokens": ["Kein", "Haus", "ist", "hier", "ver\u00b7sehrt", ",", "kein", "Tem\u00b7pel", "ward", "ver\u00b7let\u00b7zet", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "VVPP", "$,", "PIAT", "NN", "VAFIN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "So sehr man Straubing zugesetzet.", "tokens": ["So", "sehr", "man", "Strau\u00b7bing", "zu\u00b7ge\u00b7set\u00b7zet", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PIS", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.38": {"line.1": {"text": "Du armes ", "tokens": ["Du", "ar\u00b7mes"], "token_info": ["word", "word"], "pos": ["PPER", "ADJA"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Als sich der Krieg in Bayern angesponnen.", "tokens": ["Als", "sich", "der", "Krieg", "in", "Bay\u00b7ern", "an\u00b7ge\u00b7spon\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "NN", "APPR", "NE", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Der Feind hat dich umringt, belagert und gewonnen,", "tokens": ["Der", "Feind", "hat", "dich", "um\u00b7ringt", ",", "be\u00b7la\u00b7gert", "und", "ge\u00b7won\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "VVFIN", "$,", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Land, Th\u00fcrm' und Tempel zeigens mir.", "tokens": ["Land", ",", "Th\u00fcrm'", "und", "Tem\u00b7pel", "zei\u00b7gens", "mir", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "NN", "KON", "NN", "VVFIN", "PPER", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie kl\u00e4glich tobt der Menschen Lust zum Morden!", "tokens": ["Wie", "kl\u00e4g\u00b7lich", "tobt", "der", "Men\u00b7schen", "Lust", "zum", "Mor\u00b7den", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VVFIN", "ART", "NN", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Was wirkt die Kriegswuth nicht, wenn sie einmal entbrannt?", "tokens": ["Was", "wirkt", "die", "Kriegs\u00b7wuth", "nicht", ",", "wenn", "sie", "ein\u00b7mal", "ent\u00b7brannt", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KOUS", "PPER", "ADV", "VVPP", "$."], "meter": "-+-+-+--+--+", "measure": "iambic.penta.relaxed"}, "line.7": {"text": "Sie schonet nichts, was kaum erbauet worden,", "tokens": ["Sie", "scho\u00b7net", "nichts", ",", "was", "kaum", "er\u00b7bau\u00b7et", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "$,", "PRELS", "ADV", "VVPP", "VAPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und st\u00fcrzt das Volk in Jammerstand.", "tokens": ["Und", "st\u00fcrzt", "das", "Volk", "in", "Jam\u00b7mer\u00b7stand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "APPR", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Viel Jahre werden hier, ihr ungerechten Lilgen!", "tokens": ["Viel", "Jah\u00b7re", "wer\u00b7den", "hier", ",", "ihr", "un\u00b7ge\u00b7rech\u00b7ten", "Lil\u00b7gen", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "VAFIN", "ADV", "$,", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Nicht eurer Herrschsucht Spuren tilgen.", "tokens": ["Nicht", "eu\u00b7rer", "Herrschsucht", "Spu\u00b7ren", "til\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "PPOSAT", "NN", "NN", "VVINF", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.39": {"line.1": {"text": "Ber\u00fchmter ", "tokens": ["Be\u00b7r\u00fchm\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Du k\u00f6mmst herab von M\u00fcnchens edlen H\u00f6hen.", "tokens": ["Du", "k\u00f6mmst", "her\u00b7ab", "von", "M\u00fcn\u00b7chens", "ed\u00b7len", "H\u00f6\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "APPR", "NE", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Durch deinen Freundschaftsbund mu\u00dft unsre Lust entstehen,", "tokens": ["Durch", "dei\u00b7nen", "Freund\u00b7schafts\u00b7bund", "mu\u00dft", "uns\u00b7re", "Lust", "ent\u00b7ste\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "VMFIN", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Vermehrte deine Freude sich.", "tokens": ["Ver\u00b7mehr\u00b7te", "dei\u00b7ne", "Freu\u00b7de", "sich", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "PRF", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ist Sachsens Augenlust und deines Ufers Preis!", "tokens": ["Ist", "Sach\u00b7sens", "Au\u00b7gen\u00b7lust", "und", "dei\u00b7nes", "U\u00b7fers", "Preis", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "NN", "NN", "KON", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "Wie huldreich ist die Gro\u00dfmuth Ihrer Jugend!", "tokens": ["Wie", "huld\u00b7reich", "ist", "die", "Gro\u00df\u00b7muth", "Ih\u00b7rer", "Ju\u00b7gend", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "ART", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Wovon ich selbst die Proben weis;", "tokens": ["Wo\u00b7von", "ich", "selbst", "die", "Pro\u00b7ben", "weis", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ART", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Hat ", "tokens": ["Hat"], "token_info": ["word"], "pos": ["VAFIN"], "meter": "-", "measure": "single.down"}, "line.9": {"text": "Seit sie Dein Churf\u00fcrst heimgef\u00fchret?", "tokens": ["Seit", "sie", "Dein", "Chur\u00b7f\u00fcrst", "heim\u00b7ge\u00b7f\u00fch\u00b7ret", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.40": {"line.1": {"text": "Verbrannter ", "tokens": ["Ver\u00b7brann\u00b7ter"], "token_info": ["word"], "pos": ["NN"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Wie sehr der Krieg nicht l\u00e4ngst bey dir getobet.", "tokens": ["Wie", "sehr", "der", "Krieg", "nicht", "l\u00e4ngst", "bey", "dir", "ge\u00b7to\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "ART", "NN", "PTKNEG", "ADV", "APPR", "PPER", "VVPP", "$."], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der Donau, seiner F\u00fcrstinn, ein.", "tokens": ["Der", "Do\u00b7nau", ",", "sei\u00b7ner", "F\u00fcrs\u00b7tinn", ",", "ein", "."], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["ART", "NE", "$,", "PPOSAT", "NN", "$,", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.4": {"text": "Nun th\u00fcrmen sich auf beyden Seiten Berge,", "tokens": ["Nun", "th\u00fcr\u00b7men", "sich", "auf", "bey\u00b7den", "Sei\u00b7ten", "Ber\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PRF", "APPR", "PIAT", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.5": {"text": "Des breiten Stromes Fluth flie\u00dft eingeschr\u00e4nkter fort.", "tokens": ["Des", "brei\u00b7ten", "Stro\u00b7mes", "Fluth", "flie\u00dft", "ein\u00b7ge\u00b7schr\u00e4nk\u00b7ter", "fort", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "ADJD", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.6": {"text": "So sah man sonst die Schl\u00f6sser kleiner Zwerge,", "tokens": ["So", "sah", "man", "sonst", "die", "Schl\u00f6s\u00b7ser", "klei\u00b7ner", "Zwer\u00b7ge", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "ADV", "ART", "NN", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.7": {"text": "Und dichtete so manchen Ort,", "tokens": ["Und", "dich\u00b7te\u00b7te", "so", "man\u00b7chen", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.8": {"text": "Wo Ries' und Helden sich durch k\u00fchnes Unterfangen", "tokens": ["Wo", "Ries'", "und", "Hel\u00b7den", "sich", "durch", "k\u00fch\u00b7nes", "Un\u00b7ter\u00b7fan\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["PWAV", "NE", "KON", "NN", "PRF", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Im felsigten Gebirg vergangen.", "tokens": ["Im", "fel\u00b7sig\u00b7ten", "Ge\u00b7birg", "ver\u00b7gan\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.41": {"line.1": {"text": "F\u00fcrst ", "tokens": ["F\u00fcrst"], "token_info": ["word"], "pos": ["NN"], "meter": "+", "measure": "single.up"}, "line.2": {"text": "Beherrschten so der Alpen tiefste Gr\u00fcnde.", "tokens": ["Be\u00b7herrschten", "so", "der", "Al\u00b7pen", "tiefs\u00b7te", "Gr\u00fcn\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADV", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+--+-+-+-", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Tyrol und Steuermark bewahrten solche Schl\u00fcnde,", "tokens": ["Ty\u00b7rol", "und", "Steu\u00b7er\u00b7mark", "be\u00b7wahr\u00b7ten", "sol\u00b7che", "Schl\u00fcn\u00b7de", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als itzt kein Mensch zu finden weis.", "tokens": ["Als", "itzt", "kein", "Mensch", "zu", "fin\u00b7den", "weis", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ADV", "PIAT", "NN", "PTKZU", "VVINF", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Weg Fabelwerk! an diesen rohen Felsen", "tokens": ["Weg", "Fa\u00b7bel\u00b7werk", "!", "an", "die\u00b7sen", "ro\u00b7hen", "Fel\u00b7sen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["NN", "NN", "$.", "APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Stehn gleichwohl hin und her noch H\u00fctten angeklebt;", "tokens": ["Stehn", "gleich\u00b7wohl", "hin", "und", "her", "noch", "H\u00fct\u00b7ten", "an\u00b7ge\u00b7klebt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADV", "PTKVZ", "KON", "ADV", "ADV", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Darinn ein Volk mit Kr\u00f6pfen an den H\u00e4lsen,", "tokens": ["Da\u00b7rinn", "ein", "Volk", "mit", "Kr\u00f6p\u00b7fen", "an", "den", "H\u00e4l\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "ART", "NN", "APPR", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Vergn\u00fcgt in seinem Jammer lebt.", "tokens": ["Ver\u00b7gn\u00fcgt", "in", "sei\u00b7nem", "Jam\u00b7mer", "lebt", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Es kennt den Rest der Welt auch kaum vom H\u00f6rensagen:", "tokens": ["Es", "kennt", "den", "Rest", "der", "Welt", "auch", "kaum", "vom", "H\u00f6\u00b7ren\u00b7sa\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ART", "NN", "ADV", "ADV", "APPRART", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Wie k\u00f6nnt es sonst sein Nest ertragen?", "tokens": ["Wie", "k\u00f6nnt", "es", "sonst", "sein", "Nest", "er\u00b7tra\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "ADV", "PPOSAT", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.42": {"line.1": {"text": "Begl\u00fccktes Gemsenvolk! du weist nicht, was die Stadt", "tokens": ["Be\u00b7gl\u00fcck\u00b7tes", "Gem\u00b7sen\u00b7volk", "!", "du", "weist", "nicht", ",", "was", "die", "Stadt"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADJA", "NN", "$.", "PPER", "VVFIN", "PTKNEG", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "F\u00fcr Noth und Angst, bey ihrer Sch\u00f6nheit heget:", "tokens": ["F\u00fcr", "Noth", "und", "Angst", ",", "bey", "ih\u00b7rer", "Sch\u00f6n\u00b7heit", "he\u00b7get", ":"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Dir wird kein falsches Geld, zu deiner Quaal, gepr\u00e4get,", "tokens": ["Dir", "wird", "kein", "fal\u00b7sches", "Geld", ",", "zu", "dei\u00b7ner", "Qua\u00b7al", ",", "ge\u00b7pr\u00e4\u00b7get", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "VAFIN", "PIAT", "ADJA", "NN", "$,", "APPR", "PPOSAT", "NN", "$,", "VVPP", "$,"], "meter": "-+-+-+-+-+--+-", "measure": "iambic.hexa.relaxed"}, "line.4": {"text": "Das weder Werth noch Ansehn hat.", "tokens": ["Das", "we\u00b7der", "Werth", "noch", "An\u00b7sehn", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "KON", "NN", "ADV", "NN", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Dich plagt kein Geiz, der Wucher ist verbannet;", "tokens": ["Dich", "plagt", "kein", "Geiz", ",", "der", "Wu\u00b7cher", "ist", "ver\u00b7ban\u00b7net", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIAT", "NN", "$,", "ART", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Die Ehrsucht qu\u00e4lt dich nicht, bey Hofe gro\u00df zu seyn:", "tokens": ["Die", "Ehr\u00b7sucht", "qu\u00e4lt", "dich", "nicht", ",", "bey", "Ho\u00b7fe", "gro\u00df", "zu", "seyn", ":"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "PTKNEG", "$,", "APPR", "NN", "ADJD", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Du wirst ins Joch der Gro\u00dfen nicht gespannet,", "tokens": ["Du", "wirst", "ins", "Joch", "der", "Gro\u00b7\u00dfen", "nicht", "ge\u00b7span\u00b7net", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "APPRART", "NN", "ART", "NN", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und machst auch keinen Gro\u00dfen klein.", "tokens": ["Und", "machst", "auch", "kei\u00b7nen", "Gro\u00b7\u00dfen", "klein", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "PIAT", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ein Berg verstecket dich. Was ist dein Weltget\u00fcmmel?", "tokens": ["Ein", "Berg", "ver\u00b7ste\u00b7cket", "dich", ".", "Was", "ist", "dein", "Welt\u00b7ge\u00b7t\u00fcm\u00b7mel", "?"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$.", "PWS", "VAFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dein Fels, die Donau und der Himmel.", "tokens": ["Dein", "Fels", ",", "die", "Do\u00b7nau", "und", "der", "Him\u00b7mel", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "PRELS", "NE", "KON", "ART", "NN", "$."], "meter": "-+--+--+-", "measure": "amphibrach.tri"}}, "stanza.43": {"line.1": {"text": "So scheints: doch scheints auch nur. Wie elend lebt ein Mann,", "tokens": ["So", "scheints", ":", "doch", "scheints", "auch", "nur", ".", "Wie", "e\u00b7lend", "lebt", "ein", "Mann", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "$.", "ADV", "VVFIN", "ADV", "ADV", "$.", "PWAV", "ADJD", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Den die Gestalt kaum l\u00e4\u00dft zu Menschen z\u00e4hlen?", "tokens": ["Den", "die", "Ge\u00b7stalt", "kaum", "l\u00e4\u00dft", "zu", "Men\u00b7schen", "z\u00e4h\u00b7len", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ART", "NN", "ADV", "VVFIN", "APPR", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie viel gebricht ihm nicht, was sonder Gram und Qu\u00e4len", "tokens": ["Wie", "viel", "ge\u00b7bricht", "ihm", "nicht", ",", "was", "son\u00b7der", "Gram", "und", "Qu\u00e4\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["PWAV", "PIS", "VVFIN", "PPER", "PTKNEG", "$,", "PWS", "ADJA", "NN", "KON", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Uns die Gesellschaft liefern kann?", "tokens": ["Uns", "die", "Ge\u00b7sell\u00b7schaft", "lie\u00b7fern", "kann", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er lernt nicht sich, nicht andre Leute kennen.", "tokens": ["Er", "lernt", "nicht", "sich", ",", "nicht", "and\u00b7re", "Leu\u00b7te", "ken\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PTKNEG", "PRF", "$,", "PTKNEG", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Sein Gott, wird jeder Klotz, vor dem er murmelnd kniet;", "tokens": ["Sein", "Gott", ",", "wird", "je\u00b7der", "Klotz", ",", "vor", "dem", "er", "mur\u00b7melnd", "kniet", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "VAFIN", "PIAT", "NN", "$,", "APPR", "PRELS", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Den Heiligen weis er oft nicht zu nennen,", "tokens": ["Den", "Hei\u00b7li\u00b7gen", "weis", "er", "oft", "nicht", "zu", "nen\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PPER", "ADV", "PTKNEG", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+--+-", "measure": "iambic.tetra.relaxed"}, "line.8": {"text": "Den er mit dummer Ehrfurcht sieht.", "tokens": ["Den", "er", "mit", "dum\u00b7mer", "Ehr\u00b7furcht", "sieht", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wie will er, als ein Christ, das h\u00f6chste Wesen ehren,", "tokens": ["Wie", "will", "er", ",", "als", "ein", "Christ", ",", "das", "h\u00f6chs\u00b7te", "We\u00b7sen", "eh\u00b7ren", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VMFIN", "PPER", "$,", "KOUS", "ART", "NN", "$,", "ART", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Das niemand ihn will kennen lehren?", "tokens": ["Das", "nie\u00b7mand", "ihn", "will", "ken\u00b7nen", "leh\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PPER", "VMFIN", "VVINF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.44": {"line.1": {"text": "Dort zeigt sich ", "tokens": ["Dort", "zeigt", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Sein Cardinal verdient der B\u00fcrger Liebe.", "tokens": ["Sein", "Car\u00b7di\u00b7nal", "ver\u00b7dient", "der", "B\u00fcr\u00b7ger", "Lie\u00b7be", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Er dr\u00fcckt die Armen nicht, und folget keinem Triebe,", "tokens": ["Er", "dr\u00fcckt", "die", "Ar\u00b7men", "nicht", ",", "und", "fol\u00b7get", "kei\u00b7nem", "Trie\u00b7be", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PTKNEG", "$,", "KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Der ihre Quaal zur Wirkung hat.", "tokens": ["Der", "ih\u00b7re", "Qua\u00b7al", "zur", "Wir\u00b7kung", "hat", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VAFIN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Kein Schwelgen, Spiel, kein Jagen und Stolzieren,", "tokens": ["Kein", "Schwel\u00b7gen", ",", "Spiel", ",", "kein", "Ja\u00b7gen", "und", "Stol\u00b7zie\u00b7ren", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PIAT", "NN", "$,", "NN", "$,", "PIAT", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "In Kleidung und Gefolg, ersch\u00f6pft des Landes Mark.", "tokens": ["In", "Klei\u00b7dung", "und", "Ge\u00b7folg", ",", "er\u00b7sch\u00f6pft", "des", "Lan\u00b7des", "Mark", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "$,", "VVFIN", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Sein sch\u00f6ner Dom kann Aug und Herzen r\u00fchren,", "tokens": ["Sein", "sch\u00f6\u00b7ner", "Dom", "kann", "Aug", "und", "Her\u00b7zen", "r\u00fch\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VMFIN", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und ist an alter Baukunst stark.", "tokens": ["Und", "ist", "an", "al\u00b7ter", "Bau\u00b7kunst", "stark", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "APPR", "ADJA", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der ", "tokens": ["Der"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.10": {"text": "Um ihre Fluth mehr aufzuschwellen.", "tokens": ["Um", "ih\u00b7re", "Fluth", "mehr", "auf\u00b7zu\u00b7schwel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.45": {"line.1": {"text": "Wo bleibt der ", "tokens": ["Wo", "bleibt", "der"], "token_info": ["word", "word", "word"], "pos": ["PWAV", "VVFIN", "ART"], "meter": "-+-", "measure": "amphibrach.single"}, "line.2": {"text": "Ein seltner Schatz, den er dem Bischof reichet!", "tokens": ["Ein", "selt\u00b7ner", "Schatz", ",", "den", "er", "dem", "Bi\u00b7schof", "rei\u00b7chet", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Elster gleichet ihm, die Mei\u00dfens Flur durchstreichet,", "tokens": ["Die", "Els\u00b7ter", "glei\u00b7chet", "ihm", ",", "die", "Mei\u00b7\u00dfens", "Flur", "durch\u00b7strei\u00b7chet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "$,", "ART", "NN", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo sie bey Plauen sich ergeu\u00dft.", "tokens": ["Wo", "sie", "bey", "Plau\u00b7en", "sich", "er\u00b7geu\u00dft", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "NN", "PRF", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "O Deutschland! sey auf deinen Reichthum st\u00f6lzer!", "tokens": ["O", "Deutschland", "!", "sey", "auf", "dei\u00b7nen", "Reicht\u00b7hum", "st\u00f6l\u00b7zer", "!"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "$.", "VAFIN", "APPR", "PPOSAT", "NN", "ADJD", "$."], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.6": {"text": "Was fehlt dir ferner noch an Gl\u00fcck und Ueberflu\u00df?", "tokens": ["Was", "fehlt", "dir", "fer\u00b7ner", "noch", "an", "Gl\u00fcck", "und", "Ue\u00b7berf\u00b7lu\u00df", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "ADV", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Dein Boden zinst Metalle, Marmor, H\u00f6lzer,", "tokens": ["Dein", "Bo\u00b7den", "zinst", "Me\u00b7tal\u00b7le", ",", "Mar\u00b7mor", ",", "H\u00f6l\u00b7zer", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Die manches Land erborgen mu\u00df;", "tokens": ["Die", "man\u00b7ches", "Land", "er\u00b7bor\u00b7gen", "mu\u00df", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PIAT", "NN", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Wild, Viehzucht, Ackerbau, und reiche Fischereyen,", "tokens": ["Wild", ",", "Vieh\u00b7zucht", ",", "A\u00b7cker\u00b7bau", ",", "und", "rei\u00b7che", "Fi\u00b7sche\u00b7re\u00b7yen", ","], "token_info": ["word", "punct", "word", "punct", "word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "NN", "$,", "NN", "$,", "KON", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+--+", "measure": "iambic.hexa.chol.strict"}, "line.10": {"text": "Die dich mit Perlen auch erfreuen.", "tokens": ["Die", "dich", "mit", "Per\u00b7len", "auch", "er\u00b7freu\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PRF", "APPR", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Nun fleu\u00dft die Donau schnell, und breitet ihren Strand", "tokens": ["Nun", "fleu\u00dft", "die", "Do\u00b7nau", "schnell", ",", "und", "brei\u00b7tet", "ih\u00b7ren", "Strand"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NE", "ADJD", "$,", "KON", "VVFIN", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Gedoppelt aus, wenns Berg und Fels gestatten:", "tokens": ["Ge\u00b7dop\u00b7pelt", "aus", ",", "wenns", "Berg", "und", "Fels", "ge\u00b7stat\u00b7ten", ":"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "PTKVZ", "$,", "KOUS", "NN", "KON", "NN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Zuweilen tritt sie auch in dichter W\u00e4lder Schatten,", "tokens": ["Zu\u00b7wei\u00b7len", "tritt", "sie", "auch", "in", "dich\u00b7ter", "W\u00e4l\u00b7der", "Schat\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Wo ihre Fluth den Durchgang fand.", "tokens": ["Wo", "ih\u00b7re", "Fluth", "den", "Durch\u00b7gang", "fand", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPOSAT", "NN", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bald schweift sie auch in angenehmen Auen,", "tokens": ["Bald", "schweift", "sie", "auch", "in", "an\u00b7ge\u00b7neh\u00b7men", "Au\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Wo sich das Augenlicht an weiter Aussicht labt;", "tokens": ["Wo", "sich", "das", "Au\u00b7gen\u00b7licht", "an", "wei\u00b7ter", "Aus\u00b7sicht", "labt", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PRF", "ART", "NN", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wo ", "tokens": ["Wo"], "token_info": ["word"], "pos": ["PWAV"], "meter": "+", "measure": "single.up"}, "line.8": {"text": "Womit es die Natur begabt;", "tokens": ["Wo\u00b7mit", "es", "die", "Na\u00b7tur", "be\u00b7gabt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ART", "NN", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Die ungeschmolzner Schnee das ganze Jahr bedecket,", "tokens": ["Die", "un\u00b7ge\u00b7schmolz\u00b7ner", "Schnee", "das", "gan\u00b7ze", "Jahr", "be\u00b7de\u00b7cket", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und deren Anblick schon erschrecket.", "tokens": ["Und", "de\u00b7ren", "An\u00b7blick", "schon", "er\u00b7schre\u00b7cket", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PRELAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.47": {"line.1": {"text": "Was mir die Donau wies, sind Zwerge gegen euch,", "tokens": ["Was", "mir", "die", "Do\u00b7nau", "wies", ",", "sind", "Zwer\u00b7ge", "ge\u00b7gen", "euch", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ART", "NE", "VVFIN", "$,", "VAFIN", "NN", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ihr aber gleicht den ungeheuren Riesen!", "tokens": ["Ihr", "a\u00b7ber", "gleicht", "den", "un\u00b7ge\u00b7heu\u00b7ren", "Rie\u00b7sen", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Da eure Gipfel sich zehn Meilen weit gewiesen,", "tokens": ["Da", "eu\u00b7re", "Gip\u00b7fel", "sich", "zehn", "Mei\u00b7len", "weit", "ge\u00b7wie\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "PRF", "CARD", "NN", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Seyd ihr dem steilen Blocksberg gleich.", "tokens": ["Seyd", "ihr", "dem", "stei\u00b7len", "Blocks\u00b7berg", "gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAIMP", "PPER", "ART", "ADJA", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch, da das Mark von euren Eingeweiden", "tokens": ["Doch", ",", "da", "das", "Mark", "von", "eu\u00b7ren", "Ein\u00b7ge\u00b7wei\u00b7den"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "KOUS", "ART", "NN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "An Erzten, Zinn und Bley und Eisen fruchtbar ist;", "tokens": ["An", "Erz\u00b7ten", ",", "Zinn", "und", "Bley", "und", "Ei\u00b7sen", "frucht\u00b7bar", "ist", ";"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "NN", "KON", "NN", "KON", "NN", "ADJD", "VAFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "So m\u00f6gt ihr euch von unsern Tiefen scheiden,", "tokens": ["So", "m\u00f6gt", "ihr", "euch", "von", "un\u00b7sern", "Tie\u00b7fen", "schei\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPER", "PRF", "APPR", "PPOSAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Bis euch die h\u00f6chste Wolke k\u00fc\u00dft!", "tokens": ["Bis", "euch", "die", "h\u00f6chs\u00b7te", "Wol\u00b7ke", "k\u00fc\u00dft", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Mein Weg f\u00fchrt mich, Gottlob! nicht \u00fcber eure Spitzen,", "tokens": ["Mein", "Weg", "f\u00fchrt", "mich", ",", "Gott\u00b7lob", "!", "nicht", "\u00fc\u00b7ber", "eu\u00b7re", "Spit\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "PPER", "$,", "NN", "$.", "PTKNEG", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Auch nicht durch eurer Th\u00e4ler Ritzen.", "tokens": ["Auch", "nicht", "durch", "eu\u00b7rer", "Th\u00e4\u00b7ler", "Rit\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PTKNEG", "APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.48": {"line.1": {"text": "Das ", "tokens": ["Das"], "token_info": ["word"], "pos": ["PDS"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.3": {"text": "Man sieht der sch\u00f6nen Stadt erhabne Zinnen gl\u00e4nzen,", "tokens": ["Man", "sieht", "der", "sch\u00f6\u00b7nen", "Stadt", "er\u00b7hab\u00b7ne", "Zin\u00b7nen", "gl\u00e4n\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "ADJA", "NN", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und ihre Br\u00fccke zeigt sich hier.", "tokens": ["Und", "ih\u00b7re", "Br\u00fc\u00b7cke", "zeigt", "sich", "hier", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PRF", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein b\u00e4rtig Volk, nach Art der alten Zeiten,", "tokens": ["Ein", "b\u00e4r\u00b7tig", "Volk", ",", "nach", "Art", "der", "al\u00b7ten", "Zei\u00b7ten", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJD", "NN", "$,", "APPR", "NN", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Umringt mein volles Schiff an ihren Ufern schon.", "tokens": ["Um\u00b7ringt", "mein", "vol\u00b7les", "Schiff", "an", "ih\u00b7ren", "U\u00b7fern", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "ADJA", "NN", "APPR", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Mautner Schaar durchsuchts an allen Seiten,", "tokens": ["Der", "Maut\u00b7ner", "Schaar", "durch\u00b7suchts", "an", "al\u00b7len", "Sei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Und spricht verbothnem Handel Hohn.", "tokens": ["Und", "spricht", "ver\u00b7both\u00b7nem", "Han\u00b7del", "Hohn", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "So scheint die Donau mir, bey Inseln, Bergen, Schl\u00f6ssern,", "tokens": ["So", "scheint", "die", "Do\u00b7nau", "mir", ",", "bey", "In\u00b7seln", ",", "Ber\u00b7gen", ",", "Schl\u00f6s\u00b7sern", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "punct", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NE", "PPER", "$,", "APPR", "NN", "$,", "NN", "$,", "NN", "$,"], "meter": "-+-----+-+-+-", "measure": "dactylic.init"}, "line.10": {"text": "Den Schauplatz immer zu vergr\u00f6\u00dfern.", "tokens": ["Den", "Schau\u00b7platz", "im\u00b7mer", "zu", "ver\u00b7gr\u00f6\u00b7\u00dfern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.49": {"line.1": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.2": {"text": "Man sieht die Stadt, der sie den Namen giebet.", "tokens": ["Man", "sieht", "die", "Stadt", ",", "der", "sie", "den", "Na\u00b7men", "gie\u00b7bet", "."], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Die Flur versch\u00f6nert sich, die auch der Adel liebet,", "tokens": ["Die", "Flur", "ver\u00b7sch\u00f6\u00b7nert", "sich", ",", "die", "auch", "der", "A\u00b7del", "lie\u00b7bet", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PRF", "$,", "PRELS", "ADV", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Dem sie die sch\u00f6nsten Sitze gab.", "tokens": ["Dem", "sie", "die", "sch\u00f6ns\u00b7ten", "Sit\u00b7ze", "gab", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Du ", "tokens": ["Du"], "token_info": ["word"], "pos": ["PPER"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Dein Schlo\u00df liegt ungemein und \u00fcbersieht den Flu\u00df.", "tokens": ["Dein", "Schlo\u00df", "liegt", "un\u00b7ge\u00b7mein", "und", "\u00fc\u00b7ber\u00b7sieht", "den", "Flu\u00df", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVFIN", "ADV", "KON", "VVFIN", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Wirbel nur mit seinen schnellen Kreisen", "tokens": ["Der", "Wir\u00b7bel", "nur", "mit", "sei\u00b7nen", "schnel\u00b7len", "Krei\u00b7sen"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "ADV", "APPR", "PPOSAT", "ADJA", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Macht, da\u00df man dich fast scheuen mu\u00df;", "tokens": ["Macht", ",", "da\u00df", "man", "dich", "fast", "scheu\u00b7en", "mu\u00df", ";"], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PIS", "PRF", "ADV", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Indem der starke Strom auf deine Felsen sprudelt,", "tokens": ["In\u00b7dem", "der", "star\u00b7ke", "Strom", "auf", "dei\u00b7ne", "Fel\u00b7sen", "spru\u00b7delt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "ADJA", "NN", "APPR", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und seitw\u00e4rts in die Runde strudelt.", "tokens": ["Und", "seit\u00b7w\u00e4rts", "in", "die", "Run\u00b7de", "stru\u00b7delt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.50": {"line.1": {"text": "Der bl\u00f6de Schiffer zagt, sein Steuermann ist bleich,", "tokens": ["Der", "bl\u00f6\u00b7de", "Schif\u00b7fer", "zagt", ",", "sein", "Steu\u00b7er\u00b7mann", "ist", "bleich", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "$,", "PPOSAT", "NN", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Die Reisenden bedroht der Wellen Sausen:", "tokens": ["Die", "Rei\u00b7sen\u00b7den", "be\u00b7droht", "der", "Wel\u00b7len", "Sau\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Man h\u00f6rt von weitem schon die Fluth auf Steinen brausen.", "tokens": ["Man", "h\u00f6rt", "von", "wei\u00b7tem", "schon", "die", "Fluth", "auf", "Stei\u00b7nen", "brau\u00b7sen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "APPR", "PIS", "ADV", "ART", "NN", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und n\u00e4her schreckt der Blick zugleich.", "tokens": ["Und", "n\u00e4\u00b7her", "schreckt", "der", "Blick", "zu\u00b7gleich", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADJD", "VVFIN", "ART", "NN", "ADV", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Hier steht ein Fels, um dessen scharfe Spitzen", "tokens": ["Hier", "steht", "ein", "Fels", ",", "um", "des\u00b7sen", "schar\u00b7fe", "Spit\u00b7zen"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "NN", "$,", "KOUI", "PDS", "VVFIN", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Der Strom jahraus jahrein mit wildem Strudel sch\u00e4umt.", "tokens": ["Der", "Strom", "ja\u00b7hraus", "ja\u00b7hrein", "mit", "wil\u00b7dem", "Stru\u00b7del", "sch\u00e4umt", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "APPR", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der wei\u00dfe J\u00e4scht beginnt empor zu spr\u00fctzen,", "tokens": ["Der", "wei\u00b7\u00dfe", "J\u00e4scht", "be\u00b7ginnt", "em\u00b7por", "zu", "spr\u00fct\u00b7zen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wenn sich die n\u00e4chste Welle b\u00e4umt:", "tokens": ["Wenn", "sich", "die", "n\u00e4chs\u00b7te", "Wel\u00b7le", "b\u00e4umt", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "ART", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Doch Klugheit und Geschick, entziehn uns den Gefahren,", "tokens": ["Doch", "Klug\u00b7heit", "und", "Ge\u00b7schick", ",", "ent\u00b7ziehn", "uns", "den", "Ge\u00b7fah\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "NN", "KON", "NN", "$,", "VVFIN", "PPER", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Bevor wir recht erschrocken waren.", "tokens": ["Be\u00b7vor", "wir", "recht", "er\u00b7schro\u00b7cken", "wa\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADJD", "VVPP", "VAFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.51": {"line.1": {"text": "Wer keine See gesehn, der f\u00fcrchtet hier den Tod;", "tokens": ["Wer", "kei\u00b7ne", "See", "ge\u00b7sehn", ",", "der", "f\u00fcrch\u00b7tet", "hier", "den", "Tod", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PIAT", "NN", "VVPP", "$,", "PRELS", "VVFIN", "ADV", "ART", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Wenn Fluth und Schaum sich etwas lebhaft zeigen.", "tokens": ["Wenn", "Fluth", "und", "Schaum", "sich", "et\u00b7was", "leb\u00b7haft", "zei\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "NN", "PRF", "ADV", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Doch wer dich, ", "tokens": ["Doch", "wer", "dich", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "$,"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Der sieht allhier noch keine Noth.", "tokens": ["Der", "sieht", "all\u00b7hier", "noch", "kei\u00b7ne", "Noth", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und sollt ein Schiff, im Wirbel sich zerschmettern;", "tokens": ["Und", "sollt", "ein", "Schiff", ",", "im", "Wir\u00b7bel", "sich", "zer\u00b7schmet\u00b7tern", ";"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "ART", "NN", "$,", "APPRART", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Des nahen Ufers Rand erh\u00e4lt mein Leben schon.", "tokens": ["Des", "na\u00b7hen", "U\u00b7fers", "Rand", "er\u00b7h\u00e4lt", "mein", "Le\u00b7ben", "schon", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN", "PPOSAT", "NN", "ADV", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wer rettet sich im Schiffbruch, als auf Brettern?", "tokens": ["Wer", "ret\u00b7tet", "sich", "im", "Schiff\u00b7bruch", ",", "als", "auf", "Bret\u00b7tern", "?"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PRF", "APPRART", "NN", "$,", "KOUS", "APPR", "NN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Wer spricht wohl da den St\u00fcrmen Hohn?", "tokens": ["Wer", "spricht", "wohl", "da", "den", "St\u00fcr\u00b7men", "Hohn", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "ADV", "ADV", "ART", "NN", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Hier kann mein langer Kahn den Strudel leicht bezwingen:", "tokens": ["Hier", "kann", "mein", "lan\u00b7ger", "Kahn", "den", "Stru\u00b7del", "leicht", "be\u00b7zwin\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "PPOSAT", "ADJA", "NN", "ART", "NN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Dort mu\u00df das gr\u00f6\u00dfte Kriegsschiff springen.", "tokens": ["Dort", "mu\u00df", "das", "gr\u00f6\u00df\u00b7te", "Kriegs\u00b7schiff", "sprin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.52": {"line.1": {"text": "Was sag ich von dem Schlo\u00df, das die von", "tokens": ["Was", "sag", "ich", "von", "dem", "Schlo\u00df", ",", "das", "die", "von"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PWS", "VVFIN", "PPER", "APPR", "ART", "NN", "$,", "PRELS", "ART", "APPR"], "meter": "-+-+-+-++", "measure": "unknown.measure.penta"}, "line.2": {"text": "Und weiter her, ", "tokens": ["Und", "wei\u00b7ter", "her", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "ADV", "PTKVZ", "$,"], "meter": "-+-+", "measure": "iambic.di"}, "line.3": {"text": "Wer diese Gegend sieht, der kann sie nicht vergessen,", "tokens": ["Wer", "die\u00b7se", "Ge\u00b7gend", "sieht", ",", "der", "kann", "sie", "nicht", "ver\u00b7ges\u00b7sen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PDAT", "NN", "VVFIN", "$,", "PRELS", "VMFIN", "PPER", "PTKNEG", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als aller Klugen Augenmerk.", "tokens": ["Als", "al\u00b7ler", "Klu\u00b7gen", "Au\u00b7gen\u00b7merk", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Kl\u00f6ster! ihr, die ihr an so viel Stellen,", "tokens": ["Ihr", "Kl\u00f6s\u00b7ter", "!", "ihr", ",", "die", "ihr", "an", "so", "viel", "Stel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$.", "PPER", "$,", "PRELS", "PPER", "APPR", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+--+--+-", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "Pall\u00e4sten \u00e4hnlich seht, und halbe Wunder zeigt!", "tokens": ["Pal\u00b7l\u00e4s\u00b7ten", "\u00e4hn\u00b7lich", "seht", ",", "und", "hal\u00b7be", "Wun\u00b7der", "zeigt", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NN", "ADJD", "VVFIN", "$,", "KON", "ADJA", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Besonders du, um das mit treuen Wellen,", "tokens": ["Be\u00b7son\u00b7ders", "du", ",", "um", "das", "mit", "treu\u00b7en", "Wel\u00b7len", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PPER", "$,", "KOUI", "ART", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Der Donaustrom sich schmiegend beugt;", "tokens": ["Der", "Do\u00b7naus\u00b7trom", "sich", "schmie\u00b7gend", "beugt", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PRF", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "O M\u00f6lk! dein hoher Bau besch\u00e4met F\u00fcrstenh\u00e4user,", "tokens": ["O", "M\u00f6lk", "!", "dein", "ho\u00b7her", "Bau", "be\u00b7sch\u00e4\u00b7met", "F\u00fcrs\u00b7ten\u00b7h\u00e4u\u00b7ser", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NN", "$.", "PPOSAT", "ADJA", "NN", "VVFIN", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Und regt den Neid erhabner Kaiser.", "tokens": ["Und", "regt", "den", "Neid", "er\u00b7hab\u00b7ner", "Kai\u00b7ser", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.53": {"line.1": {"text": "O sollt ich dich doch auch mit eifriger Begier,", "tokens": ["O", "sollt", "ich", "dich", "doch", "auch", "mit", "eif\u00b7ri\u00b7ger", "Be\u00b7gier", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "PRF", "ADV", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Von innen her durchwandern und betrachten!", "tokens": ["Von", "in\u00b7nen", "her", "durch\u00b7wan\u00b7dern", "und", "be\u00b7trach\u00b7ten", "!"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "APZR", "VVINF", "KON", "VVINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Wie hoch w\u00fcrd ich den Schatz der Alterth\u00fcmer achten,", "tokens": ["Wie", "hoch", "w\u00fcrd", "ich", "den", "Schatz", "der", "Al\u00b7tert\u00b7h\u00fc\u00b7mer", "ach\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADJD", "VAFIN", "PPER", "ART", "NN", "ART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Als deiner Mauren sch\u00f6nste Zier.", "tokens": ["Als", "dei\u00b7ner", "Mau\u00b7ren", "sch\u00f6ns\u00b7te", "Zier", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPOSAT", "NN", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der Alten Witz lebt hier in tausend B\u00fcchern,", "tokens": ["Der", "Al\u00b7ten", "Witz", "lebt", "hier", "in", "tau\u00b7send", "B\u00fc\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVFIN", "ADV", "APPR", "CARD", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Und k\u00f6nnte meinem Geist ein s\u00fc\u00dfes Labsal seyn.", "tokens": ["Und", "k\u00f6nn\u00b7te", "mei\u00b7nem", "Geist", "ein", "s\u00fc\u00b7\u00dfes", "Lab\u00b7sal", "seyn", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "PPOSAT", "NN", "ART", "ADJA", "NN", "VAINF", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Ein gleiches k\u00f6nnt ich mich von dir versichern,", "tokens": ["Ein", "glei\u00b7ches", "k\u00f6nnt", "ich", "mich", "von", "dir", "ver\u00b7si\u00b7chern", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "VVFIN", "PPER", "PRF", "APPR", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "O ", "tokens": ["O"], "token_info": ["word"], "pos": ["NE"], "meter": "+", "measure": "single.up"}, "line.9": {"text": "Allein der schnelle Flu\u00df, der mich vor\u00fcber f\u00fchret,", "tokens": ["Al\u00b7lein", "der", "schnel\u00b7le", "Flu\u00df", ",", "der", "mich", "vor\u00b7\u00fc\u00b7ber", "f\u00fch\u00b7ret", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ART", "ADJA", "NN", "$,", "PRELS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Macht, da\u00df mein Fu\u00df kein Land ber\u00fchret.", "tokens": ["Macht", ",", "da\u00df", "mein", "Fu\u00df", "kein", "Land", "be\u00b7r\u00fch\u00b7ret", "."], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "$,", "KOUS", "PPOSAT", "NN", "PIAT", "NN", "VVFIN", "$."], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}}, "stanza.54": {"line.1": {"text": "Du weiser Antonin, desgleichen keine Zeit", "tokens": ["Du", "wei\u00b7ser", "An\u00b7to\u00b7nin", ",", "des\u00b7glei\u00b7chen", "kei\u00b7ne", "Zeit"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "ADJA", "NN", "$,", "ADV", "PIAT", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Noch auf dem Thron als Herrscher hat gesehen.", "tokens": ["Noch", "auf", "dem", "Thron", "als", "Herr\u00b7scher", "hat", "ge\u00b7se\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "KOUS", "NN", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Mich d\u00fcnkt, ich seh den Zug, der sonst von dir geschehen,", "tokens": ["Mich", "d\u00fcnkt", ",", "ich", "seh", "den", "Zug", ",", "der", "sonst", "von", "dir", "ge\u00b7sche\u00b7hen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$,", "PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "ADV", "APPR", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "An Spuren deiner Menschlichkeit.", "tokens": ["An", "Spu\u00b7ren", "dei\u00b7ner", "Menschlich\u00b7keit", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.5": {"text": "Die ", "tokens": ["Die"], "token_info": ["word"], "pos": ["ART"], "meter": "-", "measure": "single.down"}, "line.6": {"text": "Doch sah sie auch an dir die Weisheit, den Verstand;", "tokens": ["Doch", "sah", "sie", "auch", "an", "dir", "die", "Weis\u00b7heit", ",", "den", "Ver\u00b7stand", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "ADV", "APPR", "PPER", "ART", "NN", "$,", "ART", "NN", "$."], "meter": "-+--+--+-+-+", "measure": "amphibrach.tri.plus"}, "line.7": {"text": "Und ehrte stets bey fehlgeschlagnen Siegen,", "tokens": ["Und", "ehr\u00b7te", "stets", "bey", "fehl\u00b7ge\u00b7schlag\u00b7nen", "Sie\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Den Kiel in deiner klugen Hand:", "tokens": ["Den", "Kiel", "in", "dei\u00b7ner", "klu\u00b7gen", "Hand", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "APPR", "PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Der, wenn der Krieg dich gleich in Zelt und Harnisch brachte,", "tokens": ["Der", ",", "wenn", "der", "Krieg", "dich", "gleich", "in", "Zelt", "und", "Har\u00b7nisch", "brach\u00b7te", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "$,", "KOUS", "ART", "NN", "PPER", "ADV", "APPR", "NN", "KON", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Im Lager dich gesch\u00e4fftig machte.", "tokens": ["Im", "La\u00b7ger", "dich", "ge\u00b7sch\u00e4ff\u00b7tig", "mach\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.55": {"line.1": {"text": "Nun nimmt der Berge Grund des Bachus Leibtracht an,", "tokens": ["Nun", "nimmt", "der", "Ber\u00b7ge", "Grund", "des", "Ba\u00b7chus", "Leib\u00b7tracht", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "NN", "ART", "NE", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Da wo sich ", "tokens": ["Da", "wo", "sich"], "token_info": ["word", "word", "word"], "pos": ["ADV", "PWAV", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.3": {"text": "Der Reben s\u00fc\u00dfe Frucht h\u00e4ngt schon auf schweren Zweigen,", "tokens": ["Der", "Re\u00b7ben", "s\u00fc\u00b7\u00dfe", "Frucht", "h\u00e4ngt", "schon", "auf", "schwe\u00b7ren", "Zwei\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADJA", "NN", "VVFIN", "ADV", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Und zeigt ein halbes Canaan.", "tokens": ["Und", "zeigt", "ein", "hal\u00b7bes", "Ca\u00b7naan", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Der Boden sinkt und zeigt nun mildre Fl\u00e4chen,", "tokens": ["Der", "Bo\u00b7den", "sinkt", "und", "zeigt", "nun", "mild\u00b7re", "Fl\u00e4\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "KON", "VVFIN", "ADV", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ein ungemeines Land an Lag und Fruchtbarkeit;", "tokens": ["Ein", "un\u00b7ge\u00b7mei\u00b7nes", "Land", "an", "Lag", "und", "Frucht\u00b7bar\u00b7keit", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "APPR", "NN", "KON", "NN", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Der Donaustrom, statt seinen Lauf zu schw\u00e4chen,", "tokens": ["Der", "Do\u00b7naus\u00b7trom", ",", "statt", "sei\u00b7nen", "Lauf", "zu", "schw\u00e4\u00b7chen", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "KOUI", "PPOSAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "Verdoppelt seine L\u00fcsternheit:", "tokens": ["Ver\u00b7dop\u00b7pelt", "sei\u00b7ne", "L\u00fcs\u00b7tern\u00b7heit", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["VVFIN", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Und eilt viel schneller fort, auf meinem nassen Wagen,", "tokens": ["Und", "eilt", "viel", "schnel\u00b7ler", "fort", ",", "auf", "mei\u00b7nem", "nas\u00b7sen", "Wa\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ADJD", "PTKVZ", "$,", "APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Mich in den ", "tokens": ["Mich", "in", "den"], "token_info": ["word", "word", "word"], "pos": ["PPER", "APPR", "ART"], "meter": "-+-", "measure": "amphibrach.single"}}, "stanza.56": {"line.1": {"text": "In einer Stunde geht mein Lauf zwo Meilen fort:", "tokens": ["In", "ei\u00b7ner", "Stun\u00b7de", "geht", "mein", "Lauf", "zwo", "Mei\u00b7len", "fort", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPOSAT", "NN", "CARD", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Ein schnelles Ro\u00df kann kaum geschwinder eilen.", "tokens": ["Ein", "schnel\u00b7les", "Ro\u00df", "kann", "kaum", "ge\u00b7schwin\u00b7der", "ei\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VMFIN", "ADV", "ADJD", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.3": {"text": "Es zeigt sich ", "tokens": ["Es", "zeigt", "sich"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "PRF"], "meter": "-+-", "measure": "amphibrach.single"}, "line.4": {"text": "Wir suchen einen andern Port.", "tokens": ["Wir", "su\u00b7chen", "ei\u00b7nen", "an\u00b7dern", "Port", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "ADJA", "NE", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Was seh ich dort mit seinen Kronen prangen?", "tokens": ["Was", "seh", "ich", "dort", "mit", "sei\u00b7nen", "Kro\u00b7nen", "pran\u00b7gen", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VVFIN", "PPER", "ADV", "APPR", "PPOSAT", "NN", "VVFIN", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Ach! ", "tokens": ["Ach", "!"], "token_info": ["word", "punct"], "pos": ["ITJ", "$."], "meter": "+", "measure": "single.up"}, "line.7": {"text": "Mit was f\u00fcr Gegenden bist du, o ", "tokens": ["Mit", "was", "f\u00fcr", "Ge\u00b7gen\u00b7den", "bist", "du", ",", "o"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["APPR", "PRELS", "APPR", "NN", "VAFIN", "PPER", "$,", "FM"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.8": {"text": "Ich seh die Th\u00fcrme, die du hast!", "tokens": ["Ich", "seh", "die", "Th\u00fcr\u00b7me", ",", "die", "du", "hast", "!"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "$,", "PRELS", "PPER", "VAFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.9": {"text": "Ihr Musen, itzt genug! Die Stadt will n\u00e4her r\u00fccken:", "tokens": ["Ihr", "Mu\u00b7sen", ",", "itzt", "ge\u00b7nug", "!", "Die", "Stadt", "will", "n\u00e4\u00b7her", "r\u00fc\u00b7cken", ":"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "$,", "ADV", "ADV", "$.", "ART", "NN", "VMFIN", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "La\u00dft k\u00fcnftig mir die Reime gl\u00fccken.", "tokens": ["La\u00dft", "k\u00fcnf\u00b7tig", "mir", "die", "Rei\u00b7me", "gl\u00fc\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVIMP", "ADJD", "PPER", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}