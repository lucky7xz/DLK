{"textgrid.poem.38044": {"metadata": {"author": {"name": "Arnim, Ludwig Achim von", "birth": "N.A.", "death": "N.A."}, "title": "Des K\u00f6nig Ladislaus Ermordung im Jahre 1457", "genre": "verse", "period": "N.A.", "pub_year": 1806, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Von einem K\u00f6nig lobesan,", "tokens": ["Von", "ei\u00b7nem", "K\u00f6\u00b7nig", "lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nig Lasla ist sein Nahme,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "ist", "sein", "Nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ein K\u00f6nig aus Oesterreiche,", "tokens": ["Ein", "K\u00f6\u00b7nig", "aus", "O\u00b7es\u00b7ter\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ja spricht man in der Christenheit,", "tokens": ["Ja", "spricht", "man", "in", "der", "Chris\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man findt nicht seines Gleiche.", "tokens": ["Man", "findt", "nicht", "sei\u00b7nes", "Glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.2": {"line.1": {"text": "Er war in seinen jungen Tagen, (17 Jahr)", "tokens": ["Er", "war", "in", "sei\u00b7nen", "jun\u00b7gen", "Ta\u00b7gen", ",", "(", "17", "Jahr", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "number", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,", "$(", "CARD", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Ungarn hiessen ihn einen deutschen Knaben,", "tokens": ["Die", "Un\u00b7garn", "hies\u00b7sen", "ihn", "ei\u00b7nen", "deut\u00b7schen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das haben wir wohl vernommen,", "tokens": ["Das", "ha\u00b7ben", "wir", "wohl", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df er zu Ofen ist ausgeritten,", "tokens": ["Da\u00df", "er", "zu", "O\u00b7fen", "ist", "aus\u00b7ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Zu Prag ist er umkommen.", "tokens": ["Zu", "Prag", "ist", "er", "um\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Er schickte aus nach weiblicher Ehr,", "tokens": ["Er", "schick\u00b7te", "aus", "nach", "weib\u00b7li\u00b7cher", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und wollt erwerben Freundschaft mehr,", "tokens": ["Und", "wollt", "er\u00b7wer\u00b7ben", "Freund\u00b7schaft", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gar fein in Frankenreiche,", "tokens": ["Gar", "fein", "in", "Fran\u00b7ken\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach einer Jungfrau s\u00e4uberlich,", "tokens": ["Nach", "ei\u00b7ner", "Jung\u00b7frau", "s\u00e4u\u00b7ber\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man findt nicht ihres Gleiche.", "tokens": ["Man", "findt", "nicht", "ih\u00b7res", "Glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Der K\u00f6nig in Frankreich einen Brief aussandt,", "tokens": ["Der", "K\u00f6\u00b7nig", "in", "Fran\u00b7kreich", "ei\u00b7nen", "Brief", "aus\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der kam K\u00f6nig Lasla in seine Hand,", "tokens": ["Der", "kam", "K\u00f6\u00b7nig", "Las\u00b7la", "in", "sei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wie er ihn lesen sollte;", "tokens": ["Wie", "er", "ihn", "le\u00b7sen", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wie ihm der K\u00f6nig in Frankreich,", "tokens": ["Und", "wie", "ihm", "der", "K\u00f6\u00b7nig", "in", "Fran\u00b7kreich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Seine Tochter geben wollte.", "tokens": ["Sei\u00b7ne", "Toch\u00b7ter", "ge\u00b7ben", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.5": {"line.1": {"text": "Er schrieb: K\u00f6nig Lasla du lieber Sohn,", "tokens": ["Er", "schrieb", ":", "K\u00f6\u00b7nig", "Las\u00b7la", "du", "lie\u00b7ber", "Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "NE", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du wei\u00dft wohl, was du solltest thun,", "tokens": ["Du", "wei\u00dft", "wohl", ",", "was", "du", "soll\u00b7test", "thun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ketzer sollt du vertreiben,", "tokens": ["Die", "Ket\u00b7zer", "sollt", "du", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und so wird dir Ehr und Lob gesagt,", "tokens": ["Und", "so", "wird", "dir", "Ehr", "und", "Lob", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wo du im Land sollt bleiben.", "tokens": ["Wo", "du", "im", "Land", "sollt", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.6": {"line.1": {"text": "K\u00f6nig Lasla des Briefes aufm Tisch verga\u00df,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "des", "Brie\u00b7fes", "aufm", "Tisch", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Zur Hand ihm ein falscher Ketzer sa\u00df,", "tokens": ["Zur", "Hand", "ihm", "ein", "fal\u00b7scher", "Ket\u00b7zer", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er erschrack der M\u00e4hre gar sehre;", "tokens": ["Er", "er\u00b7schrack", "der", "M\u00e4h\u00b7re", "gar", "seh\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie bald er zu dem Rockenzahn lief,", "tokens": ["Wie", "bald", "er", "zu", "dem", "Ro\u00b7cken\u00b7zahn", "lief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Verk\u00fcndigt ihm die M\u00e4hre.", "tokens": ["Ver\u00b7k\u00fcn\u00b7digt", "ihm", "die", "M\u00e4h\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Und da der Rockenzahn die M\u00e4hr erh\u00f6rt,", "tokens": ["Und", "da", "der", "Ro\u00b7cken\u00b7zahn", "die", "M\u00e4hr", "er\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er ruft den Ketzer an einen Ort,", "tokens": ["Er", "ruft", "den", "Ket\u00b7zer", "an", "ei\u00b7nen", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er begunnt ihm diese Red zu melden,", "tokens": ["Er", "be\u00b7gunnt", "ihm", "die\u00b7se", "Red", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Da huben die falschen Ketzer an,", "tokens": ["Da", "hu\u00b7ben", "die", "fal\u00b7schen", "Ket\u00b7zer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "K\u00f6nig Lasla zu schelten.", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "zu", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKZU", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.8": {"line.1": {"text": "Sie schelten ihn aus ihres Herzensgrund:", "tokens": ["Sie", "schel\u00b7ten", "ihn", "aus", "ih\u00b7res", "Her\u00b7zens\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie deucht euch um den deutschen Hund,", "tokens": ["Wie", "deucht", "euch", "um", "den", "deut\u00b7schen", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sollt er uns hier vertreiben?", "tokens": ["Sollt", "er", "uns", "hier", "ver\u00b7trei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir wollen ihm nehmen sein junges Leben,", "tokens": ["Wir", "wol\u00b7len", "ihm", "neh\u00b7men", "sein", "jun\u00b7ges", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Er mag uns nicht entweichen.", "tokens": ["Er", "mag", "uns", "nicht", "ent\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Und da der Rath nun war verbracht,", "tokens": ["Und", "da", "der", "Rath", "nun", "war", "ver\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den sie \u00fcber K\u00f6nig Lasla hatten gemacht,", "tokens": ["Den", "sie", "\u00fc\u00b7ber", "K\u00f6\u00b7nig", "Las\u00b7la", "hat\u00b7ten", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Wie sie ihn t\u00f6dten wollten,", "tokens": ["Wie", "sie", "ihn", "t\u00f6d\u00b7ten", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hatten alle zusammen geschworn,", "tokens": ["Sie", "hat\u00b7ten", "al\u00b7le", "zu\u00b7sam\u00b7men", "ge\u00b7schworn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wie sie einander helfen wollten.", "tokens": ["Wie", "sie", "ein\u00b7an\u00b7der", "hel\u00b7fen", "woll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.10": {"line.1": {"text": "Sie gewinnen die Riegel und auch die Th\u00fcr,", "tokens": ["Sie", "ge\u00b7win\u00b7nen", "die", "Rie\u00b7gel", "und", "auch", "die", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Unter einer Decke zogen sie ihn herf\u00fcr,", "tokens": ["Un\u00b7ter", "ei\u00b7ner", "De\u00b7cke", "zo\u00b7gen", "sie", "ihn", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "K\u00f6nig Lasla den viel werthen;", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "den", "viel", "wert\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "ADV", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Der erste der nahm ihn beim Haar", "tokens": ["Der", "ers\u00b7te", "der", "nahm", "ihn", "beim", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ART", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und warf ihn auf die Erden.", "tokens": ["Und", "warf", "ihn", "auf", "die", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.11": {"line.1": {"text": "Er fiel wol nieder auf seine Knie:", "tokens": ["Er", "fiel", "wol", "nie\u00b7der", "auf", "sei\u00b7ne", "Knie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbgnad mir edler Herr allhie,", "tokens": ["\u00bb", "gnad", "mir", "ed\u00b7ler", "Herr", "all\u00b7hie", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnad mir meines Lebens;", "tokens": ["Gnad", "mir", "mei\u00b7nes", "Le\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und alles was ich hie gewann,", "tokens": ["Und", "al\u00b7les", "was", "ich", "hie", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das will ich hie aufgeben.\u00ab", "tokens": ["Das", "will", "ich", "hie", "auf\u00b7ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Er sah sie alle barmherzig an:", "tokens": ["Er", "sah", "sie", "al\u00b7le", "barm\u00b7her\u00b7zig", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "\u00bbnun hab ich irgend ein treuen Mann,", "tokens": ["\u00bb", "nun", "hab", "ich", "ir\u00b7gend", "ein", "treu\u00b7en", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der mir sein H\u00fclf hier th\u00e4te?", "tokens": ["Der", "mir", "sein", "H\u00fclf", "hier", "th\u00e4\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind mir denn alle treulos worden,", "tokens": ["Sind", "mir", "denn", "al\u00b7le", "treu\u00b7los", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein allerbesten R\u00e4the?", "tokens": ["Mein", "al\u00b7ler\u00b7bes\u00b7ten", "R\u00e4\u00b7the", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.13": {"line.1": {"text": "Girsig, lieber Vater mein,", "tokens": ["Gir\u00b7sig", ",", "lie\u00b7ber", "Va\u00b7ter", "mein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur la\u00df mich bei dem Leben sein,", "tokens": ["Nur", "la\u00df", "mich", "bei", "dem", "Le\u00b7ben", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will dirs immer gedenken,", "tokens": ["Ich", "will", "dirs", "im\u00b7mer", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mein Schweidnitz soll dein eigen seyn,", "tokens": ["Mein", "Schweid\u00b7nitz", "soll", "dein", "ei\u00b7gen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPOSAT", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Breslau will ich dir schenken.\u00ab", "tokens": ["Und", "Bres\u00b7lau", "will", "ich", "dir", "schen\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.14": {"line.1": {"text": "\u00bbschweig K\u00f6nig Lasla! es mag nicht sein,", "tokens": ["\u00bb", "schweig", "K\u00f6\u00b7nig", "Las\u00b7la", "!", "es", "mag", "nicht", "sein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "NE", "$.", "PPER", "VMFIN", "PTKNEG", "VAINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dein Schweidnitz ist vorhin schon mein,", "tokens": ["Dein", "Schweid\u00b7nitz", "ist", "vor\u00b7hin", "schon", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Breslau will ich gewinnen;", "tokens": ["Bres\u00b7lau", "will", "ich", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hilft mir das ganze B\u00f6hmerland,", "tokens": ["Hilft", "mir", "das", "gan\u00b7ze", "B\u00f6h\u00b7mer\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein K\u00f6nig bin ich drinnen.\u00ab", "tokens": ["Ein", "K\u00f6\u00b7nig", "bin", "ich", "drin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "\u00bbnun! schneid mir ein graue Kutten an,", "tokens": ["\u00bb", "nun", "!", "schneid", "mir", "ein", "grau\u00b7e", "Kut\u00b7ten", "an", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich will in ein Kloster gahn,", "tokens": ["Ich", "will", "in", "ein", "Klos\u00b7ter", "gahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu meines Vaters Ruhe;", "tokens": ["Zu", "mei\u00b7nes", "Va\u00b7ters", "Ru\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es bleib ein K\u00f6nig wer da will,", "tokens": ["Es", "bleib", "ein", "K\u00f6\u00b7nig", "wer", "da", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PWS", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Immer und ewigliche.\u00ab", "tokens": ["Im\u00b7mer", "und", "e\u00b7wig\u00b7li\u00b7che", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "KON", "ADJA", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.16": {"line.1": {"text": "Sein guter Rath half ihm nicht sehr,", "tokens": ["Sein", "gu\u00b7ter", "Rath", "half", "ihm", "nicht", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hatten vergessen Treu und Ehr,", "tokens": ["Sie", "hat\u00b7ten", "ver\u00b7ges\u00b7sen", "Treu", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Herrn aus B\u00f6hmerlande,", "tokens": ["Die", "Herrn", "aus", "B\u00f6h\u00b7mer\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df sie K\u00f6nig Lasla get\u00f6dtet han,", "tokens": ["Da\u00df", "sie", "K\u00f6\u00b7nig", "Las\u00b7la", "ge\u00b7t\u00f6d\u00b7tet", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NE", "VVPP", "VAFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das haben sie gro\u00dfe Schande.", "tokens": ["Das", "ha\u00b7ben", "sie", "gro\u00b7\u00dfe", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Auf die Erde haben sie ihn hingestreckt,", "tokens": ["Auf", "die", "Er\u00b7de", "ha\u00b7ben", "sie", "ihn", "hin\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Mit einem Kissen haben sie ihn ersteckt,", "tokens": ["Mit", "ei\u00b7nem", "Kis\u00b7sen", "ha\u00b7ben", "sie", "ihn", "er\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sein Genick haben sie ihm gebrochen.", "tokens": ["Sein", "Ge\u00b7nick", "ha\u00b7ben", "sie", "ihm", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Wer wollt nicht Gott vom Himmel klagen,", "tokens": ["Wer", "wollt", "nicht", "Gott", "vom", "Him\u00b7mel", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er l\u00e4\u00dft nichts ungerochen.", "tokens": ["Er", "l\u00e4\u00dft", "nichts", "un\u00b7ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Und da er nun gestorben war,", "tokens": ["Und", "da", "er", "nun", "ge\u00b7stor\u00b7ben", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es gl\u00fchet als ein Rosen gar,", "tokens": ["Es", "gl\u00fc\u00b7het", "als", "ein", "Ro\u00b7sen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wol unter seinen Augen,", "tokens": ["Wol", "un\u00b7ter", "sei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Da ihm das Blut von Wangen abrann,", "tokens": ["Da", "ihm", "das", "Blut", "von", "Wan\u00b7gen", "ab\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dran hatten sie keinen Glauben.", "tokens": ["Dran", "hat\u00b7ten", "sie", "kei\u00b7nen", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.19": {"line.1": {"text": "Es war bis an den dritten Tag,", "tokens": ["Es", "war", "bis", "an", "den", "drit\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er da unbegraben lag,", "tokens": ["Da\u00df", "er", "da", "un\u00b7be\u00b7gra\u00b7ben", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man lie\u00df ihn niemand schauen,", "tokens": ["Man", "lie\u00df", "ihn", "nie\u00b7mand", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und da man ihn zu Grabe trug,", "tokens": ["Und", "da", "man", "ihn", "zu", "Gra\u00b7be", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da weinten Mann und Frauen.", "tokens": ["Da", "wein\u00b7ten", "Mann", "und", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Da sprach ein Ketzer unter ihnen:", "tokens": ["Da", "sprach", "ein", "Ket\u00b7zer", "un\u00b7ter", "ih\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbnun hebt ihn auf und tragt ihn hin,", "tokens": ["\u00bb", "nun", "hebt", "ihn", "auf", "und", "tragt", "ihn", "hin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den K\u00f6nig aus deutschen Landen,", "tokens": ["Den", "K\u00f6\u00b7nig", "aus", "deut\u00b7schen", "Lan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sollt er uns hie vertrieben han,", "tokens": ["Sollt", "er", "uns", "hie", "ver\u00b7trie\u00b7ben", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das w\u00e4r uns eine gro\u00dfe Schande.\u00ab", "tokens": ["Das", "w\u00e4r", "uns", "ei\u00b7ne", "gro\u00b7\u00dfe", "Schan\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.21": {"line.1": {"text": "Und da sprach er: \u00bbSieh Girsig,", "tokens": ["Und", "da", "sprach", "er", ":", "\u00bb", "Sieh", "Gir\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "$(", "NE", "NE", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Der K\u00f6nig in B\u00f6hmen bin ich,", "tokens": ["Der", "K\u00f6\u00b7nig", "in", "B\u00f6h\u00b7men", "bin", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VAFIN", "PPER", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "K\u00f6nig Lasla ist gestorben,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "ist", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um seines falschen Glaubens willen,", "tokens": ["Um", "sei\u00b7nes", "fal\u00b7schen", "Glau\u00b7bens", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darum ist er verdorben.\u00ab", "tokens": ["Da\u00b7rum", "ist", "er", "ver\u00b7dor\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.22": {"line.1": {"text": "Da sprach er, der Rockenzahn:", "tokens": ["Da", "sprach", "er", ",", "der", "Ro\u00b7cken\u00b7zahn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00bbeine neue Sitte nehm ich an,", "tokens": ["\u00bb", "ei\u00b7ne", "neu\u00b7e", "Sit\u00b7te", "nehm", "ich", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Oestreich will ich zerst\u00f6ren;", "tokens": ["O\u00b7e\u00b7streich", "will", "ich", "zer\u00b7st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn ihren Glauben wei\u00df ich wohl,", "tokens": ["Denn", "ih\u00b7ren", "Glau\u00b7ben", "wei\u00df", "ich", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Herzog will ich werden.\u00ab", "tokens": ["Ihr", "Her\u00b7zog", "will", "ich", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.23": {"line.1": {"text": "Der Girsig der ist hochgeborn,", "tokens": ["Der", "Gir\u00b7sig", "der", "ist", "hoch\u00b7ge\u00b7born", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Recht als ein Sau ist er beschoren,", "tokens": ["Recht", "als", "ein", "Sau", "ist", "er", "be\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer ist der ihm wohl gleiche,", "tokens": ["Wer", "ist", "der", "ihm", "wohl", "glei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit Rauben, mit Stehlen, mit Bannerey,", "tokens": ["Mit", "Rau\u00b7ben", ",", "mit", "Steh\u00b7len", ",", "mit", "Ban\u00b7ne\u00b7rey", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Damit er worden reiche.", "tokens": ["Da\u00b7mit", "er", "wor\u00b7den", "rei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAPP", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "K\u00f6nig Lasla war ein junger Mann,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "war", "ein", "jun\u00b7ger", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er wollt den Girsig bei sich han,", "tokens": ["Er", "wollt", "den", "Gir\u00b7sig", "bei", "sich", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NE", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er hat ihn auserkohren;", "tokens": ["Er", "hat", "ihn", "au\u00b7ser\u00b7koh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja ich sprechs auf die Treue mein,", "tokens": ["Ja", "ich", "sprechs", "auf", "die", "Treu\u00b7e", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "APPR", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist ihm treulos worden.", "tokens": ["Er", "ist", "ihm", "treu\u00b7los", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.25": {"line.1": {"text": "K\u00f6nig Lasla du viel edles Blut,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "du", "viel", "ed\u00b7les", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Gott erhalte dich in seiner Hut,", "tokens": ["Gott", "er\u00b7hal\u00b7te", "dich", "in", "sei\u00b7ner", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mit seinem lieben Kinde,", "tokens": ["Mit", "sei\u00b7nem", "lie\u00b7ben", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df du also verschieden bist,", "tokens": ["Da\u00df", "du", "al\u00b7so", "ver\u00b7schie\u00b7den", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit deinem Hofgesinde.", "tokens": ["Mit", "dei\u00b7nem", "Hof\u00b7ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Von einem K\u00f6nig lobesan,", "tokens": ["Von", "ei\u00b7nem", "K\u00f6\u00b7nig", "lo\u00b7be\u00b7san", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "K\u00f6nig Lasla ist sein Nahme,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "ist", "sein", "Nah\u00b7me", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "PPOSAT", "NN", "$,"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.3": {"text": "Ein K\u00f6nig aus Oesterreiche,", "tokens": ["Ein", "K\u00f6\u00b7nig", "aus", "O\u00b7es\u00b7ter\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NN", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.4": {"text": "Ja spricht man in der Christenheit,", "tokens": ["Ja", "spricht", "man", "in", "der", "Chris\u00b7ten\u00b7heit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "VVFIN", "PIS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man findt nicht seines Gleiche.", "tokens": ["Man", "findt", "nicht", "sei\u00b7nes", "Glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Er war in seinen jungen Tagen, (17 Jahr)", "tokens": ["Er", "war", "in", "sei\u00b7nen", "jun\u00b7gen", "Ta\u00b7gen", ",", "(", "17", "Jahr", ")"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct", "number", "word", "punct"], "pos": ["PPER", "VAFIN", "APPR", "PPOSAT", "ADJA", "NN", "$,", "$(", "CARD", "NN", "$("], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Die Ungarn hiessen ihn einen deutschen Knaben,", "tokens": ["Die", "Un\u00b7garn", "hies\u00b7sen", "ihn", "ei\u00b7nen", "deut\u00b7schen", "Kna\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+-+-", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Das haben wir wohl vernommen,", "tokens": ["Das", "ha\u00b7ben", "wir", "wohl", "ver\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADV", "VVPP", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Da\u00df er zu Ofen ist ausgeritten,", "tokens": ["Da\u00df", "er", "zu", "O\u00b7fen", "ist", "aus\u00b7ge\u00b7rit\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VAFIN", "VVPP", "$,"], "meter": "-+-+--+-+-", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Zu Prag ist er umkommen.", "tokens": ["Zu", "Prag", "ist", "er", "um\u00b7kom\u00b7men", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "VAFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Er schickte aus nach weiblicher Ehr,", "tokens": ["Er", "schick\u00b7te", "aus", "nach", "weib\u00b7li\u00b7cher", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Und wollt erwerben Freundschaft mehr,", "tokens": ["Und", "wollt", "er\u00b7wer\u00b7ben", "Freund\u00b7schaft", "mehr", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VMFIN", "VVINF", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Gar fein in Frankenreiche,", "tokens": ["Gar", "fein", "in", "Fran\u00b7ken\u00b7rei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Nach einer Jungfrau s\u00e4uberlich,", "tokens": ["Nach", "ei\u00b7ner", "Jung\u00b7frau", "s\u00e4u\u00b7ber\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Man findt nicht ihres Gleiche.", "tokens": ["Man", "findt", "nicht", "ih\u00b7res", "Glei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKNEG", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Der K\u00f6nig in Frankreich einen Brief aussandt,", "tokens": ["Der", "K\u00f6\u00b7nig", "in", "Fran\u00b7kreich", "ei\u00b7nen", "Brief", "aus\u00b7sandt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "ART", "NN", "VVPP", "$,"], "meter": "-+--+-+-+-+", "measure": "iambic.penta.relaxed"}, "line.2": {"text": "Der kam K\u00f6nig Lasla in seine Hand,", "tokens": ["Der", "kam", "K\u00f6\u00b7nig", "Las\u00b7la", "in", "sei\u00b7ne", "Hand", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "NE", "NE", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.3": {"text": "Wie er ihn lesen sollte;", "tokens": ["Wie", "er", "ihn", "le\u00b7sen", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wie ihm der K\u00f6nig in Frankreich,", "tokens": ["Und", "wie", "ihm", "der", "K\u00f6\u00b7nig", "in", "Fran\u00b7kreich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWAV", "PPER", "ART", "NN", "APPR", "NE", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Seine Tochter geben wollte.", "tokens": ["Sei\u00b7ne", "Toch\u00b7ter", "ge\u00b7ben", "woll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VVINF", "VMFIN", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.30": {"line.1": {"text": "Er schrieb: K\u00f6nig Lasla du lieber Sohn,", "tokens": ["Er", "schrieb", ":", "K\u00f6\u00b7nig", "Las\u00b7la", "du", "lie\u00b7ber", "Sohn", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "$.", "NN", "NE", "PPER", "ADV", "NN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Du wei\u00dft wohl, was du solltest thun,", "tokens": ["Du", "wei\u00dft", "wohl", ",", "was", "du", "soll\u00b7test", "thun", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "$,", "PWS", "PPER", "VMFIN", "VVINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die Ketzer sollt du vertreiben,", "tokens": ["Die", "Ket\u00b7zer", "sollt", "du", "ver\u00b7trei\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VMFIN", "PPER", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und so wird dir Ehr und Lob gesagt,", "tokens": ["Und", "so", "wird", "dir", "Ehr", "und", "Lob", "ge\u00b7sagt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ADV", "VAFIN", "PPER", "NN", "KON", "NN", "VVPP", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.5": {"text": "Wo du im Land sollt bleiben.", "tokens": ["Wo", "du", "im", "Land", "sollt", "blei\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPRART", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.31": {"line.1": {"text": "K\u00f6nig Lasla des Briefes aufm Tisch verga\u00df,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "des", "Brie\u00b7fes", "aufm", "Tisch", "ver\u00b7ga\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "+--+-+--+-+", "measure": "iambic.penta.invert"}, "line.2": {"text": "Zur Hand ihm ein falscher Ketzer sa\u00df,", "tokens": ["Zur", "Hand", "ihm", "ein", "fal\u00b7scher", "Ket\u00b7zer", "sa\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "ART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er erschrack der M\u00e4hre gar sehre;", "tokens": ["Er", "er\u00b7schrack", "der", "M\u00e4h\u00b7re", "gar", "seh\u00b7re", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "ADV", "VVFIN", "$."], "meter": "--+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Wie bald er zu dem Rockenzahn lief,", "tokens": ["Wie", "bald", "er", "zu", "dem", "Ro\u00b7cken\u00b7zahn", "lief", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.5": {"text": "Verk\u00fcndigt ihm die M\u00e4hre.", "tokens": ["Ver\u00b7k\u00fcn\u00b7digt", "ihm", "die", "M\u00e4h\u00b7re", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Und da der Rockenzahn die M\u00e4hr erh\u00f6rt,", "tokens": ["Und", "da", "der", "Ro\u00b7cken\u00b7zahn", "die", "M\u00e4hr", "er\u00b7h\u00f6rt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Er ruft den Ketzer an einen Ort,", "tokens": ["Er", "ruft", "den", "Ket\u00b7zer", "an", "ei\u00b7nen", "Ort", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Er begunnt ihm diese Red zu melden,", "tokens": ["Er", "be\u00b7gunnt", "ihm", "die\u00b7se", "Red", "zu", "mel\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PDAT", "NN", "PTKZU", "VVINF", "$,"], "meter": "+-+-+-+-+-", "measure": "trochaic.penta"}, "line.4": {"text": "Da huben die falschen Ketzer an,", "tokens": ["Da", "hu\u00b7ben", "die", "fal\u00b7schen", "Ket\u00b7zer", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "K\u00f6nig Lasla zu schelten.", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "zu", "schel\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PTKZU", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.33": {"line.1": {"text": "Sie schelten ihn aus ihres Herzensgrund:", "tokens": ["Sie", "schel\u00b7ten", "ihn", "aus", "ih\u00b7res", "Her\u00b7zens\u00b7grund", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Wie deucht euch um den deutschen Hund,", "tokens": ["Wie", "deucht", "euch", "um", "den", "deut\u00b7schen", "Hund", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "VVFIN", "PPER", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sollt er uns hier vertreiben?", "tokens": ["Sollt", "er", "uns", "hier", "ver\u00b7trei\u00b7ben", "?"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PPER", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Wir wollen ihm nehmen sein junges Leben,", "tokens": ["Wir", "wol\u00b7len", "ihm", "neh\u00b7men", "sein", "jun\u00b7ges", "Le\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "VVFIN", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+--+--+-+-", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Er mag uns nicht entweichen.", "tokens": ["Er", "mag", "uns", "nicht", "ent\u00b7wei\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PPER", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Und da der Rath nun war verbracht,", "tokens": ["Und", "da", "der", "Rath", "nun", "war", "ver\u00b7bracht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADV", "VAFIN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Den sie \u00fcber K\u00f6nig Lasla hatten gemacht,", "tokens": ["Den", "sie", "\u00fc\u00b7ber", "K\u00f6\u00b7nig", "Las\u00b7la", "hat\u00b7ten", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "APPR", "NN", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-+--+", "measure": "iambic.hexa.chol"}, "line.3": {"text": "Wie sie ihn t\u00f6dten wollten,", "tokens": ["Wie", "sie", "ihn", "t\u00f6d\u00b7ten", "woll\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PPER", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sie hatten alle zusammen geschworn,", "tokens": ["Sie", "hat\u00b7ten", "al\u00b7le", "zu\u00b7sam\u00b7men", "ge\u00b7schworn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PIS", "ADV", "VVPP", "$,"], "meter": "-+-+--+--+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Wie sie einander helfen wollten.", "tokens": ["Wie", "sie", "ein\u00b7an\u00b7der", "hel\u00b7fen", "woll\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PRF", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.35": {"line.1": {"text": "Sie gewinnen die Riegel und auch die Th\u00fcr,", "tokens": ["Sie", "ge\u00b7win\u00b7nen", "die", "Rie\u00b7gel", "und", "auch", "die", "Th\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "KON", "ADV", "ART", "NN", "$,"], "meter": "--+--+--+-+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Unter einer Decke zogen sie ihn herf\u00fcr,", "tokens": ["Un\u00b7ter", "ei\u00b7ner", "De\u00b7cke", "zo\u00b7gen", "sie", "ihn", "her\u00b7f\u00fcr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVFIN", "PPER", "PPER", "ADV", "$,"], "meter": "+-+-+-+--+-+", "measure": "trochaic.hexa.relaxed"}, "line.3": {"text": "K\u00f6nig Lasla den viel werthen;", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "den", "viel", "wert\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "ART", "ADV", "VVFIN", "$."], "meter": "+--+--+-", "measure": "dactylic.tri"}, "line.4": {"text": "Der erste der nahm ihn beim Haar", "tokens": ["Der", "ers\u00b7te", "der", "nahm", "ihn", "beim", "Haar"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "ART", "VVFIN", "PPER", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und warf ihn auf die Erden.", "tokens": ["Und", "warf", "ihn", "auf", "die", "Er\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Er fiel wol nieder auf seine Knie:", "tokens": ["Er", "fiel", "wol", "nie\u00b7der", "auf", "sei\u00b7ne", "Knie", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PTKVZ", "APPR", "PPOSAT", "NN", "$."], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "\u00bbgnad mir edler Herr allhie,", "tokens": ["\u00bb", "gnad", "mir", "ed\u00b7ler", "Herr", "all\u00b7hie", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "VVIMP", "PPER", "ADJA", "NN", "ADV", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Gnad mir meines Lebens;", "tokens": ["Gnad", "mir", "mei\u00b7nes", "Le\u00b7bens", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPER", "PPOSAT", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Und alles was ich hie gewann,", "tokens": ["Und", "al\u00b7les", "was", "ich", "hie", "ge\u00b7wann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PIS", "PWS", "PPER", "ADV", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das will ich hie aufgeben.\u00ab", "tokens": ["Das", "will", "ich", "hie", "auf\u00b7ge\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VMFIN", "PPER", "ADV", "VVINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Er sah sie alle barmherzig an:", "tokens": ["Er", "sah", "sie", "al\u00b7le", "barm\u00b7her\u00b7zig", "an", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "PIS", "ADJD", "PTKVZ", "$."], "meter": "-+-+-++-+", "measure": "unknown.measure.penta"}, "line.2": {"text": "\u00bbnun hab ich irgend ein treuen Mann,", "tokens": ["\u00bb", "nun", "hab", "ich", "ir\u00b7gend", "ein", "treu\u00b7en", "Mann", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Der mir sein H\u00fclf hier th\u00e4te?", "tokens": ["Der", "mir", "sein", "H\u00fclf", "hier", "th\u00e4\u00b7te", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPER", "PPOSAT", "NN", "ADV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Sind mir denn alle treulos worden,", "tokens": ["Sind", "mir", "denn", "al\u00b7le", "treu\u00b7los", "wor\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PPER", "ADV", "PIS", "ADJD", "VAPP", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Mein allerbesten R\u00e4the?", "tokens": ["Mein", "al\u00b7ler\u00b7bes\u00b7ten", "R\u00e4\u00b7the", "?"], "token_info": ["word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Girsig, lieber Vater mein,", "tokens": ["Gir\u00b7sig", ",", "lie\u00b7ber", "Va\u00b7ter", "mein", ","], "token_info": ["word", "punct", "word", "word", "word", "punct"], "pos": ["NE", "$,", "ADV", "NN", "PPOSAT", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.2": {"text": "Nur la\u00df mich bei dem Leben sein,", "tokens": ["Nur", "la\u00df", "mich", "bei", "dem", "Le\u00b7ben", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVIMP", "PPER", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ich will dirs immer gedenken,", "tokens": ["Ich", "will", "dirs", "im\u00b7mer", "ge\u00b7den\u00b7ken", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "PIS", "ADV", "VVINF", "$,"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Mein Schweidnitz soll dein eigen seyn,", "tokens": ["Mein", "Schweid\u00b7nitz", "soll", "dein", "ei\u00b7gen", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPOSAT", "ADJD", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und Breslau will ich dir schenken.\u00ab", "tokens": ["Und", "Bres\u00b7lau", "will", "ich", "dir", "schen\u00b7ken", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["KON", "NE", "VMFIN", "PPER", "PPER", "VVINF", "$.", "$("], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.39": {"line.1": {"text": "\u00bbschweig K\u00f6nig Lasla! es mag nicht sein,", "tokens": ["\u00bb", "schweig", "K\u00f6\u00b7nig", "Las\u00b7la", "!", "es", "mag", "nicht", "sein", ","], "token_info": ["punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADJD", "NN", "NE", "$.", "PPER", "VMFIN", "PTKNEG", "VAINF", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Dein Schweidnitz ist vorhin schon mein,", "tokens": ["Dein", "Schweid\u00b7nitz", "ist", "vor\u00b7hin", "schon", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "ADV", "ADV", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Breslau will ich gewinnen;", "tokens": ["Bres\u00b7lau", "will", "ich", "ge\u00b7win\u00b7nen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Hilft mir das ganze B\u00f6hmerland,", "tokens": ["Hilft", "mir", "das", "gan\u00b7ze", "B\u00f6h\u00b7mer\u00b7land", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein K\u00f6nig bin ich drinnen.\u00ab", "tokens": ["Ein", "K\u00f6\u00b7nig", "bin", "ich", "drin\u00b7nen", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["ART", "NN", "VAFIN", "PPER", "ADV", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.40": {"line.1": {"text": "\u00bbnun! schneid mir ein graue Kutten an,", "tokens": ["\u00bb", "nun", "!", "schneid", "mir", "ein", "grau\u00b7e", "Kut\u00b7ten", "an", ","], "token_info": ["punct", "word", "punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "$.", "VVFIN", "PPER", "ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.2": {"text": "Ich will in ein Kloster gahn,", "tokens": ["Ich", "will", "in", "ein", "Klos\u00b7ter", "gahn", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu meines Vaters Ruhe;", "tokens": ["Zu", "mei\u00b7nes", "Va\u00b7ters", "Ru\u00b7he", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es bleib ein K\u00f6nig wer da will,", "tokens": ["Es", "bleib", "ein", "K\u00f6\u00b7nig", "wer", "da", "will", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PWS", "ADV", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Immer und ewigliche.\u00ab", "tokens": ["Im\u00b7mer", "und", "e\u00b7wig\u00b7li\u00b7che", ".", "\u00ab"], "token_info": ["word", "word", "word", "punct", "punct"], "pos": ["ADV", "KON", "ADJA", "$.", "$("], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.41": {"line.1": {"text": "Sein guter Rath half ihm nicht sehr,", "tokens": ["Sein", "gu\u00b7ter", "Rath", "half", "ihm", "nicht", "sehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "ADJA", "NN", "VVFIN", "PPER", "PTKNEG", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sie hatten vergessen Treu und Ehr,", "tokens": ["Sie", "hat\u00b7ten", "ver\u00b7ges\u00b7sen", "Treu", "und", "Ehr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "VVPP", "NN", "KON", "NN", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.3": {"text": "Die Herrn aus B\u00f6hmerlande,", "tokens": ["Die", "Herrn", "aus", "B\u00f6h\u00b7mer\u00b7lan\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df sie K\u00f6nig Lasla get\u00f6dtet han,", "tokens": ["Da\u00df", "sie", "K\u00f6\u00b7nig", "Las\u00b7la", "ge\u00b7t\u00f6d\u00b7tet", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "NN", "NE", "VVPP", "VAFIN", "$,"], "meter": "--+--+-+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Das haben sie gro\u00dfe Schande.", "tokens": ["Das", "ha\u00b7ben", "sie", "gro\u00b7\u00dfe", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ADJA", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.42": {"line.1": {"text": "Auf die Erde haben sie ihn hingestreckt,", "tokens": ["Auf", "die", "Er\u00b7de", "ha\u00b7ben", "sie", "ihn", "hin\u00b7ge\u00b7streckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "+-+-+-+-+-+", "measure": "trochaic.hexa"}, "line.2": {"text": "Mit einem Kissen haben sie ihn ersteckt,", "tokens": ["Mit", "ei\u00b7nem", "Kis\u00b7sen", "ha\u00b7ben", "sie", "ihn", "er\u00b7steckt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+--+-+", "measure": "iambic.penta.relaxed"}, "line.3": {"text": "Sein Genick haben sie ihm gebrochen.", "tokens": ["Sein", "Ge\u00b7nick", "ha\u00b7ben", "sie", "ihm", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPOSAT", "NN", "VAFIN", "PPER", "PPER", "VVPP", "$."], "meter": "--+-+-+-+-", "measure": "anapaest.init"}, "line.4": {"text": "Wer wollt nicht Gott vom Himmel klagen,", "tokens": ["Wer", "wollt", "nicht", "Gott", "vom", "Him\u00b7mel", "kla\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VMFIN", "PTKNEG", "NN", "APPRART", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Er l\u00e4\u00dft nichts ungerochen.", "tokens": ["Er", "l\u00e4\u00dft", "nichts", "un\u00b7ge\u00b7ro\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PIS", "ADJD", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Und da er nun gestorben war,", "tokens": ["Und", "da", "er", "nun", "ge\u00b7stor\u00b7ben", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es gl\u00fchet als ein Rosen gar,", "tokens": ["Es", "gl\u00fc\u00b7het", "als", "ein", "Ro\u00b7sen", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KOKOM", "ART", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Wol unter seinen Augen,", "tokens": ["Wol", "un\u00b7ter", "sei\u00b7nen", "Au\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Da ihm das Blut von Wangen abrann,", "tokens": ["Da", "ihm", "das", "Blut", "von", "Wan\u00b7gen", "ab\u00b7rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Dran hatten sie keinen Glauben.", "tokens": ["Dran", "hat\u00b7ten", "sie", "kei\u00b7nen", "Glau\u00b7ben", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PPER", "PIAT", "NN", "$."], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}}, "stanza.44": {"line.1": {"text": "Es war bis an den dritten Tag,", "tokens": ["Es", "war", "bis", "an", "den", "drit\u00b7ten", "Tag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "APPR", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df er da unbegraben lag,", "tokens": ["Da\u00df", "er", "da", "un\u00b7be\u00b7gra\u00b7ben", "lag", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man lie\u00df ihn niemand schauen,", "tokens": ["Man", "lie\u00df", "ihn", "nie\u00b7mand", "schau\u00b7en", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PPER", "PIS", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und da man ihn zu Grabe trug,", "tokens": ["Und", "da", "man", "ihn", "zu", "Gra\u00b7be", "trug", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PIS", "PPER", "APPR", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da weinten Mann und Frauen.", "tokens": ["Da", "wein\u00b7ten", "Mann", "und", "Frau\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.45": {"line.1": {"text": "Da sprach ein Ketzer unter ihnen:", "tokens": ["Da", "sprach", "ein", "Ket\u00b7zer", "un\u00b7ter", "ih\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "APPR", "PPER", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "\u00bbnun hebt ihn auf und tragt ihn hin,", "tokens": ["\u00bb", "nun", "hebt", "ihn", "auf", "und", "tragt", "ihn", "hin", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ADV", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den K\u00f6nig aus deutschen Landen,", "tokens": ["Den", "K\u00f6\u00b7nig", "aus", "deut\u00b7schen", "Lan\u00b7den", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ADJA", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Sollt er uns hie vertrieben han,", "tokens": ["Sollt", "er", "uns", "hie", "ver\u00b7trie\u00b7ben", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "PPER", "PRF", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Das w\u00e4r uns eine gro\u00dfe Schande.\u00ab", "tokens": ["Das", "w\u00e4r", "uns", "ei\u00b7ne", "gro\u00b7\u00dfe", "Schan\u00b7de", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PDS", "VAFIN", "PPER", "ART", "ADJA", "NN", "$.", "$("], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.46": {"line.1": {"text": "Und da sprach er: \u00bbSieh Girsig,", "tokens": ["Und", "da", "sprach", "er", ":", "\u00bb", "Sieh", "Gir\u00b7sig", ","], "token_info": ["word", "word", "word", "word", "punct", "punct", "word", "word", "punct"], "pos": ["KON", "ADV", "VVFIN", "PPER", "$.", "$(", "NE", "NE", "$,"], "meter": "--+--+-", "measure": "anapaest.di.plus"}, "line.2": {"text": "Der K\u00f6nig in B\u00f6hmen bin ich,", "tokens": ["Der", "K\u00f6\u00b7nig", "in", "B\u00f6h\u00b7men", "bin", "ich", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "NE", "VAFIN", "PPER", "$,"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.3": {"text": "K\u00f6nig Lasla ist gestorben,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "ist", "ge\u00b7stor\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "VVPP", "$,"], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Um seines falschen Glaubens willen,", "tokens": ["Um", "sei\u00b7nes", "fal\u00b7schen", "Glau\u00b7bens", "wil\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPOSAT", "ADJA", "NN", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Darum ist er verdorben.\u00ab", "tokens": ["Da\u00b7rum", "ist", "er", "ver\u00b7dor\u00b7ben", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "punct", "punct"], "pos": ["PAV", "VAFIN", "PPER", "VVPP", "$.", "$("], "meter": "-++--+-", "measure": "iambic.tri.relaxed"}}, "stanza.47": {"line.1": {"text": "Da sprach er, der Rockenzahn:", "tokens": ["Da", "sprach", "er", ",", "der", "Ro\u00b7cken\u00b7zahn", ":"], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "$,", "ART", "NN", "$."], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.2": {"text": "\u00bbeine neue Sitte nehm ich an,", "tokens": ["\u00bb", "ei\u00b7ne", "neu\u00b7e", "Sit\u00b7te", "nehm", "ich", "an", ","], "token_info": ["punct", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["$(", "ART", "ADJA", "NN", "VVFIN", "PPER", "PTKVZ", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Oestreich will ich zerst\u00f6ren;", "tokens": ["O\u00b7e\u00b7streich", "will", "ich", "zer\u00b7st\u00f6\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "VMFIN", "PPER", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}, "line.4": {"text": "Denn ihren Glauben wei\u00df ich wohl,", "tokens": ["Denn", "ih\u00b7ren", "Glau\u00b7ben", "wei\u00df", "ich", "wohl", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "VVFIN", "PPER", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihr Herzog will ich werden.\u00ab", "tokens": ["Ihr", "Her\u00b7zog", "will", "ich", "wer\u00b7den", ".", "\u00ab"], "token_info": ["word", "word", "word", "word", "word", "punct", "punct"], "pos": ["PPOSAT", "NN", "VMFIN", "PPER", "VAINF", "$.", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Der Girsig der ist hochgeborn,", "tokens": ["Der", "Gir\u00b7sig", "der", "ist", "hoch\u00b7ge\u00b7born", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NE", "ART", "VAFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Recht als ein Sau ist er beschoren,", "tokens": ["Recht", "als", "ein", "Sau", "ist", "er", "be\u00b7scho\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "KOKOM", "ART", "NN", "VAFIN", "PPER", "VVINF", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.3": {"text": "Wer ist der ihm wohl gleiche,", "tokens": ["Wer", "ist", "der", "ihm", "wohl", "glei\u00b7che", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "VAFIN", "ART", "PPER", "ADV", "ADJA", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Mit Rauben, mit Stehlen, mit Bannerey,", "tokens": ["Mit", "Rau\u00b7ben", ",", "mit", "Steh\u00b7len", ",", "mit", "Ban\u00b7ne\u00b7rey", ","], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NN", "$,", "APPR", "NN", "$,", "APPR", "NN", "$,"], "meter": "-+--+--+-+", "measure": "amphibrach.tri.plus"}, "line.5": {"text": "Damit er worden reiche.", "tokens": ["Da\u00b7mit", "er", "wor\u00b7den", "rei\u00b7che", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "VAPP", "ADJA", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "K\u00f6nig Lasla war ein junger Mann,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "war", "ein", "jun\u00b7ger", "Mann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "VAFIN", "ART", "ADJA", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.2": {"text": "Er wollt den Girsig bei sich han,", "tokens": ["Er", "wollt", "den", "Gir\u00b7sig", "bei", "sich", "han", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ART", "NE", "APPR", "PRF", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Er hat ihn auserkohren;", "tokens": ["Er", "hat", "ihn", "au\u00b7ser\u00b7koh\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja ich sprechs auf die Treue mein,", "tokens": ["Ja", "ich", "sprechs", "auf", "die", "Treu\u00b7e", "mein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "PPER", "VVFIN", "APPR", "ART", "NN", "PPOSAT", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er ist ihm treulos worden.", "tokens": ["Er", "ist", "ihm", "treu\u00b7los", "wor\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "ADJD", "VAPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.50": {"line.1": {"text": "K\u00f6nig Lasla du viel edles Blut,", "tokens": ["K\u00f6\u00b7nig", "Las\u00b7la", "du", "viel", "ed\u00b7les", "Blut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "NE", "PPER", "PIAT", "ADJA", "NN", "$,"], "meter": "+--+--+-+", "measure": "dactylic.di.plus"}, "line.2": {"text": "Gott erhalte dich in seiner Hut,", "tokens": ["Gott", "er\u00b7hal\u00b7te", "dich", "in", "sei\u00b7ner", "Hut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "VVFIN", "PPER", "APPR", "PPOSAT", "NN", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Mit seinem lieben Kinde,", "tokens": ["Mit", "sei\u00b7nem", "lie\u00b7ben", "Kin\u00b7de", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "ADJA", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Da\u00df du also verschieden bist,", "tokens": ["Da\u00df", "du", "al\u00b7so", "ver\u00b7schie\u00b7den", "bist", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVPP", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Mit deinem Hofgesinde.", "tokens": ["Mit", "dei\u00b7nem", "Hof\u00b7ge\u00b7sin\u00b7de", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}}}}