{"textgrid.poem.33323": {"metadata": {"author": {"name": "Blumauer, Aloys", "birth": "N.A.", "death": "N.A."}, "title": "Prolog zu Herrn Nicolai's neuester Reisebeschreibung von Obermayer", "genre": "verse", "period": "N.A.", "pub_year": 1776, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Der b\u00f6sen Kritik Ursprung f\u00e4llt", "tokens": ["Der", "b\u00f6\u00b7sen", "Kri\u00b7tik", "Ur\u00b7sprung", "f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gerade in das Jahr der Welt,", "tokens": ["Ge\u00b7ra\u00b7de", "in", "das", "Jahr", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das man nicht darf bedeuten;", "tokens": ["Das", "man", "nicht", "darf", "be\u00b7deu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil sich zwei gro\u00dfe Kritiker,", "tokens": ["Weil", "sich", "zwei", "gro\u00b7\u00dfe", "Kri\u00b7ti\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Petavius und Skaliger,", "tokens": ["Pe\u00b7ta\u00b7vius", "und", "Ska\u00b7li\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Grabe d'rum noch streiten.", "tokens": ["Im", "Gra\u00b7be", "d'\u00b7rum", "noch", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.2": {"line.1": {"text": "Kurzum, der erste Kritiker", "tokens": ["Kur\u00b7zum", ",", "der", "ers\u00b7te", "Kri\u00b7ti\u00b7ker"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "ADJA", "NN"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "War Cham: der ging zum Luzifer", "tokens": ["War", "Cham", ":", "der", "ging", "zum", "Lu\u00b7zi\u00b7fer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "$.", "ART", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sechs Monat' in die Lehre:", "tokens": ["Sechs", "Mo\u00b7nat'", "in", "die", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er zeigte bald recht viel Geschick,", "tokens": ["Er", "zeig\u00b7te", "bald", "recht", "viel", "Ge\u00b7schick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und machte durch sein Meisterst\u00fcck", "tokens": ["Und", "mach\u00b7te", "durch", "sein", "Meis\u00b7ter\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Meister sehr viel Ehre.", "tokens": ["Dem", "Meis\u00b7ter", "sehr", "viel", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.3": {"line.1": {"text": "Denn als sein Herr Papa sich krank", "tokens": ["Denn", "als", "sein", "Herr", "Pa\u00b7pa", "sich", "krank"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am ersten Ratzerstorfer trank,", "tokens": ["Am", "ers\u00b7ten", "Rat\u00b7zer\u00b7stor\u00b7fer", "trank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(und wie's im heissen Lande", "tokens": ["(", "und", "wie's", "im", "heis\u00b7sen", "Lan\u00b7de"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Oft Bl\u00f6ssen gibt) so sah er ihn,", "tokens": ["Oft", "Bl\u00f6s\u00b7sen", "gibt", ")", "so", "sah", "er", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und zeigte mit dem Finger hin,", "tokens": ["Und", "zeig\u00b7te", "mit", "dem", "Fin\u00b7ger", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf seines Vaters Schande.", "tokens": ["Auf", "sei\u00b7nes", "Va\u00b7ters", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.4": {"line.1": {"text": "Doch, h\u00e4tte schon um diese Zeit", "tokens": ["Doch", ",", "h\u00e4t\u00b7te", "schon", "um", "die\u00b7se", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "VAFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von derlei Bl\u00f6ssen W\u00fcrdigkeit", "tokens": ["Von", "der\u00b7lei", "Bl\u00f6s\u00b7sen", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Pr\u00e4putius", "tokens": ["Pr\u00e4\u00b7pu\u00b7tius"], "token_info": ["word"], "pos": ["NE"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Es w\u00e4re, das versichr' ich euch,", "tokens": ["Es", "w\u00e4\u00b7re", ",", "das", "ver\u00b7sichr'", "ich", "euch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der unversch\u00e4mte Fingerzeig", "tokens": ["Der", "un\u00b7ver\u00b7sch\u00e4m\u00b7te", "Fin\u00b7ger\u00b7zeig"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gewi\u00dflich unterblieben.", "tokens": ["Ge\u00b7wi\u00df\u00b7lich", "un\u00b7ter\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.5": {"line.1": {"text": "So aber ward der Wein verflucht,", "tokens": ["So", "a\u00b7ber", "ward", "der", "Wein", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und macht nun dem, der ihn versucht,", "tokens": ["Und", "macht", "nun", "dem", ",", "der", "ihn", "ver\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Koliken im Gehirne:", "tokens": ["Ko\u00b7li\u00b7ken", "im", "Ge\u00b7hir\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wir selbst sah'n noch zu uns'rer Zeit,", "tokens": ["Wir", "selbst", "sah'n", "noch", "zu", "un\u00b7s'\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Die Folgen seiner Sch\u00e4dlichkeit", "tokens": ["Die", "Fol\u00b7gen", "sei\u00b7ner", "Sch\u00e4d\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An Nicolai's Stirne.", "tokens": ["An", "Ni\u00b7co\u00b7lai's", "Stir\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.6": {"line.1": {"text": "Allein davon ein andermal \u2013", "tokens": ["Al\u00b7lein", "da\u00b7von", "ein", "an\u00b7der\u00b7mal", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ART", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kritik ward nun \u00fcberall", "tokens": ["Die", "Kri\u00b7tik", "ward", "nun", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Cham's Gebl\u00fct verbreitet:", "tokens": ["Durch", "Cham's", "Ge\u00b7bl\u00fct", "ver\u00b7brei\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Sara's Runzeln, Abram's Bart,", "tokens": ["Auf", "Sa\u00b7ra's", "Run\u00b7zeln", ",", "Ab\u00b7ram's", "Bart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus Ziegen, Ochsen, Schafe ward", "tokens": ["Aus", "Zie\u00b7gen", ",", "Och\u00b7sen", ",", "Scha\u00b7fe", "ward"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Fingern hingedeutet.", "tokens": ["Mit", "Fin\u00b7gern", "hin\u00b7ge\u00b7deu\u00b7tet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.7": {"line.1": {"text": "Noch \u00e4rger ging's zu Babel her,", "tokens": ["Noch", "\u00e4r\u00b7ger", "ging's", "zu", "Ba\u00b7bel", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war kein Ziegel, den das Heer", "tokens": ["Da", "war", "kein", "Zie\u00b7gel", ",", "den", "das", "Heer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Kritiker verschonte,", "tokens": ["Der", "Kri\u00b7ti\u00b7ker", "ver\u00b7schon\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Woher es denn auch kommen mag,", "tokens": ["Wo\u00b7her", "es", "denn", "auch", "kom\u00b7men", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man damit bis diesen Tag", "tokens": ["Da\u00df", "man", "da\u00b7mit", "bis", "die\u00b7sen", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PAV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht fertig werden konnte.", "tokens": ["Nicht", "fer\u00b7tig", "wer\u00b7den", "konn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.8": {"line.1": {"text": "Und eben von dem Saus und Braus", "tokens": ["Und", "e\u00b7ben", "von", "dem", "Saus", "und", "Braus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bekam das grosse Schneckenhaus", "tokens": ["Be\u00b7kam", "das", "gros\u00b7se", "Schne\u00b7cken\u00b7haus"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den b\u00f6sen Namen Babel;", "tokens": ["Den", "b\u00f6\u00b7sen", "Na\u00b7men", "Ba\u00b7bel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denn als sie's gar zu bunt gemacht,", "tokens": ["Denn", "als", "sie's", "gar", "zu", "bunt", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wuchs jedem Kritler \u00fcber Nacht", "tokens": ["Wuchs", "je\u00b7dem", "Krit\u00b7ler", "\u00fc\u00b7ber", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Straf ein andr'er Schnabel.", "tokens": ["Zur", "Straf", "ein", "andr'\u00b7er", "Schna\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.9": {"line.1": {"text": "Das Kritlervolk zerstreute sich", "tokens": ["Das", "Krit\u00b7ler\u00b7volk", "zer\u00b7streu\u00b7te", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun unter jeden Himmelsstrich,", "tokens": ["Nun", "un\u00b7ter", "je\u00b7den", "Him\u00b7mels\u00b7strich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward kecker in der Ferne,", "tokens": ["Ward", "ke\u00b7cker", "in", "der", "Fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und bellt nun, wenn es ihm gef\u00e4llt,", "tokens": ["Und", "bellt", "nun", ",", "wenn", "es", "ihm", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie der Hund den Mond anbellt,", "tokens": ["So", "wie", "der", "Hund", "den", "Mond", "an\u00b7bellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hinan bis an die Sterne.", "tokens": ["Hi\u00b7nan", "bis", "an", "die", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.10": {"line.1": {"text": "Der Zeichendeuter Balaam", "tokens": ["Der", "Zei\u00b7chen\u00b7deu\u00b7ter", "Ba\u00b7laam"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Lie\u00df sich der erste ohne Schaam", "tokens": ["Lie\u00df", "sich", "der", "ers\u00b7te", "oh\u00b7ne", "Schaam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Geld und Schimpfen dingen:", "tokens": ["Mit", "Geld", "und", "Schimp\u00b7fen", "din\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er wollte los gen Israel zieh'n,", "tokens": ["Er", "woll\u00b7te", "los", "gen", "Is\u00b7rael", "zieh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch gl\u00fcckt' es seinem Esel, ihn", "tokens": ["Doch", "gl\u00fcckt'", "es", "sei\u00b7nem", "E\u00b7sel", ",", "ihn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch zur Raison zu bringen.", "tokens": ["Noch", "zur", "Rai\u00b7son", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.11": {"line.1": {"text": "Daf\u00fcr gelang's dem Semei,", "tokens": ["Da\u00b7f\u00fcr", "ge\u00b7lang's", "dem", "Se\u00b7mei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der seinem Herrn in's Antlitz spie,", "tokens": ["Der", "sei\u00b7nem", "Herrn", "in's", "Ant\u00b7litz", "spie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich zu nobilitiren:", "tokens": ["Sich", "zu", "no\u00b7bi\u00b7li\u00b7ti\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Denn der Minister machte kund:", "tokens": ["Denn", "der", "Mi\u00b7nis\u00b7ter", "mach\u00b7te", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sollt' hinf\u00fcr den Titel: ", "tokens": ["Er", "sollt'", "hin\u00b7f\u00fcr", "den", "Ti\u00b7tel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Im Pr\u00e4dikate f\u00fchren", "tokens": ["Im", "Pr\u00e4\u00b7di\u00b7ka\u00b7te", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.12": {"line.1": {"text": "Inde\u00df die Kritik auf der Welt", "tokens": ["In\u00b7de\u00df", "die", "Kri\u00b7tik", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Amt bald gratis, bald um's Geld", "tokens": ["Ihr", "Amt", "bald", "gra\u00b7tis", ",", "bald", "um's", "Geld"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So ziemlich leidlich f\u00fchrte,", "tokens": ["So", "ziem\u00b7lich", "leid\u00b7lich", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geschahe in der Himmelsburg", "tokens": ["Ge\u00b7scha\u00b7he", "in", "der", "Him\u00b7mels\u00b7burg"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Ungl\u00fcck, das sie durch und durch", "tokens": ["Ein", "Un\u00b7gl\u00fcck", ",", "das", "sie", "durch", "und", "durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Giftschaum inpr\u00e4gnirte.", "tokens": ["Mit", "Gift\u00b7schaum", "in\u00b7pr\u00e4g\u00b7nir\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}}, "stanza.13": {"line.1": {"text": "Der alte Momus, der bisher", "tokens": ["Der", "al\u00b7te", "Mo\u00b7mus", ",", "der", "bis\u00b7her"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Am Hof des Vaters Jupiter", "tokens": ["Am", "Hof", "des", "Va\u00b7ters", "Ju\u00b7pi\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.3": {"text": "Den Tischhannswursten spielte,", "tokens": ["Den", "Tischhanns\u00b7wurs\u00b7ten", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Als er einst Junons M\u00f6pschen stie\u00df,", "tokens": ["Als", "er", "einst", "Ju\u00b7nons", "M\u00f6p\u00b7schen", "stie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bekam von ihm solch einen Bi\u00df,", "tokens": ["Be\u00b7kam", "von", "ihm", "solch", "ei\u00b7nen", "Bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er vor Schmerzen br\u00fcllte.", "tokens": ["Da\u00df", "er", "vor", "Schmer\u00b7zen", "br\u00fcll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.14": {"line.1": {"text": "Und weil das H\u00fcndchen w\u00fcthig war,", "tokens": ["Und", "weil", "das", "H\u00fcnd\u00b7chen", "w\u00fct\u00b7hig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ward es auch der arme Narr,", "tokens": ["So", "ward", "es", "auch", "der", "ar\u00b7me", "Narr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es schwoll ihm Mund und Kehle;", "tokens": ["Es", "schwoll", "ihm", "Mund", "und", "Keh\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und jedes W\u00f6rtchen, das er sprach,", "tokens": ["Und", "je\u00b7des", "W\u00f6rt\u00b7chen", ",", "das", "er", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ward auf der Zunge Gift, und stach", "tokens": ["Ward", "auf", "der", "Zun\u00b7ge", "Gift", ",", "und", "stach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die G\u00f6tter in die Seele.", "tokens": ["Die", "G\u00f6t\u00b7ter", "in", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.15": {"line.1": {"text": "Er tobt' und sch\u00e4umte f\u00fcrchterlich,", "tokens": ["Er", "tobt'", "und", "sch\u00e4um\u00b7te", "f\u00fcrch\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df unter'n G\u00f6ttern wild um sich", "tokens": ["Bi\u00df", "un\u00b7ter'n", "G\u00f6t\u00b7tern", "wild", "um", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJD", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihren Kammerdienern;", "tokens": ["Und", "ih\u00b7ren", "Kam\u00b7mer\u00b7die\u00b7nern", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kurzum, er spielte allen mit,", "tokens": ["Kur\u00b7zum", ",", "er", "spiel\u00b7te", "al\u00b7len", "mit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie unl\u00e4ngst ein Nicolait", "tokens": ["Wie", "un\u00b7l\u00e4ngst", "ein", "Ni\u00b7co\u00b7lait"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Es machte mit den Wienern.", "tokens": ["Es", "mach\u00b7te", "mit", "den", "Wie\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.16": {"line.1": {"text": "Seit dieser Zeit ist Kritelei", "tokens": ["Seit", "die\u00b7ser", "Zeit", "ist", "Kri\u00b7te\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und b\u00f6se Hundswuth einerlei:", "tokens": ["Und", "b\u00f6\u00b7se", "Hunds\u00b7wuth", "ei\u00b7ner\u00b7lei", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gift fieng an zu schleichen,", "tokens": ["Das", "Gift", "fi\u00b7eng", "an", "zu", "schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und ist, k\u00f6mmt's gleich vom Himmel her,", "tokens": ["Und", "ist", ",", "k\u00f6mmt's", "gleich", "vom", "Him\u00b7mel", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "NE", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Menschen nun gleich schrecklicher,", "tokens": ["Den", "Men\u00b7schen", "nun", "gleich", "schreck\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Als Pest und and're Seuchen.", "tokens": ["Als", "Pest", "und", "an\u00b7d'\u00b7re", "Seu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.17": {"line.1": {"text": "Denn ach! vom Kritlergifte wird", "tokens": ["Denn", "ach", "!", "vom", "Krit\u00b7ler\u00b7gif\u00b7te", "wird"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$.", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man augenblicklich inficirt", "tokens": ["Man", "au\u00b7gen\u00b7blick\u00b7lich", "in\u00b7fi\u00b7cirt"], "token_info": ["word", "word", "word"], "pos": ["PIS", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Fu\u00df bis auf zum Scheitel;", "tokens": ["Vom", "Fu\u00df", "bis", "auf", "zum", "Schei\u00b7tel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja vor dem Bi\u00df des Kritikus", "tokens": ["Ja", "vor", "dem", "Bi\u00df", "des", "Kri\u00b7ti\u00b7kus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "APPR", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sch\u00fctzt nicht einmal Merkurius \u2013", "tokens": ["Sch\u00fctzt", "nicht", "ein\u00b7mal", "Mer\u00b7ku\u00b7rius", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur h\u00f6chstens noch sein Beutel.", "tokens": ["Nur", "h\u00f6chs\u00b7tens", "noch", "sein", "Beu\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.18": {"line.1": {"text": "Dabei ist dieses Gift sehr fein,", "tokens": ["Da\u00b7bei", "ist", "die\u00b7ses", "Gift", "sehr", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man kann es in ein Briefelein", "tokens": ["Man", "kann", "es", "in", "ein", "Brie\u00b7fel\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ganz leichtlich einballiren;", "tokens": ["Ganz", "leicht\u00b7lich", "ein\u00b7bal\u00b7li\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Man liest, und ist des Giftes voll,", "tokens": ["Man", "liest", ",", "und", "ist", "des", "Gif\u00b7tes", "voll", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und so kann man von einem Pol", "tokens": ["Und", "so", "kann", "man", "von", "ei\u00b7nem", "Pol"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PIS", "APPR", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Zum andern inficiren.", "tokens": ["Zum", "an\u00b7dern", "in\u00b7fi\u00b7ci\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.19": {"line.1": {"text": "Ja, was noch mehr, es ist so scharf,", "tokens": ["Ja", ",", "was", "noch", "mehr", ",", "es", "ist", "so", "scharf", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "ADV", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man's nur sehen lassen darf,", "tokens": ["Da\u00df", "man's", "nur", "se\u00b7hen", "las\u00b7sen", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um Unheil anzustiften;", "tokens": ["Um", "Un\u00b7heil", "an\u00b7zu\u00b7stif\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch kann man nach Jahrtausenden", "tokens": ["Auch", "kann", "man", "nach", "Jahr\u00b7tau\u00b7sen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit die Abgeschiedenen", "tokens": ["Da\u00b7mit", "die", "Ab\u00b7ge\u00b7schie\u00b7de\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Im Grabe noch vergiften.", "tokens": ["Im", "Gra\u00b7be", "noch", "ver\u00b7gif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.20": {"line.1": {"text": "Nun sollt ihr Herr'n noch kurz und gut", "tokens": ["Nun", "sollt", "ihr", "Herr'n", "noch", "kurz", "und", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von der besagten Krittlerwuth", "tokens": ["Von", "der", "be\u00b7sag\u00b7ten", "Kritt\u00b7ler\u00b7wuth"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den ganzen Stammbaum wissen:", "tokens": ["Den", "gan\u00b7zen", "Stamm\u00b7baum", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gebt Acht: Man hat von Momus an", "tokens": ["Gebt", "Acht", ":", "Man", "hat", "von", "Mo\u00b7mus", "an"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "CARD", "$.", "PIS", "VAFIN", "APPR", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis auf den heut'gen Tag fortan", "tokens": ["Bis", "auf", "den", "heut'\u00b7gen", "Tag", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Einander sich gebissen.", "tokens": ["Ein\u00b7an\u00b7der", "sich", "ge\u00b7bis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.21": {"line.1": {"text": "Mit rechtem Hundesappetit", "tokens": ["Mit", "rech\u00b7tem", "Hun\u00b7de\u00b7sap\u00b7pe\u00b7tit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df einst Herr Momus den Thersit,", "tokens": ["Bi\u00df", "einst", "Herr", "Mo\u00b7mus", "den", "Ther\u00b7sit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NN", "NE", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So kam das Gift schon weiter:", "tokens": ["So", "kam", "das", "Gift", "schon", "wei\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil der Gebi\u00dfne bei\u00dfen mu\u00df,", "tokens": ["Weil", "der", "Ge\u00b7bi\u00df\u00b7ne", "bei\u00b7\u00dfen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So bi\u00df Thersit den Zoilus,", "tokens": ["So", "bi\u00df", "Ther\u00b7sit", "den", "Zoi\u00b7lus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Homerens Sylbenreiter.", "tokens": ["Ho\u00b7me\u00b7rens", "Syl\u00b7ben\u00b7rei\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.22": {"line.1": {"text": "Herr Zoilus war auch nicht faul,", "tokens": ["Herr", "Zoi\u00b7lus", "war", "auch", "nicht", "faul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und bi\u00df den Aristarch in's Maul,", "tokens": ["Und", "bi\u00df", "den", "A\u00b7rist\u00b7arch", "in's", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den grossen Splitterrichter;", "tokens": ["Den", "gros\u00b7sen", "Split\u00b7ter\u00b7rich\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der aber bi\u00df den Mevius,", "tokens": ["Der", "a\u00b7ber", "bi\u00df", "den", "Me\u00b7vius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Mev aber bi\u00df nun aus Verdru\u00df", "tokens": ["Mev", "a\u00b7ber", "bi\u00df", "nun", "aus", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Herrn Martial, den Dichter.", "tokens": ["Herrn", "Mar\u00b7ti\u00b7al", ",", "den", "Dich\u00b7ter."], "token_info": ["word", "word", "punct", "word", "abbreviation"], "pos": ["NN", "NE", "$,", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.23": {"line.1": {"text": "Und Skaliger, gelehrt, durch ihn,", "tokens": ["Und", "Ska\u00b7li\u00b7ger", ",", "ge\u00b7lehrt", ",", "durch", "ihn", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "VVPP", "$,", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df den Muretus", "tokens": ["Bi\u00df", "den", "Mu\u00b7re\u00b7tus"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Das m\u00fc\u00dft ihr mich nicht fragen:", "tokens": ["Das", "m\u00fc\u00dft", "ihr", "mich", "nicht", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wenn es denn gesagt seyn mu\u00df,", "tokens": ["Und", "wenn", "es", "denn", "ge\u00b7sagt", "seyn", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So gehet hin, \u2013 Pr\u00e4putius", "tokens": ["So", "ge\u00b7het", "hin", ",", "\u2013", "Pr\u00e4\u00b7pu\u00b7tius"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "$(", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wird euch's statt meiner sagen.", "tokens": ["Wird", "euch's", "statt", "mei\u00b7ner", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.24": {"line.1": {"text": "Der hochgelehrte Fleischerhund", "tokens": ["Der", "hoch\u00b7ge\u00b7lehr\u00b7te", "Flei\u00b7scher\u00b7hund"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sciopius bi\u00df alles wund,", "tokens": ["Scio\u00b7pius", "bi\u00df", "al\u00b7les", "wund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was er nur wahrgenommen,", "tokens": ["Was", "er", "nur", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und weil er die Jesuiten bi\u00df,", "tokens": ["Und", "weil", "er", "die", "Je\u00b7su\u00b7i\u00b7ten", "bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "So ist das Gift auch unter die\u00df", "tokens": ["So", "ist", "das", "Gift", "auch", "un\u00b7ter", "die\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "PDS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.25": {"line.1": {"text": "Hier ward es noch gef\u00e4hrlicher,", "tokens": ["Hier", "ward", "es", "noch", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dann schleichend Gift und trieb nicht mehr", "tokens": ["Dann", "schlei\u00b7chend", "Gift", "und", "trieb", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "NN", "KON", "VVFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Schaum heraus zum Munde;", "tokens": ["Den", "Schaum", "he\u00b7raus", "zum", "Mun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es war oft, eh man sich's versah,", "tokens": ["Es", "war", "oft", ",", "eh", "man", "sich's", "ver\u00b7sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im Leibe des Gebi\u00dfnen da,", "tokens": ["Im", "Lei\u00b7be", "des", "Ge\u00b7bi\u00df\u00b7nen", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch sah man keine Wunde.", "tokens": ["Doch", "sah", "man", "kei\u00b7ne", "Wun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.26": {"line.1": {"text": "Allein mit gifterf\u00fclltem Zahn", "tokens": ["Al\u00b7lein", "mit", "gif\u00b7ter\u00b7f\u00fcll\u00b7tem", "Zahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fiel Burmann einst Herrn Klotzen an,", "tokens": ["Fiel", "Bur\u00b7mann", "einst", "Herrn", "Klot\u00b7zen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zwickt' ihn in die Wade;", "tokens": ["Und", "zwickt'", "ihn", "in", "die", "Wa\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Klotz ward nun auch dem Wasser gram,", "tokens": ["Klotz", "ward", "nun", "auch", "dem", "Was\u00b7ser", "gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wer ihm nur zu nahe kam,", "tokens": ["Und", "wer", "ihm", "nur", "zu", "na\u00b7he", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den bi\u00df er ohne Gnade.", "tokens": ["Den", "bi\u00df", "er", "oh\u00b7ne", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.27": {"line.1": {"text": "Er bi\u00df gar schrecklich um sich her,", "tokens": ["Er", "bi\u00df", "gar", "schreck\u00b7lich", "um", "sich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es wollte schon kein Autor mehr", "tokens": ["Es", "woll\u00b7te", "schon", "kein", "Au\u00b7tor", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf off'ner Strasse gehen,", "tokens": ["Auf", "off'\u00b7ner", "Stras\u00b7se", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herr Doktor Lessing gab ihm zwar", "tokens": ["Herr", "Dok\u00b7tor", "Les\u00b7sing", "gab", "ihm", "zwar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "NE", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Schwitzen ein, allein es war", "tokens": ["Zum", "Schwit\u00b7zen", "ein", ",", "al\u00b7lein", "es", "war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "ADV", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun schon einmal geschehen.", "tokens": ["Nun", "schon", "ein\u00b7mal", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.28": {"line.1": {"text": "Einst als die Wuth in's Hirn ihm scho\u00df,", "tokens": ["Einst", "als", "die", "Wuth", "in's", "Hirn", "ihm", "scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging er auf Nikolai los,", "tokens": ["Ging", "er", "auf", "Ni\u00b7ko\u00b7lai", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und packt' ihn bei den Ohren:", "tokens": ["Und", "packt'", "ihn", "bei", "den", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Arme schrie gar j\u00e4mmerlich:", "tokens": ["Der", "Ar\u00b7me", "schrie", "gar", "j\u00e4m\u00b7mer\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Iha! Iha! \u2013 und f\u00fchlte sich", "tokens": ["I\u00b7ha", "!", "I\u00b7ha", "!", "\u2013", "und", "f\u00fchl\u00b7te", "sich"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "$.", "NE", "$.", "$(", "KON", "VVFIN", "PRF"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Zum Kritler auserkohren.", "tokens": ["Zum", "Krit\u00b7ler", "au\u00b7ser\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.29": {"line.1": {"text": "Nun war das Gift im rechten Mann:", "tokens": ["Nun", "war", "das", "Gift", "im", "rech\u00b7ten", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er sch\u00e4umte wild, und bi\u00df fortan", "tokens": ["Er", "sch\u00e4um\u00b7te", "wild", ",", "und", "bi\u00df", "for\u00b7tan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "KON", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Jedem in die Wette,", "tokens": ["Mit", "Je\u00b7dem", "in", "die", "Wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Polizei litt in Berlin", "tokens": ["Die", "Po\u00b7li\u00b7zei", "litt", "in", "Ber\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Das Beissen nicht, d'rum schlo\u00df man ihn", "tokens": ["Das", "Beis\u00b7sen", "nicht", ",", "d'\u00b7rum", "schlo\u00df", "man", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "$,", "ADV", "VVFIN", "PIS", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "An eine lange Kette.", "tokens": ["An", "ei\u00b7ne", "lan\u00b7ge", "Ket\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.30": {"line.1": {"text": "Doch um das Gift, das ihm fortan", "tokens": ["Doch", "um", "das", "Gift", ",", "das", "ihm", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Str\u00f6men aus dem Munde rann,", "tokens": ["In", "Str\u00f6\u00b7men", "aus", "dem", "Mun\u00b7de", "rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Deutschland zu verbreiten,", "tokens": ["Durch", "Deutschland", "zu", "ver\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "So lie\u00df er f\u00fcr den Giftschaum all'", "tokens": ["So", "lie\u00df", "er", "f\u00fcr", "den", "Gift\u00b7schaum", "all'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich einen eigenen Kanal", "tokens": ["Sich", "ei\u00b7nen", "ei\u00b7ge\u00b7nen", "Ka\u00b7nal"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von L\u00f6schpapier bereiten.", "tokens": ["Von", "L\u00f6schpa\u00b7pier", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.31": {"line.1": {"text": "Vor diesem m\u00e4chtigen Kanal", "tokens": ["Vor", "die\u00b7sem", "m\u00e4ch\u00b7ti\u00b7gen", "Ka\u00b7nal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df er die grossen M\u00e4nner all'", "tokens": ["Lie\u00df", "er", "die", "gros\u00b7sen", "M\u00e4n\u00b7ner", "all'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Kupfer konterfeien,", "tokens": ["In", "Kup\u00b7fer", "kon\u00b7ter\u00b7fei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Um ihnen, wenn's ihn l\u00fcstete,", "tokens": ["Um", "ih\u00b7nen", ",", "wenn's", "ihn", "l\u00fcs\u00b7te\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum mind'sten in ", "tokens": ["Zum", "min\u00b7d'\u00b7sten", "in"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "In's Angesicht zu speien.", "tokens": ["In's", "An\u00b7ge\u00b7sicht", "zu", "spei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.32": {"line.1": {"text": "Bald fiel's ihm ein, die Dichterschaar", "tokens": ["Bald", "fiel's", "ihm", "ein", ",", "die", "Dich\u00b7ter\u00b7schaar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nicht so, wie sein Ramler, war,", "tokens": ["Die", "nicht", "so", ",", "wie", "sein", "Ram\u00b7ler", ",", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In St\u00fccke zu zerreissen;", "tokens": ["In", "St\u00fc\u00b7cke", "zu", "zer\u00b7reis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bald wandelte die Lust ihn an,", "tokens": ["Bald", "wan\u00b7del\u00b7te", "die", "Lust", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Teufel, der ihm nichts gethan,", "tokens": ["Den", "Teu\u00b7fel", ",", "der", "ihm", "nichts", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur H\u00f6ll' hinauszubeissen.", "tokens": ["Zur", "H\u00f6ll'", "hin\u00b7aus\u00b7zu\u00b7beis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.33": {"line.1": {"text": "Einst fiel er einen Britten an", "tokens": ["Einst", "fiel", "er", "ei\u00b7nen", "Brit\u00b7ten", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seinem Uebersetzerzahn,", "tokens": ["Mit", "sei\u00b7nem", "Ue\u00b7ber\u00b7set\u00b7zer\u00b7zahn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(denn ach! sein Bauch war eitel)", "tokens": ["(", "denn", "ach", "!", "sein", "Bauch", "war", "ei\u00b7tel", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "XY", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den fra\u00df er, spie ihn d'rauf und hie\u00df", "tokens": ["Den", "fra\u00df", "er", ",", "spie", "ihn", "d'\u00b7rauf", "und", "hie\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Uns essen, doch wer a\u00df, den bi\u00df", "tokens": ["Uns", "es\u00b7sen", ",", "doch", "wer", "a\u00df", ",", "den", "bi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVINF", "$,", "KON", "PWS", "VVFIN", "$,", "PRELS", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er schrecklich in den Beutel.", "tokens": ["Er", "schreck\u00b7lich", "in", "den", "Beu\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.34": {"line.1": {"text": "Mit beiden Pfoten scharrt' er d'rauf", "tokens": ["Mit", "bei\u00b7den", "Pfo\u00b7ten", "scharrt'", "er", "d'\u00b7rauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der Tempelherren Gr\u00e4ber auf,", "tokens": ["Der", "Tem\u00b7pel\u00b7her\u00b7ren", "Gr\u00e4\u00b7ber", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nagt' an ihren Knochen,", "tokens": ["Und", "nagt'", "an", "ih\u00b7ren", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ruhte keinen Augenblick,", "tokens": ["Und", "ruh\u00b7te", "kei\u00b7nen", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis er den Armen das Genick", "tokens": ["Bis", "er", "den", "Ar\u00b7men", "das", "Ge\u00b7nick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum zweitenmal gebrochen.", "tokens": ["Zum", "zwei\u00b7ten\u00b7mal", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.35": {"line.1": {"text": "Einst als die Wuth am h\u00f6chsten war,", "tokens": ["Einst", "als", "die", "Wuth", "am", "h\u00f6chs\u00b7ten", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zerri\u00df er seine Kette gar,", "tokens": ["Zer\u00b7ri\u00df", "er", "sei\u00b7ne", "Ket\u00b7te", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lief nach neuer Beute:", "tokens": ["Und", "lief", "nach", "neu\u00b7er", "Beu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die B\u00f6hmen und die Deutschen sah'n", "tokens": ["Die", "B\u00f6h\u00b7men", "und", "die", "Deut\u00b7schen", "sah'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn laufen, aber jedermann", "tokens": ["Ihn", "lau\u00b7fen", ",", "a\u00b7ber", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ging h\u00fcbsch ihm auf die Seite.", "tokens": ["Ging", "h\u00fcbsch", "ihm", "auf", "die", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.36": {"line.1": {"text": "Gar bald kam er in Wien auch an,", "tokens": ["Gar", "bald", "kam", "er", "in", "Wi\u00b7en", "auch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "NE", "ADV", "PTKVZ", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Hier sch\u00e4rft' er seinen Kritlerzahn", "tokens": ["Hier", "sch\u00e4rft'", "er", "sei\u00b7nen", "Krit\u00b7ler\u00b7zahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu neuen Heldenthaten;", "tokens": ["Zu", "neu\u00b7en", "Hel\u00b7den\u00b7tha\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Trank unsern Ratzerstorfer Wein,", "tokens": ["Trank", "un\u00b7sern", "Rat\u00b7zer\u00b7stor\u00b7fer", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ach, verbi\u00df sich obend'rein", "tokens": ["Und", "ach", ",", "ver\u00b7bi\u00df", "sich", "o\u00b7ben\u00b7d'\u00b7rein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "In unsern Lungenbraten.", "tokens": ["In", "un\u00b7sern", "Lun\u00b7gen\u00b7bra\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.37": {"line.1": {"text": "Allein man scheute seine Wuth,", "tokens": ["Al\u00b7lein", "man", "scheu\u00b7te", "sei\u00b7ne", "Wuth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D'rum fand der Magistrat f\u00fct gut,", "tokens": ["D'\u00b7rum", "fand", "der", "Ma\u00b7gist\u00b7rat", "f\u00fct", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Sogleich zu publiciren:", "tokens": ["Sog\u00b7leich", "zu", "pub\u00b7li\u00b7ci\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zur Sicherheit soll man hinf\u00fcr", "tokens": ["Zur", "Si\u00b7cher\u00b7heit", "soll", "man", "hin\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "PIS", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die tollen Hund' und Krittler hier", "tokens": ["Die", "tol\u00b7len", "Hund'", "und", "Kritt\u00b7ler", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An einem Strickchen f\u00fchren.", "tokens": ["An", "ei\u00b7nem", "Strick\u00b7chen", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.38": {"line.1": {"text": "Auch lag bei hoher Obrigkeit", "tokens": ["Auch", "lag", "bei", "ho\u00b7her", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sankt Huberts Schl\u00fcssel schon bereit,", "tokens": ["Sankt", "Hu\u00b7berts", "Schl\u00fcs\u00b7sel", "schon", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihn damit zu brennen:", "tokens": ["Um", "ihn", "da\u00b7mit", "zu", "bren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch er verlie\u00df, eh dies gescheh'n,", "tokens": ["Doch", "er", "ver\u00b7lie\u00df", ",", "eh", "dies", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um in die Schweiz zu rennen.", "tokens": ["Um", "in", "die", "Schweiz", "zu", "ren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.39": {"line.1": {"text": "Was er gegessen und geseh'n,", "tokens": ["Was", "er", "ge\u00b7ges\u00b7sen", "und", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward in dem Leib des W\u00fcthigen", "tokens": ["Ward", "in", "dem", "Leib", "des", "W\u00fct\u00b7hi\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu Gift im Augenblicke:", "tokens": ["Zu", "Gift", "im", "Au\u00b7gen\u00b7bli\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So kam er toller als vorher,", "tokens": ["So", "kam", "er", "tol\u00b7ler", "als", "vor\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bepackt mit Gifte Zentnerschwer,", "tokens": ["Be\u00b7packt", "mit", "Gif\u00b7te", "Zent\u00b7ner\u00b7schwer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun nach Berlin zur\u00fccke.", "tokens": ["Nun", "nach", "Ber\u00b7lin", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.40": {"line.1": {"text": "Da staunte man ob seiner Wuth,", "tokens": ["Da", "staun\u00b7te", "man", "ob", "sei\u00b7ner", "Wuth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcrchtet' eine S\u00fcndenfluth,", "tokens": ["Und", "f\u00fcrch\u00b7tet'", "ei\u00b7ne", "S\u00fcn\u00b7den\u00b7fluth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Fall er bersten sollte;", "tokens": ["Im", "Fall", "er", "bers\u00b7ten", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich ritt die Polizey herum,", "tokens": ["Gleich", "ritt", "die", "Po\u00b7li\u00b7zey", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die ein ", "tokens": ["Die", "ein"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Daf\u00fcr zusammenholte.", "tokens": ["Da\u00b7f\u00fcr", "zu\u00b7sam\u00b7men\u00b7hol\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.41": {"line.1": {"text": "Man disputirte her und hin,", "tokens": ["Man", "dis\u00b7pu\u00b7tir\u00b7te", "her", "und", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als die Aerzte von Berlin", "tokens": ["Und", "als", "die", "A\u00b7erz\u00b7te", "von", "Ber\u00b7lin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Nun ihre Vota gaben,", "tokens": ["Nun", "ih\u00b7re", "Vo\u00b7ta", "ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So decitirte der, man sollt'", "tokens": ["So", "de\u00b7ci\u00b7tir\u00b7te", "der", ",", "man", "sollt'"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "$,", "PIS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm aderlassen, jener wollt'", "tokens": ["Ihm", "a\u00b7der\u00b7las\u00b7sen", ",", "je\u00b7ner", "wollt'"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVINF", "$,", "PDS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn angezapfet haben.", "tokens": ["Ihn", "an\u00b7ge\u00b7zap\u00b7fet", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.42": {"line.1": {"text": "Allein der Protomedicus", "tokens": ["Al\u00b7lein", "der", "Pro\u00b7to\u00b7me\u00b7di\u00b7cus"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Stand auf, und sprach: ihr Herr'n, hier mu\u00df", "tokens": ["Stand", "auf", ",", "und", "sprach", ":", "ihr", "Herr'n", ",", "hier", "mu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "KON", "VVFIN", "$.", "PPOSAT", "NN", "$,", "ADV", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man keine Zeit verlieren,", "tokens": ["Man", "kei\u00b7ne", "Zeit", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich fand des Giftes ihn so voll,", "tokens": ["Ich", "fand", "des", "Gif\u00b7tes", "ihn", "so", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er sogleich purgiren soll;", "tokens": ["Da\u00df", "er", "sog\u00b7leich", "pur\u00b7gi\u00b7ren", "soll", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.6": {"text": "Und alle schrie'n \u2013 purgieren!", "tokens": ["Und", "al\u00b7le", "schrie'n", "\u2013", "pur\u00b7gie\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.43": {"line.1": {"text": "Man gab ihm ein. Die Dosis war", "tokens": ["Man", "gab", "ihm", "ein", ".", "Die", "Do\u00b7sis", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gewaltig gro\u00df, und macht' ihm gar", "tokens": ["Ge\u00b7wal\u00b7tig", "gro\u00df", ",", "und", "macht'", "ihm", "gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entsetzliche Beschwerden:", "tokens": ["Ent\u00b7setz\u00b7li\u00b7che", "Be\u00b7schwer\u00b7den", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er schrie dabei gar j\u00e4mmerlich,", "tokens": ["Er", "schrie", "da\u00b7bei", "gar", "j\u00e4m\u00b7mer\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und kr\u00fcmmte manche Stunde sich,", "tokens": ["Und", "kr\u00fcmm\u00b7te", "man\u00b7che", "Stun\u00b7de", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Giftes los zu werden.", "tokens": ["Des", "Gif\u00b7tes", "los", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.44": {"line.1": {"text": "Nach langem Drucken endlich wich", "tokens": ["Nach", "lan\u00b7gem", "Dru\u00b7cken", "end\u00b7lich", "wich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gift von ihm, er gab von sich", "tokens": ["Das", "Gift", "von", "ihm", ",", "er", "gab", "von", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PPER", "VVFIN", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Acht dicke B\u00e4nde Reisen:", "tokens": ["Acht", "di\u00b7cke", "B\u00e4n\u00b7de", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dazu lud er uns schriftlich ein,", "tokens": ["Da\u00b7zu", "lud", "er", "uns", "schrift\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und wer von der Partie will sein,", "tokens": ["Und", "wer", "von", "der", "Par\u00b7tie", "will", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "ART", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem w\u00fcnsch' ich \u2013 wohl zu speisen!", "tokens": ["Dem", "w\u00fcn\u00b7sch'", "ich", "\u2013", "wohl", "zu", "spei\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}, "stanza.45": {"line.1": {"text": "Der b\u00f6sen Kritik Ursprung f\u00e4llt", "tokens": ["Der", "b\u00f6\u00b7sen", "Kri\u00b7tik", "Ur\u00b7sprung", "f\u00e4llt"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gerade in das Jahr der Welt,", "tokens": ["Ge\u00b7ra\u00b7de", "in", "das", "Jahr", "der", "Welt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "ART", "NN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das man nicht darf bedeuten;", "tokens": ["Das", "man", "nicht", "darf", "be\u00b7deu\u00b7ten", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "PIS", "PTKNEG", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil sich zwei gro\u00dfe Kritiker,", "tokens": ["Weil", "sich", "zwei", "gro\u00b7\u00dfe", "Kri\u00b7ti\u00b7ker", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PRF", "CARD", "ADJA", "NN", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.5": {"text": "Petavius und Skaliger,", "tokens": ["Pe\u00b7ta\u00b7vius", "und", "Ska\u00b7li\u00b7ger", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["NE", "KON", "NN", "$,"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Im Grabe d'rum noch streiten.", "tokens": ["Im", "Gra\u00b7be", "d'\u00b7rum", "noch", "strei\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "ADV", "VVFIN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.46": {"line.1": {"text": "Kurzum, der erste Kritiker", "tokens": ["Kur\u00b7zum", ",", "der", "ers\u00b7te", "Kri\u00b7ti\u00b7ker"], "token_info": ["word", "punct", "word", "word", "word"], "pos": ["NE", "$,", "ART", "ADJA", "NN"], "meter": "+--+-+--", "measure": "iambic.tri.invert"}, "line.2": {"text": "War Cham: der ging zum Luzifer", "tokens": ["War", "Cham", ":", "der", "ging", "zum", "Lu\u00b7zi\u00b7fer"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["VAFIN", "NE", "$.", "ART", "VVFIN", "APPRART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sechs Monat' in die Lehre:", "tokens": ["Sechs", "Mo\u00b7nat'", "in", "die", "Leh\u00b7re", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["CARD", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er zeigte bald recht viel Geschick,", "tokens": ["Er", "zeig\u00b7te", "bald", "recht", "viel", "Ge\u00b7schick", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "ADV", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und machte durch sein Meisterst\u00fcck", "tokens": ["Und", "mach\u00b7te", "durch", "sein", "Meis\u00b7ter\u00b7st\u00fcck"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem Meister sehr viel Ehre.", "tokens": ["Dem", "Meis\u00b7ter", "sehr", "viel", "Eh\u00b7re", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.47": {"line.1": {"text": "Denn als sein Herr Papa sich krank", "tokens": ["Denn", "als", "sein", "Herr", "Pa\u00b7pa", "sich", "krank"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "PPOSAT", "NN", "NN", "PRF", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Am ersten Ratzerstorfer trank,", "tokens": ["Am", "ers\u00b7ten", "Rat\u00b7zer\u00b7stor\u00b7fer", "trank", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(und wie's im heissen Lande", "tokens": ["(", "und", "wie's", "im", "heis\u00b7sen", "Lan\u00b7de"], "token_info": ["punct", "word", "word", "word", "word", "word"], "pos": ["$(", "KON", "NN", "APPRART", "ADJA", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Oft Bl\u00f6ssen gibt) so sah er ihn,", "tokens": ["Oft", "Bl\u00f6s\u00b7sen", "gibt", ")", "so", "sah", "er", "ihn", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ADV", "NN", "VVFIN", "$(", "ADV", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und zeigte mit dem Finger hin,", "tokens": ["Und", "zeig\u00b7te", "mit", "dem", "Fin\u00b7ger", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Auf seines Vaters Schande.", "tokens": ["Auf", "sei\u00b7nes", "Va\u00b7ters", "Schan\u00b7de", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.48": {"line.1": {"text": "Doch, h\u00e4tte schon um diese Zeit", "tokens": ["Doch", ",", "h\u00e4t\u00b7te", "schon", "um", "die\u00b7se", "Zeit"], "token_info": ["word", "punct", "word", "word", "word", "word", "word"], "pos": ["KON", "$,", "VAFIN", "ADV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von derlei Bl\u00f6ssen W\u00fcrdigkeit", "tokens": ["Von", "der\u00b7lei", "Bl\u00f6s\u00b7sen", "W\u00fcr\u00b7dig\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Pr\u00e4putius", "tokens": ["Pr\u00e4\u00b7pu\u00b7tius"], "token_info": ["word"], "pos": ["NE"], "meter": "+-+", "measure": "trochaic.di"}, "line.4": {"text": "Es w\u00e4re, das versichr' ich euch,", "tokens": ["Es", "w\u00e4\u00b7re", ",", "das", "ver\u00b7sichr'", "ich", "euch", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "PDS", "VVFIN", "PPER", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Der unversch\u00e4mte Fingerzeig", "tokens": ["Der", "un\u00b7ver\u00b7sch\u00e4m\u00b7te", "Fin\u00b7ger\u00b7zeig"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Gewi\u00dflich unterblieben.", "tokens": ["Ge\u00b7wi\u00df\u00b7lich", "un\u00b7ter\u00b7blie\u00b7ben", "."], "token_info": ["word", "word", "punct"], "pos": ["ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.49": {"line.1": {"text": "So aber ward der Wein verflucht,", "tokens": ["So", "a\u00b7ber", "ward", "der", "Wein", "ver\u00b7flucht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und macht nun dem, der ihn versucht,", "tokens": ["Und", "macht", "nun", "dem", ",", "der", "ihn", "ver\u00b7sucht", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "ART", "$,", "PRELS", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Koliken im Gehirne:", "tokens": ["Ko\u00b7li\u00b7ken", "im", "Ge\u00b7hir\u00b7ne", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["NN", "APPRART", "NN", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}, "line.4": {"text": "Wir selbst sah'n noch zu uns'rer Zeit,", "tokens": ["Wir", "selbst", "sah'n", "noch", "zu", "un\u00b7s'\u00b7rer", "Zeit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "VVFIN", "ADV", "APPR", "PPOSAT", "NN", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.5": {"text": "Die Folgen seiner Sch\u00e4dlichkeit", "tokens": ["Die", "Fol\u00b7gen", "sei\u00b7ner", "Sch\u00e4d\u00b7lich\u00b7keit"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An Nicolai's Stirne.", "tokens": ["An", "Ni\u00b7co\u00b7lai's", "Stir\u00b7ne", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$."], "meter": "+-+-+-", "measure": "trochaic.tri"}}, "stanza.50": {"line.1": {"text": "Allein davon ein andermal \u2013", "tokens": ["Al\u00b7lein", "da\u00b7von", "ein", "an\u00b7der\u00b7mal", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PAV", "ART", "ADV", "$("], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die Kritik ward nun \u00fcberall", "tokens": ["Die", "Kri\u00b7tik", "ward", "nun", "\u00fc\u00b7be\u00b7rall"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VAFIN", "ADV", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Cham's Gebl\u00fct verbreitet:", "tokens": ["Durch", "Cham's", "Ge\u00b7bl\u00fct", "ver\u00b7brei\u00b7tet", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auf Sara's Runzeln, Abram's Bart,", "tokens": ["Auf", "Sa\u00b7ra's", "Run\u00b7zeln", ",", "Ab\u00b7ram's", "Bart", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "punct"], "pos": ["APPR", "NE", "NN", "$,", "NE", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Aus Ziegen, Ochsen, Schafe ward", "tokens": ["Aus", "Zie\u00b7gen", ",", "Och\u00b7sen", ",", "Scha\u00b7fe", "ward"], "token_info": ["word", "word", "punct", "word", "punct", "word", "word"], "pos": ["APPR", "NN", "$,", "NN", "$,", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Fingern hingedeutet.", "tokens": ["Mit", "Fin\u00b7gern", "hin\u00b7ge\u00b7deu\u00b7tet", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.51": {"line.1": {"text": "Noch \u00e4rger ging's zu Babel her,", "tokens": ["Noch", "\u00e4r\u00b7ger", "ging's", "zu", "Ba\u00b7bel", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVFIN", "APPR", "NE", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da war kein Ziegel, den das Heer", "tokens": ["Da", "war", "kein", "Zie\u00b7gel", ",", "den", "das", "Heer"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["ADV", "VAFIN", "PIAT", "NN", "$,", "PRELS", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Der Kritiker verschonte,", "tokens": ["Der", "Kri\u00b7ti\u00b7ker", "ver\u00b7schon\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Woher es denn auch kommen mag,", "tokens": ["Wo\u00b7her", "es", "denn", "auch", "kom\u00b7men", "mag", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "ADV", "ADV", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df man damit bis diesen Tag", "tokens": ["Da\u00df", "man", "da\u00b7mit", "bis", "die\u00b7sen", "Tag"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PIS", "PAV", "APPR", "PDAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nicht fertig werden konnte.", "tokens": ["Nicht", "fer\u00b7tig", "wer\u00b7den", "konn\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VAINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.52": {"line.1": {"text": "Und eben von dem Saus und Braus", "tokens": ["Und", "e\u00b7ben", "von", "dem", "Saus", "und", "Braus"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "APPR", "ART", "NN", "KON", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bekam das grosse Schneckenhaus", "tokens": ["Be\u00b7kam", "das", "gros\u00b7se", "Schne\u00b7cken\u00b7haus"], "token_info": ["word", "word", "word", "word"], "pos": ["VVFIN", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den b\u00f6sen Namen Babel;", "tokens": ["Den", "b\u00f6\u00b7sen", "Na\u00b7men", "Ba\u00b7bel", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "NE", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Denn als sie's gar zu bunt gemacht,", "tokens": ["Denn", "als", "sie's", "gar", "zu", "bunt", "ge\u00b7macht", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "PTKA", "ADJD", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wuchs jedem Kritler \u00fcber Nacht", "tokens": ["Wuchs", "je\u00b7dem", "Krit\u00b7ler", "\u00fc\u00b7ber", "Nacht"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["NN", "PIAT", "NN", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur Straf ein andr'er Schnabel.", "tokens": ["Zur", "Straf", "ein", "andr'\u00b7er", "Schna\u00b7bel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.53": {"line.1": {"text": "Das Kritlervolk zerstreute sich", "tokens": ["Das", "Krit\u00b7ler\u00b7volk", "zer\u00b7streu\u00b7te", "sich"], "token_info": ["word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Nun unter jeden Himmelsstrich,", "tokens": ["Nun", "un\u00b7ter", "je\u00b7den", "Him\u00b7mels\u00b7strich", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ward kecker in der Ferne,", "tokens": ["Ward", "ke\u00b7cker", "in", "der", "Fer\u00b7ne", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und bellt nun, wenn es ihm gef\u00e4llt,", "tokens": ["Und", "bellt", "nun", ",", "wenn", "es", "ihm", "ge\u00b7f\u00e4llt", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ADV", "$,", "KOUS", "PPER", "PPER", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So wie der Hund den Mond anbellt,", "tokens": ["So", "wie", "der", "Hund", "den", "Mond", "an\u00b7bellt", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOKOM", "ART", "NN", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Hinan bis an die Sterne.", "tokens": ["Hi\u00b7nan", "bis", "an", "die", "Ster\u00b7ne", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.54": {"line.1": {"text": "Der Zeichendeuter Balaam", "tokens": ["Der", "Zei\u00b7chen\u00b7deu\u00b7ter", "Ba\u00b7laam"], "token_info": ["word", "word", "word"], "pos": ["ART", "NN", "NN"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Lie\u00df sich der erste ohne Schaam", "tokens": ["Lie\u00df", "sich", "der", "ers\u00b7te", "oh\u00b7ne", "Schaam"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PRF", "ART", "ADJA", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Geld und Schimpfen dingen:", "tokens": ["Mit", "Geld", "und", "Schimp\u00b7fen", "din\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "KON", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er wollte los gen Israel zieh'n,", "tokens": ["Er", "woll\u00b7te", "los", "gen", "Is\u00b7rael", "zieh'n", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "ADV", "APPR", "NE", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Doch gl\u00fcckt' es seinem Esel, ihn", "tokens": ["Doch", "gl\u00fcckt'", "es", "sei\u00b7nem", "E\u00b7sel", ",", "ihn"], "token_info": ["word", "word", "word", "word", "word", "punct", "word"], "pos": ["KON", "VVFIN", "PPER", "PPOSAT", "NN", "$,", "PPER"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Noch zur Raison zu bringen.", "tokens": ["Noch", "zur", "Rai\u00b7son", "zu", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.55": {"line.1": {"text": "Daf\u00fcr gelang's dem Semei,", "tokens": ["Da\u00b7f\u00fcr", "ge\u00b7lang's", "dem", "Se\u00b7mei", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PAV", "ADJA", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.2": {"text": "Der seinem Herrn in's Antlitz spie,", "tokens": ["Der", "sei\u00b7nem", "Herrn", "in's", "Ant\u00b7litz", "spie", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "PPOSAT", "NN", "APPRART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Sich zu nobilitiren:", "tokens": ["Sich", "zu", "no\u00b7bi\u00b7li\u00b7ti\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["PRF", "PTKZU", "VVINF", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}, "line.4": {"text": "Denn der Minister machte kund:", "tokens": ["Denn", "der", "Mi\u00b7nis\u00b7ter", "mach\u00b7te", "kund", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "ART", "NN", "VVFIN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Er sollt' hinf\u00fcr den Titel: ", "tokens": ["Er", "sollt'", "hin\u00b7f\u00fcr", "den", "Ti\u00b7tel", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VMFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Im Pr\u00e4dikate f\u00fchren", "tokens": ["Im", "Pr\u00e4\u00b7di\u00b7ka\u00b7te", "f\u00fch\u00b7ren"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "NN", "VVINF"], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.56": {"line.1": {"text": "Inde\u00df die Kritik auf der Welt", "tokens": ["In\u00b7de\u00df", "die", "Kri\u00b7tik", "auf", "der", "Welt"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "ART", "NN", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ihr Amt bald gratis, bald um's Geld", "tokens": ["Ihr", "Amt", "bald", "gra\u00b7tis", ",", "bald", "um's", "Geld"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPOSAT", "NN", "ADV", "ADJD", "$,", "ADV", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "So ziemlich leidlich f\u00fchrte,", "tokens": ["So", "ziem\u00b7lich", "leid\u00b7lich", "f\u00fchr\u00b7te", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Geschahe in der Himmelsburg", "tokens": ["Ge\u00b7scha\u00b7he", "in", "der", "Him\u00b7mels\u00b7burg"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ein Ungl\u00fcck, das sie durch und durch", "tokens": ["Ein", "Un\u00b7gl\u00fcck", ",", "das", "sie", "durch", "und", "durch"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "APPR", "KON", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Mit Giftschaum inpr\u00e4gnirte.", "tokens": ["Mit", "Gift\u00b7schaum", "in\u00b7pr\u00e4g\u00b7nir\u00b7te", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVFIN", "$."], "meter": "-+-+++-", "measure": "unknown.measure.tetra"}}, "stanza.57": {"line.1": {"text": "Der alte Momus, der bisher", "tokens": ["Der", "al\u00b7te", "Mo\u00b7mus", ",", "der", "bis\u00b7her"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ART", "ADJA", "NN", "$,", "PRELS", "ADV"], "meter": "-+--+--+", "measure": "prosodiakos"}, "line.2": {"text": "Am Hof des Vaters Jupiter", "tokens": ["Am", "Hof", "des", "Va\u00b7ters", "Ju\u00b7pi\u00b7ter"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "ART", "NN", "NN"], "meter": "-+-+----", "measure": "unknown.measure.di"}, "line.3": {"text": "Den Tischhannswursten spielte,", "tokens": ["Den", "Tischhanns\u00b7wurs\u00b7ten", "spiel\u00b7te", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "$,"], "meter": "+-+-+-", "measure": "trochaic.tri"}, "line.4": {"text": "Als er einst Junons M\u00f6pschen stie\u00df,", "tokens": ["Als", "er", "einst", "Ju\u00b7nons", "M\u00f6p\u00b7schen", "stie\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "ADJA", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bekam von ihm solch einen Bi\u00df,", "tokens": ["Be\u00b7kam", "von", "ihm", "solch", "ei\u00b7nen", "Bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "PPER", "PIAT", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Da\u00df er vor Schmerzen br\u00fcllte.", "tokens": ["Da\u00df", "er", "vor", "Schmer\u00b7zen", "br\u00fcll\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "NN", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.58": {"line.1": {"text": "Und weil das H\u00fcndchen w\u00fcthig war,", "tokens": ["Und", "weil", "das", "H\u00fcnd\u00b7chen", "w\u00fct\u00b7hig", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "ART", "NN", "ADJD", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "So ward es auch der arme Narr,", "tokens": ["So", "ward", "es", "auch", "der", "ar\u00b7me", "Narr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ART", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Es schwoll ihm Mund und Kehle;", "tokens": ["Es", "schwoll", "ihm", "Mund", "und", "Keh\u00b7le", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PPER", "NN", "KON", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und jedes W\u00f6rtchen, das er sprach,", "tokens": ["Und", "je\u00b7des", "W\u00f6rt\u00b7chen", ",", "das", "er", "sprach", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PIAT", "NN", "$,", "PRELS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ward auf der Zunge Gift, und stach", "tokens": ["Ward", "auf", "der", "Zun\u00b7ge", "Gift", ",", "und", "stach"], "token_info": ["word", "word", "word", "word", "word", "punct", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "NN", "$,", "KON", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Die G\u00f6tter in die Seele.", "tokens": ["Die", "G\u00f6t\u00b7ter", "in", "die", "See\u00b7le", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.59": {"line.1": {"text": "Er tobt' und sch\u00e4umte f\u00fcrchterlich,", "tokens": ["Er", "tobt'", "und", "sch\u00e4um\u00b7te", "f\u00fcrch\u00b7ter\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "KON", "VVFIN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df unter'n G\u00f6ttern wild um sich", "tokens": ["Bi\u00df", "un\u00b7ter'n", "G\u00f6t\u00b7tern", "wild", "um", "sich"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADJD", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und ihren Kammerdienern;", "tokens": ["Und", "ih\u00b7ren", "Kam\u00b7mer\u00b7die\u00b7nern", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KON", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Kurzum, er spielte allen mit,", "tokens": ["Kur\u00b7zum", ",", "er", "spiel\u00b7te", "al\u00b7len", "mit", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "punct"], "pos": ["NE", "$,", "PPER", "VVFIN", "PIS", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Wie unl\u00e4ngst ein Nicolait", "tokens": ["Wie", "un\u00b7l\u00e4ngst", "ein", "Ni\u00b7co\u00b7lait"], "token_info": ["word", "word", "word", "word"], "pos": ["PWAV", "ADV", "ART", "NN"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Es machte mit den Wienern.", "tokens": ["Es", "mach\u00b7te", "mit", "den", "Wie\u00b7nern", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.60": {"line.1": {"text": "Seit dieser Zeit ist Kritelei", "tokens": ["Seit", "die\u00b7ser", "Zeit", "ist", "Kri\u00b7te\u00b7lei"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "PDAT", "NN", "VAFIN", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und b\u00f6se Hundswuth einerlei:", "tokens": ["Und", "b\u00f6\u00b7se", "Hunds\u00b7wuth", "ei\u00b7ner\u00b7lei", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "ADJA", "NN", "PTKVZ", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Das Gift fieng an zu schleichen,", "tokens": ["Das", "Gift", "fi\u00b7eng", "an", "zu", "schlei\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "PTKVZ", "PTKZU", "VVINF", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.4": {"text": "Und ist, k\u00f6mmt's gleich vom Himmel her,", "tokens": ["Und", "ist", ",", "k\u00f6mmt's", "gleich", "vom", "Him\u00b7mel", "her", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VAFIN", "$,", "NE", "ADV", "APPRART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Menschen nun gleich schrecklicher,", "tokens": ["Den", "Men\u00b7schen", "nun", "gleich", "schreck\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "ADV", "ADV", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Als Pest und and're Seuchen.", "tokens": ["Als", "Pest", "und", "an\u00b7d'\u00b7re", "Seu\u00b7chen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "NN", "KON", "ADJA", "NN", "$."], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}}, "stanza.61": {"line.1": {"text": "Denn ach! vom Kritlergifte wird", "tokens": ["Denn", "ach", "!", "vom", "Krit\u00b7ler\u00b7gif\u00b7te", "wird"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$.", "APPRART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man augenblicklich inficirt", "tokens": ["Man", "au\u00b7gen\u00b7blick\u00b7lich", "in\u00b7fi\u00b7cirt"], "token_info": ["word", "word", "word"], "pos": ["PIS", "ADJD", "VVPP"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Vom Fu\u00df bis auf zum Scheitel;", "tokens": ["Vom", "Fu\u00df", "bis", "auf", "zum", "Schei\u00b7tel", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "APPR", "APPR", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ja vor dem Bi\u00df des Kritikus", "tokens": ["Ja", "vor", "dem", "Bi\u00df", "des", "Kri\u00b7ti\u00b7kus"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PTKANT", "APPR", "ART", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sch\u00fctzt nicht einmal Merkurius \u2013", "tokens": ["Sch\u00fctzt", "nicht", "ein\u00b7mal", "Mer\u00b7ku\u00b7rius", "\u2013"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PTKNEG", "ADV", "NE", "$("], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.6": {"text": "Nur h\u00f6chstens noch sein Beutel.", "tokens": ["Nur", "h\u00f6chs\u00b7tens", "noch", "sein", "Beu\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.62": {"line.1": {"text": "Dabei ist dieses Gift sehr fein,", "tokens": ["Da\u00b7bei", "ist", "die\u00b7ses", "Gift", "sehr", "fein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VAFIN", "PDAT", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Man kann es in ein Briefelein", "tokens": ["Man", "kann", "es", "in", "ein", "Brie\u00b7fel\u00b7ein"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PIS", "VMFIN", "PPER", "APPR", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Ganz leichtlich einballiren;", "tokens": ["Ganz", "leicht\u00b7lich", "ein\u00b7bal\u00b7li\u00b7ren", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "ADJD", "VVINF", "$."], "meter": "-+--+--", "measure": "iambic.di.relaxed"}, "line.4": {"text": "Man liest, und ist des Giftes voll,", "tokens": ["Man", "liest", ",", "und", "ist", "des", "Gif\u00b7tes", "voll", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "$,", "KON", "VAFIN", "ART", "NN", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und so kann man von einem Pol", "tokens": ["Und", "so", "kann", "man", "von", "ei\u00b7nem", "Pol"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["KON", "ADV", "VMFIN", "PIS", "APPR", "ART", "NN"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Zum andern inficiren.", "tokens": ["Zum", "an\u00b7dern", "in\u00b7fi\u00b7ci\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADJA", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.63": {"line.1": {"text": "Ja, was noch mehr, es ist so scharf,", "tokens": ["Ja", ",", "was", "noch", "mehr", ",", "es", "ist", "so", "scharf", ","], "token_info": ["word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PTKANT", "$,", "PRELS", "ADV", "ADV", "$,", "PPER", "VAFIN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Da\u00df man's nur sehen lassen darf,", "tokens": ["Da\u00df", "man's", "nur", "se\u00b7hen", "las\u00b7sen", "darf", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PIS", "ADV", "VVINF", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um Unheil anzustiften;", "tokens": ["Um", "Un\u00b7heil", "an\u00b7zu\u00b7stif\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["KOUI", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Auch kann man nach Jahrtausenden", "tokens": ["Auch", "kann", "man", "nach", "Jahr\u00b7tau\u00b7sen\u00b7den"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PIS", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Damit die Abgeschiedenen", "tokens": ["Da\u00b7mit", "die", "Ab\u00b7ge\u00b7schie\u00b7de\u00b7nen"], "token_info": ["word", "word", "word"], "pos": ["PAV", "ART", "NN"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.6": {"text": "Im Grabe noch vergiften.", "tokens": ["Im", "Gra\u00b7be", "noch", "ver\u00b7gif\u00b7ten", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADV", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.64": {"line.1": {"text": "Nun sollt ihr Herr'n noch kurz und gut", "tokens": ["Nun", "sollt", "ihr", "Herr'n", "noch", "kurz", "und", "gut"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPOSAT", "NN", "ADV", "ADJD", "KON", "ADJD"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Von der besagten Krittlerwuth", "tokens": ["Von", "der", "be\u00b7sag\u00b7ten", "Kritt\u00b7ler\u00b7wuth"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den ganzen Stammbaum wissen:", "tokens": ["Den", "gan\u00b7zen", "Stamm\u00b7baum", "wis\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gebt Acht: Man hat von Momus an", "tokens": ["Gebt", "Acht", ":", "Man", "hat", "von", "Mo\u00b7mus", "an"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["VVIMP", "CARD", "$.", "PIS", "VAFIN", "APPR", "NE", "PTKVZ"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis auf den heut'gen Tag fortan", "tokens": ["Bis", "auf", "den", "heut'\u00b7gen", "Tag", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "APPR", "ART", "ADJA", "NN", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Einander sich gebissen.", "tokens": ["Ein\u00b7an\u00b7der", "sich", "ge\u00b7bis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PRF", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.65": {"line.1": {"text": "Mit rechtem Hundesappetit", "tokens": ["Mit", "rech\u00b7tem", "Hun\u00b7de\u00b7sap\u00b7pe\u00b7tit"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df einst Herr Momus den Thersit,", "tokens": ["Bi\u00df", "einst", "Herr", "Mo\u00b7mus", "den", "Ther\u00b7sit", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ADV", "NN", "NE", "ART", "NN", "$,"], "meter": "-+--+-+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "So kam das Gift schon weiter:", "tokens": ["So", "kam", "das", "Gift", "schon", "wei\u00b7ter", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "ADV", "ADV", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Weil der Gebi\u00dfne bei\u00dfen mu\u00df,", "tokens": ["Weil", "der", "Ge\u00b7bi\u00df\u00b7ne", "bei\u00b7\u00dfen", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "ART", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So bi\u00df Thersit den Zoilus,", "tokens": ["So", "bi\u00df", "Ther\u00b7sit", "den", "Zoi\u00b7lus", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "ART", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.6": {"text": "Homerens Sylbenreiter.", "tokens": ["Ho\u00b7me\u00b7rens", "Syl\u00b7ben\u00b7rei\u00b7ter", "."], "token_info": ["word", "word", "punct"], "pos": ["NE", "NE", "$."], "meter": "+--+-+-", "measure": "iambic.tri.invert"}}, "stanza.66": {"line.1": {"text": "Herr Zoilus war auch nicht faul,", "tokens": ["Herr", "Zoi\u00b7lus", "war", "auch", "nicht", "faul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["NN", "NE", "VAFIN", "ADV", "PTKNEG", "ADJD", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.2": {"text": "Und bi\u00df den Aristarch in's Maul,", "tokens": ["Und", "bi\u00df", "den", "A\u00b7rist\u00b7arch", "in's", "Maul", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "APPRART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den grossen Splitterrichter;", "tokens": ["Den", "gros\u00b7sen", "Split\u00b7ter\u00b7rich\u00b7ter", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der aber bi\u00df den Mevius,", "tokens": ["Der", "a\u00b7ber", "bi\u00df", "den", "Me\u00b7vius", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADV", "APPR", "ART", "NE", "$,"], "meter": "-+-+--+", "measure": "iambic.tri.chol"}, "line.5": {"text": "Mev aber bi\u00df nun aus Verdru\u00df", "tokens": ["Mev", "a\u00b7ber", "bi\u00df", "nun", "aus", "Ver\u00b7dru\u00df"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NE", "ADV", "ADV", "ADV", "APPR", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Herrn Martial, den Dichter.", "tokens": ["Herrn", "Mar\u00b7ti\u00b7al", ",", "den", "Dich\u00b7ter."], "token_info": ["word", "word", "punct", "word", "abbreviation"], "pos": ["NN", "NE", "$,", "ART", "NN"], "meter": "-+-+-", "measure": "iambic.di"}}, "stanza.67": {"line.1": {"text": "Und Skaliger, gelehrt, durch ihn,", "tokens": ["Und", "Ska\u00b7li\u00b7ger", ",", "ge\u00b7lehrt", ",", "durch", "ihn", ","], "token_info": ["word", "word", "punct", "word", "punct", "word", "word", "punct"], "pos": ["KON", "NN", "$,", "VVPP", "$,", "APPR", "PPER", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Bi\u00df den Muretus", "tokens": ["Bi\u00df", "den", "Mu\u00b7re\u00b7tus"], "token_info": ["word", "word", "word"], "pos": ["APPR", "ART", "NN"], "meter": "+-+-+", "measure": "trochaic.tri"}, "line.3": {"text": "Das m\u00fc\u00dft ihr mich nicht fragen:", "tokens": ["Das", "m\u00fc\u00dft", "ihr", "mich", "nicht", "fra\u00b7gen", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PDS", "VMFIN", "PPER", "PRF", "PTKNEG", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und wenn es denn gesagt seyn mu\u00df,", "tokens": ["Und", "wenn", "es", "denn", "ge\u00b7sagt", "seyn", "mu\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ADV", "VVPP", "VAINF", "VMFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "So gehet hin, \u2013 Pr\u00e4putius", "tokens": ["So", "ge\u00b7het", "hin", ",", "\u2013", "Pr\u00e4\u00b7pu\u00b7tius"], "token_info": ["word", "word", "word", "punct", "punct", "word"], "pos": ["ADV", "VVFIN", "PTKVZ", "$,", "$(", "NE"], "meter": "-+--+-+", "measure": "iambic.tri.relaxed"}, "line.6": {"text": "Wird euch's statt meiner sagen.", "tokens": ["Wird", "euch's", "statt", "mei\u00b7ner", "sa\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VAFIN", "PIS", "APPR", "PPOSAT", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.68": {"line.1": {"text": "Der hochgelehrte Fleischerhund", "tokens": ["Der", "hoch\u00b7ge\u00b7lehr\u00b7te", "Flei\u00b7scher\u00b7hund"], "token_info": ["word", "word", "word"], "pos": ["ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sciopius bi\u00df alles wund,", "tokens": ["Scio\u00b7pius", "bi\u00df", "al\u00b7les", "wund", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NE", "APPR", "PIS", "ADJD", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.3": {"text": "Was er nur wahrgenommen,", "tokens": ["Was", "er", "nur", "wahr\u00b7ge\u00b7nom\u00b7men", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "ADV", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und weil er die Jesuiten bi\u00df,", "tokens": ["Und", "weil", "er", "die", "Je\u00b7su\u00b7i\u00b7ten", "bi\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "KOUS", "PPER", "ART", "NN", "ADV", "$,"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "So ist das Gift auch unter die\u00df", "tokens": ["So", "ist", "das", "Gift", "auch", "un\u00b7ter", "die\u00df"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VAFIN", "ART", "NN", "ADV", "APPR", "PDS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.69": {"line.1": {"text": "Hier ward es noch gef\u00e4hrlicher,", "tokens": ["Hier", "ward", "es", "noch", "ge\u00b7f\u00e4hr\u00b7li\u00b7cher", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+--", "measure": "unknown.measure.tri"}, "line.2": {"text": "Dann schleichend Gift und trieb nicht mehr", "tokens": ["Dann", "schlei\u00b7chend", "Gift", "und", "trieb", "nicht", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "ADJD", "NN", "KON", "VVFIN", "PTKNEG", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Den Schaum heraus zum Munde;", "tokens": ["Den", "Schaum", "he\u00b7raus", "zum", "Mun\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Es war oft, eh man sich's versah,", "tokens": ["Es", "war", "oft", ",", "eh", "man", "sich's", "ver\u00b7sah", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "ADV", "$,", "KOUS", "PIS", "PIS", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Im Leibe des Gebi\u00dfnen da,", "tokens": ["Im", "Lei\u00b7be", "des", "Ge\u00b7bi\u00df\u00b7nen", "da", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Doch sah man keine Wunde.", "tokens": ["Doch", "sah", "man", "kei\u00b7ne", "Wun\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIS", "PIAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.70": {"line.1": {"text": "Allein mit gifterf\u00fclltem Zahn", "tokens": ["Al\u00b7lein", "mit", "gif\u00b7ter\u00b7f\u00fcll\u00b7tem", "Zahn"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Fiel Burmann einst Herrn Klotzen an,", "tokens": ["Fiel", "Bur\u00b7mann", "einst", "Herrn", "Klot\u00b7zen", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "ADV", "NN", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und zwickt' ihn in die Wade;", "tokens": ["Und", "zwickt'", "ihn", "in", "die", "Wa\u00b7de", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Klotz ward nun auch dem Wasser gram,", "tokens": ["Klotz", "ward", "nun", "auch", "dem", "Was\u00b7ser", "gram", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["NE", "VAFIN", "ADV", "ADV", "ART", "NN", "NE", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und wer ihm nur zu nahe kam,", "tokens": ["Und", "wer", "ihm", "nur", "zu", "na\u00b7he", "kam", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "PPER", "ADV", "PTKA", "ADJD", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Den bi\u00df er ohne Gnade.", "tokens": ["Den", "bi\u00df", "er", "oh\u00b7ne", "Gna\u00b7de", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "APPR", "PPER", "APPR", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.71": {"line.1": {"text": "Er bi\u00df gar schrecklich um sich her,", "tokens": ["Er", "bi\u00df", "gar", "schreck\u00b7lich", "um", "sich", "her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ADV", "ADJD", "APPR", "PRF", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Es wollte schon kein Autor mehr", "tokens": ["Es", "woll\u00b7te", "schon", "kein", "Au\u00b7tor", "mehr"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["PPER", "VMFIN", "ADV", "PIAT", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Auf off'ner Strasse gehen,", "tokens": ["Auf", "off'\u00b7ner", "Stras\u00b7se", "ge\u00b7hen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Herr Doktor Lessing gab ihm zwar", "tokens": ["Herr", "Dok\u00b7tor", "Les\u00b7sing", "gab", "ihm", "zwar"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["NN", "NN", "NE", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum Schwitzen ein, allein es war", "tokens": ["Zum", "Schwit\u00b7zen", "ein", ",", "al\u00b7lein", "es", "war"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["APPRART", "NN", "PTKVZ", "$,", "ADV", "PPER", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun schon einmal geschehen.", "tokens": ["Nun", "schon", "ein\u00b7mal", "ge\u00b7sche\u00b7hen", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.72": {"line.1": {"text": "Einst als die Wuth in's Hirn ihm scho\u00df,", "tokens": ["Einst", "als", "die", "Wuth", "in's", "Hirn", "ihm", "scho\u00df", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPRART", "NN", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ging er auf Nikolai los,", "tokens": ["Ging", "er", "auf", "Ni\u00b7ko\u00b7lai", "los", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "APPR", "NE", "PTKVZ", "$,"], "meter": "+-+-+-+", "measure": "trochaic.tetra"}, "line.3": {"text": "Und packt' ihn bei den Ohren:", "tokens": ["Und", "packt'", "ihn", "bei", "den", "Oh\u00b7ren", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Arme schrie gar j\u00e4mmerlich:", "tokens": ["Der", "Ar\u00b7me", "schrie", "gar", "j\u00e4m\u00b7mer\u00b7lich", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "VVFIN", "ADV", "ADJD", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Iha! Iha! \u2013 und f\u00fchlte sich", "tokens": ["I\u00b7ha", "!", "I\u00b7ha", "!", "\u2013", "und", "f\u00fchl\u00b7te", "sich"], "token_info": ["word", "punct", "word", "punct", "punct", "word", "word", "word"], "pos": ["NE", "$.", "NE", "$.", "$(", "KON", "VVFIN", "PRF"], "meter": "+-+--+-+", "measure": "glykoneus"}, "line.6": {"text": "Zum Kritler auserkohren.", "tokens": ["Zum", "Krit\u00b7ler", "au\u00b7ser\u00b7koh\u00b7ren", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVIZU", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.73": {"line.1": {"text": "Nun war das Gift im rechten Mann:", "tokens": ["Nun", "war", "das", "Gift", "im", "rech\u00b7ten", "Mann", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "ART", "NN", "APPRART", "ADJA", "NN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Er sch\u00e4umte wild, und bi\u00df fortan", "tokens": ["Er", "sch\u00e4um\u00b7te", "wild", ",", "und", "bi\u00df", "for\u00b7tan"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD", "$,", "KON", "APPR", "NE"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit Jedem in die Wette,", "tokens": ["Mit", "Je\u00b7dem", "in", "die", "Wet\u00b7te", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PIAT", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die Polizei litt in Berlin", "tokens": ["Die", "Po\u00b7li\u00b7zei", "litt", "in", "Ber\u00b7lin"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ART", "NN", "VVFIN", "APPR", "NE"], "meter": "-+-+-++-", "measure": "unknown.measure.tetra"}, "line.5": {"text": "Das Beissen nicht, d'rum schlo\u00df man ihn", "tokens": ["Das", "Beis\u00b7sen", "nicht", ",", "d'\u00b7rum", "schlo\u00df", "man", "ihn"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "PTKNEG", "$,", "ADV", "VVFIN", "PIS", "PPER"], "meter": "-+--+-+-+", "measure": "iambic.tetra.relaxed"}, "line.6": {"text": "An eine lange Kette.", "tokens": ["An", "ei\u00b7ne", "lan\u00b7ge", "Ket\u00b7te", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.74": {"line.1": {"text": "Doch um das Gift, das ihm fortan", "tokens": ["Doch", "um", "das", "Gift", ",", "das", "ihm", "for\u00b7tan"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "$,", "PRELS", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "In Str\u00f6men aus dem Munde rann,", "tokens": ["In", "Str\u00f6\u00b7men", "aus", "dem", "Mun\u00b7de", "rann", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Durch Deutschland zu verbreiten,", "tokens": ["Durch", "Deutschland", "zu", "ver\u00b7brei\u00b7ten", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NE", "PTKZU", "VVINF", "$,"], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}, "line.4": {"text": "So lie\u00df er f\u00fcr den Giftschaum all'", "tokens": ["So", "lie\u00df", "er", "f\u00fcr", "den", "Gift\u00b7schaum", "all'"], "token_info": ["word", "word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "APPR", "ART", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Sich einen eigenen Kanal", "tokens": ["Sich", "ei\u00b7nen", "ei\u00b7ge\u00b7nen", "Ka\u00b7nal"], "token_info": ["word", "word", "word", "word"], "pos": ["PRF", "ART", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Von L\u00f6schpapier bereiten.", "tokens": ["Von", "L\u00f6schpa\u00b7pier", "be\u00b7rei\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "VVINF", "$."], "meter": "-+--+-", "measure": "amphibrach.di.relaxed"}}, "stanza.75": {"line.1": {"text": "Vor diesem m\u00e4chtigen Kanal", "tokens": ["Vor", "die\u00b7sem", "m\u00e4ch\u00b7ti\u00b7gen", "Ka\u00b7nal"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "PDAT", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Lie\u00df er die grossen M\u00e4nner all'", "tokens": ["Lie\u00df", "er", "die", "gros\u00b7sen", "M\u00e4n\u00b7ner", "all'"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VVFIN", "PPER", "ART", "ADJA", "NN", "PIAT"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In Kupfer konterfeien,", "tokens": ["In", "Kup\u00b7fer", "kon\u00b7ter\u00b7fei\u00b7en", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "NN", "NE", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Um ihnen, wenn's ihn l\u00fcstete,", "tokens": ["Um", "ih\u00b7nen", ",", "wenn's", "ihn", "l\u00fcs\u00b7te\u00b7te", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "$,", "KOUS", "PPER", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Zum mind'sten in ", "tokens": ["Zum", "min\u00b7d'\u00b7sten", "in"], "token_info": ["word", "word", "word"], "pos": ["APPRART", "ADJA", "APPR"], "meter": "-+-+-", "measure": "iambic.di"}, "line.6": {"text": "In's Angesicht zu speien.", "tokens": ["In's", "An\u00b7ge\u00b7sicht", "zu", "spei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.76": {"line.1": {"text": "Bald fiel's ihm ein, die Dichterschaar", "tokens": ["Bald", "fiel's", "ihm", "ein", ",", "die", "Dich\u00b7ter\u00b7schaar"], "token_info": ["word", "word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PTKVZ", "$,", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Die nicht so, wie sein Ramler, war,", "tokens": ["Die", "nicht", "so", ",", "wie", "sein", "Ram\u00b7ler", ",", "war", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct", "word", "punct"], "pos": ["ART", "PTKNEG", "ADV", "$,", "PWAV", "PPOSAT", "NN", "$,", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "In St\u00fccke zu zerreissen;", "tokens": ["In", "St\u00fc\u00b7cke", "zu", "zer\u00b7reis\u00b7sen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bald wandelte die Lust ihn an,", "tokens": ["Bald", "wan\u00b7del\u00b7te", "die", "Lust", "ihn", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PPER", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Den Teufel, der ihm nichts gethan,", "tokens": ["Den", "Teu\u00b7fel", ",", "der", "ihm", "nichts", "ge\u00b7than", ","], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "PIS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zur H\u00f6ll' hinauszubeissen.", "tokens": ["Zur", "H\u00f6ll'", "hin\u00b7aus\u00b7zu\u00b7beis\u00b7sen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "NN", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.77": {"line.1": {"text": "Einst fiel er einen Britten an", "tokens": ["Einst", "fiel", "er", "ei\u00b7nen", "Brit\u00b7ten", "an"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "ART", "NN", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Mit seinem Uebersetzerzahn,", "tokens": ["Mit", "sei\u00b7nem", "Ue\u00b7ber\u00b7set\u00b7zer\u00b7zahn", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "(denn ach! sein Bauch war eitel)", "tokens": ["(", "denn", "ach", "!", "sein", "Bauch", "war", "ei\u00b7tel", ")"], "token_info": ["punct", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["$(", "KON", "XY", "$.", "PPOSAT", "NN", "VAFIN", "ADJD", "$("], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Den fra\u00df er, spie ihn d'rauf und hie\u00df", "tokens": ["Den", "fra\u00df", "er", ",", "spie", "ihn", "d'\u00b7rauf", "und", "hie\u00df"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "word"], "pos": ["NE", "VVFIN", "PPER", "$,", "VVFIN", "PPER", "PTKVZ", "KON", "VVFIN"], "meter": "-+-+--+-+", "measure": "iambic.tetra.relaxed"}, "line.5": {"text": "Uns essen, doch wer a\u00df, den bi\u00df", "tokens": ["Uns", "es\u00b7sen", ",", "doch", "wer", "a\u00df", ",", "den", "bi\u00df"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVINF", "$,", "KON", "PWS", "VVFIN", "$,", "PRELS", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Er schrecklich in den Beutel.", "tokens": ["Er", "schreck\u00b7lich", "in", "den", "Beu\u00b7tel", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADJD", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.78": {"line.1": {"text": "Mit beiden Pfoten scharrt' er d'rauf", "tokens": ["Mit", "bei\u00b7den", "Pfo\u00b7ten", "scharrt'", "er", "d'\u00b7rauf"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["APPR", "PIAT", "NN", "VVFIN", "PPER", "PAV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.2": {"text": "Der Tempelherren Gr\u00e4ber auf,", "tokens": ["Der", "Tem\u00b7pel\u00b7her\u00b7ren", "Gr\u00e4\u00b7ber", "auf", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und nagt' an ihren Knochen,", "tokens": ["Und", "nagt'", "an", "ih\u00b7ren", "Kno\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Und ruhte keinen Augenblick,", "tokens": ["Und", "ruh\u00b7te", "kei\u00b7nen", "Au\u00b7gen\u00b7blick", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bis er den Armen das Genick", "tokens": ["Bis", "er", "den", "Ar\u00b7men", "das", "Ge\u00b7nick"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ART", "NN", "ART", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Zum zweitenmal gebrochen.", "tokens": ["Zum", "zwei\u00b7ten\u00b7mal", "ge\u00b7bro\u00b7chen", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPRART", "ADV", "VVPP", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.79": {"line.1": {"text": "Einst als die Wuth am h\u00f6chsten war,", "tokens": ["Einst", "als", "die", "Wuth", "am", "h\u00f6chs\u00b7ten", "war", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "KOUS", "ART", "NN", "APPRART", "ADJA", "VAFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Zerri\u00df er seine Kette gar,", "tokens": ["Zer\u00b7ri\u00df", "er", "sei\u00b7ne", "Ket\u00b7te", "gar", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "PPOSAT", "NN", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Und lief nach neuer Beute:", "tokens": ["Und", "lief", "nach", "neu\u00b7er", "Beu\u00b7te", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Die B\u00f6hmen und die Deutschen sah'n", "tokens": ["Die", "B\u00f6h\u00b7men", "und", "die", "Deut\u00b7schen", "sah'n"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "NN", "KON", "ART", "NN", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihn laufen, aber jedermann", "tokens": ["Ihn", "lau\u00b7fen", ",", "a\u00b7ber", "je\u00b7der\u00b7mann"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "ADV", "PIS"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ging h\u00fcbsch ihm auf die Seite.", "tokens": ["Ging", "h\u00fcbsch", "ihm", "auf", "die", "Sei\u00b7te", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "ADJD", "PPER", "APPR", "ART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.80": {"line.1": {"text": "Gar bald kam er in Wien auch an,", "tokens": ["Gar", "bald", "kam", "er", "in", "Wi\u00b7en", "auch", "an", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VVFIN", "PPER", "APPR", "NE", "ADV", "PTKVZ", "$,"], "meter": "--+--+--+", "measure": "anapaest.tri.plus"}, "line.2": {"text": "Hier sch\u00e4rft' er seinen Kritlerzahn", "tokens": ["Hier", "sch\u00e4rft'", "er", "sei\u00b7nen", "Krit\u00b7ler\u00b7zahn"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "PPER", "PPOSAT", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Zu neuen Heldenthaten;", "tokens": ["Zu", "neu\u00b7en", "Hel\u00b7den\u00b7tha\u00b7ten", ";"], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Trank unsern Ratzerstorfer Wein,", "tokens": ["Trank", "un\u00b7sern", "Rat\u00b7zer\u00b7stor\u00b7fer", "Wein", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["NN", "PPOSAT", "NN", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und ach, verbi\u00df sich obend'rein", "tokens": ["Und", "ach", ",", "ver\u00b7bi\u00df", "sich", "o\u00b7ben\u00b7d'\u00b7rein"], "token_info": ["word", "word", "punct", "word", "word", "word"], "pos": ["KON", "XY", "$,", "VVFIN", "PRF", "ADV"], "meter": "-+-+-+--+", "measure": "iambic.tetra.chol"}, "line.6": {"text": "In unsern Lungenbraten.", "tokens": ["In", "un\u00b7sern", "Lun\u00b7gen\u00b7bra\u00b7ten", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.81": {"line.1": {"text": "Allein man scheute seine Wuth,", "tokens": ["Al\u00b7lein", "man", "scheu\u00b7te", "sei\u00b7ne", "Wuth", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VVFIN", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "D'rum fand der Magistrat f\u00fct gut,", "tokens": ["D'\u00b7rum", "fand", "der", "Ma\u00b7gist\u00b7rat", "f\u00fct", "gut", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "ART", "NN", "VVFIN", "ADJD", "$,"], "meter": "+-+-+-+-+", "measure": "trochaic.penta"}, "line.3": {"text": "Sogleich zu publiciren:", "tokens": ["Sog\u00b7leich", "zu", "pub\u00b7li\u00b7ci\u00b7ren", ":"], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zur Sicherheit soll man hinf\u00fcr", "tokens": ["Zur", "Si\u00b7cher\u00b7heit", "soll", "man", "hin\u00b7f\u00fcr"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPRART", "NN", "VMFIN", "PIS", "APPR"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die tollen Hund' und Krittler hier", "tokens": ["Die", "tol\u00b7len", "Hund'", "und", "Kritt\u00b7ler", "hier"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ART", "ADJA", "NN", "KON", "NN", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "An einem Strickchen f\u00fchren.", "tokens": ["An", "ei\u00b7nem", "Strick\u00b7chen", "f\u00fch\u00b7ren", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "NN", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.82": {"line.1": {"text": "Auch lag bei hoher Obrigkeit", "tokens": ["Auch", "lag", "bei", "ho\u00b7her", "Ob\u00b7rig\u00b7keit"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["ADV", "VVFIN", "APPR", "ADJA", "NN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Sankt Huberts Schl\u00fcssel schon bereit,", "tokens": ["Sankt", "Hu\u00b7berts", "Schl\u00fcs\u00b7sel", "schon", "be\u00b7reit", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "NE", "NN", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Um ihn damit zu brennen:", "tokens": ["Um", "ihn", "da\u00b7mit", "zu", "bren\u00b7nen", ":"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "PPER", "PAV", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Doch er verlie\u00df, eh dies gescheh'n,", "tokens": ["Doch", "er", "ver\u00b7lie\u00df", ",", "eh", "dies", "ge\u00b7scheh'n", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["KON", "PPER", "VVFIN", "$,", "KOUS", "PDS", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Um in die Schweiz zu rennen.", "tokens": ["Um", "in", "die", "Schweiz", "zu", "ren\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUI", "APPR", "ART", "NN", "PTKZU", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.83": {"line.1": {"text": "Was er gegessen und geseh'n,", "tokens": ["Was", "er", "ge\u00b7ges\u00b7sen", "und", "ge\u00b7seh'n", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWS", "PPER", "VVPP", "KON", "VVPP", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Ward in dem Leib des W\u00fcthigen", "tokens": ["Ward", "in", "dem", "Leib", "des", "W\u00fct\u00b7hi\u00b7gen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["VAFIN", "APPR", "ART", "NN", "ART", "NN"], "meter": "-+-+--+-", "measure": "iambic.tri.relaxed"}, "line.3": {"text": "Zu Gift im Augenblicke:", "tokens": ["Zu", "Gift", "im", "Au\u00b7gen\u00b7bli\u00b7cke", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["APPR", "NN", "APPRART", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So kam er toller als vorher,", "tokens": ["So", "kam", "er", "tol\u00b7ler", "als", "vor\u00b7her", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PPER", "ADJD", "KOKOM", "ADV", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Bepackt mit Gifte Zentnerschwer,", "tokens": ["Be\u00b7packt", "mit", "Gif\u00b7te", "Zent\u00b7ner\u00b7schwer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VVFIN", "APPR", "ADJA", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Nun nach Berlin zur\u00fccke.", "tokens": ["Nun", "nach", "Ber\u00b7lin", "zu\u00b7r\u00fc\u00b7cke", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "APPR", "NE", "PTKVZ", "$."], "meter": "+-+--+-", "measure": "pherekrateus"}}, "stanza.84": {"line.1": {"text": "Da staunte man ob seiner Wuth,", "tokens": ["Da", "staun\u00b7te", "man", "ob", "sei\u00b7ner", "Wuth", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "PIS", "KOUS", "PPOSAT", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und f\u00fcrchtet' eine S\u00fcndenfluth,", "tokens": ["Und", "f\u00fcrch\u00b7tet'", "ei\u00b7ne", "S\u00fcn\u00b7den\u00b7fluth", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Im Fall er bersten sollte;", "tokens": ["Im", "Fall", "er", "bers\u00b7ten", "soll\u00b7te", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "PPER", "VVINF", "VMFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Gleich ritt die Polizey herum,", "tokens": ["Gleich", "ritt", "die", "Po\u00b7li\u00b7zey", "he\u00b7rum", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "VVFIN", "ART", "NN", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Die ein ", "tokens": ["Die", "ein"], "token_info": ["word", "word"], "pos": ["ART", "ART"], "meter": "-+", "measure": "iambic.single"}, "line.6": {"text": "Daf\u00fcr zusammenholte.", "tokens": ["Da\u00b7f\u00fcr", "zu\u00b7sam\u00b7men\u00b7hol\u00b7te", "."], "token_info": ["word", "word", "punct"], "pos": ["PAV", "VVFIN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.85": {"line.1": {"text": "Man disputirte her und hin,", "tokens": ["Man", "dis\u00b7pu\u00b7tir\u00b7te", "her", "und", "hin", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VVFIN", "PTKVZ", "KON", "PTKVZ", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Und als die Aerzte von Berlin", "tokens": ["Und", "als", "die", "A\u00b7erz\u00b7te", "von", "Ber\u00b7lin"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "KOUS", "ART", "NN", "APPR", "NE"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Nun ihre Vota gaben,", "tokens": ["Nun", "ih\u00b7re", "Vo\u00b7ta", "ga\u00b7ben", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PPOSAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "So decitirte der, man sollt'", "tokens": ["So", "de\u00b7ci\u00b7tir\u00b7te", "der", ",", "man", "sollt'"], "token_info": ["word", "word", "word", "punct", "word", "word"], "pos": ["ADV", "VVFIN", "ART", "$,", "PIS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Ihm aderlassen, jener wollt'", "tokens": ["Ihm", "a\u00b7der\u00b7las\u00b7sen", ",", "je\u00b7ner", "wollt'"], "token_info": ["word", "word", "punct", "word", "word"], "pos": ["PPER", "VVINF", "$,", "PDS", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Ihn angezapfet haben.", "tokens": ["Ihn", "an\u00b7ge\u00b7zap\u00b7fet", "ha\u00b7ben", "."], "token_info": ["word", "word", "word", "punct"], "pos": ["PPER", "VVPP", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.86": {"line.1": {"text": "Allein der Protomedicus", "tokens": ["Al\u00b7lein", "der", "Pro\u00b7to\u00b7me\u00b7di\u00b7cus"], "token_info": ["word", "word", "word"], "pos": ["ADV", "ART", "NN"], "meter": "-+---+-+", "measure": "dactylic.init"}, "line.2": {"text": "Stand auf, und sprach: ihr Herr'n, hier mu\u00df", "tokens": ["Stand", "auf", ",", "und", "sprach", ":", "ihr", "Herr'n", ",", "hier", "mu\u00df"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word"], "pos": ["NN", "PTKVZ", "$,", "KON", "VVFIN", "$.", "PPOSAT", "NN", "$,", "ADV", "VMFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Man keine Zeit verlieren,", "tokens": ["Man", "kei\u00b7ne", "Zeit", "ver\u00b7lie\u00b7ren", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["PIS", "PIAT", "NN", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ich fand des Giftes ihn so voll,", "tokens": ["Ich", "fand", "des", "Gif\u00b7tes", "ihn", "so", "voll", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ART", "NN", "PPER", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Da\u00df er sogleich purgiren soll;", "tokens": ["Da\u00df", "er", "sog\u00b7leich", "pur\u00b7gi\u00b7ren", "soll", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ADV", "VVINF", "VMFIN", "$."], "meter": "---+-+-+", "measure": "unknown.measure.tri"}, "line.6": {"text": "Und alle schrie'n \u2013 purgieren!", "tokens": ["Und", "al\u00b7le", "schrie'n", "\u2013", "pur\u00b7gie\u00b7ren", "!"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["KON", "PIS", "VVFIN", "$(", "VVINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.87": {"line.1": {"text": "Man gab ihm ein. Die Dosis war", "tokens": ["Man", "gab", "ihm", "ein", ".", "Die", "Do\u00b7sis", "war"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word"], "pos": ["PIS", "VVFIN", "PPER", "PTKVZ", "$.", "ART", "NN", "VAFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Gewaltig gro\u00df, und macht' ihm gar", "tokens": ["Ge\u00b7wal\u00b7tig", "gro\u00df", ",", "und", "macht'", "ihm", "gar"], "token_info": ["word", "word", "punct", "word", "word", "word", "word"], "pos": ["ADJD", "ADJD", "$,", "KON", "VVFIN", "PPER", "ADV"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Entsetzliche Beschwerden:", "tokens": ["Ent\u00b7setz\u00b7li\u00b7che", "Be\u00b7schwer\u00b7den", ":"], "token_info": ["word", "word", "punct"], "pos": ["ADJA", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Er schrie dabei gar j\u00e4mmerlich,", "tokens": ["Er", "schrie", "da\u00b7bei", "gar", "j\u00e4m\u00b7mer\u00b7lich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "PAV", "ADV", "ADJD", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.5": {"text": "Und kr\u00fcmmte manche Stunde sich,", "tokens": ["Und", "kr\u00fcmm\u00b7te", "man\u00b7che", "Stun\u00b7de", "sich", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "VVFIN", "PIAT", "NN", "PRF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Des Giftes los zu werden.", "tokens": ["Des", "Gif\u00b7tes", "los", "zu", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "PTKVZ", "PTKZU", "VAINF", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}}, "stanza.88": {"line.1": {"text": "Nach langem Drucken endlich wich", "tokens": ["Nach", "lan\u00b7gem", "Dru\u00b7cken", "end\u00b7lich", "wich"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["APPR", "ADJA", "NN", "ADV", "VVFIN"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.2": {"text": "Das Gift von ihm, er gab von sich", "tokens": ["Das", "Gift", "von", "ihm", ",", "er", "gab", "von", "sich"], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["ART", "NN", "APPR", "PPER", "$,", "PPER", "VVFIN", "APPR", "PRF"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Acht dicke B\u00e4nde Reisen:", "tokens": ["Acht", "di\u00b7cke", "B\u00e4n\u00b7de", "Rei\u00b7sen", ":"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["CARD", "ADJA", "NN", "NN", "$."], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Dazu lud er uns schriftlich ein,", "tokens": ["Da\u00b7zu", "lud", "er", "uns", "schrift\u00b7lich", "ein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PAV", "VVFIN", "PPER", "PRF", "ADJD", "PTKVZ", "$,"], "meter": "--+--+-+", "measure": "anapaest.di.plus"}, "line.5": {"text": "Und wer von der Partie will sein,", "tokens": ["Und", "wer", "von", "der", "Par\u00b7tie", "will", "sein", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KON", "PWS", "APPR", "ART", "NN", "VMFIN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.6": {"text": "Dem w\u00fcnsch' ich \u2013 wohl zu speisen!", "tokens": ["Dem", "w\u00fcn\u00b7sch'", "ich", "\u2013", "wohl", "zu", "spei\u00b7sen", "!"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PDS", "VVFIN", "PPER", "$(", "ADV", "PTKZU", "VVINF", "$."], "meter": "+-+-+-+-", "measure": "trochaic.tetra"}}}}}