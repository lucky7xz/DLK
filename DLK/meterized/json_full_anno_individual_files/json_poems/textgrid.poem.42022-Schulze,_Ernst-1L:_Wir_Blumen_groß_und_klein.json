{"textgrid.poem.42022": {"metadata": {"author": {"name": "Schulze, Ernst", "birth": "N.A.", "death": "N.A."}, "title": "1L: Wir Blumen gro\u00df und klein", "genre": "verse", "period": "N.A.", "pub_year": 1803, "urn": "N.A.", "language": ["de:0.99"], "booktitle": "N.A."}, "text": null, "poem": {"stanza.1": {"line.1": {"text": "Wir Blumen gro\u00df und klein", "tokens": ["Wir", "Blu\u00b7men", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sind freundlich dir gewogen,", "tokens": ["Sind", "freund\u00b7lich", "dir", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drum kommen wir gezogen", "tokens": ["Drum", "kom\u00b7men", "wir", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu dir aus Wies' und Hain;", "tokens": ["Zu", "dir", "aus", "Wies'", "und", "Hain", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch sollen wir von allen Quellen", "tokens": ["Auch", "sol\u00b7len", "wir", "von", "al\u00b7len", "Quel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und V\u00f6gelein", "tokens": ["Und", "V\u00f6\u00b7ge\u00b7lein"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Dir einen sch\u00f6nen Gru\u00df bestellen.", "tokens": ["Dir", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Gru\u00df", "be\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Oft auf bethauter Spur", "tokens": ["Oft", "auf", "be\u00b7thau\u00b7ter", "Spur"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sahn wir vorbei dich wallen,", "tokens": ["Sahn", "wir", "vor\u00b7bei", "dich", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und heit'rer schien's uns Allen", "tokens": ["Und", "heit'\u00b7rer", "schien's", "uns", "Al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bei dir als auf der Flur,", "tokens": ["Bei", "dir", "als", "auf", "der", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn nach den Freundlichen und Sch\u00f6nen", "tokens": ["Denn", "nach", "den", "Freund\u00b7li\u00b7chen", "und", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und Keuschen nur", "tokens": ["Und", "Keu\u00b7schen", "nur"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Kann zarter Bl\u00fcmlein Sinn sich sehnen.", "tokens": ["Kann", "zar\u00b7ter", "Bl\u00fcm\u00b7lein", "Sinn", "sich", "seh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.3": {"line.1": {"text": "Wenn uns der Mai belebt,", "tokens": ["Wenn", "uns", "der", "Mai", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dann wird aus Mondenschimmer,", "tokens": ["Dann", "wird", "aus", "Mon\u00b7den\u00b7schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Aus Thau und Quellgeflimmer", "tokens": ["Aus", "Thau", "und", "Quell\u00b7ge\u00b7flim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Kl\u00f6cklein Glanz gewebt.", "tokens": ["Der", "Kl\u00f6c\u00b7klein", "Glanz", "ge\u00b7webt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nichts darf den hellen Kelch entweihen;", "tokens": ["Nichts", "darf", "den", "hel\u00b7len", "Kelch", "ent\u00b7wei\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn leis' umschwebt", "tokens": ["Denn", "leis'", "um\u00b7schwebt"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Uns stets der Tanz der Blumenfeien.", "tokens": ["Uns", "stets", "der", "Tanz", "der", "Blu\u00b7men\u00b7fei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.4": {"line.1": {"text": "Doch zarte Liebe schleicht", "tokens": ["Doch", "zar\u00b7te", "Lie\u00b7be", "schleicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Uns doch in's Herz allm\u00e4hlig,", "tokens": ["Uns", "doch", "in's", "Herz", "all\u00b7m\u00e4h\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir suchen minneselig", "tokens": ["Wir", "su\u00b7chen", "min\u00b7ne\u00b7se\u00b7lig"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Liebchen, das uns gleicht.", "tokens": ["Ein", "Lieb\u00b7chen", ",", "das", "uns", "gleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich haben wir uns auserkoren;", "tokens": ["Dich", "ha\u00b7ben", "wir", "uns", "au\u00b7ser\u00b7ko\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bist du vielleicht", "tokens": ["Bist", "du", "viel\u00b7leicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wie wir aus reinem Glanz geboren?", "tokens": ["Wie", "wir", "aus", "rei\u00b7nem", "Glanz", "ge\u00b7bo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.5": {"line.1": {"text": "Wir Blumen gro\u00df und klein", "tokens": ["Wir", "Blu\u00b7men", "gro\u00df", "und", "klein"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PPER", "NN", "ADJD", "KON", "ADJD"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sind freundlich dir gewogen,", "tokens": ["Sind", "freund\u00b7lich", "dir", "ge\u00b7wo\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["VAFIN", "ADJD", "PPER", "VVPP", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Drum kommen wir gezogen", "tokens": ["Drum", "kom\u00b7men", "wir", "ge\u00b7zo\u00b7gen"], "token_info": ["word", "word", "word", "word"], "pos": ["PAV", "VVFIN", "PPER", "VVPP"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Zu dir aus Wies' und Hain;", "tokens": ["Zu", "dir", "aus", "Wies'", "und", "Hain", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "APPR", "NE", "KON", "NN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Auch sollen wir von allen Quellen", "tokens": ["Auch", "sol\u00b7len", "wir", "von", "al\u00b7len", "Quel\u00b7len"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["ADV", "VMFIN", "PPER", "APPR", "PIAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Und V\u00f6gelein", "tokens": ["Und", "V\u00f6\u00b7ge\u00b7lein"], "token_info": ["word", "word"], "pos": ["KON", "NN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Dir einen sch\u00f6nen Gru\u00df bestellen.", "tokens": ["Dir", "ei\u00b7nen", "sch\u00f6\u00b7nen", "Gru\u00df", "be\u00b7stel\u00b7len", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.6": {"line.1": {"text": "Oft auf bethauter Spur", "tokens": ["Oft", "auf", "be\u00b7thau\u00b7ter", "Spur"], "token_info": ["word", "word", "word", "word"], "pos": ["ADV", "APPR", "ADJA", "NN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Sahn wir vorbei dich wallen,", "tokens": ["Sahn", "wir", "vor\u00b7bei", "dich", "wal\u00b7len", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["VVFIN", "PPER", "ADV", "PPER", "VVINF", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Und heit'rer schien's uns Allen", "tokens": ["Und", "heit'\u00b7rer", "schien's", "uns", "Al\u00b7len"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN", "PPER", "NE"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Bei dir als auf der Flur,", "tokens": ["Bei", "dir", "als", "auf", "der", "Flur", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPER", "KOUS", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Denn nach den Freundlichen und Sch\u00f6nen", "tokens": ["Denn", "nach", "den", "Freund\u00b7li\u00b7chen", "und", "Sch\u00f6\u00b7nen"], "token_info": ["word", "word", "word", "word", "word", "word"], "pos": ["KON", "APPR", "ART", "NN", "KON", "NN"], "meter": "+--+-+-+-", "measure": "iambic.tetra.invert"}, "line.6": {"text": "Und Keuschen nur", "tokens": ["Und", "Keu\u00b7schen", "nur"], "token_info": ["word", "word", "word"], "pos": ["KON", "NN", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Kann zarter Bl\u00fcmlein Sinn sich sehnen.", "tokens": ["Kann", "zar\u00b7ter", "Bl\u00fcm\u00b7lein", "Sinn", "sich", "seh\u00b7nen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["VMFIN", "ADJA", "NN", "NN", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.7": {"line.1": {"text": "Wenn uns der Mai belebt,", "tokens": ["Wenn", "uns", "der", "Mai", "be\u00b7lebt", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "ART", "NN", "VVPP", "$,"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Dann wird aus Mondenschimmer,", "tokens": ["Dann", "wird", "aus", "Mon\u00b7den\u00b7schim\u00b7mer", ","], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "VAFIN", "APPR", "NN", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Aus Thau und Quellgeflimmer", "tokens": ["Aus", "Thau", "und", "Quell\u00b7ge\u00b7flim\u00b7mer"], "token_info": ["word", "word", "word", "word"], "pos": ["APPR", "NN", "KON", "NN"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Der Kl\u00f6cklein Glanz gewebt.", "tokens": ["Der", "Kl\u00f6c\u00b7klein", "Glanz", "ge\u00b7webt", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "NN", "NN", "VVPP", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Nichts darf den hellen Kelch entweihen;", "tokens": ["Nichts", "darf", "den", "hel\u00b7len", "Kelch", "ent\u00b7wei\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PIS", "VMFIN", "ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Denn leis' umschwebt", "tokens": ["Denn", "leis'", "um\u00b7schwebt"], "token_info": ["word", "word", "word"], "pos": ["KON", "ADJD", "VVFIN"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Uns stets der Tanz der Blumenfeien.", "tokens": ["Uns", "stets", "der", "Tanz", "der", "Blu\u00b7men\u00b7fei\u00b7en", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "ART", "NN", "ART", "NN", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}, "stanza.8": {"line.1": {"text": "Doch zarte Liebe schleicht", "tokens": ["Doch", "zar\u00b7te", "Lie\u00b7be", "schleicht"], "token_info": ["word", "word", "word", "word"], "pos": ["KON", "ADJA", "NN", "VVFIN"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.2": {"text": "Uns doch in's Herz allm\u00e4hlig,", "tokens": ["Uns", "doch", "in's", "Herz", "all\u00b7m\u00e4h\u00b7lig", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "APPRART", "NN", "ADJD", "$,"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.3": {"text": "Wir suchen minneselig", "tokens": ["Wir", "su\u00b7chen", "min\u00b7ne\u00b7se\u00b7lig"], "token_info": ["word", "word", "word"], "pos": ["PPER", "VVFIN", "ADJD"], "meter": "-+-+-+-", "measure": "iambic.tri"}, "line.4": {"text": "Ein Liebchen, das uns gleicht.", "tokens": ["Ein", "Lieb\u00b7chen", ",", "das", "uns", "gleicht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct"], "pos": ["ART", "NN", "$,", "PRELS", "PPER", "VVFIN", "$."], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Dich haben wir uns auserkoren;", "tokens": ["Dich", "ha\u00b7ben", "wir", "uns", "au\u00b7ser\u00b7ko\u00b7ren", ";"], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "PPER", "PRF", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Bist du vielleicht", "tokens": ["Bist", "du", "viel\u00b7leicht"], "token_info": ["word", "word", "word"], "pos": ["VAFIN", "PPER", "ADV"], "meter": "-+-+", "measure": "iambic.di"}, "line.7": {"text": "Wie wir aus reinem Glanz geboren?", "tokens": ["Wie", "wir", "aus", "rei\u00b7nem", "Glanz", "ge\u00b7bo\u00b7ren", "?"], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "APPR", "ADJA", "NN", "VVPP", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}}}}}