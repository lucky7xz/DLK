{"dta.poem.10117": {"metadata": {"author": {"name": "Brockes, Barthold Heinrich", "birth": "N.A.", "death": "N.A."}, "title": "B\u00e4ume.", "genre": "Lyrik", "period": "N.A.", "pub_year": "1735", "urn": "urn:nbn:de:kobv:b4-20086-0", "language": ["de:0.99"], "booktitle": "N.A."}, "poem": {"stanza.1": {"line.1": {"text": "Wir haben, bey der Frucht, der B\u00e4ume schon gedacht.", "tokens": ["Wir", "ha\u00b7ben", ",", "bey", "der", "Frucht", ",", "der", "B\u00e4u\u00b7me", "schon", "ge\u00b7dacht", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VAFIN", "$,", "APPR", "ART", "NN", "$,", "ART", "NN", "ADV", "VVPP", "$."], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Allein dieselbigen verdienen,", "tokens": ["Al\u00b7lein", "die\u00b7sel\u00b7bi\u00b7gen", "ver\u00b7die\u00b7nen", ","], "token_info": ["word", "word", "word", "punct"], "pos": ["ADV", "PDS", "VVINF", "$,"], "meter": "-+--+--+-", "measure": "amphibrach.tri"}, "line.3": {"text": "Da\u00df hier insonderheit von ihnen", "tokens": ["Da\u00df", "hier", "in\u00b7son\u00b7der\u00b7heit", "von", "ih\u00b7nen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["KOUS", "ADV", "ADV", "APPR", "PPER"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Noch etwas werde beygebracht.", "tokens": ["Noch", "et\u00b7was", "wer\u00b7de", "bey\u00b7ge\u00b7bracht", "."], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ADV", "PIS", "VAFIN", "VVPP", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}, "stanza.2": {"line.1": {"text": "Es giebet B\u00e4um\u2019, auf deren Rinden", "tokens": ["Es", "gie\u00b7bet", "B\u00e4um'", ",", "auf", "de\u00b7ren", "Rin\u00b7den"], "token_info": ["word", "word", "word", "punct", "word", "word", "word"], "pos": ["PPER", "VVFIN", "NN", "$,", "APPR", "PRELAT", "NN"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.2": {"text": "Wir zweymahl Fr\u00fccht\u2019 in einem Jahr,", "tokens": ["Wir", "zwey\u00b7mahl", "Fr\u00fccht'", "in", "ei\u00b7nem", "Jahr", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "ADV", "NN", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Mit billigem Erstaunen, finden:", "tokens": ["Mit", "bil\u00b7li\u00b7gem", "Er\u00b7stau\u00b7nen", ",", "fin\u00b7den", ":"], "token_info": ["word", "word", "word", "punct", "word", "punct"], "pos": ["APPR", "ADJA", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.4": {"text": "Wann noch auf andern gar", "tokens": ["Wann", "noch", "auf", "an\u00b7dern", "gar"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PWAV", "ADV", "APPR", "PIS", "ADV"], "meter": "-+-+-+", "measure": "iambic.tri"}, "line.5": {"text": "Sich Jahr\u2019 und Jahres-Zeiten binden.", "tokens": ["Sich", "Jahr'", "und", "Jah\u00b7res\u00b7Zei\u00b7ten", "bin\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PRF", "NN", "KON", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.6": {"text": "Da wir auf ihnen, sonder Zahl,", "tokens": ["Da", "wir", "auf", "ih\u00b7nen", ",", "son\u00b7der", "Zahl", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct"], "pos": ["KOUS", "PPER", "APPR", "PPER", "$,", "KON", "NN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Nicht reiff\u2019 und reiffe Fr\u00fccht\u2019 und Bluhmen,", "tokens": ["Nicht", "reiff'", "und", "reif\u00b7fe", "Fr\u00fccht'", "und", "Bluh\u00b7men", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "KON", "ADJA", "NN", "KON", "NN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.8": {"text": "Woran zugleich sich Zung und Nas\u2019 und Aug\u2019 erquicken,", "tokens": ["Wo\u00b7ran", "zu\u00b7gleich", "sich", "Zung", "und", "Nas'", "und", "Aug'", "er\u00b7qui\u00b7cken", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "ADV", "PRF", "NN", "KON", "NN", "KON", "NN", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Mit einer gantz von Lust durchdrungnen Seel\u2019 erblicken.", "tokens": ["Mit", "ei\u00b7ner", "gantz", "von", "Lust", "durch\u00b7drung\u00b7nen", "Seel'", "er\u00b7bli\u00b7cken", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "ART", "ADV", "APPR", "NN", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Indem wir ja darin von unsers Sch\u00f6pfers Macht", "tokens": ["In\u00b7dem", "wir", "ja", "da\u00b7rin", "von", "un\u00b7sers", "Sch\u00f6p\u00b7fers", "Macht"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word"], "pos": ["KOUS", "PPER", "ADV", "PAV", "APPR", "PPOSAT", "NN", "NN"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.11": {"text": "Die unumschr\u00e4nckte Freiheit sehen;", "tokens": ["Die", "un\u00b7um\u00b7schr\u00e4nck\u00b7te", "Frei\u00b7heit", "se\u00b7hen", ";"], "token_info": ["word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "VVINF", "$."], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.12": {"text": "Da\u00df, da Er der Natur Gesetz ver\u00e4ndern kann,", "tokens": ["Da\u00df", ",", "da", "Er", "der", "Na\u00b7tur", "Ge\u00b7setz", "ver\u00b7\u00e4n\u00b7dern", "kann", ","], "token_info": ["word", "punct", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "$,", "KOUS", "PPER", "ART", "NN", "NN", "VVINF", "VMFIN", "$,"], "meter": "-+-+-+-+-+-+", "measure": "alexandrine.iambic.hexa"}, "line.13": {"text": "Er ihr Beherrscher sey, und da\u00df, von allen Sachen,", "tokens": ["Er", "ihr", "Be\u00b7herr\u00b7scher", "sey", ",", "und", "da\u00df", ",", "von", "al\u00b7len", "Sa\u00b7chen", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "word", "punct"], "pos": ["PPER", "PPOSAT", "NN", "VAFIN", "$,", "KON", "KOUS", "$,", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.14": {"text": "Er alles, was Er will, zu aller Zeit kann machen.", "tokens": ["Er", "al\u00b7les", ",", "was", "Er", "will", ",", "zu", "al\u00b7ler", "Zeit", "kann", "ma\u00b7chen", "."], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "PIS", "$,", "PRELS", "PPER", "VMFIN", "$,", "APPR", "PIAT", "NN", "VMFIN", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}}, "stanza.3": {"line.1": {"text": "Ich finde, da\u00df die B\u00e4nme, welche klein", "tokens": ["Ich", "fin\u00b7de", ",", "da\u00df", "die", "B\u00e4n\u00b7me", ",", "wel\u00b7che", "klein"], "token_info": ["word", "word", "punct", "word", "word", "word", "punct", "word", "word"], "pos": ["PPER", "VVFIN", "$,", "KOUS", "ART", "NN", "$,", "PRELS", "ADJD"], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.2": {"text": "Und von der Mittel-Gattung seyn,", "tokens": ["Und", "von", "der", "Mit\u00b7tel\u00b7Gat\u00b7tung", "seyn", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["KON", "APPR", "ART", "NN", "VAINF", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.3": {"text": "Die niedlichsten und besten Fr\u00fcchte bringen.", "tokens": ["Die", "nied\u00b7lichs\u00b7ten", "und", "bes\u00b7ten", "Fr\u00fcch\u00b7te", "brin\u00b7gen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "KON", "ADJA", "NN", "VVINF", "$."], "meter": "-+---+-+-+-", "measure": "dactylic.init"}, "line.4": {"text": "Je mehr sie in die H\u00f6he dringen,", "tokens": ["Je", "mehr", "sie", "in", "die", "H\u00f6\u00b7he", "drin\u00b7gen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "PPER", "APPR", "ART", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+-", "measure": "iambic.tetra"}, "line.5": {"text": "Je minder ist die Frucht f\u00fcr uns bequem.", "tokens": ["Je", "min\u00b7der", "ist", "die", "Frucht", "f\u00fcr", "uns", "be\u00b7quem", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["ADV", "ADV", "VAFIN", "ART", "NN", "APPR", "PPER", "ADJD", "$."], "meter": "-+-+-+-+-+", "measure": "iambic.penta"}, "line.6": {"text": "Woraus ich diese Lehre nehm,", "tokens": ["Wo\u00b7raus", "ich", "die\u00b7se", "Leh\u00b7re", "nehm", ","], "token_info": ["word", "word", "word", "word", "word", "punct"], "pos": ["PWAV", "PPER", "PDAT", "NN", "VVFIN", "$,"], "meter": "-+-+-+-+", "measure": "iambic.tetra"}, "line.7": {"text": "Und deucht mich, da\u00df insonderheit die Reben", "tokens": ["Und", "deucht", "mich", ",", "da\u00df", "in\u00b7son\u00b7der\u00b7heit", "die", "Re\u00b7ben"], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word"], "pos": ["KON", "VVFIN", "PPER", "$,", "KOUS", "ADV", "ART", "NN"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.8": {"text": "In ihrer Sprache mir dieselbe deutlich geben:", "tokens": ["In", "ih\u00b7rer", "Spra\u00b7che", "mir", "die\u00b7sel\u00b7be", "deut\u00b7lich", "ge\u00b7ben", ":"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["APPR", "PPOSAT", "NN", "PPER", "PDAT", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.9": {"text": "Da\u00df in der Niedrigkeit, und nahe bey der Erden,", "tokens": ["Da\u00df", "in", "der", "Nied\u00b7rig\u00b7keit", ",", "und", "na\u00b7he", "bey", "der", "Er\u00b7den", ","], "token_info": ["word", "word", "word", "word", "punct", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "APPR", "ART", "NN", "$,", "KON", "ADJD", "APPR", "ART", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.10": {"text": "Die besten Fr\u00fcchte meist gefunden werden.", "tokens": ["Die", "bes\u00b7ten", "Fr\u00fcch\u00b7te", "meist", "ge\u00b7fun\u00b7den", "wer\u00b7den", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["ART", "ADJA", "NN", "ADV", "VVPP", "VAINF", "$."], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}}, "stanza.4": {"line.1": {"text": "Die andern, welche nichts als Bl\u00e4tter tragen, n\u00fctzen", "tokens": ["Die", "an\u00b7dern", ",", "wel\u00b7che", "nichts", "als", "Bl\u00e4t\u00b7ter", "tra\u00b7gen", ",", "n\u00fct\u00b7zen"], "token_info": ["word", "word", "punct", "word", "word", "word", "word", "word", "punct", "word"], "pos": ["ART", "ADJA", "$,", "PRELS", "PIS", "KOKOM", "NN", "VVINF", "$,", "VVINF"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.2": {"text": "Nicht weniger, als die, so fruchtbar, da durch St\u00e4rcke", "tokens": ["Nicht", "we\u00b7ni\u00b7ger", ",", "als", "die", ",", "so", "frucht\u00b7bar", ",", "da", "durch", "St\u00e4r\u00b7cke"], "token_info": ["word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "word", "word"], "pos": ["PTKNEG", "ADV", "$,", "KOUS", "ART", "$,", "ADV", "ADJD", "$,", "KOUS", "APPR", "NN"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.3": {"text": "Sie in den H\u00e4usern uns f\u00fcr Frost und Regen, sch\u00fctzen.", "tokens": ["Sie", "in", "den", "H\u00e4u\u00b7sern", "uns", "f\u00fcr", "Frost", "und", "Re\u00b7gen", ",", "sch\u00fct\u00b7zen", "."], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "word", "punct", "word", "punct"], "pos": ["PPER", "APPR", "ART", "NN", "PPER", "APPR", "NN", "KON", "NN", "$,", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.4": {"text": "Sie dienen ferner uns in mancherley Gewercke,", "tokens": ["Sie", "die\u00b7nen", "fer\u00b7ner", "uns", "in", "man\u00b7cher\u00b7ley", "Ge\u00b7wer\u00b7cke", ","], "token_info": ["word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["PPER", "VVFIN", "ADV", "PPER", "APPR", "PIAT", "NN", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.5": {"text": "Zur Schiff-Fahrt sonderlich; so da\u00df in ihnen,", "tokens": ["Zur", "Schiff\u00b7Fahrt", "son\u00b7der\u00b7lich", ";", "so", "da\u00df", "in", "ih\u00b7nen", ","], "token_info": ["word", "word", "word", "punct", "word", "word", "word", "word", "punct"], "pos": ["APPRART", "NN", "ADJD", "$.", "ADV", "KOUS", "APPR", "PPER", "$,"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.6": {"text": "Da sie uns noch fast mehr, als die, so fruchtbar, dienen,", "tokens": ["Da", "sie", "uns", "noch", "fast", "mehr", ",", "als", "die", ",", "so", "frucht\u00b7bar", ",", "die\u00b7nen", ","], "token_info": ["word", "word", "word", "word", "word", "word", "punct", "word", "word", "punct", "word", "word", "punct", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "ADV", "ADV", "ADV", "$,", "KOUS", "ART", "$,", "ADV", "ADJD", "$,", "VVINF", "$,"], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.7": {"text": "Wenn wir es mit Vernunfft und ernstlich \u00fcberlegen;", "tokens": ["Wenn", "wir", "es", "mit", "Ver\u00b7nunfft", "und", "ernst\u00b7lich", "\u00fc\u00b7berl\u00b7e\u00b7gen", ";"], "token_info": ["word", "word", "word", "word", "word", "word", "word", "word", "punct"], "pos": ["KOUS", "PPER", "PPER", "APPR", "NN", "KON", "ADJD", "VVINF", "$."], "meter": "-+-+-+-+-+-+-", "measure": "alexandrine.iambic.hexa"}, "line.8": {"text": "Man G\u00f6ttliche Versehung auch de\u00dfwegen", "tokens": ["Man", "G\u00f6tt\u00b7li\u00b7che", "Ver\u00b7se\u00b7hung", "auch", "de\u00df\u00b7we\u00b7gen"], "token_info": ["word", "word", "word", "word", "word"], "pos": ["PIS", "NN", "NN", "ADV", "PAV"], "meter": "-+-+-+-+-+-", "measure": "iambic.penta"}, "line.9": {"text": "Nicht guug erh\u00f6hn und preisen kann.", "tokens": ["Nicht", "guug", "er\u00b7h\u00f6hn", "und", "prei\u00b7sen", "kann", "."], "token_info": ["word", "word", "word", "word", "word", "word", "punct"], "pos": ["PTKNEG", "ADJD", "VVINF", "KON", "VVFIN", "VMFIN", "$."], "meter": "-+-+-+-+", "measure": "iambic.tetra"}}}}}